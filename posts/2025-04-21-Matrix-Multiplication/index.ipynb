{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: Optimizing Matrix Multiplication Using Numba and Broadcasting\n",
        "date: \"2025-04-21\"\n",
        "author: Vishal Bakshi\n",
        "description: Following the fastai course part 2 Lesson 11 video, I optimize the naive Python nested for-loop matrix multiplication using PyTorch, NumPy and Numba to achieve a 12000x speedup! \n",
        "filters:\n",
        "   - lightbox\n",
        "lightbox: auto\n",
        "categories:\n",
        "    - python\n",
        "    - deep learning\n",
        "    - LLM\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd0WtgRwidc0"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4U0laITif1g"
      },
      "source": [
        "In this notebook I'll solidy the matrix multiplication concepts taught in Lesson 11 of the fastai course (part 2). Most importantly, I want to make sure I understand the use of broadcasting to make the matmul operation 7000x faster!\n",
        "\n",
        "Here's a summary of run times for the five methods explored in this blog post:\n",
        "\n",
        "|Method|Images|Run Time (ms)|\n",
        "|:-:|:-:|:-:|\n",
        "|Python for-loops|5|1090ms|\n",
        "|Numba-compiled Dot Product|5|0.555ms|\n",
        "|Python Dot Product|5|1.47ms|\n",
        "|PyTorch Dot Product|5|1.22ms|\n",
        "|PyTorch Broadcasting|5|0.158ms|\n",
        "|Numba-compiled Broadcasting|5|0.0936ms|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's my video walkthrough of the code in this notebook:\n",
        "\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/-t8b7Otfmjo?si=XxML2gDu0u2H9P0g\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO915_wVir7C"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyZ8XLLpis4J"
      },
      "source": [
        "We'll use the MNIST dataset for this exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "P3WBHJv6lMAw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import tensor\n",
        "from pathlib import Path\n",
        "import pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IawGw_Atlv8F"
      },
      "outputs": [],
      "source": [
        "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
        "path_data = Path('data')\n",
        "path_data.mkdir(exist_ok=True)\n",
        "path_gz = path_data/'mnist.pkl.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SCWgX4sxlyV-"
      },
      "outputs": [],
      "source": [
        "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)\n",
        "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTY2MmFgm7bV",
        "outputId": "314ea9fa-e0ee-4889-b82b-2fa6eb76da22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 16656\n",
            "-rw-r--r-- 1 root root 17051982 Apr 21 22:56 mnist.pkl.gz\n"
          ]
        }
      ],
      "source": [
        "!ls -l data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od1BcYqx-0kk",
        "outputId": "35f01f0b-da44-4f57-ecd7-0735437dd72e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 784])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntjfvFFSoPJl",
        "outputId": "b485d5c3-2095-4a56-87d4-1aa1d0932eed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 28, 28])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imgs = x_train.reshape((-1,28,28))\n",
        "imgs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "lSPW0-ZcjBoN",
        "outputId": "2bf4f561-0371-41b3-fae9-e322e1b8d812"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(imgs[0]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wloq4AwVjFrd"
      },
      "source": [
        "For our weights, we'll create a set of random floats with shape 784 (rows) x 10 (columns). In an applied sense, these 10 outputs would be the logits associated with the ten possible digits (0-9) for each 28x28 image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btYIP-p8lPrr",
        "outputId": "1f22c0e7-a087-4b0b-b0d1-dd41e8940ecb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([784, 10])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(1)\n",
        "weights = torch.randn(784, 10)\n",
        "weights.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdZ8FOQ3jbEp"
      },
      "source": [
        "For our inputs (which get multiplied by our weights) we'll use the first 5 digits (28x28 images) from the validation set. These inputs and our weights are the two matrices we want to multiply!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rSMKbballXl0"
      },
      "outputs": [],
      "source": [
        "m1 = x_valid[:5]\n",
        "m2 = weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEICK5XupV27",
        "outputId": "212a05d8-26bd-4556-860b-257409a0fee5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5, 784]), torch.Size([784, 10]))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m1.shape,m2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HVWkWwjji2i"
      },
      "source": [
        "## Initial Solution: Python for-Loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylfbrt5QqUqH"
      },
      "source": [
        "![Naive implementation of matrix multiplication](1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG6MuLFGkwqp"
      },
      "source": [
        "For our first iteration, we'll do a nested for-loop---the most naive implementation of matrix multiplication in this exercise.\n",
        "\n",
        "We iterate through the 5 rows of our input matrix (images). For each row, we iterate through each column of our weights matrix. For each of the 784 elements in that row/column (i,j) combination, we take the dot product and store it in the output matrix. 5 images x 10 outputs x 784 elements = 39200 total items operated on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysqpA6A-zLgD",
        "outputId": "cb867e65-bd14-4756-a67d-532d55b3abd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39200"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "5*10*784"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-xaEHUhpWCF",
        "outputId": "60c72dc6-52ab-412f-a330-aa63684b44da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5, 784), (784, 10))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ar,ac = m1.shape # n_rows * n_cols\n",
        "br,bc = m2.shape\n",
        "(ar,ac),(br,bc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQk6d1OVpYPN",
        "outputId": "8425c8be-f9b5-40d5-f2d0-d7d301d18c05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t1 = torch.zeros(ar, bc) # resultant tensor\n",
        "t1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wAEWlmMCpg7I"
      },
      "outputs": [],
      "source": [
        "for i in range(ar): #5\n",
        "    for j in range(bc): # 10\n",
        "        for k in range(ac): # 784\n",
        "            t1[i,j] += m1[i,k] * m2[k,j]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv7smUVkzWUg"
      },
      "source": [
        "The resulting matrix has 5 rows (1 for each image) and 10 columns (one for each \"neuron\" in our weights matrix)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSzL6S4kxD4h",
        "outputId": "237f3596-1c48-43c0-bb07-bae65246ac40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n",
              "        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n",
              "        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n",
              "        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n",
              "        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wa-BgDT_xM56"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=2, linewidth=140)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BId-_fOGzc9Q"
      },
      "source": [
        "Wrapping this code into a function we can time it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "VS96poD6xNnJ"
      },
      "outputs": [],
      "source": [
        "def matmul(a,b):\n",
        "    (ar,ac),(br,bc) = a.shape,b.shape\n",
        "    c = torch.zeros(ar, bc)\n",
        "    for i in range(ar):\n",
        "        for j in range(bc):\n",
        "            for k in range(ac): c[i,j] += a[i,k] * b[k,j]\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3PigzmNxfvh",
        "outputId": "20110470-6efe-4296-fe08-6e37fb72d9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.09 s, sys: 544 µs, total: 1.09 s\n",
            "Wall time: 1.09 s\n"
          ]
        }
      ],
      "source": [
        "%time _=matmul(m1, m2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWUuBoZ1zhEa"
      },
      "source": [
        "It takes a whopping 1.09 seconds to perform this matrix multiplication for 5 images! Let's optimize this with numba."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qwINl7Ezn-v"
      },
      "source": [
        "## Compiling the Dot Product with Numba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhsZy9Nc7f7S"
      },
      "source": [
        "![Matrix multiplication using a numba-compiled dot product operation](2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u4x4TObzq7q"
      },
      "source": [
        "To reduce the number of python for-loops, we write the dot product (between the two 784-element vectors) in numba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "DA_6IoHtxiNJ"
      },
      "outputs": [],
      "source": [
        "from numba import njit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "Qqul_8Y4xv9R"
      },
      "outputs": [],
      "source": [
        "@njit\n",
        "def dot(a,b):\n",
        "    res = 0.\n",
        "    for i in range(len(a)): res+=a[i]*b[i]\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "KlpGjVZzx7KI"
      },
      "outputs": [],
      "source": [
        "from numpy import array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64JBuByIz_Vr"
      },
      "source": [
        "The first run of `dot` takes longer as it includes the compile time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z61sz30yx9N-",
        "outputId": "61b070bc-e64a-4931-eb9a-16dc74db549c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 123 ms, sys: 0 ns, total: 123 ms\n",
            "Wall time: 124 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%time dot(array([1.,2,3]),array([2.,3,4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbCX5IIX0Daz"
      },
      "source": [
        "The second run is 250x times faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa1xJF8f0E8c",
        "outputId": "8b7c64a0-582c-4b7f-ba4c-fae8fbcf9c26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "253.5787321063395"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0.124/0.000489"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPypreqex-rH",
        "outputId": "30d7d3a4-c845-477c-9623-675a383c6fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 40 µs, sys: 5 µs, total: 45 µs\n",
            "Wall time: 48.9 µs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%time dot(array([1.,2,3]),array([2.,3,4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjJGFzUb0JOL"
      },
      "source": [
        "We replace the third for-loop with our numba `dot` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "id": "AfDPEAXmyAx_"
      },
      "outputs": [],
      "source": [
        "def matmul(a,b):\n",
        "    (ar,ac),(br,bc) = a.shape,b.shape\n",
        "    c = torch.zeros(ar, bc)\n",
        "    for i in range(ar):\n",
        "        for j in range(bc): c[i,j] = dot(a[i,:], b[:,j])\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Jam2t1sbyZxz"
      },
      "outputs": [],
      "source": [
        "m1a,m2a = m1.numpy(),m2.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "5qnb7LpgyOsh"
      },
      "outputs": [],
      "source": [
        "from fastcore.test import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xOWL_Hd0R2t"
      },
      "source": [
        "We test that it yields the same result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "nKuI8eCFyTnp"
      },
      "outputs": [],
      "source": [
        "test_close(t1,matmul(m1a, m2a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-vSj7yyykIF",
        "outputId": "b9655c05-775a-425e-8921-91505c5a4d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "555 µs ± 14.5 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 50 matmul(m1a,m2a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAv2taYz0Z5X"
      },
      "source": [
        "Our numba-compiled `dot` operation makes our matrix multiplication 2000x faster!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DalDYa2yuKd",
        "outputId": "5d850c83-dc19-43fb-a238-e613ef13bfc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1963.963963963964"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1.09/555e-6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeArXqb_7q-3"
      },
      "source": [
        "The same operation can be done in Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "DbV7NrHy8u9A"
      },
      "outputs": [],
      "source": [
        "def matmul(a,b):\n",
        "    (ar,ac),(br,bc) = a.shape,b.shape\n",
        "    c = torch.zeros(ar, bc)\n",
        "    for i in range(ar):\n",
        "        for j in range(bc): c[i,j] = (a[i,:] * b[:,j]).sum()\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "HwheOolN-qFh"
      },
      "outputs": [],
      "source": [
        "test_close(t1,matmul(m1, m2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRyNzwNa7xMz"
      },
      "source": [
        "But it's three times slower than numba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZopM95q-rqQ",
        "outputId": "e9b4fe5b-ca19-4d9c-ab52-6b6e5b7f5cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.47 ms ± 32.3 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 50 _=matmul(m1, m2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUMhz6it72FH"
      },
      "source": [
        "Using `torch.dot` is a smidge faster than Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "d-mPIWFN_US9"
      },
      "outputs": [],
      "source": [
        "def matmul(a,b):\n",
        "    (ar,ac),(br,bc) = a.shape,b.shape\n",
        "    c = torch.zeros(ar, bc)\n",
        "    for i in range(ar):\n",
        "        for j in range(bc): c[i,j] = torch.dot(a[i,:], b[:,j])\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "8yBZVfq7_Ugn"
      },
      "outputs": [],
      "source": [
        "test_close(t1,matmul(m1, m2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZFT8mET_V4d",
        "outputId": "60fdda95-41de-4628-b901-bd94f407e572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.22 ms ± 39.1 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 50 _=matmul(m1, m2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROWkEFJs8CmU"
      },
      "source": [
        "## Faster: Use Broadcasting!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQQ9srw7kq_3"
      },
      "source": [
        "![Using broadcasting to compute all image/weight dot products simultaneously!](3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrfmiHR4kkDl"
      },
      "source": [
        "Broadcasting effectively expands the smaller matrix to match the size of the larger one so that element-wise operations can take place."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YohUfJHZk7dv"
      },
      "source": [
        "Suppose we wanted to take the dot product between the first image and all 10 columns of weights. Adding a `None` during indexing adds a unit axis at that position:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sOIrwC3lEtN",
        "outputId": "2676c4cc-c732-4947-e7d1-851a3b0fadf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([784])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m1[0,:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOTvu7iok3Qh",
        "outputId": "bc6ed9d8-f7cc-48b8-b6e5-a0e3e5edcf7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([784, 1])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m1[0, :, None].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY6HMI2nlJmp",
        "outputId": "8c97f11e-a361-4495-dc0e-1b02a7a41a11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([784, 10])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT7AOIqulP9e"
      },
      "source": [
        "Multiplying (element-wise) `m1[0, :, None]` with `m2` _broadcasts_ `m1[0, :, None]` across the 10 columns of `m2`. In other words, each row of `m1[0]` is virtually copied over 10 times, one for each column of `m2`.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzwhNhu9lK2N",
        "outputId": "851cd77c-a7c6-47c4-b5ab-4cf31b2f3992"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([784, 10])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(m1[0, :, None] * m2).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn94hbUXo4gh",
        "outputId": "ff7e2357-7bd5-4fcc-b145-209686989ebb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 784])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_-i2W9Bu5w0",
        "outputId": "6d3005bf-b2b3-47df-ed78-974f090d94e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMGfPFA2lkFd"
      },
      "source": [
        "Here's a smaller example. `a` has 5 rows, \"images\", each with 4 pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGwpausVllfm",
        "outputId": "a1c16304-fd94-4b01-e12c-dfe5d97511b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 4, 3, 4],\n",
              "        [1, 4, 1, 3],\n",
              "        [3, 2, 2, 4],\n",
              "        [3, 1, 3, 1],\n",
              "        [2, 3, 1, 1]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.randint(low=1, high=5, size=(5,4))\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dtmcdmo9mDvT"
      },
      "source": [
        "We pluck out the first \"image\" with `0`, then add a unit axis at the end with `None` to make it \"broadcastable\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnB9Xpcymad7",
        "outputId": "917a5f84-282b-4c51-bf82-4860c08cc859"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1],\n",
              "        [4],\n",
              "        [3],\n",
              "        [4]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[0, :, None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8l2ykqamCkM",
        "outputId": "19287d6f-36f8-42e6-8136-36cb6881f1ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), torch.Size([4, 1]))"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.shape, a[0, :, None].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7KjpaComJss"
      },
      "source": [
        "Suppose we have weights `w` with 4 rows, each 10 columns wide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh56RRbMmN8I",
        "outputId": "2370ca54-9190-4415-d920-171c9c705707"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 2, 1, 1, 4, 3, 4, 2, 4, 3],\n",
              "        [1, 2, 4, 2, 4, 1, 3, 1, 2, 1],\n",
              "        [4, 3, 4, 3, 1, 2, 1, 3, 3, 4],\n",
              "        [1, 3, 3, 3, 3, 1, 1, 1, 4, 4]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w = torch.randint(low=1, high=5, size=(4, 10))\n",
        "w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8PjXt_rmWer"
      },
      "source": [
        "We broadcast the 4-vector `a[0, :, None]` across all 10 4-vectors in `w`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXYBzc8WvgJQ",
        "outputId": "73442351-22b9-46eb-cde5-d4ee374d2679"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 2,  2,  1,  1,  4,  3,  4,  2,  4,  3],\n",
              "        [ 4,  8, 16,  8, 16,  4, 12,  4,  8,  4],\n",
              "        [12,  9, 12,  9,  3,  6,  3,  9,  9, 12],\n",
              "        [ 4, 12, 12, 12, 12,  4,  4,  4, 16, 16]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a[0, :, None] * w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMj1QTqqvpoc"
      },
      "source": [
        "Then take the sum down the columns (along the row axis) to get the 10 output \"activations\" for this \"image\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag1eJJdVvtbq",
        "outputId": "0795be2f-d5b5-42a7-91f8-13d352fc7a46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([22, 31, 41, 30, 35, 17, 23, 19, 37, 35])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(a[0, :, None] * w).sum(dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng6U5oICvyQ5"
      },
      "source": [
        "Looking at the first value of `22`, it comes from the dot product between the first \"image\" in `a` and the first row of weights (the \"neuron\") in `w`:\n",
        "\n",
        "22 = 1\\*2 + 4\\*1 + 3\\*4 + 4\\*1 = 2 + 4 + 12 + 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPbs5jR_wy9U"
      },
      "source": [
        "In this way, we have the dot product between the first image and all 10 columns. This is the first row of the matrix product between `a` and `w`.\n",
        "\n",
        "We can then loop over the images, broadcasting it across the weight matrix, summing down the columns to get each subsequent row of our resultant matrix product:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxRRLga7xHH-",
        "outputId": "db6f46a2-bfa0-48a7-b336-5f5c1332f01f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 4, 4, 10)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(ar,ac),(wr,wc) = a.shape,w.shape\n",
        "ar,ac,wr,wc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNxa4nTGxL0v",
        "outputId": "2b8330a8-6dbd-4092-8f5f-6aaeaf7ccdfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5, 10])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c = torch.zeros(ar, wc)\n",
        "c.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5p88YJAxYkY",
        "outputId": "ab5b28b8-b7be-4d85-da36-730fd8943ca4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[22., 31., 41., 30., 35., 17., 23., 19., 37., 35.],\n",
              "        [13., 22., 30., 21., 30., 12., 20., 12., 27., 23.],\n",
              "        [20., 28., 31., 25., 34., 19., 24., 18., 38., 35.],\n",
              "        [20., 20., 22., 17., 22., 17., 19., 17., 27., 26.],\n",
              "        [12., 16., 21., 14., 24., 12., 19., 11., 21., 17.]])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in range(ar):\n",
        "    c[i] = (a[i, :, None] * w).sum(dim=0)\n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWFFwCVmxgPo"
      },
      "source": [
        "In this way, we have performed matrix multiplication by taking the dot product of each row/column using broadcasting! Returning to our original dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "1DldybGPRwy4"
      },
      "outputs": [],
      "source": [
        "def matmul(a,b):\n",
        "    (ar,ac),(br,bc) = a.shape,b.shape\n",
        "    c = torch.zeros(ar, bc)\n",
        "    for i in range(ar): c[i]  = (a[i,:,None] * b).sum(dim=0)\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "5l_VgnzhR96S"
      },
      "outputs": [],
      "source": [
        "test_close(t1,matmul(m1, m2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXooe0hzR_f5",
        "outputId": "dcb5e610-3ea9-4af8-83bf-c0390020cd2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "158 µs ± 15.1 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 50 _=matmul(m1, m2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilxBYKW2yIOV"
      },
      "source": [
        "This gives us a 8x speedup from the numba-compiled dot product (1.22ms --> 0.158 ms)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4-FHwIgyObl"
      },
      "source": [
        "Now, instead of 5 images we can perform matmul with all 50k images in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Qh7dXbuSBhC",
        "outputId": "3877da3f-6cfe-433f-f7bc-6e70d2b80678"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0.96,  -2.96,  -2.11,  ..., -15.09, -17.69,   0.60],\n",
              "        [  6.89,  -0.34,   0.79,  ..., -17.13, -25.36,  16.23],\n",
              "        [-10.18,   7.38,   4.13,  ...,  -6.73,  -6.79,  -1.58],\n",
              "        ...,\n",
              "        [  7.40,   7.64,  -3.50,  ...,  -1.02, -16.22,   2.07],\n",
              "        [  3.25,   9.52,  -9.37,  ...,   2.98, -19.58,  -1.96],\n",
              "        [ 15.70,   4.12,  -5.62,  ...,   8.08, -12.21,   0.42]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr = matmul(x_train, weights)\n",
        "tr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE127dCLhSb4",
        "outputId": "a96bae33-3c9c-4380-c4da-7df3c44e1cb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tr.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8zzZKKYyVkW"
      },
      "source": [
        "This operation now takes less than two seconds!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFa5USM0hZfQ",
        "outputId": "9b5bb005-9613-4419-dfc5-af1c2b30c464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.62 s, sys: 0 ns, total: 1.62 s\n",
            "Wall time: 1.63 s\n"
          ]
        }
      ],
      "source": [
        "%time _=matmul(x_train, weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF4XLtAr7ouX"
      },
      "source": [
        "## Fastest: Numba Broadcasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow98OlDL7qgz",
        "outputId": "4af16216-46bd-41a9-a893-aa5229bb6d54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5, 784), (784, 10))"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m1a.shape, m2a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "AT8x4_RR7wNm"
      },
      "outputs": [],
      "source": [
        "@njit\n",
        "def matmul(a,b):\n",
        "    (ar,ac),(br,bc) = a.shape,b.shape\n",
        "    c = np.zeros((ar, bc))\n",
        "    for i in range(ar): c[i] = (a[i,:,None] * b).sum(axis=0)\n",
        "    return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "FRCv_1-K8LGG"
      },
      "outputs": [],
      "source": [
        "test_close(t1,matmul(m1a, m2a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJzIFKpV8HdA",
        "outputId": "13b4fff2-ef89-4c34-9bc9-0d77963e5334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93.6 µs ± 9.26 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit -n 50 _=matmul(m1a, m2a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l92CSGWw9K9R"
      },
      "source": [
        "We can now perform matrix multiplication for all 50_000 images in less time than we could for 5 images using nested for-loops. AMAZING!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwuI61LV9EER",
        "outputId": "6f076764-93d6-41d6-a7bf-b82f5ee271a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 885 ms, sys: 0 ns, total: 885 ms\n",
            "Wall time: 881 ms\n"
          ]
        }
      ],
      "source": [
        "%time _=matmul(x_train.numpy(), weights.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD83ZpBT40h0"
      },
      "source": [
        "## Final Thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaZly_rL41zE"
      },
      "source": [
        "I've been busy with other ML projects over the past few months but I'm so glad I have gotten back in the driver's seat for fastai course part 2! The videos, content, and potential projects/exercises that spring forth are absolutely delicious. Using relatively simple building blocks, I was able to understand matrix multiplication through Python loops, numba dot product, and Yorick-inspired PyTorch broadcasting. Creating the visuals (in excalidraw) was a _must_ because I really needed to cement these concepts in my mind, as encouraged by Jeremy in the video.\n",
        "\n",
        "\n",
        "Here's the summary again of run times for each of the methods shown above:\n",
        "\n",
        "|Method|Images|Run Time (ms)|\n",
        "|:-:|:-:|:-:|\n",
        "|Python for-loops|5|1090ms|\n",
        "|Numba-compiled Dot Product|5|0.555ms|\n",
        "|Python Dot Product|5|1.47ms|\n",
        "|PyTorch Dot Product|5|1.22ms|\n",
        "|PyTorch Broadcasting|5|0.158ms|\n",
        "|Numba-compiled Broadcasting|5|0.0936ms|\n",
        "\n",
        "Using numba-compiled broadcasting, the 5-image matrix multiplication with weights experienced a 12000x speedup compared to the naive Python nested for-loop implementation! Amazing!!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
