{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Prompting LLMs Using Different Prompting Styles\n",
        "author: Vishal Bakshi\n",
        "description: In this notebook I use 20 math reasoning dataset questions to prompt three 7B-parameter LLMs using 3 different prompting styles.\n",
        "categories:\n",
        "    - deep learning\n",
        "    - LLM\n",
        "    - python\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDe7x9Jnuo4L"
      },
      "source": [
        "## Background\n",
        "\n",
        "In this notebook, I test the performance of different LLMs on a small set of samples from math reasoning datasets using zero-shot, zero-shot-Chain-of-Thought and Plan-and-Solve+ (PS+) prompting techniques. The purpose of this exercise is for me to get some practice prompting LLMs.\n",
        "\n",
        "In [a previous blog post](http://vishalbakshi.com/blog/posts/2023-10-20-PS-Prompting/), I prompted questions from math reasoning datasets to different model chat interfaces (HuggingChat, Zephyr Chat and ChatGPT). However, when presenting these results to a fastai study group, one of the more experienced members noted that these model interfaces have built-in system prompts that will interfere with the prompts provided by the user. So, in order to get a sense of how these models perform without a system prompt, I decided to prompt these models directly using HuggingFace in this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-pt_5DZuo4Q"
      },
      "source": [
        "### Models Tested\n",
        "\n",
        "I'll test three models in this exercise:\n",
        "\n",
        "- [Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)\n",
        "- [zephyr-7b-alpha](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha)\n",
        "- [Llama-2-7b-chat-hf](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVpoEQCauo4R"
      },
      "source": [
        "### Prompting Styles\n",
        "\n",
        "I'll show an example of the three different prompting styles that I'll use for this evaluation.\n",
        "\n",
        "#### Zero-shot\n",
        "\n",
        "> Q: After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid 45 dollars, what was the total of the bill?\n",
        ">\n",
        "> A: The answer is\n",
        "\n",
        "#### Zero-shot-Chain-of-Thought\n",
        "\n",
        "> Q: After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid 45 dollars, what was the total of the bill?\n",
        ">\n",
        "> A: Let’s think step by step.\n",
        "\n",
        "#### PS+\n",
        "\n",
        "> Q: After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid 45 dollars, what was the total of the bill?\n",
        ">\n",
        "> A: Let’s first understand the problem, extract relevant variables and their corresponding numerals, and devise a plan. Then, let’s carry out the plan, calculate intermediate results (pay attention to calculation and common sense), solve the problem step by step, and show the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQTvUIxRuo4S"
      },
      "source": [
        "## Loading and Trying Out the Models\n",
        "\n",
        "I'll start by loading each model and testing out a prompt for each manually:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-31T01:58:45.248095Z",
          "iopub.status.busy": "2023-10-31T01:58:45.247784Z",
          "iopub.status.idle": "2023-10-31T01:59:51.608104Z",
          "shell.execute_reply": "2023-10-31T01:59:51.607351Z",
          "shell.execute_reply.started": "2023-10-31T01:58:45.248068Z"
        },
        "id": "Syvqqtj6uo4S",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git huggingface_hub\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import notebook_login\n",
        "import pandas as pd, torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:00:37.011164Z",
          "iopub.status.busy": "2023-10-31T02:00:37.010338Z",
          "iopub.status.idle": "2023-10-31T02:00:37.034535Z",
          "shell.execute_reply": "2023-10-31T02:00:37.033556Z",
          "shell.execute_reply.started": "2023-10-31T02:00:37.011129Z"
        },
        "id": "W52n5kACuo4V",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry3fo0rSuo4V"
      },
      "source": [
        "### Mistral-7B-Instruct-v0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T00:45:54.662187Z",
          "iopub.status.busy": "2023-10-31T00:45:54.661813Z",
          "iopub.status.idle": "2023-10-31T00:47:58.585462Z",
          "shell.execute_reply": "2023-10-31T00:47:58.584617Z",
          "shell.execute_reply.started": "2023-10-31T00:45:54.662156Z"
        },
        "id": "7-5c7Tjeuo4W",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T00:48:01.125465Z",
          "iopub.status.busy": "2023-10-31T00:48:01.125115Z",
          "iopub.status.idle": "2023-10-31T00:48:22.848744Z",
          "shell.execute_reply": "2023-10-31T00:48:22.847769Z",
          "shell.execute_reply.started": "2023-10-31T00:48:01.125434Z"
        },
        "id": "nkpLOrzzuo4X",
        "outputId": "d3f6d4f9-820e-4bb5-d93d-d7d8161384f4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] \n",
            "Q: After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid 45 dollars, what was the total of the bill?\n",
            "\n",
            "A: Let's first understand the problem, extract relevant variables and their corresponding numerals, and devise a plan. Then, let's carry out the plan, calculate intermediate results (pay attention to calculation and common sense), solve the problem step by step, and show the answer.\n",
            " [/INST] Plan:\n",
            "\n",
            "1. Extract the relevant variables and their corresponding numerals.\n",
            "2. Devise a plan to solve the problem.\n",
            "3. Carry out the plan and calculate intermediate results.\n",
            "4. Solve the problem step by step.\n",
            "5. Show the answer.\n",
            "\n",
            "Solution:\n",
            "\n",
            "1. Variables and their corresponding numerals:\n",
            "- Total bill (T)\n",
            "- Number of people (N)\n",
            "- Payment per person (P)\n",
            "\n",
            "2. Plan:\n",
            "We need to determine the total bill (T) based on the number of people (N) and the payment per person (P). We can use the following equation:\n",
            "\n",
            "T = P * N\n",
            "\n",
            "3. Carrying out the plan and calculating intermediate results:\n",
            "We are given the payment per person (P) as 45 dollars. We need to find the total bill (T) by multiplying the payment per person by the number of people. We are also given the number of people (N) as Sally, Sam, and Alyssa.\n",
            "\n",
            "T = 45 * N\n",
            "\n",
            "4. Solving the problem step by step:\n",
            "We can substitute the given values into the equation\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "Q: After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid 45 dollars, what was the total of the bill?\n",
        "\n",
        "A: Let's first understand the problem, extract relevant variables and their corresponding numerals, and devise a plan. Then, let's carry out the plan, calculate intermediate results (pay attention to calculation and common sense), solve the problem step by step, and show the answer.\n",
        "\"\"\"},\n",
        "]\n",
        "\n",
        "pipe.use_default_system_prompt = False\n",
        "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "print(outputs[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfxiWXrGuo4X"
      },
      "source": [
        "### zephyr-7b-alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T01:30:37.206645Z",
          "iopub.status.busy": "2023-10-31T01:30:37.206247Z",
          "iopub.status.idle": "2023-10-31T01:33:12.461735Z",
          "shell.execute_reply": "2023-10-31T01:33:12.460554Z",
          "shell.execute_reply.started": "2023-10-31T01:30:37.206607Z"
        },
        "id": "rFPFyf6Suo4X",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T01:33:33.861590Z",
          "iopub.status.busy": "2023-10-31T01:33:33.860852Z",
          "iopub.status.idle": "2023-10-31T01:33:52.378077Z",
          "shell.execute_reply": "2023-10-31T01:33:52.376373Z",
          "shell.execute_reply.started": "2023-10-31T01:33:33.861542Z"
        },
        "id": "jKDhlM3Yuo4Y",
        "outputId": "1d2c6e87-786a-4b0c-e284-6dacd50bb06b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|user|>\n",
            "\n",
            "Q: After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid 45 dollars, what was the total of the bill?\n",
            "\n",
            "A: Let's first understand the problem, extract relevant variables and their corresponding numerals, and devise a plan. Then, let's carry out the plan, calculate intermediate results (pay attention to calculation and common sense), solve the problem step by step, and show the answer.\n",
            "</s>\n",
            "<|assistant|>\n",
            "Let's assume the total bill is x.\n",
            "\n",
            "Each person paid 45 dollars, so each person's share of the bill is 45.\n",
            "\n",
            "If the total bill is x, then the sum of each person's share is also x, as each person's share is one-third of the total bill.\n",
            "\n",
            "Therefore, we have:\n",
            "\n",
            "x = 45 + 45 + 45 (the sum of each person's share)\n",
            "\n",
            "x = 135 (the total bill)\n",
            "\n",
            "So the total bill was $135.\n",
            "\n",
            "In summary, we identified the variables (total bill and each person's share), calculated intermediate results (total of each person's share), and solved the problem by setting up an equation and calculating the total bill.\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "Q: After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid 45 dollars, what was the total of the bill?\n",
        "\n",
        "A: Let's first understand the problem, extract relevant variables and their corresponding numerals, and devise a plan. Then, let's carry out the plan, calculate intermediate results (pay attention to calculation and common sense), solve the problem step by step, and show the answer.\n",
        "\"\"\"},\n",
        "]\n",
        "\n",
        "pipe.use_default_system_prompt = False\n",
        "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "print(outputs[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilfkmkd8uo4Y"
      },
      "source": [
        "### Llama-2-7b-chat-hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:00:57.538186Z",
          "iopub.status.busy": "2023-10-31T02:00:57.537507Z",
          "iopub.status.idle": "2023-10-31T02:04:51.010113Z",
          "shell.execute_reply": "2023-10-31T02:04:51.009341Z",
          "shell.execute_reply.started": "2023-10-31T02:00:57.538153Z"
        },
        "id": "Exm-JXkguo4Y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:05:07.201844Z",
          "iopub.status.busy": "2023-10-31T02:05:07.201492Z",
          "iopub.status.idle": "2023-10-31T02:05:26.665231Z",
          "shell.execute_reply": "2023-10-31T02:05:26.664031Z",
          "shell.execute_reply.started": "2023-10-31T02:05:07.201819Z"
        },
        "id": "KoXo5gl2uo4Z",
        "outputId": "311669a4-c91c-4a44-a913-26aebaa62b8d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] Q: After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid 45 dollars, what was the total of the bill?\n",
            "\n",
            "A: Let's first understand the problem, extract relevant variables and their corresponding numerals, and devise a plan. Then, let's carry out the plan, calculate intermediate results (pay attention to calculation and common sense), solve the problem step by step, and show the answer. [/INST]  Great, let's dive into the problem!\n",
            "\n",
            "After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid $45, what was the total of the bill?\n",
            "\n",
            "To solve this problem, we need to identify the variables involved and determine their values. Let's do this by breaking down the information given in the problem:\n",
            "\n",
            "Variables:\n",
            "\n",
            "* Sally\n",
            "* Sam\n",
            "* Alyssa\n",
            "* Total bill\n",
            "\n",
            "Values:\n",
            "\n",
            "* Sally paid $45\n",
            "* Sam paid $45\n",
            "* Alyssa paid $45\n",
            "* Total bill = $45 + $45 + $45 = $135\n",
            "\n",
            "Now, let's put this information together to find the total of the bill:\n",
            "\n",
            "Total bill = $135\n",
            "\n",
            "So, the total of the bill was $135.\n",
            "\n",
            "Let me know if you have any questions or if you'd like me to explain the steps in more detail!\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"\"\"\n",
        "Q: After eating at the restaurant, Sally, Sam, and Alyssa decided to divide the bill evenly. If each person paid 45 dollars, what was the total of the bill?\n",
        "\n",
        "A: Let's first understand the problem, extract relevant variables and their corresponding numerals, and devise a plan. Then, let's carry out the plan, calculate intermediate results (pay attention to calculation and common sense), solve the problem step by step, and show the answer.\n",
        "\"\"\"},\n",
        "]\n",
        "\n",
        "pipe.use_default_system_prompt = False\n",
        "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
        "print(outputs[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2BG2KTIuo4Z"
      },
      "source": [
        "## Testing All Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii8z6W32uo4Z"
      },
      "source": [
        "I have entered 20 questions (from the Appendix of the paper [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](https://arxiv.org/pdf/2305.04091.pdf) (Lei Wang, et al)) into a CSV file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:05:56.425832Z",
          "iopub.status.busy": "2023-10-31T02:05:56.425099Z",
          "iopub.status.idle": "2023-10-31T02:05:56.483103Z",
          "shell.execute_reply": "2023-10-31T02:05:56.482192Z",
          "shell.execute_reply.started": "2023-10-31T02:05:56.425799Z"
        },
        "id": "-MhyhvmGuo4Z",
        "outputId": "a9d5dac8-77a6-442d-f14a-1a3a4f506fde",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>The average wages of a worker during a fortnig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>If 27 bottles of soda cost A cents, how much w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>In a dance class of 20 students, 20% enrolled ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MultiArith</td>\n",
              "      <td>The school cafeteria ordered 42 red apples and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      dataset                                           question\n",
              "0        AQuA  The average wages of a worker during a fortnig...\n",
              "1        AQuA  If 27 bottles of soda cost A cents, how much w...\n",
              "2       GSM8K  James decides to run 3 sprints 3 times a week....\n",
              "3       GSM8K  In a dance class of 20 students, 20% enrolled ...\n",
              "4  MultiArith  The school cafeteria ordered 42 red apples and..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/kaggle/input/questions5/questions.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjrmEvE2uo4a"
      },
      "source": [
        "To prepare the questions for the prompts, I'll prepend each question with `\"Q:\"` and append each question with `\"\\n\\nA: <instruction>\"` where `<instruction>` is the given instruction based on the type of prompt I'm constructing. For example, for Zero-shot prompting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:05:59.425434Z",
          "iopub.status.busy": "2023-10-31T02:05:59.424618Z",
          "iopub.status.idle": "2023-10-31T02:05:59.432070Z",
          "shell.execute_reply": "2023-10-31T02:05:59.431034Z",
          "shell.execute_reply.started": "2023-10-31T02:05:59.425397Z"
        },
        "id": "jZRvxOcpuo4a",
        "outputId": "ddaa5b23-1a02-448c-f3c4-e54c0c9a211e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Q: If 27 bottles of soda cost A cents, how much will B bottles cost in dollars? Answer Choices: (A) AB/2700 (B) 27/AB (C) AB/270 (D) 2700/AB (E) 100AB/27\\n\\nA: The answer is'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"Q: \" + df.question[1] + \"\\n\\nA: The answer is\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGlfzGYMuo4a"
      },
      "source": [
        "I'll use the same parameters for these models as the official chat interfaces published by the model authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vuMT6eZuo4a"
      },
      "source": [
        "I'll also create a copy of the `DataFrame` with questions in order to populate responses for each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:06:02.661508Z",
          "iopub.status.busy": "2023-10-31T02:06:02.660642Z",
          "iopub.status.idle": "2023-10-31T02:06:02.681298Z",
          "shell.execute_reply": "2023-10-31T02:06:02.680499Z",
          "shell.execute_reply.started": "2023-10-31T02:06:02.661475Z"
        },
        "id": "e0fb3bDmuo4a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_names = ['Mistral-7B-Instruct-v0.1', 'zephyr-7b-alpha', 'Llama-2-7b-chat-hf']\n",
        "prompting_styles = ['Zero-shot', 'Zero-shot-CoT', 'PS+']\n",
        "dfs = []\n",
        "\n",
        "for name in model_names:\n",
        "    model_dfs = []\n",
        "    for style in prompting_styles:\n",
        "        # create a DataFrame for each prompting style\n",
        "        temp_df = df.copy()\n",
        "        temp_df['model'] = name\n",
        "        temp_df['prompting_style'] = style\n",
        "        temp_df['response'] = None\n",
        "        model_dfs.append(temp_df)\n",
        "    # Create a DataFrame for each model and store in a list\n",
        "    model_df = pd.concat(model_dfs)\n",
        "    dfs.append(model_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjn79Ztxuo4b"
      },
      "source": [
        "I now have three `DataFrames`, one for each of my models, and each with 20 rows of questions for each prompting style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:06:06.037488Z",
          "iopub.status.busy": "2023-10-31T02:06:06.036739Z",
          "iopub.status.idle": "2023-10-31T02:06:06.048920Z",
          "shell.execute_reply": "2023-10-31T02:06:06.048015Z",
          "shell.execute_reply.started": "2023-10-31T02:06:06.037455Z"
        },
        "id": "YYSebRfOuo4b",
        "outputId": "4f52390d-e740-4955-f55c-8651a688e79d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>question</th>\n",
              "      <th>model</th>\n",
              "      <th>prompting_style</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>The average wages of a worker during a fortnig...</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>If 27 bottles of soda cost A cents, how much w...</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>In a dance class of 20 students, 20% enrolled ...</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MultiArith</td>\n",
              "      <td>The school cafeteria ordered 42 red apples and...</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      dataset                                           question  \\\n",
              "0        AQuA  The average wages of a worker during a fortnig...   \n",
              "1        AQuA  If 27 bottles of soda cost A cents, how much w...   \n",
              "2       GSM8K  James decides to run 3 sprints 3 times a week....   \n",
              "3       GSM8K  In a dance class of 20 students, 20% enrolled ...   \n",
              "4  MultiArith  The school cafeteria ordered 42 red apples and...   \n",
              "\n",
              "                      model prompting_style response  \n",
              "0  Mistral-7B-Instruct-v0.1       Zero-shot     None  \n",
              "1  Mistral-7B-Instruct-v0.1       Zero-shot     None  \n",
              "2  Mistral-7B-Instruct-v0.1       Zero-shot     None  \n",
              "3  Mistral-7B-Instruct-v0.1       Zero-shot     None  \n",
              "4  Mistral-7B-Instruct-v0.1       Zero-shot     None  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs[0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:06:08.946434Z",
          "iopub.status.busy": "2023-10-31T02:06:08.945580Z",
          "iopub.status.idle": "2023-10-31T02:06:08.957734Z",
          "shell.execute_reply": "2023-10-31T02:06:08.956855Z",
          "shell.execute_reply.started": "2023-10-31T02:06:08.946403Z"
        },
        "id": "FKtIqTd3uo4b",
        "outputId": "b51cace5-5af2-478f-921a-b9a98b9b4d13",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>question</th>\n",
              "      <th>model</th>\n",
              "      <th>prompting_style</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>The average wages of a worker during a fortnig...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>If 27 bottles of soda cost A cents, how much w...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>In a dance class of 20 students, 20% enrolled ...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MultiArith</td>\n",
              "      <td>The school cafeteria ordered 42 red apples and...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      dataset                                           question  \\\n",
              "0        AQuA  The average wages of a worker during a fortnig...   \n",
              "1        AQuA  If 27 bottles of soda cost A cents, how much w...   \n",
              "2       GSM8K  James decides to run 3 sprints 3 times a week....   \n",
              "3       GSM8K  In a dance class of 20 students, 20% enrolled ...   \n",
              "4  MultiArith  The school cafeteria ordered 42 red apples and...   \n",
              "\n",
              "             model prompting_style response  \n",
              "0  zephyr-7b-alpha       Zero-shot     None  \n",
              "1  zephyr-7b-alpha       Zero-shot     None  \n",
              "2  zephyr-7b-alpha       Zero-shot     None  \n",
              "3  zephyr-7b-alpha       Zero-shot     None  \n",
              "4  zephyr-7b-alpha       Zero-shot     None  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs[1].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:06:10.567450Z",
          "iopub.status.busy": "2023-10-31T02:06:10.567072Z",
          "iopub.status.idle": "2023-10-31T02:06:10.580253Z",
          "shell.execute_reply": "2023-10-31T02:06:10.579286Z",
          "shell.execute_reply.started": "2023-10-31T02:06:10.567421Z"
        },
        "id": "GkxXhwc0uo4b",
        "outputId": "476305a9-ca74-4343-b158-a68388d1134d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>question</th>\n",
              "      <th>model</th>\n",
              "      <th>prompting_style</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>The average wages of a worker during a fortnig...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>If 27 bottles of soda cost A cents, how much w...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>In a dance class of 20 students, 20% enrolled ...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MultiArith</td>\n",
              "      <td>The school cafeteria ordered 42 red apples and...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      dataset                                           question  \\\n",
              "0        AQuA  The average wages of a worker during a fortnig...   \n",
              "1        AQuA  If 27 bottles of soda cost A cents, how much w...   \n",
              "2       GSM8K  James decides to run 3 sprints 3 times a week....   \n",
              "3       GSM8K  In a dance class of 20 students, 20% enrolled ...   \n",
              "4  MultiArith  The school cafeteria ordered 42 red apples and...   \n",
              "\n",
              "                model prompting_style response  \n",
              "0  Llama-2-7b-chat-hf       Zero-shot     None  \n",
              "1  Llama-2-7b-chat-hf       Zero-shot     None  \n",
              "2  Llama-2-7b-chat-hf       Zero-shot     None  \n",
              "3  Llama-2-7b-chat-hf       Zero-shot     None  \n",
              "4  Llama-2-7b-chat-hf       Zero-shot     None  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs[2].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_DEewvzuo4b"
      },
      "source": [
        "There should be three instances of each question, one for each prompting style:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:06:12.641697Z",
          "iopub.status.busy": "2023-10-31T02:06:12.641331Z",
          "iopub.status.idle": "2023-10-31T02:06:12.666889Z",
          "shell.execute_reply": "2023-10-31T02:06:12.666012Z",
          "shell.execute_reply.started": "2023-10-31T02:06:12.641669Z"
        },
        "id": "0xzFr7EKuo4b",
        "outputId": "8cddf533-731c-4827-a73a-99fd8e658005",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([3]), array([3]), array([3]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs[0].groupby(dfs[0].question).count()['dataset'].unique(),\\\n",
        "dfs[1].groupby(dfs[1].question).count()['dataset'].unique(),\\\n",
        "dfs[2].groupby(dfs[2].question).count()['dataset'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpLSUNUMuo4b"
      },
      "source": [
        "Each model's `DataFrame` should have 20 rows for each of the three prompting styles:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:06:14.506187Z",
          "iopub.status.busy": "2023-10-31T02:06:14.505571Z",
          "iopub.status.idle": "2023-10-31T02:06:14.518804Z",
          "shell.execute_reply": "2023-10-31T02:06:14.517894Z",
          "shell.execute_reply.started": "2023-10-31T02:06:14.506156Z"
        },
        "id": "vC7k4cZOuo4c",
        "outputId": "22028467-84ac-494c-a4e2-1a14f24086a0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([20]), array([20]), array([20]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs[0].groupby(dfs[0].prompting_style).count()['dataset'].unique(),\\\n",
        "dfs[1].groupby(dfs[1].prompting_style).count()['dataset'].unique(),\\\n",
        "dfs[2].groupby(dfs[2].prompting_style).count()['dataset'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aabj8B6uo4c"
      },
      "source": [
        "And finally, I'll check that each `DataFrame` should have `Zero-shot`, `Zero-shot-CoT` and `PS+` as the prompting styles:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:06:16.205169Z",
          "iopub.status.busy": "2023-10-31T02:06:16.204556Z",
          "iopub.status.idle": "2023-10-31T02:06:16.213905Z",
          "shell.execute_reply": "2023-10-31T02:06:16.213021Z",
          "shell.execute_reply.started": "2023-10-31T02:06:16.205138Z"
        },
        "id": "Uz6E6aVfuo4c",
        "outputId": "58f8ed82-4198-4f17-df0b-9ef9ce84e843",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['Zero-shot', 'Zero-shot-CoT', 'PS+'], dtype=object),\n",
              " array(['Zero-shot', 'Zero-shot-CoT', 'PS+'], dtype=object),\n",
              " array(['Zero-shot', 'Zero-shot-CoT', 'PS+'], dtype=object))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs[0].prompting_style.unique(),\\\n",
        "dfs[1].prompting_style.unique(),\\\n",
        "dfs[2].prompting_style.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s00rDJctuo4c"
      },
      "source": [
        "Finally, I'll create a dictionary to lookup the instruction for a given prompting style, to append to the question in the prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:06:21.834812Z",
          "iopub.status.busy": "2023-10-31T02:06:21.833942Z",
          "iopub.status.idle": "2023-10-31T02:06:21.839477Z",
          "shell.execute_reply": "2023-10-31T02:06:21.838260Z",
          "shell.execute_reply.started": "2023-10-31T02:06:21.834779Z"
        },
        "id": "AtZ7to-ouo4c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "instructions = {\n",
        "    'Zero-shot': 'The answer is',\n",
        "    'Zero-shot-CoT': \"Let's think step by step.\",\n",
        "    'PS+': \"Let’s first understand the problem, extract relevant variables and their corresponding numerals, and devise a plan. Then, let’s carry out the plan, calculate intermediate results (pay attention to calculation and common sense), solve the problem step by step, and show the answer.\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:06:23.037840Z",
          "iopub.status.busy": "2023-10-31T02:06:23.037063Z",
          "iopub.status.idle": "2023-10-31T02:06:23.043521Z",
          "shell.execute_reply": "2023-10-31T02:06:23.042632Z",
          "shell.execute_reply.started": "2023-10-31T02:06:23.037809Z"
        },
        "id": "UQffn8shuo4c",
        "outputId": "4950266b-4430-48f3-fb39-631832dce376",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Let’s first understand the problem, extract relevant variables and their corresponding numerals, and devise a plan. Then, let’s carry out the plan, calculate intermediate results (pay attention to calculation and common sense), solve the problem step by step, and show the answer.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "instructions['PS+']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftDOZucRuo4d"
      },
      "source": [
        "With my `DataFrame`s with questions and prompting styles ready, I can prompt the models one at a time. The Kaggle GPUs were running out of memory if I tried to load more than one of these models, so I have to create a new session for each model run. I export the model responses into a CSV before stopping the session so I can combine all models' responses into one `DataFrame` at the end to analyze the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX7m1DSQuo4d"
      },
      "source": [
        "### Mistral-7B-Instruct-v0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-26T02:41:55.943407Z",
          "iopub.status.busy": "2023-10-26T02:41:55.942708Z",
          "iopub.status.idle": "2023-10-26T02:45:03.065676Z",
          "shell.execute_reply": "2023-10-26T02:45:03.064889Z",
          "shell.execute_reply.started": "2023-10-26T02:41:55.943372Z"
        },
        "id": "uNdNWazLuo4d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T00:51:25.118361Z",
          "iopub.status.busy": "2023-10-31T00:51:25.117968Z",
          "iopub.status.idle": "2023-10-31T01:01:48.495156Z",
          "shell.execute_reply": "2023-10-31T01:01:48.494187Z",
          "shell.execute_reply.started": "2023-10-31T00:51:25.118327Z"
        },
        "id": "hLk3n3-ouo4e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for i in range(len(dfs[0])):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"Q: \" + dfs[0].question.iloc[i] + \"\\n\\nA: \" + instructions[dfs[0].prompting_style.iloc[i]] }\n",
        "    ]\n",
        "\n",
        "    pipe.use_default_system_prompt = False\n",
        "\n",
        "    prompt = pipe.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True)\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        do_sample=True,\n",
        "        temperature= 0.1,\n",
        "        max_new_tokens= 2048,\n",
        "        top_p= 0.95,\n",
        "        repetition_penalty= 1.2,\n",
        "        top_k= 50,\n",
        "        return_full_text= False)\n",
        "\n",
        "    dfs[0].response.iloc[i] = outputs[0][\"generated_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T01:14:34.473193Z",
          "iopub.status.busy": "2023-10-31T01:14:34.472820Z",
          "iopub.status.idle": "2023-10-31T01:14:34.485419Z",
          "shell.execute_reply": "2023-10-31T01:14:34.484264Z",
          "shell.execute_reply.started": "2023-10-31T01:14:34.473161Z"
        },
        "id": "I676Nu8iuo4f",
        "outputId": "2a893f1b-93b0-41df-d1e7-7efd0b797249",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>question</th>\n",
              "      <th>model</th>\n",
              "      <th>prompting_style</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>The average wages of a worker during a fortnig...</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>To solve this problem, we need to use the for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>If 27 bottles of soda cost A cents, how much w...</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>To convert the number of bottles from one uni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>To find out how many total meters James runs ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>In a dance class of 20 students, 20% enrolled ...</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>Let's break down this problem step by step:\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MultiArith</td>\n",
              "      <td>The school cafeteria ordered 42 red apples and...</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>33 extra apples.\\n\\nHere's the reasoning behi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      dataset                                           question  \\\n",
              "0        AQuA  The average wages of a worker during a fortnig...   \n",
              "1        AQuA  If 27 bottles of soda cost A cents, how much w...   \n",
              "2       GSM8K  James decides to run 3 sprints 3 times a week....   \n",
              "3       GSM8K  In a dance class of 20 students, 20% enrolled ...   \n",
              "4  MultiArith  The school cafeteria ordered 42 red apples and...   \n",
              "\n",
              "                      model prompting_style  \\\n",
              "0  Mistral-7B-Instruct-v0.1       Zero-shot   \n",
              "1  Mistral-7B-Instruct-v0.1       Zero-shot   \n",
              "2  Mistral-7B-Instruct-v0.1       Zero-shot   \n",
              "3  Mistral-7B-Instruct-v0.1       Zero-shot   \n",
              "4  Mistral-7B-Instruct-v0.1       Zero-shot   \n",
              "\n",
              "                                            response  \n",
              "0   To solve this problem, we need to use the for...  \n",
              "1   To convert the number of bottles from one uni...  \n",
              "2   To find out how many total meters James runs ...  \n",
              "3   Let's break down this problem step by step:\\n...  \n",
              "4   33 extra apples.\\n\\nHere's the reasoning behi...  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs[0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T01:14:40.676951Z",
          "iopub.status.busy": "2023-10-31T01:14:40.676194Z",
          "iopub.status.idle": "2023-10-31T01:14:40.684502Z",
          "shell.execute_reply": "2023-10-31T01:14:40.683732Z",
          "shell.execute_reply.started": "2023-10-31T01:14:40.676917Z"
        },
        "id": "K1TzDrAZuo4f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dfs[0].to_csv('mistral_responses.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQjhgj7vuo4f"
      },
      "source": [
        "### zephyr-7b-alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-26T03:52:01.499151Z",
          "iopub.status.busy": "2023-10-26T03:52:01.498167Z",
          "iopub.status.idle": "2023-10-26T03:53:38.275582Z",
          "shell.execute_reply": "2023-10-26T03:53:38.273670Z",
          "shell.execute_reply.started": "2023-10-26T03:52:01.499108Z"
        },
        "id": "V4ZwW7KHuo4f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T01:35:15.706124Z",
          "iopub.status.busy": "2023-10-31T01:35:15.705310Z",
          "iopub.status.idle": "2023-10-31T01:56:52.713160Z",
          "shell.execute_reply": "2023-10-31T01:56:52.712048Z",
          "shell.execute_reply.started": "2023-10-31T01:35:15.706087Z"
        },
        "id": "fCXO1qTUuo4f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for i in range(len(dfs[1])):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"Q: \" + dfs[1].question.iloc[i] + \"\\n\\nA: \" + instructions[dfs[1].prompting_style.iloc[i]] }\n",
        "    ]\n",
        "\n",
        "    pipe.use_default_system_prompt = False\n",
        "\n",
        "    prompt = pipe.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True)\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        do_sample=True,\n",
        "        temperature= 0.7,\n",
        "        max_new_tokens= 1024,\n",
        "        top_p= 0.95,\n",
        "        repetition_penalty= 1.2,\n",
        "        top_k= 50,\n",
        "        return_full_text= False)\n",
        "\n",
        "    dfs[1].response.iloc[i] = outputs[0][\"generated_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T01:57:08.182012Z",
          "iopub.status.busy": "2023-10-31T01:57:08.181142Z",
          "iopub.status.idle": "2023-10-31T01:57:08.194052Z",
          "shell.execute_reply": "2023-10-31T01:57:08.193050Z",
          "shell.execute_reply.started": "2023-10-31T01:57:08.181952Z"
        },
        "id": "_Jkbu1KOuo4g",
        "outputId": "465f803b-b29c-4043-9445-edf369bd895d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>question</th>\n",
              "      <th>model</th>\n",
              "      <th>prompting_style</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>The average wages of a worker during a fortnig...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>The total earnings for the first seven days ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>If 27 bottles of soda cost A cents, how much w...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>(A) AB/2700 \\n\\nExplanation: Let's say the pri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>James runs 3 sprints of 60 meters each, three ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>In a dance class of 20 students, 20% enrolled ...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>Let's calculate this using math:\\n\\nFirstly, l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MultiArith</td>\n",
              "      <td>The school cafeteria ordered 42 red apples and...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>Let's calculate the total number of apples (re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      dataset                                           question  \\\n",
              "0        AQuA  The average wages of a worker during a fortnig...   \n",
              "1        AQuA  If 27 bottles of soda cost A cents, how much w...   \n",
              "2       GSM8K  James decides to run 3 sprints 3 times a week....   \n",
              "3       GSM8K  In a dance class of 20 students, 20% enrolled ...   \n",
              "4  MultiArith  The school cafeteria ordered 42 red apples and...   \n",
              "\n",
              "             model prompting_style  \\\n",
              "0  zephyr-7b-alpha       Zero-shot   \n",
              "1  zephyr-7b-alpha       Zero-shot   \n",
              "2  zephyr-7b-alpha       Zero-shot   \n",
              "3  zephyr-7b-alpha       Zero-shot   \n",
              "4  zephyr-7b-alpha       Zero-shot   \n",
              "\n",
              "                                            response  \n",
              "0  The total earnings for the first seven days ar...  \n",
              "1  (A) AB/2700 \\n\\nExplanation: Let's say the pri...  \n",
              "2  James runs 3 sprints of 60 meters each, three ...  \n",
              "3  Let's calculate this using math:\\n\\nFirstly, l...  \n",
              "4  Let's calculate the total number of apples (re...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs[1].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T01:57:12.711726Z",
          "iopub.status.busy": "2023-10-31T01:57:12.710814Z",
          "iopub.status.idle": "2023-10-31T01:57:12.736529Z",
          "shell.execute_reply": "2023-10-31T01:57:12.735606Z",
          "shell.execute_reply.started": "2023-10-31T01:57:12.711691Z"
        },
        "id": "_ok1BnXcuo4g",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dfs[1].to_csv('zephyr_responses.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEUUsfgXuo4g"
      },
      "source": [
        "### Llama-2-7b-chat-hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-26T03:57:31.429215Z",
          "iopub.status.busy": "2023-10-26T03:57:31.428839Z",
          "iopub.status.idle": "2023-10-26T03:59:16.362191Z",
          "shell.execute_reply": "2023-10-26T03:59:16.361350Z",
          "shell.execute_reply.started": "2023-10-26T03:57:31.429183Z"
        },
        "id": "6LqHKNdHuo4g",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:07:09.615218Z",
          "iopub.status.busy": "2023-10-31T02:07:09.614436Z",
          "iopub.status.idle": "2023-10-31T02:21:47.599571Z",
          "shell.execute_reply": "2023-10-31T02:21:47.598443Z",
          "shell.execute_reply.started": "2023-10-31T02:07:09.615187Z"
        },
        "id": "Xizj1GRcuo4g",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "for i in range(len(dfs[2])):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"Q: \" + dfs[2].question.iloc[i] + \"\\n\\nA: \" + instructions[dfs[2].prompting_style.iloc[i]] }\n",
        "    ]\n",
        "\n",
        "    pipe.use_default_system_prompt = False\n",
        "\n",
        "    prompt = pipe.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True)\n",
        "\n",
        "    outputs = pipe(\n",
        "        prompt,\n",
        "        do_sample=True,\n",
        "        temperature= 0.1,\n",
        "        max_new_tokens= 1024,\n",
        "        top_p= 0.95,\n",
        "        repetition_penalty= 1.2,\n",
        "        top_k= 50,\n",
        "        return_full_text= False)\n",
        "\n",
        "    dfs[2].response.iloc[i] = outputs[0][\"generated_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:22:05.689688Z",
          "iopub.status.busy": "2023-10-31T02:22:05.689300Z",
          "iopub.status.idle": "2023-10-31T02:22:05.701673Z",
          "shell.execute_reply": "2023-10-31T02:22:05.700579Z",
          "shell.execute_reply.started": "2023-10-31T02:22:05.689658Z"
        },
        "id": "BDFqgwV-uo4h",
        "outputId": "0a567d36-014d-4fe9-d2ca-faab582b78c6",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>question</th>\n",
              "      <th>model</th>\n",
              "      <th>prompting_style</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>The average wages of a worker during a fortnig...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>To find the wage of the worker on the 8th da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AQuA</td>\n",
              "      <td>If 27 bottles of soda cost A cents, how much w...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>To find the cost of B bottles in dollars, we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>To find out how many total meters James runs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GSM8K</td>\n",
              "      <td>In a dance class of 20 students, 20% enrolled ...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>To find out what percentage of the entire gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MultiArith</td>\n",
              "      <td>The school cafeteria ordered 42 red apples and...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>Great question! To find out how many extra a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      dataset                                           question  \\\n",
              "0        AQuA  The average wages of a worker during a fortnig...   \n",
              "1        AQuA  If 27 bottles of soda cost A cents, how much w...   \n",
              "2       GSM8K  James decides to run 3 sprints 3 times a week....   \n",
              "3       GSM8K  In a dance class of 20 students, 20% enrolled ...   \n",
              "4  MultiArith  The school cafeteria ordered 42 red apples and...   \n",
              "\n",
              "                model prompting_style  \\\n",
              "0  Llama-2-7b-chat-hf       Zero-shot   \n",
              "1  Llama-2-7b-chat-hf       Zero-shot   \n",
              "2  Llama-2-7b-chat-hf       Zero-shot   \n",
              "3  Llama-2-7b-chat-hf       Zero-shot   \n",
              "4  Llama-2-7b-chat-hf       Zero-shot   \n",
              "\n",
              "                                            response  \n",
              "0    To find the wage of the worker on the 8th da...  \n",
              "1    To find the cost of B bottles in dollars, we...  \n",
              "2    To find out how many total meters James runs...  \n",
              "3    To find out what percentage of the entire gr...  \n",
              "4    Great question! To find out how many extra a...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dfs[2].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:22:08.986975Z",
          "iopub.status.busy": "2023-10-31T02:22:08.986082Z",
          "iopub.status.idle": "2023-10-31T02:22:08.999454Z",
          "shell.execute_reply": "2023-10-31T02:22:08.998661Z",
          "shell.execute_reply.started": "2023-10-31T02:22:08.986918Z"
        },
        "id": "tES1UCEBuo4h",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dfs[2].to_csv('llama2_responses.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM5fAK_buo4h"
      },
      "source": [
        "## Grading the Responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixywQALVuo4h"
      },
      "source": [
        "I really liked the way Johnathan Whitaker (on the Data Science Castnet YouTube channel) used gradio as a tool to check responses from an LLM, so I'm using the approach from [his notebook](https://colab.research.google.com/drive/1pXk9cbahwmtb0ultmnjGSmABjogYzDKt?usp=sharing#scrollTo=d99wEgr0rc-7) below.\n",
        "\n",
        "For each row of data, the gradio app displays the question, response and two buttons (\"Correct\" and \"Incorrect\"). If the answer is correct, I'll press \"Correct\" and the `is_correct` column value will be set to `1`. If it's not, I'll press \"Incorrect\" and `is_correct` will stay `0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T02:56:26.138818Z",
          "iopub.status.busy": "2023-10-31T02:56:26.137866Z",
          "iopub.status.idle": "2023-10-31T02:56:46.400728Z",
          "shell.execute_reply": "2023-10-31T02:56:46.399668Z",
          "shell.execute_reply.started": "2023-10-31T02:56:26.138779Z"
        },
        "id": "4vXvMimjuo4h",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#install gradio (quick fix for install error on colab)\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76-JubHvRCxx"
      },
      "source": [
        "I'll load the three CSVs (each with responses for 3 prompting styles across 20 questions from each model) into a single `DataFrame`, and sort it by the `question` column so it's easier for me to grade the responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T03:04:15.535619Z",
          "iopub.status.busy": "2023-10-31T03:04:15.534982Z",
          "iopub.status.idle": "2023-10-31T03:04:15.545883Z",
          "shell.execute_reply": "2023-10-31T03:04:15.544994Z",
          "shell.execute_reply.started": "2023-10-31T03:04:15.535587Z"
        },
        "id": "sy13xFknuo4i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import gradio as gr, pandas as pd\n",
        "from functools import partial\n",
        "\n",
        "dfs = []\n",
        "files = ['llama2_responses.csv', 'mistral_responses.csv', 'zephyr_responses.csv']\n",
        "\n",
        "for file in files:\n",
        "  df = pd.read_csv(file)\n",
        "  df = df.drop('Unnamed: 0', axis=1)\n",
        "  df['is_correct'] = 0\n",
        "  dfs.append(df)\n",
        "\n",
        "df = pd.concat(dfs, axis=0, ignore_index=True)\n",
        "\n",
        "# sort by question so it's easier to grade\n",
        "df = df.sort_values(by=['question'])\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "execution": {
          "iopub.execute_input": "2023-10-31T03:04:16.237348Z",
          "iopub.status.busy": "2023-10-31T03:04:16.236733Z",
          "iopub.status.idle": "2023-10-31T03:04:16.249585Z",
          "shell.execute_reply": "2023-10-31T03:04:16.248609Z",
          "shell.execute_reply.started": "2023-10-31T03:04:16.237313Z"
        },
        "id": "zgyNAxCmuo4i",
        "outputId": "20cf3fca-6b18-44a2-ab7a-7b230533734e",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-70e490b3-af52-4560-a200-3aa3232c10c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>question</th>\n",
              "      <th>model</th>\n",
              "      <th>prompting_style</th>\n",
              "      <th>response</th>\n",
              "      <th>is_correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Coin Flip</td>\n",
              "      <td>'A coin is heads up. Lorena does not flip the ...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>PS+</td>\n",
              "      <td>Problem understanding:\\n- The question asks wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coin Flip</td>\n",
              "      <td>'A coin is heads up. Lorena does not flip the ...</td>\n",
              "      <td>zephyr-7b-alpha</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>Yes, according to the given scenario, since no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coin Flip</td>\n",
              "      <td>'A coin is heads up. Lorena does not flip the ...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>No, the coin is no longer heads up. Since no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coin Flip</td>\n",
              "      <td>'A coin is heads up. Lorena does not flip the ...</td>\n",
              "      <td>Mistral-7B-Instruct-v0.1</td>\n",
              "      <td>Zero-shot</td>\n",
              "      <td>Yes, the coin is still heads up.\\n\\nHere's th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coin Flip</td>\n",
              "      <td>'A coin is heads up. Lorena does not flip the ...</td>\n",
              "      <td>Llama-2-7b-chat-hf</td>\n",
              "      <td>PS+</td>\n",
              "      <td>Great! Let's tackle this problem together. H...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70e490b3-af52-4560-a200-3aa3232c10c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70e490b3-af52-4560-a200-3aa3232c10c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70e490b3-af52-4560-a200-3aa3232c10c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33f5eb18-10fd-457c-ad63-b69fe5296789\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33f5eb18-10fd-457c-ad63-b69fe5296789')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33f5eb18-10fd-457c-ad63-b69fe5296789 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     dataset                                           question  \\\n",
              "0  Coin Flip  'A coin is heads up. Lorena does not flip the ...   \n",
              "1  Coin Flip  'A coin is heads up. Lorena does not flip the ...   \n",
              "2  Coin Flip  'A coin is heads up. Lorena does not flip the ...   \n",
              "3  Coin Flip  'A coin is heads up. Lorena does not flip the ...   \n",
              "4  Coin Flip  'A coin is heads up. Lorena does not flip the ...   \n",
              "\n",
              "                      model prompting_style  \\\n",
              "0           zephyr-7b-alpha             PS+   \n",
              "1           zephyr-7b-alpha       Zero-shot   \n",
              "2        Llama-2-7b-chat-hf       Zero-shot   \n",
              "3  Mistral-7B-Instruct-v0.1       Zero-shot   \n",
              "4        Llama-2-7b-chat-hf             PS+   \n",
              "\n",
              "                                            response  is_correct  \n",
              "0  Problem understanding:\\n- The question asks wh...           0  \n",
              "1  Yes, according to the given scenario, since no...           0  \n",
              "2    No, the coin is no longer heads up. Since no...           0  \n",
              "3   Yes, the coin is still heads up.\\n\\nHere's th...           0  \n",
              "4    Great! Let's tackle this problem together. H...           0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j60Dbv6xRQ3d"
      },
      "source": [
        "The gradio app consists of a `Textbox` which will display the text of the question and response. I'll modify the existing `get_text` function, which takes an index and returns a concatenated string.\n",
        "\n",
        "The `label` function is called when the user clicks either of the buttons. If the button clicked has a value of `\"Correct\"` then the `choice` parameter will be `\"correct\"` and the `is_correct` column will be set to `1`. The `label` function returns the next index and string to display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T03:04:05.030898Z",
          "iopub.status.busy": "2023-10-31T03:04:05.030480Z",
          "iopub.status.idle": "2023-10-31T03:04:05.037054Z",
          "shell.execute_reply": "2023-10-31T03:04:05.036012Z",
          "shell.execute_reply.started": "2023-10-31T03:04:05.030869Z"
        },
        "id": "1F7mi_gUuo4i",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_text(idx):\n",
        "    \"\"\" Combine the question and answer into a single string \"\"\"\n",
        "    global df\n",
        "    text = 'Q: ' + df.iloc[idx]['question'] + '\\n\\nA: ' + df.iloc[idx]['response']\n",
        "\n",
        "    return text\n",
        "\n",
        "def label(idx, choice='correct'):\n",
        "    \"\"\" Set `is_correct` column to `1` if response is correct \"\"\"\n",
        "    if choice == 'correct':\n",
        "        df.loc[idx, 'is_correct'] = 1\n",
        "    return idx+1, get_text(idx+1) # Move on to next one"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9kDIBvQSJHq"
      },
      "source": [
        "In order to avoid the gradio app from timing out, I have called `queue` on the `demo` object before I `launch` it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-31T03:04:55.089579Z",
          "iopub.status.busy": "2023-10-31T03:04:55.089210Z",
          "iopub.status.idle": "2023-10-31T03:05:07.988781Z",
          "shell.execute_reply": "2023-10-31T03:05:07.987874Z",
          "shell.execute_reply.started": "2023-10-31T03:04:55.089552Z"
        },
        "id": "iZD8eMa_uo4m",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "with gr.Blocks() as demo:\n",
        "    starting_idx = 0\n",
        "    with gr.Column():\n",
        "        idx = gr.Slider(value=starting_idx, label=\"idx\") # Progress bar, borrowed the idea from https://www.kaggle.com/code/nbroad/create-science-wikipedia-dataset\n",
        "        text = gr.Textbox(value=get_text(0), label=\"text\")\n",
        "    with gr.Row():\n",
        "        correct_btn = gr.Button(value=\"Correct\")\n",
        "        incorrect_btn = gr.Button(value=\"Incorrect\")\n",
        "\n",
        "    correct_btn.click(fn=partial(label, choice='correct'), inputs=[idx], outputs=[idx, text])\n",
        "    incorrect_btn.click(fn=partial(label, choice='incorrect'), inputs=[idx], outputs=[idx, text])\n",
        "\n",
        "#demo.launch(debug=True, show_error=True)\n",
        "demo.queue().launch(share=True, show_error=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmT3_7T-fpW3"
      },
      "source": [
        "Here is an example of what the gradio app looks like:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![A screenshot of my gradio app used to grade LLM responses](gradio_app.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kFADk3rnaes0"
      },
      "outputs": [],
      "source": [
        "df.to_csv('graded_responses.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7SDEU5HawOl"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9rRHO7Ga1AW"
      },
      "source": [
        "With all of the model responses graded, I can now calculate the percentage of correct responses from each model for each dataset and prompting style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fge7FbvPcrNV",
        "outputId": "38a5cc7d-698a-49cb-dafd-33d6b7cb8fc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "model                     prompting_style\n",
              "Llama-2-7b-chat-hf        PS+                25.0\n",
              "                          Zero-shot          45.0\n",
              "                          Zero-shot-CoT      30.0\n",
              "Mistral-7B-Instruct-v0.1  PS+                60.0\n",
              "                          Zero-shot          60.0\n",
              "                          Zero-shot-CoT      45.0\n",
              "zephyr-7b-alpha           PS+                30.0\n",
              "                          Zero-shot          45.0\n",
              "                          Zero-shot-CoT      45.0\n",
              "Name: is_correct, dtype: float64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['model', 'prompting_style'])['is_correct'].mean() * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUI25Zb8cNuB"
      },
      "source": [
        "Overall, the best performing model and prompting style (60% correct) was the Mistral-7B-Instruct-v0.1 model using the PS+ and Zero-shot prompting styles. Mistral was the only model where PS+ outperformed Zero-shot and Zero-shot-CoT.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I44zomYJcNCv",
        "outputId": "2e941153-7dce-4162-9b43-3478a5afdc7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "model\n",
              "Llama-2-7b-chat-hf          33.333333\n",
              "Mistral-7B-Instruct-v0.1    55.000000\n",
              "zephyr-7b-alpha             40.000000\n",
              "Name: is_correct, dtype: float64"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['model'])['is_correct'].mean() * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzjFa5p2c-Fy"
      },
      "source": [
        "Overall the best performing model across all prompting styles was Mistral (55%) following by Zephyr (40%) and Llama-2 coming in last at 33.33%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YVH7AcFdPBN",
        "outputId": "50de3b09-7526-40da-cede-382af76e41c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dataset\n",
              "AQuA             5.555556\n",
              "AddSub          77.777778\n",
              "CSQA            27.777778\n",
              "Coin Flip       77.777778\n",
              "GSM8K           50.000000\n",
              "Last Letters     0.000000\n",
              "MultiArith      38.888889\n",
              "SVAMP           77.777778\n",
              "SingleEq        72.222222\n",
              "StrategyQA       0.000000\n",
              "Name: is_correct, dtype: float64"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.groupby(['dataset'])['is_correct'].mean() * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfPSFO1pdTH8"
      },
      "source": [
        "Across all models and prompting styles, the highest performing datasets (78% correct) were AddSub, Coin Flip and SVAMP. The lowest performing datasets (0% correct) were Last Letters and StrategyQA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWs6ry-yeInl"
      },
      "source": [
        "## Final Thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YoW9WCReJxy"
      },
      "source": [
        "I want to reiterate that the purpose of this exercise for me to get some practice prompting LLMs. I also got some experience setting up a gradio app to help me evaluate the responses of the models.\n",
        "\n",
        "\n",
        "Given the small sample size for each model (20 questions and responses for each prompting style) I don't think these results can be used to conclude anything about the performance of these prompting styles and models. Yes, Mistral and Zephyr out-performed Llama-2 on these 20 questions across these 3 particular prompting styles, but testing the models on another thousand questions might yield different results.\n",
        "\n",
        "I hope you enjoyed this blog post!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
