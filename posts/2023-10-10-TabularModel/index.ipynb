{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Understanding the fastai TabularModel Class\n",
        "date: \"2023-10-10\"\n",
        "author: Vishal Bakshi\n",
        "description: In this notebook I walk through line-by-line the source code of the fastai TabularModel class.\n",
        "categories:\n",
        "    - deep learning\n",
        "    - python\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8bpESW-oRtp"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZAARvoNoUuR"
      },
      "source": [
        "In this notebook, I will work through the last \"Further Research\" exercise from Chapter 9 of the fastai textbook:\n",
        "\n",
        "> Explain what each line of the source of `TabularModel` does (with the exception of the `BatchNorm1d` and `Dropout` layers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNsUxsvaorLr"
      },
      "source": [
        "I'll start by pasting the source code of `TabularModel` here:\n",
        "\n",
        "```python\n",
        "class TabularModel(Module):\n",
        "    \"Basic model for tabular data.\"\n",
        "    def __init__(self,\n",
        "        emb_szs:list, # Sequence of (num_embeddings, embedding_dim) for each categorical variable\n",
        "        n_cont:int, # Number of continuous variables\n",
        "        out_sz:int, # Number of outputs for final `LinBnDrop` layer\n",
        "        layers:list, # Sequence of ints used to specify the input and output size of each `LinBnDrop` layer\n",
        "        ps:float|MutableSequence=None, # Sequence of dropout probabilities for `LinBnDrop`\n",
        "        embed_p:float=0., # Dropout probability for `Embedding` layer\n",
        "        y_range=None, # Low and high for `SigmoidRange` activation\n",
        "        use_bn:bool=True, # Use `BatchNorm1d` in `LinBnDrop` layers\n",
        "        bn_final:bool=False, # Use `BatchNorm1d` on final layer\n",
        "        bn_cont:bool=True, # Use `BatchNorm1d` on continuous variables\n",
        "        act_cls=nn.ReLU(inplace=True), # Activation type for `LinBnDrop` layers\n",
        "        lin_first:bool=True # Linear layer is first or last in `LinBnDrop` layers\n",
        "    ):\n",
        "        ps = ifnone(ps, [0]*len(layers))\n",
        "        if not is_listy(ps): ps = [ps]*len(layers)\n",
        "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
        "        self.emb_drop = nn.Dropout(embed_p)\n",
        "        self.bn_cont = nn.BatchNorm1d(n_cont) if bn_cont else None\n",
        "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
        "        self.n_emb,self.n_cont = n_emb,n_cont\n",
        "        sizes = [n_emb + n_cont] + layers + [out_sz]\n",
        "        actns = [act_cls for _ in range(len(sizes)-2)] + [None]\n",
        "        _layers = [LinBnDrop(sizes[i], sizes[i+1], bn=use_bn and (i!=len(actns)-1 or bn_final), p=p, act=a, lin_first=lin_first)\n",
        "                       for i,(p,a) in enumerate(zip(ps+[0.],actns))]\n",
        "        if y_range is not None: _layers.append(SigmoidRange(*y_range))\n",
        "        self.layers = nn.Sequential(*_layers)\n",
        "\n",
        "    def forward(self, x_cat, x_cont=None):\n",
        "        if self.n_emb != 0:\n",
        "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
        "            x = torch.cat(x, 1)\n",
        "            x = self.emb_drop(x)\n",
        "        if self.n_cont != 0:\n",
        "            if self.bn_cont is not None: x_cont = self.bn_cont(x_cont)\n",
        "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
        "        return self.layers(x)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekXSgnrLuVfI"
      },
      "source": [
        "In the sections below, I will walk through each line of code to make sure I understand what it does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "steGhWB7fqVT"
      },
      "outputs": [],
      "source": [
        "from fastai.tabular.all import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-Dq4-oApdi1"
      },
      "source": [
        "## `__init__`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VC3mm4rpgIv"
      },
      "source": [
        "The `__init__` method's parameters are well-defined by the comments in the source code so I will not list each of them here. However, in order to run actual code for the rest of the lines, I will assign some test values to each of the parameters. I'll also define `x_cat` and `x_cont` so that we have some fake data to work with. I have set all `BatchNorm1d` and `Dropout` related parameters to `0`, `False`, or `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "ucE6Q2dMe1gB"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42);\n",
        "\n",
        "# self.init parameters\n",
        "emb_szs = [(4,2), (17,8)]\n",
        "n_cont = 1\n",
        "out_sz = 1\n",
        "layers = [200,100]\n",
        "ps = None\n",
        "embed_p = 0.\n",
        "y_range = (0,1)\n",
        "use_bn = False\n",
        "bn_final = False\n",
        "bn_cont = False\n",
        "act_cls=nn.ReLU(inplace=True)\n",
        "lin_first = True\n",
        "\n",
        "# fake data\n",
        "x_cat1 = torch.randint(0,4,(10,))\n",
        "x_cat2 = torch.randint(0,17,(10,))\n",
        "x_cat = torch.column_stack((x_cat1, x_cat2))\n",
        "x_cont = torch.randn(10)[:,None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljDGbwVhkZm7"
      },
      "source": [
        "### `ps`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtneRH8okfva"
      },
      "source": [
        "I am not sure what dropout probabilities do exactly, so I won't explain the code here other than running it as shown in the source code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "nWZw9hwbkpnx"
      },
      "outputs": [],
      "source": [
        "ps = ifnone(ps, [0]*len(layers))\n",
        "if not is_listy(ps): ps = [ps]*len(layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M8ENTdFktbf",
        "outputId": "bf920da7-8e6d-439d-fdc2-c08b5168dfab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY5jqGnrqTh1"
      },
      "source": [
        "### `self.embeds`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE9cRF1yq2zV"
      },
      "source": [
        "`self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSnjWhmvqWOw"
      },
      "source": [
        "This line of code creates `Embedding`s, one for each tuple defined in `emb_szs`, which in turn is one tuple defined for each categorical variable. In my example, I have two categorical variables so I will create two `Embedding`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ8Z2PTcrCoa",
        "outputId": "2bffbc9b-401d-4e2b-dc52-327b9f9c0ec0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Embedding(4, 2)\n",
              "  (1): Embedding(17, 8)\n",
              ")"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeds = nn.ModuleList(Embedding(ni, nf) for ni,nf in emb_szs)\n",
        "embeds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrjEHoSYtyhL"
      },
      "source": [
        "### `self.emb_drop`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhosguEct3be"
      },
      "source": [
        "The following line creates an `nn.Dropout` object which will be used in the model. According to the PyTorch website:\n",
        "\n",
        "> During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution. Each channel will be zeroed out independently on every forward call.\n",
        "\n",
        "`self.emb_drop = nn.Dropout(embed_p)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjdxxQXkuI12",
        "outputId": "11222b4b-322b-450c-f50a-12ebdb6b4021"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dropout(p=0.0, inplace=False)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_drop = nn.Dropout(embed_p)\n",
        "emb_drop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sGxb08Sv9eN"
      },
      "source": [
        "### `self.bn_cont`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUIpNQixv_7C"
      },
      "source": [
        "The following line assigns a `BatchNorm1d` function to `self.bn_cont` if the input argument `bn_cont` is `True`. Since in this case, I have set `bn_cont` to `False`, it would set `self.bn_cont` to `None`:\n",
        "\n",
        "`self.bn_cont = nn.BatchNorm1d(n_cont) if bn_cont else None`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "oWi3A6rTwT_c"
      },
      "outputs": [],
      "source": [
        "bn_cont = nn.BatchNorm1d(n_cont) if bn_cont else None\n",
        "bn_cont"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQDDG6E4qXCX"
      },
      "source": [
        "### `n_emb`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUiudB3LqbrS"
      },
      "source": [
        "`n_emb = sum(e.embedding_dim for e in self.embeds)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyQCYyNIrDDO"
      },
      "source": [
        "In my toy example, I have one `Embedding` containing 4 tensors of size 2, and one `Embedding` containing 17 tensors of size 8, so the total size will be 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4kgezlwrBmZ",
        "outputId": "16982323-7bc8-4ead-9b39-0e9d12539b1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_emb = sum(e.embedding_dim for e in embeds)\n",
        "n_emb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o25hWdFKqby2"
      },
      "source": [
        "### `self.n_emb,self.n_cont`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35tgvgqsqb31"
      },
      "source": [
        "`self.n_emb,self.n_cont = n_emb,n_cont`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm0Hp7QrrIzS"
      },
      "source": [
        "This line of code is simply storing the total `Embedding` size and number of continuous variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjSei6ByqcAH"
      },
      "source": [
        "### `sizes`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTgawlLgqb77"
      },
      "source": [
        "`sizes = [n_emb + n_cont] + layers + [out_sz]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACUzkQlBrNxx"
      },
      "source": [
        "This line defines the sizes of the input to the model (which contains `Embeddings` for categorical variables and `n_cont` continuous variables), a number of intermediate `layers`, and a final `out_sz` output size for the output of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zI7RfWvrN8E",
        "outputId": "4ea62813-6361-4453-994f-17f333249db2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[11, 200, 100, 1]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sizes = [n_emb + n_cont] + layers + [out_sz]\n",
        "sizes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZC0lBHdqcDR"
      },
      "source": [
        "### `actns`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zKWWZyUrQ4Y"
      },
      "source": [
        "`actns = [act_cls for _ in range(len(sizes)-2)] + [None]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8WyWhv2qpX2"
      },
      "source": [
        "This line defines the activations for the model for all layers. The final layer does not have an activation function so it is set to `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOg0w-PDrQQ-",
        "outputId": "472a8eb5-63ec-4ab5-db0f-d9e0c8e266d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ReLU(inplace=True), ReLU(inplace=True), None]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "actns = [act_cls for _ in range(len(sizes)-2)] + [None]\n",
        "actns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfQwapYJqpjG"
      },
      "source": [
        "### `_layers`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAgj3o8MrVHn"
      },
      "source": [
        "`_layers = [LinBnDrop(sizes[i], sizes[i+1], bn=use_bn and (i!=len(actns)-1 or bn_final), p=p, act=a, lin_first=lin_first) for i,(p,a) in enumerate(zip(ps+[0.],actns))]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU1bMauMnyIU"
      },
      "source": [
        "I'll walk through the components of this line, without going into detail about the \"why\" behind code related to `BatchNorm1d` and `Dropout` layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVE8KmNdn7oF"
      },
      "source": [
        "The following code zips together the list of `ps` probabilities and activations `actns`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9hShicMoqXe",
        "outputId": "38dae51f-b88f-46db-834f-924bbea473fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, ReLU(inplace=True)), (0, ReLU(inplace=True)), (0.0, None)]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(zip(ps+[0.], actns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWpxHIRSpCJk"
      },
      "source": [
        "The following code determines whether the `bn` parameter for `LinBnDrop` is set to `True` or `False`. If `use_bn` is `True`, and either of `i!=len(actns)-1` or `bn_final` are `True` then `bn` will be assigned `True`, otherwise it will be `False`.\n",
        "\n",
        "Looking at the second condition, `(i!=len(actns)-1 or bn_final)`, in more detail:\n",
        "\n",
        "If `i!=len(actns)-1` is `True`, it means that the final element of the enumeration has not been reached. In other words, the index does not correspond to the final layer of the model. If it's `False`, that means we have reached the index corresponding to the final layer in the model. In that case, the `or` condition can still result in truth if `bn_final` is `True`.\n",
        "\n",
        "`bn=use_bn and (i!=len(actns)-1 or bn_final)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TuqOAm7pvQK",
        "outputId": "648e64f0-cf8d-4ce3-8483-57dc8f2b9885"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "True and (True or False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQXCd8ujpxjA",
        "outputId": "53d8c866-dfca-4ef0-a3fb-58ab5ae643ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "True and (False or True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt7aB7j6oJz8"
      },
      "source": [
        "The following code generates a `LinBnDrop` layer for each activation function, setting the inputs and outputs of the layer based on the values in the `sizes` list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpiZ3SaloTCD",
        "outputId": "39121fcd-3e8c-4794-8a07-5911a958302d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[LinBnDrop(\n",
              "   (0): Linear(in_features=11, out_features=200, bias=True)\n",
              "   (1): ReLU(inplace=True)\n",
              " ),\n",
              " LinBnDrop(\n",
              "   (0): Linear(in_features=200, out_features=100, bias=True)\n",
              "   (1): ReLU(inplace=True)\n",
              " ),\n",
              " LinBnDrop(\n",
              "   (0): Linear(in_features=100, out_features=1, bias=True)\n",
              " )]"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_layers = [LinBnDrop(sizes[i], sizes[i+1], bn=use_bn and (i!=len(actns)-1 or bn_final), p=p, act=a,\n",
        "                     lin_first=lin_first) for i, (p,a) in enumerate(zip(ps+[0.], actns))]\n",
        "\n",
        "_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oFp1sSnrXMO"
      },
      "source": [
        "### `y_range`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7XnunGyrXVG"
      },
      "source": [
        "`if y_range is not None: _layers.append(SigmoidRange(*y_range))`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38vFHQWRqRT1"
      },
      "source": [
        "This line of code adds on a `SigmoidRange` function which limits the output values to the values defined in `y_range`.\n",
        "\n",
        "Here is what the function `SigmoidRange(0,1)` looks like for input values between -10 and 10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "IMtZMWiKq1-F"
      },
      "outputs": [],
      "source": [
        "def plot_function(f, tx=None, ty=None, title=None, min=-2, max=2, figsize=(6,4)):\n",
        "    x = torch.linspace(min,max, 100)\n",
        "    fig,ax = plt.subplots(figsize=figsize)\n",
        "    ax.plot(x,f(x))\n",
        "    if tx is not None: ax.set_xlabel(tx)\n",
        "    if ty is not None: ax.set_ylabel(ty)\n",
        "    if title is not None: ax.set_title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "6XZ8hyogq3Qi",
        "outputId": "297bcecd-c528-49f3-b0d6-16efcce12c05"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_function(SigmoidRange(0,1), min=-10, max=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "csC55hP3rO-c"
      },
      "outputs": [],
      "source": [
        "if y_range is not None: _layers.append(SigmoidRange(*y_range))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCOnxPqzrapT",
        "outputId": "0bd95298-34da-42a1-d1ab-a9f0e4d4b7ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[LinBnDrop(\n",
              "   (0): Linear(in_features=11, out_features=200, bias=True)\n",
              "   (1): ReLU(inplace=True)\n",
              " ),\n",
              " LinBnDrop(\n",
              "   (0): Linear(in_features=200, out_features=100, bias=True)\n",
              "   (1): ReLU(inplace=True)\n",
              " ),\n",
              " LinBnDrop(\n",
              "   (0): Linear(in_features=100, out_features=1, bias=True)\n",
              " ),\n",
              " fastai.layers.SigmoidRange(low=0, high=1)]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woLwtPNsrXsK"
      },
      "source": [
        "### `self.layers`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcDpobmWrX1J"
      },
      "source": [
        "`self.layers = nn.Sequential(*_layers)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-4Y3Va5rekK"
      },
      "source": [
        "The final piece to handling the layers in the model is to wrap them in a `nn.Sequential` model, so that inputs are passed sequentially to each layer in the list `_layers`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDfMFTi3rX-T",
        "outputId": "1a04b0a1-9d1e-45ae-d22e-32c5b64151ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): LinBnDrop(\n",
              "    (0): Linear(in_features=11, out_features=200, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (1): LinBnDrop(\n",
              "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (2): LinBnDrop(\n",
              "    (0): Linear(in_features=100, out_features=1, bias=True)\n",
              "  )\n",
              "  (3): fastai.layers.SigmoidRange(low=0, high=1)\n",
              ")"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layers = nn.Sequential(*_layers)\n",
        "layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc85zNJNrYLg"
      },
      "source": [
        "## `forward`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUVz8QRJvJ2_"
      },
      "source": [
        "### `if self.n_emb != 0:`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2MPFHoHscZi"
      },
      "source": [
        "In this example, `n_emb` is not equal to 0 so the following code will run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3eTlQmZrYUi"
      },
      "source": [
        "`x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]`\n",
        "\n",
        "In this line of code, the categorical variable columns are passed to the corresponding `Embedding` and the output tensor is stored in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJtvWhppsjLL",
        "outputId": "0e140f6b-fb74-47de-abb8-29a8634b3dc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 10, 10)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = [e(x_cat[:,i]) for i,e in enumerate(embeds)]\n",
        "len(x), len(x[0]), len(x[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa-DxwOatVTp"
      },
      "source": [
        "There are 10 rows in `x_cat`. The `Embedding` corresponding to the first column outputs 2 columns of tensors, and the `Embedding` corresponding to the second column outputs 8 columns of tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrJxsowOtK_v",
        "outputId": "1f2db8ea-4d10-408e-a64d-a91d85fbc024"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 2])"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaJbYP4ntMid",
        "outputId": "6a47f9d8-c0d2-44d4-acb7-282d8c66e0ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 8])"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSvjx-nksmAS"
      },
      "source": [
        "The following line takes the list of tensors `x` (with a 10 x 2 and 10 x 8 tensor) and concatenates them into a single 10 x 10 tensor.\n",
        "\n",
        "`x = torch.cat(x, 1)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUlRJD4Dsllw"
      },
      "outputs": [],
      "source": [
        "x = torch.cat(x,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41WF_G-xuguY",
        "outputId": "eb8fd687-79af-45c7-b6d3-2aa0319d1c8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 10])"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuoE2_Zkva0n",
        "outputId": "d5cd6022-500e-4cd1-8644-e0b2ec9b5f4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.3314e-03,  8.6398e-03,  2.0744e-04,  2.5392e-03,  9.3644e-03,\n",
              "          7.1224e-03, -3.1766e-04,  1.0164e-03,  1.3433e-02,  7.1327e-03],\n",
              "        [-1.0157e-02, -8.8875e-03, -1.5988e-02, -1.0913e-03,  7.1520e-03,\n",
              "          3.9139e-04,  1.3059e-02,  2.4659e-03, -1.9776e-02,  1.7896e-04],\n",
              "        [-4.9903e-04,  5.2634e-03,  3.7818e-03,  7.0511e-03, -1.7237e-02,\n",
              "         -8.4348e-03,  4.3514e-03,  2.6589e-03, -5.8710e-03,  8.2689e-04],\n",
              "        [ 1.3314e-03,  8.6398e-03, -1.5988e-02, -1.0913e-03,  7.1520e-03,\n",
              "          3.9139e-04,  1.3059e-02,  2.4659e-03, -1.9776e-02,  1.7896e-04],\n",
              "        [ 1.3314e-03,  8.6398e-03, -7.1988e-04, -9.0609e-03, -4.8712e-04,\n",
              "         -1.0811e-02,  1.7623e-04,  7.8226e-04,  1.9316e-03,  4.0967e-03],\n",
              "        [-1.0157e-02, -8.8875e-03,  1.2554e-02, -7.1496e-03,  8.5392e-03,\n",
              "          5.1299e-03,  5.3973e-03,  5.6551e-03,  5.0579e-03,  2.2245e-03],\n",
              "        [-4.9903e-04,  5.2634e-03, -6.8548e-03,  5.6356e-03, -1.5072e-02,\n",
              "         -1.6107e-02, -1.4790e-02,  4.3227e-03, -1.2503e-03,  7.8212e-03],\n",
              "        [-4.9903e-04,  5.2634e-03,  4.0380e-03, -7.1398e-03,  8.3373e-03,\n",
              "         -9.5855e-03,  4.5363e-03,  1.2461e-02, -3.0651e-03, -1.2869e-02],\n",
              "        [ 1.3314e-03,  8.6398e-03,  1.2554e-02, -7.1496e-03,  8.5392e-03,\n",
              "          5.1299e-03,  5.3973e-03,  5.6551e-03,  5.0579e-03,  2.2245e-03],\n",
              "        [-8.4988e-05,  7.2906e-03, -6.8548e-03,  5.6356e-03, -1.5072e-02,\n",
              "         -1.6107e-02, -1.4790e-02,  4.3227e-03, -1.2503e-03,  7.8212e-03]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mbVj7vwsnXJ"
      },
      "source": [
        "The following line of code passes the `x` tensor through the `nn.Dropout` function. If I understand correctly, since I defined `embed_p` as 0, passing it through the `Dropout` layer will not affect the tensor `x`.\n",
        "\n",
        "`x = self.emb_drop(x)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "fcFYanO9sntg"
      },
      "outputs": [],
      "source": [
        "x = emb_drop(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j9BpnoYvQpX"
      },
      "source": [
        "### `if self.n_cont != 0`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQORkpPjwdKZ"
      },
      "source": [
        "In this example, `n_cont` is not 0 so the following code will run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "din9HOHdvzje"
      },
      "source": [
        "Since `bn_cont` is `None`, the code `x_cont = self.bn_cont(x_cont)` will not run.\n",
        "\n",
        "`if self.bn_cont is not None: x_cont = self.bn_cont(x_cont)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "iWoIzQpFvz7t"
      },
      "outputs": [],
      "source": [
        "if bn_cont is not None: x_cont = bn_cont(x_cont)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ6C5-87uEPc"
      },
      "source": [
        "In the following line, if `n_emb` is not 0, it will concatenate `x` (which holds the outputs of the categorical `Embedding`s) with `x_cont` (which holds the continuous variable columns) into a single tensor. If `n_emb` is 0, it will assign `x_cont` to `x`.\n",
        "\n",
        "In this example, `n_emb` is not 0 so it will concatenate `x` with `x_cont`.\n",
        "\n",
        "`x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vhlwYYqxMQh",
        "outputId": "356a4454-5a28-43ab-e91f-248728d5df6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 10])"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "kSjtu0I2um64"
      },
      "outputs": [],
      "source": [
        "x = torch.cat([x, x_cont], 1) if n_emb != 0 else x_cont"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ere-PR9cyA1i"
      },
      "source": [
        "The concatenation has added a column of tensors (continuous variable) to `x`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzMTOwljxLG7",
        "outputId": "5ff67c34-4fd2-4be0-ed3b-739bf8459acb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 11])"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxl5JK0HrYr3"
      },
      "source": [
        "### `return`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEqnPs2ByFMh"
      },
      "source": [
        "The final piece of the `forward` method is to return the outputs of the model. This is done by passing our 11 inputs in `x` (10 categorical embeddings, 1 continuous variable) to the `layers` `nn.Sequential` model defined before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyEIV8ElvbWZ"
      },
      "source": [
        "`self.layers(x)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PD6TbeMyQvZ",
        "outputId": "7f6f4958-6712-440d-cb4b-3aa3dbb7dfdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): LinBnDrop(\n",
              "    (0): Linear(in_features=11, out_features=200, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (1): LinBnDrop(\n",
              "    (0): Linear(in_features=200, out_features=100, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (2): LinBnDrop(\n",
              "    (0): Linear(in_features=100, out_features=1, bias=True)\n",
              "  )\n",
              "  (3): fastai.layers.SigmoidRange(low=0, high=1)\n",
              ")"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMAR427ByWxK"
      },
      "source": [
        "The output is a tensor with 10 values, 1 for each of the 10 input rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD7Oc7CBrY9t",
        "outputId": "25a077fc-616a-497a-b1a7-3ad8c93f0fbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5217],\n",
              "        [0.5210],\n",
              "        [0.5216],\n",
              "        [0.5214],\n",
              "        [0.5149],\n",
              "        [0.5192],\n",
              "        [0.5377],\n",
              "        [0.5174],\n",
              "        [0.5223],\n",
              "        [0.5221]], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlBrOD-EyjM4"
      },
      "source": [
        "## Final Thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk4EyPA_y7lR"
      },
      "source": [
        "I _**really**_ enjoyed this exercise and will definitely apply the same process of running line-by-line code in the future when I am trying to understand fastai (or other) library source code. By the end of this exercise, I was surprised at how simple and straightforward it is to build a `TabularModel` object. It's so powerful given its simplicity.\n",
        "\n",
        "I hope you enjoyed this blog post!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
