{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: The Evolution of Matrix Multiplication (fastai course Part 2 Lessons 11 and 12)\n",
    "date: \"2025-05-21\"\n",
    "author: Vishal Bakshi\n",
    "description: In this blog post I walk through 10 different implementations of matrix multiplication in python, Numba and PyTorch, comparing execution times on matrix multiplications between a 5-digit subset of MNIST and a single weight matrix, as well as matrix multiplications between the full 50k-image MNIST dataset and the weight matrix. My two main takeaways&#58; 1) when in doubt, use PyTorch's `.cuda` with the `@` operator, and 2) different matrix multiplication algorithms scale differently!\n",
    "filters:\n",
    "   - lightbox\n",
    "lightbox: auto\n",
    "categories:\n",
    "    - python\n",
    "    - deep learning\n",
    "    - fastai\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMAfON7ZIBRM",
    "outputId": "47621598-8fd6-4b6a-9893-4dc62cc9ee45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show setup code\"\n",
    "\n",
    "# !conda install -y -c nvidia/label/cuda-12.8.0 cuda-toolkit\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "# !conda install -y numba\n",
    "# !conda install -y fastcore -c fastai\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle, gzip, math, os, time, shutil\n",
    "from urllib.request import urlretrieve\n",
    "import torch\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "from numpy import array\n",
    "from fastcore.test import *\n",
    "\n",
    "from numba import cuda\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "np.set_printoptions(precision=2, linewidth=140)\n",
    "\n",
    "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
    "path_data = Path('data')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "\n",
    "\n",
    "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)\n",
    "\n",
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "\n",
    "x_train,y_train,x_valid,y_valid = map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x29neL5KFXvg",
    "outputId": "a4f3c78a-4f61-4f8c-cf21-4c103270afd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show setup code\"\n",
    "\n",
    "torch.manual_seed(1)\n",
    "weights = torch.randn(784,10)\n",
    "bias = torch.zeros(10)\n",
    "\n",
    "m1 = x_valid[:5]\n",
    "m2 = weights\n",
    "\n",
    "m1.shape,m2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/iV63qy4ETJQ?si=RVTeCMWgSHf_IHq0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-digit Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Method|Time|\n",
    "|:-:|:-:|\n",
    "|PyTorch `@` Op|18.1 μs\n",
    "|Numba Broadcasting|69.2 μs\n",
    "|Einstein Summation|83.1 μs\n",
    "|PyTorch Cuda|108 μs|\n",
    "|Numba Cuda|108 μs|\n",
    "|PyTorch Broadcasting|203 μs\n",
    "|Numba Dot Product|542 μs\n",
    "|`torch.dot`|1.19 ms\n",
    "|Element-wise PyTorch Ops|1.49 ms\n",
    "|Nested for-loops|604 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCu-n0kGFfZX",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 0: Nested For-Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4aZT4UZHMHW"
   },
   "source": [
    "![Excalidraw diagram showing nested for-loop implementation of matrix multiplication](1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvKIPTy0FobY",
    "outputId": "f1b07e28-eb6a-42f0-9863-d962b0843dff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 784), (784, 10))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar,ac = m1.shape # n_rows * n_cols\n",
    "br,bc = m2.shape\n",
    "(ar,ac),(br,bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQn6KOTdFrZa",
    "outputId": "50202d80-fbe0-4ea8-aa39-4fe0691cb4b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.zeros(ar, bc)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "LEChGJhxFa7A"
   },
   "outputs": [],
   "source": [
    "for i in range(ar):         # 5\n",
    "    for j in range(bc):     # 10\n",
    "        for k in range(ac): # 784\n",
    "            t1[i,j] += m1[i,k] * m2[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTxP9MwjFyR6",
    "outputId": "de65336e-e04e-4d55-81aa-228a6f7bf7bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAB9dvn_FvR6",
    "outputId": "a46dd7f0-06d7-4d86-aa3a-577743471963"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],\n",
       "        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],\n",
       "        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],\n",
       "        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],\n",
       "        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "mlYnl3vbF7BD"
   },
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    (ar,ac),(br,bc) = a.shape,b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            for k in range(ac): c[i,j] += a[i,k] * b[k,j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RV4pQRbNF-xe",
    "outputId": "75bfe38a-2fc3-4f8d-8934-7fbd7c8036e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 675 ms, sys: 0 ns, total: 675 ms\n",
      "Wall time: 674 ms\n"
     ]
    }
   ],
   "source": [
    "%time _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8s6rqcKGTgW",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 1: Numba Dot Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4i5JcfrGV3S"
   },
   "source": [
    "Replacing the inner-most for-loop with a numba dot-product implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Excalidraw diagram showing dot-product implementation of matrix multiplication](2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "E-wIQPNbF-3s"
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def dot(a,b):\n",
    "    res = 0.\n",
    "    for i in range(len(a)): res+=a[i]*b[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCaJFIrZGc0I",
    "outputId": "217464df-4573-40a9-f926-37186bb47d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 124 ms, sys: 0 ns, total: 124 ms\n",
      "Wall time: 123 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dot(array([1.,2,3]),array([2.,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CftKKTXGiQQ",
    "outputId": "64bc96a7-7cc1-404a-c47b-6b8a54d5c6b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 μs, sys: 2 μs, total: 28 μs\n",
      "Wall time: 32.4 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dot(array([1.,2,3]),array([2.,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "EmyMh2FlKDMj"
   },
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    (ar,ac),(br,bc) = a.shape,b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc): c[i,j] = dot(a[i,:], b[:,j])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "_puzTJIgH6Kr"
   },
   "outputs": [],
   "source": [
    "m1a,m2a = m1.numpy(),m2.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "hoouxAASH6Y6"
   },
   "outputs": [],
   "source": [
    "test_close(t1,matmul(m1a, m2a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPGsU19JIFf7",
    "outputId": "10968392-3789-4272-b708-9a99560bad48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495 μs ± 39.4 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 matmul(m1a,m2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HaBdH7MJ0V_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 2: Element-wise Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "ZqdkpaOWJrbh"
   },
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    (ar,ac),(br,bc) = a.shape,b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc): c[i,j] = (a[i,:] * b[:,j]).sum()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "in7O1ZVfKJ4j"
   },
   "outputs": [],
   "source": [
    "test_close(t1,matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3Rkd-7nKNzu",
    "outputId": "fc775c33-b82e-4076-ef1b-5eb260224b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.48 ms ± 354 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8v1morKSGU",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 3: `torch.dot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "dlXJpnZ7KWpe"
   },
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    (ar,ac),(br,bc) = a.shape,b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc): c[i,j] = torch.dot(a[i,:], b[:,j])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "y5VXx1gIKX8V"
   },
   "outputs": [],
   "source": [
    "test_close(t1,matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCYtb-BNKYfU",
    "outputId": "b97d9eea-9c0f-4ac5-9db1-c73b3661cfec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 ms ± 380 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bh5T4fZwKbpO",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 4: PyTorch Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Excalidraw diagram showing broadcasting implementation of matrix multiplication](3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "IYYRHrGQLM0E"
   },
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    (ar,ac),(br,bc) = a.shape,b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar): c[i] = (a[i,:,None] * b).sum(dim=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "mj-5wtgRLSF0"
   },
   "outputs": [],
   "source": [
    "test_close(t1,matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBdlKdKYLTmj",
    "outputId": "2acf0524-81f2-4fab-e67d-b2354bacbf36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314 μs ± 92.1 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjAFLkECNY6_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 5: Numba Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "lj3xuHdbLWIU"
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def matmul(a,b):\n",
    "    (ar,ac),(br,bc) = a.shape,b.shape\n",
    "    c = np.zeros((ar, bc))\n",
    "    for i in range(ar): c[i] = (a[i,:,None] * b).sum(axis=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "JZn7-E9kNbzX"
   },
   "outputs": [],
   "source": [
    "test_close(t1,matmul(m1a, m2a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9eYoayeSNcfo",
    "outputId": "1d46ad9d-a40d-4643-c1cf-f535fa528a2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 μs ± 1.96 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 _=matmul(m1a, m2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSaHK4wsN00B",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 6: Einstein Summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Excalidraw diagram showing einsum implementation of matrix multiplication](4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "YkOs95NgN2na"
   },
   "outputs": [],
   "source": [
    "def matmul(a,b): return torch.einsum('ik,kj->ij', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "0t4lMgpaOEfj"
   },
   "outputs": [],
   "source": [
    "test_close(t1,matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7wp-8Z7eOJpM",
    "outputId": "65bbe1b5-0ab3-4162-ef3f-bdeaeb96f800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.8 μs ± 4.18 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yj5DtcYsOUVt",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 7: PyTorch `@` Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "kRhaBu8POLND"
   },
   "outputs": [],
   "source": [
    "test_close(t1,m1@m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yklf0tkEOYOF",
    "outputId": "0bdd14b8-2dbf-42d9-f565-0746be389f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.7 μs ± 1.96 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 50 _=m1@m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "056eLGnwOfJN",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 8: Numba CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "mlHiV4R3OgJj"
   },
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(a,b,c):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < c.shape[0] and j < c.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n",
    "        c[i,j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "ndtuY9QNOldT"
   },
   "outputs": [],
   "source": [
    "def launch_kernel(kernel, grid_x, grid_y, *args, **kwargs):\n",
    "    for i in range(grid_x):\n",
    "        for j in range(grid_y): kernel((i,j), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "9N3p8JXBOsDQ"
   },
   "outputs": [],
   "source": [
    "r = np.zeros(t1.shape)\n",
    "m1g,m2g,rg = map(cuda.to_device, (m1,m2,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lttoTzc-O-XT",
    "outputId": "2852ccb1-8bed-450f-8864-1928e10117f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 784), (784, 10), (5, 10))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1g.shape, m2g.shape, rg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZofmAypAO_DR",
    "outputId": "d4e0a549-a04f-43db-9d1f-c96e9a6026e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPB = 16\n",
    "rr,rc = r.shape\n",
    "blockspergrid = (math.ceil(rr / TPB), math.ceil(rc / TPB))\n",
    "blockspergrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "UhIczyMGPMgE",
    "outputId": "bf632387-a756-4efb-ec6a-ce589b1c023a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/my4tb/vishal_data/miniconda3/envs/course-numba/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)\n",
    "r = rg.copy_to_host()\n",
    "test_close(t1, r, eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "rru87graRos-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 μs ± 47.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)\n",
    "r = rg.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Version 9: PyTorch `.cuda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1c,m2c = m1.cuda(),m2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=(m1c@m2c).cpu()\n",
    "test_close(t1, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113 μs ± 26.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 r=(m1c@m2c).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Fastest Versions on Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Method|Time|\n",
    "|:-:|:-:|\n",
    "|PyTorch `cuda`|541 μs\n",
    "|Numba Cuda|3.91 ms\n",
    "|PyTorch `@` Op|5.8 ms\n",
    "|Einstein Summation|5.87 ms\n",
    "|Numba Broadcasting|663 ms\n",
    "|PyTorch Broadcasting|1.26 s\n",
    "|Numba Dot Product|3.71 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Numba Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.71 s ± 20.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def matmul(a,b):\n",
    "    (ar,ac),(br,bc) = a.shape,b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc): c[i,j] = dot(a[i,:], b[:,j])\n",
    "    return c\n",
    "\n",
    "x_train_a,weights_a = x_train.numpy(),weights.numpy()\n",
    "%timeit _ = matmul(x_train_a, weights_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PyTorch Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26 s ± 1.42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def matmul(a,b):\n",
    "    (ar,ac),(br,bc) = a.shape,b.shape\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar): c[i] = (a[i,:,None] * b).sum(dim=0)\n",
    "    return c\n",
    "\n",
    "%timeit _ = matmul(x_train, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.86 s ± 4.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _ = matmul(x_train.cuda(), weights.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, putting the tensors on the GPU and then broadcasting is slower than the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Numba Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def matmul(a,b,c):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < c.shape[0] and j < c.shape[1]:\n",
    "        tmp = 0.\n",
    "        for k in range(a.shape[1]): tmp += a[i, k] * b[k, j]\n",
    "        c[i,j] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.zeros((50000, 10))\n",
    "m1g,m2g,rg = map(cuda.to_device, (x_train,weights,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3125, 1)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TPB = 16\n",
    "rr,rc = r.shape\n",
    "blockspergrid = (math.ceil(rr / TPB), math.ceil(rc / TPB))\n",
    "blockspergrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.91 ms ± 68.6 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)\n",
    "r = rg.copy_to_host()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PyTorch `cuda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541 μs ± 6.82 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "m1c,m2c = x_train.cuda(),weights.cuda()\n",
    "%timeit -n 10 r=(m1c@m2c).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Einstein Summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.87 ms ± 229 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "def matmul(a,b): return torch.einsum('ik,kj->ij', a, b)\n",
    "%timeit -n 10 _=matmul(x_train, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Numba Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def matmul(a,b):\n",
    "    (ar,ac),(br,bc) = a.shape,b.shape\n",
    "    c = np.zeros((ar, bc))\n",
    "    for i in range(ar): c[i] = (a[i,:,None] * b).sum(axis=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=matmul(x_train.numpy(), weights.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663 ms ± 378 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit _=matmul(x_train.numpy(), weights.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PyTorch `@` Op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8 ms ± 212 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=x_train@weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing 5-digit Subset to Full Dataset Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Method|Full Dataset Time|5-digit Subset Time/Rank|\n",
    "|:-:|:-:|:-:|\n",
    "|PyTorch `cuda`|541 μs|108 μs (4)\n",
    "|Numba Cuda|3.91 ms|108 μs (4)\n",
    "|PyTorch `@` Op|5.8 ms|18.1 μs (1)\n",
    "|Einstein Summation|5.87 ms|83.1 μs (3)\n",
    "|Numba Broadcasting|663 ms|69.2 μs (2)\n",
    "|PyTorch Broadcasting|1.26 s|203 μs (6)\n",
    "|Numba Dot Product|3.71 s|542 μs (7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initially ran into some problems on Colab when implementing `@cuda.jit` (an error about compute compatibility) so I switched to an RTX 3090 machine and installed the following, which let me successfully run this notebook:\n",
    "\n",
    "```\n",
    "conda install -y -c nvidia/label/cuda-12.8.0 cuda-toolkit\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "conda install -y numba\n",
    "conda install -y fastcore -c fastai\n",
    "```\n",
    "\n",
    "The glaring takeaway from this exercise is that these methods all scale differently. For the 5-digit subset, PyTorch `cuda` was about 9 times slower than PyTorch CPU (when using the `@` operator). Numba cuda and PyTorch `cuda` were tied for the small subset, but PyTorch `cuda` was 8 times faster for the larger dataset. I don't yet understand _why_ these differences exist, so that's something I'll keep an eye out for as I learn more about how GPUs work!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
