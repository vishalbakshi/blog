{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Evaluating 4 Retrieval Methods with 6 Chunking Strategies on my fastbook-benchmark Dataset\n",
    "date: \"2024-11-26\"\n",
    "author: Vishal Bakshi\n",
    "description: In this blog post, I perform retrieval on the fastbook chapter documents using 24 different retrieval method-chunking strategy combinations, auto-scoring using my fastbook-benchmark dataset.\n",
    "filters:\n",
    "   - lightbox\n",
    "lightbox: auto\n",
    "categories:\n",
    "    - python\n",
    "    - fastbookRAG\n",
    "    - information retrieval\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfEjn69cKJKX"
   },
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lN5NYP0dKKpb"
   },
   "source": [
    "In this notebook I re-run my full text search and semantic search retrieval methods for fastbook questions and use my newly curated [fastbook-benchmark](https://gist.github.com/vishalbakshi/a507b6e9e893475e93a4141e96b8947d) dataset to calculate Answer Component MRR@10 and Answer Component Recall@10 retrieval metrics. Due to how my benchmark dataset is structured, I had to modify (with Claude's help) the classic MRR and Recall functions:\n",
    "\n",
    "- Answer Component MRR@10: Returns the rank of the n-th passage needed to satisfy all `answer_component`s for the question. So, if a question has 4 `answer_component`s and their relevant contexts were contained across the first 5 retrieved passages, MRR would be 1/5 = 0.2.\n",
    "\n",
    "- Answer Component Recall@10: Measures the proportion of answer components for which at least one supporting context was retrieved. Using the same example, if the top-10 passages only contain contexts relevant to 2 `answer_component`s, Recall would be 2/4 = 0.5\n",
    "\n",
    "See the section below to see how my benchmark dataset is structured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCtcnbQfLWzB"
   },
   "source": [
    "There are four retrieval methods I implement in this notebook:\n",
    "\n",
    "- Full text search (using sqlite and Claude-generated keywords)\n",
    "- Single-vector cosine similarity (using BAAI/bge-small-en-v1.5)\n",
    "- ColBERTv2\n",
    "- answerai-colbert-small-v1\n",
    "\n",
    "There are six chunking strategies I implement:\n",
    "\n",
    "|Chunking Strategy Name|Description|\n",
    "|:-:|:-:|\n",
    "|A|1-paragraph (w/headers)\n",
    "|B|3-paragraph (w/headers)\n",
    "|C|1-paragraph (w/o headers)\n",
    "|D|3-paragraph (w/o headers)\n",
    "|E|3-paragraph (w/headers, w/o HTML tags)\n",
    "|F|3-paragraph (w/headers, w/o HTML tags, w/o punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PGkevYCKunG"
   },
   "source": [
    "Here are the results from this notebook:\n",
    "\n",
    "**Answer Component MRR@10**\n",
    "\n",
    "| Retrieval Method | A | B | C | D | E | F |\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Full text search|0.30|0.46|0.29|0.44|0.46|0.46|\n",
    "|Single-vector cosine similiarity|0.38|0.50|0.35|0.46|0.50|0.49|\n",
    "|ColBERTv2|0.46|0.49|0.41|0.50|0.49|0.44|\n",
    "|answerai-colbert-small-v1|0.48|0.52|0.45|0.52|0.52|0.45|\n",
    "\n",
    "<br>\n",
    "\n",
    "**Answer Component Recall@10**\n",
    "\n",
    "| Retrieval Method | A | B | C | D | E | F |\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "| Full text search | 65% | 83% | 65% | 82% | 83% | 83% |\n",
    "| Single-vector cosine similiarity | 71% | 85% | 72% | 82% | 87% | 86% |\n",
    "| ColBERTv2 | 80% | 80% | 74% | 80% | 81% | 71% |\n",
    "| answerai-colbert-small-v1 | 82% | 84% | 77% | 82% | 84% | 73% |\n",
    "\n",
    "The best-performing retrieval method and chunking strategies:\n",
    "\n",
    "|Metric Name|Retrieval Method|Chunking Strategies|Metric Value|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|Answer Component MRR@10|answerai-colbert-small-v1|B, D, E|0.52\n",
    "|Answer Component Recall@10|Single-vector cosine similiarty|E|87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f2HKIB7KPia"
   },
   "source": [
    "## The fastbook-benchmark Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CevVR5pFKP_r"
   },
   "source": [
    "The fastbook-benchmark dataset contains a list of items (questions). Each item looks something like this:\n",
    "\n",
    "```\n",
    "{\n",
    "            \"chapter\": 1,\n",
    "            \"question_number\": 1,\n",
    "            \"question_text\": \"Do you need these for deep learning?\\n\\n- Lots of math...\"\",\n",
    "            \"answer_context\": [\n",
    "                {\n",
    "                    \"answer_component\": \"\\\"Lots of math...\"\",\n",
    "                    \"scoring_type\": \"simple\",\n",
    "                    \"context\": [\n",
    "                        \"...Lots of math...\"\n",
    "                    ],\n",
    "                    \"explicit_context\": \"true\",\n",
    "                    \"extraneous_answer\": \"false\"\n",
    "                }\n",
    "            ],\n",
    "            \"question_context\": []\n",
    "        },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBq4GCADKVnU"
   },
   "source": [
    "I have broken down each `gold_standard_answer` into separate `answer_component`s, each of which has associated with it one or more `context`s from the chapter text that address that `answer_component`. Here's an example of a question with two `answer_component`s:\n",
    "\n",
    "```\n",
    "{\n",
    "            \"chapter\": 1,\n",
    "            \"question_number\": 5,\n",
    "            \"question_text\": \"What were the two theoretical misunderstandings that held back the field of neural networks?\",\n",
    "            \"gold_standard_answer\": \"\\\"In 1969...\"\",\n",
    "            \"answer_context\": [\n",
    "                {\n",
    "                    \"answer_component\": \"\\\"In 1969...\"\",\n",
    "                    \"scoring_type\": \"simple\",\n",
    "                    \"context\": [\n",
    "                        \"An MIT professor named...\"\n",
    "                    ],\n",
    "                    \"explicit_context\": \"true\",\n",
    "                    \"extraneous_answer\": \"false\"\n",
    "                },\n",
    "                {\n",
    "                    \"answer_component\": \"\\\"\\n\\nIn the 1980's...\"\",\n",
    "                    \"scoring_type\": \"simple\",\n",
    "                    \"context\": [\n",
    "                        \"In the 1980's...\"\n",
    "                    ],\n",
    "                    \"explicit_context\": \"true\",\n",
    "                    \"extraneous_answer\": \"false\"\n",
    "                }\n",
    "            ],\n",
    "            \"question_context\": []\n",
    "        },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSAbsM71KYnO"
   },
   "source": [
    "Any one of the `context`s is sufficient to address the associated `answer_component`. For example, for Chapter 1 Question 12:\n",
    "\n",
    "```\n",
    "{\n",
    "  \"answer_component\": \"We instead use the term parameters.\",\n",
    "  \"scoring_type\": \"simple\",\n",
    "  \"context\": [\n",
    "      \"By the way, what Samuel called \\\"weights\\\" are most generally referred to as model *parameters* these days\",\n",
    "\n",
    "      \"The *weights* are called *parameters*\"\n",
    "  ],\n",
    "  \"explicit_context\": \"true\",\n",
    "  \"extraneous_answer\": \"false\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cfb8eqHxKddn"
   },
   "source": [
    "For some questions' `gold_standard_answer` I found that some `answer_component`s were extraneous to the goal of the question. These have been marked with the flag `\"extraneous_answer\": \"false\"`.\n",
    "\n",
    "For some `answer_component`s I found the corresponding `context` implicitly addressing it. These have been marked with the flag `\"explicit_context\": \"false\"`.\n",
    "\n",
    "Finally, for some `answer_component`s I did not find relevant context in the given chapter so the `context` field is assigned an empty list `[]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywY6QSzPKgMb"
   },
   "source": [
    "All of the design decisions for this fastbook-benchmark dataset have largely been driven by one goal: don't change the `gold_standard_answer`. I have been using the fastai Forums' Wiki solutions page for each chapter as the gold standard answer set ([example](https://forums.fast.ai/t/fastbook-chapter-1-questionnaire-solutions-wiki/65647))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmSX0HSBKhC9"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "eCPQg38ZZYIr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers -Uqq\n",
    "!pip install -qq RAGatouille\n",
    "!pip install ftfy -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XynUV4RZYIw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show imports\"\n",
    "import sqlite3\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from ftfy import fix_text\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from ragatouille import RAGPretrainedModel\n",
    "emb_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:40:50.025834Z",
     "iopub.status.busy": "2024-11-26T00:40:50.025034Z",
     "iopub.status.idle": "2024-11-26T00:40:50.036117Z",
     "shell.execute_reply": "2024-11-26T00:40:50.035220Z",
     "shell.execute_reply.started": "2024-11-26T00:40:50.025798Z"
    },
    "id": "yVgg6cCxZYIy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show chunking code\"\n",
    "def get_chunks(notebook_path):\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as file:\n",
    "        notebook = json.load(file)\n",
    "\n",
    "    chunks = []\n",
    "    current_header = \"\"\n",
    "\n",
    "    def add_chunk(content):\n",
    "        if content.strip():\n",
    "            chunks.append(f\"{current_header}\\n\\n{content.strip()}\")\n",
    "\n",
    "    for cell in notebook['cells']:\n",
    "        if cell['cell_type'] == 'markdown':\n",
    "            content = ''.join(cell['source'])\n",
    "            # see if the cell starts with a markdown header\n",
    "            header_match = re.match(r'^(#+\\s+.*?)$', content, re.MULTILINE)\n",
    "            if header_match:\n",
    "                # grab the header\n",
    "                current_header = header_match.group(1)\n",
    "                # add any content after the header in the same cell\n",
    "                remaining_content = content[len(current_header):].strip()\n",
    "                if remaining_content:\n",
    "                    # split content into paragraphs\n",
    "                    paragraphs = re.split(r'\\n\\s*\\n', remaining_content)\n",
    "                    # append the paragraph to the list of chunks\n",
    "                    for paragraph in paragraphs:\n",
    "                        add_chunk(paragraph)\n",
    "            else:\n",
    "                # split content into paragraphs\n",
    "                paragraphs = re.split(r'\\n\\s*\\n', content)\n",
    "                # append the paragraph to the list of chunks\n",
    "                for paragraph in paragraphs:\n",
    "                    add_chunk(paragraph)\n",
    "        elif cell['cell_type'] == 'code':\n",
    "          code_content = '```python\\n' + ''.join(cell['source']) + '\\n```'\n",
    "\n",
    "          # include the output of the code cell\n",
    "          output_content = ''\n",
    "          if 'outputs' in cell and cell['outputs']:\n",
    "              for output in cell['outputs']:\n",
    "                  if 'text' in output:\n",
    "                      output_content += ''.join(output['text'])\n",
    "                  elif 'data' in output and 'text/plain' in output['data']:\n",
    "                      output_content += ''.join(output['data']['text/plain'])\n",
    "\n",
    "          # combine code and output in the same chunk\n",
    "          combined_content = code_content + '\\n\\nOutput:\\n' + output_content if output_content else code_content\n",
    "          add_chunk(combined_content)\n",
    "\n",
    "    def filter_chunks(chunks, exclude_headers=[\"Questionnaire\", \"Further Research\"]):\n",
    "      filtered_chunks = []\n",
    "      for chunk in chunks:\n",
    "          lines = chunk.split('\\n')\n",
    "          # check if the first line (header) is in the exclude list\n",
    "          if not any(header in lines[0] for header in exclude_headers):\n",
    "              filtered_chunks.append(chunk)\n",
    "      return filtered_chunks\n",
    "\n",
    "    return filter_chunks(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:40:57.639923Z",
     "iopub.status.busy": "2024-11-26T00:40:57.639543Z",
     "iopub.status.idle": "2024-11-26T00:40:57.647438Z",
     "shell.execute_reply": "2024-11-26T00:40:57.646406Z",
     "shell.execute_reply.started": "2024-11-26T00:40:57.639889Z"
    },
    "id": "Kz2bIJJ2ZYI0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show chunking code\"\n",
    "def combine_chunks(chunks, num_p=3):\n",
    "    combined_chunks = []\n",
    "    current_header = None\n",
    "    current_group = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # Extract header from chunk\n",
    "        header = chunk.split('\\n\\n')[0]\n",
    "\n",
    "        if header != current_header:\n",
    "            if len(current_group) > 1:  # Only add if group has content besides header\n",
    "                # Add current group to combined chunks if header changes\n",
    "                combined_chunks.append('\\n\\n'.join(current_group))\n",
    "            # Update current header\n",
    "            current_header = header\n",
    "            # Start new group with header and content of current chunk\n",
    "            current_group = [header, chunk.split('\\n\\n', 1)[1] if len(chunk.split('\\n\\n')) > 1 else '']\n",
    "        else:\n",
    "            if len(current_group) < num_p + 1:  # +1 to account for header\n",
    "                # Add chunk content (without header) to current group\n",
    "                current_group.append(chunk.split('\\n\\n', 1)[1] if len(chunk.split('\\n\\n')) > 1 else '')\n",
    "\n",
    "            if len(current_group) == num_p + 1:  # +1 to account for header\n",
    "                # Add full group to combined chunks\n",
    "                combined_chunks.append('\\n\\n'.join(current_group))\n",
    "                # Reset current group, keeping the header\n",
    "                current_group = [current_header]\n",
    "\n",
    "    if len(current_group) > 1:  # Only add if group has content besides header\n",
    "        # Add any remaining group to combined chunks\n",
    "        combined_chunks.append('\\n\\n'.join(current_group))\n",
    "\n",
    "    return combined_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:41:04.360423Z",
     "iopub.status.busy": "2024-11-26T00:41:04.360060Z",
     "iopub.status.idle": "2024-11-26T00:41:04.367195Z",
     "shell.execute_reply": "2024-11-26T00:41:04.366259Z",
     "shell.execute_reply.started": "2024-11-26T00:41:04.360389Z"
    },
    "id": "aCVk_he2ZYI1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the `load_data` function used for full text search\"\n",
    "def load_data(chunks, db_path, chapter=1):\n",
    "    try:\n",
    "        # create virtual table if database doesn't exist\n",
    "        if not os.path.exists(db_path):\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "              cur = conn.cursor()\n",
    "              cur.execute(\"\"\"\n",
    "              CREATE VIRTUAL TABLE fastbook_text\n",
    "              USING FTS5(chapter, text);\n",
    "              \"\"\")\n",
    "              conn.commit()\n",
    "\n",
    "        # load in the chunks for each chapter\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            cur = conn.cursor()\n",
    "\n",
    "            for chunk in chunks:\n",
    "                cur.execute(\"INSERT INTO fastbook_text(chapter, text) VALUES (?, ?)\", (chapter, chunk))\n",
    "\n",
    "            conn.commit()\n",
    "            res = cur.execute(\"SELECT * FROM fastbook_text WHERE chapter = ?\", (chapter,)).fetchall()\n",
    "        # make sure all the data was loaded into the database\n",
    "        if len(res) != len(chunks):\n",
    "            raise ValueError(f\"Number of inserted chunks ({len(res)}) doesn't match input chunks ({len(chunks)})\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:41:10.555260Z",
     "iopub.status.busy": "2024-11-26T00:41:10.554898Z",
     "iopub.status.idle": "2024-11-26T00:41:10.561423Z",
     "shell.execute_reply": "2024-11-26T00:41:10.560523Z",
     "shell.execute_reply.started": "2024-11-26T00:41:10.555227Z"
    },
    "id": "6N_OWOWcZYI1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the `db_search` function used for full text search\"\n",
    "def db_search(df, limit=1):\n",
    "  results = []\n",
    "  with sqlite3.connect('fastbook.db') as conn:\n",
    "    cur = conn.cursor()\n",
    "    # concatenate the keywords into a string \"keyword1 OR keyword 2 OR keyword3 ...\"\n",
    "    for _, row in df.iterrows():\n",
    "      keywords = ' OR '.join([f'\"{keyword.strip(\",\")}\"' for keyword in row['keywords'].replace('\"', '').split()])\n",
    "\n",
    "      q = f\"\"\"\n",
    "        SELECT text, rank\n",
    "        FROM fastbook_text\n",
    "        WHERE fastbook_text MATCH ?\n",
    "        AND chapter = ?\n",
    "        ORDER BY rank\n",
    "        LIMIT ?\n",
    "        \"\"\"\n",
    "      res = cur.execute(q, (keywords, str(row['chapter']), limit)).fetchall()\n",
    "      # grab the retrieved chunk from the query results\n",
    "      res = [item[0] for item in res]\n",
    "\n",
    "      # if there are multiple chunks retrieved, combine them into a single string\n",
    "      results.append(res)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T00:41:18.494100Z",
     "iopub.status.busy": "2024-11-26T00:41:18.493681Z",
     "iopub.status.idle": "2024-11-26T00:41:37.633040Z",
     "shell.execute_reply": "2024-11-26T00:41:37.632137Z",
     "shell.execute_reply.started": "2024-11-26T00:41:18.494059Z"
    },
    "id": "Zt04i8ofZYI2",
    "outputId": "5ae64c31-c3da-4454-8bda-9378f25d3613",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully: 01_intro.ipynb\n",
      "File downloaded successfully: 02_production.ipynb\n",
      "File downloaded successfully: 04_mnist_basics.ipynb\n",
      "File downloaded successfully: 08_collab.ipynb\n",
      "File downloaded successfully: 09_tabular.ipynb\n",
      "File downloaded successfully: 10_nlp.ipynb\n",
      "File downloaded successfully: 13_convolutions.ipynb\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Download chapter ipynb files\"\n",
    "urls = {\n",
    "    '01_intro.ipynb': 'https://drive.google.com/uc?export=view&id=1mmBjFH_plndPBC4iRZHChfMazgBxKK4_',\n",
    "    '02_production.ipynb': 'https://drive.google.com/uc?export=view&id=1Cf5QHthHy1z13H0iu3qrzAWgquCfqVHk',\n",
    "    '04_mnist_basics.ipynb': 'https://drive.google.com/uc?export=view&id=113909_BNulzyLIKUNJHdya0Hhoqie30I',\n",
    "    '08_collab.ipynb': 'https://drive.google.com/uc?export=view&id=1BtvStgFjUtvtqbSZNrL7Y2N-ey3seNZU',\n",
    "    '09_tabular.ipynb': 'https://drive.google.com/uc?export=view&id=1rHFvwl_l-AJLg_auPjBpNrOgG9HDnfqg',\n",
    "    '10_nlp.ipynb': 'https://drive.google.com/uc?export=view&id=1pg1pH7jMMElzrXS0kBBz14aAuDsi2DEP',\n",
    "    '13_convolutions.ipynb': 'https://drive.google.com/uc?export=view&id=19P-eEHpAO3WrOvdxgXckyhHhfv_R-hnS'\n",
    "}\n",
    "\n",
    "def download_file(url, filename):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open the file in write-binary mode\n",
    "        with open(filename, 'wb') as file:\n",
    "            # Write the content of the response to the file\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully: {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
    "\n",
    "for fname, url in urls.items():\n",
    "  download_file(url, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:41:41.213422Z",
     "iopub.status.busy": "2024-11-26T00:41:41.213043Z",
     "iopub.status.idle": "2024-11-26T00:41:41.217836Z",
     "shell.execute_reply": "2024-11-26T00:41:41.216877Z",
     "shell.execute_reply.started": "2024-11-26T00:41:41.213381Z"
    },
    "id": "Mps5hK4uZYI4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show the dict w/ notebook filenames\"\n",
    "nbs = {\n",
    "    '1': '01_intro.ipynb',\n",
    "    '2': '02_production.ipynb',\n",
    "    '4': '04_mnist_basics.ipynb',\n",
    "    '8': '08_collab.ipynb',\n",
    "    '9': '09_tabular.ipynb',\n",
    "    '10': '10_nlp.ipynb',\n",
    "    '13': '13_convolutions.ipynb'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T00:41:47.840474Z",
     "iopub.status.busy": "2024-11-26T00:41:47.839850Z",
     "iopub.status.idle": "2024-11-26T00:41:48.275128Z",
     "shell.execute_reply": "2024-11-26T00:41:48.274245Z",
     "shell.execute_reply.started": "2024-11-26T00:41:47.840432Z"
    },
    "id": "69VrnicMZYI5",
    "outputId": "062365c7-026f-415c-82a8-2487ac087279",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"questions\",\n  \"rows\": 191,\n  \"fields\": [\n    {\n      \"column\": \"chapter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 13,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          2,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1,\n        \"max\": 40,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          23,\n          20,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 191,\n        \"samples\": [\n          \"Why do we need padding for text classification? Why don't we need it for language modeling?\",\n          \"What is the function to calculate new weights using a learning rate?\",\n          \"What is the value of a convolutional kernel apply to a 3\\u00d73 matrix of zeros?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 191,\n        \"samples\": [\n          \"\\\"Since the documents have variable sizes, padding is needed to collate the batch. Other approaches. like cropping or squishing, either to negatively affect training or do not make sense in this context. Therefore, padding is used. It is not required for language modeling since the documents are all concatenated.\\\"\",\n          \"\\\"The optimizer step function\\\"\",\n          \"\\\"A zero matrix.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 191,\n        \"samples\": [\n          \"\\\"padding, text, classification, language, modeling, need\\\"\",\n          \"\\\"function, calculate, weight, weights, learning, rate\\\"\",\n          \"\\\"convolutional, kernel, matrix, zeros, value\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "questions"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3e6b4ae2-1a9d-4308-bcbd-b26864aa22b3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter</th>\n",
       "      <th>question_number</th>\n",
       "      <th>question_text</th>\n",
       "      <th>answer</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Do you need these for deep learning?\\n\\n- Lots...</td>\n",
       "      <td>\"Lots of math - False\\nLots of data - False\\nL...</td>\n",
       "      <td>\"deep learning, math, data, computers, PhD\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Name five areas where deep learning is now the...</td>\n",
       "      <td>\"Any five of the following:\\nNatural Language ...</td>\n",
       "      <td>deep learning, areas, best, world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>What was the name of the first device that was...</td>\n",
       "      <td>\"Mark I perceptron built by Frank Rosenblatt\"</td>\n",
       "      <td>\"neuron, neurons, device, artificial, principle\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Based on the book of the same name, what are t...</td>\n",
       "      <td>\"A set of processing units\\nA state of activat...</td>\n",
       "      <td>\"parallel, distributed, processing, PDP, requi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>What were the two theoretical misunderstanding...</td>\n",
       "      <td>\"In 1969, Marvin Minsky and Seymour Papert dem...</td>\n",
       "      <td>\"neural, networks, theoretical, misunderstandi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e6b4ae2-1a9d-4308-bcbd-b26864aa22b3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3e6b4ae2-1a9d-4308-bcbd-b26864aa22b3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3e6b4ae2-1a9d-4308-bcbd-b26864aa22b3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-05c06f37-b463-46c7-b469-35a27b3ccafc\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05c06f37-b463-46c7-b469-35a27b3ccafc')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-05c06f37-b463-46c7-b469-35a27b3ccafc button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   chapter  question_number  \\\n",
       "0        1                1   \n",
       "1        1                2   \n",
       "2        1                3   \n",
       "3        1                4   \n",
       "4        1                5   \n",
       "\n",
       "                                       question_text  \\\n",
       "0  Do you need these for deep learning?\\n\\n- Lots...   \n",
       "1  Name five areas where deep learning is now the...   \n",
       "2  What was the name of the first device that was...   \n",
       "3  Based on the book of the same name, what are t...   \n",
       "4  What were the two theoretical misunderstanding...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  \"Lots of math - False\\nLots of data - False\\nL...   \n",
       "1  \"Any five of the following:\\nNatural Language ...   \n",
       "2      \"Mark I perceptron built by Frank Rosenblatt\"   \n",
       "3  \"A set of processing units\\nA state of activat...   \n",
       "4  \"In 1969, Marvin Minsky and Seymour Papert dem...   \n",
       "\n",
       "                                            keywords  \n",
       "0        \"deep learning, math, data, computers, PhD\"  \n",
       "1                  deep learning, areas, best, world  \n",
       "2   \"neuron, neurons, device, artificial, principle\"  \n",
       "3  \"parallel, distributed, processing, PDP, requi...  \n",
       "4  \"neural, networks, theoretical, misunderstandi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the question texts\n",
    "url = 'https://gist.githubusercontent.com/vishalbakshi/2c22ca69ac7bc4bc845052c1b9d949c8/raw/d498259f2fc75d27c485ddc73933f145987feef3/cs_bm25_baselines.csv'\n",
    "questions = pd.read_csv(url).query(\"is_answerable == 1\")[[\"chapter\", \"question_number\", \"question_text\", \"answer\", \"keywords\"]]\n",
    "\n",
    "# remove double quotations from the question text\n",
    "# as these affect embeddings/cosine similarity: https://vishalbakshi.github.io/blog/posts/2024-11-08-punctuation-cosine-similarity/\n",
    "questions['question_text'] = questions['question_text'].str.strip('\"\\'')\n",
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:41:55.266890Z",
     "iopub.status.busy": "2024-11-26T00:41:55.265966Z",
     "iopub.status.idle": "2024-11-26T00:41:55.271153Z",
     "shell.execute_reply": "2024-11-26T00:41:55.270326Z",
     "shell.execute_reply.started": "2024-11-26T00:41:55.266842Z"
    },
    "id": "uSdkI-R5ZYI6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "assert questions.shape == (191,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T00:42:05.050170Z",
     "iopub.status.busy": "2024-11-26T00:42:05.049578Z",
     "iopub.status.idle": "2024-11-26T00:42:05.255531Z",
     "shell.execute_reply": "2024-11-26T00:42:05.254600Z",
     "shell.execute_reply.started": "2024-11-26T00:42:05.050132Z"
    },
    "id": "SvRI37ckZYI6",
    "outputId": "16dfee82-dbf5-42b4-ef9b-6e7c4954cb08",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully: fastbook-benchmark.json\n"
     ]
    }
   ],
   "source": [
    "# download fastbook-benchmark\n",
    "download_file(\n",
    "    \"https://gist.githubusercontent.com/vishalbakshi/a507b6e9e893475e93a4141e96b8947d/raw/e32835ba1dbf94384943ed5a65404112e1c89df2/fastbook-benchmark.json\",\n",
    "    \"fastbook-benchmark.json\"\n",
    "    )\n",
    "\n",
    "# Load the benchmark data\n",
    "with open('fastbook-benchmark.json', 'r') as f:\n",
    "    benchmark = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:42:11.224927Z",
     "iopub.status.busy": "2024-11-26T00:42:11.224542Z",
     "iopub.status.idle": "2024-11-26T00:42:11.229055Z",
     "shell.execute_reply": "2024-11-26T00:42:11.228216Z",
     "shell.execute_reply.started": "2024-11-26T00:42:11.224887Z"
    },
    "id": "sK9uklKfZYI7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "assert len(benchmark['questions']) == 191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:42:18.313016Z",
     "iopub.status.busy": "2024-11-26T00:42:18.312453Z",
     "iopub.status.idle": "2024-11-26T00:42:18.318329Z",
     "shell.execute_reply": "2024-11-26T00:42:18.317466Z",
     "shell.execute_reply.started": "2024-11-26T00:42:18.312980Z"
    },
    "id": "t82Ht7YcZYI7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show `calculate_mrr` function\"\n",
    "def calculate_mrr(question, retrieved_passages, cutoff=10):\n",
    "    retrieved_passages = retrieved_passages[:cutoff]\n",
    "    highest_rank = 0\n",
    "\n",
    "    for ans_comp in question[\"answer_context\"]:\n",
    "        contexts = ans_comp.get(\"context\", [])\n",
    "        component_found = False\n",
    "\n",
    "        for rank, passage in enumerate(retrieved_passages, start=1):\n",
    "            if any(fix_text(context) in fix_text(passage) for context in contexts):\n",
    "                highest_rank = max(highest_rank, rank)\n",
    "                component_found = True\n",
    "                break\n",
    "\n",
    "        if not component_found:\n",
    "            return 0.0\n",
    "\n",
    "    return 1.0/highest_rank if highest_rank > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:42:24.358734Z",
     "iopub.status.busy": "2024-11-26T00:42:24.358394Z",
     "iopub.status.idle": "2024-11-26T00:42:24.364432Z",
     "shell.execute_reply": "2024-11-26T00:42:24.363549Z",
     "shell.execute_reply.started": "2024-11-26T00:42:24.358702Z"
    },
    "id": "8SLtkghLZYI8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show `calculate_recall` function\"\n",
    "def calculate_recall(question, retrieved_passages, cutoff=10):\n",
    "    retrieved_passages = retrieved_passages[:cutoff]\n",
    "\n",
    "    # Track if we've found at least one context for each answer component\n",
    "    ans_comp_found = []\n",
    "\n",
    "    for ans_comp in question[\"answer_context\"]:\n",
    "        contexts = ans_comp.get(\"context\", [])\n",
    "        found = False\n",
    "\n",
    "        # Check if any context for this answer component appears in retrieved passages\n",
    "        for passage in retrieved_passages:\n",
    "            if any(fix_text(context) in fix_text(passage) for context in contexts):\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        ans_comp_found.append(found)\n",
    "\n",
    "    # Recall is ratio of answer components with at least one found context\n",
    "    return sum(ans_comp_found) / len(ans_comp_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:42:31.976734Z",
     "iopub.status.busy": "2024-11-26T00:42:31.976386Z",
     "iopub.status.idle": "2024-11-26T00:42:31.982038Z",
     "shell.execute_reply": "2024-11-26T00:42:31.981238Z",
     "shell.execute_reply.started": "2024-11-26T00:42:31.976705Z"
    },
    "id": "zOqMCqQ_ZYI8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show `fts_retrieval` function\"\n",
    "def fts_retrieval(data, questions):\n",
    "    if os.path.exists(\"fastbook.db\"):\n",
    "        os.remove(\"fastbook.db\")\n",
    "\n",
    "    for chapter, chunks in data.items():\n",
    "      print(f\"Chapter {chapter}:\", load_data(chunks, 'fastbook.db', chapter))\n",
    "\n",
    "    print(\"Retrieving passages...\")\n",
    "    results = db_search(questions, limit=10)\n",
    "\n",
    "    assert len(results) == 191\n",
    "    for res in results:\n",
    "        assert len(res) <= 10\n",
    "\n",
    "    print(\"Retrieval complete.\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:42:40.213339Z",
     "iopub.status.busy": "2024-11-26T00:42:40.212942Z",
     "iopub.status.idle": "2024-11-26T00:42:40.221922Z",
     "shell.execute_reply": "2024-11-26T00:42:40.221014Z",
     "shell.execute_reply.started": "2024-11-26T00:42:40.213297Z"
    },
    "id": "eNfHbYTYZYI8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show `single_vector_retrieval` function\"\n",
    "def single_vector_retrieval(data, benchmark):\n",
    "    # Group questions by chapter\n",
    "    questions = {}\n",
    "    for q in benchmark[\"questions\"]:\n",
    "        chapter = str(q[\"chapter\"])\n",
    "        if chapter not in questions:\n",
    "            questions[chapter] = []\n",
    "        questions[chapter].append(q['question_text'].strip('\"\\''))\n",
    "\n",
    "    q_embs = {}\n",
    "    print(\"Encoding Questions...\")\n",
    "    for chapter, _ in data.items():\n",
    "        qs = questions[chapter]\n",
    "        q_embs[chapter] = emb_model.encode(qs, convert_to_tensor=True)\n",
    "\n",
    "    data_embs = {}\n",
    "    print(\"Encoding Data...\")\n",
    "    for chapter, chunks in data.items():\n",
    "        data_embs[chapter] = emb_model.encode(chunks, convert_to_tensor=True)\n",
    "\n",
    "    results = []\n",
    "    print(\"Retrieving passages...\")\n",
    "    for chapter in ['1', '2', '4', '8', '9', '10', '13']:\n",
    "        # Compute cosine similarity and get top 10 indices for each row\n",
    "        idxs = F.cosine_similarity(q_embs[chapter].unsqueeze(1), data_embs[chapter].unsqueeze(0), dim=2).sort(descending=True)[1]\n",
    "        top_10_idxs = idxs[:, :10]  # Get the top 10 indices for each row\n",
    "\n",
    "        # Extract top 10 chunks for each row\n",
    "        top_10_chunks = [\n",
    "            [data[chapter][idx.item()] for idx in row_idxs]\n",
    "            for row_idxs in top_10_idxs\n",
    "        ]\n",
    "        results.extend(top_10_chunks)\n",
    "\n",
    "    assert len(results) == 191\n",
    "\n",
    "    for res in results:\n",
    "        assert len(res) <= 10\n",
    "\n",
    "    print(\"Retrieval complete.\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T01:06:39.877391Z",
     "iopub.status.busy": "2024-11-26T01:06:39.877005Z",
     "iopub.status.idle": "2024-11-26T01:06:39.885940Z",
     "shell.execute_reply": "2024-11-26T01:06:39.885048Z",
     "shell.execute_reply.started": "2024-11-26T01:06:39.877357Z"
    },
    "id": "kkcHfXSwZYI9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show `ragetouille_retrieval` function\"\n",
    "def ragatouille_retrieval(data, benchmark, model_nm=\"colbert-ir/colbertv2.0\"):\n",
    "    # Group questions by chapter\n",
    "    questions_by_chapter = {}\n",
    "    for q in benchmark[\"questions\"]:\n",
    "        chapter = str(q[\"chapter\"])\n",
    "        if chapter not in questions_by_chapter:\n",
    "            questions_by_chapter[chapter] = []\n",
    "        questions_by_chapter[chapter].append(q)\n",
    "\n",
    "    # Dictionary to store results per chapter\n",
    "    chapter_results = {}\n",
    "    chapter_metrics = {}\n",
    "\n",
    "    # Initialize ColBERTv2\n",
    "    RAG = RAGPretrainedModel.from_pretrained(model_nm)\n",
    "\n",
    "    # Process each chapter separately\n",
    "    for chapter in nbs.keys():\n",
    "        print(f\"\\nProcessing Chapter {chapter}\")\n",
    "\n",
    "        # Create chapter-specific index\n",
    "        index_path = RAG.index(\n",
    "            index_name=f\"chapter_{chapter}_index\",\n",
    "            collection=data[chapter],\n",
    "            document_ids=[f\"{chapter}_{i}\" for i in range(len(data[chapter]))]\n",
    "        )\n",
    "\n",
    "        # Get questions for this chapter\n",
    "        chapter_questions = questions_by_chapter[chapter]\n",
    "\n",
    "        # Perform retrieval for each question in this chapter\n",
    "        results = []\n",
    "        for q in chapter_questions:\n",
    "            retrieved = RAG.search(q[\"question_text\"].strip('\"\\''), k=10)\n",
    "            results.append(retrieved)\n",
    "\n",
    "        # Store results\n",
    "        chapter_results[chapter] = results\n",
    "\n",
    "    results = []\n",
    "    for chapter, res in chapter_results.items():\n",
    "        results.extend(res)\n",
    "\n",
    "    assert len(results) == 191\n",
    "\n",
    "    final_results = []\n",
    "    for res in results:\n",
    "        assert len(res) <= 10\n",
    "        intermediate_results = [r['content'] for r in res]\n",
    "        final_results.append(intermediate_results)\n",
    "\n",
    "    print(\"Retrieval complete.\")\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T01:06:51.651038Z",
     "iopub.status.busy": "2024-11-26T01:06:51.650684Z",
     "iopub.status.idle": "2024-11-26T01:06:51.656817Z",
     "shell.execute_reply": "2024-11-26T01:06:51.655754Z",
     "shell.execute_reply.started": "2024-11-26T01:06:51.651007Z"
    },
    "id": "oC4e2fcaZYI9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show `do_retrieval` function\"\n",
    "def do_retrieval(method, chunking_strategy, data, benchmark, benchmark_results, questions=None):\n",
    "  if method == \"bm25\": results = fts_retrieval(data, questions)\n",
    "  if method == \"single_vector\": results = single_vector_retrieval(data, benchmark)\n",
    "  if method == \"colbertv2\": results = ragatouille_retrieval(data, benchmark, model_nm=\"colbert-ir/colbertv2.0\")\n",
    "  if method == \"answerai_colbert\": results = ragatouille_retrieval(data, benchmark, model_nm=\"answerdotai/answerai-colbert-small-v1\")\n",
    "\n",
    "  name = f\"{method}_{chunking_strategy}\"\n",
    "  q_mrr, q_recall = score_retrieval(results, benchmark)\n",
    "  benchmark_results = save_results(results, benchmark_results, q_mrr, q_recall, name=name)\n",
    "\n",
    "  return benchmark_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:43:03.484422Z",
     "iopub.status.busy": "2024-11-26T00:43:03.483575Z",
     "iopub.status.idle": "2024-11-26T00:43:03.491562Z",
     "shell.execute_reply": "2024-11-26T00:43:03.490588Z",
     "shell.execute_reply.started": "2024-11-26T00:43:03.484360Z"
    },
    "id": "PK4XXWkIZYI9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show `score_retrieval` function\"\n",
    "def score_retrieval(results, benchmark):\n",
    "    q_mrr = []\n",
    "    q_recall = []\n",
    "\n",
    "    for i, question in enumerate(benchmark[\"questions\"]):\n",
    "        mrr = calculate_mrr(question, results[i], cutoff=10)\n",
    "        recall = calculate_recall(question, results[i], cutoff=10)\n",
    "        q_mrr.append(mrr)\n",
    "        q_recall.append(recall)\n",
    "\n",
    "    assert len(q_mrr) == 191\n",
    "    assert len(q_recall) == 191\n",
    "\n",
    "    return q_mrr, q_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T00:43:09.476964Z",
     "iopub.status.busy": "2024-11-26T00:43:09.476628Z",
     "iopub.status.idle": "2024-11-26T00:43:09.481771Z",
     "shell.execute_reply": "2024-11-26T00:43:09.480823Z",
     "shell.execute_reply.started": "2024-11-26T00:43:09.476931Z"
    },
    "id": "sRp34-duZYI9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show `save_results` function\"\n",
    "def save_results(results, df, q_mrr, q_recall, name):\n",
    "    flat_results = []\n",
    "    for res in results:\n",
    "        flat_results.append(\"\\n\\n\".join(res))\n",
    "\n",
    "    assert len(flat_results) == 191\n",
    "\n",
    "    df[f'{name}_retrieval'] = flat_results\n",
    "    df[f'{name}_mrr10'] = q_mrr\n",
    "    df[f'{name}_recall10'] = q_recall\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eBt_PrTZYI-"
   },
   "source": [
    "## Chunking Strategy A: 1-Paragraph (with headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T00:51:29.646506Z",
     "iopub.status.busy": "2024-11-26T00:51:29.645668Z",
     "iopub.status.idle": "2024-11-26T00:51:29.685541Z",
     "shell.execute_reply": "2024-11-26T00:51:29.684729Z",
     "shell.execute_reply.started": "2024-11-26T00:51:29.646468Z"
    },
    "id": "lsjUKOFbZYI_",
    "outputId": "a60b9b2b-05fd-4a7b-db14-bf2e9beb44e3",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 307\n",
      "2 227\n",
      "4 433\n",
      "8 157\n",
      "9 387\n",
      "10 190\n",
      "13 266\n"
     ]
    }
   ],
   "source": [
    "# chunking each notebook\n",
    "data = {}\n",
    "\n",
    "for chapter, nb in nbs.items():\n",
    "  data[chapter] = get_chunks(nb)\n",
    "\n",
    "total_chunks = 0\n",
    "for chapter, chunks in data.items():\n",
    "  print(chapter, len(chunks))\n",
    "  total_chunks += len(chunks)\n",
    "\n",
    "assert total_chunks == 1967 # 1-paragraph chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCNlHJqLZYI_"
   },
   "source": [
    "### Retrieval Method: Full Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T00:52:53.273359Z",
     "iopub.status.busy": "2024-11-26T00:52:53.272986Z",
     "iopub.status.idle": "2024-11-26T00:52:54.283069Z",
     "shell.execute_reply": "2024-11-26T00:52:54.282328Z",
     "shell.execute_reply.started": "2024-11-26T00:52:53.273326Z"
    },
    "id": "BUOneUZGZYI_",
    "outputId": "3f99d796-b24e-438f-90a8-ff2eb672f1de",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: True\n",
      "Chapter 2: True\n",
      "Chapter 4: True\n",
      "Chapter 8: True\n",
      "Chapter 9: True\n",
      "Chapter 10: True\n",
      "Chapter 13: True\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"bm25\",\n",
    "    chunking_strategy=\"A\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=questions.copy(),\n",
    "    questions=questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T00:52:59.673041Z",
     "iopub.status.busy": "2024-11-26T00:52:59.672738Z",
     "iopub.status.idle": "2024-11-26T00:52:59.679368Z",
     "shell.execute_reply": "2024-11-26T00:52:59.678484Z",
     "shell.execute_reply.started": "2024-11-26T00:52:59.673016Z"
    },
    "id": "tiaem1fGZYJA",
    "outputId": "e864e397-6c5c-448a-a695-d44dc34f075c",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3, 0.65)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['bm25_A_mrr10'].mean(),2), round(benchmark_results['bm25_A_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OL-5Wk-gZYJA"
   },
   "source": [
    "### Retrieval Method: Single-Vector Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T00:53:13.136073Z",
     "iopub.status.busy": "2024-11-26T00:53:13.135765Z",
     "iopub.status.idle": "2024-11-26T00:53:19.206390Z",
     "shell.execute_reply": "2024-11-26T00:53:19.205660Z",
     "shell.execute_reply.started": "2024-11-26T00:53:13.136046Z"
    },
    "id": "C6mYDg4xZYJA",
    "outputId": "fb291378-abfe-47e5-f8a4-2a798a99979e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Questions...\n",
      "Encoding Data...\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"single_vector\",\n",
    "    chunking_strategy=\"A\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T00:53:22.883480Z",
     "iopub.status.busy": "2024-11-26T00:53:22.883045Z",
     "iopub.status.idle": "2024-11-26T00:53:22.890175Z",
     "shell.execute_reply": "2024-11-26T00:53:22.889157Z",
     "shell.execute_reply.started": "2024-11-26T00:53:22.883444Z"
    },
    "id": "aCwNhqyMZYJA",
    "outputId": "d1507f36-f5b7-4c92-e298-4767378245b3",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38, 0.71)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['single_vector_A_mrr10'].mean(),2), round(benchmark_results['single_vector_A_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJZ1GtzLZYJA"
   },
   "source": [
    "### Retrieval Method: ColBERTv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECUf4ybTZYJB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"colbertv2\",\n",
    "    chunking_strategy=\"A\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:10:44.232174Z",
     "iopub.status.busy": "2024-11-26T01:10:44.231884Z",
     "iopub.status.idle": "2024-11-26T01:10:44.238858Z",
     "shell.execute_reply": "2024-11-26T01:10:44.238107Z",
     "shell.execute_reply.started": "2024-11-26T01:10:44.232146Z"
    },
    "id": "OMu2nd1qZYJB",
    "outputId": "c0cee31e-9fe6-4d72-a579-90d37f48cf5e",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46, 0.8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['colbertv2_A_mrr10'].mean(),2), round(benchmark_results['colbertv2_A_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTzuFrHbZYJC"
   },
   "source": [
    "### Retrieval Method: answerai-colbert-small-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-mphBQLZYJC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"answerai_colbert\",\n",
    "    chunking_strategy=\"A\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:14:41.402607Z",
     "iopub.status.busy": "2024-11-26T01:14:41.401908Z",
     "iopub.status.idle": "2024-11-26T01:14:41.408764Z",
     "shell.execute_reply": "2024-11-26T01:14:41.407873Z",
     "shell.execute_reply.started": "2024-11-26T01:14:41.402570Z"
    },
    "id": "dHRdgR2oZYJC",
    "outputId": "411aee2a-727b-424b-bc14-16097044747e",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48, 0.82)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['answerai_colbert_A_mrr10'].mean(),2), round(benchmark_results['answerai_colbert_A_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oouk5LZ-ZYJC"
   },
   "source": [
    "## Chunking Strategy B: 3-Paragraph (with headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOBb8sWgZYJD"
   },
   "source": [
    "Next, I'll expand the chunks to include 3-paragraphs at a time. I'm still keeping the headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:15:08.474995Z",
     "iopub.status.busy": "2024-11-26T01:15:08.474668Z",
     "iopub.status.idle": "2024-11-26T01:15:08.484289Z",
     "shell.execute_reply": "2024-11-26T01:15:08.483444Z",
     "shell.execute_reply.started": "2024-11-26T01:15:08.474963Z"
    },
    "id": "-zmfb9n2ZYJD",
    "outputId": "427c0da0-a586-486b-9613-ef5d171172be",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 112\n",
      "2 84\n",
      "4 152\n",
      "8 58\n",
      "9 141\n",
      "10 70\n",
      "13 96\n"
     ]
    }
   ],
   "source": [
    "for chapter, chunks in data.items():\n",
    "  data[chapter] = combine_chunks(chunks, num_p=3)\n",
    "\n",
    "total_chunks = 0\n",
    "\n",
    "for chapter, chunks in data.items():\n",
    "  print(chapter, len(chunks))\n",
    "  total_chunks += len(chunks)\n",
    "\n",
    "assert total_chunks == 713"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkohfIoHZYJD"
   },
   "source": [
    "### Retrieval Method: Full Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:21:42.900175Z",
     "iopub.status.busy": "2024-11-26T01:21:42.899823Z",
     "iopub.status.idle": "2024-11-26T01:21:44.142204Z",
     "shell.execute_reply": "2024-11-26T01:21:44.141542Z",
     "shell.execute_reply.started": "2024-11-26T01:21:42.900141Z"
    },
    "id": "_uCJwST7ZYJP",
    "outputId": "abd4dc29-24af-4ab6-d031-567c7a8497f9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: True\n",
      "Chapter 2: True\n",
      "Chapter 4: True\n",
      "Chapter 8: True\n",
      "Chapter 9: True\n",
      "Chapter 10: True\n",
      "Chapter 13: True\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"bm25\",\n",
    "    chunking_strategy=\"B\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results,\n",
    "    questions=questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:21:44.731440Z",
     "iopub.status.busy": "2024-11-26T01:21:44.731076Z",
     "iopub.status.idle": "2024-11-26T01:21:44.737976Z",
     "shell.execute_reply": "2024-11-26T01:21:44.737048Z",
     "shell.execute_reply.started": "2024-11-26T01:21:44.731406Z"
    },
    "id": "zmrrf3nyZYJf",
    "outputId": "b886106b-7d30-48c1-f78c-9a97bd1e5b34",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46, 0.83)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['bm25_B_mrr10'].mean(),2), round(benchmark_results['bm25_B_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1ngeDTGZYJf"
   },
   "source": [
    "### Retrieval Method: Single-Vector Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:22:23.269973Z",
     "iopub.status.busy": "2024-11-26T01:22:23.269748Z",
     "iopub.status.idle": "2024-11-26T01:22:29.060680Z",
     "shell.execute_reply": "2024-11-26T01:22:29.059996Z",
     "shell.execute_reply.started": "2024-11-26T01:22:23.269948Z"
    },
    "id": "M4q37d4qZYJf",
    "outputId": "ee004991-ee4f-4778-c6b7-72d459ac81c1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Questions...\n",
      "Encoding Data...\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"single_vector\",\n",
    "    chunking_strategy=\"B\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:22:32.334662Z",
     "iopub.status.busy": "2024-11-26T01:22:32.333867Z",
     "iopub.status.idle": "2024-11-26T01:22:32.340872Z",
     "shell.execute_reply": "2024-11-26T01:22:32.339937Z",
     "shell.execute_reply.started": "2024-11-26T01:22:32.334624Z"
    },
    "id": "9tA_WlFJZYJg",
    "outputId": "5484102d-1158-48c2-cb2e-f67d7751953b",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.85)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['single_vector_B_mrr10'].mean(),2), round(benchmark_results['single_vector_B_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEnP_m-fZYJg"
   },
   "source": [
    "### Retrieval Method: ColBERTv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N__7Nl1XZYJg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"colbertv2\",\n",
    "    chunking_strategy=\"B\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:26:40.994007Z",
     "iopub.status.busy": "2024-11-26T01:26:40.993740Z",
     "iopub.status.idle": "2024-11-26T01:26:41.000087Z",
     "shell.execute_reply": "2024-11-26T01:26:40.999259Z",
     "shell.execute_reply.started": "2024-11-26T01:26:40.993980Z"
    },
    "id": "b3495s2DZYJg",
    "outputId": "7f153334-7712-4b1f-8277-54d93cf9ddcb",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49, 0.8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['colbertv2_B_mrr10'].mean(),2), round(benchmark_results['colbertv2_B_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkpEL8BSZYJh"
   },
   "source": [
    "### Retrieval Method: answerai-colbert-small-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6SUgxy5ZYJh",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"answerai_colbert\",\n",
    "    chunking_strategy=\"B\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:30:18.190218Z",
     "iopub.status.busy": "2024-11-26T01:30:18.189864Z",
     "iopub.status.idle": "2024-11-26T01:30:18.197158Z",
     "shell.execute_reply": "2024-11-26T01:30:18.196203Z",
     "shell.execute_reply.started": "2024-11-26T01:30:18.190179Z"
    },
    "id": "d70cd4qGZYJh",
    "outputId": "0fbaa6c4-f6e8-4fd3-a9dd-41fffe8a5eef",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.52, 0.84)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['answerai_colbert_B_mrr10'].mean(),2), round(benchmark_results['answerai_colbert_B_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOAfqi__ZYJi"
   },
   "source": [
    "## Chunking Strategy C: 1-Paragraph (w/o headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjbsrrchHX39"
   },
   "source": [
    "Next, I'll remove markdown headers from each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T02:18:36.662925Z",
     "iopub.status.busy": "2024-11-26T02:18:36.662593Z",
     "iopub.status.idle": "2024-11-26T02:18:36.710061Z",
     "shell.execute_reply": "2024-11-26T02:18:36.709141Z",
     "shell.execute_reply.started": "2024-11-26T02:18:36.662894Z"
    },
    "id": "Ugkj_EGuZYJi",
    "outputId": "812b1cfa-de14-43a9-90f0-244bdfd34eb2",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 307\n",
      "2 227\n",
      "4 433\n",
      "8 157\n",
      "9 387\n",
      "10 190\n",
      "13 266\n"
     ]
    }
   ],
   "source": [
    "# chunking each notebook\n",
    "data = {}\n",
    "\n",
    "for chapter, nb in nbs.items():\n",
    "    data[chapter] = get_chunks(nb)\n",
    "\n",
    "for chapter, chunks in data.items():\n",
    "    data[chapter] = [re.sub(r'^#+\\s+[^\\n]+\\n*', '', c) for c in data[chapter]]\n",
    "\n",
    "total_chunks = 0\n",
    "for chapter, chunks in data.items():\n",
    "    print(chapter, len(chunks))\n",
    "    total_chunks += len(chunks)\n",
    "\n",
    "assert total_chunks == 1967 # 1-paragraph chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qwi2a2QMZYJj"
   },
   "source": [
    "### Retrieval Method: Full Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:50:28.409613Z",
     "iopub.status.busy": "2024-11-26T01:50:28.408983Z",
     "iopub.status.idle": "2024-11-26T01:50:29.306803Z",
     "shell.execute_reply": "2024-11-26T01:50:29.306115Z",
     "shell.execute_reply.started": "2024-11-26T01:50:28.409574Z"
    },
    "id": "KMZMMszLZYJk",
    "outputId": "2a763f15-020f-4031-e770-0115470e8698",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: True\n",
      "Chapter 2: True\n",
      "Chapter 4: True\n",
      "Chapter 8: True\n",
      "Chapter 9: True\n",
      "Chapter 10: True\n",
      "Chapter 13: True\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"bm25\",\n",
    "    chunking_strategy=\"C\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results,\n",
    "    questions=questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:50:29.977570Z",
     "iopub.status.busy": "2024-11-26T01:50:29.977247Z",
     "iopub.status.idle": "2024-11-26T01:50:29.983900Z",
     "shell.execute_reply": "2024-11-26T01:50:29.983041Z",
     "shell.execute_reply.started": "2024-11-26T01:50:29.977541Z"
    },
    "id": "0gxMP_ooZYJz",
    "outputId": "7202028e-894e-4629-9d7c-a424626b1cfb",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.29, 0.65)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['bm25_C_mrr10'].mean(),2), round(benchmark_results['bm25_C_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVnml93ZZYJz"
   },
   "source": [
    "### Retrieval Method: Single-Vector Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:51:05.345206Z",
     "iopub.status.busy": "2024-11-26T01:51:05.344866Z",
     "iopub.status.idle": "2024-11-26T01:51:10.910854Z",
     "shell.execute_reply": "2024-11-26T01:51:10.909942Z",
     "shell.execute_reply.started": "2024-11-26T01:51:05.345173Z"
    },
    "id": "phtWbjioZYJ0",
    "outputId": "8bb433d4-333f-4fe5-b908-480a0ecd232e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Questions...\n",
      "Encoding Data...\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"single_vector\",\n",
    "    chunking_strategy=\"C\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:51:19.644687Z",
     "iopub.status.busy": "2024-11-26T01:51:19.644254Z",
     "iopub.status.idle": "2024-11-26T01:51:19.651422Z",
     "shell.execute_reply": "2024-11-26T01:51:19.650429Z",
     "shell.execute_reply.started": "2024-11-26T01:51:19.644651Z"
    },
    "id": "2AB2yphXZYJ0",
    "outputId": "e16721c1-080b-415d-898b-4bb81587c524",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35, 0.72)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['single_vector_C_mrr10'].mean(),2), round(benchmark_results['single_vector_C_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E6zqCLl7ZYJ6"
   },
   "source": [
    "### Retrieval Method: ColBERTv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxshkdG-ZYJ7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"colbertv2\",\n",
    "    chunking_strategy=\"C\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:55:36.156991Z",
     "iopub.status.busy": "2024-11-26T01:55:36.156709Z",
     "iopub.status.idle": "2024-11-26T01:55:36.163281Z",
     "shell.execute_reply": "2024-11-26T01:55:36.162427Z",
     "shell.execute_reply.started": "2024-11-26T01:55:36.156963Z"
    },
    "id": "dz-p9TtsZYJ-",
    "outputId": "00f173f8-10af-4ba9-f683-4445ac7b762e",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41, 0.74)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['colbertv2_C_mrr10'].mean(),2), round(benchmark_results['colbertv2_C_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oY8D_c8LZYJ_"
   },
   "source": [
    "### Retrieval Method: answerai-colbert-small-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwsEiA-TZYKA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"answerai_colbert\",\n",
    "    chunking_strategy=\"C\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T01:59:13.167358Z",
     "iopub.status.busy": "2024-11-26T01:59:13.166923Z",
     "iopub.status.idle": "2024-11-26T01:59:13.174970Z",
     "shell.execute_reply": "2024-11-26T01:59:13.174299Z",
     "shell.execute_reply.started": "2024-11-26T01:59:13.167298Z"
    },
    "id": "iE5XpsxiZYKA",
    "outputId": "b4d69dc6-1001-4e86-f231-9f7d7e5c26ba",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45, 0.77)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['answerai_colbert_C_mrr10'].mean(),2), round(benchmark_results['answerai_colbert_C_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2QgJ_8RZYKA"
   },
   "source": [
    "## Chunking Strategy D: 3-Paragraph (w/o headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raojGJbUHb2S"
   },
   "source": [
    "Expanding header-less chunks to 3-paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T02:18:59.619716Z",
     "iopub.status.busy": "2024-11-26T02:18:59.618912Z",
     "iopub.status.idle": "2024-11-26T02:18:59.624729Z",
     "shell.execute_reply": "2024-11-26T02:18:59.623786Z",
     "shell.execute_reply.started": "2024-11-26T02:18:59.619681Z"
    },
    "id": "ZwMy61x9ZYKA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show modified `combine_chunks` function\"\n",
    "def combine_chunks2(chunks, num_p=3):\n",
    "    \"\"\"\n",
    "    Combines text chunks into groups of specified size (num_p).\n",
    "    If chunks have no headers, treats them as standalone content.\n",
    "    \"\"\"\n",
    "    combined_chunks = []\n",
    "    current_group = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if len(current_group) < num_p:\n",
    "            current_group.append(chunk)\n",
    "\n",
    "        if len(current_group) == num_p:\n",
    "            combined_chunks.append('\\n\\n'.join(current_group))\n",
    "            current_group = []\n",
    "\n",
    "    # Add any remaining chunks\n",
    "    if current_group:\n",
    "        combined_chunks.append('\\n\\n'.join(current_group))\n",
    "\n",
    "    return combined_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T02:19:01.221431Z",
     "iopub.status.busy": "2024-11-26T02:19:01.221066Z",
     "iopub.status.idle": "2024-11-26T02:19:01.227953Z",
     "shell.execute_reply": "2024-11-26T02:19:01.227032Z",
     "shell.execute_reply.started": "2024-11-26T02:19:01.221397Z"
    },
    "id": "7f-4RL-GZYKB",
    "outputId": "1a99dfba-0541-44f6-b31e-0e1f3cb0d4d0",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 103\n",
      "2 76\n",
      "4 145\n",
      "8 53\n",
      "9 129\n",
      "10 64\n",
      "13 89\n"
     ]
    }
   ],
   "source": [
    "for chapter, chunks in data.items():\n",
    "  data[chapter] = combine_chunks2(chunks, num_p=3)\n",
    "\n",
    "total_chunks = 0\n",
    "\n",
    "for chapter, chunks in data.items():\n",
    "  print(chapter, len(chunks))\n",
    "  total_chunks += len(chunks)\n",
    "\n",
    "assert total_chunks == 659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3S3bodNZYKB"
   },
   "source": [
    "### Retrieval Method: Full Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T02:19:08.187884Z",
     "iopub.status.busy": "2024-11-26T02:19:08.187252Z",
     "iopub.status.idle": "2024-11-26T02:19:09.404320Z",
     "shell.execute_reply": "2024-11-26T02:19:09.403632Z",
     "shell.execute_reply.started": "2024-11-26T02:19:08.187848Z"
    },
    "id": "SElKFG5VZYKB",
    "outputId": "c829e29b-5397-49a6-c798-2ee73ab94753",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: True\n",
      "Chapter 2: True\n",
      "Chapter 4: True\n",
      "Chapter 8: True\n",
      "Chapter 9: True\n",
      "Chapter 10: True\n",
      "Chapter 13: True\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"bm25\",\n",
    "    chunking_strategy=\"D\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results,\n",
    "    questions=questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T02:19:11.000307Z",
     "iopub.status.busy": "2024-11-26T02:19:10.999957Z",
     "iopub.status.idle": "2024-11-26T02:19:11.006879Z",
     "shell.execute_reply": "2024-11-26T02:19:11.005978Z",
     "shell.execute_reply.started": "2024-11-26T02:19:11.000258Z"
    },
    "id": "kt7i2U5NZYKB",
    "outputId": "8bb81432-28e6-4472-d2e1-05e14e0c1e0f",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44, 0.82)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['bm25_D_mrr10'].mean(),2), round(benchmark_results['bm25_D_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_LfLTzkZYKC"
   },
   "source": [
    "### Retrieval Method: Single-Vector Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T02:19:26.213399Z",
     "iopub.status.busy": "2024-11-26T02:19:26.212708Z",
     "iopub.status.idle": "2024-11-26T02:19:31.639801Z",
     "shell.execute_reply": "2024-11-26T02:19:31.639098Z",
     "shell.execute_reply.started": "2024-11-26T02:19:26.213361Z"
    },
    "id": "lwH4VJgiZYKC",
    "outputId": "8feac0c6-3779-4b47-90ad-e4ed75fa12aa",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Questions...\n",
      "Encoding Data...\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"single_vector\",\n",
    "    chunking_strategy=\"D\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T02:19:31.860104Z",
     "iopub.status.busy": "2024-11-26T02:19:31.859901Z",
     "iopub.status.idle": "2024-11-26T02:19:31.866516Z",
     "shell.execute_reply": "2024-11-26T02:19:31.865665Z",
     "shell.execute_reply.started": "2024-11-26T02:19:31.860081Z"
    },
    "id": "k2mwt1Z7ZYKC",
    "outputId": "6a21ac81-4f08-4ead-fffc-08ddccf49f01",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46, 0.82)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['single_vector_D_mrr10'].mean(),2), round(benchmark_results['single_vector_D_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0L94XeHZYKD"
   },
   "source": [
    "### Retrieval Method: ColBERTv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGIcx6LpZYKD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"colbertv2\",\n",
    "    chunking_strategy=\"D\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T02:25:00.952874Z",
     "iopub.status.busy": "2024-11-26T02:25:00.952598Z",
     "iopub.status.idle": "2024-11-26T02:25:00.959190Z",
     "shell.execute_reply": "2024-11-26T02:25:00.958249Z",
     "shell.execute_reply.started": "2024-11-26T02:25:00.952846Z"
    },
    "id": "WsiwtVo_ZYKD",
    "outputId": "db7e3b68-f54e-49f9-dada-53f746fe9d34",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['colbertv2_D_mrr10'].mean(),2), round(benchmark_results['colbertv2_D_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwdkwIP-ZYKE"
   },
   "source": [
    "### Retrieval Method: answerai-colbert-small-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uN_4YIE1ZYKF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"answerai_colbert\",\n",
    "    chunking_strategy=\"D\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T02:28:36.873734Z",
     "iopub.status.busy": "2024-11-26T02:28:36.873458Z",
     "iopub.status.idle": "2024-11-26T02:28:36.880094Z",
     "shell.execute_reply": "2024-11-26T02:28:36.879220Z",
     "shell.execute_reply.started": "2024-11-26T02:28:36.873707Z"
    },
    "id": "OJhhFeM_ZYKG",
    "outputId": "713135f7-7b6e-47f3-add7-5b3db7dbdbce",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.52, 0.82)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['answerai_colbert_D_mrr10'].mean(),2), round(benchmark_results['answerai_colbert_D_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hB-FFg7Wjr6Y"
   },
   "source": [
    "## Chunking Strategy E: (3-paragraph w/headers, w/o HTML tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eg2c43kIHgPa"
   },
   "source": [
    "I'll add headers back, but will remove HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "doJA4XZ5n9q0"
   },
   "outputs": [],
   "source": [
    "# chunking each notebook\n",
    "data = {}\n",
    "\n",
    "for chapter, nb in nbs.items():\n",
    "  data[chapter] = get_chunks(nb)\n",
    "\n",
    "total_chunks = 0\n",
    "for chapter, chunks in data.items():\n",
    "  total_chunks += len(chunks)\n",
    "\n",
    "assert total_chunks == 1967 # 1-paragraph chunks\n",
    "\n",
    "for chapter, chunks in data.items():\n",
    "  data[chapter] = combine_chunks(chunks, num_p=3)\n",
    "\n",
    "total_chunks = 0\n",
    "\n",
    "for chapter, chunks in data.items():\n",
    "  total_chunks += len(chunks)\n",
    "\n",
    "assert total_chunks == 713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "8Q3sHxGyqLKK",
    "outputId": "9f240ac1-b0ec-49c2-a440-fd29ac67be70"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'## The Magic of Convolutions\\n\\nIt turns out that finding the edges in an image is a very common task in computer vision, and is surprisingly straightforward. To do it, we use something called a *convolution*. A convolution requires nothing more than multiplication, and addition—two operations that are responsible for the vast majority of work that we will see in every single deep learning model in this book!\\n\\nA convolution applies a *kernel* across an image. A kernel is a little matrix, such as the 3×3 matrix in the top right of <<basic_conv>>.\\n\\n<img src=\"images/chapter9_conv_basic.png\" id=\"basic_conv\" caption=\"Applying a kernel to one location\" alt=\"Applying a kernel to one location\" width=\"700\">'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mUSHCmKJ0CP9",
    "outputId": "20111447-31ee-48b8-9d01-a40bdd0c12d6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'The text is <<untouched>>.'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_html(text):\n",
    "    # Step 1: Temporarily replace double-bracketed content with a placeholder\n",
    "    import uuid\n",
    "    placeholder = f\"PLACEHOLDER_{uuid.uuid4()}\"\n",
    "    double_bracketed = re.findall(r'<<[^>]*>>', text)\n",
    "    step1 = re.sub(r'<<[^>]*>>', placeholder, text)\n",
    "\n",
    "    # Step 2: Remove HTML tags\n",
    "    step2 = re.sub(r'<[/]?[a-zA-Z][^>]*>', '', step1)\n",
    "\n",
    "    # Step 3: Restore double-bracketed content\n",
    "    if double_bracketed:\n",
    "        step3 = step2.replace(placeholder, double_bracketed[0])\n",
    "        return step3\n",
    "    return step2\n",
    "\n",
    "clean_html('The <a href=\"#\">text</a> is <<untouched>>.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "c-XvYWNLogO3"
   },
   "outputs": [],
   "source": [
    "for chapter, chunks in data.items():\n",
    "  data[chapter] = [clean_html(chunk) for chunk in chunks]\n",
    "\n",
    "total_chunks = 0\n",
    "\n",
    "for chapter, chunks in data.items():\n",
    "  total_chunks += len(chunks)\n",
    "\n",
    "assert total_chunks == 713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "6L1vCnWypk4c",
    "outputId": "f0271933-ae7b-482e-cca5-32542a8e5130"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'## The Magic of Convolutions\\n\\nIt turns out that finding the edges in an image is a very common task in computer vision, and is surprisingly straightforward. To do it, we use something called a *convolution*. A convolution requires nothing more than multiplication, and addition—two operations that are responsible for the vast majority of work that we will see in every single deep learning model in this book!\\n\\nA convolution applies a *kernel* across an image. A kernel is a little matrix, such as the 3×3 matrix in the top right of <<basic_conv>>.\\n\\n'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUaVQQD9jwe3"
   },
   "source": [
    "### Retrieval Method: Full Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2AHQ6JU0VMj",
    "outputId": "af2da950-e989-4a3a-f7aa-2036de7e493b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: True\n",
      "Chapter 2: True\n",
      "Chapter 4: True\n",
      "Chapter 8: True\n",
      "Chapter 9: True\n",
      "Chapter 10: True\n",
      "Chapter 13: True\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"bm25\",\n",
    "    chunking_strategy=\"E\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results,\n",
    "    questions=questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NGIhxRq80c7g",
    "outputId": "83446096-6429-453b-a860-31a9cdcdfa82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46, 0.83)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['bm25_E_mrr10'].mean(),2), round(benchmark_results['bm25_E_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRSdfGv9jyqI"
   },
   "source": [
    "### Retrieval Method: Single-Vector Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4pfuBS230grK",
    "outputId": "831fe930-bc8a-4e64-9f5e-b709703860ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Questions...\n",
      "Encoding Data...\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"single_vector\",\n",
    "    chunking_strategy=\"E\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hwM97JV30lTS",
    "outputId": "abadbb46-d641-4003-a353-5da32f447cbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.87)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['single_vector_E_mrr10'].mean(),2), round(benchmark_results['single_vector_E_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2bbueRaj0_p"
   },
   "source": [
    "### Retrieval Method: ColBERTv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwvVp7cS0r_v"
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"colbertv2\",\n",
    "    chunking_strategy=\"E\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jIAvOj30ub7",
    "outputId": "4108adcd-495a-4c42-c56b-5e5dc685cef5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49, 0.81)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['colbertv2_E_mrr10'].mean(),2), round(benchmark_results['colbertv2_E_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXdxNgySj3Rp"
   },
   "source": [
    "### Retrieval Method: answerai-colbert-small-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "165ef1TB0wwU"
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"answerai_colbert\",\n",
    "    chunking_strategy=\"E\",\n",
    "    data=data,\n",
    "    benchmark=benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aw-D6Iw00w4A",
    "outputId": "e723ecd0-7550-488b-a202-2b20b378a599"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.52, 0.84)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['answerai_colbert_E_mrr10'].mean(),2), round(benchmark_results['answerai_colbert_E_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t31fSgVhj6ai"
   },
   "source": [
    "## Chunking Strategy F: (w/headers, w/o HTML tags, w/o punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPS9LGmSHj-S"
   },
   "source": [
    "Finally, I'll keep headers, remove HTML tags and remove all punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "ZH-zyDEK3ALo",
    "outputId": "ce7661e8-c5ee-44f5-950e-d01dd944b7f1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'## The Magic of Convolutions\\n\\nIt turns out that finding the edges in an image is a very common task in computer vision, and is surprisingly straightforward. To do it, we use something called a *convolution*. A convolution requires nothing more than multiplication, and addition—two operations that are responsible for the vast majority of work that we will see in every single deep learning model in this book!\\n\\nA convolution applies a *kernel* across an image. A kernel is a little matrix, such as the 3×3 matrix in the top right of <<basic_conv>>.\\n\\n'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "qXKIxOr63CWX",
    "outputId": "cf3eb589-4d15-4760-82ab-c02317c613a2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'## The Magic of Convolutions\\n\\nIt turns out that finding the edges in an image is a very common task in computer vision  and is surprisingly straightforward  To do it  we use something called a  convolution   A convolution requires nothing more than multiplication  and addition—two operations that are responsible for the vast majority of work that we will see in every single deep learning model in this book \\n\\nA convolution applies a  kernel  across an image  A kernel is a little matrix  such as the 3×3 matrix in the top right of   basic conv   \\n\\n'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "  import string\n",
    "  return ''.join(char if char.isalnum() or char == '#' else ' ' if char in string.punctuation else char for char in text)\n",
    "\n",
    "remove_punctuation(chunks[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "JZkeFUeL3alq"
   },
   "outputs": [],
   "source": [
    "for chapter, chunks in data.items():\n",
    "  data[chapter] = [remove_punctuation(chunk) for chunk in chunks]\n",
    "\n",
    "total_chunks = 0\n",
    "\n",
    "for chapter, chunks in data.items():\n",
    "  total_chunks += len(chunks)\n",
    "\n",
    "assert total_chunks == 713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "GnkWFXbM3oWk",
    "outputId": "421a9221-8070-419a-e330-f5382c9dee54"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'## The Magic of Convolutions\\n\\nIt turns out that finding the edges in an image is a very common task in computer vision  and is surprisingly straightforward  To do it  we use something called a  convolution   A convolution requires nothing more than multiplication  and addition—two operations that are responsible for the vast majority of work that we will see in every single deep learning model in this book \\n\\nA convolution applies a  kernel  across an image  A kernel is a little matrix  such as the 3×3 matrix in the top right of   basic conv   \\n\\n'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UKxxvMZ6ZdA"
   },
   "source": [
    "Since I'm removing punctuation from the contexts, I need to do the same for the benchmark dataset. I think a better solution would be to modify the scoring functions by removing the punctuation there, but I'm saving some time and space by just copying the benchmark dataset and removing punctuation from each context string in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "4XOTQOKh7rcW"
   },
   "outputs": [],
   "source": [
    "def process_contexts(data):\n",
    "    # Process questions\n",
    "    for question in data['questions']:\n",
    "        # Process only answer_context\n",
    "        if 'answer_context' in question:\n",
    "            for context_item in question['answer_context']:\n",
    "                if 'context' in context_item:\n",
    "                    if isinstance(context_item['context'], list):\n",
    "                        # If context is a list, process each string in the list\n",
    "                        context_item['context'] = [\n",
    "                            remove_punctuation(text) if text else text\n",
    "                            for text in context_item['context']\n",
    "                        ]\n",
    "                    elif isinstance(context_item['context'], str):\n",
    "                        # If context is a single string, process it directly\n",
    "                        context_item['context'] = remove_punctuation(context_item['context'])\n",
    "\n",
    "    return data\n",
    "\n",
    "modified_benchmark = process_contexts(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2jHD_tw8pXF",
    "outputId": "7d2c1a5b-5162-481f-eb62-b5a1789e29f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An MIT professor named Marvin Minsky  who was a grade behind Rosenblatt at the same high school    along with Seymour Papert  wrote a book called  Perceptrons   MIT Press   about Rosenblatt s invention  They showed that a single layer of these devices was unable to learn some simple but critical mathematical functions  such as XOR   In the same book  they also showed that using multiple layers of the devices would allow these limitations to be addressed  Unfortunately  only the first of these insights was widely recognized  As a result  the global academic community nearly entirely gave up on neural networks for the next two decades ']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_benchmark['questions'][4]['answer_context'][0]['context']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-r2p6ilqj9EU"
   },
   "source": [
    "### Retrieval Method: Full Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvj0Gqst3qTl",
    "outputId": "13b24ca1-582e-416d-bbbf-eafaf4e4732f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: True\n",
      "Chapter 2: True\n",
      "Chapter 4: True\n",
      "Chapter 8: True\n",
      "Chapter 9: True\n",
      "Chapter 10: True\n",
      "Chapter 13: True\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"bm25\",\n",
    "    chunking_strategy=\"F\",\n",
    "    data=data,\n",
    "    benchmark=modified_benchmark,\n",
    "    benchmark_results=benchmark_results,\n",
    "    questions=questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YRGy2ES3qX5",
    "outputId": "4f94af84-57fa-4326-ddf9-c65f4c6d1251"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46, 0.83)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['bm25_F_mrr10'].mean(),2), round(benchmark_results['bm25_F_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsdFm_Tsj_B2"
   },
   "source": [
    "### Retrieval Method: Single-Vector Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPyuDxwY3q6V",
    "outputId": "ec40a8af-9cc9-4051-c89c-760d8e374fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Questions...\n",
      "Encoding Data...\n",
      "Retrieving passages...\n",
      "Retrieval complete.\n"
     ]
    }
   ],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"single_vector\",\n",
    "    chunking_strategy=\"F\",\n",
    "    data=data,\n",
    "    benchmark=modified_benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrV6RCrg3q9k",
    "outputId": "15ad5b99-d7b2-4560-b4ae-2be1280375a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49, 0.86)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['single_vector_F_mrr10'].mean(),2), round(benchmark_results['single_vector_F_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PbqUmBUkBhs"
   },
   "source": [
    "### Retrieval Method: ColBERTv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtETh0EN3tAF"
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"colbertv2\",\n",
    "    chunking_strategy=\"F\",\n",
    "    data=data,\n",
    "    benchmark=modified_benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0I9I3S2i3tII",
    "outputId": "2a96fd76-8b57-486d-947b-e049cb8be797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.44, 0.71)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['colbertv2_F_mrr10'].mean(),2), round(benchmark_results['colbertv2_F_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOVydAhEkDHx"
   },
   "source": [
    "### Retrieval Method: answerai-colbert-small-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDBjuE363tnm"
   },
   "outputs": [],
   "source": [
    "benchmark_results = do_retrieval(\n",
    "    method=\"answerai_colbert\",\n",
    "    chunking_strategy=\"F\",\n",
    "    data=data,\n",
    "    benchmark=modified_benchmark,\n",
    "    benchmark_results=benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-q2OiSu3tt0",
    "outputId": "f72ca3d9-cfda-43ec-8548-14c4d124db5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45, 0.73)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(benchmark_results['answerai_colbert_F_mrr10'].mean(),2), round(benchmark_results['answerai_colbert_F_recall10'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEEleG30Ihkz"
   },
   "source": [
    "## Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsfMPbp3HqnL"
   },
   "source": [
    "Here are the definitions of the metrics, retrieval methods and chunking strategies that I am using in this benchmark evaluation:\n",
    "\n",
    "\n",
    "**Metrics**\n",
    "\n",
    "- Answer Component MRR@10: Returns the rank of the n-th passage needed to satisfy all `answer_component`s for the question. So, if a question has 4 `answer_component`s and their relevant contexts were contained across the first 5 retrieved passages, MRR would be 1/5 = 0.2.\n",
    "\n",
    "- Answer Component Recall@10: Measures the proportion of answer components for which at least one supporting context was retrieved. Using the same example, if the top-10 passages only contain contexts relevant to 2 `answer_component`s, Recall would be 2/4 = 0.5\n",
    "\n",
    "**Retrieval Methods**\n",
    "\n",
    "- Full text search (using sqlite and Claude-generated keywords)\n",
    "- Single-vector cosine similarity (using BAAI/bge-small-en-v1.5)\n",
    "- ColBERTv2\n",
    "- answerai-colbert-small-v1\n",
    "\n",
    "**Chunking Strategies**\n",
    "\n",
    "|Chunking Strategy Name|Description|\n",
    "|:-:|:-:|\n",
    "|A|1-paragraph (w/headers)\n",
    "|B|3-paragraph (w/headers)\n",
    "|C|1-paragraph (w/o headers)\n",
    "|D|3-paragraph (w/o headers)\n",
    "|E|3-paragraph (w/headers, w/o HTML tags)\n",
    "|F|3-paragraph (w/headers, w/o HTML tags, w/o punctuation)\n",
    "\n",
    "\n",
    "Here are the results from this notebook:\n",
    "\n",
    "**Answer Component MRR@10**\n",
    "\n",
    "| Retrieval Method | A | B | C | D | E | F |\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|Full text search|0.30|0.46|0.29|0.44|0.46|0.46|\n",
    "|Single-vector cosine similiarity|0.38|0.50|0.35|0.46|0.50|0.49|\n",
    "|ColBERTv2|0.46|0.49|0.41|0.50|0.49|0.44|\n",
    "|answerai-colbert-small-v1|0.48|0.52|0.45|0.52|0.52|0.45|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVKbE87yIX7W"
   },
   "source": [
    "**Answer Component Recall@10**\n",
    "\n",
    "| Retrieval Method | A | B | C | D | E | F |\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "| Full text search | 65% | 83% | 65% | 82% | 83% | 83% |\n",
    "| Single-vector cosine similiarity | 71% | 85% | 72% | 82% | 87% | 86% |\n",
    "| ColBERTv2 | 80% | 80% | 74% | 80% | 81% | 71% |\n",
    "| answerai-colbert-small-v1 | 82% | 84% | 77% | 82% | 84% | 73% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_nSXDOTIi_M"
   },
   "source": [
    "The best-performing retrieval method and chunking strategies:\n",
    "\n",
    "|Metric Name|Retrieval Method|Chunking Strategies|Metric Value|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|Answer Component MRR@10|answerai-colbert-small-v1|B, D, E|0.52\n",
    "|Answer Component Recall@10|Single-vector cosine similiarty|E|87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was quite surprised that single-vector cosine similarity yielded the best Recall. I was less surprised that answerai-colbert-small-v1 had the best MRR@10 since it was better than the other retrieval methods for 5 out of 6 chunking strategies. Other noteworthy observations:\n",
    "\n",
    "- ColBERTv2 and answerai-colbert-small-v1 both experienced a considerable performance drop when punctuation was removed from the documents.\n",
    "- Full text search was very competitive after the chunk size was increased to 3-paragraphs (B, D, E, F). It yielded the second-highest MRR@10 for Chunking Strategy F (3-paragraph, w/headers, w/o HTMl tags, w/o punctuation).\n",
    "- Removing HTML tags (Chunking Strategy E) improved the performance of all four retrieval methods than when they were included (Chunking Strategy D). The biggest beneficiary of removing them was single-vector cosine similarity (82% --> 87%).\n",
    "\n",
    "A couple of notes about my process:\n",
    "\n",
    "- Having a benchmark dataset saved me about 15-20 hours of manual evaluation.\n",
    "- Refactoring the code (into a `do_retrieval` function) made it easier for me to iterate quickly different chunking strategies.\n",
    "\n",
    "Before I move on to experimenting with hybrid approaches (full text search + semantic search) I want to research and apply chunking strategies that are particularly suited to ColBERTv2 and answerai-colbert-small-v1 to see if I can improve on the overall-best Recall@10 of 87% and MRR@10 of 0.52."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
