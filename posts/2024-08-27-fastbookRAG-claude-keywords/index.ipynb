{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: Iterating on Full Text Search Keywords using `claudette`\n",
        "date: \"2024-08-27\"\n",
        "author: Vishal Bakshi\n",
        "description: In this blog post, I use Answer.AI's `claudette` library to iteratively improve keywords generated for sqlite's full text search.\n",
        "filters:\n",
        "   - lightbox\n",
        "lightbox: auto\n",
        "categories:\n",
        "    - python\n",
        "    - RAG\n",
        "    - information retrieval\n",
        "    - LLM\n",
        "    - fastbookRAG\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaSHjzDoOa2b"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsTYe-E6Ochz"
      },
      "source": [
        "In a [previous blog post](https://vishalbakshi.github.io/blog/posts/2024-08-25-fastbookRAG-claude-keywords/) I used Claude (with the help of the Answer.AI `claudette` library) to generate keywords for 220 questions across the 7 Chapter Questionnaires covered in Part 1 of the fastai course. Using those keywords I retrieved context from fastbook that allowed me to answer 33% (10/30 questions) of the Chapter 1 Questionnaire. In [another blog post](https://vishalbakshi.github.io/blog/posts/2024-08-04-fastbook-ch1-fts5/) I manually came up with keywords and achieved a 40% answer rate.\n",
        "\n",
        "In this notebook I'll see if I can improve the quality of information retrieval by improving the keywords that Claude generates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo1gvwCadKkc"
      },
      "source": [
        ":::{.callout-important}\n",
        "Full text search uses corpus-wide statistics so I've made sure to load the entire corpus (7 chapter notebooks) into the database which matches my final production environment. Otherwise the same keywords with FTS5 may retrieve different top-1 BM25-ranked contexts.\n",
        ":::"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFb2N4tkPhPw"
      },
      "source": [
        "This notebook is part [a series of blog posts](https://vishalbakshi.github.io/blog/index.html#category=fastbookRAG) for a project I'm working on called **fastbookRAG** in which I'm building a hybrid search + LLM pipeline to answer questions from the end-of-chapter Questionnaires in the freely available [fastai textbook](https://github.com/fastai/fastbook/tree/master)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here are the results from this notebook. **Answer Rate** is the percentage of Chapter 1 Questionnaire questions answered using context retrieved from SQLite full-text search with Claude-generated keywords.\n",
        "\n",
        "|Prompt|Answer Rate|\n",
        "|:-:|:-:|\n",
        "|[A](#prompt-a)|33%\n",
        "|[B](#prompt-b)|33%\n",
        "|[C](#prompt-c)|36%\n",
        "|[D](#prompt-d)|33%\n",
        "|[E](#prompt-e)|**40%**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uho5pJVREdb"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtCJV3b8RFy8"
      },
      "source": [
        "This section defines helper functions needed to chunk, load and retrieve the Chapter 1 notebook from a sqlite database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Tok-sEKeOXEl"
      },
      "outputs": [],
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show imports\"\n",
        "!pip install claudette -qq\n",
        "import sqlite3\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import pandas as pd, numpy as np\n",
        "from claudette import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NXWfTaQemU_p",
        "outputId": "3179f1b6-24b5-4f8d-efa3-788c5bffe91b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'claude-3-5-sonnet-20240620'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = models[1]\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "TsE9tnQIRf3o"
      },
      "outputs": [],
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show chunking code\"\n",
        "def get_chunks(notebook_path):\n",
        "    with open(notebook_path, 'r', encoding='utf-8') as file:\n",
        "        notebook = json.load(file)\n",
        "\n",
        "    chunks = []\n",
        "    current_header = \"\"\n",
        "\n",
        "    def add_chunk(content):\n",
        "        if content.strip():\n",
        "            chunks.append(f\"{current_header}\\n\\n{content.strip()}\")\n",
        "\n",
        "    for cell in notebook['cells']:\n",
        "        if cell['cell_type'] == 'markdown':\n",
        "            content = ''.join(cell['source'])\n",
        "            header_match = re.match(r'^(#+\\s+.*?)$', content, re.MULTILINE)\n",
        "            if header_match:  # Check if the cell starts with a header\n",
        "                current_header = header_match.group(1)\n",
        "                # Add any content after the header in the same cell\n",
        "                remaining_content = content[len(current_header):].strip()\n",
        "                if remaining_content:\n",
        "                    paragraphs = re.split(r'\\n\\s*\\n', remaining_content)\n",
        "                    for paragraph in paragraphs:\n",
        "                        add_chunk(paragraph)\n",
        "            else:\n",
        "                paragraphs = re.split(r'\\n\\s*\\n', content)\n",
        "                for paragraph in paragraphs:\n",
        "                    add_chunk(paragraph)\n",
        "        elif cell['cell_type'] == 'code':\n",
        "          code_content = '```python\\n' + ''.join(cell['source']) + '\\n```'\n",
        "\n",
        "          # Include the output of the code cell\n",
        "          output_content = ''\n",
        "          if 'outputs' in cell and cell['outputs']:\n",
        "              for output in cell['outputs']:\n",
        "                  if 'text' in output:\n",
        "                      output_content += ''.join(output['text'])\n",
        "                  elif 'data' in output and 'text/plain' in output['data']:\n",
        "                      output_content += ''.join(output['data']['text/plain'])\n",
        "\n",
        "          # Combine code and output in the same chunk\n",
        "          combined_content = code_content + '\\n\\nOutput:\\n' + output_content if output_content else code_content\n",
        "          add_chunk(combined_content)\n",
        "\n",
        "    def filter_chunks(chunks, exclude_headers=[\"Questionnaire\", \"Further Research\"]):\n",
        "      filtered_chunks = []\n",
        "      for chunk in chunks:\n",
        "          lines = chunk.split('\\n')\n",
        "          # Check if the first line (header) is in the exclude list\n",
        "          if not any(header in lines[0] for header in exclude_headers):\n",
        "              filtered_chunks.append(chunk)\n",
        "      return filtered_chunks\n",
        "\n",
        "    return filter_chunks(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "NRwKesL-Rit4"
      },
      "outputs": [],
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the `load_data` function\"\n",
        "def load_data(chunks, db_path, chapter=1):\n",
        "    try:\n",
        "        # Create virtual table if database doesn't exist\n",
        "        if not os.path.exists(db_path):\n",
        "            with sqlite3.connect(db_path) as conn:\n",
        "              cur = conn.cursor()\n",
        "              cur.execute(\"\"\"\n",
        "              CREATE VIRTUAL TABLE fastbook_text\n",
        "              USING FTS5(chapter, text);\n",
        "              \"\"\")\n",
        "              conn.commit()\n",
        "\n",
        "        # Load in the chunks for each chapter\n",
        "        with sqlite3.connect(db_path) as conn:\n",
        "            cur = conn.cursor()\n",
        "\n",
        "            for chunk in chunks:\n",
        "                cur.execute(\"INSERT INTO fastbook_text(chapter, text) VALUES (?, ?)\", (chapter, chunk))\n",
        "\n",
        "            conn.commit()\n",
        "            res = cur.execute(\"SELECT * FROM fastbook_text WHERE chapter = ?\", (chapter,)).fetchall()\n",
        "\n",
        "        if len(res) != len(chunks):\n",
        "            raise ValueError(f\"Number of inserted chunks ({len(res)}) doesn't match input chunks ({len(chunks)})\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "h6W63OEjRjHB"
      },
      "outputs": [],
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the `load_data` function\"\n",
        "def load_data(chunks, db_path, chapter=1):\n",
        "    try:\n",
        "        # Create virtual table if database doesn't exist\n",
        "        if not os.path.exists(db_path):\n",
        "            with sqlite3.connect(db_path) as conn:\n",
        "              cur = conn.cursor()\n",
        "              cur.execute(\"\"\"\n",
        "              CREATE VIRTUAL TABLE fastbook_text\n",
        "              USING FTS5(chapter, text);\n",
        "              \"\"\")\n",
        "              conn.commit()\n",
        "\n",
        "        # Load in the chunks for each chapter\n",
        "        with sqlite3.connect(db_path) as conn:\n",
        "            cur = conn.cursor()\n",
        "\n",
        "            for chunk in chunks:\n",
        "                cur.execute(\"INSERT INTO fastbook_text(chapter, text) VALUES (?, ?)\", (chapter, chunk))\n",
        "\n",
        "            conn.commit()\n",
        "            res = cur.execute(\"SELECT * FROM fastbook_text WHERE chapter = ?\", (chapter,)).fetchall()\n",
        "\n",
        "        if len(res) != len(chunks):\n",
        "            raise ValueError(f\"Number of inserted chunks ({len(res)}) doesn't match input chunks ({len(chunks)})\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except sqlite3.Error as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "RYtUhMVqSbif"
      },
      "outputs": [],
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the `db_search` function\"\n",
        "def db_search(df, limit=1):\n",
        "  results = []\n",
        "  with sqlite3.connect('fastbook.db') as conn:\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "      keywords = ' OR '.join([f'\"{keyword.strip(\",\")}\"' for keyword in row['keywords'].replace('\"', '').split()])\n",
        "\n",
        "      q = f\"\"\"\n",
        "        SELECT text, rank\n",
        "        FROM fastbook_text\n",
        "        WHERE fastbook_text MATCH ?\n",
        "        AND chapter = ?\n",
        "        ORDER BY rank\n",
        "        LIMIT ?\n",
        "        \"\"\"\n",
        "      res = cur.execute(q, (keywords, str(row['chapter']), limit)).fetchall()\n",
        "      res = [item[0] for item in res]\n",
        "      results.extend(res)\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BG5f9vnfN-f"
      },
      "source": [
        "During this notebook I learned the implications of full text search using corpus-wide statistics. I wanted to test out Claude keywords for chapter 1 search and only loaded in chapter 1 into the database. This retrieved different contexts for the same keywords than when I used FTS with all 7 chapters loaded in the database. In order to improve the keywords, I need to make sure the corpus is the same as the final \"production\" environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Comparison of retrieved chunks using the same keywords on different databases](1.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "sTBIrkQxfoKq"
      },
      "outputs": [],
      "source": [
        "#| code-fold: true\n",
        "#| code-summary: \"Show the dict w/ notebook filenames\"\n",
        "\n",
        "nbs = {\n",
        "    '1': '01_intro.ipynb',\n",
        "    '2': '02_production.ipynb',\n",
        "    '4': '04_mnist_basics.ipynb',\n",
        "    '8': '08_collab.ipynb',\n",
        "    '9': '09_tabular.ipynb',\n",
        "    '10': '10_nlp.ipynb',\n",
        "    '13': '13_convolutions.ipynb'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "5lANRX35Rkri"
      },
      "outputs": [],
      "source": [
        "# chunkify all notebooks\n",
        "# chunking each notebook\n",
        "data = {}\n",
        "\n",
        "for chapter, nb in nbs.items():\n",
        "  data[chapter] = get_chunks(nb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g29TEv60gDEm",
        "outputId": "44bb45b2-c568-4371-d918-707317e70a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 307\n",
            "2 227\n",
            "4 433\n",
            "8 157\n",
            "9 387\n",
            "10 190\n",
            "13 266\n"
          ]
        }
      ],
      "source": [
        "for chapter, chunks in data.items():\n",
        "  print(chapter, len(chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdw6eGBcRu_w",
        "outputId": "4ac07efa-53a1-40b8-ae69-daad5456f6a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chapter 1: True\n",
            "Chapter 2: True\n",
            "Chapter 4: True\n",
            "Chapter 8: True\n",
            "Chapter 9: True\n",
            "Chapter 10: True\n",
            "Chapter 13: True\n"
          ]
        }
      ],
      "source": [
        "# load chunks into the database\n",
        "for chapter, chunks in data.items():\n",
        "  print(f\"Chapter {chapter}:\", load_data(chunks, 'fastbook.db', chapter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0az0whLZR2vy",
        "outputId": "c2b07fe9-0b9c-4dfe-9e3a-e65e4309e4ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, 6)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the questions and keywords\n",
        "url = 'https://gist.githubusercontent.com/vishalbakshi/309fb3abb222d32446b2c4e29db753fe/raw/5e41b9eb34f515f00321e55307cc4d5abbd75cb5/fastbookRAG_evals.csv'\n",
        "questions = pd.read_csv(url).query('chapter == 1 and is_answerable == 1')\n",
        "questions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_3t2J02R9tz",
        "outputId": "194409c3-0b06-4cf9-db07-6ea5cb9aae7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# retrieve Top-1 chunk by BM25\n",
        "results = db_search(questions, limit=1)\n",
        "len(results) == 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "atqeVqq9Tx3b"
      },
      "outputs": [],
      "source": [
        "# export results\n",
        "questions['context'] = results\n",
        "questions.to_csv('bm25_a_keywordsA.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u80BC5yhLWH"
      },
      "source": [
        "## Generating Keywords with Claude Using Different Prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prompt A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9A74y7xgrg8"
      },
      "source": [
        "The keywords generated using the following prompt retrieved context that allowed me to answer **10/30 (33%)** of the Chapter 1 Questionnaire questions:\n",
        "\n",
        "\n",
        "> I am working on a keyword search project and i need to create 3-6 keywords for each `question_text` that I provide you.\n",
        "Do not generate keywords that stray too far in meaning from the `question_text`. Only respond with the comma-separated list of keywords surrounded by double quotes.\n",
        ">  \n",
        "> No yapping.\n",
        ">  \n",
        "> Examples:\n",
        ">  \n",
        "> question_text: Name five areas where deep learning is now the best in the world\n",
        ">\n",
        "> keywords: \"deep learning, state of the art, best, world\"\n",
        ">\n",
        "> question_text: Why is it hard to use a traditional computer program to recognize images in a photo?\n",
        ">  \n",
        "> keywords: \"image, recognize, recognition, traditional, computer, program\"\n",
        ">\n",
        "> question_text: What were the two theoretical misunderstandings that held back the field of neural networks?\n",
        ">\n",
        "> keywords: \"theoretical, misunderstandings, held, back, field, neural network\"\n",
        ">\n",
        "> question_text: Why is it hard to understand why a deep learning model makes a particular prediction?\n",
        ">\n",
        "> keywords:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuYumZCiAkp3"
      },
      "source": [
        "### Prompt B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rplddQBnmwns"
      },
      "source": [
        "I'll start by creating a prompt that was recommended by Claude:\n",
        "\n",
        "> For the following question text, please generate 3-6 comma-separated keywords that capture the main concepts and are suitable for use in a SQLite full-text search query. The keywords should be concise, relevant, and help in retrieving appropriate text chunks from a database. Avoid using articles, prepositions, or other common words that don't add significant meaning. Here's the question text:\n",
        ">\n",
        ">{question_text}\n",
        ">\n",
        ">Please provide the keywords in the following format:\n",
        "keywords: \"keyword1, keyword2, keyword3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "Jv7isaFOZtBn"
      },
      "outputs": [],
      "source": [
        "promptB = \"\"\"For the following question text, please generate 3-6 comma-separated keywords that capture the main concepts and are suitable for use in a SQLite full-text search query. The keywords should be concise, relevant, and help in retrieving appropriate text chunks from a database. Avoid using articles, prepositions, or other common words that don't add significant meaning. Here's the question text:\n",
        "\n",
        "{question_text}\n",
        "\n",
        "Please provide the keywords in the following format:\n",
        "keywords: \"keyword1, keyword2, keyword3\" \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7HauD2bn1Q8",
        "outputId": "0d806f49-904f-44ae-8860-0f0acba65921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the following question text, please generate 3-6 comma-separated keywords that capture the main concepts and are suitable for use in a SQLite full-text search query. The keywords should be concise, relevant, and help in retrieving appropriate text chunks from a database. Avoid using articles, prepositions, or other common words that don't add significant meaning. Here's the question text:\n",
            "\n",
            "Why is it hard to understand why a deep learning model makes a particular prediction?\n",
            "\n",
            "Please provide the keywords in the following format:\n",
            "keywords: \"keyword1, keyword2, keyword3\" \n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = promptB.format(question_text=\"Why is it hard to understand why a deep learning model makes a particular prediction?\")\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5VHkiPqn8-G",
        "outputId": "52a4607c-f911-48ed-b1d4-93a99fd0742c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "In: 0; Out: 0; Total: 0"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "chat.use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "vcOFvp6Xn1er",
        "outputId": "13b67444-3a1f-4521-c061-e603221a3881"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "keywords: \"deep learning, model, prediction, understanding, interpretability\"\n",
              "\n",
              "<details>\n",
              "\n",
              "- id: `msg_01FTbVhR4dwjNqoDmEmBexS1`\n",
              "- content: `[{'text': 'keywords: \"deep learning, model, prediction, understanding, interpretability\"', 'type': 'text'}]`\n",
              "- model: `claude-3-5-sonnet-20240620`\n",
              "- role: `assistant`\n",
              "- stop_reason: `end_turn`\n",
              "- stop_sequence: `None`\n",
              "- type: `message`\n",
              "- usage: `{'input_tokens': 141, 'output_tokens': 18, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
              "\n",
              "</details>"
            ],
            "text/plain": [
              "Message(id='msg_01FTbVhR4dwjNqoDmEmBexS1', content=[TextBlock(text='keywords: \"deep learning, model, prediction, understanding, interpretability\"', type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 141; Out: 18; Total: 159)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r = chat(formatted_prompt)\n",
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BmvTBljoV0Z"
      },
      "source": [
        "Looks good! I'll now use this prompt to generate keywords for all 30 Chapter 1 Questionnaire questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "yGamDgnGn-MU"
      },
      "outputs": [],
      "source": [
        "keyword_results = []\n",
        "tokens = 0\n",
        "for row in questions['question_text']:\n",
        "  chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "  formatted_prompt = promptB.format(question_text=row[2:-2])\n",
        "  r = chat(formatted_prompt)\n",
        "  keyword_results.append(r.content[0].text)\n",
        "  tokens += chat.use.total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DokvZqrg8G0T"
      },
      "source": [
        "That was about 2 cents of tokens used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNRLLhNc7OVc",
        "outputId": "74caa44c-021b-4d74-c3e9-b34d19c87ba4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, 4736)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(keyword_results), tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DllDf1CZ8Lv-",
        "outputId": "68a9aae4-4873-4e4a-b73f-62ec4ea0a209"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['keywords: \"deep learning, math, data, expensive computers, PhD\"',\n",
              " 'keywords: \"deep learning, best, areas, applications, achievements\"',\n",
              " 'keywords: \"device, artificial neuron, first\"',\n",
              " 'keywords: \"parallel distributed processing, PDP, book, requirements\"',\n",
              " 'keywords: \"theoretical misunderstandings, neural networks, field setbacks\"']"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_results[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFGda1Uh8SNS"
      },
      "source": [
        "Unfortunately I missed the fact that Claude includes 'keywords' in each respone---oops! I'll have to do some quick cleanup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLj479Ov8CJL",
        "outputId": "554b2d58-87e8-4605-cd93-140779494d6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"deep learning, math, data, expensive computers, PhD\"',\n",
              " '\"deep learning, best, areas, applications, achievements\"',\n",
              " '\"device, artificial neuron, first\"',\n",
              " '\"parallel distributed processing, PDP, book, requirements\"',\n",
              " '\"theoretical misunderstandings, neural networks, field setbacks\"']"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_keywords = [s.replace('keywords: ', '') for s in keyword_results]\n",
        "cleaned_keywords[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up-hw6pD9OW-"
      },
      "source": [
        "I'll replace the existing keywords and run the full text search again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Zw0-yG4d8KJo",
        "outputId": "6fc23abb-c3aa-44b2-8a56-c2e0689b444c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"deep learning, math, data, expensive computer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"deep learning, best, areas, applications, ach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"device, artificial neuron, first\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"parallel distributed processing, PDP, book, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"theoretical misunderstandings, neural network...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    \"deep learning, math, data, expensive computer...\n",
              "1    \"deep learning, best, areas, applications, ach...\n",
              "2                   \"device, artificial neuron, first\"\n",
              "3    \"parallel distributed processing, PDP, book, r...\n",
              "4    \"theoretical misunderstandings, neural network...\n",
              "Name: keywords, dtype: object"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions['keywords'] = cleaned_keywords\n",
        "questions['keywords'].iloc[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R-ijulU9WbL",
        "outputId": "a7005387-dcd2-4638-b39f-5dbdded56335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"architecture, design, structure, building, framework\"',\n",
              " '\"segmentation, market, division, targeting, customer groups\"',\n",
              " '\"y_range, purpose, usage, necessity\"',\n",
              " '\"hyperparameters, machine learning, model tuning, optimization\"',\n",
              " '\"avoid failures, AI implementation, organization, best practices\"']"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleaned_keywords[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "-PCBK5qt9b1V",
        "outputId": "2aaafb29-67f4-4eb5-fe18-dec355c26147"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>\"architecture, design, structure, building, fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>\"segmentation, market, division, targeting, cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>\"y_range, purpose, usage, necessity\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>\"hyperparameters, machine learning, model tuni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>\"avoid failures, AI implementation, organizati...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "28    \"architecture, design, structure, building, fr...\n",
              "29    \"segmentation, market, division, targeting, cu...\n",
              "30                 \"y_range, purpose, usage, necessity\"\n",
              "31    \"hyperparameters, machine learning, model tuni...\n",
              "32    \"avoid failures, AI implementation, organizati...\n",
              "Name: keywords, dtype: object"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions['keywords'].iloc[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FWbjNTn9dnF",
        "outputId": "0c7fd03d-610a-41cd-8a2d-a1cec4d460f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# retrieve Top-1 chunk by BM25\n",
        "results = db_search(questions, limit=1)\n",
        "len(results) == 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "pCZ2gk_r9i-F"
      },
      "outputs": [],
      "source": [
        "# export results\n",
        "questions['context'] = results\n",
        "questions.to_csv('bm25_a_keywordsB.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWtZANnL-xlg"
      },
      "source": [
        "These keywords retrieved chunks that allowed me to answer 10/30 or 33% of the Chapter 1 Questionnaire. This was a different set of 10 questions that Prompt A."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyn1rek6AnXG"
      },
      "source": [
        "### Prompt C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-153ZWmUAolX"
      },
      "source": [
        "After looking at the data, I'll modify the prompt to provide some more flexibility in the keyword search by requesting Claude to do two things:\n",
        "\n",
        "- use single-word keywords when possible\n",
        "- include singular and plural versions of nouns when applicable\n",
        "- remove the `keywords:` string before the example keywords\n",
        "\n",
        "Here's the new prompt:\n",
        "\n",
        "> For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords when possible. Include both singular and plural forms for nouns if relevant. Avoid articles, prepositions, and common words. Use this format:\n",
        ">\n",
        ">{question_text}\n",
        ">\n",
        ">\"keyword1, keyword2, keyword3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "5sZz-DbW-8NN"
      },
      "outputs": [],
      "source": [
        "promptC = \"\"\"\"For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords when possible. Include both singular and plural forms for nouns if relevant. Avoid articles, prepositions, and common words. Use this format:\n",
        "\n",
        "{question_text}\n",
        "\n",
        "\"keyword1, keyword2, keyword3\" \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acyP7z5kBEgx",
        "outputId": "19435b53-e75d-40a0-8cc0-e265ae502fb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords when possible. Include both singular and plural forms for nouns if relevant. Avoid articles, prepositions, and common words. Use this format:\n",
            "\n",
            "Why is it hard to understand why a deep learning model makes a particular prediction?\n",
            "\n",
            "\"keyword1, keyword2, keyword3\" \n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = promptC.format(question_text=\"Why is it hard to understand why a deep learning model makes a particular prediction?\")\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "rp6l54H3BIC4",
        "outputId": "e0fd396b-c550-4a7b-c909-5aa84c0245e7"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\"deep learning, model, models, prediction, predictions, understand, understanding\"\n",
              "\n",
              "<details>\n",
              "\n",
              "- id: `msg_01HNHpvbABHGxLzxacXLXuv1`\n",
              "- content: `[{'text': '\"deep learning, model, models, prediction, predictions, understand, understanding\"', 'type': 'text'}]`\n",
              "- model: `claude-3-5-sonnet-20240620`\n",
              "- role: `assistant`\n",
              "- stop_reason: `end_turn`\n",
              "- stop_sequence: `None`\n",
              "- type: `message`\n",
              "- usage: `{'input_tokens': 114, 'output_tokens': 19, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
              "\n",
              "</details>"
            ],
            "text/plain": [
              "Message(id='msg_01HNHpvbABHGxLzxacXLXuv1', content=[TextBlock(text='\"deep learning, model, models, prediction, predictions, understand, understanding\"', type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 114; Out: 19; Total: 133)"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "r = chat(formatted_prompt)\n",
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyPy2JAaBXko"
      },
      "source": [
        "Nice! It's following my instructions. I'll run through the process of generating keywords, running full text search, and evaluating the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "VL_uFt_FBWJK"
      },
      "outputs": [],
      "source": [
        "keyword_results = []\n",
        "tokens = 0\n",
        "for row in questions['question_text']:\n",
        "  chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "  formatted_prompt = promptC.format(question_text=row[2:-2])\n",
        "  r = chat(formatted_prompt)\n",
        "  keyword_results.append(r.content[0].text)\n",
        "  tokens += chat.use.total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOypk0OOBlv7",
        "outputId": "18718a8f-2d27-4c12-aa05-ee248f7431c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, 3884)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(keyword_results), tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5siIdLZ6DXpe",
        "outputId": "9cfa92ed-47f5-4e9b-fc23-588309ce2b62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"deep learning, math, data, computers, expensive, PhD\"',\n",
              " '\"deep learning, areas, best, world, artificial intelligence, neural networks\"',\n",
              " '\"neuron, neurons, device, artificial, first\"',\n",
              " '\"parallel, distributed, processing, PDP, requirements, book\"',\n",
              " '\"neural, networks, theoretical, misunderstandings, field\"']"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_results[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "40E_QucBDeO_",
        "outputId": "8d9ea165-8f90-4550-b3ab-4ab3e643ad72"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"deep learning, math, data, computers, expensi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"deep learning, areas, best, world, artificial...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"neuron, neurons, device, artificial, first\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"parallel, distributed, processing, PDP, requi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"neural, networks, theoretical, misunderstandi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    \"deep learning, math, data, computers, expensi...\n",
              "1    \"deep learning, areas, best, world, artificial...\n",
              "2         \"neuron, neurons, device, artificial, first\"\n",
              "3    \"parallel, distributed, processing, PDP, requi...\n",
              "4    \"neural, networks, theoretical, misunderstandi...\n",
              "Name: keywords, dtype: object"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions['keywords'] = keyword_results\n",
        "questions['keywords'].iloc[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNk1c1-6DsWo",
        "outputId": "15f46802-9f99-4e93-d80f-9943fcd3214b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# retrieve Top-1 chunk by BM25\n",
        "results = db_search(questions, limit=1)\n",
        "len(results) == 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "q6SH-BS_Dzv6"
      },
      "outputs": [],
      "source": [
        "# export results\n",
        "questions['context'] = results\n",
        "questions.to_csv('bm25_a_keywordsC.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vduATiQPHNx8"
      },
      "source": [
        "The retrieved context allowed me to answer **11/30 or 36%** of the questions. Moving in the right direction! One of the set of keywords had some additional text and that would have likely increased the answer rate to 12/30:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qqCL3Hj7HP9e",
        "outputId": "8e672a42-3e04-40b0-d797-b97bf5731924"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Here are the keywords for the given question:\\n\\n\"hyperparameters, hyperparameter, parameter, parameters, machine learning, tuning\"'"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_results[-2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7Fi9AboHvjG"
      },
      "source": [
        "I'll also ask it to include any numbers it finds in the question text as separate keywords, as that might have gotten me another correct answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "Rfnp1YW9H1DP",
        "outputId": "59b67c50-a9b0-45ad-b697-d67ddd114cb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>17</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>chapter</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_number</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question_text</th>\n",
              "      <td>\"\"Do we always have to use 224×224-pixel image...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer</th>\n",
              "      <td>\"\"No we do not. 224x224 is commonly used for h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_answerable</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keywords</th>\n",
              "      <td>\"cat, cats, recognition, model, image, images,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>context</th>\n",
              "      <td>### How Our Image Recognizer Works\\n\\nIn the t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "chapter                                                            1\n",
              "question_number                                                   18\n",
              "question_text      \"\"Do we always have to use 224×224-pixel image...\n",
              "answer             \"\"No we do not. 224x224 is commonly used for h...\n",
              "is_answerable                                                      1\n",
              "keywords           \"cat, cats, recognition, model, image, images,...\n",
              "context            ### How Our Image Recognizer Works\\n\\nIn the t...\n",
              "Name: 17, dtype: object"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions.iloc[14]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKXutCGRHeGT"
      },
      "source": [
        "### Prompt D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mLQfO7eHgSO"
      },
      "source": [
        "I'll update the prompt with the following observations:\n",
        "\n",
        "- remind Claude \"no yapping\" so it doesn't include additional explanatory text other than the keywords.\n",
        "- ask Claude to include any numbers in the question as a keyword."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "517F-B5DIdp1"
      },
      "source": [
        "Here's the new prompt:\n",
        "\n",
        "> For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords when possible. Include both singular and plural forms for nouns if relevant. Include any numbers as keywords. Avoid articles, prepositions, and common words. Use this format. No yapping:\n",
        ">\n",
        ">{question_text}\n",
        ">\n",
        " >\"keyword1, keyword2, keyword3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "fxHEPsTsHQmO"
      },
      "outputs": [],
      "source": [
        "promptD = \"\"\"For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords when possible. Include both singular and plural forms for nouns if relevant. Include any numbers as keywords. Avoid articles, prepositions, and common words. Use this format. No yapping:\n",
        "\n",
        "{question_text}\n",
        "\n",
        "\"keyword1, keyword2, keyword3\" \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3DLJ4POIwYq",
        "outputId": "75cfd03c-8d50-4527-f267-38db55df5795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords when possible. Include both singular and plural forms for nouns if relevant. Include any numbers as keywords. Avoid articles, prepositions, and common words. Use this format. No yapping:\n",
            "\n",
            "Why is it hard to understand why a deep learning model makes a particular prediction?\n",
            "\n",
            "\"keyword1, keyword2, keyword3\" \n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = promptD.format(question_text=\"Why is it hard to understand why a deep learning model makes a particular prediction?\")\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "QdcV6QQBI0Vp",
        "outputId": "411f466b-7d08-45d5-ef15-ccebdc965243"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\"deep, learning, model, prediction, understand, hard\"\n",
              "\n",
              "<details>\n",
              "\n",
              "- id: `msg_01QtPrjfRGNPmt8eLxDxZcZE`\n",
              "- content: `[{'text': '\"deep, learning, model, prediction, understand, hard\"', 'type': 'text'}]`\n",
              "- model: `claude-3-5-sonnet-20240620`\n",
              "- role: `assistant`\n",
              "- stop_reason: `end_turn`\n",
              "- stop_sequence: `None`\n",
              "- type: `message`\n",
              "- usage: `{'input_tokens': 123, 'output_tokens': 16, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
              "\n",
              "</details>"
            ],
            "text/plain": [
              "Message(id='msg_01QtPrjfRGNPmt8eLxDxZcZE', content=[TextBlock(text='\"deep, learning, model, prediction, understand, hard\"', type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 123; Out: 16; Total: 139)"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "r = chat(formatted_prompt)\n",
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLkiCta-JF-7"
      },
      "source": [
        "It's not including plural versions of nouns so I'll remove the \"if relevant\" from the instruction and try again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "5vXYOkS9JMfw"
      },
      "outputs": [],
      "source": [
        "promptD = \"\"\"For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords. Include both singular and plural forms for nouns. Include any numbers as keywords. Avoid articles, prepositions, and common words. No yapping:\n",
        "\n",
        "{question_text}\n",
        "\n",
        "\"keyword1, keyword2, keyword3\" \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Fg163fJUvd",
        "outputId": "a849f63c-8638-49b9-e8d2-ae77fb85dc80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords. Include both singular and plural forms for nouns. Include any numbers as keywords. Avoid articles, prepositions, and common words. No yapping:\n",
            "\n",
            "Why is it hard to understand why a deep learning model makes a particular prediction?\n",
            "\n",
            "\"keyword1, keyword2, keyword3\" \n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = promptD.format(question_text=\"Why is it hard to understand why a deep learning model makes a particular prediction?\")\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "ZmgyI_snJTZ6",
        "outputId": "382cb92b-5205-4354-9bf1-08a8ac17d932"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "deep, learning, model, models, prediction, predictions, understand, understanding\n",
              "\n",
              "<details>\n",
              "\n",
              "- id: `msg_01EQqyCJDRCc81cLL78E8sA7`\n",
              "- content: `[{'text': 'deep, learning, model, models, prediction, predictions, understand, understanding', 'type': 'text'}]`\n",
              "- model: `claude-3-5-sonnet-20240620`\n",
              "- role: `assistant`\n",
              "- stop_reason: `end_turn`\n",
              "- stop_sequence: `None`\n",
              "- type: `message`\n",
              "- usage: `{'input_tokens': 115, 'output_tokens': 18, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
              "\n",
              "</details>"
            ],
            "text/plain": [
              "Message(id='msg_01EQqyCJDRCc81cLL78E8sA7', content=[TextBlock(text='deep, learning, model, models, prediction, predictions, understand, understanding', type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 115; Out: 18; Total: 133)"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "r = chat(formatted_prompt)\n",
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRa-cmPTJZwi"
      },
      "source": [
        "Nice! That fixed it at least for one example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "3LB96V9YI6hb"
      },
      "outputs": [],
      "source": [
        "keyword_results = []\n",
        "tokens = 0\n",
        "for row in questions['question_text']:\n",
        "  chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "  formatted_prompt = promptD.format(question_text=row[2:-2])\n",
        "  r = chat(formatted_prompt)\n",
        "  keyword_results.append(r.content[0].text)\n",
        "  tokens += chat.use.total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNssoozeLJ5m"
      },
      "source": [
        "I'll look at the full set of keywords to make sure there are no filler texts included:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlnpotCFJgIE",
        "outputId": "187cc60d-d352-49c7-b200-a61c2d7e42c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['deep, learning, math, data, computers, phd',\n",
              " 'deep, learning, areas, best, world',\n",
              " '\"neuron, neurons, device, devices, artificial, first\"',\n",
              " 'book, requirements, parallel, distributed, processing, pdp',\n",
              " 'theoretical, misunderstandings, held, back, field, neural, networks',\n",
              " '\"GPU, GPUs, graphics, processor, processors\"',\n",
              " 'notebook, notebooks, execute, cell, cells, 1',\n",
              " 'image, images, photo, photos, recognize, recognition, computer, program, traditional',\n",
              " '\"Samuel, weight, weights, assignment, assignments\"',\n",
              " 'deep, learning, weights, weight, Samuel, term',\n",
              " 'deep, learning, model, models, prediction, predictions, understand, understanding',\n",
              " 'theorem, neural, networks, mathematical, problem, accuracy',\n",
              " 'train, model, models, training, dataset, datasets, data',\n",
              " 'feedback, loops, rollout, rollouts, predictive, policing, model, models',\n",
              " 'cat, cats, recognition, model, 224, pixel, pixels, image, images',\n",
              " 'classification, classifications, regression, regressions, difference, differences',\n",
              " 'validation, validations, test, tests, set, sets',\n",
              " 'fastai, validation, set, sets',\n",
              " 'random, sample, samples, validation, set, sets',\n",
              " 'overfitting, overfits, example, examples, model, models',\n",
              " 'metric, metrics, loss, losses, differ, difference',\n",
              " 'pretrained, models, model, help',\n",
              " 'head, heads, model, models',\n",
              " 'cnn, cnns, layer, layers, feature, features, early, late',\n",
              " 'image, images, model, models, photo, photos',\n",
              " 'architecture, architectures',\n",
              " '\"segmentation, segment, segments\"',\n",
              " '\"y_range, ranges, plotting, visualization, axis, limits\"',\n",
              " 'hyperparameters, hyperparameter, machine, learning, model, parameter',\n",
              " '\"ai, artificial, intelligence, failures, avoid, organization, organizations\"']"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "SR-7B_meLf0C",
        "outputId": "475f1d7e-58b9-43df-9ce2-98967ff2d87a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deep, learning, math, data, computers, phd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>deep, learning, areas, best, world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"neuron, neurons, device, devices, artificial,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>book, requirements, parallel, distributed, pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>theoretical, misunderstandings, held, back, fi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0           deep, learning, math, data, computers, phd\n",
              "1                   deep, learning, areas, best, world\n",
              "2    \"neuron, neurons, device, devices, artificial,...\n",
              "3    book, requirements, parallel, distributed, pro...\n",
              "4    theoretical, misunderstandings, held, back, fi...\n",
              "Name: keywords, dtype: object"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions['keywords'] = keyword_results\n",
        "questions['keywords'].iloc[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJLyfFUJLo_j",
        "outputId": "b756e229-976a-46f9-b410-32f49b4d3376"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# retrieve Top-1 chunk by BM25\n",
        "results = db_search(questions, limit=1)\n",
        "len(results) == 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "eWCVvg87LHIB"
      },
      "outputs": [],
      "source": [
        "# export results\n",
        "questions['context'] = results\n",
        "questions.to_csv('bm25_a_keywordsD.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5ta4mU4MUPB"
      },
      "source": [
        "This prompt resulted in **10/30 or a 33% Answer Rate** and didn't improve the retrieved contexts in the way I thought it would! I'll go back to Prompt C and only add \"no yapping\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p78lr3J0MfXz"
      },
      "source": [
        "### Prompt E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "zv9m5Q-XMTdH"
      },
      "outputs": [],
      "source": [
        "promptE = \"\"\"\"For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords when possible. Include both singular and plural forms for nouns if relevant. Avoid articles, prepositions, and common words. Use this format. No yapping:\n",
        "\n",
        "{question_text}\n",
        "\n",
        "\"keyword1, keyword2, keyword3\" \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSo_eukaLq0E",
        "outputId": "4b5586fc-dffb-42b4-c980-205942f4ed2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"For the given question text, generate 3-6 comma-separated keywords that capture the main concepts for a SQLite full-text search query. Prefer single-word keywords when possible. Include both singular and plural forms for nouns if relevant. Avoid articles, prepositions, and common words. Use this format. No yapping:\n",
            "\n",
            "Why is it hard to understand why a deep learning model makes a particular prediction?\n",
            "\n",
            "\"keyword1, keyword2, keyword3\" \n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = promptE.format(question_text=\"Why is it hard to understand why a deep learning model makes a particular prediction?\")\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "qiC-BmmTNF7R",
        "outputId": "578a6f02-15a2-460f-ec89-1f390553f7b7"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\"deep learning, model, prediction, understand, predictions\"\n",
              "\n",
              "<details>\n",
              "\n",
              "- id: `msg_01G3w22vDXTpWryUwUpqouXN`\n",
              "- content: `[{'text': '\"deep learning, model, prediction, understand, predictions\"', 'type': 'text'}]`\n",
              "- model: `claude-3-5-sonnet-20240620`\n",
              "- role: `assistant`\n",
              "- stop_reason: `end_turn`\n",
              "- stop_sequence: `None`\n",
              "- type: `message`\n",
              "- usage: `{'input_tokens': 118, 'output_tokens': 15, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0}`\n",
              "\n",
              "</details>"
            ],
            "text/plain": [
              "Message(id='msg_01G3w22vDXTpWryUwUpqouXN', content=[TextBlock(text='\"deep learning, model, prediction, understand, predictions\"', type='text')], model='claude-3-5-sonnet-20240620', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=In: 118; Out: 15; Total: 133)"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "r = chat(formatted_prompt)\n",
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "vB8l3FQINGXD"
      },
      "outputs": [],
      "source": [
        "keyword_results = []\n",
        "tokens = 0\n",
        "for row in questions['question_text']:\n",
        "  chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "  formatted_prompt = promptE.format(question_text=row[2:-2])\n",
        "  r = chat(formatted_prompt)\n",
        "  keyword_results.append(r.content[0].text)\n",
        "  tokens += chat.use.total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeTHRmHhPS6s",
        "outputId": "19d4af17-7e2e-4f62-8a46-3677a31eb6a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"deep learning, math, data, computers, PhD\"',\n",
              " 'deep learning, areas, best, world',\n",
              " '\"neuron, neurons, device, artificial, principle\"',\n",
              " '\"parallel, distributed, processing, PDP, requirements, book\"',\n",
              " '\"neural, networks, theoretical, misunderstandings, field\"',\n",
              " '\"GPU, graphics, processor, processors, computing, hardware\"',\n",
              " '\"notebook, execute, cell, calculation, result\"',\n",
              " '\"computer, computers, image, images, recognition, photo, photos\"',\n",
              " '\"Samuel, weight, weights, assignment, assignments\"',\n",
              " 'deep learning, weights, Samuel, term',\n",
              " '\"deep learning, model, prediction, understand, predictions\"',\n",
              " '\"theorem, neural, network, networks, mathematical, problem, accuracy\"',\n",
              " '\"train, model, training, models, dataset, data\"',\n",
              " '\"feedback, loop, rollout, predictive, policing, model, models\"',\n",
              " '\"cat, cats, recognition, model, image, images, pixel, pixels\"',\n",
              " '\"classification, regression, difference, differences, machine learning, models\"',\n",
              " '\"validation, test, set, sets, need, purpose\"',\n",
              " '\"fastai, validation, set, datasets\"',\n",
              " '\"random, sample, samples, validation, set, sets\"',\n",
              " '\"overfitting, overfit, example, model, data, machine learning\"',\n",
              " '\"metric, metrics, loss, differ, difference, measurement\"',\n",
              " '\"pretrained, models, help, pretraining, model\"',\n",
              " 'head, model, models',\n",
              " '\"CNN, layers, features, early, later\"',\n",
              " '\"image, images, model, models, photo, photos\"',\n",
              " '\"architecture, architectures, design, structure, building\"',\n",
              " '\"segmentation, segment, segments, divide, division, categorize\"',\n",
              " '\"y_range, range, purpose, usage, need\"',\n",
              " '\"hyperparameters, hyperparameter, machine learning, model, tuning, optimization\"',\n",
              " '\"AI, failures, avoid, organization, organizations\"']"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keyword_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "YDQzof3yQ0Qd",
        "outputId": "430bc578-3954-48cb-9bed-1da993b069d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"deep learning, math, data, computers, PhD\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>deep learning, areas, best, world</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"neuron, neurons, device, artificial, principle\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"parallel, distributed, processing, PDP, requi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"neural, networks, theoretical, misunderstandi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0          \"deep learning, math, data, computers, PhD\"\n",
              "1                    deep learning, areas, best, world\n",
              "2     \"neuron, neurons, device, artificial, principle\"\n",
              "3    \"parallel, distributed, processing, PDP, requi...\n",
              "4    \"neural, networks, theoretical, misunderstandi...\n",
              "Name: keywords, dtype: object"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions['keywords'] = keyword_results\n",
        "questions['keywords'].iloc[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5-2C2VtQ5Et",
        "outputId": "142e0a6f-e677-46b0-8cd1-5337fa07c93a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# retrieve Top-1 chunk by BM25\n",
        "results = db_search(questions, limit=1)\n",
        "len(results) == 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "Y4gKKbbIQ_y-"
      },
      "outputs": [],
      "source": [
        "# export results\n",
        "questions['context'] = results\n",
        "questions.to_csv('bm25_a_keywordsE.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESGBpheySAsc"
      },
      "source": [
        "The keywords generated by this prompt resulted in retrieved chunks that allowed me to answer **12/30 or 40%** of the questions! This is comparable to the 40% achieved with my manually generated keywords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LfDjD3sS400"
      },
      "source": [
        "I'll go ahead and Claude-generate keywords for all 202 questions in my dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNsZ6kXKTAic"
      },
      "source": [
        "## Generating Keywords for All Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBO7dDJqS_t2",
        "outputId": "373ed5d5-6a7a-4577-d1ee-7a3f932c23b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(202, 6)"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get the questions\n",
        "url = 'https://gist.githubusercontent.com/vishalbakshi/309fb3abb222d32446b2c4e29db753fe/raw/5e41b9eb34f515f00321e55307cc4d5abbd75cb5/fastbookRAG_evals.csv'\n",
        "questions = pd.read_csv(url).query('is_answerable == 1')\n",
        "questions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "vALOVKevVofD"
      },
      "outputs": [],
      "source": [
        "keyword_results = []\n",
        "tokens = 0\n",
        "for row in questions['question_text']:\n",
        "  chat = Chat(model, sp=\"\"\"You are a helpful and concise assistant.\"\"\")\n",
        "  formatted_prompt = promptE.format(question_text=row[2:-2])\n",
        "  r = chat(formatted_prompt)\n",
        "  keyword_results.append(r.content[0].text)\n",
        "  tokens += chat.use.total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZtJEhgYVuGz",
        "outputId": "52124e57-4ec7-40b0-fb58-74315b403525"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 167,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(keyword_results) == 202"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "YSyUvaS1iBCc"
      },
      "outputs": [],
      "source": [
        "questions['keywords'] = keyword_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "fWXtNDb3iF_M"
      },
      "outputs": [],
      "source": [
        "questions.to_csv('evals_promptE_keywords.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quYlLS6Riexs"
      },
      "source": [
        "## Final Thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here are the results from this notebook. **Answer Rate** is the percentage of Chapter 1 Questionnaire questions answered using context retrieved from SQLite full-text search with Claude-generated keywords.\n",
        "\n",
        "|Prompt|Answer Rate|\n",
        "|:-:|:-:|\n",
        "|[A](#prompt-a)|33%\n",
        "|[B](#prompt-b)|33%\n",
        "|[C](#prompt-c)|36%\n",
        "|[D](#prompt-d)|33%\n",
        "|[E](#prompt-e)|**40%**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBOyg_A7igET"
      },
      "source": [
        "I learned a few important lessons in this work:\n",
        "\n",
        "- **The implications of full text search using corpus-wide statistics**: sqlite's FTS5 retrieved different contexts for the same keywords when I used it on a database with 1 versus 7 chapters.\n",
        "- **Claude will tell you how to prompt**: I haven't explored this as much as I should, but definitely benefited from asking Claude what prompt would be effective for generating keywords.\n",
        "- **Claude will make mistakes:** It's sometimes easy to forget that even for relatively simple instructions (\"follow this format\") Claude will incorrectly include extraneous text. A good reminder to add \"no yapping\" to the prompt when brevity is needed.\n",
        "\n",
        "I'm pretty excited about using these Claude-generated keywords as they resulted in the same answer rate (40%) as my manually generated keywords. That's a promising start!\n",
        "\n",
        "I hope you enjoyed this blog post. Follow me on Twitter [@vishal_learner](https://twitter.com/vishal_learner).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
