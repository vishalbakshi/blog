

[Feb 16, 18:16:33] #> Note: Output directory /home/ColBERT/experiments/notebook/indexes/Genomics.2bits already exists


[Feb 16, 18:16:33] #> Will delete 22 files already at /home/ColBERT/experiments/notebook/indexes/Genomics.2bits in 20 seconds...
#> Starting...
nranks = 1 	 num_gpus = 1 	 device=0
{
    "query_token_id": "[unused0]",
    "doc_token_id": "[unused1]",
    "query_token": "[Q]",
    "doc_token": "[D]",
    "ncells": null,
    "centroid_score_threshold": null,
    "ndocs": null,
    "load_index_with_mmap": false,
    "index_path": null,
    "index_bsize": 64,
    "nbits": 2,
    "kmeans_niters": 4,
    "resume": false,
    "pool_factor": 1,
    "clustering_mode": "hierarchical",
    "protected_tokens": 0,
    "similarity": "cosine",
    "bsize": 64,
    "accumsteps": 1,
    "lr": 1e-5,
    "maxsteps": 15626,
    "save_every": null,
    "warmup": 781,
    "warmup_bert": null,
    "relu": false,
    "nway": 32,
    "use_ib_negatives": false,
    "reranker": false,
    "distillation_alpha": 1.0,
    "ignore_scores": false,
    "model_name": "answerdotai\/AnswerAI-ColBERTv2.5-small",
    "query_maxlen": 32,
    "attend_to_mask_tokens": false,
    "interaction": "colbert",
    "dim": 96,
    "doc_maxlen": 256,
    "mask_punctuation": true,
    "checkpoint": "answerdotai\/answerai-colbert-small-v1",
    "triples": "\/home\/bclavie\/colbertv2.5_en\/data\/msmarco\/triplets.jsonl",
    "collection": [
        "list with 250000 elements starting with...",
        [
            "Deconstructing a Disease: RAR, Its Fusion Partners, and Their\r\nRoles  in the Pathogenesis of Acute Promyelocytic Leukemia\r\n",
            "By\r\nAri Melnick and\r\nJonathan D. Licht\r\n",
            "From the Derald H.\u00a0Ruttenberg Cancer Center and Department of\r\nMedicine, Mount Sinai School of Medicine, New York, NY.\r\n"
        ]
    ],
    "queries": "\/home\/bclavie\/colbertv2.5_en\/data\/msmarco\/queries.tsv",
    "index_name": "Genomics.2bits",
    "overwrite": false,
    "root": "\/home\/ColBERT\/experiments",
    "experiment": "notebook",
    "index_root": null,
    "name": "2025-02\/16\/18.16.22",
    "rank": 0,
    "nranks": 1,
    "amp": true,
    "gpus": 1,
    "avoid_fork_if_possible": false
}
[Feb 16, 18:17:27] [0] 		 # of sampled PIDs = 87636 	 sampled_pids[:3] = [109214, 192069, 2665]
Filename: /home/ColBERT/colbert/indexing/collection_indexer.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   102    815.7 MiB    815.7 MiB           1           @profile
   103                                                 def _sample_pids_profiled():
   104    829.7 MiB     14.0 MiB           1               return self._sample_pids()


[Feb 16, 18:17:45] [0] 		 #> Encoding 87636 passages..
Filename: /home/ColBERT/colbert/indexing/collection_indexer.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   146    829.7 MiB    829.7 MiB           1           @profile
   147                                                 def _encode_passages_profiled(*args, **kwargs):
   148   2820.8 MiB   1991.1 MiB           1               return self.encoder.encode_passages(*args, **kwargs)


[Feb 16, 18:19:48] [0] 		 avg_doclen_est = 79.57461547851562 	 len(local_sample) = 87,636
Filename: /home/ColBERT/colbert/indexing/collection_indexer.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   144    829.7 MiB    829.7 MiB           1       @profile
   145                                             def _sample_embeddings(self, sampled_pids):
   146    829.7 MiB      0.0 MiB           2           @profile
   147    829.7 MiB      0.0 MiB           1           def _encode_passages_profiled(*args, **kwargs):
   148   2820.8 MiB   1991.1 MiB           1               return self.encoder.encode_passages(*args, **kwargs)
   149                                                     
   150    829.7 MiB      0.0 MiB           1           local_pids = self.collection.enumerate(rank=self.rank)
   151    829.7 MiB      0.0 MiB      250003           local_sample = [passage for pid, passage in local_pids if pid in sampled_pids]
   152                                         
   153   2820.8 MiB      0.0 MiB           1           local_sample_embs, doclens = _encode_passages_profiled(local_sample)
   154                                         
   155   2820.8 MiB      0.0 MiB           1           if torch.cuda.is_available():
   156   2820.8 MiB      0.0 MiB           1               if torch.distributed.is_available() and torch.distributed.is_initialized():
   157   2820.8 MiB      0.0 MiB           1                   self.num_sample_embs = torch.tensor([local_sample_embs.size(0)]).cuda()
   158   2914.6 MiB     93.8 MiB           1                   torch.distributed.all_reduce(self.num_sample_embs)
   159                                         
   160   2914.6 MiB      0.0 MiB           1                   avg_doclen_est = sum(doclens) / len(doclens) if doclens else 0
   161   2914.6 MiB      0.0 MiB           1                   avg_doclen_est = torch.tensor([avg_doclen_est]).cuda()
   162   2914.6 MiB      0.0 MiB           1                   torch.distributed.all_reduce(avg_doclen_est)
   163                                         
   164   2914.6 MiB      0.0 MiB           1                   nonzero_ranks = torch.tensor([float(len(local_sample) > 0)]).cuda()
   165   2914.6 MiB      0.0 MiB           1                   torch.distributed.all_reduce(nonzero_ranks)
   166                                                     else:
   167                                                         self.num_sample_embs = torch.tensor([local_sample_embs.size(0)]).cuda()
   168                                         
   169                                                         avg_doclen_est = sum(doclens) / len(doclens) if doclens else 0
   170                                                         avg_doclen_est = torch.tensor([avg_doclen_est]).cuda()
   171                                         
   172                                                         nonzero_ranks = torch.tensor([float(len(local_sample) > 0)]).cuda()
   173                                                 else:
   174                                                     if torch.distributed.is_available() and torch.distributed.is_initialized():
   175                                                         self.num_sample_embs = torch.tensor([local_sample_embs.size(0)]).cpu()
   176                                                         torch.distributed.all_reduce(self.num_sample_embs)
   177                                         
   178                                                         avg_doclen_est = sum(doclens) / len(doclens) if doclens else 0
   179                                                         avg_doclen_est = torch.tensor([avg_doclen_est]).cpu()
   180                                                         torch.distributed.all_reduce(avg_doclen_est)
   181                                         
   182                                                         nonzero_ranks = torch.tensor([float(len(local_sample) > 0)]).cpu()
   183                                                         torch.distributed.all_reduce(nonzero_ranks)
   184                                                     else:
   185                                                         self.num_sample_embs = torch.tensor([local_sample_embs.size(0)]).cpu()
   186                                         
   187                                                         avg_doclen_est = sum(doclens) / len(doclens) if doclens else 0
   188                                                         avg_doclen_est = torch.tensor([avg_doclen_est]).cpu()
   189                                         
   190                                                         nonzero_ranks = torch.tensor([float(len(local_sample) > 0)]).cpu()
   191                                         
   192   2914.6 MiB      0.0 MiB           1           avg_doclen_est = avg_doclen_est.item() / nonzero_ranks.item()
   193   2914.6 MiB      0.0 MiB           1           self.avg_doclen_est = avg_doclen_est
   194                                         
   195   2914.6 MiB      0.0 MiB           1           Run().print(f'avg_doclen_est = {avg_doclen_est} \t len(local_sample) = {len(local_sample):,}')
   196                                         
   197   2915.6 MiB      1.0 MiB           1           torch.save(local_sample_embs.half(), os.path.join(self.config.index_path_, f'sample.{self.rank}.pt'))
   198                                         
   199   2915.6 MiB      0.0 MiB           1           return avg_doclen_est


Filename: /home/ColBERT/colbert/indexing/collection_indexer.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   106    829.7 MiB    829.7 MiB           1           @profile
   107                                                 def _sample_embeddings_profiled(pids):
   108   1638.7 MiB    809.0 MiB           1               return self._sample_embeddings(pids)


[Feb 16, 18:19:49] [0] 		 Creating 65,536 partitions.
[Feb 16, 18:19:49] [0] 		 *Estimated* 19,893,653 embeddings.
[Feb 16, 18:19:49] [0] 		 #> Saving the indexing plan to /home/ColBERT/experiments/notebook/indexes/Genomics.2bits/plan.json ..
Clustering 6923601 points in 96D to 65536 clusters, redo 1 times, 4 iterations
  Preprocessing in 0.27 s
  Iteration 0 (6.75 s, search 6.42 s): objective=342792 imbalance=3.333 nsplit=554         Iteration 1 (13.51 s, search 13.08 s): objective=222013 imbalance=2.933 nsplit=18         Iteration 2 (20.35 s, search 19.83 s): objective=203231 imbalance=3.873 nsplit=10         Iteration 3 (27.25 s, search 26.65 s): objective=195560 imbalance=3.844 nsplit=0       Filename: /home/ColBERT/colbert/indexing/collection_indexer.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    82    815.7 MiB    815.7 MiB           1       @profile
    83                                             def setup(self):
    84                                                 '''
    85                                                 Calculates and saves plan.json for the whole collection.
    86                                                 
    87                                                 plan.json { config, num_chunks, num_partitions, num_embeddings_est, avg_doclen_est}
    88                                                 num_partitions is the number of centroids to be generated.
    89                                                 '''
    90    815.7 MiB      0.0 MiB           1           if self.config.resume:
    91                                                     if self._try_load_plan():
    92                                                         if self.verbose > 1:
    93                                                             Run().print_main(f"#> Loaded plan from {self.plan_path}:")
    94                                                             Run().print_main(f"#> num_chunks = {self.num_chunks}")
    95                                                             Run().print_main(f"#> num_partitions = {self.num_chunks}")
    96                                                             Run().print_main(f"#> num_embeddings_est = {self.num_embeddings_est}")
    97                                                             Run().print_main(f"#> avg_doclen_est = {self.avg_doclen_est}")
    98                                                         return
    99                                         
   100    815.7 MiB      0.0 MiB           1           self.num_chunks = int(np.ceil(len(self.collection) / self.collection.get_chunksize()))
   101                                                 
   102    815.7 MiB      0.0 MiB           2           @profile
   103    815.7 MiB      0.0 MiB           1           def _sample_pids_profiled():
   104    829.7 MiB     14.0 MiB           1               return self._sample_pids()
   105                                             
   106    829.7 MiB      0.0 MiB           2           @profile
   107    815.7 MiB      0.0 MiB           1           def _sample_embeddings_profiled(pids):
   108   1638.7 MiB    809.0 MiB           1               return self._sample_embeddings(pids)
   109                                                     
   110                                                 # Saves sampled passages and embeddings for training k-means centroids later 
   111    829.7 MiB      0.0 MiB           1           sampled_pids = _sample_pids_profiled()
   112   1638.7 MiB      0.0 MiB           1           avg_doclen_est = _sample_embeddings_profiled(sampled_pids)
   113                                         
   114                                                 # Select the number of partitions
   115   1638.7 MiB      0.0 MiB           1           num_passages = len(self.collection)
   116   1638.7 MiB      0.0 MiB           1           self.num_embeddings_est = num_passages * avg_doclen_est
   117   1638.7 MiB      0.0 MiB           1           self.num_partitions = int(2 ** np.floor(np.log2(16 * np.sqrt(self.num_embeddings_est))))
   118                                         
   119   1638.7 MiB      0.0 MiB           1           if self.verbose > 0:
   120   1638.7 MiB      0.0 MiB           1               Run().print_main(f'Creating {self.num_partitions:,} partitions.')
   121   1638.7 MiB      0.0 MiB           1               Run().print_main(f'*Estimated* {int(self.num_embeddings_est):,} embeddings.')
   122                                         
   123   1639.7 MiB      1.0 MiB           1           self._save_plan()


[Feb 16, 18:20:28] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...
[Feb 16, 18:20:29] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...
[0.013, 0.013, 0.012, 0.013, 0.012, 0.013, 0.013, 0.013, 0.014, 0.012, 0.012, 0.014, 0.015, 0.012, 0.013, 0.015, 0.011, 0.014, 0.013, 0.012, 0.012, 0.013, 0.014, 0.012, 0.012, 0.014, 0.013, 0.013, 0.013, 0.013, 0.013, 0.012, 0.013, 0.013, 0.013, 0.014, 0.012, 0.013, 0.013, 0.013, 0.012, 0.013, 0.013, 0.012, 0.012, 0.014, 0.013, 0.014, 0.012, 0.013, 0.014, 0.013, 0.013, 0.013, 0.012, 0.012, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.012, 0.014, 0.014, 0.014, 0.013, 0.013, 0.013, 0.014, 0.012, 0.012, 0.013, 0.013, 0.013, 0.012, 0.012, 0.013, 0.014, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.012, 0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.014, 0.013, 0.013]
[Feb 16, 18:20:29] #> Got bucket_cutoffs_quantiles = tensor([0.2500, 0.5000, 0.7500], device='cuda:0') and bucket_weights_quantiles = tensor([0.1250, 0.3750, 0.6250, 0.8750], device='cuda:0')
[Feb 16, 18:20:29] #> Got bucket_cutoffs = tensor([-0.0100,  0.0000,  0.0103], device='cuda:0') and bucket_weights = tensor([-0.0181, -0.0044,  0.0046,  0.0183], device='cuda:0')
[Feb 16, 18:20:29] avg_residual = 0.012939453125
[Feb 16, 18:20:30] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:20:50] [0] 		 #> Saving chunk 0: 	 25,000 passages and 1,897,577 embeddings. From #0 onward.
[Feb 16, 18:20:51] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:21:11] [0] 		 #> Saving chunk 1: 	 25,000 passages and 1,877,590 embeddings. From #25,000 onward.
[Feb 16, 18:21:11] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:21:32] [0] 		 #> Saving chunk 2: 	 25,000 passages and 1,953,069 embeddings. From #50,000 onward.
[Feb 16, 18:21:33] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:21:52] [0] 		 #> Saving chunk 3: 	 25,000 passages and 2,028,875 embeddings. From #75,000 onward.
[Feb 16, 18:21:52] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:22:11] [0] 		 #> Saving chunk 4: 	 25,000 passages and 1,962,099 embeddings. From #100,000 onward.
[Feb 16, 18:22:12] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:22:31] [0] 		 #> Saving chunk 5: 	 25,000 passages and 2,017,239 embeddings. From #125,000 onward.
[Feb 16, 18:22:32] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:22:51] [0] 		 #> Saving chunk 6: 	 25,000 passages and 2,015,742 embeddings. From #150,000 onward.
[Feb 16, 18:22:51] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:23:10] [0] 		 #> Saving chunk 7: 	 25,000 passages and 1,989,287 embeddings. From #175,000 onward.
[Feb 16, 18:23:11] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:23:30] [0] 		 #> Saving chunk 8: 	 25,000 passages and 2,092,270 embeddings. From #200,000 onward.
[Feb 16, 18:23:31] [0] 		 #> Encoding 25000 passages..
[Feb 16, 18:23:50] [0] 		 #> Saving chunk 9: 	 25,000 passages and 2,127,784 embeddings. From #225,000 onward.
[Feb 16, 18:23:51] [0] 		 #> Checking all files were saved...
[Feb 16, 18:23:51] [0] 		 Found all files!
[Feb 16, 18:23:51] [0] 		 #> Building IVF...
[Feb 16, 18:23:51] [0] 		 #> Loading codes...
[Feb 16, 18:23:51] [0] 		 Sorting codes...
[Feb 16, 18:23:51] [0] 		 Getting unique codes...
[Feb 16, 18:23:51] #> Optimizing IVF to store map from centroids to list of pids..
[Feb 16, 18:23:51] #> Building the emb2pid mapping..
[Feb 16, 18:23:53] len(emb2pid) = 19961532
[Feb 16, 18:23:57] #> Saved optimized IVF to /home/ColBERT/experiments/notebook/indexes/Genomics.2bits/ivf.pid.pt
[Feb 16, 18:23:57] [0] 		 #> Saving the indexing metadata to /home/ColBERT/experiments/notebook/indexes/Genomics.2bits/metadata.json ..
Filename: /home/ColBERT/colbert/indexing/collection_indexer.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    62    815.7 MiB    815.7 MiB           1       @profile
    63                                             def run(self, shared_lists):
    64    815.7 MiB      0.0 MiB           1           with torch.inference_mode():
    65   1632.1 MiB    816.4 MiB           1               self.setup() # Computes and saves plan for whole collection
    66   1632.1 MiB      0.0 MiB           1               distributed.barrier(self.rank)
    67   1632.1 MiB      0.0 MiB           1               print_memory_stats(f'RANK:{self.rank}')
    68                                         
    69   1632.1 MiB      0.0 MiB           1               if not self.config.resume or not self.saver.try_load_codec():
    70   1760.9 MiB    128.8 MiB           1                   self.train(shared_lists) # Trains centroids from selected passages
    71   1760.9 MiB      0.0 MiB           1               distributed.barrier(self.rank)
    72   1760.9 MiB      0.0 MiB           1               print_memory_stats(f'RANK:{self.rank}')
    73                                         
    74   2024.4 MiB    263.5 MiB           1               self.index() # Encodes and saves all tokens into residuals
    75   2024.4 MiB      0.0 MiB           1               distributed.barrier(self.rank)
    76   2024.4 MiB      0.0 MiB           1               print_memory_stats(f'RANK:{self.rank}')
    77                                         
    78   2024.0 MiB     -0.4 MiB           1               self.finalize() # Builds metadata and centroid to passage mapping
    79   2024.0 MiB      0.0 MiB           1               distributed.barrier(self.rank)
    80   2024.0 MiB      0.0 MiB           1               print_memory_stats(f'RANK:{self.rank}')


Filename: /home/ColBERT/colbert/indexing/collection_indexer.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    31    690.5 MiB    690.5 MiB           1   @profile
    32                                         def encode(config, collection, shared_lists, shared_queues, verbose: int = 3):
    33    815.7 MiB    125.2 MiB           1       encoder = CollectionIndexer(config=config, collection=collection, verbose=verbose)
    34   2024.0 MiB   1208.3 MiB           1       encoder.run(shared_lists)



#> Joined...
Filename: /home/ColBERT/colbert/infra/launcher.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    28   1754.0 MiB   1754.0 MiB           1       @profile
    29                                             def launch(self, custom_config, *args):
    30   1754.0 MiB      0.0 MiB           1           assert isinstance(custom_config, BaseConfig)
    31   1754.0 MiB      0.0 MiB           1           assert isinstance(custom_config, RunSettings)
    32                                                 
    33   1754.0 MiB      0.0 MiB           1           return_value_queue = mp.Queue()
    34   1754.0 MiB      0.0 MiB           1           rng = random.Random(time.time())
    35   1754.0 MiB      0.0 MiB           1           port = str(12355 + rng.randint(0, 1000))  # randomize the port to avoid collision on launching several jobs.
    36   1754.0 MiB      0.0 MiB           1           all_procs = []
    37   1754.0 MiB      0.0 MiB           2           for new_rank in range(0, self.nranks):
    38   1754.0 MiB      0.0 MiB           1               new_config = type(custom_config).from_existing(custom_config, self.run_config, RunConfig(rank=new_rank))
    39                                         
    40   1754.0 MiB      0.0 MiB           1               args_ = (self.callee, port, return_value_queue, new_config, *args)
    41   1754.0 MiB      0.0 MiB           1               all_procs.append(mp.Process(target=setup_new_process, args=args_))
    42                                         
    43                                                 # Clear GPU space (e.g., after a `Searcher` on GPU-0 is deleted)
    44                                                 # TODO: Generalize this from GPU-0 only!
    45                                                 # TODO: Move this to a function. And call that function from __del__ in a class that's inherited by Searcher, Indexer, etc.
    46                                         
    47                                                 # t = torch.cuda.get_device_properties(0).total_memory
    48                                                 # r = torch.cuda.memory_reserved(0)
    49                                                 # a = torch.cuda.memory_allocated(0)
    50                                                 # f = r-a
    51                                         
    52                                                 # print_message(f"[Pre-Emptying] GPU memory check: r={r}, a={a}, f={f}")
    53                                         
    54   1754.0 MiB      0.0 MiB           1           torch.cuda.empty_cache()
    55                                         
    56                                                 # t = torch.cuda.get_device_properties(0).total_memory
    57                                                 # r = torch.cuda.memory_reserved(0)
    58                                                 # a = torch.cuda.memory_allocated(0)
    59                                                 # f = r-a
    60                                         
    61                                                 # print_message(f"[Post-Emptying] GPU memory check: r={r}, a={a}, f={f}")
    62                                         
    63   1754.0 MiB      0.0 MiB           1           print_memory_stats('MAIN')
    64                                         
    65   1846.8 MiB      0.0 MiB           2           for proc in all_procs:
    66   1754.0 MiB      0.0 MiB           1               print("#> Starting...")
    67   1846.8 MiB     92.8 MiB           1               proc.start()
    68                                         
    69   1846.8 MiB      0.0 MiB           1           print_memory_stats('MAIN')
    70                                         
    71                                                 # TODO: If the processes crash upon join, raise an exception and don't block on .get() below!
    72                                         
    73   1846.8 MiB      0.0 MiB           4           return_values = sorted([return_value_queue.get() for _ in all_procs])
    74   1846.8 MiB      0.0 MiB           4           return_values = [val for rank, val in return_values]
    75                                         
    76   1846.8 MiB      0.0 MiB           1           if not self.return_all:
    77   1846.8 MiB      0.0 MiB           1               return_values = return_values[0]
    78                                                 
    79   1846.8 MiB      0.0 MiB           2           for proc in all_procs:
    80   1846.8 MiB      0.0 MiB           1               proc.join()
    81   1846.8 MiB      0.0 MiB           1               print("#> Joined...")
    82                                         
    83   1846.8 MiB      0.0 MiB           1           print_memory_stats('MAIN')
    84                                                 
    85   1846.8 MiB      0.0 MiB           1           return return_values


Filename: /home/ColBERT/colbert/indexer.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    85   1754.0 MiB   1754.0 MiB           1       @profile
    86                                             def __launch(self, collection):
    87   1754.0 MiB      0.0 MiB           1           launcher = Launcher(encode)
    88   1754.0 MiB      0.0 MiB           1           if self.config.nranks == 1 and self.config.avoid_fork_if_possible:
    89                                                     shared_queues = []
    90                                                     shared_lists = []
    91                                                     launcher.launch_without_fork(self.config, collection, shared_lists, shared_queues, self.verbose)
    92                                         
    93                                                     return
    94                                         
    95   1754.0 MiB      0.0 MiB           1           manager = mp.Manager()
    96   1754.0 MiB      0.0 MiB           4           shared_lists = [manager.list() for _ in range(self.config.nranks)]
    97   1754.0 MiB      0.0 MiB           4           shared_queues = [manager.Queue(maxsize=1) for _ in range(self.config.nranks)]
    98                                         
    99                                                 # Encodes collection into index using the CollectionIndexer class
   100   1846.8 MiB     92.8 MiB           1           launcher.launch(self.config, collection, shared_lists, shared_queues, self.verbose)


Filename: /home/ColBERT/colbert/indexer.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    60   1754.0 MiB   1754.0 MiB           1       @profile
    61                                             def index(self, name, collection, overwrite=False):
    62   1754.0 MiB      0.0 MiB           1           assert overwrite in [True, False, 'reuse', 'resume', "force_silent_overwrite"]
    63                                         
    64   1754.0 MiB      0.0 MiB           1           self.configure(collection=collection, index_name=name, resume=overwrite=='resume')
    65                                                 # Note: The bsize value set here is ignored internally. Users are encouraged
    66                                                 # to supply their own batch size for indexing by using the index_bsize parameter in the ColBERTConfig.
    67   1754.0 MiB      0.0 MiB           1           self.configure(bsize=64, partitions=None)
    68                                         
    69   1754.0 MiB      0.0 MiB           1           self.index_path = self.config.index_path_
    70   1754.0 MiB      0.0 MiB           1           index_does_not_exist = (not os.path.exists(self.config.index_path_))
    71                                         
    72   1754.0 MiB      0.0 MiB           1           assert (overwrite in [True, 'reuse', 'resume', "force_silent_overwrite"]) or index_does_not_exist, self.config.index_path_
    73   1754.0 MiB      0.0 MiB           1           create_directory(self.config.index_path_)
    74                                         
    75   1754.0 MiB      0.0 MiB           1           if overwrite == 'force_silent_overwrite':
    76                                                     self.erase(force_silent=True)
    77   1754.0 MiB      0.0 MiB           1           elif overwrite is True:
    78   1754.0 MiB      0.0 MiB           1               self.erase()
    79                                         
    80   1754.0 MiB      0.0 MiB           1           if index_does_not_exist or overwrite != 'reuse':
    81   1846.8 MiB     92.8 MiB           1               self.__launch(collection)
    82                                         
    83   1846.8 MiB      0.0 MiB           1           return self.index_path


Filename: ../colbert_index_250k.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     8   1754.0 MiB   1754.0 MiB           1   @profile
     9                                         def _index(indexer, name, collection):
    10   1846.8 MiB     92.8 MiB           1       return indexer.index(name=name, collection=collection, overwrite=True)


