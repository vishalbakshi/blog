{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "title: Memory Profiling raw ColBERT and RAGatouille\n",
        "date: \"2025-02-17\"\n",
        "author: Vishal Bakshi\n",
        "description: I use the `memory-profiler` library to log memory using for different indexing functions for raw ColBERT and RAGatouille indexing operations for 100k, 250k, 500k, 1M and 2M collection sizes. In general, RAGatouille uses more memory than raw ColBERT.\n",
        "filters:\n",
        "   - lightbox\n",
        "lightbox: auto\n",
        "categories:\n",
        "    - python\n",
        "    - information retrieval\n",
        "    - deep learning\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyDKfQzgXfTm"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRPF21ubXgqN"
      },
      "source": [
        "A disclaimer: this is the first time I've done memory profiling, and while I've probably spent 8-10 hours [poring through the RAGatouille and ColBERT codebases](https://vishalbakshi.github.io/blog/posts/2024-12-24-PLAID-ColBERTv2-scoring-pipeline/) I still consider myself a beginner, and don't have a solid mental model of how indexing (and search) work.\n",
        "\n",
        "With that out of the way, let's dig in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEitMTv0YklR"
      },
      "source": [
        "[In a previous blog post](https://vishalbakshi.github.io/blog/posts/2025-02-12-indexing-memory/) I used `psutil.Process().memory_info().rss` in a separate thread to monitor memory usage while indexing 100k, 250k, 500k, 1M and 2M documents from the Genomics datasets (via UKPLab/DAPR) with RAGatouille. I have also run this for raw ColBERT. Here's an example comparison (for 250k docs on an RTX6000Ada instance) with RAGatouille on the left and raw ColBERT on the right:\n",
        "\n",
        "![CPU memory usage while indexing 250k documents](1.png)\n",
        "\n",
        "While the peak memory increased with number of documents, they all follow the same trend. ColBERT always has a significantly lower peak memory. The ColBERT runs in total took about an hour and the RAGatouille runs took about 1.5 hours. Comparison of all collection sizes can be seen in [this folder](https://github.com/vishalbakshi/RAGatouille/tree/profiling/profiling_results/memory_time_plots)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLCOcOPLayOA"
      },
      "source": [
        "In this blog post I go deeper and use the `memory_profiler` package to understand how much memory is being consumed by different functions down the chain of calls when you index 100k, 250k, 500k, 1M and 2M documents using raw ColBERT and RAGatouille. For all of these runs I use a RTX6000Ada instance on Jarvis Labs. When using RAGatouille, I execute all runs with `use_faiss=False` (since that's the default value in RAGatouille) and runs of 100k, 250k and 500k with `use_faiss=True`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXgikA7Xb0-_"
      },
      "source": [
        "## Repo Setup and Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHsqN05Ab2W_"
      },
      "source": [
        "Since I needed to add the `@profile` decorator above each function I wanted to profile, I created my own forks of the raw ColBERT and RAGatouille repos and created a `profiling` branch. Since RAGatouille is built on top of ColBERT, I switched the `colbert-ai` dependency in my RAGatouille fork from `\"colbert-ai>=0.2.19\"` to:\n",
        "\n",
        "```\n",
        "\"colbert-ai @ git+https://github.com/vishalbakshi/ColBERT.git@profiling\"\n",
        "```\n",
        "\n",
        "I also added `memory-profiler` as a dependency for both ColBERT and RAGatouille.\n",
        "\n",
        "I used the terminal for all experiments. Here are the commands to install RAGatouille:\n",
        "\n",
        "```bash\n",
        "python -m venv ragatouille-env\n",
        "source ragatouille-env/bin/activate\n",
        "git clone -b profiling https://github.com/vishalbakshi/RAGatouille.git\n",
        "cd RAGatouille\n",
        "pip install -e .\n",
        "pip install datasets\n",
        "pip uninstall --y faiss-cpu\n",
        "pip install faiss-gpu-cu12\n",
        "```\n",
        "\n",
        "Note that I uninstalled `faiss-cpu` and installed `faiss-gpu-cu12`.\n",
        "\n",
        "Here are the commands to install ColBERT (which took considerably more effort, and assistance from Claude, to figure out):\n",
        "\n",
        "```bash\n",
        "git clone -b profiling https://github.com/vishalbakshi/ColBERT.git\n",
        "cd ColBERT\n",
        "conda env create -f conda_env.yml\n",
        "conda init\n",
        "source ~/.bashrc\n",
        "conda activate colbert\n",
        "pip install -e .\n",
        "conda remove -y --force pytorch torchvision torchaudio cudatoolkit\n",
        "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "apt-get update\n",
        "apt-get install -y gcc-11 g++-11\n",
        "export CC=gcc-11\n",
        "export CXX=g++-11\n",
        "```\n",
        "\n",
        "I had to uninstall pytorch, torchvision, torchaudio, cudatoolkit and reinstall them to resolve the following error:\n",
        "\n",
        "```bash\n",
        "File \"/home/ColBERT/colbert/utils/utils.py\", line 3, in <module>\n",
        "    import torch\n",
        "  File \"/root/miniconda3/envs/colbert/lib/python3.8/site-packages/torch/__init__.py\", line 218, in <module>\n",
        "    from torch._C import *  # noqa: F403\n",
        "ImportError: /root/miniconda3/envs/colbert/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent\n",
        "```\n",
        "\n",
        "The last four commands I ran:\n",
        "\n",
        "```bash\n",
        "apt-get update\n",
        "apt-get install -y gcc-11 g++-11\n",
        "export CC=gcc-11\n",
        "export CXX=g++-11\n",
        "```\n",
        "\n",
        "Resolved `fatal error: crypt.h: No such file or directory`/`ninja: build stopped: subcommand failed` as is detailed in ColBERT issue [#371](https://github.com/stanford-futuredata/ColBERT/issues/371)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zYtIsEgeJuB"
      },
      "source": [
        "## Functions Selected for Profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZCLVjlQeNrm"
      },
      "source": [
        "I determined which functions to profile by trial and error, adding/removing the `@profile` decorator to see which function was being called. Again, lots of Claude assistance was needed. Here are the filenames and method names that I chose to profile:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjhz_QgVejOr"
      },
      "source": [
        "### ColBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyp_91Lkekhq"
      },
      "source": [
        "|Filename|Method|\n",
        "|:-:|:-:|\n",
        "|indexer.py|`index`|\n",
        "|indexer.py|`__launch`|\n",
        "|indexing/collection_indexer.py|`encode`|\n",
        "|indexing/collection_indexer.py|`run`|\n",
        "|indexing/collection_indexer.py|`setup`|\n",
        "|indexing/collection_indexer.py|`__sample_pids`|\n",
        "|indexing/collection_indexer.py|`__sample_embeddings`|\n",
        "|indexing/collection_indexer.py|`encoder.encode_passages`|\n",
        "|infra/launcher.py|`launch`|\n",
        "|infra/launcher.py|`launch_without_fork`|\n",
        "|infra/launcher.py|`run_process_without_mp`|\n",
        "|infra/launcher.py|`callee`|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymqHyUhuf4Xl"
      },
      "source": [
        "### RAGatouille"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RB_ti2wf5k-"
      },
      "source": [
        "|Filename|Method|\n",
        "|:-:|:-:|\n",
        "|RAGPretrainedModel.py|`_process_corpus`|\n",
        "|RAGPretrainedModel.py|`model.index`|\n",
        "|models/colbert.py|`ModelIndexFactory.construct`\n",
        "|models/index.py|`PLAIDModelIndex.__init__`|\n",
        "|models/index.py|`PLAIDModelIndex.construct`|\n",
        "|models/index.py|`PLAIDModelIndex.build`|\n",
        "|models/index.py|`PLAIDModelIndex.indexer.index`|\n",
        "\n",
        "Note that in RAGatouille, `PLAIDModelIndex.indexer` is of class `Indexer` which is imported from ColBERT, so I understood this to be the \"bridge\" between the RAGatouille and ColBERT repos during profiling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOT8RD3vh36b"
      },
      "source": [
        "## Scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1wPSNpMh7ry"
      },
      "source": [
        "Here's the script for indexing using ColBERT:\n",
        "\n",
        "```python\n",
        "import colbert\n",
        "from colbert import Indexer, Searcher\n",
        "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
        "from colbert.data import Queries, Collection\n",
        "from datasets import load_dataset\n",
        "from memory_profiler import profile\n",
        "\n",
        "@profile\n",
        "def _index(indexer, name, collection):\n",
        "    return indexer.index(name=name, collection=collection, overwrite=True)\n",
        "\n",
        "def main():\n",
        "    nbits = 2  \n",
        "    ndocs = 100_000\n",
        "    dataset_name = \"Genomics\"\n",
        "    index_name = f'{dataset_name}.{nbits}bits'\n",
        "\n",
        "    passages = load_dataset(\"UKPLab/dapr\", f\"{dataset_name}-corpus\", split=\"test\")\n",
        "    checkpoint = 'answerdotai/answerai-colbert-small-v1'\n",
        "\n",
        "    with Run().context(RunConfig(nranks=1, experiment='notebook')):\n",
        "        config = ColBERTConfig(doc_maxlen=256, nbits=nbits, kmeans_niters=4, avoid_fork_if_possible=True)\n",
        "        indexer = Indexer(checkpoint=checkpoint, config=config)\n",
        "        _index(indexer, index_name, passages[:ndocs][\"text\"])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "```\n",
        "\n",
        "and the script for RAGatouille:\n",
        "\n",
        "```python\n",
        "from memory_profiler import profile\n",
        "from datasets import load_dataset\n",
        "from ragatouille import RAGPretrainedModel\n",
        "\n",
        "dataset_name = \"Genomics\"\n",
        "passages = load_dataset(\"UKPLab/dapr\", f\"{dataset_name}-corpus\", split=\"test\")\n",
        "RAG = RAGPretrainedModel.from_pretrained(\"answerdotai/answerai-colbert-small-v1\")\n",
        "ndocs=250_000\n",
        "\n",
        "@profile\n",
        "def _index():\n",
        "    return RAG.index(\n",
        "        index_name=f\"{dataset_name}_index\",\n",
        "        collection=passages[:ndocs][\"text\"],\n",
        "        document_ids=passages[:ndocs][\"_id\"],\n",
        "        use_faiss=True # or False\n",
        "    )\n",
        "\n",
        "_index()\n",
        "```\n",
        "\n",
        "Finally, here's the terminal command to run the scripts and profile them:\n",
        "\n",
        "```bash\n",
        "python -m memory_profiler ../colbert_index_2M.py > ../colbert_2M_RTX6000Ada.txt\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC8GfCgnhnvY"
      },
      "source": [
        "## Profiling Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EovJA6Zkimvf"
      },
      "source": [
        "The profile logs were 400+ lines each (you can see the full files [here](https://github.com/vishalbakshi/RAGatouille/tree/profiling/profiling_results)) so I have only included some of the lines with non-zero memory changes. I have showed the starting memory, memory increment and final memory.\n",
        "\n",
        "Here's how I'm interpreting the profiler logs--given this log:\n",
        "\n",
        "```\n",
        "Filename: /home/RAGatouille/ragatouille/models/index.py\n",
        "\n",
        "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
        "=============================================================\n",
        "   198   3406.4 MiB   3406.4 MiB           1           @profile\n",
        "   199                                                 def _index_with_profiling(indexer, name, collection, overwrite):\n",
        "   200   4872.2 MiB   1465.8 MiB           1               return indexer.index(name=name, collection=collection, overwrite=overwrite)\n",
        "```\n",
        "\n",
        "I would interpret that to mean that before `indexer.index` was called, 3406.4 MB memory was used, and the `indexer.index` call increased it by 1465.8 MB to 4872.2 MB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu5MR0I6tgoW"
      },
      "source": [
        "### colbert/indexer.py/`indexer.index`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n519fOu4V9TM"
      },
      "source": [
        "For RAGatouille, this call takes place in [ragatouille/models/index.py](https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L243)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b97Ad014y0XM"
      },
      "source": [
        "It's interesting to note that even before `indexer.index` is called, the starting memory varies between raw ColBERT and RAGatouille. Most notably, for 2M documents, ColBERT starts at ~<mark>4GB</mark> while RAGatouille starts at ~<mark>8 GB</mark>.\n",
        "\n",
        "Even more interesting, the memory increments for ColBERT are <mark>2x to 35x</mark> smaller than RAGatouille for each collection size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Mfqou0tq8f"
      },
      "source": [
        "|Indexing Method|Document Size|Starting Memory|Memory Increment| Final Memory|\n",
        "|:-:|:-:|:-:|:-:|:-:|\n",
        "|ColBERT|100k|1596.9 MB|36.7 MB|1633.6 MB\n",
        "|ColBERT|250k|1754.0 MB|92.8 MB|1846.8 MB\n",
        "|ColBERT|500k|2072.1 MB|199.1 MB|2271.2 MB\n",
        "|ColBERT|1M|2707.3 MB|421.9 MB|3129.2 MB\n",
        "|ColBERT|2M|4000.6 MB|876.4 MB|4877.1 MB\n",
        "|RAGatouille (`use_faiss=True`)|100k|2114.2 MB|1320.1 MB|3434.3 MB\n",
        "|RAGatouille (`True`)|250k|2592.5 MB|1175.0 MB|3767.5 MB\n",
        "|RAGatouille (`True`)|500k|3405.0 MB|1430.0 MB|4835.0 MB\n",
        "|RAGatouille (`use_faiss=False`)|100k|1750.9 MB|1203.9 MB|2954.8 MB\n",
        "|RAGatouille (`False`)|250k|2597.4 MB|1341.4 MB|3938.8 MB\n",
        "|RAGatouille (`False`)|500k|3406.4 MB|1465.8 MB|4872.2 MB\n",
        "|RAGatouille (`False`)|1M|5040.1 MB|1593.3 MB|6633.3 MB\n",
        "|RAGatouille (`False`)|2M|8354.7 MB|1882.0 MB|10236.8 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpzFeQ50h2M5"
      },
      "source": [
        "### colbert/indexing/collection_indexer.py/`encoder.encode_passages`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1db-Qo2Az5Y4"
      },
      "source": [
        "`encoder.encode_passages` involves the following code:\n",
        "\n",
        "```python\n",
        "\n",
        "def encode_passages(self, passages):\n",
        "        Run().print(f\"#> Encoding {len(passages)} passages..\")\n",
        "\n",
        "        if len(passages) == 0:\n",
        "            return None, None\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            embs, doclens = [], []\n",
        "\n",
        "            for passages_batch in batch(passages, self.config.index_bsize * 50):\n",
        "                embs_, doclens_ = self.checkpoint.docFromText(\n",
        "                    passages_batch,\n",
        "                    bsize=self.config.index_bsize,\n",
        "                    keep_dims=\"flatten\",\n",
        "                    showprogress=(not self.use_gpu),\n",
        "                    pool_factor=self.config.pool_factor,\n",
        "                    clustering_mode=self.config.clustering_mode,\n",
        "                    protected_tokens=self.config.protected_tokens,\n",
        "                )\n",
        "                embs.append(embs_)\n",
        "                doclens.extend(doclens_)\n",
        "\n",
        "            embs = torch.cat(embs)\n",
        "\n",
        "        return embs, doclens\n",
        "```\n",
        "\n",
        "IIUC, this is calling `docFromText` on the ColBERT model (`answerai-colbert-small-v1` in our case). I would expect raw ColBERT and RAGatouille to experience equal memory change during this method call but RAGatouille uses <mark>10-15%</mark> more memory for each dataset size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "111HZfDYmgVd"
      },
      "source": [
        "|Indexing Method|Document Size|Initial Memory|Memory Change|Final Memory\n",
        "|:-:|:-:|:-:|:-:|:-:|\n",
        "|ColBERT|100k|732.9 MB|1502.4 MB|2235.3 MB\n",
        "|ColBERT|250k|829.7 MB|1991.1 MB|2820.8 MB\n",
        "|ColBERT|500k|1000.2 MB|2549.8 MB|3550.0 MB\n",
        "|ColBERT|1M|1351.6 MB|3462.0 MB|4813.6 MB\n",
        "|ColBERT|2M|1997.3 MB|4692.3 MB|6689.6 MB\n",
        "|RAGatouille (`use_faiss=True`)|100k|2115.0 MB|1677.3 MB|3792.3 MB\n",
        "|RAGatouille (`True`)|250k|2593.5 MB|2279.7 MB|4873.2 MB\n",
        "|RAGatouille (`True`)|500k|3405.1 MB|3004.6 MB|6409.6 MB\n",
        "|RAGatouille (`use_faiss=False`)|100k|1751.0 MB|1685.6 MB|3436.6 MB\n",
        "|RAGatouille (`False`)|250k|2597.9 MB|2270.4 MB|4868.3 MB\n",
        "|RAGatouille (`False`)|500k|3406.4 MB|3003.8 MB|6410.2 MB\n",
        "|RAGatouille (`False`)|1M|5040.7 MB|3915.3 MB|8956.0 MB\n",
        "|RAGatouille (`False`)|2M|8355.1 MB|5349.5 MB|13704.6 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlMrF6xqmQej"
      },
      "source": [
        "### colbert/indexing/collection_indexer.py/`_sample_embeddings`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXzkeoWR1AZk"
      },
      "source": [
        "`encode_passages` is called from inside `_sample_embeddings`. For ColBERT, `_sample_embeddings` has different starting/final memory values than `_encode_passages` while for RAGatouille they are the same.\n",
        "\n",
        "For example, for 100k documents using raw ColBERT, `_sample_embeddings` increases memory by 797 MB while for `encoder.encode_passages` the memory increases by 1488.8MB.\n",
        "\n",
        "For 100k using RAGatouille, both memory increases the same (1677.3 MB for `use_faiss=True` and 1685.6 MB for `use_faiss=False`). I'm not sure what this means so I asked Claude and got the response:\n",
        "\n",
        "> This discrepancy reveals memory reuse patterns between function calls. In ColBERT, the 1488.8 MB used by `encode_passages` is partially freed before returning to `_sample_embeddings`, resulting in a net increase of 797 MB. In RAGatouille, the memory appears to be retained between calls, showing the same 1677.3 MB increase at both levels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbyVEsDWmWrT"
      },
      "source": [
        "|Indexing Method|Document Size|Initial Memory|Memory Change|Final Memory\n",
        "|:-:|:-:|:-:|:-:|:-:|\n",
        "|ColBERT|100k|732.9 MB|813.8 MB|1546.7 MB\n",
        "|ColBERT|250k|829.7 MB|809.0 MB|1638.7 MB\n",
        "|ColBERT|500k|1000.2 MB|770.1 MB|1770.3 MB\n",
        "|ColBERT|1M|1351.6 MB|813.3 MB|2164.9 MB\n",
        "|ColBERT|2M|1997.3 MB|782.4 MB|2779.7 MB\n",
        "|RAGatouille (`use_faiss=True`)|100k|2115.0 MB|1677.3 MB|3792.3 MB\n",
        "|RAGatouille (`True`)|250k|2593.5 MB|2279.7 MB|4873.2 MB\n",
        "|RAGatouille (`True`)|500k|3405.1 MB|3004.6 MB|6409.6 MB\n",
        "|RAGatouille (`use_faiss=False`)|100k|1751.0 MB|1685.6 MB|3436.6 MB\n",
        "|RAGatouille (`False`)|250k|2597.9 MB|2270.4 MB|4868.3 MB\n",
        "|RAGatouille (`False`)|500k|3406.4 MB|3003.8 MB|6410.2 MB\n",
        "|RAGatouille (`False`)|1M|5040.7 MB|3915.3 MB|8956.0 MB\n",
        "|RAGatouille (`False`)|2M|8355.1 MB|5349.5 MB|13704.6 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLGkqvverCkm"
      },
      "source": [
        "### colbert/indexing/collection_indexer.py/`setup`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGS6wgN32zRc"
      },
      "source": [
        "A similar pattern for `setup`, within which `_sample_embeddings` is called. Raw ColBERT seems more efficient in releasing memory while RAGatouille retains it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9XEKVhCrHtX"
      },
      "source": [
        "|Indexing Method|Document Size|Initial Memory|Memory Change|Final Memory\n",
        "|:-:|:-:|:-:|:-:|:-:|\n",
        "|ColBERT|100k|727.9 MB|817.5 MB|1545.5 MB\n",
        "|ColBERT|250k|815.7 MB|816.4 MB|1632.1 MB\n",
        "|ColBERT|500k|978.2 MB|787.9 MB|1766.1 MB\n",
        "|ColBERT|1M|1305.6 MB|840.2 MB|2145.8 MB\n",
        "|ColBERT|2M|1966.3 MB|822.2 MB|2788.5 MB\n",
        "|RAGatouille (`use_faiss=True`)|100k|3434.3 MB|1677.3 MB|3792.3 MB\n",
        "|RAGatouille (`True`)|250k|3767.5 MB|2279.7 MB|4873.2 MB\n",
        "|RAGatouille (`True`)|500k|4835.0 MB|3004.6 MB|6409.6 MB\n",
        "|RAGatouille (`use_faiss=False`)|100k|2954.8 MB|1685.6  MB|3436.6 MB\n",
        "|RAGatouille (`False`)|250k|3938.8 MB|2270.4 MB|4868.3 MB\n",
        "|RAGatouille (`False`)|500k|4872.2 MB|3003.8 MB|6410.2 MB\n",
        "|RAGatouille (`False`)|1M|6633.3 MB|3915.3 MB|8956.0 MB\n",
        "|RAGatouille (`False`)|2M|10236.8 MB|5349.5 MB|13704.6 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ot8GchsZeV"
      },
      "source": [
        "### colbert/indexing/collection_indexer.py/`train`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA5IFSsvzPfW"
      },
      "source": [
        "IIUC, this function call finds centroids based on a sample of document token embeddings. Interesting to note that the memory change for raw ColBERT is smallest for 1M documents (87.2 MB) and for RAGatouille, 2M docs is the smallest (23.4 MB). For most collection sizes, RAGatouille uses <mark>40-50%</mark> more memory for this operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x_Sry5_meD_"
      },
      "source": [
        "|Indexing Method|Document Size|Initial Memory|Memory Change|Final Memory\n",
        "|:-:|:-:|:-:|:-:|:-:|\n",
        "|ColBERT|100k|1545.5 MB|115.8 MB|1661.3 MB\n",
        "|ColBERT|250k|1632.1 MB|128.8 MB|1760.9 MB\n",
        "|ColBERT|500k|1766.1 MB|124.3 MB|1890.4 MB\n",
        "|ColBERT|1M|2145.8 MB|87.2 MB|2233.0 MB\n",
        "|ColBERT|2M|2788.5 MB|133.5 MB|2921.9 MB\n",
        "|RAGatouille (`use_faiss=True`)|100k|3792.3 MB|179.6 MB|3971.9 MB\n",
        "|RAGatouille (`True`)|250k|4873.2 MB|182.7 MB|5055.9 MB\n",
        "|RAGatouille (`True`)|500k|6409.6 MB|174.1 MB|6583.8 MB\n",
        "|RAGatouille (`use_faiss=False`)|100k|3436.6 MB|175.9 MB|3612.6 MB\n",
        "|RAGatouille (`False`)|250k|4868.3 MB|181.5 MB|5049.8 MB\n",
        "|RAGatouille (`False`)|500k|6410.2 MB|179.2 MB|6589.4 MB\n",
        "|RAGatouille (`False`)|1M|8956.0 MB|191.5 MB|9147.5 MB\n",
        "|RAGatouille (`False`)|2M|13704.6 MB|23.4 MB|13728.1 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFVl5MN8wveb"
      },
      "source": [
        "### colbert/indexing/collection_indexer.py/`index`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKOkT9yozoGv"
      },
      "source": [
        "This is one of the more interesting results---raw ColBERT has a positive memory change during this operation (which IIUC is the indexing of all document token embeddings) while _all_ RAGatouille `index()` operations actually _reduce the memory usage_. Not sure what that means. The final memory for raw ColBERT is less than RAGatouille."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9klgJMowv9E"
      },
      "source": [
        "|Indexing Method|Document Size|Initial Memory|Memory Change|Final Memory\n",
        "|:-:|:-:|:-:|:-:|:-:|\n",
        "|ColBERT|100k|1661.3 MB|287.0 MB|1948.3 MB\n",
        "|ColBERT|250k|1760.9 MB|263.5 MB|2024.4 MB\n",
        "|ColBERT|500k|1890.4 MB|371.9 MB|2262.2 MB\n",
        "|ColBERT|1M|2233.0 MB|599.9 MB|2832.9 MB\n",
        "|ColBERT|2M|2921.9 MB|958.0 MB|3880.0 MB\n",
        "|RAGatouille (`use_faiss=True`)|100k|3971.9 MB|-536.3 MB|3435.6 MB\n",
        "|RAGatouille (`True`)|250k|5055.9 MB|-1375.8 MB|3680.1 MB\n",
        "|RAGatouille (`True`)|500k|6583.8 MB|-1936.3 MB|4647.5 MB\n",
        "|RAGatouille (`use_faiss=False`)|100k|3612.6 MB|-652.4 MB|2960.2 MB\n",
        "|RAGatouille (`False`)|250k|5049.8 MB|-1112.5 MB|3937.3 MB\n",
        "|RAGatouille (`False`)|500k|6589.4 MB|-1906.8 MB|4682.6  MB\n",
        "|RAGatouille (`False`)|1M|9147.5 MB|-2917.3 MB|6230.1 MB\n",
        "|RAGatouille (`False`)|2M|13728.1 MB|-4910.2 MB|8817.9 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo2Vl-klx4l9"
      },
      "source": [
        "### colbert/indexing/collection_indexer.py/`finalize`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2eqCFEH0R2b"
      },
      "source": [
        "This function maps passage IDs to centroid IDs---one of the efficiencies of the PLAID indexing approach. Within each approach (raw ColBERT and RAGatouille) the memory change varies drastically between less than 0 and up to ~500MB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4k1oNQwxDEA"
      },
      "source": [
        "|Indexing Method|Document Size|Initial Memory|Memory Change|Final Memory\n",
        "|:-:|:-:|:-:|:-:|:-:|\n",
        "|ColBERT|100k|1948.3 MB|35.1 MB|1983.3 MB\n",
        "|ColBERT|250k|2024.4 MB|-0.4 MB|2024.0 MB\n",
        "|ColBERT|500k|2262.2 MB|59.2 MB|2321.5 MB\n",
        "|ColBERT|1M|2832.9 MB|201.5 MB|3034.4 MB\n",
        "|ColBERT|2M|3880.0 MB|490.2 MB|4370.2 MB\n",
        "|RAGatouille (`use_faiss=True`)|100k|3435.6 MB|-1.3 MB|3434.3 MB\n",
        "|RAGatouille (`True`)|250k|3680.1 MB|87.4 MB|3767.5 MB\n",
        "|RAGatouille (`True`)|500k|4647.5 MB|187.5 MB|4835.0 MB\n",
        "|RAGatouille (`use_faiss=False`)|100k|2960.2 MB|-5.3 MB|2954.8 MB\n",
        "|RAGatouille (`False`)|250k|3937.3 MB|1.5 MB|3938.8 MB\n",
        "|RAGatouille (`False`)|500k|4682.6 MB|189.6 MB|4872.2 MB\n",
        "|RAGatouille (`False`)|1M|6230.1 MB|403.2 MB|6633.3 MB\n",
        "|RAGatouille (`False`)|2M|8817.9 MB|1418.9 MB|10236.8 MB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idhcUlUkOmkr"
      },
      "source": [
        "## Indexing Time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbPglfuSOntk"
      },
      "source": [
        "I didn't measure runtime for each run, but some observations:\n",
        "\n",
        "- During passage encoding (25k passages per iteration) ColBERT took about <mark>20 seconds/it</mark> and RAGatouille took about <mark>110 seconds/it</mark>. Note that without profiling ColBERT took about 11/seconds/it and RAGatouille 22 seconds/it.\n",
        "- ColBERT encoding lasted 4, 10, 20, 40 and 80 iterations for 100k, 250k, 500k, 1M and 2M docs. RAGatouille always overshot it (e.g. 14 iters for 250k docs or 22 iters for 500k docs).\n",
        "- Overall ColBERT profiling took ~2 hours while RAGatouille took ~16 hours.\n",
        "- It took a lot of time before the final encoding takes place, I think that's because of the initial \"planning\" step that ColBERT and RAGatouille both do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHQDOVxk39B9"
      },
      "source": [
        "## Indexing 10k Documents (PyTorch vs FAISS K-means Clustering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx86kO1qPlAJ"
      },
      "source": [
        "While I was experimenting indexing scripts with 10k documents I noticed curious behavior. For 10k documents, with `use_faiss=False`, RAGatouille attempts to use PyTorch for K-means clustering. The memory usage for `encoder.encode_passages` during this attempt:\n",
        "\n",
        "```\n",
        "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
        "=============================================================\n",
        "   146   1849.2 MiB   1849.2 MiB           1           @profile\n",
        "   147                                                 def _encode_passages_profiled(*args, **kwargs):\n",
        "   148   2675.7 MiB    826.5 MiB           1               return self.encoder.encode_passages(*args, **kwargs)\n",
        "```\n",
        "\n",
        "It then runs into an OOM error:\n",
        "\n",
        "```\n",
        "PyTorch-based indexing did not succeed with error: CUDA out of memory. Tried to allocate 27.55 GiB. GPU 0 has a total capacity of 47.51 GiB of which 4.88 GiB is free.\n",
        "```\n",
        "\n",
        "And switches to FAISS K-means. The memory usage for `encoder.encode_passages` changes (note the drop from an increase of 826.5 MB to an increase of 373 MB, but an increase in initial memory usage from 1849.2 MB to 2652.6MB):\n",
        "\n",
        "```\n",
        "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
        "=============================================================\n",
        "   146   2652.6 MiB   2652.6 MiB           1           @profile\n",
        "   147                                                 def _encode_passages_profiled(*args, **kwargs):\n",
        "   148   3025.6 MiB    373.0 MiB           1               return self.encoder.encode_passages(*args, **kwargs)\n",
        "```\n",
        "\n",
        "When I run the script with `use_faiss=True`, the `encoder.encode_passages` memory usage reflects the PyTorch attempt, whereas I would expect the memory increase to be 373 MB:\n",
        "\n",
        "```\n",
        "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
        "=============================================================\n",
        "   146   1853.4 MiB   1853.4 MiB           1           @profile\n",
        "   147                                                 def _encode_passages_profiled(*args, **kwargs):\n",
        "   148   2678.8 MiB    825.4 MiB           1               return self.encoder.encode_passages(*args, **kwargs)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz16Mpy-OY4l"
      },
      "source": [
        "## Final Thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTlqGU4_OaA7"
      },
      "source": [
        "This exercise has left me with more questions than answers that I need to explore:\n",
        "\n",
        "- Is this the best way to go about profiling memory?\n",
        "- Am I interpreting the memory profiling results correctly?\n",
        "- Why does RAGatouille have a higher initial memory before indexing starts?\n",
        "- Why does RAGatouille retain more memory after indexing than ColBERT?\n",
        "- Why does RAGatouille memory usage drastically _decrease_ during `index()`?\n",
        "- Why does RAGatouille max out CUDA memory for 10k documents? Related to [Issue #247](https://github.com/AnswerDotAI/RAGatouille/issues/247).\n",
        "- Why does RAGatouille's memory usage when `use_faiss=True` match PyTorch K-means' memory usage and not the FAISS K-means' memory usage after PyTorch's attempt fails with OOM?\n",
        "\n",
        "Additionally, and probably relatedly, I still haven't figured out what is causing the large memory spike in the diagram below:\n",
        "\n",
        "![CPU memory usage while indexing 250k documents](1.png)\n",
        "\n",
        "The largest memory value profiled while indexing 250k docs using RAGatouille was 5049.8 MB but the chart shows a spike up to ~8GB. Where's the ghost 3GB?\n",
        "\n",
        "TBD."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
