{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Using TinyInstruct-33M for `financial_phrasebank` Sentiment Classification\n",
    "date: \"2024-08-05\"\n",
    "author: Vishal Bakshi\n",
    "description: In this blog post I find that TinyInstruct-33M does not follow instructions that deviate from its training data.\n",
    "categories:\n",
    "    - python\n",
    "    - LLM\n",
    "    - TinySentiment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pip installs\"\n",
    "\n",
    "!pip install transformers~=4.37.2 -qq\n",
    "!pip install huggingface_hub~=0.20.3 -qq\n",
    "!pip install datasets~=2.16.1 -qq\n",
    "!pip install accelerate -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:42:21.611068Z",
     "iopub.status.busy": "2024-08-06T02:42:21.609748Z",
     "iopub.status.idle": "2024-08-06T02:42:23.611829Z",
     "shell.execute_reply": "2024-08-06T02:42:23.610638Z",
     "shell.execute_reply.started": "2024-08-06T02:42:21.611018Z"
    }
   },
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show imports\"\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline, logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "model_name = \"roneneldan/TinyStories-Instruct-33M\"\n",
    "\n",
    "# create pipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_name,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# load dataset\n",
    "dataset = load_dataset(\n",
    "    \"financial_phrasebank\", \"sentences_allagree\", \n",
    "    split=\"train\"  # note that the dataset does not have a default test split\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll see how accurately the TinyInstruct-33M model can classify sentiment in the `financial_phrasebank` dataset out-of-the-box, \n",
    "without any fine-tuning. I expect that the model will not perform well for two reasons:\n",
    "\n",
    "1. it's trained specifically to generate stories given a set of prompts.\n",
    "2. it's vocabulary is at a much lower grade level than the `financial_phrasebank` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Warmup Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by prompting TinyInstruct-33M with a prompt format it's trained on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:13:45.070571Z",
     "iopub.status.busy": "2024-08-06T02:13:45.070027Z",
     "iopub.status.idle": "2024-08-06T02:13:45.077991Z",
     "shell.execute_reply": "2024-08-06T02:13:45.076589Z",
     "shell.execute_reply.started": "2024-08-06T02:13:45.070515Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Summary: Lily and Timmy build a sandcastle together and learn to compromise, but it gets knocked over by a gust of wind.\n",
    "They find beauty in the broken sandcastle and play happily with a butterfly.\n",
    "Features: Dialogue, Foreshadowing, Twist\n",
    "Sentence: One day, she went to the park and saw a beautiful butterfly.\n",
    "Words: disagree, network, beautiful\n",
    "Story: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:14:34.224897Z",
     "iopub.status.busy": "2024-08-06T02:14:34.224532Z",
     "iopub.status.idle": "2024-08-06T02:14:35.603560Z",
     "shell.execute_reply": "2024-08-06T02:14:35.602413Z",
     "shell.execute_reply.started": "2024-08-06T02:14:34.224870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Once upon a time, there were two best friends, Lily and Timmy. Every day they would play together and have lots of fun. \n",
      "\n",
      "One day, they decided to build a sandcastle. Lily wanted to make it really tall, but Timmy wanted to make it straight. They disagreed and argued for a long time. \n",
      "\n",
      "Finally, Lily said, \"Let's make it really tall, Timmy!\" \n",
      "\n",
      "Timmy agreed and they started to build. They worked together and soon they had built the most beautiful sandcastle ever. \n",
      "\n",
      "But then something unexpected happened. A big gust of wind blew through the park and knocked over their sandcastle! \n",
      "\n",
      "Lily and Timmy were sad, but they decided to find something else to do. They found a beautiful butterfly and decided to make it even better. \n",
      "\n",
      "They were so happy and they spent the rest of the day playing with the butterfly. \n",
      "\n",
      "The end\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pipeline\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=True, \n",
    "    temperature=0.3,\n",
    "    return_full_text=False)\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The model responds appropriately to the type of prompt it's trained on. Next, I'll try a simple prompt that contains language the model should be\n",
    "able to understand (given that it understands words like `'beautiful'`, `'Foreshadowing'`, and `'network'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:16:51.255439Z",
     "iopub.status.busy": "2024-08-06T02:16:51.254982Z",
     "iopub.status.idle": "2024-08-06T02:16:51.260550Z",
     "shell.execute_reply": "2024-08-06T02:16:51.259524Z",
     "shell.execute_reply.started": "2024-08-06T02:16:51.255405Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"What color is an apple?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:16:55.593957Z",
     "iopub.status.busy": "2024-08-06T02:16:55.593591Z",
     "iopub.status.idle": "2024-08-06T02:16:56.201690Z",
     "shell.execute_reply": "2024-08-06T02:16:56.199460Z",
     "shell.execute_reply.started": "2024-08-06T02:16:55.593927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "”\n",
      "\n",
      "The little girl smiled and said, “It’s a red apple.”\n",
      "\n",
      "The man smiled and said, “That’s right! Apples are healthy and delicious.”\n",
      "\n",
      "The little girl smiled and said, “I like apples!”\n",
      "\n",
      "The man and the little girl both laughed and enjoyed the apple together. They had a wonderful time in the park.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pipeline\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=True, \n",
    "    temperature=0.3,\n",
    "    return_full_text=False)\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suppose it indirectly answers the question by including `\"red apple\"` in the context of the story. Does it respond to an instruction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:18:18.736901Z",
     "iopub.status.busy": "2024-08-06T02:18:18.736423Z",
     "iopub.status.idle": "2024-08-06T02:18:18.742640Z",
     "shell.execute_reply": "2024-08-06T02:18:18.741516Z",
     "shell.execute_reply.started": "2024-08-06T02:18:18.736866Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"What color is a banana? Respond with one word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:18:31.158096Z",
     "iopub.status.busy": "2024-08-06T02:18:31.157740Z",
     "iopub.status.idle": "2024-08-06T02:18:31.201104Z",
     "shell.execute_reply": "2024-08-06T02:18:31.200037Z",
     "shell.execute_reply.started": "2024-08-06T02:18:31.158071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", like\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pipeline\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=2,\n",
    "    do_sample=True, \n",
    "    temperature=0.3,\n",
    "    return_full_text=False)\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:19:45.310876Z",
     "iopub.status.busy": "2024-08-06T02:19:45.310364Z",
     "iopub.status.idle": "2024-08-06T02:19:45.316058Z",
     "shell.execute_reply": "2024-08-06T02:19:45.314743Z",
     "shell.execute_reply.started": "2024-08-06T02:19:45.310842Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"What color is an orange? Respond with one word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:19:46.890431Z",
     "iopub.status.busy": "2024-08-06T02:19:46.889920Z",
     "iopub.status.idle": "2024-08-06T02:19:46.919050Z",
     "shell.execute_reply": "2024-08-06T02:19:46.917750Z",
     "shell.execute_reply.started": "2024-08-06T02:19:46.890389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pipeline\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=2,\n",
    "    do_sample=True, \n",
    "    temperature=0.9,\n",
    "    return_full_text=False)\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:19:54.578293Z",
     "iopub.status.busy": "2024-08-06T02:19:54.577743Z",
     "iopub.status.idle": "2024-08-06T02:19:54.583870Z",
     "shell.execute_reply": "2024-08-06T02:19:54.582273Z",
     "shell.execute_reply.started": "2024-08-06T02:19:54.578249Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"What color is a crow? Respond with one word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:19:56.015766Z",
     "iopub.status.busy": "2024-08-06T02:19:56.015418Z",
     "iopub.status.idle": "2024-08-06T02:19:56.040427Z",
     "shell.execute_reply": "2024-08-06T02:19:56.039375Z",
     "shell.execute_reply.started": "2024-08-06T02:19:56.015740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": C\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pipeline\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=2,\n",
    "    do_sample=True, \n",
    "    temperature=0.6,\n",
    "    return_full_text=False)\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope! Trying different simple prompts (with different temperature levels) yields unsatisfactory results. The model is not following the given instruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting TinyInstruct-33M with `financial_phrasebank` Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that TinyInstruct-33M can't follow simple instructions that differ from its training data, I am expecting it won't follow sentiment classification\n",
    "for the `financial_phrasebank` datset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by giving it my best-performing phi-2 prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:29:04.542225Z",
     "iopub.status.busy": "2024-08-06T02:29:04.541728Z",
     "iopub.status.idle": "2024-08-06T02:29:04.550136Z",
     "shell.execute_reply": "2024-08-06T02:29:04.548918Z",
     "shell.execute_reply.started": "2024-08-06T02:29:04.542188Z"
    }
   },
   "outputs": [],
   "source": [
    "promptM = \"\"\"Your task is to analyze the sentiment (from an investor's perspective) of the text below.\n",
    "\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Instruct: According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "Output: neutral\n",
    "\n",
    "Instruct: For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "Output: positive\n",
    "\n",
    "Instruct: Jan. 6 -- Ford is struggling in the face of slowing truck and SUV sales and a surfeit of up-to-date , gotta-have cars .\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "Output: negative\n",
    "\n",
    "Instruct: At the request of Finnish media company Alma Media 's newspapers , research manager Jari Kaivo-oja at the Finland Futures Research Centre at the Turku School of Economics has drawn up a future scenario for Finland 's national economy by using a model developed by the University of Denver .\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "Output: neutral\n",
    "\n",
    "Instruct: STOCK EXCHANGE ANNOUNCEMENT 20 July 2006 1 ( 1 ) BASWARE SHARE SUBSCRIPTIONS WITH WARRANTS AND INCREASE IN SHARE CAPITAL A total of 119 850 shares have been subscribed with BasWare Warrant Program .\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "Output: neutral\n",
    "\n",
    "Instruct: A maximum of 666,104 new shares can further be subscribed for by exercising B options under the 2004 stock option plan .\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "Output: neutral\n",
    "\n",
    "Instruct: In the third quarter of 2010 , net sales increased by 5.2 % to EUR 205.5 mn , and operating profit by 34.9 % to EUR 23.5 mn .\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "Output:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:29:06.806748Z",
     "iopub.status.busy": "2024-08-06T02:29:06.806237Z",
     "iopub.status.idle": "2024-08-06T02:29:06.873205Z",
     "shell.execute_reply": "2024-08-06T02:29:06.872068Z",
     "shell.execute_reply.started": "2024-08-06T02:29:06.806645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". It is black and\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pipeline\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=5,\n",
    "    do_sample=True, \n",
    "    temperature=0.3,\n",
    "    return_full_text=False)\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope! That doesn't seem to work. I'll give it a simpler prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:29:22.180731Z",
     "iopub.status.busy": "2024-08-06T02:29:22.179659Z",
     "iopub.status.idle": "2024-08-06T02:29:22.186627Z",
     "shell.execute_reply": "2024-08-06T02:29:22.185087Z",
     "shell.execute_reply.started": "2024-08-06T02:29:22.180691Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Your task is to analyze the sentiment (from an investor's perspective) of the text below.\n",
    "\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "\n",
    "According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\n",
    "Respond with only one of these words: negative, positive, or neutral. If the amount of money is not explicitly increasing or decreasing, respond with neutral.\n",
    "Output:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:29:32.590084Z",
     "iopub.status.busy": "2024-08-06T02:29:32.589618Z",
     "iopub.status.idle": "2024-08-06T02:29:32.633302Z",
     "shell.execute_reply": "2024-08-06T02:29:32.632314Z",
     "shell.execute_reply.started": "2024-08-06T02:29:32.590049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary: Two countries\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pipeline\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=5,\n",
    "    do_sample=True, \n",
    "    temperature=0.3,\n",
    "    return_full_text=False)\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TinyInstruct-33M does not seem aligned to this type of instruction following. \n",
    "As a final party trick I'll see if setting up the `financial_phrasebank` data in the model's training format nudges it in the right direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:35:06.188139Z",
     "iopub.status.busy": "2024-08-06T02:35:06.187481Z",
     "iopub.status.idle": "2024-08-06T02:35:06.193048Z",
     "shell.execute_reply": "2024-08-06T02:35:06.191732Z",
     "shell.execute_reply.started": "2024-08-06T02:35:06.188111Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Summary: For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier,\n",
    "while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .\n",
    "Features: positive\n",
    "Sentence: positive\n",
    "Words: positive\n",
    "Story: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:36:23.751720Z",
     "iopub.status.busy": "2024-08-06T02:36:23.750268Z",
     "iopub.status.idle": "2024-08-06T02:36:24.524912Z",
     "shell.execute_reply": "2024-08-06T02:36:24.523900Z",
     "shell.execute_reply.started": "2024-08-06T02:36:23.751671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Once upon a time there was a little girl called Athena. She was three years old and loved to play with her friends. One day, Athena's friends asked her to come to the park with them. When she arrived, Athena noticed that everyone was wearing the same type of clothing as her. She was confused and asked her friends what they were doing.\n",
      "\n",
      "Athenaces were announced that they were called distinguishedIN Neck�a, and she was the official mascot of the local Park\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pipeline\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True, \n",
    "    temperature=0.2,\n",
    "    return_full_text=False)\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:37:01.729712Z",
     "iopub.status.busy": "2024-08-06T02:37:01.728768Z",
     "iopub.status.idle": "2024-08-06T02:37:01.733535Z",
     "shell.execute_reply": "2024-08-06T02:37:01.732742Z",
     "shell.execute_reply.started": "2024-08-06T02:37:01.729684Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"Summary: For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier,\n",
    "while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .\n",
    "Features: respond with one word (negative, positive, neutral)\n",
    "Sentence: respond with one word (negative, positive, neutral)\n",
    "Words: respond with one word (negative, positive, neutral)\n",
    "Story: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-06T02:37:47.219918Z",
     "iopub.status.busy": "2024-08-06T02:37:47.219023Z",
     "iopub.status.idle": "2024-08-06T02:37:47.896880Z",
     "shell.execute_reply": "2024-08-06T02:37:47.895629Z",
     "shell.execute_reply.started": "2024-08-06T02:37:47.219889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Once upon a time there was a quarter yearrissa. She was a quarterstruck shopper and loved to move around. Every year, she would go to a different town and meet new people.\n",
      "\n",
      "One year, she was asked to come to a special place. It was called \"Adopt A Receive\". She was excited to go and meet new people.\n",
      "\n",
      "When she arrived at the place, she saw a big sign that said \"Adwin Opener\".\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "#| code-summary: \"Show pipeline\"\n",
    "\n",
    "output = pipe(\n",
    "    prompt,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True, \n",
    "    temperature=0.1,\n",
    "    return_full_text=False)\n",
    "\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that at a low temperature (`0.1`) TinyInstruct has snuck in the word \"quarter\" from the `financial_phrasebank` sentence. However, it still does not classify\n",
    "the sentiment of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was probably the least exciting LLM exercise I've ever done, but I felt it was necessary to at least give TinyInstruct-33M a fair shot\n",
    "at classifying `financial_phrasebank` sentiment without fine-tuning it.\n",
    "\n",
    "\n",
    "In a separate notebook, I'll fine-tune TinyInstruct-33M on a portion of the `financial_phrasebank` \n",
    "dataset and see how it performs on a held out test set.\n",
    "\n",
    "I hope you enjoyed this (short) blog post! Follow me on Twitter [@vishal_learner](https://twitter.com/vishal_learner)."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
