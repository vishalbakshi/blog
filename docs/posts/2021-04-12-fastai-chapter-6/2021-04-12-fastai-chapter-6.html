<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vishal Bakshi">
<meta name="dcterms.date" content="2021-04-12">

<title>Vishal Bakshi’s Blog - fast.ai Chapter 6: Classification Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Vishal Bakshi’s Blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#setup" id="toc-setup" class="nav-link active" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#the-data" id="toc-the-data" class="nav-link" data-scroll-target="#the-data">The Data</a></li>
  <li><a href="#constructing-a-datablock" id="toc-constructing-a-datablock" class="nav-link" data-scroll-target="#constructing-a-datablock">Constructing a DataBlock</a></li>
  <li><a href="#chapter-4-two-digit-mnist-classifier" id="toc-chapter-4-two-digit-mnist-classifier" class="nav-link" data-scroll-target="#chapter-4-two-digit-mnist-classifier">Chapter 4: Two-Digit MNIST Classifier</a></li>
  <li><a href="#chapter-5-37-breed-pet-classifier" id="toc-chapter-5-37-breed-pet-classifier" class="nav-link" data-scroll-target="#chapter-5-37-breed-pet-classifier">Chapter 5: 37 Breed Pet Classifier</a></li>
  <li><a href="#binary-cross-entropy-loss" id="toc-binary-cross-entropy-loss" class="nav-link" data-scroll-target="#binary-cross-entropy-loss">Binary Cross Entropy Loss</a></li>
  <li><a href="#mult-label-classification-accuracy" id="toc-mult-label-classification-accuracy" class="nav-link" data-scroll-target="#mult-label-classification-accuracy">Mult-Label Classification Accuracy</a></li>
  <li><a href="#training-the-model" id="toc-training-the-model" class="nav-link" data-scroll-target="#training-the-model">Training the Model</a></li>
  <li><a href="#regression" id="toc-regression" class="nav-link" data-scroll-target="#regression">Regression</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">fast.ai Chapter 6: Classification Models</h1>
  <div class="quarto-categories">
    <div class="quarto-category">deep learning</div>
    <div class="quarto-category">python</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Vishal Bakshi </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 12, 2021</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="boat-train.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">An example image from the image dataset used in this lesson. The image has a train going over a bridge with skyscrapers in the background.</figcaption><p></p>
</figure>
</div>
<p>This chapter introduced two more classification models:</p>
<ul>
<li>Multi-label classification, for when you want to predict more than one or no label per image</li>
<li>Regression, for when you want to predict a quantity instead of a category for an image</li>
</ul>
<p>In this chapter the authors walk us through in the chapter is the PASCAL dataset.</p>
<hr>
<p>Here’s my video walkthrough for this notebook:</p>
<div class="cell" data-outputid="1a6bdd0a-f7e6-4b3e-a669-331b5c129132" data-execution_count="6">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>HTML(<span class="st">'&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/cJOtrHtzDSU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<iframe width="560" height="315" src="https://www.youtube.com/embed/cJOtrHtzDSU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>
</div>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
</section>
<section id="the-data" class="level2">
<h2 class="anchored" data-anchor-id="the-data">The Data</h2>
<p>fastai comes with datasets available for download using the <code>URLs</code> object. We will use the <code>PASCAL_2007</code> dataset.</p>
<div class="cell" data-outputid="16304d3e-3924-4c1c-cacb-df234b2e72b7">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># download the dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.PASCAL_2007)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#read label CSV into a DataFrame</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'train.csv'</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="4">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>fname</th>
      <th>labels</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>000005.jpg</td>
      <td>chair</td>
      <td>True</td>
    </tr>
    <tr>
      <th>1</th>
      <td>000007.jpg</td>
      <td>car</td>
      <td>True</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000009.jpg</td>
      <td>horse person</td>
      <td>True</td>
    </tr>
    <tr>
      <th>3</th>
      <td>000012.jpg</td>
      <td>car</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>000016.jpg</td>
      <td>bicycle</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>Next, they have us go through some pandas fundamentals for accessing data in a DataFrame</p>
<div class="cell" data-outputid="08830681-b3f1-4bb0-fab2-c1699ad87e31">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># accessing all rows and the 0th column</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df.iloc[:,<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>0       000005.jpg
1       000007.jpg
2       000009.jpg
3       000012.jpg
4       000016.jpg
           ...    
5006    009954.jpg
5007    009955.jpg
5008    009958.jpg
5009    009959.jpg
5010    009961.jpg
Name: fname, Length: 5011, dtype: object</code></pre>
</div>
</div>
<div class="cell" data-outputid="e3da6177-52c8-4df6-88e6-33eb4b17d107">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># accessing all columns for the 0th row</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>df.iloc[<span class="dv">0</span>,:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>fname       000005.jpg
labels           chair
is_valid          True
Name: 0, dtype: object</code></pre>
</div>
</div>
<div class="cell" data-outputid="ac4cfc90-cb4d-4f90-9654-a3b3d5a8ecab">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># trailing :s are not needed</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>df.iloc[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>fname       000005.jpg
labels           chair
is_valid          True
Name: 0, dtype: object</code></pre>
</div>
</div>
<div class="cell" data-outputid="bc5e442c-5d1c-47bf-8378-26688c928376">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># accessing a column by its name</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'fname'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>0       000005.jpg
1       000007.jpg
2       000009.jpg
3       000012.jpg
4       000016.jpg
           ...    
5006    009954.jpg
5007    009955.jpg
5008    009958.jpg
5009    009959.jpg
5010    009961.jpg
Name: fname, Length: 5011, dtype: object</code></pre>
</div>
</div>
<div class="cell" data-outputid="c353b4b2-595f-439e-bce7-811b9eb51535">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># creating a new DataFrame and performing operations on it</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.DataFrame()</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># adding a new column</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">'a'</span>] <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>]</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>df1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>a</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-outputid="85f37376-2a9f-4e75-f4fa-df464bef963d">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># adding a new column</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">'b'</span>] <span class="op">=</span> [<span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># adding two columns</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">'a'</span>] <span class="op">+</span> df1[<span class="st">'b'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>0    11
1    22
2    33
3    44
dtype: int64</code></pre>
</div>
</div>
</section>
<section id="constructing-a-datablock" class="level2">
<h2 class="anchored" data-anchor-id="constructing-a-datablock">Constructing a DataBlock</h2>
<p>A DataBlock can be used to create Datasets from which DataLoaders can be created to use during training. A DataBlock is an object which contains the data and has helper functions which can access and transform the data.</p>
<p>They start by creating an empty DataBlock</p>
<div class="cell" data-outputid="ccd8e189-d72a-464e-a3ad-48b0f029b33f">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>dblock <span class="op">=</span> DataBlock()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>dblock</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>&lt;fastai.data.block.DataBlock at 0x7efe5c559d90&gt;</code></pre>
</div>
</div>
<p>The DataFrame with filenames and labels can be fed to the DataBlock to create a Datasets object, which is &gt; an iterator that contains a training Dataset and validation Dataset</p>
<p>Each dataset is</p>
<blockquote class="blockquote">
<p>a collection that returns a tuple of your independent and dependent variable for a single item</p>
</blockquote>
<p>A Dataet created from an empty DataBlock (meaning, a DataBlock with no helper functions to tell it how the data is structured and accessed) will contain a tuple for each row of the DataFrame, where both values of the tuple are the same row.</p>
<div class="cell" data-outputid="3382a2cd-f036-43be-8894-fd33c5fc3ef5">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>dsets <span class="op">=</span> dblock.datasets(df)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>dsets.train[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>(fname                   005618.jpg
 labels      tvmonitor chair person
 is_valid                      True
 Name: 2820, dtype: object, fname                   005618.jpg
 labels      tvmonitor chair person
 is_valid                      True
 Name: 2820, dtype: object)</code></pre>
</div>
</div>
<p>What we want is for the DataBlock to create Datasets of (independent, dependent) values. In this case, the independent variable is the image and the dependent variable is a list of labels.</p>
<p>In order to parse the DataFrame rows, we need to provide two helper functions to the DataBlock: <code>get_x</code> and <code>get_y</code>. In ordert to convert them to the appropriate objects that will be used in training, we need to provide two more arguments: <code>ImageBlock</code> and <code>MultiCategoryBlock</code>. In order for the DataBlock to correctly split the data into training and validation datasets, we need to define a <code>splitter</code> function and pass it as an argument as well.</p>
<p><code>get_x</code> will access the filename from each row of the DataFrame and convert it to a file path.</p>
<p><code>get_y</code> will access the labels from each row and split them into a list.</p>
<p><code>ImageBlock</code> will take the file path and convert it to a <code>PILImage</code> object.</p>
<p><code>MultiCategoryBlock</code> will convert the list of labels to a one-hot encoded tensor using the Dataset’s <code>vocab</code>.</p>
<p><code>splitter</code> will explicitly choose for the validation set the rows where <code>is_valid</code> is <code>True</code>.</p>
<p><code>RandomResizedCrop</code> will ensure that each image is the same size, which is a requirement for creating a tensor with all images.</p>
<div class="cell" data-outputid="1158966c-312d-4927-d517-917620e40187">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_x(row): <span class="cf">return</span> path<span class="op">/</span><span class="st">'train'</span><span class="op">/</span>row[<span class="st">'fname'</span>]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_y(row): <span class="cf">return</span> row[<span class="st">'labels'</span>].split(<span class="st">' '</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> splitter(df):</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  train <span class="op">=</span> df.index[<span class="op">~</span>df[<span class="st">'is_valid'</span>]].tolist()</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>  valid <span class="op">=</span> df.index[df[<span class="st">'is_valid'</span>]].tolist()</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> train, valid</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>dblock <span class="op">=</span> DataBlock(</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    blocks<span class="op">=</span>(ImageBlock, MultiCategoryBlock),</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    splitter<span class="op">=</span>splitter,</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    get_x<span class="op">=</span>get_x,</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    get_y<span class="op">=</span>get_y,</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    item_tfms <span class="op">=</span> RandomResizedCrop(<span class="dv">128</span>, min_scale<span class="op">=</span><span class="fl">0.35</span>))</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>dsets <span class="op">=</span> dblock.datasets(df)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> dblock.dataloaders(df)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>dsets.train[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(PILImage mode=RGB size=500x333,
 TensorMultiCategory([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0.]))</code></pre>
</div>
</div>
<p>The Datasets <code>vocab</code> is a list of alphabetically ordered unique labels:</p>
<div class="cell" data-outputid="d65817bc-ade5-4600-d68a-864e033625f3">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>dsets.train.vocab</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']</code></pre>
</div>
</div>
<p>Let me breakdown the tuple returned by <code>dsets.train[0]</code>. The first value is a <code>PILImage</code>object which can be viewed by calling its <code>show()</code> method:</p>
<div class="cell" data-outputid="41eae50e-77d8-4cac-93ed-248178ea9ebd">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>dsets.train[<span class="dv">0</span>][<span class="dv">0</span>].show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7efe5c3764d0&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-18-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>The second value is a one-hot encoded list, where <code>1</code>s are in the location of the labels in the corresponding vocab list. I’ll use the <code>torch.where</code> method to access the indices where there are <code>1</code>s:</p>
<div class="cell" data-outputid="0059928c-46db-4c6b-ed53-3a7082c2de36">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>torch.where(dsets.train[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">==</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>(TensorMultiCategory([6]),)</code></pre>
</div>
</div>
<div class="cell" data-outputid="2903c2f5-6ffd-423d-d599-5cfe5b350ad1">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>dsets.train.vocab[torch.where(dsets.train[<span class="dv">0</span>][<span class="dv">1</span>]<span class="op">==</span><span class="dv">1</span>)[<span class="dv">0</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>(#1) ['car']</code></pre>
</div>
</div>
<div class="cell" data-outputid="1852fda1-02d2-475d-b908-233c88f34659">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>dls.show_batch(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="chapter-4-two-digit-mnist-classifier" class="level2">
<h2 class="anchored" data-anchor-id="chapter-4-two-digit-mnist-classifier">Chapter 4: Two-Digit MNIST Classifier</h2>
<p>I’ll first review the loss function used in the single-label classification models created in Chapters 4 and 5 before reviewing Binary Cross Entropy Loss introduced in this chapter.</p>
<p>In this chapter, we built a image classifier which would predict if an input image was an of the digit 3 or the digit 7.</p>
<p>The target (or expected outcome) is a list of 0s (for 7) and 1s (for 3). If we gave a batch of images of a 3, a 7 and a 3, the target would be <code>[1, 0, 1]</code>.</p>
<p>Suppose the model predicted the following values: <code>[0.9, 0.4, 0.2]</code> where each value represented the probability or confidence it had that each image was a 3.</p>
<p>Loss represents the positive difference between the target and the prediction: - 1 - prediction when target == 1 - prediction when target == 0</p>
<p>For the first image, the model had 90% confidence it was a 3, and it was indeed a 3. The loss is <code>1 - 0.9</code> = <code>0.1</code>.</p>
<p>For the second second image, the model had a 40% confidence it was a three, and the image was of a 7. The loss is <code>0.4</code>.</p>
<p>For the last image, the model had a 20% confidence it was a 3, and the image was a 3. The loss is <code>1 - 0.2</code> = <code>0.8</code>.</p>
<p>The average of these three losses is <code>1.3/3</code> or <code>0.433</code>.</p>
<p>The following cell illustrates this with code:</p>
<div class="cell" data-outputid="552355a5-b7c2-4cc0-b33e-9594d49f65a9">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mnist_loss(predictions, targets):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> torch.where(targets<span class="op">==</span><span class="dv">1</span>, <span class="dv">1</span><span class="op">-</span>predictions, predictions).mean()</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>targets <span class="op">=</span> tensor([<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>])</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> tensor([<span class="fl">0.9</span>, <span class="fl">0.4</span>, <span class="fl">0.2</span>])</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>mnist_loss(predictions<span class="op">=</span>predictions, targets<span class="op">=</span>targets)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor(0.4333)</code></pre>
</div>
</div>
<p>The assumption that this loss function makes is that the predictions are always between 0 and 1. That may not always be true! In order to make this assumption explicit, we take the sigmoid of the prediction before calculating the loss. The sigmoid function outputs a value between 0 and 1 for any input value.</p>
<div class="cell" data-outputid="bf8fa712-34f7-4592-d96d-0a6d91082b0f">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>tensor([<span class="fl">0.4</span>,<span class="op">-</span><span class="dv">100</span>,<span class="dv">200</span>]).sigmoid()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([0.5987, 0.0000, 1.0000])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mnist_loss(predictions, targets):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>  predictions <span class="op">=</span> predictions.sigmoid()</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> torch.where(targets<span class="op">==</span><span class="dv">1</span>, <span class="dv">1</span><span class="op">-</span>predictions, predictions).mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="chapter-5-37-breed-pet-classifier" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5-37-breed-pet-classifier">Chapter 5: 37 Breed Pet Classifier</h2>
<p>In this chapter, we train an image classifier that when given an input image, predicts which of the 37 pet breeds the image shows. The loss function needs to handle 37 activations for each image. In order to ensure the sum of those activations equals 1.0—so that the highest activation represents the model’s highest confidence—the softmax function is used. In order to increase the separation between probabilities, the softmax function’s output is passed through the logarithm function, and the negative value is taken. The combination of softmax and (negative) logarithm is called <em>cross entropy loss</em>.</p>
<p>Suppose we had 4 images in a batch. The model would output activations something like this:</p>
<div class="cell" data-outputid="2e3b1d04-57bc-4e2a-9235-321e94207af5">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a pseudo-random 4 x 37 tensor </span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># with values from -2 to 2</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>acts <span class="op">=</span> (<span class="op">-</span><span class="dv">2</span> <span class="op">-</span> <span class="dv">2</span>) <span class="op">*</span> torch.rand(<span class="dv">4</span>, <span class="dv">37</span>) <span class="op">+</span> <span class="dv">2</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>acts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([[-1.9994e+00,  7.0629e-01, -1.8230e+00,  8.6118e-02,  8.8579e-01,
         -9.7763e-01,  9.7619e-01,  5.4613e-01,  9.2020e-01,  8.2653e-01,
         -1.3831e+00,  1.2236e+00, -4.2582e-01,  1.1371e+00,  1.2409e+00,
          1.4403e-02, -9.2988e-01, -1.1939e+00, -9.9743e-01, -1.9572e+00,
         -6.8404e-02,  6.2455e-01,  8.6748e-01, -1.4574e+00, -1.4451e+00,
          1.1349e-01,  1.7424e+00,  6.5414e-02, -1.2517e+00, -1.9933e+00,
         -1.5570e+00,  1.3880e+00,  1.5099e+00,  6.2576e-01, -1.4279e-03,
          1.7448e+00,  1.9862e+00],
        [ 4.5219e-02,  4.6843e-01, -1.1474e+00, -1.8876e+00, -5.7879e-01,
          6.9787e-01, -7.2457e-02, -1.7235e+00, -9.9028e-01,  1.2248e+00,
          6.4889e-01,  5.0363e-01,  1.8472e-01, -1.0468e+00, -1.0113e+00,
         -1.0628e+00,  1.9783e+00, -1.8394e+00, -8.0410e-02, -5.9383e-01,
         -1.6868e+00, -2.6366e-01, -8.3354e-01,  6.8552e-01, -8.6600e-02,
          1.6034e+00,  7.3355e-01,  1.3205e+00,  1.4004e+00, -5.2889e-01,
          5.6740e-01, -9.6958e-01, -1.4997e+00,  4.6890e-01, -1.7328e+00,
          1.0302e+00, -5.7672e-01],
        [-2.0183e-01,  9.5745e-01, -6.7022e-01, -1.4942e+00, -1.7716e+00,
         -1.5369e+00,  5.3614e-01,  2.1942e-01, -4.8692e-01, -1.0483e+00,
         -1.3250e+00, -2.7229e-01,  7.0113e-01,  6.7435e-01,  1.3605e+00,
         -5.5024e-01, -8.2829e-01, -3.0993e-01, -2.9132e-02, -6.5741e-01,
         -1.8838e+00, -1.5611e+00,  1.3386e+00, -9.3677e-01,  9.4050e-01,
          1.6461e+00, -1.7923e+00, -1.2952e+00, -1.4606e+00,  1.9617e+00,
          1.8974e+00, -3.5640e-01, -5.1258e-01,  1.3049e+00,  9.6022e-01,
          1.8340e+00, -1.6090e+00],
        [ 3.3658e-01, -1.9117e+00,  1.3840e+00,  1.4359e+00,  3.0289e-01,
         -1.9664e+00, -1.8941e+00,  4.2836e-02,  1.6804e+00,  1.5752e+00,
         -4.4672e-01,  1.0409e+00, -2.8504e-01, -1.3567e+00,  3.1620e-01,
         -1.9444e+00,  1.5615e+00, -5.0563e-01, -1.8748e+00, -1.1123e+00,
         -1.9222e+00,  1.3545e+00, -2.9159e-01, -4.6669e-01,  1.2639e+00,
         -1.4171e+00, -2.7517e-01, -1.2380e+00, -1.5908e+00,  1.4929e+00,
          1.0642e+00, -3.4285e-01, -1.8219e+00,  1.6329e+00, -1.2953e+00,
          1.7803e+00,  3.6970e-01]])</code></pre>
</div>
</div>
<p>Passing these through softmax will normalize them from 0 to 1:</p>
<div class="cell" data-outputid="2d8fcc7f-d383-4c4d-a121-ba1c5b9fec36">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>sm_acts <span class="op">=</span> acts.softmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>sm_acts[<span class="dv">0</span>], sm_acts[<span class="dv">0</span>].<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>(tensor([0.0020, 0.0302, 0.0024, 0.0162, 0.0361, 0.0056, 0.0396, 0.0257, 0.0374,
         0.0341, 0.0037, 0.0507, 0.0097, 0.0465, 0.0516, 0.0151, 0.0059, 0.0045,
         0.0055, 0.0021, 0.0139, 0.0278, 0.0355, 0.0035, 0.0035, 0.0167, 0.0851,
         0.0159, 0.0043, 0.0020, 0.0031, 0.0597, 0.0675, 0.0279, 0.0149, 0.0853,
         0.1086]), tensor(1.0000))</code></pre>
</div>
</div>
<p>Taking the negative log of this tensor will give us the final loss:</p>
<div class="cell" data-outputid="9af48fb3-1408-4fbb-bd5f-deb1399500bb">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>nll_loss <span class="op">=</span> <span class="op">-</span><span class="fl">1.</span> <span class="op">*</span> torch.log(sm_acts)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>nll_loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([[6.2054, 3.4997, 6.0290, 4.1199, 3.3202, 5.1836, 3.2298, 3.6599, 3.2858,
         3.3795, 5.5891, 2.9825, 4.6318, 3.0690, 2.9651, 4.1916, 5.1359, 5.3999,
         5.2035, 6.1632, 4.2744, 3.5815, 3.3385, 5.6635, 5.6511, 4.0925, 2.4636,
         4.1406, 5.4577, 6.1994, 5.7630, 2.8180, 2.6961, 3.5803, 4.2074, 2.4612,
         2.2198],
        [3.9156, 3.4924, 5.1082, 5.8484, 4.5396, 3.2629, 4.0333, 5.6843, 4.9511,
         2.7360, 3.3119, 3.4572, 3.7761, 5.0076, 4.9721, 5.0235, 1.9825, 5.8002,
         4.0412, 4.5546, 5.6476, 4.2245, 4.7943, 3.2753, 4.0474, 2.3574, 3.2273,
         2.6403, 2.5604, 4.4897, 3.3934, 4.9304, 5.4605, 3.4919, 5.6936, 2.9306,
         4.5375],
        [4.3197, 3.1604, 4.7881, 5.6121, 5.8895, 5.6548, 3.5817, 3.8985, 4.6048,
         5.1662, 5.4429, 4.3902, 3.4167, 3.4435, 2.7574, 4.6681, 4.9462, 4.4278,
         4.1470, 4.7753, 6.0016, 5.6790, 2.7793, 5.0546, 3.1774, 2.4718, 5.9102,
         5.4131, 5.5785, 2.1562, 2.2205, 4.4743, 4.6305, 2.8130, 3.1577, 2.2839,
         5.7269],
        [3.8515, 6.0998, 2.8041, 2.7522, 3.8852, 6.1545, 6.0822, 4.1453, 2.5077,
         2.6129, 4.6348, 3.1472, 4.4732, 5.5448, 3.8719, 6.1325, 2.6266, 4.6937,
         6.0629, 5.3004, 6.1103, 2.8336, 4.4797, 4.6548, 2.9243, 5.6052, 4.4633,
         5.4261, 5.7790, 2.6952, 3.1239, 4.5310, 6.0101, 2.5552, 5.4834, 2.4078,
         3.8184]])</code></pre>
</div>
</div>
<p>Suppose the target for each image was given by the following tensor, where the target is an integer from 0 to 36 representing one of the pet breeds:</p>
<div class="cell" data-outputid="77d70bf8-410f-4e0e-e7f5-43285bed8ae5">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>targs <span class="op">=</span> tensor([<span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">34</span>, <span class="dv">10</span>])</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> <span class="bu">range</span>(<span class="dv">4</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>nll_loss[idx, targs]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([4.1199, 3.9156, 3.1577, 4.6348])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cross_entropy(acts, targs):</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  idx <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(targs))</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  sm_acts <span class="op">=</span> acts.softmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  nll_loss <span class="op">=</span> <span class="op">-</span><span class="fl">1.</span> <span class="op">*</span> torch.log(sm_acts)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> nll_loss[idx, targs].mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>I compare this with the built-in <code>F.cross_entropy</code> and <code>nn.CrossEntropyLoss</code> functions:</p>
<div class="cell" data-outputid="48c9b0c2-7963-4a41-dced-2b650c00b16e">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>F.cross_entropy(acts, targs,reduction<span class="op">=</span><span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor([4.1199, 3.9156, 3.1577, 4.6348])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e901ad98-9343-4e35-d534-ad7fd35b21e3">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>nn.CrossEntropyLoss(reduction<span class="op">=</span><span class="st">'none'</span>)(acts, targs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([4.1199, 3.9156, 3.1577, 4.6348])</code></pre>
</div>
</div>
<p>Note that the <code>nn</code> version of the loss function returns an instantiation of that function which then must be called with the activations and targets as its inputs.</p>
<div class="cell" data-outputid="aa5e00d1-83cc-4eae-ed5b-9dc7b37ca157">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(nn.CrossEntropyLoss(reduction<span class="op">=</span><span class="st">'none'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>torch.nn.modules.loss.CrossEntropyLoss</code></pre>
</div>
</div>
</section>
<section id="binary-cross-entropy-loss" class="level2">
<h2 class="anchored" data-anchor-id="binary-cross-entropy-loss">Binary Cross Entropy Loss</h2>
<p>The authors begin the discussion of explaining the multi-label classification model loss function by observing the activations from the trained model. I’ll do the same—I love that approach since it grounds the concepts involved in the construction of loss function in the actual model outputs.</p>
<div class="cell" data-outputid="1d11d0fa-a218-4af2-f30e-59740d1755fb">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> cnn_learner(dls, resnet18)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Downloading: "https://download.pytorch.org/models/resnet18-5c106cde.pth" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"107ed4eb869b488d991069955405d7b6","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
</div>
<div class="cell" data-outputid="04b35d08-7fc4-491b-d008-ed1b1fd76b0d">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> dls.train.one_batch()</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>    learn.model.cuda()</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>activs <span class="op">=</span> learn.model(x)</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>activs.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>torch.Size([64, 20])</code></pre>
</div>
</div>
<p>Each batch has 64 images and each of those images has 20 activations, one for each label in <code>.vocab</code>. Currently, they are not restricted to values between 0 and 1.</p>
<p><em>Note: the activations tensor has to first be placed on the cpu and then detached from the graph (which is used to track and calculate gradients of the weights with respect to the loss function) before it can be converted to a numpy array used for the plot.</em></p>
<div class="cell" data-outputid="4a67f0db-78b5-4635-b8d2-0a6887793788">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> activs[<span class="dv">0</span>].cpu().detach().numpy()</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Vocab Index"</span>)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Activation"</span>)</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="dv">20</span>), np.arange(<span class="dv">20</span>))</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(<span class="dv">20</span>), ys)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>&lt;BarContainer object of 20 artists&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-35-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Passing them through a sigmoid function achieves that:</p>
<div class="cell" data-outputid="de11c0c9-3c2b-470d-92dd-1d7b2799d2c4">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> activs[<span class="dv">0</span>].sigmoid().cpu().detach().numpy()</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Vocab Index"</span>)</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Activation"</span>)</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="dv">20</span>), np.arange(<span class="dv">20</span>))</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(<span class="dv">20</span>), ys)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>&lt;BarContainer object of 20 artists&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-36-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>The negative log of the activations is taken in order to push the differences between loss values. For vocab where the target is <code>1</code>, <code>-log(inputs)</code> is calculated. For vocab where the target is <code>0</code>, <code>-log(1-inputs)</code> is calculated. This seems counterintuitive at first, but let’s take a look at the plot of these functions:</p>
<div class="cell" data-outputid="13fea8bc-46ba-47ee-89ac-3a560273978e">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> <span class="op">-</span>activs[<span class="dv">0</span>].sigmoid().log().cpu().detach().numpy()</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Vocab Index"</span>)</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Activation"</span>)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="dv">20</span>), np.arange(<span class="dv">20</span>))</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(<span class="dv">20</span>), ys)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>&lt;BarContainer object of 20 artists&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-37-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>The sigmoid activations that were very close to <code>0</code> (Vocab Index = <code>0</code>, <code>2</code>, <code>5</code>, and <code>16</code>) are now much larger than those that were very close to <code>1</code> (Vocab Index = <code>6</code>, <code>14</code>, and <code>18</code>). Since the target is <code>1</code>, this correctly assigns a larger loss to the inaccurate predictions and the smaller loss to the accurate ones. We can say the same (but opposite) for <code>-log(1-inputs)</code>, which is used when the target is <code>0</code>.:</p>
<div class="cell" data-outputid="83e22b61-0048-426b-e0c8-29c6ce47658b">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>ys <span class="op">=</span> <span class="op">-</span>(<span class="dv">1</span><span class="op">-</span> activs[<span class="dv">0</span>].sigmoid()).log().cpu().detach().numpy()</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Vocab Index"</span>)</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Activation"</span>)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>plt.xticks(np.arange(<span class="dv">20</span>), np.arange(<span class="dv">20</span>))</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(<span class="dv">20</span>), ys)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>&lt;BarContainer object of 20 artists&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-38-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Finally, the <code>mean</code> of all image loss values is taken for the batch. The Binary Cross Entropy Function look likes this:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> binary_cross_entropy(inputs, targets):</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>  inputs <span class="op">=</span> inputs.sigmoid()</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="op">-</span>torch.where(targets<span class="op">==</span><span class="dv">1</span>, inputs, <span class="dv">1</span><span class="op">-</span>inputs).log().mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>inputs</code> (the activations for each <code>vocab</code> value)) is the first value and the <code>targets</code> of each image are the second value of the <code>dls.train.one_batch()</code> tuple.</p>
<div class="cell" data-outputid="723c37f6-a659-4e0a-c59b-9c5dea076208">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>binary_cross_entropy(activs,y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>TensorMultiCategory(1.0472, device='cuda:0', grad_fn=&lt;AliasBackward&gt;)</code></pre>
</div>
</div>
<p>I will compare this with the built-in function <code>F.binary_cross_entropy_with_logits</code> and function class <code>nn.BCEWithLogitsLoss</code> to make sure I receive the same result.</p>
<div class="cell" data-outputid="cbb36d33-3b29-4e9f-82c4-cad57aa7739b">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>F.binary_cross_entropy_with_logits(activs,y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>TensorMultiCategory(1.0472, device='cuda:0', grad_fn=&lt;AliasBackward&gt;)</code></pre>
</div>
</div>
<div class="cell" data-outputid="d788cb32-2271-47c1-fd72-b2d4cd983244">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>nn.BCEWithLogitsLoss()(activs,y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>TensorMultiCategory(1.0472, device='cuda:0', grad_fn=&lt;AliasBackward&gt;)</code></pre>
</div>
</div>
</section>
<section id="mult-label-classification-accuracy" class="level2">
<h2 class="anchored" data-anchor-id="mult-label-classification-accuracy">Mult-Label Classification Accuracy</h2>
<p>For single-label classification, the accuracy function compared whether the index of the highest activation matched the index of the target <code>vocab</code>. A single index for a single label.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> accuracy(inputs, targets, axis<span class="op">=-</span><span class="dv">1</span>):</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>  predictions <span class="op">=</span> inputs.argmax(dim<span class="op">=</span>axis)</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> (predictions<span class="op">==</span>targets).<span class="bu">float</span>().mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For multi-label classification, each image can have more than one correct corresponding <code>vocab</code> index and the corresponding activations may not be the maximum of the <code>inputs</code> tensor. So instead of using the maximum, a threshold is used to identify predictions. If the activation is above that threshold, it’s considered to be a prediction.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> accuracy_multi(inp, targ, thresh<span class="op">=</span><span class="fl">0.5</span>, sigmoid<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> sigmoid: inp <span class="op">=</span> inp.sigmoid()</span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> ((inp <span class="op">&gt;</span> thresh)<span class="op">==</span>targ.<span class="bu">bool</span>()).<span class="bu">float</span>().mean()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>targ</code> is a one-hot encoded Tensor, so <code>1</code>s are converted to <code>True</code> and <code>0</code>s are converted to <code>False</code> using the <code>.bool</code> method.</p>
</section>
<section id="training-the-model" class="level2">
<h2 class="anchored" data-anchor-id="training-the-model">Training the Model</h2>
<p>At last! I can now train the model, setting a different accuracy threshold as needed using the built-in <code>partial</code> function.</p>
<div class="cell" data-outputid="f53ffbbf-6702-482e-bc11-83e39ccf204b">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> cnn_learner(dls, resnet50, metrics<span class="op">=</span>partial(accuracy_multi, thresh<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">3</span>, base_lr<span class="op">=</span><span class="fl">3e-3</span>, freeze_epochs<span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4b32a8aa47704cd7bdb47910162bcaba","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.942256</td>
      <td>0.698276</td>
      <td>0.239323</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.821279</td>
      <td>0.566598</td>
      <td>0.281633</td>
      <td>00:28</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.602543</td>
      <td>0.208145</td>
      <td>0.805498</td>
      <td>00:28</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.359614</td>
      <td>0.125162</td>
      <td>0.939801</td>
      <td>00:28</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.133149</td>
      <td>0.112483</td>
      <td>0.947072</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.115643</td>
      <td>0.105032</td>
      <td>0.953028</td>
      <td>00:29</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.096643</td>
      <td>0.103564</td>
      <td>0.952769</td>
      <td>00:29</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>In about three and a half minutes, this model was able to achieve more than 95% accuracy. I’ll look at its predictions on the validation images:</p>
<div class="cell" data-outputid="5774a32d-aec1-491b-b1c8-4fcd81618325">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>learn.show_results(max_n<span class="op">=</span><span class="dv">18</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-46-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Varying the threshold will vary the accuracy of the model. The <code>metrics</code> of the learner can be changed after training, and calling the <code>validate</code> method will recalculate the accuracy:</p>
<div class="cell" data-outputid="218c06a7-7a5d-4a58-b90a-86805fdf8029">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>learn.metrics <span class="op">=</span> partial(accuracy_multi, thresh<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>learn.validate()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>(#2) [0.1035640612244606,0.930816650390625]</code></pre>
</div>
</div>
<p>A threshold of <code>0.1</code> decreases the accuracy of the model, as does a threshold of <code>0.99</code>. A <code>0.1</code> threshold includes labels for which the model was not confident, and a <code>0.99</code> threshold exclused labels for which the model was not <em>very</em> confident. I can calculate and plot the accuracy for a range of thresholds, as they did in the book:</p>
<div class="cell" data-outputid="b954f826-ad5d-4327-c73a-9b687445100c">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>preds, targs <span class="op">=</span> learn.get_preds()</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>xs <span class="op">=</span> torch.linspace(<span class="fl">0.05</span>, <span class="fl">0.95</span>, <span class="dv">29</span>)</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>accs <span class="op">=</span> [accuracy_multi(preds, targs, thresh<span class="op">=</span>i, sigmoid<span class="op">=</span><span class="va">False</span>) <span class="cf">for</span> i <span class="kw">in</span> xs]</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>plt.plot(xs, accs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-48-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="aa0d836e-d69f-495c-cc59-f69c61b7252d">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>best_threshold <span class="op">=</span> xs[np.argmax(accs)]</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>best_threshold</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>tensor(0.4679)</code></pre>
</div>
</div>
<div class="cell" data-outputid="9e8ff6e3-736b-41fb-8434-b6ff9d2af7d8">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>learn.metrics <span class="op">=</span> partial(accuracy_multi, thresh<span class="op">=</span>best_threshold)</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>learn.validate()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="95">
<pre><code>(#2) [0.1035640612244606,0.9636053442955017]</code></pre>
</div>
</div>
<p>The highest accuracy (96.36%) is achieved when the threshold is 0.4679.</p>
</section>
<section id="regression" class="level2">
<h2 class="anchored" data-anchor-id="regression">Regression</h2>
<p>The authors provide some context here which, while I can appreciate, judge I won’t fully understand until I experience the next 5 or 6 chapters.</p>
<blockquote class="blockquote">
<p>A model is defined by its independent and dependent variables, along with its loss function. The means that there’s really a far wider array of models than just the simple domain-based split</p>
</blockquote>
<p>The “domain-based split” is a reference to the distinction between computer vision, NLP and other different types of problems.</p>
<p>To illustrate their point, they have us work through an image regression problem with much of the same process (and model) as an image classification problem.</p>
<div class="cell" data-outputid="af9659cc-ffed-4ff3-a94f-494b12ce3467">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># download data</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.BIWI_HEAD_POSE)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="co"># helper functions to retrieve images</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and to retrieve text files</span></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>img_files <span class="op">=</span> get_image_files(path)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> img2pose(x): <span class="cf">return</span> Path(<span class="ss">f'</span><span class="sc">{</span><span class="bu">str</span>(x)[:<span class="op">-</span><span class="dv">7</span>]<span class="sc">}</span><span class="ss">pose.txt'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="3a18de28-b288-43a3-bf9f-1ae809b1434a">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check that `img2pose` converts file name correctly</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>img_files[<span class="dv">0</span>], img2pose(img_files[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(Path('/root/.fastai/data/biwi_head_pose/03/frame_00457_rgb.jpg'),
 Path('/root/.fastai/data/biwi_head_pose/03/frame_00457_pose.txt'))</code></pre>
</div>
</div>
<div class="cell" data-outputid="c60cdf5a-583c-4384-acaf-d82dae1c37a5">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check image size</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> PILImage.create(img_files[<span class="dv">0</span>])</span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>im.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(480, 640)</code></pre>
</div>
</div>
<div class="cell" data-outputid="beb41cc8-bcdf-48e2-999a-d4a97135a2ed">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># view the image</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>im.to_thumb(<span class="dv">160</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-55-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># helper function to extract coordinates</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a><span class="co"># of the subject's center of head</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>cal <span class="op">=</span> np.genfromtxt(path<span class="op">/</span><span class="st">'01'</span><span class="op">/</span><span class="st">'rgb.cal'</span>, skip_footer<span class="op">=</span><span class="dv">6</span>)</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_ctr(f):</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>  ctr <span class="op">=</span> np.genfromtxt(img2pose(f), skip_header<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>  c1 <span class="op">=</span> ctr[<span class="dv">0</span>] <span class="op">*</span> cal[<span class="dv">0</span>][<span class="dv">0</span>]<span class="op">/</span>ctr[<span class="dv">2</span>] <span class="op">+</span> cal[<span class="dv">0</span>][<span class="dv">2</span>]</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>  c2 <span class="op">=</span> ctr[<span class="dv">1</span>] <span class="op">*</span> cal[<span class="dv">1</span>][<span class="dv">1</span>]<span class="op">/</span>ctr[<span class="dv">2</span>] <span class="op">+</span> cal[<span class="dv">1</span>][<span class="dv">2</span>]</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> tensor([c1,c2])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="7a73efa1-7e50-44a3-f0f8-e433b837911a">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check coordinates of the first file</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>get_ctr(img_files[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([444.7946, 261.7657])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the DataBlock</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>biwi <span class="op">=</span> DataBlock(</span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>    blocks<span class="op">=</span>(ImageBlock, PointBlock),</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>    get_items<span class="op">=</span>get_image_files,</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>    get_y<span class="op">=</span>get_ctr,</span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>    splitter<span class="op">=</span>FuncSplitter(<span class="kw">lambda</span> o: o.parent.name<span class="op">==</span><span class="st">'13'</span>),</span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>    batch_tfms<span class="op">=</span>[<span class="op">*</span>aug_transforms(size<span class="op">=</span>(<span class="dv">240</span>,<span class="dv">320</span>)), Normalize.from_stats(<span class="op">*</span>imagenet_stats)]</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="c3e0017d-e031-4f1b-8196-80c54587df94">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># confirm that the data looks OK</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> biwi.dataloaders(path)</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>dls.show_batch(max_n<span class="op">=</span><span class="dv">9</span>, figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">6</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-59-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="137df576-c79a-4167-d89e-b84119721ff7">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="co"># view tensors</span></span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>xb, yb <span class="op">=</span> dls.one_batch()</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>xb.shape, yb.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>(torch.Size([64, 3, 240, 320]), torch.Size([64, 1, 2]))</code></pre>
</div>
</div>
<p>Each batch has 64 images. Each image has 3 channels (rgb) and is 240x320 pixels in size. Each image has 1 pair of coordinates.</p>
<div class="cell" data-outputid="c30cb670-bcd4-47f3-f64f-bad872e3b5e1">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="co"># view a single coordinate pair</span></span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>yb[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>TensorPoint([[0.0170, 0.3403]], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="b3ec358f-69ab-4cc5-8dfe-ab13c2a39049">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create Learner object</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> cnn_learner(dls, resnet18, y_range<span class="op">=</span>(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Downloading: "https://download.pytorch.org/models/resnet18-5c106cde.pth" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"20f7cd9e8c8a4f8c848a28a4f8480224","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
</div>
<p>The <code>y_range</code> argument shifts the final layer’s sigmoid output to a coordinate between -1 and 1. The sigmoid function is transformed using the following function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_function(f, tx<span class="op">=</span><span class="va">None</span>, ty<span class="op">=</span><span class="va">None</span>, title<span class="op">=</span><span class="va">None</span>, <span class="bu">min</span><span class="op">=-</span><span class="dv">2</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">4</span>)):</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> torch.linspace(<span class="bu">min</span>,<span class="bu">max</span>)</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>    fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>figsize)</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>    ax.plot(x,f(x))</span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> tx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: ax.set_xlabel(tx)</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ty <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: ax.set_ylabel(ty)</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> title <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>: ax.set_title(title)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="8a98dda2-3185-4696-cd99-d3df415ea43b">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid_range(x, lo, hi): <span class="cf">return</span> torch.sigmoid(x) <span class="op">*</span> (hi<span class="op">-</span>lo) <span class="op">+</span> lo</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>plot_function(partial(sigmoid_range, lo<span class="op">=-</span><span class="dv">1</span>, hi<span class="op">=</span><span class="dv">1</span>), <span class="bu">min</span><span class="op">=-</span><span class="dv">4</span>, <span class="bu">max</span><span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-64-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="b3c8bcea-eec8-43fd-fc6f-0276ffe25c7e">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="co"># confirm loss function</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>dls.loss_func</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>FlattenedLoss of MSELoss()</code></pre>
</div>
</div>
<p>fastai has chosen MSE as the loss function, which is appropriate for a regression problem.</p>
<div class="cell" data-outputid="d4ac52d5-c1c2-4e35-e5b8-64ff85b7560c">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pick a learning rate</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>learn.lr_find()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>SuggestedLRs(lr_min=0.004786301031708717, lr_steep=0.033113110810518265)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2021-04-12-fastai-chapter-6_files/figure-html/cell-66-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="16dc36b2-a817-4994-99fb-81f486bf83b1">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># use lr = 2e-2</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">2e-2</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, lr)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.047852</td>
      <td>0.011552</td>
      <td>01:55</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.007220</td>
      <td>0.002150</td>
      <td>01:56</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.003190</td>
      <td>0.001313</td>
      <td>01:56</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.002376</td>
      <td>0.000295</td>
      <td>01:56</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.001650</td>
      <td>0.000106</td>
      <td>01:54</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>A loss of 0.000106 is an accuracy of:</p>
<div class="cell" data-outputid="4446a678-d9c9-4b34-e778-37ca18abba62">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>math.sqrt(<span class="fl">0.000106</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>0.010295630140987</code></pre>
</div>
</div>
<p>The conclusion to this (what has felt like a marathon of a) chapter is profound:</p>
<blockquote class="blockquote">
<p>In problems that are at first glance completely different (single-label classification, multi-label classification, and regression), we end up using the same model with just different number of outputs. The loss function is the one thing that changes, which is why it’s important to double-check that you are using the right loss function for your problem…make sure you think hard about your loss function, and remember that you most probably want the following:</p>
</blockquote>
<ul>
<li><code>nn.CrossEntropyLoss</code> for single-label classification</li>
<li><code>nn.BCEWithLogitsLoss</code> for multi-label classification</li>
<li><code>nn.MSELoss</code> for regression</li>
</ul>


</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"0831ecbc94c14a53bc8331e66a4dd05e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_941f87b9e3a24d99a6e603af0cd9bd30","max":46827520,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a8e4b07b6e547f58f00708f6433f9e5","value":46827520}},"107ed4eb869b488d991069955405d7b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0831ecbc94c14a53bc8331e66a4dd05e","IPY_MODEL_cb17b64fd4bf4a1386efd2193ae48f0f"],"layout":"IPY_MODEL_c77c2c4e189043d5ba9e0685040d36b5"}},"153040ff9dda42b6a5a1e4466d70b577":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1597566a1c3f46c28c8313ca1279ab3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20f7cd9e8c8a4f8c848a28a4f8480224":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad78a11909124453baf2fb91bf0a1375","IPY_MODEL_a3e74914f80f4f64bca9e408e90cc67d"],"layout":"IPY_MODEL_de1a475b694b46aaa1d1d8ab86c4df4a"}},"2603d53f660449eaa69f2a80e2ccc96e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c979f36c338440ab1e0c183a65b8ba9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"3dd0fedcf4334c3583e9bf3d93a17805":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e32df70ca084daeb8ef5961397d76f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"4b32a8aa47704cd7bdb47910162bcaba":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce149905596244b6a1f4fe4717df9114","IPY_MODEL_cad392d5004e420b938222e6f2d7e19e"],"layout":"IPY_MODEL_515c4d98f5044d1793a8917dcccd7433"}},"515c4d98f5044d1793a8917dcccd7433":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5df77d3fab61467a95f22564ad844c62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a8e4b07b6e547f58f00708f6433f9e5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"941f87b9e3a24d99a6e603af0cd9bd30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a7aae81fb024833a95126492f313844":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3e74914f80f4f64bca9e408e90cc67d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_153040ff9dda42b6a5a1e4466d70b577","placeholder":"​","style":"IPY_MODEL_1597566a1c3f46c28c8313ca1279ab3d","value":" 44.7M/44.7M [00:01&lt;00:00, 44.8MB/s]"}},"ad78a11909124453baf2fb91bf0a1375":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_c13affd6b53b4179a4d854b57f8a7ac4","max":46827520,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e32df70ca084daeb8ef5961397d76f4","value":46827520}},"c13affd6b53b4179a4d854b57f8a7ac4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c77c2c4e189043d5ba9e0685040d36b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cad392d5004e420b938222e6f2d7e19e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a7aae81fb024833a95126492f313844","placeholder":"​","style":"IPY_MODEL_3dd0fedcf4334c3583e9bf3d93a17805","value":" 97.8M/97.8M [00:02&lt;00:00, 47.0MB/s]"}},"cb17b64fd4bf4a1386efd2193ae48f0f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff01b78213784e679b849e1df34b0b88","placeholder":"​","style":"IPY_MODEL_2603d53f660449eaa69f2a80e2ccc96e","value":" 44.7M/44.7M [00:01&lt;00:00, 23.5MB/s]"}},"ce149905596244b6a1f4fe4717df9114":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_5df77d3fab61467a95f22564ad844c62","max":102502400,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c979f36c338440ab1e0c183a65b8ba9","value":102502400}},"de1a475b694b46aaa1d1d8ab86c4df4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff01b78213784e679b849e1df34b0b88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>