<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vishal Bakshi">
<meta name="dcterms.date" content="2024-05-21">
<meta name="description" content="Inspired by Aman Arora’s blog post, I walk through code of the fastai function LabelSmoothingCrossEntropy. - deep learning - fastai - python">

<title>vishal bakshi - Understanding the Code in fastai’s LabelSmoothingCrossEntropy</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">vishal bakshi</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#background" id="toc-background" class="nav-link active" data-scroll-target="#background">Background</a></li>
  <li><a href="#excel-version" id="toc-excel-version" class="nav-link" data-scroll-target="#excel-version">Excel Version</a></li>
  <li><a href="#fastais-labelsmoothingcrossentropy" id="toc-fastais-labelsmoothingcrossentropy" class="nav-link" data-scroll-target="#fastais-labelsmoothingcrossentropy">fastai’s <code>LabelSmoothingCrossEntropy</code></a></li>
  <li><a href="#recreating-excel-calculation-in-pytorch" id="toc-recreating-excel-calculation-in-pytorch" class="nav-link" data-scroll-target="#recreating-excel-calculation-in-pytorch">Recreating Excel Calculation in PyTorch</a></li>
  <li><a href="#bringing-it-all-together" id="toc-bringing-it-all-together" class="nav-link" data-scroll-target="#bringing-it-all-together">Bringing it All Together</a></li>
  <li><a href="#final-thoughts" id="toc-final-thoughts" class="nav-link" data-scroll-target="#final-thoughts">Final Thoughts</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Understanding the Code in fastai’s <code>LabelSmoothingCrossEntropy</code></h1>
</div>

<div>
  <div class="description">
    Inspired by Aman Arora’s blog post, I walk through code of the fastai function LabelSmoothingCrossEntropy. - deep learning - fastai - python
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Vishal Bakshi </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 21, 2024</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post I’ll walk through fastai’s <code>LabelSmoothingCrossEntropy</code> function line-by-line and compare it to the helpful Excel example and explanation presented by Aman Arora in his <a href="https://amaarora.github.io/posts/2020-07-18-label-smoothing.html#fastaipytorch-implementation-of-label-smoothing-cross-entropy-loss">Label Smoothing Explained using Microsoft Excel</a> blog post. This process helped me better visualize how something in Excel (which is visually intuitive for beginners) translates to PyTorch (not always intuitive for beginners).</p>
</section>
<section id="excel-version" class="level2">
<h2 class="anchored" data-anchor-id="excel-version">Excel Version</h2>
<p>I’ll start be recreating Aman’s Excel example with the following columns:</p>
<ul>
<li><code>image_name</code>: example name of training data</li>
<li><code>is_cat</code>: ground truth noisy label</li>
<li><code>is_dog</code>: ground truth noisy label</li>
<li><code>logit (cat)</code>: model output (activation) for cat class</li>
<li><code>logit (dog)</code>: model output (activation) for dog class</li>
<li><code>exp (cat)</code>: exponential of the cat logit</li>
<li><code>exp (dog)</code>: exponential of the dog logit</li>
<li><code>sum (exp)</code>: sum of cat and dog exponential for each image</li>
<li><code>prob (cat)</code>: exponential of cat divided by sum of exponential o fdog and exponential of cat</li>
<li><code>prob (dog)</code>: exponential of dog divided by sum of exponential o fdog and exponential of cat</li>
<li><code>LS X-entropy</code>: the negative sum of the ground truth noisy label times the natural log of the class probability (for both dog and cat). The screenshot below shows how this value is calculated in Excel.</li>
</ul>
<p><img src="1.png" style="width:100%;"></p>
</section>
<section id="fastais-labelsmoothingcrossentropy" class="level2">
<h2 class="anchored" data-anchor-id="fastais-labelsmoothingcrossentropy">fastai’s <code>LabelSmoothingCrossEntropy</code></h2>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is the <code>forward</code> method of <a href="https://github.com/fastai/fastai/blob/6db9f9cd77d6bb1cd8a939852b0a0c48ce20e01b/fastai/losses.py#L188">fastai’s <code>LabelSmoothingCrossEntropy</code> class</a>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> forward(<span class="va">self</span>, output:Tensor, target:Tensor) <span class="op">-&gt;</span> Tensor:</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>        <span class="co">"Apply `F.log_softmax` on output then blend the loss/num_classes(`c`) with the `F.nll_loss`"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        c <span class="op">=</span> output.size()[<span class="dv">1</span>]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        log_preds <span class="op">=</span> F.log_softmax(output, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.reduction<span class="op">==</span><span class="st">'sum'</span>: loss <span class="op">=</span> <span class="op">-</span>log_preds.<span class="bu">sum</span>()</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="op">-</span>log_preds.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>) <span class="co">#We divide by that size at the return line so sum and not mean</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.reduction<span class="op">==</span><span class="st">'mean'</span>:  loss <span class="op">=</span> loss.mean()</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss<span class="op">*</span><span class="va">self</span>.eps<span class="op">/</span>c <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span><span class="va">self</span>.eps) <span class="op">*</span> F.nll_loss(log_preds, target.<span class="bu">long</span>(), weight<span class="op">=</span><span class="va">self</span>.weight, reduction<span class="op">=</span><span class="va">self</span>.reduction)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>I’ll start by defining the <code>output</code> and <code>target</code> tensors. I’ll also define the noisy target defined in the Excel spreadsheet (<code>is_cat</code> and <code>is_dog</code>).</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># logits</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> torch.tensor([</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">4.2</span>, <span class="op">-</span><span class="fl">2.4</span>],</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">1.6</span>, <span class="op">-</span><span class="fl">0.6</span>],</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">3.6</span>, <span class="fl">1.2</span>],</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    [<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">0.5</span>],</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    [<span class="op">-</span><span class="fl">0.25</span>, <span class="fl">1.7</span>]</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># labels</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> torch.tensor([<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>])</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># noisy labels</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>noisy_target <span class="op">=</span> torch.tensor([</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.95</span>, <span class="fl">0.05</span>],</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.05</span>, <span class="fl">0.95</span>],</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.05</span>, <span class="fl">0.95</span>],</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.95</span>, <span class="fl">0.05</span>],</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.95</span>, <span class="fl">0.05</span>]])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>First let’s calculate the loss with fastai to show that it matches the Excel calculations:</p>
<div class="cell" data-outputid="fb4795e6-a60e-4770-88c6-601373780875" data-execution_count="40">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>LabelSmoothingCrossEntropy(eps<span class="op">=</span><span class="fl">0.1</span>, reduction<span class="op">=</span><span class="st">'none'</span>)(output,target)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>tensor([0.3314, 2.1951, 2.3668, 1.2633, 1.9855])</code></pre>
</div>
</div>
<p>Note the <code>eps</code> parameter which is <span class="math inline">\(\epsilon\)</span> in Aman’s blog post. I understand this to be the total “noisiness” divided across the classes. In our case, this value is <code>0.1</code>.</p>
<p>Next, I’ll run through the lines of code in <code>LabelSmoothingCrossEntropy</code>’s <code>forward</code> method if <code>reduction='none'</code> (which is the case for our Excel example), and show that it outputs the same values as Excel.</p>
<div class="cell" data-outputid="fa6c8b39-4241-44b9-d45c-54f9aa467931" data-execution_count="13">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>eps<span class="op">=</span><span class="fl">0.1</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> output.size()[<span class="dv">1</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>log_preds <span class="op">=</span> F.log_softmax(output, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span>log_preds.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>loss<span class="op">*</span>eps<span class="op">/</span>c <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>eps) <span class="op">*</span> F.nll_loss(log_preds, target.<span class="bu">long</span>(), reduction<span class="op">=</span><span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([0.3314, 2.1951, 2.3668, 1.2633, 1.9855])</code></pre>
</div>
</div>
<p>Here, <code>c</code> is the number of classes (<code>2</code>).</p>
</section>
<section id="recreating-excel-calculation-in-pytorch" class="level2">
<h2 class="anchored" data-anchor-id="recreating-excel-calculation-in-pytorch">Recreating Excel Calculation in PyTorch</h2>
<p>I found it a bit more intuitive to recreate the Excel calculation in PyTorch in a slightly different order of operations.</p>
<p>In Excel, we take the softmax of the logits to get the probability of cat and dog (highlighted in the screenshot below).</p>
<p><img src="2.png" style="width:100%;"></p>
<p>In PyTorch, we can recreate those values with <code>F.softmax</code>. <code>dim=-1</code> tells it to take the softmax across the last dimension (of <code>2</code> classes).</p>
<div class="cell" data-outputid="a79fbe9c-1da6-4b41-a1aa-99a8b20cfbf8" data-execution_count="14">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>F.softmax(output, dim<span class="op">=-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([[0.9986, 0.0014],
        [0.9002, 0.0998],
        [0.9168, 0.0832],
        [0.2689, 0.7311],
        [0.1246, 0.8754]])</code></pre>
</div>
</div>
<p>Next, to calculate cross entropy, we multiply the noisy label with the log probability, sum across classes and multiply by negative 1:</p>
<p><img src="3.png" style="width:100%;"></p>
<p>In PyTorch, we do that by multiplying <code>noisy_target</code>s by the <code>torch.log</code> probabilities (<code>F.softmax</code>), summing across each row (<code>dim=-1</code>) and multiplying by negative 1.</p>
<div class="cell" data-outputid="9a6f2f00-d699-4c8f-dbb8-57105300dc0c" data-execution_count="19">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="op">-</span><span class="dv">1</span> <span class="op">*</span> (noisy_target <span class="op">*</span> torch.log(F.softmax(output, dim<span class="op">=-</span><span class="dv">1</span>))).<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([0.3314, 2.1951, 2.3668, 1.2633, 1.9855])</code></pre>
</div>
</div>
<p>This gives us the desired result. Although this looks different from the fastai implementation.</p>
</section>
<section id="bringing-it-all-together" class="level2">
<h2 class="anchored" data-anchor-id="bringing-it-all-together">Bringing it All Together</h2>
<p>The Excel calculation that I recreated in PyTorch and the fastai implementation look different but achieve the same result. I’ll try to connect and reason through the two approaches.</p>
<p>The first two lines of interest in <code>LabelSmoothingCrossEntropy</code> are straightforward—they define constants used later on.</p>
<div class="cell" data-outputid="13f0370b-8cb9-4511-8be6-68a8e1b4a428" data-execution_count="20">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>eps<span class="op">=</span><span class="fl">0.1</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> output.size()[<span class="dv">1</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>eps, c</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>(0.1, 2)</code></pre>
</div>
</div>
<p>In the next line, <code>log_preds</code> is defined as:</p>
<div class="cell" data-outputid="b75c0278-01dc-4f1f-9c97-16e8bf9e0d2a" data-execution_count="24">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>log_preds <span class="op">=</span> F.log_softmax(output, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>log_preds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([[-1.3595e-03, -6.6014e+00],
        [-1.0508e-01, -2.3051e+00],
        [-8.6836e-02, -2.4868e+00],
        [-1.3133e+00, -3.1326e-01],
        [-2.0830e+00, -1.3302e-01]])</code></pre>
</div>
</div>
<p>In Excel, we fold this step into the following formula (multiplying the noisy labels with the log probabilities and summing both classes):</p>
<p><img src="4.png" style="width:100%;"></p>
<p><code>log_preds</code> is just the <code>LN(I2)</code> and <code>LN(J2)</code> parts in the Excel formula for each image (or row).</p>
<p>The next line in <code>LabelSmoothingCrossEntropy</code> sums the log probabilities across each row (or image) and multiplies the sum by negative 1.</p>
<p>In Excel, this is would be the same as the part of the formula with the noisy labels removed: <code>=-LN(I2)-LN(J2)</code>.</p>
<p><img src="5.png" style="width:100%;"></p>
<div class="cell" data-outputid="3230f8fa-c3e8-4223-e48d-ea54fd94b37a" data-execution_count="26">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="op">-</span>log_preds.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>loss</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor([6.6027, 2.4102, 2.5737, 1.6265, 2.2160])</code></pre>
</div>
</div>
<p>The last part is where the noisy label magic happens in PyTorch.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>loss<span class="op">*</span>eps<span class="op">/</span>c <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>eps) <span class="op">*</span> F.nll_loss(log_preds, target.<span class="bu">long</span>(), reduction<span class="op">=</span><span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In the first term, <code>loss*eps/c</code>, the log probabilities summed across both classes for each image is multiplied by <code>0.1/2</code> or <code>0.05</code>:</p>
<div class="cell" data-outputid="a583dee1-c7c2-4030-b66c-374868469397" data-execution_count="31">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>loss<span class="op">*</span>eps<span class="op">/</span>c</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor([0.3301, 0.1205, 0.1287, 0.0813, 0.1108])</code></pre>
</div>
</div>
<p>The second term, <code>(1-eps) * F.nll_loss(log_preds, target.long(), reduction='none')</code> does a couple of things:</p>
<p>First, it calculates the negative log likelihood loss given the log probabilities (<code>log_preds</code>) and the targets. Note that all <code>nll_loss</code> does is pick out the <code>log_preds</code> items at the <code>target</code> indices for each row:</p>
<div class="cell" data-outputid="aaba87a1-2379-434f-b209-45d5f11f4f7e" data-execution_count="32">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>F.nll_loss(log_preds, target.<span class="bu">long</span>(), reduction<span class="op">=</span><span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([1.3595e-03, 2.3051e+00, 2.4868e+00, 1.3133e+00, 2.0830e+00])</code></pre>
</div>
</div>
<p>Since <code>reduction</code> is <code>'none'</code>, this is the same as just indexing each row with our <code>target</code> tensor and multiplying by -1:</p>
<div class="cell" data-outputid="fa5a290d-5036-4a04-c6fd-6300461bc8f6" data-execution_count="39">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="op">-</span><span class="dv">1</span> <span class="op">*</span> log_preds[[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>], target]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>tensor([1.3595e-03, 2.3051e+00, 2.4868e+00, 1.3133e+00, 2.0830e+00])</code></pre>
</div>
</div>
<div class="cell" data-outputid="16e85a07-e631-4b9d-e229-5f9620bee7a0" data-execution_count="37">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>log_preds <span class="co"># reminder of what log_preds looks like</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([[-1.3595e-03, -6.6014e+00],
        [-1.0508e-01, -2.3051e+00],
        [-8.6836e-02, -2.4868e+00],
        [-1.3133e+00, -3.1326e-01],
        [-2.0830e+00, -1.3302e-01]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="873e64f2-97b9-49fa-d820-61fbacaf3f2a" data-execution_count="38">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>target <span class="co"># reminder of what target looks like</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([0, 1, 1, 0, 0])</code></pre>
</div>
</div>
<p>So, basically, <code>nll_loss</code> with <code>reduction='none'</code> takes the 0-th element of the first row (<code>-1.3595e-03</code>), the 1-th element in the second row (<code>-2.3051e+00</code>) and so on. <strong><code>nll_loss</code> picks only the chosen label’s probabilities, whereas <code>loss</code> is the sum of both class’ probabilities.</strong></p>
<p>The chosen probabilities are then multiplied by <code>1-eps</code> or <code>0.90</code>.</p>
<p>Let’s visualize what that last line in <code>LabelSmoothCrossEntropy</code> is doing, row by row, given the <code>log_preds</code> values. I’ve rewritten <code>loss</code> as <code>-log_preds.sum(dim=1)</code>.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>(<span class="op">-</span>log_preds.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>))<span class="op">*</span>eps<span class="op">/</span>c <span class="op">+</span> (<span class="dv">1</span><span class="op">-</span>eps) <span class="op">*</span> F.nll_loss(log_preds, target.<span class="bu">long</span>(), reduction<span class="op">=</span><span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 10%">
<col style="width: 40%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">row</th>
<th style="text-align: center;">-log_preds.sum(dim=1)*eps/c</th>
<th style="text-align: center;">(1-eps) * F.nll_loss(log_preds, target.long(), reduction=‘none’)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">-(-1.3595e-03 + -6.6014e+00) * 0.05</td>
<td style="text-align: center;">0.90 * 1.3595e-03</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">-(-1.0508e-01 + -2.3051e+00) * 0.05</td>
<td style="text-align: center;">0.90 * 2.3051e+00</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">-(-8.6836e-02 + -2.4868e+00) * 0.05</td>
<td style="text-align: center;">0.90 * 2.4868e+00</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">-(-1.3133e+00, -3.1326e-01) * 0.05</td>
<td style="text-align: center;">0.90 * 1.3133e+00</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">-(-2.0830e+00, -1.3302e-01) * 0.05</td>
<td style="text-align: center;">0.90 * 2.0830e+00</td>
</tr>
</tbody>
</table>
<p>In each row you’ll notice that the target log probability is multiplied first by <code>0.05</code> (which is <code>eps/c</code>) and then multiplied by <code>0.90</code> (which is <code>1-eps</code>) and then added together. We can rewrite this as follows (adding together <code>0.05</code> and <code>0.90</code> to get <code>0.95</code> for the target class)</p>
<table class="table">
<colgroup>
<col style="width: 5%">
<col style="width: 95%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">row</th>
<th style="text-align: center;">-log_preds.sum(dim=1)*eps/c + (1-eps) * F.nll_loss(log_preds, target.long(), reduction=‘none’)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.05 * 6.6014e+00 + 0.95 * 1.3595e-03</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.05 * 1.0508e-01 + 0.95 * 2.3051e+00</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">0.05 * 8.6836e-02 + 0.95 * 2.4868e+00</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">0.05 * 3.1326e-01 + 0.95 * 1.3133e+00</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.05 * 1.3302e-01 + 0.95 * 2.0830e+00</td>
</tr>
</tbody>
</table>
<p>I’ll expand the Excel version a bit more to match this form so we can see the parallels:</p>
<p><img src="6.png" style="width:100%;"></p>
<p>In this way, the fastai implementation, Aman Arora’s Excel implementation and my PyTorch implementation are visualized and aligned.</p>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>I often underestimate how much time and thinking it takes to unpack the amount of calculation done in a few lines of code. That’s the beauty and elegance of fastai and PyTorch! But it also emphasizes the time and care needed to walk through each step manually to visualize what is going on.</p>
<p>I hope you enjoyed this blog post!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>