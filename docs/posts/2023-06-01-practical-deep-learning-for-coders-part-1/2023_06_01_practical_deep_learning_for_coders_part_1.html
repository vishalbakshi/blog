<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>vishal bakshi – practical_deep_learning_for_coders_part_1</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">vishal bakshi</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#practical-deep-learning-for-coders---part-1" id="toc-practical-deep-learning-for-coders---part-1" class="nav-link active" data-scroll-target="#practical-deep-learning-for-coders---part-1">Practical Deep Learning for Coders - Part 1</a>
  <ul class="collapse">
  <li><a href="#lesson-1" id="toc-lesson-1" class="nav-link" data-scroll-target="#lesson-1">Lesson 1</a>
  <ul class="collapse">
  <li><a href="#notebook-exercise" id="toc-notebook-exercise" class="nav-link" data-scroll-target="#notebook-exercise">Notebook Exercise</a></li>
  <li><a href="#video-notes" id="toc-video-notes" class="nav-link" data-scroll-target="#video-notes">Video Notes</a></li>
  <li><a href="#book-notes" id="toc-book-notes" class="nav-link" data-scroll-target="#book-notes">Book Notes</a></li>
  <li><a href="#questionnaire" id="toc-questionnaire" class="nav-link" data-scroll-target="#questionnaire">Questionnaire</a></li>
  <li><a href="#further-research" id="toc-further-research" class="nav-link" data-scroll-target="#further-research">Further Research</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">



<section id="practical-deep-learning-for-coders---part-1" class="level1">
<h1>Practical Deep Learning for Coders - Part 1</h1>
<p>Vishal Bakshi</p>
<p>This notebook contains my notes (of course videos, example notebooks and book chapters) and exercises of Part 1 of the course <a href="https://course.fast.ai/">Practical Deep Learning for Coders</a>.</p>
<section id="lesson-1" class="level2">
<h2 class="anchored" data-anchor-id="lesson-1">Lesson 1</h2>
<section id="notebook-exercise" class="level3">
<h3 class="anchored" data-anchor-id="notebook-exercise">Notebook Exercise</h3>
<p>The first thing I did was to run through the <a href="https://www.kaggle.com/code/vishalbakshi/is-it-a-bird-creating-a-model-from-your-own-data/edit">lesson 1 notebook</a> from start to finish. In this notebook, they download training and validation images of birds and forests then train an image classifier with 100% accuracy in identifying images of birds.</p>
<p>The first exercise is for us to create our own image classifier with our own image searches. I’ll create a classifier which accurately predicts an image of an alligator.</p>
<p>I’ll start by using their example code for getting images using Duck Duck Go image search:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-06T02:28:11.126325Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-06T02:28:11.125724Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-06T02:28:15.194050Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-06T02:28:15.192710Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-06T02:28:11.126212Z&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># It's a good idea to ensure you're running the latest version of any libraries you need.</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># `!pip install -Uqq &lt;libraries&gt;` upgrades to the latest version of &lt;libraries&gt;</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># NB: You can safely ignore any warnings or errors pip spits out about running as root or incompatibilities</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>Uqq fastai duckduckgo_search</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:49:48.308894Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:49:48.308531Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:49:49.551469Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:49:49.549941Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:49:48.308864Z&quot;}">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> duckduckgo_search <span class="im">import</span> ddg_images</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastcore.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> search_images(term, max_images<span class="op">=</span><span class="dv">30</span>):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Searching for '</span><span class="sc">{</span>term<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> L(ddg_images(term, max_results<span class="op">=</span>max_images)).itemgot(<span class="st">'image'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The <code>search_images</code> function takes a search <code>term</code> and <code>max_images</code> maximum number of images value. It prints out a line of text that it’s <code>"Searching for"</code> the <code>term</code> and returns an <code>L</code> object with the <code>image</code> URL.</p>
<p>The <code>ddg_images</code> function returns a <code>list</code> of JSON objects containing the <code>title</code>, <code>image</code> URL, <code>thumbnail</code> URL, <code>height</code>, <code>width</code> and <code>source</code> of the image.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:49:51.925094Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:49:51.924614Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:49:58.298665Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:49:58.297360Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:49:51.925058Z&quot;}" data-outputid="dc80bb3d-f529-433e-e262-698301b024f2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>search_object <span class="op">=</span> ddg_images(<span class="st">'alligator'</span>, max_results<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>search_object</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.9/dist-packages/duckduckgo_search/compat.py:60: UserWarning: ddg_images is deprecated. Use DDGS().images() generator
  warnings.warn("ddg_images is deprecated. Use DDGS().images() generator")
/usr/local/lib/python3.9/dist-packages/duckduckgo_search/compat.py:64: UserWarning: parameter page is deprecated
  warnings.warn("parameter page is deprecated")
/usr/local/lib/python3.9/dist-packages/duckduckgo_search/compat.py:66: UserWarning: parameter max_results is deprecated
  warnings.warn("parameter max_results is deprecated")</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>[{'title': 'The Creature Feature: 10 Fun Facts About the American Alligator | WIRED',
  'image': 'https://www.wired.com/wp-content/uploads/2015/03/Gator-2.jpg',
  'thumbnail': 'https://tse4.mm.bing.net/th?id=OIP.FS96VErnOXAGSWU092I_DQHaE8&amp;pid=Api',
  'url': 'https://www.wired.com/2015/03/creature-feature-10-fun-facts-american-alligator/',
  'height': 3456,
  'width': 5184,
  'source': 'Bing'}]</code></pre>
</div>
</div>
<p>Wrapping this list in <code>L</code> object and calling <code>.itemgot('image')</code> on it extracts URL value associated with the <code>image</code> key in the JSON object.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:50:01.253198Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:50:01.252820Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:50:01.260817Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:50:01.259586Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:50:01.253170Z&quot;}" data-outputid="7b540948-2d00-4db0-d847-f3fbd3738159">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>L(search_object).itemgot(<span class="st">'image'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(#1) ['https://www.wired.com/wp-content/uploads/2015/03/Gator-2.jpg']</code></pre>
</div>
</div>
<p>Next, they provide some code to download the image to a destination filename and view the image:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:50:03.568630Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:50:03.567640Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:50:07.519666Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:50:07.518661Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:50:03.568630Z&quot;}" data-outputid="900e257e-3777-4c3e-f2c0-f961b6ec1392">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>urls <span class="op">=</span> search_images(<span class="st">'alligator'</span>, max_images<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastdownload <span class="im">import</span> download_url</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>dest <span class="op">=</span> <span class="st">'alligator.jpg'</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>download_url(urls[<span class="dv">0</span>], dest, show_progress<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> Image.<span class="bu">open</span>(dest)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>im.to_thumb(<span class="dv">256</span>,<span class="dv">256</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Searching for 'alligator'</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="11">
<p><img src="2023_06_01_practical_deep_learning_for_coders_part_1_files/figure-html/cell-6-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>For my not-alligator images, I’ll use images of a <strong>swamp</strong>.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:50:13.461890Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:50:13.460904Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:50:15.183874Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:50:15.182494Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:50:13.461857Z&quot;}" data-outputid="a0a78b7e-fe28-4570-b34e-e48e90ede634">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>download_url(search_images(<span class="st">'swamp photos'</span>, max_images<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>], <span class="st">'swamp.jpg'</span>, show_progress<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>Image.<span class="bu">open</span>(<span class="st">'swamp.jpg'</span>).to_thumb(<span class="dv">256</span>,<span class="dv">256</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Searching for 'swamp photos'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.9/dist-packages/duckduckgo_search/compat.py:60: UserWarning: ddg_images is deprecated. Use DDGS().images() generator
  warnings.warn("ddg_images is deprecated. Use DDGS().images() generator")
/usr/local/lib/python3.9/dist-packages/duckduckgo_search/compat.py:64: UserWarning: parameter page is deprecated
  warnings.warn("parameter page is deprecated")
/usr/local/lib/python3.9/dist-packages/duckduckgo_search/compat.py:66: UserWarning: parameter max_results is deprecated
  warnings.warn("parameter max_results is deprecated")</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="12">
<p><img src="2023_06_01_practical_deep_learning_for_coders_part_1_files/figure-html/cell-7-output-3.png" class="img-fluid"></p>
</div>
</div>
<p>In the following code, I’ll search for both terms, <code>alligator</code> and <code>swamp</code> and store the images in <code>alligator_or_not/alligator</code> and <code>alligator_or_not/swamp</code> paths, respectively.</p>
<p>The <code>parents=TRUE</code> argument creates any intermediate parent directories that don’t exist (in this case, the <code>alligator_or_not</code> directory). The <code>exist_ok=TRUE</code> argument suppresses the <code>FileExistsError</code> and does nothing.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:50:19.759385Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:50:19.759032Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:52:44.471898Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:52:44.469904Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:50:19.759360Z&quot;}" data-outputid="58b3adf5-9fba-4c9e-facc-de1f07e0331b">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>searches <span class="op">=</span> <span class="st">'swamp'</span>,<span class="st">'alligator'</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path(<span class="st">'alligator_or_not'</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> sleep</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> searches:</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    dest <span class="op">=</span> (path<span class="op">/</span>o)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    dest.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>, parents<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    download_images(dest, urls<span class="op">=</span>search_images(<span class="ss">f'</span><span class="sc">{</span>o<span class="sc">}</span><span class="ss"> photo'</span>))</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    sleep(<span class="dv">10</span>)  <span class="co"># Pause between searches to avoid over-loading server</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    download_images(dest, urls<span class="op">=</span>search_images(<span class="ss">f'</span><span class="sc">{</span>o<span class="sc">}</span><span class="ss"> sun photo'</span>))</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    sleep(<span class="dv">10</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    download_images(dest, urls<span class="op">=</span>search_images(<span class="ss">f'</span><span class="sc">{</span>o<span class="sc">}</span><span class="ss"> shade photo'</span>))</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    sleep(<span class="dv">10</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    resize_images(path<span class="op">/</span>o, max_size<span class="op">=</span><span class="dv">400</span>, dest<span class="op">=</span>path<span class="op">/</span>o)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Searching for 'swamp photo'
Searching for 'swamp sun photo'
Searching for 'swamp shade photo'
Searching for 'alligator photo'
Searching for 'alligator sun photo'
Searching for 'alligator shade photo'</code></pre>
</div>
</div>
<p>Next, I’ll train my model using the code they have provided.</p>
<p>The <code>get_image_files</code> function is a fastai function which takes a <code>Path</code> object and returns an <code>L</code> object with paths to the image files.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:52:47.958260Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:52:47.957554Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:52:47.970819Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:52:47.969416Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:52:47.958211Z&quot;}" data-outputid="64b0f008-d8bf-47a9-d774-b05eab99f4c9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(get_image_files(path))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>fastcore.foundation.L</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:52:48.686378Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:52:48.685953Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:52:48.699089Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:52:48.697660Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:52:48.686347Z&quot;}" data-outputid="37f3db2e-541c-4fe7-d99b-244d492a7ba5">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>get_image_files(path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>(#349) [Path('alligator_or_not/swamp/1b3c3a61-0f7f-4dc2-a704-38202d593207.jpg'),Path('alligator_or_not/swamp/9c9141f2-024c-4e26-b343-c1ca1672fde8.jpeg'),Path('alligator_or_not/swamp/1340dd85-5d98-428e-a861-d522c786c3d7.jpg'),Path('alligator_or_not/swamp/2d3f91dc-cc5f-499b-bec6-7fa0e938fb13.jpg'),Path('alligator_or_not/swamp/84afd585-ce46-4016-9a09-bd861a5615db.jpg'),Path('alligator_or_not/swamp/6222f0b6-1f5f-43ec-b561-8e5763a91c61.jpg'),Path('alligator_or_not/swamp/a71c8dcb-7bbb-4dba-8ae6-8a780d5c27c6.jpg'),Path('alligator_or_not/swamp/bbd1a832-a901-4e8f-8724-feac35fa8dcb.jpg'),Path('alligator_or_not/swamp/45b358b3-1a12-41d4-8972-8fa98b2baa52.jpg'),Path('alligator_or_not/swamp/cf664509-8eb6-42c8-9177-c17f48bc026b.jpg')...]</code></pre>
</div>
</div>
<p>The fastai <code>parent_label</code> function takes a <code>Path</code> object and returns a string of the file’s parent folder name.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:52:52.220251Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:52:52.219899Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:52:52.228734Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:52:52.227090Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:52:52.220222Z&quot;}" data-outputid="addf1548-9f73-4967-ee43-194a21b691d1">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>parent_label(Path(<span class="st">'alligator_or_not/swamp/18b55d4f-3d3b-4013-822b-724489a23f01.jpg'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>'swamp'</code></pre>
</div>
</div>
<p>Some image files that are downloaded may be corrupted, so they have provided a <code>verify_images</code> function to find images that can’t be opened. Those images are then removed (<code>unlink</code>ed) from the path.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:54:57.585333Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:54:57.584969Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:54:59.045943Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:54:59.044336Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:54:57.585333Z&quot;}" data-outputid="9ec9854d-e39e-4b8f-cba0-85537d1a5af7">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>failed <span class="op">=</span> verify_images(get_image_files(path))</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>failed.<span class="bu">map</span>(Path.unlink)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(failed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>1</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:55:26.522060Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:55:26.521466Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:55:26.531156Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:55:26.529641Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:55:26.522013Z&quot;}" data-outputid="c4807346-e943-4545-ba8d-ed54e8c119e1">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>failed</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(#1) [Path('alligator_or_not/alligator/1eb55508-274b-4e23-a6ae-dbbf1943a9d1.jpg')]</code></pre>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:55:31.955680Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:55:31.955680Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:55:34.911386Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:55:34.910265Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:55:31.955680Z&quot;}" data-outputid="6c219276-360f-4784-abbf-276889fbdaf0">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> DataBlock(</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    blocks<span class="op">=</span>(ImageBlock, CategoryBlock), </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    get_items<span class="op">=</span>get_image_files, </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    splitter<span class="op">=</span>RandomSplitter(valid_pct<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    get_y<span class="op">=</span>parent_label,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    item_tfms<span class="op">=</span>[Resize(<span class="dv">192</span>, method<span class="op">=</span><span class="st">'squish'</span>)]</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>).dataloaders(path, bs<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>dls.show_batch(max_n<span class="op">=</span><span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023_06_01_practical_deep_learning_for_coders_part_1_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>I’ll train the model using their code which uses the <code>resnet18</code> image classification model, and <code>fine_tune</code>s it for 3 epochs.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:55:40.668677Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:55:40.668172Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:55:53.089759Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:55:53.087080Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:55:40.668635Z&quot;}" data-outputid="8dc8256c-25c8-4ba9-aeae-f084bfb12181">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet18, metrics<span class="op">=</span>error_rate)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"796b8df19db8457d9fed77da8be14094","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.690250</td>
      <td>0.171598</td>
      <td>0.043478</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.127188</td>
      <td>0.001747</td>
      <td>0.000000</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.067970</td>
      <td>0.006409</td>
      <td>0.000000</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.056453</td>
      <td>0.004981</td>
      <td>0.000000</td>
      <td>00:02</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>The accuracy is 100%.</p>
<p>Next, I’ll test the model as they’ve done in the lesson.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:55:58.325965Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:55:58.325487Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:55:58.689187Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:55:58.687780Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:55:58.325925Z&quot;}" data-outputid="93d581d9-3cd1-4325-939f-03af9e26f174">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>PILImage.create(<span class="st">'alligator.jpg'</span>).to_thumb(<span class="dv">256</span>,<span class="dv">256</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<p><img src="2023_06_01_practical_deep_learning_for_coders_part_1_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T02:56:48.007685Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T02:56:48.006449Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T02:56:48.645473Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T02:56:48.644401Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T02:56:48.007685Z&quot;}" data-outputid="cd302286-a946-4129-d60c-26fcd85c9bdb">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>is_alligator,_,probs <span class="op">=</span> learn.predict(PILImage.create(<span class="st">'alligator.jpg'</span>))</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"This is an: </span><span class="sc">{</span>is_alligator<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Probability it's an alligator: </span><span class="sc">{</span>probs[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>This is an: alligator.
Probability it's an alligator: 1.0000</code></pre>
</div>
</div>
</section>
<section id="video-notes" class="level3">
<h3 class="anchored" data-anchor-id="video-notes">Video Notes</h3>
<p>In this section, I’ll take notes while I watch the lesson 1 video.</p>
<ul>
<li>This is the fifth version of the course!</li>
<li>What seemed impossible in 2015 (image recognition of a bird) is now free and something we can build in 2 minutes.</li>
<li>All models need numbers as their inputs. Images are already stored as numbers in computers. [PixSpy] allows you to (among other things) view the color of each pixel in an image file.</li>
<li>A <code>DataBlock</code> gives fastai all the information it needs to create a computer vision model.</li>
<li>Creating really interesting, real, working programs with deep learning is something that doesn’t take a lot of code, math, or more than a laptop computer. It’s pretty accessible.</li>
<li>Deep Learning models are doing things that very few, if any of us, believed would be possible to do by computers in our lifetime.</li>
<li>See the <a href="www.ethics.fast.ai">Practical Data Ethics</a> course as well.</li>
<li><a href="https://www.goodreads.com/en/book/show/58213068">Meta Learning: How To Learn Deep Learning And Thrive In The Digital World</a>.</li>
<li>Books on learning/education:
<ul>
<li>Mathematician’s Lament by Paul Lockhart</li>
<li>Making Learning Whole by David Perkins</li>
</ul></li>
<li>Why are we able to create a bird-recognizer in a minute or two? And why couldn’t we do it before?
<ul>
<li>2012: Project looking at 5-year survival of breast cancer patients, pre-deep learning approach
<ul>
<li>Assembled a team to build ideas for thousands of features that required a lot of expertise, took years.</li>
<li>They fed these features into a logistic regression model to predict survival.</li>
<li>Neural networks don’t require us to build these features, they build them for us.</li>
</ul></li>
<li>2015: Matthew D. Zeiler and Rob Fergus looked inside a neural network to see what it had learned.
<ul>
<li>We don’t give it features, we ask it to learn features.</li>
<li>The neural net is the basic function used in deep learning.</li>
<li>You start with a random neural network, feed it examples and you have it learn to recognize things.</li>
<li>The deeper you get, the more sophisticated the features it can find are.</li>
<li>What we’re going to learn is how neural networks do this automatically.</li>
<li>This is the key difference in why we can now do things that we couldn’t previously conceive of as possible.</li>
</ul></li>
</ul></li>
<li>An image recognizer can also be used to classify sounds (pictures of waveforms).</li>
<li>Turning time series into pictures for image classification.</li>
<li>fastai is built on top of PyTorch.</li>
<li><code>!pip install -Uqq fastai</code> to update.</li>
<li>Always view your data at every step of building a model.</li>
<li>For computer vision algorithms you don’t need particularly big images.</li>
<li>For big images, most of the time is taken up opening it, the neural net on the GPU is must faster.</li>
<li>The main thing you’re going to try and figure out is how do I get this data into my model?</li>
<li><code>DataBlock</code>
<ul>
<li><code>blocks=(ImageBlock, CategoryBlock)</code>: <code>ImageBlock</code> is the type of input to the model, <code>CategoryBlock</code> is the type of model output</li>
<li><code>get_image_files(path)</code> returns a list of all image files in a <code>path</code>.</li>
<li>It’s critical that you put aside some data for testing the accuracy of your model (validation set) with something like <code>RandomSplitter</code> for the <code>splitter</code> parameter.</li>
<li><code>get_y</code> tells fastai how to get the correct label for the photo.</li>
<li>Most computer vision architectures need all of your inputs to be the same size, using <code>Resize</code> (either <code>crop</code> out a piece in the middle or <code>squish</code> the image) for the parameter <code>item_tfms</code>.</li>
<li><code>DataLoaders</code> contains iterators that PyTorch can run through to grab batches of your data to feed the training algorithm.</li>
<li><code>show_batch</code> shows you a batch of input/label pairs.</li>
<li>A <code>Learner</code> combines a model (the actual neural network that we are training) and the data we use to train it with.</li>
<li><a href="www.timm.fast.ai">PyTorch Image Models (timm)</a>.</li>
<li>resnet has already been trained to recognize over 1 million images of over 1000 different types. fastai downloads this so you can start with a neural network that can do a lot.</li>
<li><code>fine_tune</code> takes those pretrained weights downloaded for you and adjusts them in a carefully controlled way to teach the model differences between your dataset and what it was originally trained for.</li>
<li>You pass <code>.predict</code> an image, which is how you would deploy your model, returns whether it’s a bird or not as a string, integer and probability of whether it’s a bird (in this example).</li>
</ul></li>
</ul>
<p>In the code blocks below, I’ll train the different types of models presented in the video lesson.</p>
<section id="image-segmentation" class="level4">
<h4 class="anchored" data-anchor-id="image-segmentation">Image Segmentation</h4>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T23:56:34.634169Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T23:56:34.633811Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T23:57:06.225065Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T23:57:06.224220Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T23:56:34.634143Z&quot;}" data-outputid="a1fd3255-08bc-4409-a5f6-94503ec7efae">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.CAMVID_TINY)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> SegmentationDataLoaders.from_label_func(</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    path, bs <span class="op">=</span> <span class="dv">8</span>, fnames <span class="op">=</span> get_image_files(path<span class="op">/</span><span class="st">"images"</span>),</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    label_func <span class="op">=</span> <span class="kw">lambda</span> o: path<span class="op">/</span><span class="st">'labels'</span><span class="op">/</span><span class="ss">f'</span><span class="sc">{</span>o<span class="sc">.</span>stem<span class="sc">}</span><span class="ss">_P</span><span class="sc">{</span>o<span class="sc">.</span>suffix<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    codes <span class="op">=</span> np.loadtxt(path<span class="op">/</span><span class="st">'codes.txt'</span>, dtype<span class="op">=</span><span class="bu">str</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> unet_learner(dls, resnet34)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">8</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet34-b627a593.pth" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"96a180d833b54002bfe712de11acca7d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>3.454409</td>
      <td>3.015761</td>
      <td>00:06</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.928762</td>
      <td>1.719756</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.649520</td>
      <td>1.394089</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.533350</td>
      <td>1.344445</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.414438</td>
      <td>1.279674</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.291168</td>
      <td>1.063977</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>5</td>
      <td>1.174492</td>
      <td>0.980055</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>6</td>
      <td>1.073124</td>
      <td>0.931532</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.992161</td>
      <td>0.922516</td>
      <td>00:02</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-02T23:58:15.388952Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-02T23:58:15.388543Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-02T23:58:15.895325Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-02T23:58:15.894448Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-02T23:58:15.388925Z&quot;}" data-outputid="30f09ef9-1e80-4961-bc47-cac60dd6f07d">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>learn.show_results(max_n<span class="op">=</span><span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">7</span>,<span class="dv">8</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<p><img src="2023_06_01_practical_deep_learning_for_coders_part_1_files/figure-html/cell-19-output-3.png" class="img-fluid"></p>
</div>
</div>
<p>It’s amazing how many it’s getting correct because this model was trained in about 24 seconds using a tiny amount of data.</p>
<p>I’ll take a look at the codes out of curiousity, which is an array of string elements describing different objects in view.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-03T00:01:52.973792Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-03T00:01:52.972844Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-03T00:01:52.980767Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-03T00:01:52.979964Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-03T00:01:52.973764Z&quot;}" data-outputid="0da52cfd-03e7-4d5f-a9fd-1979a2dbaee1">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>np.loadtxt(path<span class="op">/</span><span class="st">'codes.txt'</span>, dtype<span class="op">=</span><span class="bu">str</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array(['Animal', 'Archway', 'Bicyclist', 'Bridge', 'Building', 'Car',
       'CartLuggagePram', 'Child', 'Column_Pole', 'Fence', 'LaneMkgsDriv',
       'LaneMkgsNonDriv', 'Misc_Text', 'MotorcycleScooter', 'OtherMoving',
       'ParkingBlock', 'Pedestrian', 'Road', 'RoadShoulder', 'Sidewalk',
       'SignSymbol', 'Sky', 'SUVPickupTruck', 'TrafficCone',
       'TrafficLight', 'Train', 'Tree', 'Truck_Bus', 'Tunnel',
       'VegetationMisc', 'Void', 'Wall'], dtype='&lt;U17')</code></pre>
</div>
</div>
</section>
<section id="tabular-analysis" class="level4">
<h4 class="anchored" data-anchor-id="tabular-analysis">Tabular Analysis</h4>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-03T00:14:11.040180Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-03T00:14:11.039746Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-03T00:14:11.310155Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-03T00:14:11.308220Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-03T00:14:11.040153Z&quot;}" data-outputid="fe1f0ed2-5efb-4d4d-db1f-5f39d16f1a37">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.tabular.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.ADULT_SAMPLE)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> TabularDataLoaders.from_csv(path<span class="op">/</span><span class="st">'adult.csv'</span>, path<span class="op">=</span>path, y_names<span class="op">=</span><span class="st">'salary'</span>,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>                                  cat_names <span class="op">=</span> [<span class="st">'workclass'</span>, <span class="st">'education'</span>, <span class="st">'marital-status'</span>, <span class="st">'occupation'</span>,</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>                                               <span class="st">'relationship'</span>, <span class="st">'race'</span>],</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>                                  cont_names <span class="op">=</span> [<span class="st">'age'</span>, <span class="st">'fnlwgt'</span>, <span class="st">'education-num'</span>],</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>                                  procs <span class="op">=</span> [Categorify, FillMissing, Normalize])</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>dls.show_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>workclass</th>
      <th>education</th>
      <th>marital-status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>education-num_na</th>
      <th>age</th>
      <th>fnlwgt</th>
      <th>education-num</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>State-gov</td>
      <td>Some-college</td>
      <td>Divorced</td>
      <td>Adm-clerical</td>
      <td>Own-child</td>
      <td>White</td>
      <td>False</td>
      <td>42.0</td>
      <td>138162.000499</td>
      <td>10.0</td>
      <td>&lt;50k</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Private</td>
      <td>HS-grad</td>
      <td>Married-civ-spouse</td>
      <td>Other-service</td>
      <td>Husband</td>
      <td>Asian-Pac-Islander</td>
      <td>False</td>
      <td>40.0</td>
      <td>73025.003080</td>
      <td>9.0</td>
      <td>&lt;50k</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Private</td>
      <td>Assoc-voc</td>
      <td>Married-civ-spouse</td>
      <td>Prof-specialty</td>
      <td>Wife</td>
      <td>White</td>
      <td>False</td>
      <td>36.0</td>
      <td>163396.000571</td>
      <td>11.0</td>
      <td>&gt;=50k</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Private</td>
      <td>HS-grad</td>
      <td>Never-married</td>
      <td>Sales</td>
      <td>Own-child</td>
      <td>White</td>
      <td>False</td>
      <td>18.0</td>
      <td>110141.999831</td>
      <td>9.0</td>
      <td>&lt;50k</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Self-emp-not-inc</td>
      <td>12th</td>
      <td>Divorced</td>
      <td>Other-service</td>
      <td>Unmarried</td>
      <td>White</td>
      <td>False</td>
      <td>28.0</td>
      <td>33035.002716</td>
      <td>8.0</td>
      <td>&lt;50k</td>
    </tr>
    <tr>
      <th>5</th>
      <td>?</td>
      <td>7th-8th</td>
      <td>Separated</td>
      <td>?</td>
      <td>Own-child</td>
      <td>White</td>
      <td>False</td>
      <td>50.0</td>
      <td>346013.994175</td>
      <td>4.0</td>
      <td>&lt;50k</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Self-emp-inc</td>
      <td>HS-grad</td>
      <td>Never-married</td>
      <td>Farming-fishing</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>False</td>
      <td>36.0</td>
      <td>37018.999571</td>
      <td>9.0</td>
      <td>&lt;50k</td>
    </tr>
    <tr>
      <th>7</th>
      <td>State-gov</td>
      <td>Masters</td>
      <td>Married-civ-spouse</td>
      <td>Prof-specialty</td>
      <td>Husband</td>
      <td>White</td>
      <td>False</td>
      <td>37.0</td>
      <td>239409.001471</td>
      <td>14.0</td>
      <td>&gt;=50k</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Self-emp-not-inc</td>
      <td>Doctorate</td>
      <td>Married-civ-spouse</td>
      <td>Prof-specialty</td>
      <td>Husband</td>
      <td>White</td>
      <td>False</td>
      <td>50.0</td>
      <td>167728.000009</td>
      <td>16.0</td>
      <td>&gt;=50k</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Private</td>
      <td>HS-grad</td>
      <td>Married-civ-spouse</td>
      <td>Tech-support</td>
      <td>Husband</td>
      <td>White</td>
      <td>False</td>
      <td>38.0</td>
      <td>247111.001513</td>
      <td>9.0</td>
      <td>&gt;=50k</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>For tabular models, there’s not generally going to be a pretrained model that already does something like what you want because every table of data is very different, so generally it doesn’t make too much sense to <code>fine_tune</code> a tabular model.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-03T00:17:53.373998Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-03T00:17:53.373652Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-03T00:18:05.741254Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-03T00:18:05.740365Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-03T00:17:53.373971Z&quot;}" data-outputid="2290b9e2-cec1-45ab-8337-763e2fb93444">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> tabular_learner(dls, metrics<span class="op">=</span>accuracy)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.373780</td>
      <td>0.365976</td>
      <td>0.832770</td>
      <td>00:06</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.356514</td>
      <td>0.358780</td>
      <td>0.833999</td>
      <td>00:05</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</section>
<section id="collaborative-filtering" class="level4">
<h4 class="anchored" data-anchor-id="collaborative-filtering">Collaborative Filtering</h4>
<p>The basis of most recommendation systems.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-03T00:21:14.590969Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-03T00:21:14.589974Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-03T00:21:14.639100Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-03T00:21:14.637918Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-03T00:21:14.590940Z&quot;}" data-outputid="a35cdb96-f3df-47f7-be63-9ccd2214f3de">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.collab <span class="im">import</span> <span class="op">*</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.ML_SAMPLE)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> CollabDataLoaders.from_csv(path<span class="op">/</span><span class="st">'ratings.csv'</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>dls.show_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>457</td>
      <td>457</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>407</td>
      <td>2959</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>294</td>
      <td>356</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>78</td>
      <td>356</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>596</td>
      <td>3578</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>5</th>
      <td>547</td>
      <td>541</td>
      <td>3.5</td>
    </tr>
    <tr>
      <th>6</th>
      <td>105</td>
      <td>1193</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>176</td>
      <td>4993</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>8</th>
      <td>430</td>
      <td>1214</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>607</td>
      <td>858</td>
      <td>4.5</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>There’s actually no pretrained collaborative filtering model so we could use <code>fit_one_cycle</code> but <code>fine_tune</code> works here as well.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-03T00:22:52.587261Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-03T00:22:52.586796Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-03T00:22:59.235681Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-03T00:22:59.234818Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-03T00:22:52.587236Z&quot;}" data-outputid="c6cc253b-a278-4a51-e8c7-5fdba24b0d5e">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> collab_learner(dls, y_range<span class="op">=</span>(<span class="fl">0.5</span>, <span class="fl">5.5</span>))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.498450</td>
      <td>1.417215</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.375927</td>
      <td>1.357755</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.274781</td>
      <td>1.176326</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.033917</td>
      <td>0.870168</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.810119</td>
      <td>0.719341</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.704180</td>
      <td>0.679201</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.640635</td>
      <td>0.667121</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.623741</td>
      <td>0.661391</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.620811</td>
      <td>0.657624</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.606947</td>
      <td>0.656678</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.605081</td>
      <td>0.656613</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-03T00:25:40.850317Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-03T00:25:40.849783Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-03T00:25:40.903649Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-03T00:25:40.902637Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-03T00:25:40.850289Z&quot;}" data-outputid="b32b5d3b-3e90-420b-95a1-39016951935b">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>learn.show_results()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>rating</th>
      <th>rating_pred</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>15.0</td>
      <td>35.0</td>
      <td>4.5</td>
      <td>3.886339</td>
    </tr>
    <tr>
      <th>1</th>
      <td>68.0</td>
      <td>64.0</td>
      <td>5.0</td>
      <td>3.822170</td>
    </tr>
    <tr>
      <th>2</th>
      <td>62.0</td>
      <td>33.0</td>
      <td>4.0</td>
      <td>3.088149</td>
    </tr>
    <tr>
      <th>3</th>
      <td>39.0</td>
      <td>91.0</td>
      <td>4.0</td>
      <td>3.788227</td>
    </tr>
    <tr>
      <th>4</th>
      <td>37.0</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>4.434169</td>
    </tr>
    <tr>
      <th>5</th>
      <td>38.0</td>
      <td>98.0</td>
      <td>3.5</td>
      <td>4.380877</td>
    </tr>
    <tr>
      <th>6</th>
      <td>3.0</td>
      <td>25.0</td>
      <td>3.0</td>
      <td>3.443295</td>
    </tr>
    <tr>
      <th>7</th>
      <td>23.0</td>
      <td>13.0</td>
      <td>2.0</td>
      <td>3.220192</td>
    </tr>
    <tr>
      <th>8</th>
      <td>15.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>4.306846</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>Note: <a href="https://rise.readthedocs.io/en/stable/">RISE</a> turnes your notebook into a presentation.</p>
<p>Generally speaking, if it’s something that a human can do reasonably quickly, even an expert human (like look at a Go board and decide if it’s a good board or not) then that’s probably something that deep learning will probably be good at. If it’s something that takes logical thought process over time, particularly if it’s not based on much data, deep learning probably won’t do that well.</p>
<p>The first neural network was built in 1957. The basic ideas have not changed much at all.</p>
<p>What’s going on in these models?</p>
<ul>
<li>Arthur Samuel in late 1950s invented Machine Learning.</li>
<li>Normal program: input -&gt; program -&gt; results.</li>
<li>Machine Learning model: input and weights (parameters) -&gt; model -&gt; results.
<ul>
<li>The model is a mathematical function that takes the input, multiplies them with one set of weights and adds them up, then does that again for a second set of weights, and so forth.</li>
<li>It takes all of the negative numbers and replaces them with 0.</li>
<li>It takes all those numbers as inputs to the next layer.</li>
<li>And it repeats a few times.</li>
</ul></li>
<li>Weights start out as being random.</li>
<li>A more useful workflow: input/weights -&gt; model -&gt; results -&gt; loss -&gt; update weights.</li>
<li>The loss is a number that says how good the results were.</li>
<li>We need a way to come up with a new set of weights that are a bit better than the current weights.</li>
<li>“bit better” weights means it makes the loss a bit better.</li>
<li>If we make it a little bit better a few times, it’ll eventually get good.</li>
<li>Neural nets proven to solve any computable function (i.e.&nbsp;it’s flexible enough to update weights until the results are good).</li>
<li>“Generate artwork based on someone’s twitter bio” is a computable function.</li>
<li>Once we’ve finished the training procedure we don’t the loss and the weights can be integrated into the model.</li>
<li>We end up with inputs -&gt; model -&gt; results which looks like our original idea of a program.</li>
<li>Deploying a model will have lots of tricky details but there will be one line of code which says <code>learn.predict</code> which takes an input and provides results.</li>
<li>The most important thing to do is experiment.</li>
</ul>
</section>
</section>
<section id="book-notes" class="level3">
<h3 class="anchored" data-anchor-id="book-notes">Book Notes</h3>
<p>Chapter 1: Your Deep Learning Journey In this section, I’ll take notes while I read Chapter 1 in the textbook.</p>
<section id="deep-learning-is-for-everyone" class="level4">
<h4 class="anchored" data-anchor-id="deep-learning-is-for-everyone">Deep Learning is for Everyone</h4>
<ul>
<li>What you don’t need for deep learning: lots of math, lots of data, lots of expensive computers.</li>
<li>Deep learning is a computer technique to extract and transform data by using multiple layers of neural networks. Each of these layers takes its inputs from previous layers and progressively refines them. The layers are trained by algorithms that minimize their errors and improve their accuracy. In this way, the network learns to perform a specified task.</li>
</ul>
</section>
<section id="neural-networks-a-brief-history" class="level4">
<h4 class="anchored" data-anchor-id="neural-networks-a-brief-history">Neural Networks: A Brief History</h4>
<ul>
<li>Warren McCulloch and Walter Pitts developed a mathematical model of an artificial neuron in 1943.</li>
<li>Most of Pitt’s famous work was done while he was homeless.</li>
<li>Psychologist Frank Rosenblatt further developed the artificial neuron to give it the ability to learn and built the first device that used these principles, the Mark I Perceptron, which was able to recognize simple shapes.</li>
<li>Marvin Minsky and Seymour Papert wrote a book about the Perceptron and showed that using multiple layers of the devices would allow the limitations of a single layer to be addressed.</li>
<li>The 1986 book Parallel Distributed Processing (PDP) by David Rumelhart, James McClelland, and the PDP Research Group defined PDP as requiring the following:
<ul>
<li>A set of <em>processing units</em>.</li>
<li>A <em>state of activation</em>.</li>
<li>An <em>output function</em> for each unit.</li>
<li>A <em>pattern of connectivity</em> among units.</li>
<li>A <em>propogation rule</em> for propagating patterns of activities through the network of connectivities.</li>
<li>An <em>activation rule</em> for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit.</li>
<li>A <em>learning rule</em> whereby patterns of connectivity are modified by experience.</li>
<li>An <em>environment</em> within which the system must operate.</li>
</ul></li>
</ul>
</section>
<section id="how-to-learn-deep-learning" class="level4">
<h4 class="anchored" data-anchor-id="how-to-learn-deep-learning">How to Learn Deep Learning</h4>
<ul>
<li>The hardest part of deep learning is artisanal: how do you know if you’ve got enough data, whether it is in the right format, if your model is training properly, and, if it’s not, what you should do about it?</li>
</ul>
<div class="cell" data-outputid="5eb90963-9bcc-4bbd-db0e-42e945ee6308" data-execution_count="1">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span> </span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.PETS)<span class="op">/</span><span class="st">'images'</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> is_cat(x): <span class="cf">return</span> x[<span class="dv">0</span>].isupper()</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> ImageDataLoaders.from_name_func(</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>    path,</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    get_image_files(path),</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    valid_pct<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    label_func<span class="op">=</span>is_cat, </span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    item_tfms<span class="op">=</span>Resize(<span class="dv">224</span>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>dls.show_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="811712512" class="" max="811706944" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [811712512/811706944 00:11&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display">
<p><img src="2023_06_01_practical_deep_learning_for_coders_part_1_files/figure-html/cell-26-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="f474f3c8-e45c-4fe3-b47b-ba1817f00f7b" data-execution_count="2">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> cnn_learner(dls, resnet34, metrics<span class="op">=</span>error_rate)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/fastai/vision/learner.py:288: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code
  warn("`cnn_learner` has been renamed to `vision_learner` -- please update your code")
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet34-b627a593.pth" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth
100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 162MB/s]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.140327</td>
      <td>0.019135</td>
      <td>0.007442</td>
      <td>01:05</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">


    <div>
      <progress value="0" class="" max="1" style="width:300px; height:20px; vertical-align: middle;"></progress>
      0.00% [0/1 00:00&lt;?]
    </div>
    
<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table><p>

    </p><div>
      <progress value="1" class="" max="24" style="width:300px; height:20px; vertical-align: middle;"></progress>
      4.17% [1/24 00:01&lt;00:34]
    </div>
    
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>error_rate</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.070464</td>
      <td>0.024966</td>
      <td>0.006766</td>
      <td>01:00</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>The <em>error rate</em> is the proportion of images that were incorrectly identified.</p>
<p>Check this model actually works with an image of a dog or cat. I’ll download a picture from google and use it for prediction:</p>
<div class="cell" data-outputid="2597cfba-f2cd-4a22-8b5e-a4c3aef5795e" data-execution_count="4">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ipywidgets <span class="im">as</span> widgets</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>uploader <span class="op">=</span> widgets.FileUpload()</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>uploader</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d7c5b1cfaf89495caa581dc1c23ba698","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-outputid="f5df690e-a9d6-4996-f2fa-60606df4c5b3" data-execution_count="5">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> PILImage.create(uploader.data[<span class="dv">0</span>])</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>is_cat, _, probs <span class="op">=</span> learn.predict(im)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>im.to_thumb(<span class="dv">256</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<p><img src="2023_06_01_practical_deep_learning_for_coders_part_1_files/figure-html/cell-29-output-3.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="47f0d9a0-2dab-419b-cd49-bd1585a2a292" data-execution_count="6">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Is this a cat?: </span><span class="sc">{</span>is_cat<span class="sc">}</span><span class="ss">.'</span>)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Probability it's a cat: </span><span class="sc">{</span>probs[<span class="dv">1</span>]<span class="sc">.</span>item()<span class="sc">:.6f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Is this a cat?: True.
Probability it's a cat: 1.000000</code></pre>
</div>
</div>
</section>
<section id="what-is-machine-learning" class="level4">
<h4 class="anchored" data-anchor-id="what-is-machine-learning">What is Machine Learning?</h4>
<ul>
<li>A traditional program: <strong>inputs</strong> -&gt; <strong>program</strong> -&gt; <strong>results</strong>.</li>
<li>In 1949, IBM researcher Arthur Samuel started working on machine learning. His basic idea was this: instead of telling the computer the exact steps required to solve a problem, show it examples of the problem to solve, and let it figure out how to solve it itself.</li>
<li>In 1961 his checkers-playing program had learned so much that it beat the Connecticut state champion.</li>
<li>Weights are just variables and a <em>weight assignment</em> is a particular choice of values for those variables.</li>
<li>The program’s inputs are values that it processes in order to produce its results (for instance, taking image pixels as inputs, and returning the classification “dog” as a result).</li>
<li>Because the weights affect the program, they are in a sense another kind of input.</li>
<li>A program using weight assignment: <strong>inputs and weights</strong> -&gt; <strong>model</strong> -&gt; <strong>results</strong>.</li>
<li>A model is a special kind of program, on that can do many different things depending on the weights.</li>
<li>Weights = parameters, with the term “weights” reserved for a particulat type of model parameter.</li>
<li>Learning would become entirely automatic when the adjustment of the weights was also automatic.</li>
<li>Training a maching learning model: <strong>inputs and weights</strong> -&gt; <strong>model</strong> -&gt; <strong>results</strong> -&gt; <strong>performance</strong> -&gt; <strong>update weights</strong>.</li>
<li>results are different than the performance of a model.</li>
<li>Using a trained model as a program -&gt; <strong>inputs</strong> -&gt; <strong>model</strong> -&gt; <strong>results</strong>.</li>
<li>maching learning is the training of programs developed by allowing a computer to learn from its experience, rather than through manually coding the individual steps.</li>
</ul>
</section>
<section id="what-is-a-neural-network" class="level4">
<h4 class="anchored" data-anchor-id="what-is-a-neural-network">What is a Neural Network?</h4>
<ul>
<li>Neural networks is a mathematical function that can solve any problem to any level of accuracy.</li>
<li>Stochastic Gradient Descent (SGD) is a completely general way to update the weights of a neural network, to make it improve at any given task.</li>
<li>Image classification problem:
<ul>
<li>Our inputs are the images.</li>
<li>Our weights are the weights in the neural net.</li>
<li>Our model is a neural net.</li>
<li>Our results are the values that are calculated by the neural net, like “dog” or “cat”.</li>
</ul></li>
</ul>
</section>
<section id="a-bit-of-deep-learning-jargon" class="level4">
<h4 class="anchored" data-anchor-id="a-bit-of-deep-learning-jargon">A Bit of Deep Learning Jargon</h4>
<ul>
<li>The functional form of the model is called its <em>architecture</em>.</li>
<li>The weights are called <em>parameters</em>.</li>
<li>The <em>predictions</em> are calculated from the <em>independent variable</em>, which is the <em>data</em> not including the <em>labels</em>.</li>
<li>The <em>results</em> or the model are called <em>predictions</em>.</li>
<li>The measure of <em>performance</em> is called the <em>loss</em>.</li>
<li>The loss depends not only on the predictions, but also on the correct <em>labels</em> (also known as <em>targets</em> or the <em>dependent variable</em>).</li>
<li>Detailed training loop: <strong>inputs</strong> and <strong>parameters</strong> -&gt; <strong>architecture</strong> -&gt; <strong>predictions</strong> (+ <strong>labels</strong>) -&gt; <strong>loss</strong> -&gt; update <strong>parameters</strong>.</li>
</ul>
</section>
<section id="limitations-inherent-to-machine-learning" class="level4">
<h4 class="anchored" data-anchor-id="limitations-inherent-to-machine-learning">Limitations Inherent to Machine Learning</h4>
<ul>
<li>A model cannot be created without data.</li>
<li>A model can learn to operate on only the patterns seen in the input data used to train it.</li>
<li>This learning approach creates only predictions, not recommended actions.</li>
<li>It’s not enough to just have examples of input data, we need labels for that data too.</li>
<li><em>Positive feedback loop</em>: the more the model is used, the more biased the data becomes, making the model even more biased, and so forth.</li>
</ul>
</section>
<section id="how-our-image-recognizer-works" class="level4">
<h4 class="anchored" data-anchor-id="how-our-image-recognizer-works">How Our Image Recognizer Works</h4>
<ul>
<li><code>item_tfms</code> are applied to each item while <code>batch_tfms</code> are applied to a <em>batch</em> of items at a time using the GPU.</li>
<li>A <em>classification model</em> attempts to predict a class, or category.</li>
<li>A <em>regression model</em> is one that attempts to predict one or more numeric quantities, such as temperature or location.</li>
<li>The parameter <code>seed=42</code> sets the <em>random seed</em> to the same value every time we run this code, which means we get the same validation set every time we run it. This way, if we change our model and retrain it, we know that any differences are due to the changes to the model, not due to having a different random validation set.</li>
<li>We care about how well our model works on <em>previously unseen images</em>.</li>
<li>The longer you train for, the better your accuracy will get on the training set; the validation set accuracy will also improve for a while, but eventually it will start getting worse as the model starts to memorize the training set rather than finding generalizable underlying patterns in the data. When this happens, we say that the model is <em>overfitting</em>.</li>
<li>Overfitting is the single most important and challenging issue when training for all machine learning practitioners, and all algorithms.</li>
<li>You should only use methods to avoid overfitting after you have confirmed that overfitting is occurring (i.e., if you have observed the validation accuracy getting worse during training)</li>
<li>fastai defaults to <code>valid_pct=0.2</code>.</li>
<li>Models using architectures with more layers take longer to train and are more prone to overfitting, on the other hand, when using more data, they can be quite a bit more accurate.</li>
<li>A <em>metric</em> is a function that measures the quality of the model’s predictions using the validation set.</li>
<li><em>error_rate</em> tells you what percentage of inputs in the validation set are being classified incorrectly.</li>
<li><em>accuracy</em> = <code>1.0 - error_rate</code>.</li>
<li>The entire purpose of loss is to define a “measure of performance” that the training system can use to update weights automatically. A good choice for loss is a choice that is easy for stochastic gradient descent to use. But a metric is defined for human consumption, so a good metric is one that is easy for you to understand.</li>
<li>A model that has weights that have already been trained on another dataset is called a <em>pretrained model</em>.</li>
<li>When using a pretrained model, <code>cnn_learner</code> will remove the last layer and replace it with one or more new layers with randomized weights. This last part of the model is known as the <em>head</em>.</li>
<li>Using a pretrained model for a task different from what is was originally trained for is known as <em>transfer learning</em>.</li>
<li>The architecture only describes a <em>template</em> for a mathematical function; it doesn’t actually do anything until we provide values for the millions of parameters it contains.</li>
<li>To fit a model, we have to provide at least one piece of information: how many times to look at each image (known as number of epochs).</li>
<li><code>fit</code> will fit a model (i.e., look at images in the training set multiple times, each time updating the parameters to make the predictions closer and closer to the target labels).</li>
<li>Fine-Tuning: a transfer learning technique that updates the parameters of a pretrained model by training for additional epochs using a different task from that used for pretraining.</li>
<li><code>fine_tune</code> has a few parameters you can set, but in the default form it does two steps:
<ul>
<li>Use one epoch to fit just those parts of the model necessary to get the new random head to work correctly with your dataset.</li>
<li>Use the number of epochs requested when calling the method to fit the entire model, updating the weights of the later layers (especially the head) faster than the earlier layers (which don’t require many changes from the pretrained weights).</li>
</ul></li>
<li>The <em>head</em> of the model is the part that is newly added to be specific to the new dataset.</li>
<li>An <em>epoch</em> is one complete pass through the dataset.</li>
</ul>
</section>
<section id="what-our-image-recognizer-learned" class="level4">
<h4 class="anchored" data-anchor-id="what-our-image-recognizer-learned">What Our Image Recognizer Learned</h4>
<ul>
<li>When we fine tune our pretrained models, we adapt what the last layers focus on to specialize on the problem at hand.</li>
</ul>
</section>
<section id="image-recognizers-can-tackle-non-image-tasks" class="level4">
<h4 class="anchored" data-anchor-id="image-recognizers-can-tackle-non-image-tasks">Image Recognizers Can Tackle Non-Image Tasks</h4>
<ul>
<li>A lot of things can be represented as images.</li>
<li>Sound can be converted to a spectogram.</li>
<li>Times series data can be created into an image using Gramian Angular Difference Field (GADF).</li>
<li>If the human eye can recognize categories from the images, then a deep learning model should be able to do so too.</li>
</ul>
</section>
<section id="jargon-recap" class="level4">
<h4 class="anchored" data-anchor-id="jargon-recap">Jargon Recap</h4>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Term</th>
<th style="text-align: left;">Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Label</td>
<td style="text-align: left;">The data that we’re trying to predict</td>
</tr>
<tr class="even">
<td style="text-align: left;">Architecture</td>
<td style="text-align: left;">The <em>template</em> of the model that we’re trying to fit; i.e., the actual mathematical function that we’re passing the input data and parameters to</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Model</td>
<td style="text-align: left;">The combination of the architecture with a particular set of parameters</td>
</tr>
<tr class="even">
<td style="text-align: left;">Parameters</td>
<td style="text-align: left;">The values in the model that change what task it can do and that are updated through model training</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Fit</td>
<td style="text-align: left;">Update the parameters of the model such that the predictions of the model using the input data match the target labels</td>
</tr>
<tr class="even">
<td style="text-align: left;">Train</td>
<td style="text-align: left;">A synonym for <em>fit</em></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Pretrained Model</td>
<td style="text-align: left;">A model that has already been trained, generally using a large dataset, and will be fine-tuned</td>
</tr>
<tr class="even">
<td style="text-align: left;">Fine-tune</td>
<td style="text-align: left;">Update a pretrained model for a different task</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Epoch</td>
<td style="text-align: left;">One complete pass through the input data</td>
</tr>
<tr class="even">
<td style="text-align: left;">Loss</td>
<td style="text-align: left;">A measure of how good the model is, chosen to drive training via SGD</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Metric</td>
<td style="text-align: left;">A measurement of how good the model is using the validation set, chosen for human consumption</td>
</tr>
<tr class="even">
<td style="text-align: left;">Validation set</td>
<td style="text-align: left;">A set of data held out from training, used only for measuring how good the model is</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Training set</td>
<td style="text-align: left;">The data used for fitting the model; does not include any data from the validation set</td>
</tr>
<tr class="even">
<td style="text-align: left;">Overfitting</td>
<td style="text-align: left;">Training a model in such a way that it remembers specific features of the input data, rather than generalizing wel to data not seen during training</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CNN</td>
<td style="text-align: left;">Convolutional neural network; a type of neural network that works particularly well for computer vision tasks</td>
</tr>
</tbody>
</table>
</section>
<section id="deep-learning-is-not-just-for-image-classification" class="level4">
<h4 class="anchored" data-anchor-id="deep-learning-is-not-just-for-image-classification">Deep Learning is Not Just for Image Classification</h4>
<ul>
<li>Segmentation</li>
<li>Natural language processing (see below)</li>
<li>Tabular (see Adults income classification above)</li>
<li>Collaborative filtering (see MovieLens ratings predictor above)</li>
<li>Start by using one of the cut-down dataset versions and later scale up to the full-size version. This is how the world’s top practitioners do their modeling in practice; they do most of their experimentation and prototyping with subsets of their data, and use the full dataset only when they have a good understanding of what they have to do.</li>
</ul>
</section>
<section id="validation-sets-and-test-sets" class="level4">
<h4 class="anchored" data-anchor-id="validation-sets-and-test-sets">Validation Sets and Test Sets</h4>
<ul>
<li>If the model makes an accurate prediction for a data item, that should be because it has learned characteristics of that kind of item, and not because the model has been shaped by <em>actually having seen that particular item</em>.</li>
<li>Hyperparameters: various modeling choices regarding network architecture, learning rates, data augmentation strategies, and other factors.</li>
<li>We, as modelers, are evaluating the model by looking at predictions on the validation data when we decide to explore new hyperparameter values and we are in danger of overfitting the validation data through human trial and error and exploration.</li>
<li>The <em>test set</em> can be used only to evaluate the model at the very end of our efforts.</li>
<li>Training data is fully exposed to training and modeling processes, validation data is less exposed and test data is fully hidden.</li>
<li>The test and validation sets should have enough data to ensure that you get a good estimate of your accuracy.</li>
<li>The discipline of the test set helps us keep ourselves intellectually honest.</li>
<li>It’s a good idea for you to try out a simple baseline model yourself, so you know what a really simply model can achieve.</li>
</ul>
</section>
<section id="use-judgment-in-defining-test-sets" class="level4">
<h4 class="anchored" data-anchor-id="use-judgment-in-defining-test-sets">Use Judgment in Defining Test Sets</h4>
<ul>
<li>A key property of the validation and test sets is that they must be representative of the new data you will see in the future.</li>
<li>As an example, for time series data, use earlier dates for training set and later more recent dates as validation set</li>
<li>The data you will be making predictions for in production may be <em>qualitatively different</em> from the data you have to train your model with.</li>
</ul>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-06T04:03:08.930221Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-06T04:03:08.929803Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-06T04:03:21.475093Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-06T04:03:21.473954Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-06T04:03:08.930130Z&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.text.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># I'm using IMDB_SAMPLE instead of the full IMDB dataset since it either takes too long or </span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># I get a CUDA Out of Memory error if the batch size is more than 16 for the full dataset</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Using a batch size of 16 with the sample dataset works fast</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> TextDataLoaders.from_csv(</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>    path<span class="op">=</span>untar_data(URLs.IMDB_SAMPLE),</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>    csv_fname<span class="op">=</span><span class="st">'texts.csv'</span>,</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>    text_col<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>    label_col<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    bs<span class="op">=</span><span class="dv">16</span>) </span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>dls.show_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>category</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \n\n xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , xxunk bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no matter how warm and gooey xxmaj raising xxmaj victor xxmaj vargas became i was always aware that something did n't quite feel right . xxmaj victor xxmaj vargas suffers from a certain xxunk on the director 's part . xxmaj apparently , the director thought that the ethnic backdrop of a xxmaj latino family on the lower east side , and an xxunk storyline would make the film critic proof . xxmaj he was right , but it did n't fool me . xxmaj raising xxmaj victor xxmaj vargas is</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>1</th>
      <td>xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the xxunk and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that tries too hard , nor does it come up with the xxunk possible scenarios to get the two protagonists together in the end . xxmaj in fact , all its charm is xxunk , contained within the characters and the setting and the plot … which is highly believable to xxunk . xxmaj it 's easy to think that such a love story , as beautiful as any other ever told , * could * happen to you … a feeling you do n't often get from other romantic comedies</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>2</th>
      <td>xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj xxunk , after xxunk ) , i can xxunk join both xxunk of " at xxmaj the xxmaj movies " in taking xxmaj steven xxmaj soderbergh to task . \n\n xxmaj it 's usually satisfying to watch a film director change his style / subject , but xxmaj soderbergh 's most recent stinker , xxmaj the xxmaj girlfriend xxmaj xxunk ) , was also missing a story , so narrative ( and editing ? ) seem to suddenly be xxmaj soderbergh 's main challenge . xxmaj strange , after 20 - odd years in the business . xxmaj he was probably never much good at narrative , just xxunk it well inside " edgy " projects . \n\n xxmaj none of this excuses him this present ,</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>3</th>
      <td>xxbos i really wanted to love this show . i truly , honestly did . \n\n xxmaj for the first time , gay viewers get their own version of the " the xxmaj bachelor " . xxmaj with the help of his obligatory " hag " xxmaj xxunk , xxmaj james , a good looking , well - to - do thirty - something has the chance of love with 15 suitors ( or " mates " as they are referred to in the show ) . xxmaj the only problem is half of them are straight and xxmaj james does n't know this . xxmaj if xxmaj james picks a gay one , they get a trip to xxmaj new xxmaj zealand , and xxmaj if he picks a straight one , straight guy gets $ 25 , xxrep 3 0 . xxmaj how can this not be fun</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>4</th>
      <td>xxbos xxmaj many neglect that this is n't just a classic due to the fact that it 's the first 3d game , or even the first xxunk - up . xxmaj it 's also one of the first xxunk games , one of the xxunk definitely the first ) truly claustrophobic games , and just a pretty well - xxunk gaming experience in general . xxmaj with graphics that are terribly dated today , the game xxunk you into the role of xxunk even * think * xxmaj i 'm going to attempt spelling his last name ! ) , an xxmaj american xxup xxunk . caught in an underground bunker . xxmaj you fight and search your way through xxunk in order to achieve different xxunk for the six xxunk , let 's face it , most of them are just an excuse to hand you a weapon</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>5</th>
      <td>xxbos xxmaj i 'm sure things did n't exactly go the same way in the real life of xxmaj homer xxmaj hickam as they did in the film adaptation of his book , xxmaj rocket xxmaj boys , but the movie " october xxmaj sky " ( an xxunk of the book 's title ) is good enough to stand alone . i have not read xxmaj hickam 's memoirs , but i am still able to enjoy and understand their film adaptation . xxmaj the film , directed by xxmaj joe xxmaj xxunk and written by xxmaj lewis xxmaj xxunk , xxunk the story of teenager xxmaj homer xxmaj hickam ( jake xxmaj xxunk ) , beginning in xxmaj october of 1957 . xxmaj it opens with the sound of a radio broadcast , bringing news of the xxmaj russian satellite xxmaj xxunk , the first artificial satellite in</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>6</th>
      <td>xxbos xxmaj to review this movie , i without any doubt would have to quote that memorable scene in xxmaj tarantino 's " pulp xxmaj fiction " ( xxunk ) when xxmaj jules and xxmaj vincent are talking about xxmaj mia xxmaj wallace and what she does for a living . xxmaj jules tells xxmaj vincent that the " only thing she did worthwhile was pilot " . xxmaj vincent asks " what the hell is a pilot ? " and xxmaj jules goes into a very well description of what a xxup tv pilot is : " well , the way they make shows is , they make one show . xxmaj that show 's called a ' pilot ' . xxmaj then they show that show to the people who make shows , and on the strength of that one show they decide if they 're going to</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>7</th>
      <td>xxbos xxmaj how viewers react to this new " adaption " of xxmaj shirley xxmaj jackson 's book , which was promoted as xxup not being a remake of the original 1963 movie ( true enough ) , will be based , i suspect , on the following : those who were big fans of either the book or original movie are not going to think much of this one … and those who have never been exposed to either , and who are big fans of xxmaj hollywood 's current trend towards " special effects " being the first and last word in how " good " a film is , are going to love it . \n\n xxmaj things i did not like about this adaption : \n\n 1 . xxmaj it was xxup not a true adaption of the book . xxmaj from the xxunk i had</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>8</th>
      <td>xxbos xxmaj the trouble with the book , " memoirs of a xxmaj geisha " is that it had xxmaj japanese xxunk but underneath the xxunk it was all an xxmaj american man 's way of thinking . xxmaj reading the book is like watching a magnificent ballet with great music , sets , and costumes yet performed by xxunk animals dressed in those xxunk far from xxmaj japanese ways of thinking were the characters . \n\n xxmaj the movie is n't about xxmaj japan or real geisha . xxmaj it is a story about a few xxmaj american men 's mistaken ideas about xxmaj japan and geisha xxunk through their own ignorance and misconceptions . xxmaj so what is this movie if it is n't about xxmaj japan or geisha ? xxmaj is it pure fantasy as so many people have said ? xxmaj yes , but then why</td>
      <td>negative</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-06T04:03:24.682751Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-06T04:03:24.681122Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-06T04:05:48.714632Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-06T04:05:48.712873Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-06T04:03:24.682708Z&quot;}" data-execution_count="2">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> text_classifier_learner(dls, AWD_LSTM, drop_mult<span class="op">=</span><span class="fl">0.5</span>, metrics<span class="op">=</span>accuracy)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">4</span>, <span class="fl">1e-2</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.629276</td>
      <td>0.553454</td>
      <td>0.740000</td>
      <td>00:19</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.466581</td>
      <td>0.548400</td>
      <td>0.740000</td>
      <td>00:30</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.410401</td>
      <td>0.418941</td>
      <td>0.825000</td>
      <td>00:30</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.286162</td>
      <td>0.410872</td>
      <td>0.830000</td>
      <td>00:31</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.192047</td>
      <td>0.405275</td>
      <td>0.845000</td>
      <td>00:31</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-06T04:05:52.386624Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-06T04:05:52.386147Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-06T04:05:53.655249Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-06T04:05:53.653601Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-06T04:05:52.386590Z&quot;}" data-execution_count="3">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># view actual vs prediction</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>learn.show_results()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>category</th>
      <th>category_</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>xxbos xxmaj this film sat on my xxmaj xxunk for weeks before i watched it . i xxunk a self - indulgent xxunk flick about relationships gone bad . i was wrong ; this was an xxunk xxunk into the screwed - up xxunk of xxmaj new xxmaj xxunk . \n\n xxmaj the format is the same as xxmaj max xxmaj xxunk ' " la xxmaj xxunk , " based on a play by xxmaj arthur xxmaj xxunk , who is given an " inspired by " credit . xxmaj it starts from one person , a prostitute , standing on a street corner in xxmaj brooklyn . xxmaj she is picked up by a home contractor , who has sex with her on the hood of a car , but ca n't come . xxmaj he refuses to pay her . xxmaj when he 's off xxunk , she</td>
      <td>positive</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>1</th>
      <td>xxbos xxmaj bonanza had a great cast of wonderful actors . xxmaj xxunk xxmaj xxunk , xxmaj pernell xxmaj whitaker , xxmaj michael xxmaj xxunk , xxmaj dan xxmaj blocker , and even xxmaj guy xxmaj williams ( as the cousin who was brought in for several episodes during 1964 to replace xxmaj adam when he was leaving the series ) . xxmaj the cast had chemistry , and they seemed to genuinely like each other . xxmaj that made many of their weakest stories work a lot better than they should have . xxmaj it also made many of their best stories into great western drama . \n\n xxmaj like any show that was shooting over thirty episodes every season , there are bound to be some weak ones . xxmaj however , most of the time each episode had an interesting story , some kind of conflict ,</td>
      <td>positive</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>2</th>
      <td>xxbos i watched xxmaj grendel the other night and am compelled to put together a xxmaj public xxmaj service xxmaj announcement . \n\n xxmaj grendel is another version of xxmaj beowulf , the thousand - year - old xxunk - saxon epic poem . xxmaj the scifi channel has a growing catalog of xxunk and uninteresting movies , and the previews promised an xxunk low - budget mini - epic , but this one xxunk to let me switch xxunk . xxmaj it was xxunk , xxunk , bad . i watched in xxunk and horror at the train wreck you could n't tear your eyes away from . i reached for a xxunk and managed to capture part of what i was seeing . xxmaj the following may contain spoilers or might just save your xxunk . xxmaj you 've been warned . \n\n - xxmaj just to get</td>
      <td>negative</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>3</th>
      <td>xxbos xxmaj this is the last of four xxunk from xxmaj france xxmaj i 've xxunk for viewing during this xxmaj christmas season : the others ( in order of viewing ) were the uninspired xxup the xxup black xxup tulip ( 1964 ; from the same director as this one but not nearly as good ) , the surprisingly effective xxup lady xxmaj oscar ( 1979 ; which had xxunk as a xxmaj japanese manga ! ) and the splendid xxup cartouche ( xxunk ) . xxmaj actually , i had watched this one not too long ago on late - night xxmaj italian xxup tv and recall not being especially xxunk over by it , so that i was genuinely surprised by how much i enjoyed it this time around ( also bearing in mind the xxunk lack of enthusiasm shown towards the film here and elsewhere when</td>
      <td>positive</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>4</th>
      <td>xxbos xxmaj this is not really a zombie film , if we 're xxunk zombies as the dead walking around . xxmaj here the protagonist , xxmaj xxunk xxmaj louque ( played by an unbelievably young xxmaj dean xxmaj xxunk ) , xxunk control of a method to create zombies , though in fact , his ' method ' is to mentally project his thoughts and control other living people 's minds turning them into hypnotized slaves . xxmaj this is an interesting concept for a movie , and was done much more effectively by xxmaj xxunk xxmaj lang in his series of ' dr . xxmaj mabuse ' films , including ' dr . xxmaj mabuse the xxmaj xxunk ' ( 1922 ) and ' the xxmaj testament of xxmaj dr . xxmaj mabuse ' ( 1933 ) . xxmaj here it is unfortunately xxunk to his quest to</td>
      <td>negative</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>5</th>
      <td>xxbos " once upon a time there was a charming land called xxmaj france … . xxmaj people lived happily then . xxmaj the women were easy and the men xxunk in their favorite xxunk : war , the only xxunk of xxunk which the people could enjoy . " xxmaj the war in question was the xxmaj seven xxmaj year 's xxmaj war , and when it was noticed that there were more xxunk of soldiers than soldiers , xxunk were sent out to xxunk the ranks . \n\n xxmaj and so it was that xxmaj fanfan ( gerard xxmaj philipe ) , caught xxunk a farmer 's daughter in a pile of hay , escapes marriage by xxunk in the xxmaj xxunk xxunk … but only by first believing his future as xxunk by a gypsy , that he will win fame and fortune in xxmaj his xxmaj</td>
      <td>positive</td>
      <td>positive</td>
    </tr>
    <tr>
      <th>6</th>
      <td>xxbos xxup ok , let me again admit that i have n't seen any other xxmaj xxunk xxmaj ivory ( the xxunk ) films . xxmaj nor have i seen more celebrated works by the director , so my capacity to xxunk xxmaj before the xxmaj rains outside of analysis of the film itself is xxunk . xxmaj with that xxunk , let me begin . \n\n xxmaj before the xxmaj rains is a different kind of movie that does n't know which genre it wants to be . xxmaj at first , it pretends to be a romance . xxmaj in most romances , the protagonist falls in love with a supporting character , is separated from the supporting character , and is ( sometimes ) united with his or her partner . xxmaj this movie 's hero has already won the heart of his lover but can not</td>
      <td>negative</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>7</th>
      <td>xxbos xxmaj first off , anyone looking for meaningful " outcome xxunk " cinema that packs some sort of social message with meaningful performances and soul searching dialog spoken by dedicated , xxunk , heartfelt xxunk , please leave now . xxmaj you are wasting your time and life is short , go see the new xxmaj xxunk xxmaj jolie movie , have a good cry , go out &amp; buy a xxunk car or throw away your conflict xxunk if that will make you feel better , and leave us alone . \n\n xxmaj do n't let the door hit you on the way out either . xxup the xxup incredible xxup melting xxup man is a grade b minus xxunk horror epic shot in the xxunk of xxmaj oklahoma by a young , xxup tv friendly cast &amp; crew , and concerns itself with an astronaut who is</td>
      <td>positive</td>
      <td>negative</td>
    </tr>
    <tr>
      <th>8</th>
      <td>xxbos " national xxmaj treasure " ( 2004 ) is a thoroughly misguided xxunk - xxunk of plot xxunk that borrow from nearly every xxunk and dagger government conspiracy cliché that has ever been written . xxmaj the film stars xxmaj nicholas xxmaj cage as xxmaj benjamin xxmaj xxunk xxmaj xxunk ( how precious is that , i ask you ? ) ; a seemingly normal fellow who , for no other reason than being of a xxunk of like - minded misguided fortune hunters , decides to steal a ' national treasure ' that has been hidden by the xxmaj united xxmaj states xxunk fathers . xxmaj after a bit of subtext and background that plays laughably ( unintentionally ) like xxmaj indiana xxmaj jones meets xxmaj the xxmaj patriot , the film xxunk into one misguided xxunk after another  attempting to create a ' stanley xxmaj xxunk</td>
      <td>negative</td>
      <td>negative</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-06-06T04:06:50.045677Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-06-06T04:06:50.045106Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-06-06T04:06:50.335478Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-06-06T04:06:50.334327Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-06-06T04:06:50.045639Z&quot;}" data-execution_count="5">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>review_text <span class="op">=</span> <span class="st">"I really liked the movie!"</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>learn.predict(review_text)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>('positive', tensor(1), tensor([0.0174, 0.9826]))</code></pre>
</div>
</div>
</section>
</section>
<section id="questionnaire" class="level3">
<h3 class="anchored" data-anchor-id="questionnaire">Questionnaire</h3>
<ol type="1">
<li>Do you need these for deep learning?
<ul>
<li>Lots of Math (FALSE).</li>
<li>Lots of Data (FALSE).</li>
<li>Lots of expensive computers (FALSE).</li>
<li>A PhD (FALSE).</li>
</ul></li>
<li>Name five areas where deep learning is now the best tool in the world
<ul>
<li>Natural Language Processing (NLP).</li>
<li>Computer vision.</li>
<li>Medicine.</li>
<li>Image generation.</li>
<li>Recommendation systems.</li>
</ul></li>
<li>What was the name of the first device that was based on the principle of the artificial neuron?
<ul>
<li>Mark I Perceptron.</li>
</ul></li>
<li>Based on the book of the same name, what are the requirements for parallel distributed processing (PDP)?
<ul>
<li>A series of <em>processing units</em>.</li>
<li>A <em>state of activation</em>.</li>
<li>An <em>output function</em> for each unit.</li>
<li>A <em>pattern of connectivity</em> among units.</li>
<li>A <em>propagation rule</em> for propagating patterns of activities through the network of connectivities.</li>
<li>An <em>activation rule</em> for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit.</li>
<li>A <em>learning rule</em> whereby patterns of connectivity are modified by experience.</li>
<li>An <em>environment</em> within which the system must operate.</li>
</ul></li>
<li>What were the two theoretical misunderstandings that held back the field of neural networks?
<ul>
<li>Using multiple layers of the device would allow limitations of one layer to be addressed—this was ignored.</li>
<li>More than two layers are needed to get practical, good perforamnce—only in the last decade has this been more widely appreciated and applied.</li>
</ul></li>
<li>What is a GPU?
<ul>
<li>A Graphical Processing Unit, which can perform thousands of tasks at the same time.</li>
</ul></li>
<li>Open a notebook and execute a cell containing: <code>1+1</code>. What happens?
<ul>
<li>Depending on the server, it may take some time for the output to generate, but running this cell will output <code>2</code>.</li>
</ul></li>
<li>Follow through each cell of the stripped version of the notebook for this chapter. Before executing each cell, guess what will happen.
<ul>
<li>(I did this for the notebook shared for Lesson 1).</li>
</ul></li>
<li>Complete the Jupyter Notebook online appendix.
<ul>
<li>Done. Will reference some of it again.</li>
</ul></li>
<li>Why is it hard to use a traditional computer program to recognize images in a photo?
<ul>
<li>Because it’s hard to instruct a computer clear instructions to recognize images.</li>
</ul></li>
<li>What did Samuel mean by “weight assignment”?
<ul>
<li>A particular choice for weights (variables)</li>
</ul></li>
<li>What term do we normally use in deep learning for what Samuel called “weights”?
<ul>
<li>Parameters</li>
</ul></li>
<li>Draw a picture that summarizes Samuel’s view of a machine learning model
<ul>
<li>input and weights -&gt; model -&gt; results -&gt; performance -&gt; update weights/inputs</li>
</ul></li>
<li>Why is it hard to understand why a deep learning model makes a particular prediction?
<ul>
<li>Because a deep learning model has many layers and connectivities and activations between neurons that are not intuitive to our understanding.</li>
</ul></li>
<li>What is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy?
<ul>
<li>Universal approximation theorem.</li>
</ul></li>
<li>What do you need in order to train a model?
<ul>
<li>Labeled data (Inputs and targets).</li>
<li>Architecture.</li>
<li>Initial weights.</li>
<li>A measure of performance (loss, accuracy).</li>
<li>A way to update the model (SGD).</li>
</ul></li>
<li>How could a feedback loop impact the rollout of a predictive policing model?
<ul>
<li>The model will end up predicting where arrests are made, not where crime is taking place, so more police officers will go to locations where more arrests are predicted and feed that data back to the model which will reinforce the prediction of arrests in those areas, continuing this feedback loop of predictions -&gt; arrests -&gt; predictions.</li>
</ul></li>
<li>Do we always have to use 224x224-pixel images with the cat recognition model?
<ul>
<li>No, that’s just the convention for image recognition models.</li>
<li>You can use larger images but it will slow down the training process (it takes longer to open up bigger images).</li>
</ul></li>
<li>What is the difference between classification and regression?
<ul>
<li>Classification predicts discrete classes or categories.</li>
<li>Regression predicts continuous values.</li>
</ul></li>
<li>What is a validation set? What is a test set? Why do we need them?
<ul>
<li>A validation set is a dataset upon which a model’s accuracy (or metrics in general) is calculated during training, as well as the dataset upon which the performance of different hyperparameters (like batch size and learning rate) are measured.</li>
<li>A test set is a dataset upon which a model’s final performance is measured, a truly unseen dataset for both the model and the practitioner</li>
</ul></li>
<li>What will fastai do if you don’t provide a validation set?
<ul>
<li>Set aside a random 20% of the data as the validation set by default</li>
</ul></li>
<li>Can we always use a random sample for a validation set? Why or why not?
<ul>
<li>No, in situations where we want to ensure that the model’s accuracy is evaluated on data the model has not seen, we should not use a random validation set. Instead, we should create an intentional validation set. For example:
<ul>
<li>For time series data, use the most recent dates as the validation set</li>
<li>For human recognition data, use images of different people for training and validation sets</li>
</ul></li>
</ul></li>
<li>What is overfitting? Provide an example.
<ul>
<li>Overfitting is when a model memorizes features of the training dataset instead of learning generalizations of the features in the data. An example of this is when a model memorizes training data facial features but then cannot recognize different faces in the real world. Another example is when a model memorizes the handwritten digits in the training data, so it cannot then recognize digits written in different handwriting. Overfitting can be observed during training when the validation loss starts to increase as the training loss decreases.</li>
</ul></li>
<li>What is a metric? How does it differ from loss?
<ul>
<li>A metric a measurement of how good a model is performing, chosen for human consumption. A loss is also a measurement of how good a model is performing, but it’s chosen to drive training using an optimizer.</li>
</ul></li>
<li>How can pretrained models help?
<ul>
<li>Pretrained models are already good at recognizing many generalized features and so they can help by providing a set of weights in an architecture that are capable, reducing the amount of time you need to train a model specific to your task.</li>
</ul></li>
<li>What is the “head” of the model?
<ul>
<li>The last/top few neural network layers which are replaced with randomized weights in order to specialize your model via training on the task at hand (and not the task it was pretrained to perform).</li>
</ul></li>
<li>What kinds of features do the early layers of a CNN find? How about the later layers?
<ul>
<li>Early layers: simple features lie lines, color gradients</li>
<li>Later layers: compelx features like dog faces, outlines of people</li>
</ul></li>
<li>Are image models useful only for photos?
<ul>
<li>No! Lots of things can be represented by images so if you can represent something (like a sound) as an image (spectogram) and differences between classes/categories are easily recognizable by the human eye, you can train an image classifier to recognize it.</li>
</ul></li>
<li>What is an architecture?
<ul>
<li>A template, mathematical function, to which you pass input data to in order to fit/train a model</li>
</ul></li>
<li>What is segmentation?
<ul>
<li>Recognizing different objects in an image based on pixel colors (each object is a different pixel color)</li>
</ul></li>
<li>What is <code>y_range</code> used for? When do we need it?
<ul>
<li>It’s used to specify the output range of a regression model. We need it when the target is a continuous value.</li>
</ul></li>
<li>What are hyperparameters?
<ul>
<li>Modeling choices such as network architecture, learning rates, data augmentation strategies and other higher level choices that govern the meaning of the weight parameters.</li>
</ul></li>
<li>What is the best way to avoid failures when using AI in an organization?
<ul>
<li>Making sure you have good validation and test sets to evaluate the performance of a model on real world data.</li>
<li>Trying out a simple baseline model to know what level of performance such a model can achieve.</li>
</ul></li>
</ol>
</section>
<section id="further-research" class="level3">
<h3 class="anchored" data-anchor-id="further-research">Further Research</h3>
<ol type="1">
<li>Why is a GPU useful for deep learning? How is a CPU different, and why is it less effective for deep learning?
<ul>
<li><a href="https://blog.purestorage.com/purely-informational/cpu-vs-gpu-for-machine-learning/">CPU vs GPU for Machine Learning</a>
<ul>
<li>CPUs process tasks in a sequential manner, GPUs process tasks in parallel.</li>
<li>GPUs can have thousands of cores, processing tasks at the same time.</li>
<li>GPUs have many cores processing at low speeds, CPUs have few cores processing at high speeds.</li>
<li>Some algorithms are optimized for CPUs rather than GPUs (time series data, recommendation systems that need lots of memory).</li>
<li>Neural networks are designed to process tasks in parallel.</li>
</ul></li>
<li><a href="https://thinkml.ai/cpu-vs-gpu-in-machine-learning-algorithms-which-is-better/">CPU vs GPU in Machine Learning Algorithms: Which is Better?</a>
<ul>
<li>Machine Learning Operations Preferred on CPUs
<ul>
<li>Recommendation systems that involve huge memory for embedding layers.</li>
<li>Support vector machines, time-series data, algorithms that don’t require parallel computing.</li>
<li>Recurrent neural networks because they use sequential data.</li>
<li>Algorithms with intensive branching.</li>
</ul></li>
<li>Machine Learning Operations Preferred on GPUs
<ul>
<li>Operations that involve parallelism.</li>
</ul></li>
</ul></li>
<li><a href="https://towardsdatascience.com/why-deep-learning-uses-gpus-c61b399e93a0">Why Deep Learning Uses GPUs</a>
<ul>
<li>Neural networks are specifically made for running in parallel.</li>
</ul></li>
</ul></li>
<li>Try to think of three areas where feedback loops might impact the use of machine learning. See if you can find documented examples of that happening in practice.
<ul>
<li><a href="http://proceedings.mlr.press/v126/adam20a/adam20a.pdf">Hidden Risks of Machine Learning Applied to Healthcare: Unintended Feedback Loops Between Models and Future Data Causing Model Degradation</a>
<ul>
<li>If clinicians fully trust the machine learning model (100% adoption of the predicted label) the false positive rate (FPR) grows uncontrollably with the number of updates.</li>
</ul></li>
<li><a href="https://arxiv.org/pdf/1706.09847.pdf">Runaway Feedback Loops in Predictive Policing</a>
<ul>
<li>Once police are deployed based on these predictions, data from observations in the neighborhood is then used to further update the model.</li>
<li>Discovered crime data (e.g., arrest counts) are used to help update the model, and the process is repeated.</li>
<li>Predictive policing systems have been empirically shown to be susceptible to runaway feedback loops, where police are repeatedly sent back to the same neighborhoods regardless of the true crime rate.</li>
</ul></li>
<li><a href="https://vce.usc.edu/volume-5-issue-3/pitfalls-of-predictive-policing-an-ethical-analysis/#:~:text=By%20highlighting%20neighborhoods%20as%20high,also%20impacted%20by%20predictive%20policing.">Pitfalls of Predictive Policing: An Ethical Analysis</a>
<ul>
<li>Predictive policing relies on a large database of previous crime data and forecasts where crime is likely to occur. Since the program relies on old data, those previous arrests need to be unbiased to generate unbiased forecasts.</li>
<li>People of color are arrested far more often than white people for committing the same crime.</li>
<li>Racially biased arrest data creates biased forecasts in neighborhoods where more people of color are arrested.</li>
<li>If the predictive policing algorithm is using biased data to divert more police forces towards less affluent neighborhoods and neighborhoods of color, then those neighborhoods are not receiving the same treatment as others.</li>
</ul></li>
<li><a href="https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say">Bias in Criminal Risk Scores Is Mathematically Inevitable, Researchers Say</a>
<ul>
<li>The algorithm COMPAS which predicts whether a person is “high-risk” and deemed more likely to be arrested in the future, leads to being imprisoned (instead of sent to rehab) or longer sentences.</li>
</ul></li>
<li><a href="https://www.nprillinois.org/2023-01-31/can-bots-discriminate-its-a-big-question-as-companies-use-ai-for-hiring">Can bots discriminate? It’s a big question as companies use AI for hiring</a>
<ul>
<li>If an older candidate makes it past the resume screening process but gets confused by or interacts poorly with the chatbot, that data could teach the algorithm that candidates with similar profiles should be ranked lower</li>
</ul></li>
<li><a href="https://www.brookings.edu/research/echo-chambers-rabbit-holes-and-ideological-bias-how-youtube-recommends-content-to-real-users/">Echo chambers, rabbit holes, and ideological bias: How YouTube recommends content to real users</a>
<ul>
<li>We find that YouTube’s algorithm pushes real users into (very) mild ideological echo chambers.</li>
<li>We found that 14 out of 527 (~3%) of our users ended up in rabbit holes.</li>
<li>Finally, we found that, regardless of the ideology of the study participant, the algorithm pushes all users in a moderately conservative direction.</li>
</ul></li>
</ul></li>
</ol>


</section>
</section>
</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"63d0c81a06144c038ec6cac42ea19105":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7c5b1cfaf89495caa581dc1c23ba698":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FileUploadModel","state":{"_counter":1,"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FileUploadModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"FileUploadView","accept":"","button_style":"","data":[null],"description":"Upload","description_tooltip":null,"disabled":false,"error":"","icon":"upload","layout":"IPY_MODEL_63d0c81a06144c038ec6cac42ea19105","metadata":[{"lastModified":1685915950408,"name":"cat.jpg","size":634575,"type":"image/jpeg"}],"multiple":false,"style":"IPY_MODEL_ef0d803f166145bd8fbe613033fb8512"}},"ef0d803f166145bd8fbe613033fb8512":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>