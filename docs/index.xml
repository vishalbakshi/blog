<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Vishal Bakshi&#39;s Blog</title>
<link>https://vishalbakshi.github.io/blog/index.html</link>
<atom:link href="https://vishalbakshi.github.io/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Machine Learning blog by Vishal Bakshi</description>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Sat, 31 May 2025 07:00:00 GMT</lastBuildDate>
<item>
  <title>Under the Mean Shift Clustering Algorithm (and PyTorch Broadcasting)</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index.html</link>
  <description><![CDATA[ 



<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> math, matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt, operator, torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> functools <span class="im" style="color: #00769E;">import</span> partial</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> torch.distributions.multivariate_normal <span class="im" style="color: #00769E;">import</span> MultivariateNormal</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> tensor</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb2-2">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post I’ll walk through the Mean Shift Clustering algorithm as introduced <a href="https://github.com/fastai/course22p2/blob/master/nbs/02_meanshift.ipynb">in Lesson 12 of the fastai course (Part 2)</a>.</p>
<p>The algorithm:</p>
<blockquote class="blockquote">
<ul>
<li>For each data point <code>x</code> in the sample <code>X</code>, find the distance between that point <code>x</code> and every other point in <code>X</code></li>
<li>Create weights for each point in <code>X</code> by using the Gaussian kernel of that point’s distance to <code>x</code></li>
<li>This weighting approach penalizes points further away from <code>x</code></li>
<li>The rate at which the weights fall to zero is determined by the bandwidth, which is the standard deviation of the Gaussian</li>
<li>Update <code>x</code> as the weighted average of all other points in <code>X</code>, weighted based on the previous step</li>
</ul>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Conceptual visual showing the mean shift clustering algorithm weighting by distance. The red point is x."><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Conceptual visual showing the mean shift clustering algorithm weighting by distance. The red point is <code>x</code>.</figcaption><p></p>
</figure>
</div>
</section>
<section id="generating-clearly-clustered-data" class="level2">
<h2 class="anchored" data-anchor-id="generating-clearly-clustered-data">Generating Clearly Clustered Data</h2>
<p>An important point: we start by creating fake data such that it is knowingly clustered around a set of centroids we can then compare to the final clustering result.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">n_clusters<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span></span>
<span id="cb3-2">n_samples <span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">250</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">centroids <span class="op" style="color: #5E5E5E;">=</span> torch.rand(n_clusters, <span class="dv" style="color: #AD0000;">2</span>)<span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">70</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">35</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="f832bd33-2d31-4058-a7e6-9139a6b3acef" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">centroids.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>torch.Size([6, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="98fe6cdb-34d3-4a22-bb3a-f6f5e2b5019e" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">centroids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[ 26.759,  29.050],
        [ -8.200,  32.151],
        [ -7.669,   7.063],
        [-17.040,  20.555],
        [ 30.854, -25.677],
        [ 30.422,   6.551]])</code></pre>
</div>
</div>
<p>We’ll generate data around these 6 centroids using PyTorch’s <code>MultivariateNormal</code> which:</p>
<blockquote class="blockquote">
<p>Creates a multivariate normal (also called Gaussian) distribution parameterized by a mean vector and a covariance matrix.</p>
</blockquote>
<p>The covariance matrix in our case is a diagonal matrix with 5s on the diagonal.</p>
<p>We generate 250 samples for each mean vector (centroid).</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;">def</span> sample(m): <span class="cf" style="color: #003B4F;">return</span> MultivariateNormal(m, torch.diag(tensor([<span class="fl" style="color: #AD0000;">5.</span>,<span class="fl" style="color: #AD0000;">5.</span>]))).sample((n_samples,))</span></code></pre></div>
</div>
<div class="cell" data-outputid="5684ae06-811e-4a0e-ec3e-f5e9830a41ed" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">torch.diag(tensor([<span class="fl" style="color: #AD0000;">5.</span>,<span class="fl" style="color: #AD0000;">5.</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor([[5., 0.],
        [0., 5.]])</code></pre>
</div>
</div>
<p>From Gemini this covariance matrix shows:</p>
<blockquote class="blockquote">
<ul>
<li><strong>No Correlation</strong>: The two variables are uncorrelated (covariance is 0.0). For a <code>MultivariateNormal</code> distribution, this implies they are independent.</li>
<li><strong>Equal Variance</strong>: Both variables have the same variance of 5.0.</li>
<li><strong>Shape</strong>: If used in a 2D MultivariateNormal distribution, this will produce a circular cloud of data points, equally spread along both the X and Y axes.</li>
</ul>
</blockquote>
<div class="cell" data-outputid="93047335-d41d-4def-a752-5e331b1e26b4" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">coords <span class="op" style="color: #5E5E5E;">=</span> MultivariateNormal(centroids[<span class="dv" style="color: #AD0000;">0</span>], torch.diag(tensor([<span class="fl" style="color: #AD0000;">5.</span>,<span class="fl" style="color: #AD0000;">5.</span>]))).sample((n_samples,))</span>
<span id="cb12-2">coords.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>torch.Size([250, 2])</code></pre>
</div>
</div>
<p>We see how the <code>MultivariateNormal</code> distribution samples are spread out in a circular shape around the mean, with the density of samples decreasing as you move further away from the centroid.</p>
<div class="cell" data-outputid="440bb3e9-4b5c-4e69-9934-4ca1a298a0be" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">plt.scatter(coords[:,<span class="dv" style="color: #AD0000;">0</span>], coords[:,<span class="dv" style="color: #AD0000;">1</span>], alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.7</span>, s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">30</span>)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb14-2">plt.scatter(centroids[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>], centroids[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">1</span>], c <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'red'</span>, s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span>)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb14-3">ax <span class="op" style="color: #5E5E5E;">=</span> plt.gca() <span class="co" style="color: #5E5E5E;"># Get current axes</span></span>
<span id="cb14-4">ax.set_aspect(<span class="st" style="color: #20794D;">'equal'</span>, adjustable<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'box'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We sample from the <code>MultivariateNormal</code> distribution for all six of our centroids and concatenate the result.</p>
<div class="cell" data-outputid="1889ba4c-48d1-46cb-dfe4-7674b1cc04a5" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">slices <span class="op" style="color: #5E5E5E;">=</span> [sample(c) <span class="cf" style="color: #003B4F;">for</span> c <span class="kw" style="color: #003B4F;">in</span> centroids]</span>
<span id="cb15-2">data <span class="op" style="color: #5E5E5E;">=</span> torch.cat(slices)</span>
<span id="cb15-3">data.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="kw" style="color: #003B4F;">def</span> plot_data(centroids, data, n_samples, ax<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb17-2">    <span class="cf" style="color: #003B4F;">if</span> ax <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>: _,ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots()</span>
<span id="cb17-3">    ax.set_aspect(<span class="st" style="color: #20794D;">'equal'</span>, adjustable<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'box'</span>)</span>
<span id="cb17-4">    <span class="cf" style="color: #003B4F;">for</span> i, centroid <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(centroids):</span>
<span id="cb17-5">        samples <span class="op" style="color: #5E5E5E;">=</span> data[i<span class="op" style="color: #5E5E5E;">*</span>n_samples:(i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">*</span>n_samples]</span>
<span id="cb17-6">        ax.scatter(samples[:,<span class="dv" style="color: #AD0000;">0</span>], samples[:,<span class="dv" style="color: #AD0000;">1</span>], s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb17-7">        ax.plot(<span class="op" style="color: #5E5E5E;">*</span>centroid, markersize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>, marker<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"x"</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'k'</span>, mew<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="8b2d7253-df04-4a27-8d32-c8b6ff94647d" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">plot_data(centroids, data, n_samples)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-14-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="generating-sample-weights" class="level2">
<h2 class="anchored" data-anchor-id="generating-sample-weights">Generating Sample Weights</h2>
<p>With our data generated, we’ll now prepare for the third step in the algorithm: <em>create weights</em>.</p>
<blockquote class="blockquote">
<p>Create weights for each point in X by using the Gaussian kernel of that point’s distance to x</p>
</blockquote>
<p>We’ll start by defining a function which takes some distance <code>d</code> and some bandwidth <code>bw</code> and returns the gaussian normal output given these two inputs. This output will be our <em>weights</em>:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;">def</span> gaussian(d, bw): <span class="cf" style="color: #003B4F;">return</span> torch.exp(<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.5</span><span class="op" style="color: #5E5E5E;">*</span>((d<span class="op" style="color: #5E5E5E;">/</span>bw))<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>) <span class="op" style="color: #5E5E5E;">/</span> (bw<span class="op" style="color: #5E5E5E;">*</span>math.sqrt(<span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>math.pi))</span></code></pre></div>
</div>
<p>(Wikipedia) the probability density function of the normal distribution is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?f(x)=%7B%5Cfrac%20%7B1%7D%7B%5Csqrt%20%7B2%5Cpi%20%5Csigma%20%5E%7B2%7D%7D%7D%7De%5E%7B-%7B%5Cfrac%20%7B(x-%5Cmu%20)%5E%7B2%7D%7D%7B2%5Csigma%20%5E%7B2%7D%7D%7D%7D"></p>
<p>In our case, <code>d</code> (the distance from a point in X to another point in X) is equivalent in this function to <img src="https://latex.codecogs.com/png.latex?x-%5Cmu">, and bandwidth <code>bw</code> is the standard deviation <img src="https://latex.codecogs.com/png.latex?%5Csigma">.</p>
<p>As bandwidth increases, the gaussian distribution flattens out (i.e.&nbsp;weights decay slower as distance increases).</p>
<div class="cell" data-outputid="e1629736-ae5f-4857-afff-f8340d8019b6" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">x <span class="op" style="color: #5E5E5E;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">10</span>,<span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb20-2">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1.0</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'bw = 1.0'</span>)</span>
<span id="cb20-3">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">2.5</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'bw = 2.5'</span>)</span>
<span id="cb20-4">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">5.0</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'bw = 5.0'</span>)</span>
<span id="cb20-5">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10.0</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'bw = 10.0'</span>)</span>
<span id="cb20-6">plt.legend()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-16-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We can also try to use a simpler linear function for our weights.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;">def</span> tri(d, i): <span class="cf" style="color: #003B4F;">return</span> (<span class="op" style="color: #5E5E5E;">-</span>d<span class="op" style="color: #5E5E5E;">+</span>i).clamp_min(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">/</span>i</span></code></pre></div>
</div>
<p>Mathematically, this calculates <code>max(0, (i - d) / i)</code> which is equivalent to <code>max(0, 1 - d / i)</code></p>
<p><code>clamp_min</code> ensures that the value of <code>-d+i</code> does not go below <code>0</code>. <code>i</code> becomes the d-intercept.</p>
<p>As <code>i</code> increases, the slope decreases, and weights decay slower as distance increases.</p>
<div class="cell" data-outputid="be09317b-d3b8-4bb4-936b-f9f9f8193618" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">x <span class="op" style="color: #5E5E5E;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">10</span>,<span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb22-2">plt.plot(x, tri(x,i<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'i = 3'</span>)</span>
<span id="cb22-3">plt.plot(x, tri(x,i<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'i = 8'</span>)</span>
<span id="cb22-4">plt.plot(x, tri(x,i<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'i = 12'</span>)</span>
<span id="cb22-5">plt.legend()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-18-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="implementing-the-full-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="implementing-the-full-algorithm">Implementing the Full Algorithm</h2>
<blockquote class="blockquote">
<ul>
<li>For each data point x in the sample X, find the distance between that point x and every other point in X (<code>d = f(x-X)</code>)</li>
<li>Create weights for each point in X by using the Gaussian kernel of that point’s distance to x (<code>weights = gaussian(d)</code>)</li>
<li>Update x as the weighted average of all other points in X, weighted based on the previous step (<code>x = weighted_avg(weights, X)</code>)</li>
</ul>
</blockquote>
<p>Since we are going to update the data after each step of the algorithm, we clone the data to start. As a reminder, these 1500 coordinates come from 250 <code>MultivariateNormal</code> samples given 6 centroids as the mean.</p>
<div class="cell" data-outputid="e19a0afd-3b1f-4189-ea40-f73820d8e75c" data-execution_count="19">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb23-2">x <span class="op" style="color: #5E5E5E;">=</span> X[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb23-3">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([29.764, 26.161])</code></pre>
</div>
</div>
<div class="cell" data-outputid="c9005ded-deaa-4406-b70c-119c6584c3f1" data-execution_count="20">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">X.shape, x.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>(torch.Size([1500, 2]), torch.Size([2]))</code></pre>
</div>
</div>
<p>We now calculate <em>the distance between that point x and every other point in X</em>. Since <code>x</code> and <code>X</code> share a dimension <code>2</code>, we can just subtract and PyTorch will use broadcasting.</p>
<div class="cell" data-outputid="b58458b1-4d24-4b3d-87c3-07828202e61b" data-execution_count="21">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">(x<span class="op" style="color: #5E5E5E;">-</span>X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="568b564f-4973-4b77-b312-4b94f6a6fa1b" data-execution_count="22">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">(x<span class="op" style="color: #5E5E5E;">-</span>X)[<span class="dv" style="color: #AD0000;">0</span>] <span class="co" style="color: #5E5E5E;"># subtracting the first point from itself</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([0., 0.])</code></pre>
</div>
</div>
<div class="cell" data-outputid="7f96405a-0d6b-4af5-ab8d-1bf57fc26b99" data-execution_count="23">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([29.764, 26.161])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e35d50a5-a69d-46f0-99b2-570902ac3787" data-execution_count="24">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">X[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([[29.764, 26.161],
        [28.472, 30.493],
        [27.549, 23.130],
        [23.500, 26.879],
        [27.327, 28.650]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="8afce871-6987-4f4d-a85b-5eb08f5d18fe" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">(x<span class="op" style="color: #5E5E5E;">-</span>X)[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([[ 0.000,  0.000],
        [ 1.292, -4.333],
        [ 2.215,  3.030],
        [ 6.264, -0.718],
        [ 2.437, -2.489]])</code></pre>
</div>
</div>
<p>We’ll use Euclidean distance, which is the square root of the sum (across the columns, or rather across coordinates) of the difference in coordinates squared.</p>
<div class="cell" data-outputid="16661ce5-493e-4029-9f13-ac9120032ec2" data-execution_count="26">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="092208c5-a396-4f01-cb0e-c6be84342589" data-execution_count="27">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([[ 0.000,  0.000],
        [ 1.668, 18.772],
        [ 4.906,  9.184],
        [39.239,  0.515],
        [ 5.939,  6.196]])</code></pre>
</div>
</div>
<p>Summing across the columns to get <img src="https://latex.codecogs.com/png.latex?x%5E2+y%5E2">.</p>
<div class="cell" data-outputid="0919cf3c-5bb0-4e84-9bc4-53c71e956312" data-execution_count="29">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>torch.Size([1500])</code></pre>
</div>
</div>
<div class="cell" data-outputid="9e39b39a-6f71-4de2-d839-c6d380711aee" data-execution_count="30">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>)[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor([ 0.000, 20.440, 14.089, 39.754, 12.134])</code></pre>
</div>
</div>
<div class="cell" data-outputid="442c76ad-4328-4762-a9a0-32c30a8bd601" data-execution_count="31">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">dist <span class="op" style="color: #5E5E5E;">=</span> ((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>).sqrt()</span>
<span id="cb45-2">dist.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>torch.Size([1500])</code></pre>
</div>
</div>
<div class="cell" data-outputid="433c5588-1779-4bcf-e4b5-21017d014186" data-execution_count="32">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">dist[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([0.000, 4.521, 3.754, 6.305, 3.483])</code></pre>
</div>
</div>
<p>Since we are performing elementwise multiplication following by a summation, we can use Einstein Summation:</p>
<div class="cell" data-outputid="554d97b7-31a8-45a3-b1d2-4ee4a8d2fb3f" data-execution_count="33">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">torch.einsum(<span class="st" style="color: #20794D;">'ij,ij-&gt;i'</span>, x<span class="op" style="color: #5E5E5E;">-</span>X, x<span class="op" style="color: #5E5E5E;">-</span>X).sqrt()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor([ 0.000,  4.521,  3.754,  ..., 21.305, 21.850, 21.958])</code></pre>
</div>
</div>
<p>We can also use matrix multiplication, though IIUC, you have to pluck out the values on the resulting matrix’s diagonal to get the elementwise product between <code>x-X</code> and itself.</p>
<div class="cell" data-outputid="ce689bc7-0002-472e-ab83-2f3e471a9dac" data-execution_count="34">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">(x<span class="op" style="color: #5E5E5E;">-</span>X).shape, (x<span class="op" style="color: #5E5E5E;">-</span>X).T.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>(torch.Size([1500, 2]), torch.Size([2, 1500]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="424e1e07-8126-4325-b353-92c59a2375ca" data-execution_count="35">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">res <span class="op" style="color: #5E5E5E;">=</span> (x<span class="op" style="color: #5E5E5E;">-</span>X) <span class="op" style="color: #5E5E5E;">@</span> (x<span class="op" style="color: #5E5E5E;">-</span>X).T</span>
<span id="cb53-2">res.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>torch.Size([1500, 1500])</code></pre>
</div>
</div>
<div class="cell" data-outputid="3565fc9c-f460-4158-8f7e-8f0926b1cd85" data-execution_count="36">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">torch.diag(res)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor([  0.000,  20.440,  14.089,  ..., 453.898, 477.408, 482.169])</code></pre>
</div>
</div>
<div class="cell" data-outputid="d964c841-d00e-4173-9a53-acdba5e6b33a" data-execution_count="37">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">torch.diag(res).sqrt()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([ 0.000,  4.521,  3.754,  ..., 21.305, 21.850, 21.958])</code></pre>
</div>
</div>
<p>We now <em>create weights for each point in X by using the Gaussian kernel of that point’s distance to x</em>.</p>
<div class="cell" data-outputid="75f33898-b162-4628-8098-56bc99e441b1" data-execution_count="38">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist, <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb59-2">weight</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([    0.160,     0.031,     0.052,  ...,     0.000,     0.000,     0.000])</code></pre>
</div>
</div>
<p>We have 1500 weights, one for each distance between our current point <code>x</code> and all of the points in <code>X</code>.</p>
<div class="cell" data-outputid="5b48ca56-ce3b-426b-dc41-a73ce4596e99" data-execution_count="39">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1">weight.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>torch.Size([1500])</code></pre>
</div>
</div>
<p>We can now move on to the last step in the algorithm: <em>update x as the weighted average of all other points in X, weighted based on the previous step</em>.</p>
<p>The weighted average is the elementwise product of the <code>weights</code> and <code>X</code>, summed down the rows (two get 2 coordinates) and then divided by the sum of the weights.</p>
<p>Starting from the last dimension, <code>weight</code> and <code>X</code> do not have compatible dimensions (1500 is not 2 or 1), so we have to add a unit axis to <code>weight</code> to allow for broadcasting.</p>
<div class="cell" data-outputid="3c055193-07d4-41b2-9c45-83a7b9c18ddc" data-execution_count="42">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e0b2b54d-21ea-4cee-a98f-0f6f9ba44500" data-execution_count="43">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1">weight<span class="op" style="color: #5E5E5E;">*</span>X</span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: The size of tensor a (1500) must match the size of tensor b (2) at non-singleton dimension 1</code></pre>
</div>
</div>
<div class="cell" data-outputid="799bd54d-0612-4a9e-8f4b-adeb29264253" data-execution_count="44">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1">weight[:,<span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>torch.Size([1500, 1])</code></pre>
</div>
</div>
<div class="cell" data-outputid="81c78206-bb4d-4b3d-b05c-77e844403318" data-execution_count="46">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1">weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>tensor([[    4.750,     4.175],
        [    0.886,     0.948],
        [    1.424,     1.196],
        ...,
        [    0.000,     0.000],
        [    0.000,     0.000],
        [    0.000,     0.000]])</code></pre>
</div>
</div>
<p>We then sum down the rows to get two coordinates:</p>
<div class="cell" data-outputid="94a51182-983c-4f79-c54b-59577b97c8b5" data-execution_count="48">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1">(weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([296.880, 291.612])</code></pre>
</div>
</div>
<p>This is the same as applying the weights to each column separately:</p>
<div class="cell" data-outputid="cedc0ce9-89c7-4b77-98dc-be9e885f5cb2" data-execution_count="49">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1">(weight <span class="op" style="color: #5E5E5E;">*</span> X[:,<span class="dv" style="color: #AD0000;">0</span>]).<span class="bu" style="color: null;">sum</span>(), (weight <span class="op" style="color: #5E5E5E;">*</span> X[:,<span class="dv" style="color: #AD0000;">1</span>]).<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>(tensor(296.880), tensor(291.612))</code></pre>
</div>
</div>
<p>We then divide by the sum of the weights to get our final, updated <code>x</code>:</p>
<div class="cell" data-outputid="26fcab42-b6a3-448a-b5b8-cf8c85c2f3a6" data-execution_count="50">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1">(weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">/</span>weight.<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>tensor([28.118, 27.619])</code></pre>
</div>
</div>
<p>Wrapping this up into a function for each <code>x</code> in <code>X</code> we calculate the distance between <code>x</code> and all points in <code>X</code>, calculate the weights for those distances and replace <code>x</code> with the weighted average of those weights and all the points.</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><span class="kw" style="color: #003B4F;">def</span> one_update(X):</span>
<span id="cb77-2">    <span class="cf" style="color: #003B4F;">for</span> i, x <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(X):</span>
<span id="cb77-3">        dist <span class="op" style="color: #5E5E5E;">=</span> torch.sqrt(((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb77-4">        weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist, <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb77-5">        X[i] <span class="op" style="color: #5E5E5E;">=</span> (weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">/</span>weight.<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
</div>
<div class="cell" data-outputid="72b4ced3-11b0-4477-e0de-28e7ec8b3e34" data-execution_count="52">
<div class="sourceCode cell-code" id="cb78" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1">X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb78-2">x <span class="op" style="color: #5E5E5E;">=</span> X[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb78-3">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>tensor([29.764, 26.161])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1">one_update(X)</span></code></pre></div>
</div>
<div class="cell" data-outputid="4dfc8da8-06c7-4400-a1da-5415bf4bbcaf" data-execution_count="55">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">X[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>tensor([28.118, 27.619])</code></pre>
</div>
</div>
<p>We can now wrap up into a <code>meanshift</code> function where it performs <code>n</code> such updates.</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><span class="kw" style="color: #003B4F;">def</span> meanshift(data, n<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb83-2">    X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb83-3">    <span class="cf" style="color: #003B4F;">for</span> it <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(n): one_update(X)</span>
<span id="cb83-4">    <span class="cf" style="color: #003B4F;">return</span> X</span></code></pre></div>
</div>
<div class="cell" data-outputid="120554f2-356c-4445-c260-6590aa44c457" data-execution_count="68">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><span class="op" style="color: #5E5E5E;">%</span>time X<span class="op" style="color: #5E5E5E;">=</span>meanshift(data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.39 s, sys: 3.12 ms, total: 1.4 s
Wall time: 1.42 s</code></pre>
</div>
</div>
<p>We can now see that in 5 iterations, the weight updates have resulted in the points to converge at the original centroids!</p>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><span class="kw" style="color: #003B4F;">def</span> plot_data(centroids, data, n_samples, ax<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>):</span>
<span id="cb86-2">    <span class="cf" style="color: #003B4F;">if</span> ax <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>: _,ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots()</span>
<span id="cb86-3">    ax.set_aspect(<span class="st" style="color: #20794D;">'equal'</span>, adjustable<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'box'</span>) <span class="co" style="color: #5E5E5E;"># Add this line</span></span>
<span id="cb86-4">    <span class="cf" style="color: #003B4F;">for</span> i, centroid <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(centroids):</span>
<span id="cb86-5">        samples <span class="op" style="color: #5E5E5E;">=</span> data[i<span class="op" style="color: #5E5E5E;">*</span>n_samples:(i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">*</span>n_samples]</span>
<span id="cb86-6">        ax.plot(<span class="op" style="color: #5E5E5E;">*</span>centroid, markersize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>, marker<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"x"</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'k'</span>, mew<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">-</span> alpha<span class="op" style="color: #5E5E5E;">*</span><span class="fl" style="color: #AD0000;">0.2</span>)</span>
<span id="cb86-7">        ax.scatter(samples[:,<span class="dv" style="color: #AD0000;">0</span>], samples[:,<span class="dv" style="color: #AD0000;">1</span>], s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="2143afe3-6582-445c-d40c-1bf41e2dce13" data-execution_count="70">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1">plot_data(centroids, X, n_samples)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-53-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-53-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="animating-the-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="animating-the-algorithm">Animating the Algorithm</h2>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><span class="im" style="color: #00769E;">from</span> matplotlib.animation <span class="im" style="color: #00769E;">import</span> FuncAnimation</span>
<span id="cb88-2"><span class="im" style="color: #00769E;">from</span> IPython.display <span class="im" style="color: #00769E;">import</span> HTML</span></code></pre></div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><span class="kw" style="color: #003B4F;">def</span> do_one(d):</span>
<span id="cb89-2">    <span class="cf" style="color: #003B4F;">if</span> d: one_update(X)</span>
<span id="cb89-3">    ax.clear()</span>
<span id="cb89-4">    plot_data(centroids, X, n_samples, ax<span class="op" style="color: #5E5E5E;">=</span>ax, alpha<span class="op" style="color: #5E5E5E;">=</span>d)</span></code></pre></div>
</div>
<p>We can visualize the “gravity” of the cluster centroids as the data points are “pulled in” via the weighted average.</p>
<div class="cell" data-outputid="57402cb2-2ebd-467a-ed23-a962aa25f28a" data-execution_count="73">
<div class="sourceCode cell-code" id="cb90" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1">X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb90-2">fig,ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots()</span>
<span id="cb90-3">ani <span class="op" style="color: #5E5E5E;">=</span> FuncAnimation(fig, do_one, frames<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, interval<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">500</span>, repeat<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb90-4">plt.close()</span>
<span id="cb90-5">HTML(ani.to_jshtml())</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<script language="javascript">
  function isInternetExplorer() {
    ua = navigator.userAgent;
    /* MSIE used to detect old browsers and Trident used to newer ones*/
    return ua.indexOf("MSIE ") > -1 || ua.indexOf("Trident/") > -1;
  }

  /* Define the Animation class */
  function Animation(frames, img_id, slider_id, interval, loop_select_id){
    this.img_id = img_id;
    this.slider_id = slider_id;
    this.loop_select_id = loop_select_id;
    this.interval = interval;
    this.current_frame = 0;
    this.direction = 0;
    this.timer = null;
    this.frames = new Array(frames.length);

    for (var i=0; i<frames.length; i++)
    {
     this.frames[i] = new Image();
     this.frames[i].src = frames[i];
    }
    var slider = document.getElementById(this.slider_id);
    slider.max = this.frames.length - 1;
    if (isInternetExplorer()) {
        // switch from oninput to onchange because IE <= 11 does not conform
        // with W3C specification. It ignores oninput and onchange behaves
        // like oninput. In contrast, Microsoft Edge behaves correctly.
        slider.setAttribute('onchange', slider.getAttribute('oninput'));
        slider.setAttribute('oninput', null);
    }
    this.set_frame(this.current_frame);
  }

  Animation.prototype.get_loop_state = function(){
    var button_group = document[this.loop_select_id].state;
    for (var i = 0; i < button_group.length; i++) {
        var button = button_group[i];
        if (button.checked) {
            return button.value;
        }
    }
    return undefined;
  }

  Animation.prototype.set_frame = function(frame){
    this.current_frame = frame;
    document.getElementById(this.img_id).src =
            this.frames[this.current_frame].src;
    document.getElementById(this.slider_id).value = this.current_frame;
  }

  Animation.prototype.next_frame = function()
  {
    this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));
  }

  Animation.prototype.previous_frame = function()
  {
    this.set_frame(Math.max(0, this.current_frame - 1));
  }

  Animation.prototype.first_frame = function()
  {
    this.set_frame(0);
  }

  Animation.prototype.last_frame = function()
  {
    this.set_frame(this.frames.length - 1);
  }

  Animation.prototype.slower = function()
  {
    this.interval /= 0.7;
    if(this.direction > 0){this.play_animation();}
    else if(this.direction < 0){this.reverse_animation();}
  }

  Animation.prototype.faster = function()
  {
    this.interval *= 0.7;
    if(this.direction > 0){this.play_animation();}
    else if(this.direction < 0){this.reverse_animation();}
  }

  Animation.prototype.anim_step_forward = function()
  {
    this.current_frame += 1;
    if(this.current_frame < this.frames.length){
      this.set_frame(this.current_frame);
    }else{
      var loop_state = this.get_loop_state();
      if(loop_state == "loop"){
        this.first_frame();
      }else if(loop_state == "reflect"){
        this.last_frame();
        this.reverse_animation();
      }else{
        this.pause_animation();
        this.last_frame();
      }
    }
  }

  Animation.prototype.anim_step_reverse = function()
  {
    this.current_frame -= 1;
    if(this.current_frame >= 0){
      this.set_frame(this.current_frame);
    }else{
      var loop_state = this.get_loop_state();
      if(loop_state == "loop"){
        this.last_frame();
      }else if(loop_state == "reflect"){
        this.first_frame();
        this.play_animation();
      }else{
        this.pause_animation();
        this.first_frame();
      }
    }
  }

  Animation.prototype.pause_animation = function()
  {
    this.direction = 0;
    if (this.timer){
      clearInterval(this.timer);
      this.timer = null;
    }
  }

  Animation.prototype.play_animation = function()
  {
    this.pause_animation();
    this.direction = 1;
    var t = this;
    if (!this.timer) this.timer = setInterval(function() {
        t.anim_step_forward();
    }, this.interval);
  }

  Animation.prototype.reverse_animation = function()
  {
    this.pause_animation();
    this.direction = -1;
    var t = this;
    if (!this.timer) this.timer = setInterval(function() {
        t.anim_step_reverse();
    }, this.interval);
  }
</script>

<style>
.animation {
    display: inline-block;
    text-align: center;
}
input[type=range].anim-slider {
    width: 374px;
    margin-left: auto;
    margin-right: auto;
}
.anim-buttons {
    margin: 8px 0px;
}
.anim-buttons button {
    padding: 0;
    width: 36px;
}
.anim-state label {
    margin-right: 8px;
}
.anim-state input {
    margin: 0;
    vertical-align: middle;
}
</style>

<div class="animation">
  <img id="_anim_imgbf18fa8feeef42df9ff1917d1946c4bf">
  <div class="anim-controls">
    <input id="_anim_sliderbf18fa8feeef42df9ff1917d1946c4bf" type="range" class="anim-slider" name="points" min="0" max="1" step="1" value="0" oninput="animbf18fa8feeef42df9ff1917d1946c4bf.set_frame(parseInt(this.value));">
    <div class="anim-buttons">
      <button title="Decrease speed" aria-label="Decrease speed" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.slower()">
          <i class="fa fa-minus"></i></button>
      <button title="First frame" aria-label="First frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.first_frame()">
        <i class="fa fa-fast-backward"></i></button>
      <button title="Previous frame" aria-label="Previous frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.previous_frame()">
          <i class="fa fa-step-backward"></i></button>
      <button title="Play backwards" aria-label="Play backwards" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.reverse_animation()">
          <i class="fa fa-play fa-flip-horizontal"></i></button>
      <button title="Pause" aria-label="Pause" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.pause_animation()">
          <i class="fa fa-pause"></i></button>
      <button title="Play" aria-label="Play" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.play_animation()">
          <i class="fa fa-play"></i></button>
      <button title="Next frame" aria-label="Next frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.next_frame()">
          <i class="fa fa-step-forward"></i></button>
      <button title="Last frame" aria-label="Last frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.last_frame()">
          <i class="fa fa-fast-forward"></i></button>
      <button title="Increase speed" aria-label="Increase speed" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.faster()">
          <i class="fa fa-plus"></i></button>
    </div>
    <form title="Repetition mode" aria-label="Repetition mode" action="#n" name="_anim_loop_selectbf18fa8feeef42df9ff1917d1946c4bf" class="anim-state">
      <input type="radio" name="state" value="once" id="_anim_radio1_bf18fa8feeef42df9ff1917d1946c4bf" checked="">
      <label for="_anim_radio1_bf18fa8feeef42df9ff1917d1946c4bf">Once</label>
      <input type="radio" name="state" value="loop" id="_anim_radio2_bf18fa8feeef42df9ff1917d1946c4bf">
      <label for="_anim_radio2_bf18fa8feeef42df9ff1917d1946c4bf">Loop</label>
      <input type="radio" name="state" value="reflect" id="_anim_radio3_bf18fa8feeef42df9ff1917d1946c4bf">
      <label for="_anim_radio3_bf18fa8feeef42df9ff1917d1946c4bf">Reflect</label>
    </form>
  </div>
</div>


<script language="javascript">
  /* Instantiate the Animation class. */
  /* The IDs given should match those used in the template above. */
  (function() {
    var img_id = "_anim_imgbf18fa8feeef42df9ff1917d1946c4bf";
    var slider_id = "_anim_sliderbf18fa8feeef42df9ff1917d1946c4bf";
    var loop_select_id = "_anim_loop_selectbf18fa8feeef42df9ff1917d1946c4bf";
    var frames = new Array(5);
    
  frames[0] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAY7dJREFUeJzt3Xl8VNXdP/DPnSQzk3USIAvBsAg0KJshVYhEVEBAaBUFFdqK\
C0tLqbLYFqgL9aeWRR8R+iguUK0bUWnFWhChQeCJEsQQViUVlEVCEhAyE7LMJDP398fNvbl3MjOZ\
hCQzk/t5P6+8IDN37hx47PDJ95zzPYIoiiKIiIiISDcMgR4AEREREbUvBkAiIiIinWEAJCIiItIZ\
BkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIi\
ItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEA\
JCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIi\
nWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAi\
IiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZ\
BkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIi\
ItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinQkP\
9ACImuJyuVBcXIzY2FgIghDo4RARtRlRFFFRUYHU1FQYDKzRUNthAKSgV1xcjLS0tEAPg4io3Zw+\
fRpXXHFFoIdBHRgDIAW92NhYANIHYlxcXIBHQ0TUdmw2G9LS0pTPPaK2wgBIQU+e9o2Li2MAJCJd\
4HIXamtcYEBERESkMwyARERERDrDAEhERESkMwyARERERDrDAEhERESkMwyARERERDrDAEhERESk\
MwyARERERDrDAEitZtmyZRAEAfPmzVMeq6mpwZw5c9C5c2fExMRg0qRJKC0tDdwgiYiIiAGQWsfe\
vXvxyiuvYNCgQZrH58+fj48//hgffPABdu7cieLiYtx5550BGiUREREBDIDUCi5duoRf/vKXeO21\
15CQkKA8brVasW7dOjz//PMYOXIkMjMz8frrr+OLL75Afn5+AEdMRESkbwyAdNnmzJmDCRMmYPTo\
0ZrHCwoKUFtbq3m8X79+6N69O3bv3t3ewyQiIqJ64YEeAIW2nJwc7Nu3D3v37m30XElJCYxGI+Lj\
4zWPJycno6SkxOs97XY77Ha78r3NZmu18ZIHe9cBeSuB7PnAtdMDPRoiImoHrABSi50+fRpz587F\
O++8A7PZ3Gr3Xbp0KSwWi/KVlpbWavcmD/JWAtbT0q9ERKQLDIDUYgUFBSgrK8OQIUMQHh6O8PBw\
7Ny5E6tXr0Z4eDiSk5PhcDhQXl6ueV1paSlSUlK83nfx4sWwWq3K1+nTp9v4T6Jz2fMBS5r0KxER\
6QKngKnFRo0ahUOHDmkee+CBB9CvXz8sXLgQaWlpiIiIQG5uLiZNmgQAKCoqwqlTp5CVleX1viaT\
CSaTqU3HTirXTufULxGRzjAAUovFxsZiwIABmseio6PRuXNn5fHp06djwYIF6NSpE+Li4vDQQw8h\
KysLw4YNC8SQiYiICAyA1MZWrlwJg8GASZMmwW63Y+zYsXjppZcCPSwiIiJdE0RRFAM9CCJfbDYb\
LBYLrFYr4uLiAj0cIqI2w887ai/cBEIU6vauA1YOkH4lIiLyAwMgUahjGxciImomBkCiUMc2LkRE\
1EzcBEIU6tjGhYiImokVQCIiIiKdYQAkIiIi0hkGQCKS+NpNzJ3GREQdCgMgEUl87SbmTmMiog6F\
AZCIJL52E/u705iVQiKikMCTQCjosTN+CFk5QKoUWtKA+YcDPRqikMPPO2ovrAASUetV7tiTkIgo\
JDAAEhGw/Smpcrf9Kf/DoKfrrp0uVf7kvoScEiYiCkoMgEQdUXODV6294Vd/N3z4cx03jxARBSUG\
QKKOyN/gJQdFof77CJP/07j+XMcpYd17O/8khi/bjrfzTwZ6KESkwgBI1BG5By9vFUE5KIabgPAo\
oLocOPlFwzSu++vU37tP93rizzXUoa3ZcRxnyquxZsdxr9cwJBK1PwZAolDmLdi5By856G3+g/ba\
6C7Srwk9AacdgAgc+bDhefdKYmtP6XKNYIc3+6be6BYfidk39fZ6jT8hkYhaFwMgUSjzN5BlzweE\
MEB0StfKwat4v/T82YNA/zsACECYCdgwXXo+bai2kpg2VLpP2lDp+8sNcFwj2OH9algPfL5oJH41\
rIfXa3yFRFYHidoGAyBRKPN3jd2106WAJ4c3OXhFREqP9b8DmLwOsFwB1FVJVUDraeD0noZ+fisH\
AMdzpRB5PFf6Xt493NIAxzWCBN8hsTWqgwyRRI0xABKFMvVUr6dqnPoxObx98xFg/QEwREhr/7oO\
kgLfhukNgazroIawuHcdsOkRKejV2aXnRUjfi7i8AMc1gtQEf6aQm8IpZqLGeBIIBT12xveTp1M4\
5MciE6QNHvDxP3chDFhyofG9HJeA6ovS4+FRQHRnae2gPG3c43qpApg9n0GOgtLb+SexZsdxzL6p\
t8+p6GDAzztqL6wAEoUSX1W+tKFS0LNfang+e742/AlhQGpGw6+WNOlXX2v/1JmxrloKhmcPStXE\
03u4jo8ABPc0qz/rEIn0JjzQAyCiZlCHLfcdvgBgjGn8fI0NSvgb/6znKt2ynkDNReDwBul7xyVg\
4Qnt+8qVQHnN4Ok9DVO/cgWQdEs9zepP0FJX5eTXh0KFjqijYAWQKJR42jShfsz9+byVUqXOW/iT\
q4e1l7SP19obnpPfQ4RUTRz/rLRhRF67x3V8hIa1epk9EvyqBKoDY0vW6AVzxZEoFHANIAU9rom5\
DHvXadfnuX8vV/7cRSZIga/mImBOAEwxjdcXEnkwfNl2nCmvRrf4SHy+aKTX6y63Aujv+4Qaft5R\
e2EFkKgjkqt3hW8BtmLpdI+964DNf0Deoe8begHWlEvXGyK0rx/5OPJO1ki/F8B2LeQ39a5dT1U6\
+TEAyro8f9boud+rNXYHE+kZK4AU9HT5E7F7pa655F28auYE/HnLWTy504Fl4+KxMCsMcNVKz0Um\
NOz0taRh+abjWJRbgyWjLPjz0v9p+fTuhulSixm5zyDpyjVPbkV5dS3iIyOwf8kYAC2v3HXUip87\
XX7eUUCwAkgUjC53Z628+1do+J943n/P48mdDgDAoi3lWL5LXvcnACMfl643JyjhDwCezLUi782n\
G5/0IVcY5V3D3k4COfKhtAZRfbwc6VpzKnfqqh9PCyFqXQyARMHIfcrV25Frvs4CNsYAoqvhlt3D\
sGxCkvL9olw7lufZgQGTlOuX/6dECX8AsGxcPLI7X9AG0fqpZFhPN5wY4i2oyqeP9L+jRX8NFNp+\
PzYd3eIj8fux6cpjvxrWA7Nv6o01O443Cmxv55/ENU9uxTVPblXWCKp3Fnt7HRs9EzUfp4Ap6HFK\
BNrGzNnzG6aH5Uqhp80Ze9cBuU9Ja/h6j1Latiz/+ydY9OI/lMuWLVuGhQsXYvnvJmsfH2XGwt/8\
oqHdizwNLI/FvR0MdwGTn7xN58qPA0CYAEwYlIqCkxeR2SMBBScvotJeh/Lq2kavC6VGz03h5x21\
FwZACnr8QIR2TWDuUw27c/uMat4au/pQuPw/pZpKX6e4aFywVSrfLxtlwsJskzZYymNQnwLCdX3U\
DHJQkwOdHNjUj+/67zlYq2shQgqBT94+AM99WoTy6lpERhjQKdrUoXsH8vOO2gsbQROFArnfHgBs\
f0r6VYBUfZNP5PBH3kqg5iIWZhsBiFiUawcAz+EPkMKeHPwulQDOWukcYYgN6/rcK4CXu4GFOix5\
qhaApoKnfvz3Y9OVwOcUgec+LVKuM4WH4fNFI/Hw+kL860Cx8tqOFACJ2gvXABKFmpGPS5W5kY83\
rBVMG+rfpoy0oQAEICIKC3/zS3SKFDRPd4oObwh/gFTpy31KmvJ11u8Ylk8VkTd3uK8BlKelN//B\
+zhIl7xt5FA/vmbHcZRX12qed19LuOlgsfJc52gjei3ahKse34KH1xcqm0G4MYTIN04BU9DjlEgT\
5E0ZohNSWVAEIqKAqM7aE0HShjbsyjUnYPlOKxZtKW90O6UCKIQBXQcBxYXSE4JBun//O4Ae1zfc\
U10B3LtOqlDKZw+zcTQ1k7q6J08Bu1f4Hl5fiI8PFMMcYUBNrUs5rjpMAJwi0C0+EgBCsm0MP++o\
vXAKmCjUyce9AYAgAKII1FYB1iopGIaZgLoqVV9AoVH46xRlwIUqacfwolw7EBaBhU8/r63sGcKA\
mBQp/KmnpIGG3cjyecHmBOlxxyXpOU4F69Lb+SeVKdzfj033a6q24KTUj1IAEGuO8HjN6qkZKDh5\
EWfKqxFZHwLNEWG45epkZW0h0LBGsCNtEiFqLawAUtDjT8RN8FYBrK2Wfq+QnlueZ1fW/gFSq5eF\
N1rqW8CoHh8Tg4UjOzc0iJbv7WljiP2S9ti4pnYoky6od/V6q8S5HwmnXvPnvuO3pcfHhVITaX7e\
UXvhGkCiUCYHsP53SEFrwCTp1/Tx2uvMCUDqNY3D3ygTFk6/ExCAhSNisGyUWXlu0dZLWL6tRAqT\
6nurj4OTQ54A6blRj0th79rpPD6OMPum3oiPjEB8ZITXxs/qHn7y5g9AqhjGR0ag0l6nrO177tMi\
TV9AT8fHeVr7x2PjiBpjBZCCHn8i9qGp/oCy8CjkfVeJG16vUB7SrPWrXxcIUwyWF0Ri0TtfKdf9\
34xOyL66q+ddvdzxS37wNQX78PpCbDpYjAmDUrHt61JU1zoRGRGGb54ap1Tu5LV98ZERiDaF+6wA\
ql/jaf1gsOPnHbUXVgDpsqxZswaDBg1CXFwc4uLikJWVhU8++UR5vqamBnPmzEHnzp0RExODSZMm\
obS0NIAj7mDUVTY59OU+Ja29i4iCVJoDUFeF7O4CltxoBOAW/uTqodMOWE9j4cBzyokhS240I7tP\
rPfTPq6d3lDx8/d4ONKVt/NPYslHh5XKnXuFruDkRThFee2fXI8Q8Xb+SVyodEAA0D/VouwClqt+\
cuVwyUeHG1X75MDIk0GIvGMFkC7Lxx9/jLCwMPTt2xeiKOLvf/87nn32WRQWFqJ///6YPXs2Nm3a\
hDfeeAMWiwW/+93vYDAY8Pnnn/v9HvyJ2E9yNa7qR2kTCACERajatwAQDMg76UT2wO5SP7+ISGDM\
01KAW9ZTWscHARgwCXk7tyN72mPS6/yp8snVyIY3AyLjpXY1nl7H6qEuXPPkVpRX10IA8NTEAUpw\
k9fjvZ1/Es9s+ho1tS6EhwmodYrSioLICGU6WK78qRtIf/n9Ba+7hT2tFXRvPh2s+HlH7YUBkFpd\
p06d8Oyzz2Ly5MlITEzEu+++i8mTJwMAjh49iquuugq7d+/GsGHD/LofPxDr+RuYlvdUbdwAlM0b\
ABCZACw8oQ1r8iaNDdOBwxvqX+LHMW/u49FsRlHxtglEPX3NTSId0tv5J/H4xsMQIYW4/UvGeJwO\
7rVoE6p/OALzFf010732Oheqa7X/PdX8cAS9B/wUAJQNJoD3TSbu08jBvhGEn3fUXjgFTK3G6XQi\
JycHlZWVyMrKQkFBAWprazF69Gjlmn79+qF79+7YvXu31/vY7XbYbDbNF6FhitfTVKzayMelyh8g\
/TpgkhT8zAnSc4AU2swJ0jSxvb5Vi/o0EdEJHP6H9H6bHpGqg+5Tuu7juXY6MP7Z+g0jk6X7RyZ4\
3wTCTSId3podx5VJ3RE/SWwU/h5eX4jeizehPO8dlL6zENb8DZgwKFWZ7jWFa/+JsuZvQOk7C5F8\
7F/KVC8gVQC9bfCQN4DI9+VGECIJ+wDSZTt06BCysrJQU1ODmJgYfPjhh7j66quxf/9+GI1GxMfH\
a65PTk5GSUmJ1/stXboUTz75ZBuPOgSpN3n4cu30hnAWk+L5vF65orfpEWm6eNMjUlAEVFPIDeux\
UHNRuqf6uDfHJSnkZc/XVgP9rea59xKkkNBUTz11778RP0lEibVaWeMn9+5b8pH038img8WoPH0E\
5Z+vBwCU73wDH0WG4+QnrwHQtoSx5m9A+c43AAAfrluF/tdmI9YsVcjkE0KGL9veaFy/GtZDOW9Y\
7jFIRKwAUitIT0/H/v37sWfPHsyePRv33Xcfvv766xbfb/HixbBarcrX6dOnm36RHqg3XDTFV3VN\
3qyx/SloQt6xXOm36eMbqnjyJhIIDcfNyWGv+qLU808dOJuqTlLIU7dt8fZ8eXUtyqtrUXDyIp68\
fYBSeXPfoDFhUCrMV/RH/I33K68/tWUtpsxZhOHLtmPETxIRJmjDHwAsW7YMH5fEoby6FvY6l9JC\
xtOmEH/HTaQ3rADSZTMajejTpw8AIDMzE3v37sWqVatwzz33wOFwoLy8XFMFLC0tRUpKitf7mUwm\
mEwmr8+TB3vXSbt/nXbp5A+5H5/8nHxs27FcoKYcgChV78wJ0mvC6/++5XWB8mt7XC8FxVq7NCUM\
UdtqRg6Y/lYnKeTJ5/X6mnKVK3dyNc69Uqh+/a7/nkP8zVMxtn8y3ntpOQDgvZeWI/7GUmDcvUg5\
sRXfqcJf4sgH8C/xWtjrpH6W1bXO+hNBwjTh0v09mxo3kd5wEwi1upEjR6J79+5YtWoVEhMTsX79\
ekyaJE0vFhUVoV+/ftwE0trcd+CqN1bIz8n9/mSpGUDl+YbQtv0pqSA46vGGTR3qUz4A6R7jn+XU\
LfnF13Sx3B7GKTbs4v33W2uUEAgABnMsXDUNvSu7jn4QSdn3KLuKLZERsNc5UV3rQmSEAabwMAD+\
HzsXjPh5R+2FFUC6LIsXL8att96K7t27o6KiAu+++y527NiBTz/9FBaLBdOnT8eCBQvQqVMnxMXF\
4aGHHkJWVpbf4Y+8cN+Bmz1fWwFUr8tLGyq9xr0CePagFAjladvqi1JwBLTn+sr9BNUtY4j8IE+7\
Pr7xMJ77tAjRpjCcKa/BoG4W/FjpgLO+/KD07Esbg/gbS5XpXnX4i7/xfvQa9UvMvqm3EhyjTeH4\
/dh0rNlxHJX2OuXoOHnNH8//JfKOawDpspSVlWHatGlIT0/HqFGjsHfvXnz66ae45ZZbAAArV67E\
z372M0yaNAkjRoxASkoK/vnPfwZ41B2Apx24i05IAc0Uo73myIdSIJy8Trpmwv9IQU9uAJ0933ND\
aRHSY+EmACIQ1Vkb/uS1hGz4TPXcmzzLa/5ESOf6nimvAQAcPGNVjomLMAgQAHSONqLSXof4YZNh\
MMdq7mswxyJ+2GQlzKVY5CMLReVIuN+PTdfs8m3Omj9Px8cRdXScAqagxykRD7z1BHQ/Gk7uy9ec\
Xnue+vv5eq/6I+TY0Jnkps/xkRFKZS6zRwJ2/fccAGgqgP96KFu5Xu3Sng34cccbje6dOPIBPP/M\
EiXYyZ6e6Pm4t+ZUAOVegcHQI5Cfd9ReWAEkCkXyjmBAW4VTV/LUffl8bc5wr+S53xvwvPtYfi8B\
3AFMGtbqWmVXbsHJi9i/ZAz2LxmDzxeNwollE/Cvh7I118t7za352vCnrgSe2/465i7+M86UVyNC\
bgCIxse9ydU8AMqxcU2RewVygwjpCSuAFPT4E7EPrXGahrd7+HvvDdOlaeb+d3juOUgdklxhUx+x\
BkBZnycf3yZX4Nwrcrf9NQ8Hz1gRYRCw5Lb++MtfluGbj19W7h9/4/2wDJsMW/4GXFTtAk648X6s\
XvZnAA19AuU+gOq1gO7vHyr4eUfthRVAolDWGqdpeLtH2lBp16+8icSb03ukaWb1SSLU4clTsZsO\
Fitr7X41rIfS9+/3Y9M1FTj3NXkHz1gBALUuEWd25jQKf12uvwvxkRHofvNUJKj6BF7c+Qb+/dYa\
/GpYD0SbwlFeXYs1O44r97fXOREmAPY6l8c1gFzvRyRhACRqYxdzcvDtyFG4mJPT+jdvTnPo5t7D\
V7BTTxvzSDdd8nbEmrwpQ111ezv/pLTBIzICmT0SMHzZdhjqZ3EdPxzBokWLlGsTRz6AHjdPxZLb\
+isBL27YZE2z6PdeWo7HX9mgmbrN7JFQfzScAKcImMINHqd12RCaSMIpYAp6oT4l8u3IUagrLkZ4\
air6bs9t+Y28bcZoK3vXNe4NKGuNqWcKCc1tp+LpevUmCwA4U16tTNFeqLTj7Gdvwfr5enQfN0M5\
Bk6+lzylDECZDrYMn4r+P5uh2bAhv0d8ZITymKd+gMHeHibUP+8odLACSNTGusyaifDUVHSZNfPy\
btQWx635auVy7XTAGNNwDrAaq3660dyKmbz54/GNhzXtYNTHwclTxJk9ElBd60J89i+R/MvlEAZP\
VO4jnyksVygiDAKyJ01H8i+XIz77l8jskYC380/imie34pontyKzR4JyX/XUsDtPFUoiPWIFkIIe\
fyKu1xYVwKYqea3xnu1duaRW1dyKmbq1S1NtVXov3qRU9wAgPjIc+5eMBdBQ0ZOFCUCKJVJ5TN4H\
LCqv1baekTemhFrQ4+cdtRdWAImCRJNrBVtjvZ+7pip5rfGebVG5pHbT3IrZ78emIz4yApERBlTa\
6/B2/slGGy/k7/unWiCoXhttapi+zeyRAAFQ1goaww3I7JGA+MgICJCCn3v1Qq5WFpy8qIyZmz6I\
PGMAJAoS5199DXXFxTj/6mtNX+yvpk7rcA94bXG6B6eLdeVXw3pg/5Ix6BRtarRDV56SlaeJT12o\
Qmr9usAwAZoNGwUnL0IE0NUSiW7xkaiudSk9BZ+aOACREWHKtQKk4Ompn5/83ks+OswQSKTCAEgU\
JJq9VtCfsNbc6ltbVOvaonJJQc/Tuj9PjZbl5568XXuih3xUXKW9TlnfJ+8gBoBO0UblWkv9xg9P\
U9XycXTKecNEBIABkChoJEyZgr7bc5EwZYp/L/AnrDW3+uZv7z+iJshTx0DjYCaf2ys3cPb2enkz\
x6aDxZh9U28UnLyoVBLlgKhe+3emvBrPbPoGvRdvwsPrC5X7yL0J5QDJSiARN4FQCOCiaC8CsSmE\
qJmaOmdX/fzsm3prwqK6DYyn59XkzSrF5dUQIU0pH186oVljCQb8vKP2wgogUagKxKYQIj/Jmy/k\
6Vv19K96Y4Z6eliu4j33aZEy1fvk7QOUqWDA+/m+csXx54NTESYAEwalNrqGZ/4SNWAFkIIefyIm\
Cj2+qm3enpOrePJ5vmGCFADlYNgalTs2giaSsAJI1AxNtWrx9nxrHwfXpsfLEbUCfzZ+uD8nV/FG\
/CQRgLRx47lPi7xe35IWLzwKjkjCAEjUDHKrlpKnnvYYvry1cmlui5emAl6btIwhakW++gc21Vuw\
4ORFj9cD0AS+loQ5TgMTSRgAiZqhy6yZQFgY4HR6DF/eWrnIj0dlZPhVuWsq4LXa8XJEQch9h6/M\
PfC1JMzxKDgiCdcAUtAL5JqYizk5OP/qa+gya6bSnuViTg7KVr4AAEiaP0/zuPu17r4dOQp1xcUI\
T01F3+25Xt8vKiMDVYWFPu9FpDctXb8X7Ov+1LgGkNoLK4BEKu5Tr54qcQlTpsAQHQ2X1aqZCvZn\
Wrapyp18j6rCwub1BCQKcq1xJFtLq3dc90fUGAMgkYp7iPM1pStPBZetfAHfjhyFqIwMr+HuzCO/\
xzf9B6B8wz98vr/6/bjRgzoKuZ+fpxCmDoZtdW4v1/0RNcYpYAp67TUl4m1q19f15199Da7KSris\
ViAsDCmPP+bxdd/0HwA4ncr33qaA1eTpYl/3JQoFctsXua2LuoKnbgkDIOgbNbc1TgFTe2EFkKje\
+Vdfg8tqhSE6ullhKyY72+fGEACIGzcOCAuDecAAvzdveKoyshpIoeTt/JO45smtuFBpR3xkRKPw\
B3g+89dTpa6tqoNEehUe6AEQBYsus2Yqmzi8UW/0UNbrAUh5/DGfr+32P8+h2/8816zxJEyZgqq9\
X8G2ZQtEux119WsO5eeIgt2aHcdRXl0LAOgUbfLaEkZeo1dw8qLHxtDqU0KWfHRYeR0RtRwrgET1\
EqZMaXLjhXqNoHq9nj+vVa/p83d9X1VhIeB0QjCZmqwyEgUL9TFwcjsXX+vvvK3RU2/emH1Tb4QJ\
UnNobuYgunysABK58dXORV0llJ9TBzJfbWDcN5jIv/cVGt2rkk1VKImCgRzcAGD/kjFNXv+rYT08\
VvTkyp+6fYv8PRFdHm4CoaDX3oui5c0XBosFhuhov/r6ISwMQkQExJoaGCwWpO/Jb3Stusffpbw8\
AA2bTfzpIUgUKlq7714o9fG7XNwEQu2FU8BEbuSpXaChSie3cTnzyO8107fhnTpJL3I6IdbUAABE\
hwNA456C8jRxVWGhZrPJxZwclDz1dLOPdmObGApWrX3aBvv4EbU+BkAiN3JQS5o/T1njZ9uyBXA6\
YduyRTOVW3P4cMMLw6UVFWJ1NYqGDkPpsuWoKy5G2coXNGGty6yZMFgscFVWKpU/OJ1AWJjH6V1v\
QY/nAZNe+NPHj7uEiZqHAZA6rOZWyLxV7BKmTFHauMSNG4eojAwgLEz6VUWIiFB+77JalYogoA1r\
6pNEyla+AFdlJQwWC1IefwwAGo3ZW9DzNg6ijsafiiKrhETNwzWAFPRauiamqXN3Ze4NnZu6vmjo\
MGkK12KB6HBArJYWuxssFrhsNkD9P6n6Js4ANGf8yr8qTaQFAYLJBNFuB0RRGYOv5tT+/vmIQp0/\
awA7yjpBrgGk9sIKIHVYTZ27K5MrbACavP5iTo4U8uolL/wjDBYLBLMZABA3fjzCU1MRN2GCtIkk\
JgZVe79SKn0VubmoKy7Gpbw8ZZoZYWGAKEoVQ1FUqnrfjhwlvc5qhevSJc0Ymjp6jqgj8ae619rr\
Dok6OgZA6rD86c0HNATFpPnz/OoDKIe0pPnzAACG6GgIJhP2nj2LqsJC9N2eqzR9dlmtsG3aJIU4\
qxWi3Y6CqirNGOPGjQMEAQgPV6aCqwoLlVDq3v9PaUBd/17cNUwdHc/yJWp97ANIupcwZYrfISoq\
IwO20lKYr7pKqs7VT/m+WFGBF4vPYEn2cPzZ24sFAW+Eh2HF6VP4bU0NHh46DEnz50nNnkUR4UlJ\
mqlc9/5/clUwKiMDVfVj+XbkKLaOoQ7PW59AImo5VgCJ6vmzaeRSXh7gdKLmyBFp7Z4oosBegxeL\
zwAAnly/HsuXLwfQcEawfP7vexnXYEX9ruGXzpVh79mzjU4U8UTdPkaePpbHwl3ARETUEgyARPXk\
qdWylS94DIIXc3Kk0AcAYWHS2r/ISPzUEo8FiYnKdYsWLcKfbhgB2+bNgNMJx+nT+OfYMXhy/Xrl\
mgVdEpEZFdXQR9DLWNThzr0/ISCtWZQrgewHSERE/uIuYAp67bUrTt5xK0/ruu+uVU79gLTjN2n+\
PJQ89bTUww/A2gs/4vlz55TrF3RJxIzOnbGushL/88PpRo8DAMLCEJ6crDl5RD4pRLTbpd3BRqNm\
B7D7qSHcDUzUcXAXMLUXVgDpsixduhTXXnstYmNjkZSUhIkTJ6KoqEhzTU1NDebMmYPOnTsjJiYG\
kyZNQmlpaYBG7J3cn0/e5OE+JRuVkSEFsshIJM2f19DAud6sXldiydSpyvfPnz+HrGPfeg5/Bul/\
ekJEhFQFDAuD6HCgrrhY2TQi1tZCrK6Gy2rVVALdN7f4u9uZiIhIxgBIl2Xnzp2YM2cO8vPzsW3b\
NtTW1mLMmDGorKxUrpk/fz4+/vhjfPDBB9i5cyeKi4tx5513BnDU3slhKuXxxzQVt29HjpLW3oki\
BKNR2ZShbvkCAHNvu00TAq2qgLigSyJmdOki7fR94nGEp6ZCrKmRThNxOiEYjdKOX0BpOm2wWGCw\
WHyGO393OxMREck4BUyt6ty5c0hKSsLOnTsxYsQIWK1WJCYm4t1338XkyZMBAEePHsVVV12F3bt3\
Y9iwYU3eM9BTInLjZ8FsRlinTnBeuCD17BMEpCx5AgCUqWB5GjY+PAJWZ51yD0tYGPZk/hQAlGbT\
XWbN1EwhC5GRiB05ElWFhcr0rq9G0ETU8QT68470gxVAalXW+k0Sneo3NxQUFKC2thajR49WrunX\
rx+6d++O3bt3e7yH3W6HzWbTfAWCXPkT7XYAgGAyocusmcr3EEWcf/U1lC5foYS4qIwM/D6tuyb8\
AVIl8O9GIwBp/WBURgbOv/qacsQcIJ0hXJErreGr2vuVthF0/bFx/o6ZG0KIiMgXBkBqNS6XC/Pm\
zcPw4cMxYMAAAEBJSQmMRiPi4+M11yYnJ6OkpMTjfZYuXQqLxaJ8paWltfXQPZJ34op2u7LpQ2kE\
Dali12XWTM2Zv8+vf1ez5s9iCFN+vzTv//Dqd9/BEB2ttHSpKiyUQmA90W5X1gEqjaAFAQDgstk8\
Bjt16PN2bjAREZEaAyC1mjlz5uDw4cPIuczq0+LFi2G1WpWv06dPN/2iNtBl1kzlmDZDdDQSpkxp\
eAyAWFODspUvwNy/PwBg7Y8/4vmzZ5XXL+iSiN19+2JB167KY8+fP4d3UpLRZdZM6ezgykqlrx/C\
whA3fnzDOkBIvQRTljyhjMNTsFOHPm4IISIif/AkEGoVv/vd7/Dvf/8bu3btwhVXXKE8npKSAofD\
gfLyck0VsLS0FCkpKR7vZTKZYDKZ2nrIHrm3WAG0J3IAgCEmRmkC7bJaURcdjfeGZOB5tz5/cquX\
WWndIYSFK5XBJ9evh+P0D7j30iXA6YTBYlFCW8KUKYi69qfK2sCqwkLlWDn3cci6zJqpGTPXCRIR\
UVO4CYQuiyiKeOihh/Dhhx9ix44d6Nu3r+Z5eRPI+vXrMWnSJABAUVER+vXrF5SbQHz11LuYk9Ow\
aUMQpKlgQcCJe+7G+CefVK5bMnUqpnz9jTI1bB4wAI7Tp/Hq6VOaCuFbad2RGRur2XF85pHfw7Zl\
C8xXXYW6Cxd4zBuRznATCLUXVgDpssyZMwfvvvsuPvroI8TGxirr+iwWCyIjI2GxWDB9+nQsWLAA\
nTp1QlxcHB566CFkZWX5Ff7am7qapqYJf/UtWuTduldNmYI/Hj6MFf/4Bx65Ig1zb7sNZce/UwJg\
zZEjgChiRpwFqK3D8+fPYf6wLAytX0OoDni2LVuko+a++QZXHTncrn92IiLSD1YA6bII9RsU3L3+\
+uu4//77AUiNoB955BGsX78edrsdY8eOxUsvveR1CthdMPxErJwC4hb+yjf8Q+rjB6Cgqko63i01\
Fa7KSmmaWBAgmM0Qq6ulGwkCCgUBtz7xuNLmRT19e+aR38O2eTMEkwnJixay+kekM8HweUf6wABI\
QS+QH4jqKVmHajOKy2qVNnHIZwPXk3cLA9o1e6XLV0CsqVHCoDzFrJ5y7jJrps+j6Iio42MApPbC\
KWAiH9RTsvKZvYLZDAiCx/CXvidf85gcAgWjEWJ1NcTaWiAsTDpWDtop5/OvvtZwTw9H0REREbUW\
BkAiH+LGjZOmZCMiEJWRgSoArsrKht5/9VO8gtGIpPnzNFO6HnvyOZ2AKKKqsBAAGu3a5akfRETU\
HjgFTEEv0FMi8jStwWKBIToaURkZuJSXB9Fuh2AyacKap7WC8vWA1NdPfdRbc3lqU0NEHUegP+9I\
P9gImqgJcnNlAMrpHel78hHWqRNcVivOv/qachpHVEaG1LTZ6YRtyxZ0mTUTVYWF0nFuly55fQ9/\
j3CTq4olTz3N496IiKjFGACJmpAwZQr6bs9F0vx5mlM21KduyMFMc7Sb09mwEUQVCuVp4Ys5OSga\
OgxFQ4ehbOULfh3hpr4Xj3sjIqKW4hpAIj+5r9dTf1+19yvYSkuldYL16/vkjRwJU6ZIz7s1eFZv\
+lCfBtLUGADvp4IQERH5gwGQqIXU6/GqCguVo9vcj2YDoDxfd+GCprVLSzZ98Lg3IiK6XJwCJt3x\
d71dU9S7fLvMmin1BaysBAD03Z6rCWnq6WJZwpQpSN+Tj/Q9+Qx0RETUrhgASXc8tmdpAXWoS5gy\
BYboaGVTiJqvnbutFUaJiIiagwGQdMdTNa4l5M0hcqjzdl9fgbO1wigREVFzMACS7rgHt7a+r7dg\
eDEnB67KShgsFp9hlFVCIiJqbQyARG3MWzCUdwEboqM1z7kHPlYJiYiotTEAEgWI3DRaPhdY5h74\
WmvKmoiISMYASORBe0y7qlvHqLkHvraasiYiIv1iACTyoK2nXX2t/2PgIyKitsYASORBU9Oul1sh\
9Lb+j4iIqD0wABJ50FQV7nIrhFzXR0REgcSj4IhaQH3cW0vwODciIgokQRRFMdCDIPLFZrPBYrHA\
arUiLi4u0MMhImoz/Lyj9sIpYCIiIiKdYQAk6gDeL3ofYzaMwftF7wd6KEREFAIYAIk6gLWH1uJs\
5VmsPbQ20EMhIqIQwABI1AHMGDgDXaO7YsbAGYEeChERhQBuAqGgx0XRRKQX/Lyj9sIKIBEREZHO\
MAASERER6QwDIBEREZHOMAASERF5cWDbZrw250Ec2LY50EMhalUMgERERF58uXEDbOfL8OXGDYEe\
ClGrYgAkIr+w2TTpUWp6PwgGA1LT+wV6KEStigGQiPxyuc2mGSApFBUXHYXocqG46Gigh0LUqhgA\
iQhA0wHtcptN87QSCkXXTZyMuC5JuG7i5EAPhahVsRE0BT02Rm2594vex9pDazFj4AzcnX63z2vH\
bBiDs5Vn0TW6K7ZO3hrQsRDpFT/vqL2wAkjUgTWn6qau8LXFdO3d6Xdj6+StDH/U5i5n5y53/ZJe\
MAASdWC+pm3dQ546oHG6lkLZ5ezcVb+WYZA6MgZAog7MveqmDn2+Qt6MgTNgMVpQWVvJTRsUFJoT\
xi5n3Z76tWwBQx0ZAyBdll27duHnP/85UlNTIQgCNm7cqHleFEU88cQT6Nq1KyIjIzF69Gh8++23\
gRksaUKfr+rg3el3IyoiCjaHrVFA5G5eam8Htm1G7t9e9hjGPAXDwbeMx8wX/4bBt4z3ej9vYVL9\
Wm4AoY6MAZAuS2VlJQYPHowXX3zR4/MrVqzA6tWr8fLLL2PPnj2Ijo7G2LFjUVNT084jJUA7JSxX\
BwF4DHTeAiKnh6m9fblxA0SXC4LB0CiMtaRK5+9rmgqSRKGMAZAuy6233oqnn34ad9xxR6PnRFHE\
Cy+8gMceewy33347Bg0ahDfffBPFxcWNKoV0+fypzN2dfjdmDJyBtYfWKtd5C3TeAuLltoMhai65\
Ejfqwd80CmP+NGqWK35vL56H56fehsi4OFb2SPcYAKnNfP/99ygpKcHo0aOVxywWC4YOHYrdu3cH\
cGQdk6cgpw6F7xe9j+z12Xg6/2nNde6Bzj1I+qr4cTqY2oOvSlxTjZrV08el3x2D6HKh7MR3rOyR\
7jEAUpspKSkBACQnJ2seT05OVp7zxG63w2azab6oaZ4qc+rwtvbQWlgdVogQlesB7UaR94vexzN7\
nvEZEN3vyelgCqSm1unl5bwJ0eUCBAHJV/aBYDAgPSubO3xJ9xgAKegsXboUFotF+UpLSwv0kIKa\
XIUD0KjPnjq8uU/ZeurHt/bQWrhEFwyCwWNA9HRPX9VDorZ0YNtmfLlxA66bONl7NU8UAADmqBj8\
aukLGPXgb1BcdBR569+C7XwZcv/2MkMg6RIDILWZlJQUAEBpaanm8dLSUuU5TxYvXgyr1ap8nT59\
uk3HGep8VeHU6/jWHlqLCEMEAMAcZlauUYc2OdA9OvRRrw2b1YHQPRyyIkhN8VV5a25VLi/nTdjO\
lyEv502vr82eei/iuiQhe+q9ABo2gEAQAUGA6HIhb/1bzXpvVg+pI2AApDbTq1cvpKSkIDc3V3nM\
ZrNhz549yMrK8vo6k8mEuLg4zRd558+mDDmYhQlhMAgGjOw+stFzq/etxtpDa5GRlKFsEpHD4cJd\
Cz1W9twrft7GwsogyXztwG32jt766h5Ewetr5XYucmNnedOIJUn1Q6gg+nxv98DH/oDUETAA0mW5\
dOkS9u/fj/379wOQNn7s378fp06dgiAImDdvHp5++mn861//wqFDhzBt2jSkpqZi4sSJAR13R1NZ\
W4nV+1Z7DVhyMDOGGeESXcg7k6cEu6raKsQZ42B32nG28iw++f6TRmv8tpzYooTE7PXZGL5+uMdm\
0t6Oe2NlkGS+1ux5e86f6p6v+6oDm7xppOzEd4AoQjAYkD1lmub1TQU+9gekjkAQRVEM9CAodO3Y\
sQM333xzo8fvu+8+vPHGGxBFEUuWLMGrr76K8vJyZGdn46WXXsJPfvITv9+Dh6P7Nnz9cNgc0kaZ\
rtFdlSlfT+TQdrHmImqcNRAgQISIrtFdUVVbBavDCnOYGQnmBM2mj4ykDBSWFaKytlJ5rzhjHBxO\
B+xOO27tdSuWj1je5PvK/QeJ/CGv8XNUV6OmsgJxXZIw88W/ebzG0zpA+bnU9H4oLjqK1PR+OLG/\
EBBE9Bw8BMVFRz2+7rU5D8J2vkx5P7/WGrYSft5Re2EApKDHD0Tfstdnw+qwQoCAx4Y95jVgqUPY\
s3ufRY2zBuFCOMIN4bA77UiJTkFpVSnG9RyH5SOWY+GuhdhyYguu6nQVLtRcUALh6n2rIUKEw+lA\
jVNq6N1U8CRqCTmImWNiYDRHKRU3dRh7cfoU1Fy6BHNMDOasy/H4erla9591awBRhDk6FnP+tl5z\
rTrkub9He+LnHbUXBkAKevxA9EwOdHJ1zlN1TR365GlYdbVPrgCqGQQDHh36KJ7Z8wxcokt53Bxm\
hsPlwLie45CZnImn859WXhtnjMPcIXNZ3aNWdWDbZuTlvAmIAnpek4ETB/ahprISEEWlOvfig1NR\
U1kBQ1g4XC4nwo1G3HTvdAy+ZbymAli0O09qBwMAgoDR02drrnHUVKHm0iWPVUZvY2uLkMjPO2ov\
DIAU9PiB6NmYDWOUQOet+iZfI9T/nwsu9O/cHz3iemDz95tR+d9KRP8kGgBggAEuSP9Ado3uioyk\
DGw5sQXJUcn4bv93iOwbqdw3zhgHm8MGg2BATEQMbA4bq4DUJuQqnmAwKAFOMBiUU0HkIGY7X6a8\
xj3EyfdQCzeZEBVrQVWFFXV2Owzh4RBdLqRnZWPCw3/0e1z+BkZ/8fOO2gs3gRCFKH92/84YOAMG\
wQARohLuvrnwDQrLClH6YSm+/8v3OLfpnBIOAUCAgBkDZ2D5iOU4MO0A/vuP/+L4M8dxbuM55b7V\
ddUAgKs6XYW5Q+Yq4+BuX2pt8oaL9KxsmGNiEG40wRQVpTwvnxISbjJpXgM0bB6J9BCk6ux22M6X\
oc5uBwC46uo8nijibQMKN4JQqGMFkIIefyK+PO8XvY/V+1ajsrYSTtGJW3vdiugforHkl0uUa7pP\
6Y64cQ1/t+YwM4xhRvQs6Il3/+dd5fEn33kSW4WtsDqsAKTp4gPTDijP+1OVJGou9XRrQx8/AeER\
RkAAwsON6HlNBnbu2Ilfzp6jTMl6qh4CwKnyClyZ3EWp/Lnq6qQnVFPD8vvm/u1liC5Xq1f6vOHn\
HbUXVgCJQpC3Spunx+9Ovxt5U/OweOhixBnjsP3UdnwqfIoeU3oo15zKOYXzm84r39c4a3D8w+Oa\
8Nftnm7ol9kPUREN1ZerOl2lef8ZA2cgzhiHqtoqr70DSZ8up3myug3LdRMnA4IAiCLqHHbU2e2o\
qazAy2+tx7MfbsaWfYdwYNtmvPjgVFRVWGGOjkV6VjbiuiTBHBOD7d8cx+qtu/CNaEZclyQYTQ1L\
G8IjjEq/QPl9RZcLgsHASh91OKwAUtDjT8SNeau0qR+XN37Im0Tk1i9qFz+5iDPvnVG+7z6lO5Im\
JOHsv89qHk++KxmJExKV+8obRNTvI29CkccgYzWQgMtbM6fezHFifyFqKiuU58JNJpz80YqVmxsa\
zt85LBPXd69v9Fxf1QOAJX9ajI++Oqhc93//93+IrbYhL+dN1DlqUeeQpoPN0bHInnov8ta/BQgi\
sqdMA9A+O4P5eUfthRVAohDkbf2f+nH3Js52p73RfTqP74xly5Yp35/KOYXv5n6nCX/d7umGxAmJ\
AICMpAzcnX43Hh36qPI+q/atwtnKs1i1b5UyBoMgfbSozxQmffNnzZy3KqG8zq+46KgS/gSDAaNn\
/BZz3/wH7pu3AHcOy1Su/2d+AbZ/c1z6RhTxn3Vr8KdHHtGEv/ED++HEpoaTPOpqHQ2/r3Pgy40b\
UFNZAaNZqnjn/u1lnv5BHUp4oAdARM0nn8PrS0ZSBkpPlCp9/DKSMvD5mc8hQkRabBq+/vFrGA1G\
9JrYC8uwDIsWLQIAXLhwQblH8l3JSLg1Qfl+y4ktyEzO1LyPAOk4rgpHBRbuWojCskKM6znOa2sa\
0qfBt4xvsnKmnur1dO11Eydjx5vrUFfrQHpWtnLNlxs34PruKbBXX4VNB74BAGw+JG3mGHlVb2z/\
+pjyPSCFv5FX9Ubpd8fw4w+nlcqfrM7hQGp6P+U95algAMrjRKGOFUCiDkSu+q3atwpbTmyBS3Th\
Qs0FbJ28FZnJmYiKiMLcIXPRI64HRIiocdZg7aG16DWxF8JjtD8PRsREKJU/QAp6LtGlnBksH+02\
vNtwAIAIUak2FpYVejwSjsiXpqqEg28Zj6g4CyCKKNqdhwPbNuPAts1w1FTBHB2L2Q/ej9szByvX\
bz50FE9s3Noo/N1+wzAAQPKVfTSVP4Uo4sSBfZpxCQbpn0v3XcLA5a1vJAoUBkCiDkSeApbDmnoK\
Vg5tq/etxubvG/6h6mTuhIcffxh1l+o096q9VItzm6TWL/0790esMRYAYHfaUVlbCYvRghkDZ+Dz\
M58rr7mq01VNtqYhag73cCWHMdHlQu7fXkbe+rdQc+mSMjW88av9uP2ng5TXVzlqld/LlT8BAh55\
79/41dIX0O/6G6RNJSpxXZIAUdBUI0c9+Bu/zhr2Nm6iYMMASBRifPXauzv9bmydvBUPD3kYXaO7\
4tGhjypVuIykDBgEAyprK5Xr+3fujx1v7kDpB6XKY2HRYcrvSz8oRefdnZHzsxzMHTIXccY42J12\
2Bw2iBCx9tBazdpCudro6zg67gwmbzwFKffHBt8yHulZ2QAgTcsKDfsYi3bnAQBm3vtLRBkjNPeO\
MkZg5NV9IBgMsJ0vw8pfTMSBbZsx4eE/4pGcj9Fv+AgIBgP6DR+BmS/+DdlT71UCX1OnfniqXHr6\
sxAFEwZAohCjnn71Rg6CAJTAVVhWCJfoglN0AgAsRgsKcgo04a/7lO6YnDMZyXclK4/tfGUnekyV\
WsZER0RDhAgBAiocFThbeRbGMCPijHFKRfByx0765SlIeXpMnoYVDAZkT5mmhDc5GL725ruayh8g\
VQI/K/pOWcvnctYh928vKxW6CQ//EaMe/A2Ki47iwLbNysaTwbeMbzLMqa/1NW6iYMI2MBT02BZB\
e6YvAKzatwoOpwOmMBOuiL0CX//4NUxhJvzh2j9oqm9ySxaDYFA2ZshtYUr/XYqDf2/YFZl8VzIG\
3T0IMwbOwFP5T+HcpnONwmHShCRNKxn53GD1e6rH6utsYq4P1LeWnqV7YNtm7HhrHeocDiT36g1r\
aSkgiOg5eAiKi47ii9MleOPjT5Tro4wRHqeBZeq2NN5a1WxavQJFu/P8PibucvDzjtoLAyAFPX4g\
Nu77595rTxZnjEN0RLQSsBbuWqis91P34/t/7/4/zUkgXe/uis7jO6N/5/64UHNBubd7COz1p17K\
2cECBDw27DElyC3ctRBbTmyB0WBEjbNGeT9voY9hUN+a0xdQHRbz1r/V0AewviG0/Htvu323f3Nc\
8/idwzLx4NS7lVB3xVUDlD6DxUVHlapdXs6bgCitD6yprFDG2tLw6g9+3lF74RQwUQhw7/snn7hh\
MVrQv3N/CBBgDjPD4XQoGz0AoLCsULlHRlKG8vutwlYk3i7t8O12Tzd0Gd8FAPD1j1/jYs1F5bqu\
P+uK7lO6AwCSJyYj5icxynOxxlhNcJN3Hdc4a2AQDMr7eZv25XSwvjWnL2BezpsNU7CqNX/SUXBS\
QPvs6Hcewx8gtYIZP7Chfcs/8wvw0trXIbpcOLZ3D/6z9iXYzpfhxP5CzbSvsrlEEDVjlaeE1VPI\
RKGGAZAoBMhr+uTAdXf63fh86ufIm5qHnJ/l4OB9B7H3V3thDDMCkFqyAFJQlPv0ffL9J8rmCxEi\
ku9IxoAnBuCHnB9wa69bYRAMCBPCNFO80RHRSLstDb3+1AtJE5MgQoTFaEHX6K6YO2SuZozjeo6D\
QTDAHGaGS3Qp4dOfptWkP57WzblTzv0VBZhjYuCorkbPwUNgCJdaFnW+Ig39rr8B3/94EZsOfK28\
btmyZdh08Bv0Gz5CeWz0wHT8LKO/8v3mQ0fx/Y8XtW1gBFEJnanp/WCOiYE5OhY9Bw/RjEu9E5mb\
PChUMQASdSBzh8zVhLO70+9GnFGaRpJ37aqvGz9qPMZsGAMASI5KRrhB2wtweLfheHjIw+iT0Qe3\
9roVXaO74uEhD3vc6bt8xHI8OvRRANL0cEZShs9pXvdQS/rhb4sUuUqYPfVeGM1RqKmsQHHRUWUj\
R+l3x3DiwD706pyAW/r3BQD8LKM/Yor248XpU/DfPV8o9zKazbgt6zqlEjh2UD/cetvtCDdKPzSF\
G03InjJNCZ3FRUcxZ10Osqfei6LdeY12IvtqC0MUCngSCFEHoj4hRA5fw7sNV04AmTFwhiaUrdq3\
CjaHDSXflyhVQzW5ildaJa0D9HWm7/tF7ytnBMuvLSwrVKZ5GfRI1tSJHzL59BB1s+frJk7GD98c\
xtHPd0kXiQLiuiRh7qwRuGbHTvSIj9OcFawQBVw3cTIc1dVIT0vFffMewZcbN6DObtes7XNUV8Mc\
E6OZ7hVdLggGgybs+XOyCVEwYwWQqIOS19jlnclTTgC5O/1uzdo7eXrYFGZSzu8FpApenDEOGUkZ\
2Pz9ZrhEF7ac2OLxfeTefqv3rYZLdEGAoLSE4TQvedLcFinyejxjZCQG3zIeEx7+I0bP+K1SHbxu\
4mScOLAPPeLj0POaDJijY2GOiUHylX0AQUC4yYTsqfdi8C3jYYyMRLeYSGUTh/vaPvn8XzncydeM\
evA3msDHRs8U6rgLmIIed8U13/tF72P1vtVKzz6rw+pxVy4A5fcFpQX45PtPNO1k1LuN5R3C6unc\
94vex9P5T0OECHOYGQnmBL939XIXMHniaYdtU7tu5R3Fsn7DR2jatbi3jqm22TzeqzntXpqzi7k5\
+HlH7YUVQKIOaNW+VbA6rKhwVGB4t+HoGt0VGUkZyno/ee3d3el3Y8bAGVh7aK0yTZxgTlACWSdz\
JwDQtIdR79pde2itMnVsDDNq1vQ1deoHdwGTJ56aLrtvGNm0egWen3obNq1eAUCq0pljGnaoy+cE\
yxU6eaoXooiyE9953Xwiry/0dN6vOzZ6plDHAEgUwryFLHlqV4SIwrJCbJ28FZ+f+VzTIka2at8q\
nK08C6vD2ug0j28ufKP86mk6d8bAGbAYLYgzxmHukLma8TQV8Dg9TJ74ClZyqDv6xf9BdLmUo98G\
3zIec9blaE4EyVv/Fmzny7DjrXWoslmVe8inhbjf88C2zc0Kdf7sYiYKZtwEQhTC5E0cq/at0kyj\
PjzkYazatwoCBCVgyZU6980eclgEgIpa7eL5cT3HYcuJLRjXc5xmg4nM/TF5ylie2lVPNbvzdD8i\
X5sr5CbQgsEAURSR1PNKzfMTHv4jrrhqgKZZdJ3DoTSLjuuS1GhqV11xbCrQtWUDaKL2xgogUQiT\
w5s6xAHaPoGAFMyyu2VrWsTI1brh3YbDYrRAgACX6NJU7JaPWI4D0w5g+YjlXquN6sczkjKUJtBs\
80Ktrr4JtLx0vdpma3SJvJEDkM4KTu7VW9kI4qmy15yqX1NnAhOFEgZAohD28JCHld58QOMpYbk1\
y9nKs8pUsBzI5CnawrJC5E3Nw2PDHvM4Jave5dvUiR6FZYWaJtBErSl7yjTEdUlCv+tv8BraUtP7\
KYFv1IO/kUKiKCIq1uKxaudrKtd9py/X/VFHwilgohDmPo2qDmNyyxeX6IJBMCjBTl6fl5GUAZSh\
yTV48j3jjHEeA2JGUgZKT5QiIykDmcmZPqd9iS6HP733iouOAqIIZ20tACm0ydO2zZ3ClSt+eTlv\
Kq9rzR2/RIHECiBRB+LpzOCu0V3x6NBHPVb+PFUE3St88j3mDpnrcUpXXfXjtC+1NW/999RHuKmP\
aVNX+Jo7hStX/CAKnPqlDocBkKgD8XRmsHsga+7ZvE2FOu7mpfYkh7jcv72sCYHqI9y8HdMmh8PU\
9H7KY74aOsvhMXvqvZz6pQ6HjaAp6LExauhis2dqDeqpWwDI/dvLEF0uTRNmX9O7B7ZtRl7Om6ip\
rAREUfO6tmro3FL8vKP2wgogUQfUVBPm9sJmz9Qa3M8Odq/wbVq9Arl/exmp6f08ru2Tj5KDKDY6\
05cbO0ivGACJOqBgCV6cHqbLdWDbZjhqqmCOjlVCmvvO3aLdeZrG0O7kk0LM0bGNzvT1tAuY5/yS\
HnAXMFEH1FQT5vbCZs90ueTqXVyXJK+tWsLCI1BX62h0yofMn93D7u+prjgSdUQMgEQdEIMXdRTq\
Ni6efLlxA+oc9kanfMhrAlPT+6G46GizTu9o6j2JOgJuAqGgx0XRROSNt80f8uYOuSWMvM4v2I9y\
4+cdtReuASTqQIJl8wdRe/F2koe8uSM9K1sT/tjPj0jCKWCiDsT9JJBAYfsXCjRv6/44tUskYQWQ\
2sWLL76Inj17wmw2Y+jQofjyyy8DPaQOKVh23QbLLmQiNV/n/hLpDQMgtbn33nsPCxYswJIlS7Bv\
3z4MHjwYY8eORVlZWaCH1uG05VFszZleDpYgSkREnnETCLW5oUOH4tprr8X//u//AgBcLhfS0tLw\
0EMPYdGiRU2+nouig8OYDWNwtvIsukZ3xdbJWwM9HKIOiZ931F5YAaQ25XA4UFBQgNGjRyuPGQwG\
jB49Grt37w7gyKi5WNUjIuo4uAmE2tT58+fhdDqRnJyseTw5ORlHjx71+Bq73Q673a58b7PZ2nSM\
5B/2FiQi6jhYAaSgs3TpUlgsFuUrLS0t0EMiIiLqUBgAqU116dIFYWFhKC0t1TxeWlqKlJQUj69Z\
vHgxrFar8nX69On2GCoREZFuMABSmzIajcjMzERubq7ymMvlQm5uLrKysjy+xmQyIS4uTvNFRERE\
rYdrAKnNLViwAPfddx9++tOf4rrrrsMLL7yAyspKPPDAA4EeGhERkS4xAFKbu+eee3Du3Dk88cQT\
KCkpwTXXXIMtW7Y02hhCRERE7YN9ACnosS8WEekFP++ovXANIBEREZHOMAASERER6QwDIBEREZHO\
MAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBER\
EZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwD\
IBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER\
6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAAS\
ERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMABSiz3zzDO4/vrrERUVhfj4eI/XnDp1ChMmTEBU\
VBSSkpLwhz/8AXV1de07UCIiItIID/QAKHQ5HA7cddddyMrKwrp16xo973Q6MWHCBKSkpOCLL77A\
2bNnMW3aNEREROAvf/lLAEZMREREACCIoigGehAU2t544w3MmzcP5eXlmsc/+eQT/OxnP0NxcTGS\
k5MBAC+//DIWLlyIc+fOwWg0+nV/m80Gi8UCq9WKuLi41h4+EVHQ4OcdtRdOAVOb2b17NwYOHKiE\
PwAYO3YsbDYbjhw54vV1drsdNptN80VERESthwGQ2kxJSYkm/AFQvi8pKfH6uqVLl8JisShfaWlp\
bTpOIiIivWEAJI1FixZBEASfX0ePHm3TMSxevBhWq1X5On36dJu+HxERkd5wEwhpPPLII7j//vt9\
XnPllVf6da+UlBR8+eWXmsdKS0uV57wxmUwwmUx+vQcRERE1HwMgaSQmJiIxMbFV7pWVlYVnnnkG\
ZWVlSEpKAgBs27YNcXFxuPrqq1vlPYiIiKj5GACpxU6dOoULFy7g1KlTcDqd2L9/PwCgT58+iImJ\
wZgxY3D11Vfj3nvvxYoVK1BSUoLHHnsMc+bMYYWPiIgogNgGhlrs/vvvx9///vdGj3/22We46aab\
AAAnT57E7NmzsWPHDkRHR+O+++7DsmXLEB7u/88ebItARHrBzztqLwyAFPT4gUhEesHPO2ov3AVM\
REREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6\
wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgERE\
REQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMM\
gEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIRERE\
pDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIRES6d3jXGbz5p89xeNeZQA+FqF0wABIRke7t23IC\
FRfs2LflRKCHQtQuGACpRU6cOIHp06ejV69eiIyMRO/evbFkyRI4HA7NdQcPHsQNN9wAs9mMtLQ0\
rFixIkAjJiLybsi4nojtZMKQcT0DPRSidhEe6AFQaDp69ChcLhdeeeUV9OnTB4cPH8bMmTNRWVmJ\
5557DgBgs9kwZswYjB49Gi+//DIOHTqEBx98EPHx8Zg1a1aA/wRERA0GjOiGASO6BXoYRO1GEEVR\
DPQgqGN49tlnsWbNGnz33XcAgDVr1uDRRx9FSUkJjEYjAGDRokXYuHEjjh496vd9bTYbLBYLrFYr\
4uLi2mTsRKRPh3edwb4tJzBkXM+gCID8vKP2wilgajVWqxWdOnVSvt+9ezdGjBihhD8AGDt2LIqK\
inDx4sVADJGISMPftX/cJEIdDQMgtYpjx47hr3/9K379618rj5WUlCA5OVlznfx9SUmJ13vZ7XbY\
bDbNFxFRS/kKb/6u/eMmEepoGABJY9GiRRAEweeX+/TtmTNnMG7cONx1112YOXPmZY9h6dKlsFgs\
yldaWtpl35OIQlNrVN58hbcBI7ph2l+GNzn9y00i1NFwDSBpnDt3Dj/++KPPa6688kplWre4uBg3\
3XQThg0bhjfeeAMGQ8PPFNOmTYPNZsPGjRuVxz777DOMHDkSFy5cQEJCgsf72+122O125XubzYa0\
tDSuiSHSoTf/9DkqLtgR28mEaX8Z3qJ7BNs6P1+4BpDaC3cBk0ZiYiISExP9uvbMmTO4+eabkZmZ\
iddff10T/gAgKysLjz76KGpraxEREQEA2LZtG9LT072GPwAwmUwwmUwt/0MQUYcxZFxPJbw1h3vo\
C/bgR9TeOAVMLXLmzBncdNNN6N69O5577jmcO3cOJSUlmrV9v/jFL2A0GjF9+nQcOXIE7733Hlat\
WoUFCxYEcOREFEr8naJ1xzV7RL6xAkgtsm3bNhw7dgzHjh3DFVdcoXlOXlVgsViwdetWzJkzB5mZ\
mejSpQueeOIJ9gAkojbnb+UwlKaHiVoT1wBS0OOaGCJqC4d3ncGunCKILlzWGsPWxM87ai+cAiYi\
opDSWj359m05AdEFCAZwdy/pDgMgERGFFH/W9/kTEuXWLiOmpHP6l3SHawCJiCjoqdfq+bO+Tx0S\
vYW71todzHWEFIpYASQioqDhrXLnHujUO4M9vSaldzwEg/Srr/u2daNpomDFCiAREQUNb5U7T1U/\
ufLmqHHCXlWnBLD8jcdhr64DRKDkeLnmvvkbj2uqdfkbj8NeVYf8jcdbXL1raa9CokBiACQioqDh\
LUx5mq6VQ50pKlw5pm3flhOwV9UB0G7ukJ9z1Dh9Tg23ZDqXjaYpFDEAEhFR0PAVptzD2ZBxPZG/\
8TicdS44aqRrUnrHo+JiKcIjDBg+uS+Kvy3Hrpwi9MlMVq4PjzDAUePE4V1nMGxib03g9GftoPt4\
UnrHo+R4OdcAUkjhGkAiIgo4f9biua+1GzCiG4zmMNQ5XMoUcMnxckAEImMiMGBENxwrKIXoAr79\
qhS7copgr6qD09lwvft6QnlnsD/TufJ4vv2qVJleJgoVDIBERBRw7uHOPRAe3nUGjhonTFHhSOkd\
rzw3ZFxPhEcYAEGq/rkHuD6ZyRAMQHi4AaJLeq8uabFeQ15zjp6T3ys8nP+UUujhf7VERBRw7sHN\
PRDKa/uM5jCUHC/XTNNGxkYAInCsoBQANAEutW88YuJN6HVNIoT6f/FqKhyNQp6/u4HV18lhcfhd\
fRHbyYRhE3u37l8KURtiACQiooBraipW/b2n5yAAoguaaVj5qLeKC3aUHC/HiCnpXit/+RuPa6Zx\
/WlH423sRKGAm0CIiCjoyJtB5CA2ZFxPzVm98nNrF+wCIE3x1tW6NPdQH/VmjjUqm0HU/QO9tW+R\
28PsXF+kvB/Ali/UcQiiKIqBHgSRLzwcnUi/3vzT56i4YEdsJ5MmAKqfAwBTVDiM5jDNFLJ6d+6u\
nCJpDaAAxCaYkNI7XtkgIhiktYIlx8uR0jsep478qLSSAeDxvdsKP++ovXAKmIiIgpY83ave+KF+\
zhQVDlNUOIZN7K1Mw+a89hEqLtjx/f5zqLhox+cffIsuabHKZhB55+6xM4cASFPHp478CADa8CdI\
wZLVPuqIWAGkoMefiInIVyUQALauO4JjBaXYeuhtfJT3OiYOm4nRg6coz8uvO7zrDPI3Hse/v3gL\
H+1Zi1szp+H2rAdQV+cCRCA8omEque+1yRgzvX+7/RkBft5R+2EFkIiIgp5c7ZMbOLs7ViBV9D7K\
ex0AsDH/NWzbv155Xj4TeMCIbvhk77v4aM9aAMAnBW+i6IcDgChNBYdFNPyzKB8jR9QRMQASEVHA\
NdWGRW76rD7zV61PZjL6dBuIu276jfLYR3vWKiHw+wPnsHbBLky64Tf4Z94ryjV3Zv8a6WmDYYoK\
x4gp6Rg2sbcyrSxP/frbIoYolHAXMBERBZz7EWyezuSVj3KrrqjF2gW7MGxib+W5MdP7Sz3/tvwK\
3dIT8MIrSwFAqfTdcs1UfPLlO8r3ADDv14uR0WkCKi7YlZNDADRq59Kc4+GIQgUrgEREFHBNNYKW\
OWrqUFcrHeW2K6dIc1KI3POvf9Q43O1WCVz4xh2a8Hdn9q+x8uW/NDm1LI+tqWuIQg03gVDQ46Jo\
Iv1RVwCLvy3HsYJShIUbUOdwAUL9RWJD+xdHjRP2qjoIBsBoDoe9qg7b9q/XhD7Z7UNn4JZrpgIC\
0PenycrOX1NUOGY8P8LjeJrahNJa+HlH7YUVQCIiCjrq0zXkfn11tS7EdjLhxqnpuHFqOkxRUtCr\
uGBHrd2J2E4m9MlMhrNO2sV7yzVTEWWK1dw3yhQrhT8AEIFv95ai1u4EADhrXV7X+rlXKLkukEId\
AyAREQVUU2GqT2YyBINUrZNDYfG35ZpmzS6nCEeNE99+VSpVCQFsO7AeVfYKzb2q7BWa3cHya+Wq\
onwcnPt4BozoppwCIlcnPU1RE4UKBkAiIgqopsLUmOn98duXRmp68h0rKG24QAAMYYIUCEXp++1H\
3sdH+Q3Tv+pKoLw72GAQGu4hSi1g1FVF9bnC7uN0rwgShRoGQCIiCqjmhCm5WhgdbwIAJPaIxY1T\
0+Fy1S9nF4Bj4n80rV5uHzoDq377bzw4ab7y2Ed71uK/rm248RfpCI8wAALQvX9nGM1hmvfbuu4I\
Xvrtdmxdd0RzKol6hzKngykUcRMIBT0uiibSN/WGELkKJxignOOr3hxyTPyP0gIGaNjwEdtJCoz/\
3P5Go1YwfQ2jlXOCw8OlMChXBNXHws1ZMxJA4w0hrblBhJ931F5YASQiooDzVUXzNPUqrwuUN4cA\
wPGzhzTh746sWcqGj4oLdphjjRib+QvcPnSGcs0LryxVzgSGKN3LWefShj/UB8N67hVLTgdTKGIA\
JCKiduMt6MkhT93bT+Zp6jW1bzyMZunEjr4/lcJg75SBmJj9AABg2bJl+OcXr8AU1XDewblTFXA5\
RdxyzVQlBN6aOQ29UwciPMKAcKNU/RNd0o5gwSBNMZuiwhEWYcDhXWeUaqQ8lsO7zmh2LBOFCk4B\
U9DjlAhRx+FtulRu5Cy64HUqVf1aQKrqyX0AzbFGnD9dgT6ZySip/i+qixJQV+eCQRCU9YHhEQal\
WigIwLHiQ+iTOhDGSGnjh1zFy994HPZqaUOJ+r3Uv5erj63dF5Cfd9ReWAEkIqJ24226dMCIbhgx\
Jd3nVKr6tfLvASmQnTtVAdEFnDryI1CcJAU9EXC5RKmFzLXJGH5XXwj1/+qJItC760CIgHL+r6NG\
6gdoNIcBorS+UP1e6t/3yUzmtC+FNFYAKejxJ2Ii8kaekq20OuByijCECYgwhcFRXQdRBAwGqQIo\
VwpTesej5Hi5cn240YBfr75JU12UN5uozyFu6v39udYf/Lyj9sIKIBERBSV/26s4apxSM2dIFT97\
VZ3S2DnCHKapFJYcL8e0vwxH7yFJEAxAr8GJALTrDPM3HleqgU1hQ2gKVQyAREQUdOQ1gd5O5lBf\
o96tm9g9VjNFO2xib0z7y3DNNO/hXWdQcrwcogsoOV4OoOHouZLj0gkj9qo6v0IddwBTqApv+hIi\
IqL2IU+pOmqcSp8/AEqVTT3Num/LCaV/HwBABGznqmE0hyG1b7zm5JABI7o1aicj7+Z980+fK1PD\
5lgjKi7aER5h8Bjq3Kd85S+iUMMKIBERBQ05pAHSDtsRU9IxbGJvj1U2ufp249R0pRWMs87ldUpW\
Xa2Tz/Y9VlCKigt25dfzpysAEYiMifAY7DjlSx0FK4BERBQ0vG3AcA9j7pU4uRoYFm5AZExEo7Do\
abOG/BrBAKl9zPFypRLoayeyfB+iUMYASEREQcPfKVV1JU6u5u3bckLpB1j8bblyTu++LSdQfakW\
dQ4X8jceV+7vHuZKjpc3mjoGoGn+LIdDTvtSqOMUMLXYbbfdhu7du8NsNqNr16649957UVxcrLnm\
4MGDuOGGG2A2m5GWloYVK1YEaLRE1JG4b76QQ+C5k1I/wG/3lirBreKCXWkArSZv/ACgbDjxNLUr\
30OeJub0L3UEDIDUYjfffDPef/99FBUV4R//+AeOHz+OyZMnK8/bbDaMGTMGPXr0QEFBAZ599ln8\
+c9/xquvvhrAURNRR+B+/Jq8I1hNfXZw35827Ap2p54K9jS1y+bP1BGxETS1mn/961+YOHEi7HY7\
IiIisGbNGjz66KMoKSmB0WgEACxatAgbN27E0aNH/b4vG6MSUVPkRs4QgPBwA8IiDBg2sbdmqtZb\
02b3x1u7uXNz8POO2gvXAFKruHDhAt555x1cf/31iIiIAADs3r0bI0aMUMIfAIwdOxbLly/HxYsX\
kZCQEKjhElEH48/pHfJUbv7G4z5bubivLyTqiDgFTJdl4cKFiI6ORufOnXHq1Cl89NFHynMlJSVI\
Tk7WXC9/X1JS4vWedrsdNptN80VE5IunKWH35tHu5wd7W8vH5s6kBwyApLFo0SIIguDzSz19+4c/\
/AGFhYXYunUrwsLCMG3aNFzuqoKlS5fCYrEoX2lpaZf7xyIiHVCHPrmKtyunSAmBckj01ldQ5h4m\
iToirgEkjXPnzuHHH3/0ec2VV16pmdaV/fDDD0hLS8MXX3yBrKwsTJs2DTabDRs3blSu+eyzzzBy\
5EhcuHDB6xSw3W6H3W5XvrfZbEhLS+OaGCLySV4HKIe7XTlFEF1SQ2l5t683gVz3p8Y1gNReuAaQ\
NBITE5GYmNii17pcUpsFObxlZWXh0UcfRW1trbIucNu2bUhPT/e5/s9kMsFkMrVoDEQUOIEOUZ7W\
AfrbtJnr/khvWAGkFtmzZw/27t2L7OxsJCQk4Pjx43j88cdRWlqKI0eOwGQywWq1Ij09HWPGjMHC\
hQtx+PBhPPjgg1i5ciVmzZrl93vxJ2Ki0KCuwDVVcQs2vsJrewZbft5Re2EFkFokKioK//znP7Fk\
yRJUVlaia9euGDduHB577DGlemexWLB161bMmTMHmZmZ6NKlC5544olmhT8iCh3tcUza4V1nkL/x\
OAA0avNyOXydQMLqIHVErABS0ONPxEQkU/r9wb+1fa2BFUDqiFgBJCKikDFkXE+lAthebVr8PZ+Y\
KJQwABIRUchgGCNqHewDSERERKQzDIBEREREOsMASERERKQzDIBEREREOsMASERERKQzDIBERERE\
OsMASERERKQzDIBEREREOsMASERERKQzDIBEREREOsMASERERKQzDIBEREREOsMASERERKQz4YEe\
AFFTRFEEANhstgCPhIiobcmfc/LnHlFbYQCkoFdRUQEASEtLC/BIiIjax48//giLxRLoYVAHJoj8\
MYOCnMvlQnFxMWJjYyEIQru/v81mQ1paGk6fPo24uLh2f//LFcrj59gDJ5THH8pjt1qt6N69Oy5e\
vIj4+PhAD4c6MFYAKegZDAZcccUVgR4G4uLiQu4fE7VQHj/HHjihPP5QHrvBwCX61Lb4XxgRERGR\
zjAAEhEREekMAyBRE0wmE5YsWQKTyRToobRIKI+fYw+cUB4/x07UNG4CISIiItIZVgCJiIiIdIYB\
kIiIiEhnGACJiIiIdIYBkIiIiEhnGACJvDhx4gSmT5+OXr16ITIyEr1798aSJUvgcDg01x08eBA3\
3HADzGYz0tLSsGLFigCNuLFnnnkG119/PaKioryeKnDq1ClMmDABUVFRSEpKwh/+8AfU1dW170A9\
ePHFF9GzZ0+YzWYMHToUX375ZaCH5NGuXbvw85//HKmpqRAEARs3btQ8L4oinnjiCXTt2hWRkZEY\
PXo0vv3228AM1s3SpUtx7bXXIjY2FklJSZg4cSKKioo019TU1GDOnDno3LkzYmJiMGnSJJSWlgZo\
xA3WrFmDQYMGKc2es7Ky8MknnyjPB+u4PVm2bBkEQcC8efOUx0Jp/BSaGACJvDh69ChcLhdeeeUV\
HDlyBCtXrsTLL7+MP/3pT8o1NpsNY8aMQY8ePVBQUIBnn30Wf/7zn/Hqq68GcOQNHA4H7rrrLsye\
Pdvj806nExMmTIDD4cAXX3yBv//973jjjTfwxBNPtPNItd577z0sWLAAS5Yswb59+zB48GCMHTsW\
ZWVlAR2XJ5WVlRg8eDBefPFFj8+vWLECq1evxssvv4w9e/YgOjoaY8eORU1NTTuPtLGdO3dizpw5\
yM/Px7Zt21BbW4sxY8agsrJSuWb+/Pn4+OOP8cEHH2Dnzp0oLi7GnXfeGcBRS6644gosW7YMBQUF\
+OqrrzBy5EjcfvvtOHLkCIDgHbe7vXv34pVXXsGgQYM0j4fK+CmEiUTktxUrVoi9evVSvn/ppZfE\
hIQE0W63K48tXLhQTE9PD8TwvHr99ddFi8XS6PHNmzeLBoNBLCkpUR5bs2aNGBcXp/kztbfrrrtO\
nDNnjvK90+kUU1NTxaVLlwZsTP4AIH744YfK9y6XS0xJSRGfffZZ5bHy8nLRZDKJ69evD8AIfSsr\
KxMBiDt37hRFURprRESE+MEHHyjXfPPNNyIAcffu3YEaplcJCQni2rVrQ2bcFRUVYt++fcVt27aJ\
N954ozh37lxRFEPv751CEyuARM1gtVrRqVMn5fvdu3djxIgRMBqNymNjx45FUVERLl68GIghNsvu\
3bsxcOBAJCcnK4+NHTsWNptNqaS0N4fDgYKCAowePVp5zGAwYPTo0di9e3dAxtRS33//PUpKSjR/\
FovFgqFDhwbln8VqtQKA8t94QUEBamtrNePv168funfvHlTjdzqdyMnJQWVlJbKyskJm3HPmzMGE\
CRM04wRC5++dQlt4oAdAFCqOHTuGv/71r3juueeUx0pKStCrVy/NdXKYKikpQUJCQruOsblKSko0\
4Q/Qjj8Qzp8/D6fT6XFcR48eDciYWkr+O/T0ZwnU3683LpcL8+bNw/DhwzFgwAAA0viNRmOj9aPB\
Mv5Dhw4hKysLNTU1iImJwYcffoirr74a+/fvD+pxA0BOTg727duHvXv3Nnou2P/eqWNgBZB0Z9Gi\
RRAEweeXe9A4c+YMxo0bh7vuugszZ84M0MglLRk/UVPmzJmDw4cPIycnJ9BD8Vt6ejr279+PPXv2\
YPbs2bjvvvvw9ddfB3pYTTp9+jTmzp2Ld955B2azOdDDIZ1iBZB055FHHsH999/v85orr7xS+X1x\
cTFuvvlmXH/99Y02d6SkpDTamSd/n5KS0joDdtPc8fuSkpLSaHdtW4+/KV26dEFYWJjHv9dAjaml\
5PGWlpaia9euyuOlpaW45pprAjSqxn73u9/h3//+N3bt2oUrrrhCeTwlJQUOhwPl5eWaalSw/P/C\
aDSiT58+AIDMzEzs3bsXq1atwj333BPU4y4oKEBZWRmGDBmiPOZ0OrFr1y787//+Lz799NOgHj91\
DAyApDuJiYlITEz069ozZ87g5ptvRmZmJl5//XUYDNqieVZWFh599FHU1tYiIiICALBt2zakp6e3\
2fRvc8bflKysLDzzzDMoKytDUlISAGn8cXFxuPrqq1vlPZrLaDQiMzMTubm5mDhxIgBpejI3Nxe/\
+93vAjKmlurVqxdSUlKQm5urBD6bzaZUrAJNFEU89NBD+PDDD7Fjx45GyxkyMzMRERGB3NxcTJo0\
CQBQVFSEU6dOISsrKxBD9snlcsFutwf9uEeNGoVDhw5pHnvggQfQr18/LFy4EGlpaUE9fuogAr0L\
hShY/fDDD2KfPn3EUaNGiT/88IN49uxZ5UtWXl4uJicni/fee694+PBhMScnR4yKihJfeeWVAI68\
wcmTJ8XCwkLxySefFGNiYsTCwkKxsLBQrKioEEVRFOvq6sQBAwaIY8aMEffv3y9u2bJFTExMFBcv\
XhzQcefk5Igmk0l84403xK+//lqcNWuWGB8fr9mtHCwqKiqUv1cA4vPPPy8WFhaKJ0+eFEVRFJct\
WybGx8eLH330kXjw4EHx9ttvF3v16iVWV1cHeOSiOHv2bNFisYg7duzQ/PddVVWlXPOb3/xG7N69\
u7h9+3bxq6++ErOyssSsrKwAjlqyaNEicefOneL3338vHjx4UFy0aJEoCIK4detWURSDd9zeqHcB\
i2LojZ9CDwMgkRevv/66CMDjl9qBAwfE7Oxs0WQyid26dROXLVsWoBE3dt9993kc/2effaZcc+LE\
CfHWW28VIyMjxS5duoiPPPKIWFtbG7hB1/vrX/8qdu/eXTQajeJ1110n5ufnB3pIHn322Wce/47v\
u+8+URSlVjCPP/64mJycLJpMJnHUqFFiUVFRYAddz9t/36+//rpyTXV1tfjb3/5WTEhIEKOiosQ7\
7rhD80NQoDz44INijx49RKPRKCYmJoqjRo1Swp8oBu+4vXEPgKE2fgo9giiKYjsWHImIiIgowLgL\
mIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiI\
dIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJ\
iIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhn\
GACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiI\
iEhn/j+T4Nec091cJAAAAABJRU5ErkJggg==\
"
  frames[1] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAOQpJREFUeJzt3Xl4lPW9///XJGQlzCSQjSUsoo0Lm6YgAaQiKdFaKy2odFGs\
LJUiPQr1CFWx/arFAx43jgUpVvRYRfQUrBUVCgI/NYAiUUBJlbJJmCBKZiCQyTL3749hbjIkbEoy\
y+f5uK65YO65Z/K+9XJ85f1ZbodlWZYAAABgjLhwFwAAAICWRQAEAAAwDAEQAADAMARAAAAAwxAA\
AQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAE\
AAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAA\
AMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAA\
AMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAA\
DEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAw\
DAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMO0CncBwLfh9/tVXl6uNm3ayOFw\
hLscADgly7J08OBBdejQQXFx9GEQHgRARLXy8nLl5eWFuwwAOGO7d+9Wp06dwl0GDEUARFRr06aN\
pMAXqdPpDHM1AHBqXq9XeXl59vcXEA4EQES14LCv0+kkAAKIKkxbQTgx+QAAAMAwBEAAAADDEAAB\
AAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQA\
ADAMARAwwftPS4/2CPwJADAeARAwwTuPSp7dgT8BAMYjAAImGHSH5MoL/AkAMF6rcBcAoAX0HRN4\
AAAgOoAAAADGIQACAAAYhgAIxApW+gIAThMBEIgVrPQFAJwmAiAQK0610pcOIQDgKAIgECv6jpHu\
2Hzi1b6n0yEkJAKAEQiAgAnef1ryHZISUqWaQycOeAwjA4ARCICACVbcL1UfkGqPSEcOSCvvb7rT\
13AYmW4gAMQsNoIGYt37TwfCnyTJklIypFpfIAi+PiVwODhs3HDD6Ed7HOsGsok0AMQUOoBArDja\
sSv9630hz7Xi/tDzan1S3WGVuuslWdLSO5vu8nH7OACIWQ7LsqxwFwF8U16vVy6XSx6PR06nM9zl\
hNejPTRv5TbNK5UmPTBXo7+eFejghXBIkp4t9Wn2+hqNL0jU+ILEQNC7Y3OLlwyYiO8tRAI6gEA0\
azBPrzR7hOaVSkrL0ezZs/XstrZNvMGyw58kzdvoV+mhTLp8AGAYAiAQzRqs2u3z8z9o0gNzA8cr\
tmj24hI9W1oTcvqzpTV2+JOkSWN+rj4Pbwud48fiDwCIeQRAIJodN09v9OjRmtTzkFRfI1l+zV5f\
Y4fA0PDn0KSfDNToP/yl8WeyFQwAxDwCIBCt3n86ENIG3RHSwRvdK0GT+iXaz2evr9EVz1aFdv5+\
MkCju399rMvXsOvH4g9EmOfX7tTAh1bq+bU7w10KEDNYBIKoZvRk6uA2LSkZkqXA+o4r7pWW3SPV\
Hm403Bs0qV+iRvc5GhBTMqS7dhz7LBaDIAINfGil9lQeUcf0FL079Ypwl/OtGf29hYhBBxCIVsFO\
naXAPn9HDtjhT5JG90mUM8kR8hZnkuNY+JMC7wl2/VIyAncLYe4fIsyEy7urY3qKJlzePdylADGD\
AAhEq+C9f4feKyVnBG7zdjT8SYE5f15faIPf67MaLQzRyvsDn5WYFgiSzP1DBGg47PuL/l307tQr\
9Iv+XU563qk+B8AxBEAg2vUdEwiBtUfsQ8cP/zbsBDZcGCIptAvI3D9EiDmrtmlP5RHNWbXtW513\
up8DmIYACMSCdx5VYCy4ia1e+iVq5ejWjRaGhITAlfeHLihhKxiE2cmGfX/z4kZ1n/a6fvPixlMO\
DzN8DDSNRSCIakymPur9p6WV9+vZ9ZWavbZKsvySjlvwoYbh0CHFxWvSpSkafUnK0e6hdWwRCItC\
EMG6T3td9ZYU75C2zbg63OWcMb63EAnoAALRLNipk1RavESz1/tOGP4Ul6DRfRIDnUCHJH+dZq/3\
qfRAqiRLcsQfG/5lOBgR7OpeHRTvCPx5POb8AaeHDiCimvG/SR+3Fcy8kv2a9/4RTeqfotG94o+d\
12Nk4M/Nr0iSnv0kQbNLqjT+xus0/sffa3I/QSBSPL92p+as2qYJl3e3F4Icfyz4vMpXp8ojtRG9\
ZYzx31uICHQA0WzmzJmjXr16yel0yul0qrCwUG+88Yb9enV1tSZOnKh27dopLS1NI0aMUEVFRRgr\
jkLHbQUz/uJ4zf/R0fCXkBro6vUYKY18Wtq9LvAeR7xGX3+t5t/QQeMvSSD8IeIFF3Lcs2SzLrj3\
DTvsNVzcEXwuiTl/wGmgA4hm89prryk+Pl7nnXeeLMvSs88+q1mzZmnjxo266KKLNGHCBL3++uta\
sGCBXC6XbrvtNsXFxendd9897Z/Bb9JHvf+0tOJ+qd4XCIMJSYFNofuOkV4ZI21ZLLXvJR3YcWzT\
6CMHjv7FOrYhNBCBnl+7U/csOTYXNRjwHnz9E1XX+nVN78BQ8Osfl+vqXh30xE8vDlepp4XvLUQC\
AiBaVNu2bTVr1iyNHDlSWVlZeuGFFzRyZGB4cuvWrbrgggtUUlKi/v37n9bn8UV6Gv7QVrLqA93A\
JGdgr79WqVLrdlLVV1Ld4cA+gkPvpRuIiBPs9rVrnagPPtyo1u27q3VSK/22OF/3Ltms4P/AUhLi\
dKTWr/SUBC24Nlt9+vQJZ9knxfcWIgFDwGgR9fX1WrhwoaqqqlRYWKgNGzaotrZWRUVF9jnnn3++\
OnfurJKSkhN+js/nk9frDXkY7XS2a7nox4Hwd9GPAw0/KdAhvGOzVPxAYAg5GP48u9kIGhElOLS7\
5e2/qcOmZ6XPVqvySK3mrNomR4Mb3RypDSx+2vP+mxr0wxt0y9QZYaoYiA4EQDSrTZs2KS0tTUlJ\
Sbr11lu1ePFiXXjhhXK73UpMTFR6enrI+Tk5OXK73Sf8vBkzZsjlctmPvLy8Zr6CCHc6oW3k09IP\
ZgXmAHYfGgh8V9wbeC14N5G+Y1j5i4g04fLuSj+8R9an/5Qk1W9+Q/6yVdrrOSL/ceNXhzatkHfD\
a6qt92vR8wtUWlra8gUDUYIAiGaVn5+v0tJSrVu3ThMmTNDo0aP1ySeffOPPmzZtmjwej/3YvXv3\
Waw2Cp1uaAsGxd3rjgW+4zUMg0CE+EX/Lip9Yry+P3K0Pin3aq/niCrWLpH34xUh5x3atEIHP3zN\
ft6+cLgmvvk128EAJ0AARLNKTEzUueeeq4KCAs2YMUO9e/fW448/rtzcXNXU1KiysjLk/IqKCuXm\
5p7w85KSkuxVxcGH0YKhTTr5UDDdPUS5za0vVurFP7S7fgc/fE2HNgVC4PHhr80l16i2+2BuAQec\
BAEQLcrv98vn86mgoEAJCQlaseLYb/FlZWXatWuXCgsLw1hhlDrVUDDdPUS5gi4ZSus5VG0uucY+\
dvDD1+R+8XeNwl9az6FKSYhTvCPwPgCNtQp3AYhd06ZN01VXXaXOnTvr4MGDeuGFF7Rq1Sq99dZb\
crlcGjNmjCZPnqy2bdvK6XRq0qRJKiwsPO0VwGhg0B3HVvACMeb5tTv12kflkqS0nkMlyQ59Vs1h\
+7xg+JOOLQrZsPNAS5YKRA0CIJrNvn37dNNNN2nv3r1yuVzq1auX3nrrLX3/+9+XJD366KOKi4vT\
iBEj5PP5VFxcrD/96U9hrjpK9R1Ddw8xpeGdPuas2qaG6z3Seg7Voc0rQsKfIzHVDn9B6SkJbAgN\
nAD7ACKqsZ8WEJsGPrRSeyqP2Pf8/fvRDqDUeM5fUMMOoKSIvR0c31uIBMwBBABElOfX7lSVr04O\
SfVWYBi3V0eXpMbhz5GYav+94cIQifl/wMkQAAEAYff82p0a+NBKe+i38kitXCkJ9m3f/j5pkM7z\
bGi04CP3p39stDAkGALX/OvLFr8OIFoQAIFIdTp3+QBiRPCOH8F5fx3TU/Tb4ny9O/UK/aJ/F/3q\
3v9WyWt/tW9m03C4t6nVwYc2rZCvrj4MVwJEBwIgEKm4NRsMEgx9Ey7vrl/072LP3Rv40Eo9+NxS\
/e/TT6m23i9Ljef6SU2HQP+XO1rwCoDoQgAEIhWbN8MgwdD3i/5d7GPBruDS8mS1K/iBpKbDX1Ba\
z6FyXnKN0lMS1KnwGt17c+A9DYeXAQSwChhRjdV0QOxquBWMJN379Guy2nVrdJ5DkiUpIc6h+350\
kXokH9Dm6gzNWbVNBV0y9PrH5aq3ImdVMN9biATsAwgAiEi/6N/F7gg+v3an4jK7qd4K7O8nSZ4j\
tbIke49Av2UdPb+LJh7dRsbtOaJ6S4p3iD0BgQYYAgYARLyH3ypTvRXo9v22OF+l9w3T/cN7qGN6\
inp1dNn7BQYF5xRe3auDOqan6A/X9ggZXgZMRwcQiETvP33s1m7c4QOwuVIS9Iv+Xezh4YIuGdqw\
84D+cG0PSYFFI8GFJAQ+4MQIgEAkargCmAAIwwUXb6SnJOi3xfmSji0QCQ7xzlm1TZLsrWQIf8DJ\
MQQMRCJWAAO24MbQrZNa2d2/Kl+d0lMS7CHeCZd3D9lKBsDJ0QEEIlHfMXT+gKMmXN49ZDVwMBB2\
TE/REz+9OORcOn/A6SEAAgAi2vHz+Y4PhADOHPsAIqqxnxaAhvsFRkMHkO8tRALmAAIAotrDb5Vp\
T+URPfxWWbhLAaIGARAAAMAwBEAAQFT7bXG+Oqan2FvEADg15gAiqjGXBkC04XsLkYAOIAAAgGEI\
gAAAAIYhAAIAABiGAAgAAGAYAiDQDA4sXKjPrhiqAwsXntFrAAC0BAIg0Az2z/uz6srLtX/en8/o\
NQAAWgIBEGgGmePHqVWHDsocP+6MXgMAoCWwDyCiGvtpAYg2fG8hEtABBAAAMAwBEAAAwDAEQAAA\
AMMQAIFvgK1cAADRjAAIfANs5QIAiGYEQEAn7uid6HhTW7nQFQQARAu2gUFUO1vbKXx2xVDVlZer\
VYcOOm/lilMeP9VnZI4fp/3z/qzM8eOUMWrUN64LQOxhGxhEAjqAgJru6G0feZ3qysulVq0adfrK\
Lu2vskv7h3T7MsePU5zLJX9VlfY9+pjqysvlvv8BOoIAgIhDBxBRrbl+kz6wcKHcv/+D/bxhOHTf\
/4BUX28fb6pjKIcjcMCyTqt7CMAcdAARCegAAkcF5/DtmfJbue9/QJ9WV9uvBbt5+x59LBD+HA7F\
uVxKvfhivdq3n93lyxw/ToqPlyxLcU4nt3wDAEQkAiCM1NSCjeDKXu/rr2vRV19peoVbSzyeY2+q\
r5f/8GFJUqv27RXXurX+d/Fi3b1pk/7n97+XJGWMGqXce+9Rqw4dlDZoUEteEgAAp40ACCM1tY1L\
5vhxksOhT6ur9bKnUoqL118PHAgNgbW1kgIdwVc+/VTP7y2XHNIrlZUqLS0N+RmH3nmHrWIAABGJ\
AAgjNbXoI2PUKMU5nbogOVm/aN9B8W3SJKlxCJS0xOPRXw8ckCxJljTKEacuW7cG5g7e/0BgHqDE\
EDAAICKxCARR7WxNpj6wcKH2z/uzUi++WIfeeUf+qiot+eqrQMg76ucZGRruch0Lf8cdlyRHcrKs\
6urAHEGnU9l33M42MABCsAgEkYAAiKjWHPsASrI7eMeHvbT4OB2q99vPG4Y/W3y8HImJso4cYQUw\
gEYIgIgEDAGj2cyYMUN9+/ZVmzZtlJ2dreHDh6usrCzknOrqak2cOFHt2rVTWlqaRowYoYqKihav\
NTgknHrxxarbt88+Ptzl0s8zMuznpwx/klRfL0diIsO/AICIRQBEs1m9erUmTpyotWvXavny5aqt\
rdWwYcNUVVVln3PHHXfotdde08svv6zVq1ervLxcP/nJT1q81oxRo3TeyhU6vHGjVFcX8tpwl0tp\
8aH/qaTFxzUd/hSY95d9x+06b+UKZYwaxS3iAAARhyFgtJgvv/xS2dnZWr16tQYPHiyPx6OsrCy9\
8MILGjlypCRp69atuuCCC1RSUqL+/fuf8jPP5lDKgYULte/Rx+SvqpLq6xXndMrv8TQaBg6yO4AO\
R2Dvv7o6OZKTdX7pxpDzzuR2cgBiH0PAiAR0ANFiPEdX0rZt21aStGHDBtXW1qqoqMg+5/zzz1fn\
zp1VUlLS5Gf4fD55vd6Qx9myf96f5fd41Co7W7n3TW8y/DXsBNqrgy3LDoFthg5t9LlNrTgGACCc\
CIBoEX6/X7fffrsGDhyoHj16SJLcbrcSExOVnp4ecm5OTo7cbneTnzNjxgy5XC77kZeXd9ZqbBjU\
3A882ORq32fyOofMCbRDYG2tVF8v75tvNhrqDQ4vsxoYABApCIBoERMnTtTmzZu18FvOg5s2bZo8\
Ho/92L1791mq8FhQk3TCLWCk0IUhjpQU/bWywT6B9fVs/AwAiHgEQDS72267Tf/4xz/09ttvq1On\
Tvbx3Nxc1dTUqLKyMuT8iooK5ebmNvlZSUlJcjqdIY+zbc1/P9Jk+Ltg66f2NjHBEGj5qgN3DPF6\
tbtvX4Z6AQBRgQCIZmNZlm677TYtXrxYK1euVLdu3UJeLygoUEJCglasOLYwoqysTLt27VJhYWFL\
l2sbPGWybujaRfHpLv08M1PDXS4lHx22Dg4TO1JSAiHQlS7V1+uGvE4a9r/PMdQLAIgKrAJGs/n1\
r3+tF154Qa+++qry8/Pt4y6XSykpKZKkCRMmaOnSpVqwYIGcTqcmTZokSXrvvfdO62ec7TuBZI4f\
Zwe40tJStZ48pckVvMFbvqm+Xp/W1mjIgw8S/ACcFlYBIxLQAUSzmTNnjjwejy6//HK1b9/efrz0\
0kv2OY8++qh++MMfasSIERo8eLByc3P1t7/9rcVr3T/vz6orLw+Zv9enTx9ljh+nOJdL/qqqRos7\
4tLSFOdyhYQ/9vwDAEQDOoCIas3ZAQxqah+/E+3tx55/AE6FDiAiAR1AQCffqqWpffyOPxbs/KVe\
fDELQQAAEY8OIKJapPwmTecPwOmKlO8tmI0OIHAWcLcPAEA0oQOIqMZv0gCiDd9biAR0AAEAAAxD\
AAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwB\
EAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARA\
AAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQCCCLSpbpGGvDNOiskXhLgUAEEMIgEAEm79pvvZW7dX8\
TfPDXQoAIIYQAIEINrbnWLVv3V5je44NdykAgBjisCzLCncRwDfl9Xrlcrnk8XjkdDrDXQ4AnBLf\
W4gEdAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEA\
AAxDAAQAADAMARDNZs2aNbrmmmvUoUMHORwOLVmyJOR1y7I0ffp0tW/fXikpKSoqKtJnn30WnmIB\
ADAIARDNpqqqSr1799aTTz7Z5OszZ87UE088oblz52rdunVq3bq1iouLVV1d3cKVAgBgllbhLgCx\
66qrrtJVV13V5GuWZemxxx7TPffco2uvvVaS9NxzzyknJ0dLlizRqFGjWrJUAACMQgcQYbF9+3a5\
3W4VFRXZx1wuly699FKVlJSc8H0+n09erzfkAQAAzgwBEGHhdrslSTk5OSHHc3Jy7NeaMmPGDLlc\
LvuRl5fXrHUCABCLCICIKtOmTZPH47Efu3fvDndJAABEHQIgwiI3N1eSVFFREXK8oqLCfq0pSUlJ\
cjqdIQ8AAHBmCIAIi27duik3N1crVqywj3m9Xq1bt06FhYVhrAwAgNjHKmA0m0OHDunzzz+3n2/f\
vl2lpaVq27atOnfurNtvv10PPPCAzjvvPHXr1k333nuvOnTooOHDh4evaAA4gY+WL9X6Ja+o3/CR\
6v39H4S7HOBbIQCi2XzwwQcaMmSI/Xzy5MmSpNGjR2vBggX6z//8T1VVVWn8+PGqrKzUoEGD9Oab\
byo5OTlcJQPACa1f8oq8+/dp/ZJXCICIeg7LsqxwFwF8U16vVy6XSx6Ph/mAZ2hR2SLN3zRfY3uO\
1fX514e7HCDina0OIN9biAQEQEQ1vkhP7FQBb9grw7S3aq/at26vZSOXhaFCwEx8byESsAgEiFHz\
N83X3qq9euLDJzTwxYEa9OIgLSpbZL8+tudYtW/dXmN7jg1536KyRRr2yrCQc4FY8dHypfrzxFv0\
0fKlzXI+EC0IgECMujj7Yvl2+eSr98lb45WnxqP5m+Y3eW5paan992BwPNG5QDRrOI/veE2FvZOd\
D0QzFoEAMeq1v76m3ct2y/d9n5wDnUqIS1Db5Lbq+WxPSVJyfLKq66t1z2P3yL3MrVGjR2ne9Hka\
23OsPXQMxJp+w0fa8/ik0Hl9wbD3z6fnaNVzT6tVYoK69r7Efh8QS5gDiKjGXJrGFpUt0qN/f1Tb\
n96uw7WHVeevU9uitsoYlNHo3Oq11Sp/q1x+y694R7ze+ds76tOnT8sXDbSw0tJS9enTR3+eeIu8\
+/fJmZmtfsNHasVf5sry++3zPIrX/3vp1bP6s/neQiSgAwjEmPmb5utQ9iElXJagun/WyZKlr/75\
lSSFhMAD7xyQd6VXDjkkSe2L2xP+YIR58+Zp3rx5mjRpUkhHMLiy952Fz6muplbr/71T/1/Zv3Vg\
1Aj1aueyu4DsBYhYQAcQUY3fpBtbVLZID6x9QJYsHXjngB3+JKldUTtlDMqwjzvkkCVLucNy9V+T\
/4vtYBDTPlq+VP83/ym9WLJBtdXVSkhOVv8unfTdbh0lSa0SEuTKzlXFvz/X+zu+0Luf7bDfe913\
e6p7p05KTEmRd/8+OeLiNPSWW79RCOR7C5GARSBAjAiu3pUkZ2LgfyoZgzLUrqidfc5X//xK2/9r\
ux0KLVlqV9ROaQPStKFiQ8sXDbSg9UtekUv1+m6HLNXX1an60CGt2rJVJWXbVOfzqfrQoSbD38Dz\
uqpjhktyWOo3fKQccXGy/H4WhiCqEQCBGNFw9e5vLvmN2rduL4ccjUJg/ZF6++/BjqAkLd2+VHet\
uavF6wZaSof88+WIi9PVQ76nQd/pZh9/97Mden/HF5LUZPi7tHtXyeFQ196XqPf3f6Cht9xqzxkE\
ohVzAIEY0XD1bnAo94G1D0gKdAIr360MCX/xKfGNFoYs3b5UBTkFDAUjJpWXbZXl98uzz63+3zlH\
lmXZYe/dz3bogx1fyFdbZ58/8Lyu6tu1k/z1dfb7Jan393/A/D9EPTqAQJRrOPS7bOQyXZ9/ve5a\
c5fuX3u/LAWm+B5450BI+JMCncAD7xxo9HnzN81nM2jEpH7DR8qZmS1ZDtX5fOrbtZMGntfVfr2p\
8BfUKilJNUeO2HsEskE0oh2LQBDVTJ9MvahskR5c96D8lt++q8f8TfPlrnKHhL+GC0HiU+JPOAws\
BfYHTIpPkqfGw23iEJM+Wr5U/5z/J/v5nFVrQ8JfUkIrTbi8f9NvdjhUNGaC3nnxf1VddVDJrdto\
4l9ePKOfb/r3FiIDHUAgis3fNF9+y684R5wd/vZW7T1h+GtX1E7d7urWaGFIw05gdX21PDUeuRJd\
bAaNmNRw+Pb944Z9pUAnMDgnsBHLCiz+cBztnTjooSA6MQcQiGJNzfsLdgRPtAWMdGw/wODrTe0T\
6Kv32beDY04gYkHwrh8d8s+X1HjBR1JCKzsMBo83HAaWJDkcjfYDBKIRQ8CIagylNLaobJHuWXSP\
dv9lt30ssyhT6YPSQ85zyCHPux7t/+d+WZYlS5Y639JZiZ0TQ85jGBixInjXD0dcnNb/e1ej1b59\
u3ZqchVw3255Sk5NkxyWBo266VsvAOF7C5GAIWAgxlyff70euP4BZV6eKSnQ+Ts+/F3U7iK1SWwj\
50Cn2g5tqzhHnNpe3laJnROVHJ+sOEfgqyE4tAzEguAikC/iU/Tetl328YYLPhouDHHExWnt9i90\
OO88DfrpjUpMTg1H2UCzYAgYiFFth7RVUrckpXRJ0UXtLtIXB7+Qt8YrS5a+rv7avgVc+qB0tTun\
nfwd/PbcwbSENDnk0G8u+Q3Dv4gZvb//A1lZHfTU2LHK7nqO9u34twZ079xomDf4fNOBKqU4XXr1\
7TWq3bVNLtVr/ZJX2AIGMYEACMSQRWWLNH/TfB2uPSy/5Vfrrq1196V32yEu+Hqwq/fEh0/IkqX/\
+Ml/SAosKqmqrZK3xqv2rdsT/hBz+vTpo/Hjx+vxh2fpsvxzdEmn3MYnORy68ec/0yuvvqb1u936\
j9/eqUu7dWLOH2IKcwAR1ZhLE2rYK8O0t2qvnIlOtU5oHbI45HQ1DIkEQMSij5Yv1XP//V/q4GoT\
crxVYpLkkOpqatQqMVF1Pp88itf/e+nVs/rz+d5CJKADCMSQsT3H6vEPH5dDjm8c4K7Pv57gh5j2\
zsLnjoU/h0OyrMCfDqnO55MUCIHOzGwV0fFDjGIRCBBDrs+/Xq0TWstT47G3cAFwHCsw/zW5dRsV\
jZkgZ2a23fELOn/AZRr35F+Y74eYRQAEYszYnmPtu4J8U9wKDrFs0E9vlDMzW137XGzP62vV6uj2\
Rw6Hisb+Wlf/5j/DWyTQzJgDiKjGXJrmEZxLyB6AiGXBfQGdmdnqN3ykHQabu+vH9xYiAR1AAI2c\
jS4iEOmC+wIGQx9DvjAJHUBENX6TBhBt+N5CJKADCAAAYBgCIAAAgGEIgAAAAIYhAAIAABiGAAgA\
AGAYAiAAAIBhCIAAAACGIQACAAAYhgAIAABgGAIgAACAYQiAAAAAhiEAAgAAGIYACAAAYBgCIAAA\
gGEIgAAAAIYhAAIAABiGAIiwe/LJJ9W1a1clJyfr0ksv1fr168NdEgAAMY0AiLB66aWXNHnyZN13\
33368MMP1bt3bxUXF2vfvn3hLg0AgJhFAERYPfLIIxo3bpx++ctf6sILL9TcuXOVmpqqv/zlL+Eu\
DQCAmEUARNjU1NRow4YNKioqso/FxcWpqKhIJSUlYawMAIDY1ircBcBc+/fvV319vXJyckKO5+Tk\
aOvWrU2+x+fzyefz2c+9Xm+z1ggAQCyiA4ioMmPGDLlcLvuRl5cX7pIAAIg6BECETWZmpuLj41VR\
URFyvKKiQrm5uU2+Z9q0afJ4PPZj9+7dLVEqAAAxhQCIsElMTFRBQYFWrFhhH/P7/VqxYoUKCwub\
fE9SUpKcTmfIAwAAnBnmACKsJk+erNGjR+u73/2u+vXrp8cee0xVVVX65S9/Ge7SAACIWQRAhNUN\
N9ygL7/8UtOnT5fb7VafPn305ptvNloYAgAAzh6HZVlWuIsAvimv1yuXyyWPx8NwMICowPcWIgFz\
AAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMA\
BAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQ\
AADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAA\
AADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEA\
AAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwBEs3nwwQc1YMAApaamKj09vclzdu3apauvvlqp\
qanKzs7WnXfeqbq6upYtFAAAw7QKdwGIXTU1NbruuutUWFiop59+utHr9fX1uvrqq5Wbm6v33ntP\
e/fu1U033aSEhAT98Y9/DEPFAACYwWFZlhXuIhDbFixYoNtvv12VlZUhx9944w398Ic/VHl5uXJy\
ciRJc+fO1V133aUvv/xSiYmJp/xsr9crl8slj8cjp9PZHOUDwFnF9xYiAUPACJuSkhL17NnTDn+S\
VFxcLK/Xqy1btoSxMgAAYhtDwAgbt9sdEv4k2c/dbneT7/H5fPL5fPZzr9fbfAUCABCj6ADijEyd\
OlUOh+Okj61btzbbz58xY4ZcLpf9yMvLa7afBQBArKIDiDMyZcoU3XzzzSc955xzzjmtz8rNzdX6\
9etDjlVUVNivNWXatGmaPHmy/dzr9RICAQA4QwRAnJGsrCxlZWWdlc8qLCzUgw8+qH379ik7O1uS\
tHz5cjmdTl144YVNvicpKUlJSUln5ecDAGAqAiCaza5du/T1119r165dqq+vV2lpqSTp3HPPVVpa\
moYNG6YLL7xQN954o2bOnCm326177rlHEydOJOQBANCM2AYGzebmm2/Ws88+2+j422+/rcsvv1yS\
tHPnTk2YMEGrVq1S69atNXr0aD300ENq1er0fjdhOwUA0YbvLUQCAiCiGl+kAKIN31uIBKwCBgAA\
MAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADA\
MARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADD\
EAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxD\
AAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwB\
EAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEA0ix07dmjMmDHq1q2bUlJS1L17d913332q\
qakJOe/jjz/WZZddpuTkZOXl5WnmzJlhqhgAAHO0CncBiE1bt26V3+/XU089pXPPPVebN2/WuHHj\
VFVVpYcffliS5PV6NWzYMBUVFWnu3LnatGmTbrnlFqWnp2v8+PFhvgIAAGKXw7IsK9xFwAyzZs3S\
nDlz9O9//1uSNGfOHN19991yu91KTEyUJE2dOlVLlizR1q1bT+szvV6vXC6XPB6PnE5ns9UOAGcL\
31uIBAwBo8V4PB61bdvWfl5SUqLBgwfb4U+SiouLVVZWpgMHDjT5GT6fT16vN+QBAADODAEQLeLz\
zz/X7Nmz9atf/co+5na7lZOTE3Je8Lnb7W7yc2bMmCGXy2U/8vLymq9oAABiFAEQZ2Tq1KlyOBwn\
fRw/fLtnzx5deeWVuu666zRu3Lhv9fOnTZsmj8djP3bv3v2tPg8AABOxCARnZMqUKbr55ptPes45\
55xj/728vFxDhgzRgAEDNG/evJDzcnNzVVFREXIs+Dw3N7fJz05KSlJSUtI3qBwAAAQRAHFGsrKy\
lJWVdVrn7tmzR0OGDFFBQYGeeeYZxcWFNpwLCwt19913q7a2VgkJCZKk5cuXKz8/XxkZGWe9dgAA\
EMAQMJrFnj17dPnll6tz5856+OGH9eWXX8rtdofM7fvZz36mxMREjRkzRlu2bNFLL72kxx9/XJMn\
Tw5j5QAAxD46gGgWy5cv1+eff67PP/9cnTp1CnktuPOQy+XSsmXLNHHiRBUUFCgzM1PTp09nD0AA\
AJoZ+wAiqrGfFoBow/cWIgFDwAAAAIYhAAIAABiGAAgAAGAYAiAAAIBhCIAAAACGIQACAAAYhgAI\
AABgGAIgAACAYQiAAAAAhiEAAgBw1OY1e/Tc797V5jV7wl0K0KwIgAAAHPXhmzt08GufPnxzR7hL\
AZoVARAAAAW6fzXV9UpKbaVLruza6DU6g4glBEAAABTo/vkO1ykxOV6SQgIfnUHEGgIgAMA4TXX0\
Lrmyq9q0TdIlV3bV2iXbdPBrn9Yu2dbotRO9H4gmrcJdAAAALS3Y0Vv9YpnWLtmm/sO7q8fgjuox\
uKMk2cEvqOFrDd//4Zs7Qo4D0YIOIAAgpp2o2yeHJEvyHa5rNLTb+aJ2kkOqr/Vr2dNbmnx/Umor\
1VTX0wVEVCIAAgBiWlPz93oM7qiklFb6Yv/nkkNKbpOoP/16pZY9vUWStGvLV5Il1dX69fmGCn36\
ry2N3p+YHN9keASiAQEQABDTjp+/F7Q7rkQL331En+xfrS93HpTllz57v0Kb1+xRra/ePm979Vot\
fPcRbat5J6SbeKLPBaKBw7IsK9xFAN+U1+uVy+WSx+OR0+kMdzkAosDmNXu0+Nnl+t8Vs+Q7UifL\
L32vx3D1zy+WJLVKiFNdrV+StPZfb+lT7wpJ0pFDtfpRr4nq1PZctWmbpJv+OPAb/Xy+txAJ6AAC\
AIzy4Zs71Dahsy7t9kNZgZyn1ZuXaG3ZW5J0LPyVvaX3/vV3fbnroPbtPKjvdrhKndqeK0ec6Poh\
6hEAAQBGueTKrnLESf3zi/W9HsPt4w1D4Nqyt7R68xLV+vyyrECHsN93hqlN2yQNHpXPyl9EPbaB\
AQAYYfOaPfb2LucW5Mi9rVLXDBspOaTVm5ZICoTA9f9apiM1h+33BYeHs7q00fXT+oajdOCsowMI\
ADBC8E4fvsN1+nxDhXK7p+vLXQfV/zuhncCmwp8kpWensvkzYgYBEABghODefXIosOL3gwrp6DLI\
/vnFSklMDTk/JTHVDn9SYIVw8O4gBEFEOwIgAMAIPQZ31NhHBut7P81Xm7ZJinM47NfWlr0V0vmT\
Ap3A4JzAhmqr6+27iBACEa0IgACAmNVw377g3yUFtnA5mv+CCz6CGnYCGy4MCfIHd0+zxCbQiFoE\
QABAzGp4F5Dj7wji91uNwt/3egzXb6757xOuDpak876bo6TUVkpKbcV2MIharAIGAMSsS67sqg/f\
3KFLruyq8s8qdaiyQsltEvXc797VJ/tXa82WJUpIilOtzx+y4CP4ZzAcBv+8ZthIDRtzkaRAdzEY\
JtkWBtGGDiAAIGb1GNxRN/1xoHoM7ij3tkpZfmn/7oP69F9btPSdl5TVuY389VZI+Avqn1+sIb1+\
bD9/Z+uriss+YA8pN3WPYSBaEAABAEYI3rv33IIcXfCdi3TTz38pSRr7y1s14IIrG7/BIV3W+wf6\
Xo/hcjikm37+Sx3e1toOfdwLGNGMewEjqnFPTQDfRmlpqfr06aP5k9fId7hOkhQX55DfbykptZX6\
D++uD9/codTuVRo5Zpjd+bvkyq7feNiX7y1EAuYAAgCM1adPn9ADDql7Qbbc2yrtkNcw6B3/HIhW\
BEAAgJEadvP6D++uNQvLZPkl97bKwDYxJzmfEIhoxxxAAICRGi7i6DG4owaPyj/pnD4WfSCW0AEE\
ABip4RYx0qmHd48/H4hmLAJBVGMyNYBow/cWIgFDwAAAAIYhAAIAIl7De/oC+PYIgACAiMcCDODs\
IgACACIed90Azi5WAQMAIh4bMANnFx1ANJsf/ehH6ty5s5KTk9W+fXvdeOONKi8vDznn448/1mWX\
Xabk5GTl5eVp5syZYaoWAABzEADRbIYMGaJFixaprKxM//d//6dt27Zp5MiR9uter1fDhg1Tly5d\
tGHDBs2aNUu///3vNW/evDBWDQBA7GMfQLSYv//97xo+fLh8Pp8SEhI0Z84c3X333XK73UpMTJQk\
TZ06VUuWLNHWrVtP6zPZTwtAtOF7C5GADiBaxNdff62//vWvGjBggBISEiRJJSUlGjx4sB3+JKm4\
uFhlZWU6cOBAk5/j8/nk9XpDHgAA4MwQANGs7rrrLrVu3Vrt2rXTrl279Oqrr9qvud1u5eTkhJwf\
fO52u5v8vBkzZsjlctmPvLy85iseAIAYRQDEGZk6daocDsdJHw2Hb++8805t3LhRy5YtU3x8vG66\
6SZ9m1kH06ZNk8fjsR+7d+8+G5cFAIBR2AYGZ2TKlCm6+eabT3rOOeecY/89MzNTmZmZ+s53vqML\
LrhAeXl5Wrt2rQoLC5Wbm6uKioqQ9waf5+bmNvnZSUlJSkpK+nYXAQCA4QiAOCNZWVnKysr6Ru/1\
+/2SAvP4JKmwsFB33323amtr7XmBy5cvV35+vjIyMs5OwQAAoBGGgNEs1q1bp//5n/9RaWmpdu7c\
qZUrV+qnP/2punfvrsLCQknSz372MyUmJmrMmDHasmWLXnrpJT3++OOaPHlymKsHACC2EQDRLFJT\
U/W3v/1NQ4cOVX5+vsaMGaNevXpp9erV9hCuy+XSsmXLtH37dhUUFGjKlCmaPn26xo8fH+bqAQCI\
bewDiKjGfloAog3fW4gEdAABAAAMQwAEAAAwDKuAEdWCMxi4IwiAaBH8vmIGFsKJAIiodvDgQUni\
jiAAos7BgwflcrnCXQYMxSIQRDW/36/y8nK1adNGDofjlOd7vV7l5eVp9+7dMTH5muuJbLF2PVLs\
XVM4rseyLB08eFAdOnRQXBwzsRAedAAR1eLi4tSpU6czfp/T6YyJ/3kFcT2RLdauR4q9a2rp66Hz\
h3DjVw8AAADDEAABAAAMQwCEUZKSknTffffZdyOJdlxPZIu165Fi75pi7XqA08UiEAAAAMPQAQQA\
ADAMARAAAMAwBEAAAADDEAABAAAMQwCEEXbs2KExY8aoW7duSklJUffu3XXfffeppqYm5LyPP/5Y\
l112mZKTk5WXl6eZM2eGqeJTe/DBBzVgwAClpqYqPT29yXN27dqlq6++WqmpqcrOztadd96purq6\
li30DDz55JPq2rWrkpOTdemll2r9+vXhLum0rFmzRtdcc406dOggh8OhJUuWhLxuWZamT5+u9u3b\
KyUlRUVFRfrss8/CU+xpmDFjhvr27as2bdooOztbw4cPV1lZWcg51dXVmjhxotq1a6e0tDSNGDFC\
FRUVYar45ObMmaNevXrZmz0XFhbqjTfesF+PpmsBzhYCIIywdetW+f1+PfXUU9qyZYseffRRzZ07\
V7/73e/sc7xer4YNG6YuXbpow4YNmjVrln7/+99r3rx5Yaz8xGpqanTddddpwoQJTb5eX1+vq6++\
WjU1NXrvvff07LPPasGCBZo+fXoLV3p6XnrpJU2ePFn33XefPvzwQ/Xu3VvFxcXat29fuEs7paqq\
KvXu3VtPPvlkk6/PnDlTTzzxhObOnat169apdevWKi4uVnV1dQtXenpWr16tiRMnau3atVq+fLlq\
a2s1bNgwVVVV2efccccdeu211/Tyyy9r9erVKi8v109+8pMwVn1inTp10kMPPaQNGzbogw8+0BVX\
XKFrr71WW7ZskRRd1wKcNRZgqJkzZ1rdunWzn//pT3+yMjIyLJ/PZx+76667rPz8/HCUd9qeeeYZ\
y+VyNTq+dOlSKy4uznK73faxOXPmWE6nM+QaI0W/fv2siRMn2s/r6+utDh06WDNmzAhjVWdOkrV4\
8WL7ud/vt3Jzc61Zs2bZxyorK62kpCTrxRdfDEOFZ27fvn2WJGv16tWWZQXqT0hIsF5++WX7nE8/\
/dSSZJWUlISrzDOSkZFhzZ8/PyauBfgm6ADCWB6PR23btrWfl5SUaPDgwUpMTLSPFRcXq6ysTAcO\
HAhHid9KSUmJevbsqZycHPtYcXGxvF6v3fmIFDU1NdqwYYOKiorsY3FxcSoqKlJJSUkYK/v2tm/f\
LrfbHXJtLpdLl156adRcm8fjkST7v5cNGzaotrY25JrOP/98de7cOeKvqb6+XgsXLlRVVZUKCwuj\
+lqAb4MACCN9/vnnmj17tn71q1/Zx9xud0hYkmQ/d7vdLVrf2RBN17N//37V19c3WW+k1XqmgvVH\
67X5/X7dfvvtGjhwoHr06CEpcE2JiYmN5p5G8jVt2rRJaWlpSkpK0q233qrFixfrwgsvjMprAc4G\
AiCi2tSpU+VwOE762Lp1a8h79uzZoyuvvFLXXXedxo0bF6bKm/ZNrgdoThMnTtTmzZu1cOHCcJfy\
reTn56u0tFTr1q3ThAkTNHr0aH3yySfhLgsIm1bhLgD4NqZMmaKbb775pOecc8459t/Ly8s1ZMgQ\
DRgwoNHijtzc3EYr/4LPc3Nzz07Bp3Cm13Myubm5jVbRtvT1nK7MzEzFx8c3+c8/0mo9U8H6Kyoq\
1L59e/t4RUWF+vTpE6aqTs9tt92mf/zjH1qzZo06depkH8/NzVVNTY0qKytDOmeR/O8rMTFR5557\
riSpoKBA77//vh5//HHdcMMNUXctwNlAAERUy8rKUlZW1mmdu2fPHg0ZMkQFBQV65plnFBcX2gAv\
LCzU3XffrdraWiUkJEiSli9frvz8fGVkZJz12ptyJtdzKoWFhXrwwQe1b98+ZWdnSwpcj9Pp1IUX\
XnhWfsbZkpiYqIKCAq1YsULDhw+XFBh6XLFihW677bbwFvctdevWTbm5uVqxYoUd+Lxer92JikSW\
ZWnSpElavHixVq1apW7duoW8XlBQoISEBK1YsUIjRoyQJJWVlWnXrl0qLCwMR8lnzO/3y+fzxcS1\
AN9IuFehAC3hiy++sM4991xr6NCh1hdffGHt3bvXfgRVVlZaOTk51o033mht3rzZWrhwoZWammo9\
9dRTYaz8xHbu3Glt3LjR+sMf/mClpaVZGzdutDZu3GgdPHjQsizLqqurs3r06GENGzbMKi0ttd58\
800rKyvLmjZtWpgrb9rChQutpKQka8GCBdYnn3xijR8/3kpPTw9ZxRypDh48aP/zl2Q98sgj1saN\
G62dO3dalmVZDz30kJWenm69+uqr1scff2xde+21Vrdu3awjR46EufKmTZgwwXK5XNaqVatC/ls5\
fPiwfc6tt95qde7c2Vq5cqX1wQcfWIWFhVZhYWEYqz6xqVOnWqtXr7a2b99uffzxx9bUqVMth8Nh\
LVu2zLKs6LoW4GwhAMIIzzzzjCWpyUdDH330kTVo0CArKSnJ6tixo/XQQw+FqeJTGz16dJPX8/bb\
b9vn7Nixw7rqqquslJQUKzMz05oyZYpVW1sbvqJPYfbs2Vbnzp2txMREq1+/ftbatWvDXdJpefvt\
t5v8dzF69GjLsgJbwdx7771WTk6OlZSUZA0dOtQqKysLb9EncaL/Vp555hn7nCNHjli//vWvrYyM\
DCs1NdX68Y9/HPILVSS55ZZbrC5duliJiYlWVlaWNXToUDv8WVZ0XQtwtjgsy7JasOEIAACAMGMV\
MAAAgGEIgAAAAIYhAAIAABiGAAgAAGAYAiAAAIBhCIAAAACGIQACAAAYhgAIAABgGAIgAACAYQiA\
AAAAhiEAAgAAGIYACAAAYBgCIAAAgGEIgAAAAIYhAAIAABiGAAgAAGAYAiAAAIBhCIAAAACGIQAC\
AAAYhgAIAABgGAIgAACAYQiAAAAAhiEAAgAAGIYACAAAYBgCIAAAgGEIgAAAAIYhAAIAABiGAAgA\
AGAYAiAAAIBhCIAAAACGIQACAAAY5v8Hf0/s1WeYjUQAAAAASUVORK5CYII=\
"
  frames[2] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAJFNJREFUeJzt3X2QXXWd7/tPR9JNnrohENLkJtFAe4AcAauiQKtjKWbooYgl\
0+A4M3U0KOoMBqogXGdIycP5Q41Fe1C0EOZeZ8C5VTwM5wasTqltKmKoM0bUeFMCmhz7DJpcQjdh\
MN2hNZ2Y7PsHN3to6CRNSPfO7t/rVbWr2Wuv3nxXpVi8s/ZaazdUKpVKAAAoxpRaDwAAwMQSgAAA\
hRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIUR\
gAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAA\
AIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACF\
EYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGA\
AACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhTmh1gPA0Tpw4EB27NiR\
WbNmpaGhodbjAIxZpVLJ7t27M2/evEyZ4lgME08AUrd27NiRBQsW1HoMgKO2ffv2zJ8/v9ZjUCAB\
SN2aNWtWkpd3oM3NzTWeBmDsBgcHs2DBgup+DCaaAKRuHfzYt7m5WQACdcnpK9SKEw8AAAojAAEA\
CiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAKGO9Pb2HtP1ACiTAIQ60d3dna6urvT09Bx2vZ6e\
nnR1daW7u3uCJgOg3ghAqAO9vb1Zu3ZtkmTNmjWHjMCenp6sWbMmSbJ27VpHAgEYlQCEOtDW1pbO\
zs7q89Ei8JXxlySdnZ1pa2ubsBkBqB8CEOpER0fHISNwtPjr6OiY8BkBqA8NlUqlUush4GgMDg6m\
paUlAwMDaW5urvU4E2ZE7O3ckhkvPp2h2f85mXN2EvEH9aDU/RfHjxNqPQDw+hyMuzX/9a+SvS9l\
KEl2b0zmnC3+ABgTHwFDHero6MiMl9OvasaMGeIPgDERgFCHenp6MrR35NkbQ0NDR7xFDAAkAhDq\
zqsv+JjR2FD958PdIgYADhKAUEdGxN/sM9K5uCl33Phf0vnF/7jpswgE4EhcBAJ1oqenJ2v+4YvJ\
c08mp5+bzv/9zuo5fwfP/DsYhwd/OicQgNE4Agh1oLe39+Woe+7JZO9L6Zzz29fE3Wj3CfRNIACM\
RgBCHWhra8uyZctePvL3jnnp+OQto673yghctmyZbwIBYFRuBE3dKvFGqr29vWOKurGuB9RGifsv\
ji+OAHLM3X333TnvvPPS3Nyc5ubmtLe357vf/W719T179mTFihU55ZRTMnPmzFxxxRXp7++v4cT1\
Y6xRJ/4AOBwByDE3f/78fOlLX8qmTZvys5/9LBdffHE+9KEP5emnn06S3HDDDenu7s7DDz+cDRs2\
ZMeOHSPOXQMAxpePgJkQs2fPTldXV6688srMmTMn999/f6688sokyZYtW3LOOedk48aNueiii8b8\
nj5CAeqV/Re15ggg42r//v158MEHMzQ0lPb29mzatCn79u3L0qVLq+ucffbZWbhwYTZu3FjDSYHJ\
YKxXvrtCntIJQMbFk08+mZkzZ6apqSl/+7d/m0ceeSSLFy9OX19fGhsbc9JJJ41Yf+7cuenr6zvs\
ew4PD2dwcHDEY9L66T8mX3nbyz+BMenu7k5XV9cRb4Te09OTrq6udHd3H3Y9mMwEIOPirLPOyubN\
m/PEE0/kmmuuyfLly/PLX/7yDb3n6tWr09LSUn0sWLDgGE17HPofX0kGtr/8Ezii3t7erF27Nsnh\
vw3nld+ms3btWkcCKZYAZFw0Njamra0tS5YsyerVq3P++efnzjvvTGtra/bu3Ztdu3aNWL+/vz+t\
ra2Hfc9Vq1ZlYGCg+ti+ffs4bkGNveeGpGXByz+BI2pra3vNjdBfHYGv/h7tzs5OV8xTLF8Fx4Q4\
cOBAhoeHs2TJkkydOjXr16/PFVdckSTZunVrtm3blvb29sO+R1NTU5qamiZi3Np759UvP4AxO/jt\
OKN9JeJo8eerEimZAOSYW7VqVS699NIsXLgwu3fvzv33358f/vCH6enpSUtLS66++uqsXLkys2fP\
TnNzc6677rq0t7e/riuAAUbz6ghcfuvX8/ub705l33DefMr0vLvtVPEHEYCMg+effz4f+9jH8txz\
z6WlpSXnnXdeenp68qd/+qdJkq985SuZMmVKrrjiigwPD6ejoyPf+MY3ajw1MFm8MgKHhvcn2Z8k\
+e2//z7/7e/EHyTuA0gdcx8t4HBWrlyZ//MHv6o+b5jalMGfPlq7gV7B/otacxEIAJNOT09PhoaG\
Riyr7Bs+4i1ioBQCEIBJ5dUXfDRMffniscYTGg57ixgoiXMAAZg0Xh1/11z1V/nXPfPz7hP/3wz8\
6l+TjLw6GEolAAGYFI50q5eenrmj3iIGSuQjYADqXm9v7xHv89fR0fGam0X7JhBKJQABqHttbW1Z\
tmxZksPf5PmVEbhs2TLfBEKx3AaGuuU2CsCr9fb2jinqxrreeLH/otYcAQRg0hhr1DnyR+kEIABA\
YQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEE\
IABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAA\
QGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIJNeb2/vMV0P\
AOqdAGRS6+7uTldXV3p6eg67Xk9PT7q6utLd3T1BkwFA7QhAJq3e3t6sXbs2SbJmzZpDRmBPT0/W\
rFmTJFm7dq0jgQBMegKQSautrS2dnZ3V56+MwN89+GC2XnhRvnnW2Xmgq6u6TmdnZ9ra2iZ8VgCY\
SCfUegAYTx0dHUlSPcL3QFdXtn3yk3nPjJn5H0MvZd3ulzLlpd1pOvPMdHZ2VtcHgMlMADLpvTIC\
9/zqV1k39Pv869BQfn+gkiQ58ZxzxB8ARfERMMfc6tWr8853vjOzZs3Kaaedlssvvzxbt24dsc6e\
PXuyYsWKnHLKKZk5c2auuOKK9Pf3j9tMHR0d6ezszInnnJMk1fhLkr/67GfFHwBFEYAccxs2bMiK\
FSvy4x//OOvWrcu+fftyySWXZGhoqLrODTfckO7u7jz88MPZsGFDduzYMeJ8vfHQ0dGR2eedN2LZ\
9CkN4g+A4jRUKpXKkVeDo7dz586cdtpp2bBhQ9773vdmYGAgc+bMyf33358rr7wySbJly5acc845\
2bhxYy666KIxve/g4GBaWloyMDCQ5ubmI67/yqt9h//X/8qeX/0qJ55zjiOAwIR7vfsvONacA8i4\
GxgYSJLMnj07SbJp06bs27cvS5cura5z9tlnZ+HChYcNwOHh4QwPD1efDw4OjnmGV8Zfksw+77wM\
nXlmkv+4QEQEAlAKHwEzrg4cOJDrr78+7373u/O2t70tSdLX15fGxsacdNJJI9adO3du+vr6Dvle\
q1evTktLS/WxYMGCMc3w6vjr7OzMHXfccchbxADAZCcAGVcrVqzIU089lQcffPANv9eqVasyMDBQ\
fWzfvv2IvzNa/B080nfwwpCDRCAApfARMOPm2muvzdq1a/P4449n/vz51eWtra3Zu3dvdu3aNeIo\
YH9/f1pbWw/5fk1NTWlqahrzv7+3t/eQ8XfQq+8TuGbNmpx55pluBg3ApOYIIMdcpVLJtddem0ce\
eSQ/+MEPsmjRohGvL1myJFOnTs369eury7Zu3Zpt27alvb39mM3R1taWZcuWJRk9/g565ZHAZcuW\
iT8AJj1XAXPMfeYzn8n999+fb3/72znrrLOqy1taWjJt2rQkyTXXXJPvfOc7ue+++9Lc3Jzrrrsu\
SfKjH/1ozP+esV5F19vbO6aoG+t6AG+Uq4CpNQHIMdfQ0DDq8nvvvTdXXXVVkpdvBH3jjTfmgQce\
yPDwcDo6OvKNb3zjsB8Bv5odKFCv7L+oNQFI3bIDBeqV/Re15hxAAIDCCEAAgMIIQACAwghAAIDC\
CEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghA\
AIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACA\
wghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMII\
QACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEDGxeOPP54PfvCDmTdvXhoa\
GvLoo4+OeL1SqeTWW2/N6aefnmnTpmXp0qX59a9/XZthAaAwApBxMTQ0lPPPPz933XXXqK/ffvvt\
+drXvpZ77rknTzzxRGbMmJGOjo7s2bNngicFgPKcUOsBmJwuvfTSXHrppaO+VqlU8tWvfjU333xz\
PvShDyVJ/vmf/zlz587No48+mr/8y7+cyFEBoDiOADLhnnnmmfT19WXp0qXVZS0tLbnwwguzcePG\
Gk4GAGVwBJAJ19fXlySZO3fuiOVz586tvjaa4eHhDA8PV58PDg6Oz4AAMMk5AkjdWL16dVpaWqqP\
BQsW1HqkCfEvW/8ll/z3S/IvW/+l1qMAMEkIQCZca2trkqS/v3/E8v7+/upro1m1alUGBgaqj+3b\
t4/rnMeLbz75zTw39Fy++eQ3az0KAJOEAGTCLVq0KK2trVm/fn112eDgYJ544om0t7cf8veamprS\
3Nw84lGCT577yZw+4/R88txP1noUACYJ5wAyLl566aX09vZWnz/zzDPZvHlzZs+enYULF+b666/P\
5z//+bz1rW/NokWLcsstt2TevHm5/PLLazf0ceovzvqL/MVZf1HrMQCYRAQg4+JnP/tZ3v/+91ef\
r1y5MkmyfPny3Hffffm7v/u7DA0N5dOf/nR27dqV97znPfne976XE088sVYjA0AxGiqVSqXWQ8DR\
GBwcTEtLSwYGBor5OBiYHOy/qDXnAAIAFEYAAgAURgACABRGAAIAFEYAQp165W12jsV6AJRDAEId\
6u7uTldXV3p6eg67Xk9PT7q6utLd3T1BkwFQDwQg1Jne3t6sXbs2SbJmzZpDRmBPT0/WrFmTJFm7\
dq0jgQBUCUCoM21tbens7Kw+Hy0CXxl/SdLZ2Zm2trYJmxEmE6dbMBkJQKhDHR0dh4zA0eKvo6Nj\
wmeEycDpFkxWvgoO6tTBqDsYewcjcGhoqLqO+IOj9+rTLZKM+t/Tq0+3OOeccxxx57jnCCDUsVce\
CXz4fz6c+/6f+/Lw/3w4ifiDN8rpFkxmvguYuuW7NP/DWZeflZ0DO6vPpzRNyQvfe6GGE8HkcajT\
Kt7I6Rb2X9Saj4ChzvX09IyIvyQ5MHwgPT09jgDCMXCo0y02fvv/rq7zX7/xf/jvjbriI2CoYweP\
QJzcdHKSl4/8JUlDGg57ixjg9Xn1hVebH1tX/edz57eKP+qOAIQ69cqPn5a+eWkeuOmBvPC9F/LA\
TQ/kyv90ZZLD3ycQeH06OjoyY8aMJMkfBgeTJI0nvClntc6p5VhwVAQg1KHDnXt0uFvEAEfvlVfZ\
T/v/z9vb+8f92dq383C/Bscl5wBCnent7T3iieejnbN05plnujoRjtKr/9L19vf/6YhbLjnnlnrj\
CCDUmba2tixbtizJ4a86fOWRwGXLlok/OEqjHXG/4447HGmnrrkNDHWr9Nso9Pb2jinqxroe8FpH\
utXL0d4KpvT9F7XnCCDUqbFGnfiDozPW0y1efSTQdwJTDwQgAIzC6RZMZj4Cpm75CAWYCONxuoX9\
F7XmCCAAHIbTLZiMBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBh\
BCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQg\
AEBhBCAAQGEEIABAYQQgAEBhBCA1ddddd+Utb3lLTjzxxFx44YX5yU9+UuuRAGDSE4DUzEMPPZSV\
K1fmtttuy89//vOcf/756ejoyPPPP1/r0QBgUhOA1Mwdd9yRT33qU/n4xz+exYsX55577sn06dPz\
T//0T7UeDQAmNQFITezduzebNm3K0qVLq8umTJmSpUuXZuPGjaP+zvDwcAYHB0c8AIDXTwBSEy+8\
8EL279+fuXPnjlg+d+7c9PX1jfo7q1evTktLS/WxYMGCiRgVACYdAUjdWLVqVQYGBqqP7du313ok\
AKhLJ9R6AMp06qmn5k1velP6+/tHLO/v709ra+uov9PU1JSmpqaJGA8AJjVHAKmJxsbGLFmyJOvX\
r68uO3DgQNavX5/29vYaTgYAk58jgNTMypUrs3z58rzjHe/IBRdckK9+9asZGhrKxz/+8VqPBgCT\
mgCkZj7ykY9k586dufXWW9PX15e3v/3t+d73vveaC0MAgGOroVKpVGo9BByNwcHBtLS0ZGBgIM3N\
zbUeB2DM7L+oNecAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYA\
AgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIA\
FEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRG\
AAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgAC\
ABRGAAIAFEYAAgAURgByzH3hC1/Iu971rkyfPj0nnXTSqOts27Ytl112WaZPn57TTjstn/3sZ/PH\
P/5xYgcFgEKdUOsBmHz27t2bD3/4w2lvb88//uM/vub1/fv357LLLktra2t+9KMf5bnnnsvHPvax\
TJ06NV/84hdrMDEAlKWhUqlUaj0Ek9N9992X66+/Prt27Rqx/Lvf/W6WLVuWHTt2ZO7cuUmSe+65\
J3//93+fnTt3prGxcUzvPzg4mJaWlgwMDKS5uflYjw8wbuy/qDUfATPhNm7cmHPPPbcaf0nS0dGR\
wcHBPP300zWcDADK4CNgJlxfX9+I+EtSfd7X13fI3xseHs7w8HD1+eDg4PgMCACTnCOAjMlNN92U\
hoaGwz62bNkyrjOsXr06LS0t1ceCBQvG9d8HAJOVI4CMyY033pirrrrqsOucccYZY3qv1tbW/OQn\
PxmxrL+/v/raoaxatSorV66sPh8cHBSBAHAUBCBjMmfOnMyZM+eYvFd7e3u+8IUv5Pnnn89pp52W\
JFm3bl2am5uzePHiQ/5eU1NTmpqajskMAFAyAcgxt23btrz44ovZtm1b9u/fn82bNydJ2traMnPm\
zFxyySVZvHhxPvrRj+b2229PX19fbr755qxYsULgAcAEcBsYjrmrrroq3/rWt16z/LHHHsv73ve+\
JMlvf/vbXHPNNfnhD3+YGTNmZPny5fnSl76UE04Y+99J3EYBqFf2X9SaAKRu2YEC9cr+i1pzFTAA\
QGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBh\
BCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQg\
AEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABA\
YQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEE\
IABAYQQgx9RvfvObXH311Vm0aFGmTZuWM888M7fddlv27t07Yr1f/OIX+ZM/+ZOceOKJWbBgQW6/\
/fYaTQwA5Tmh1gMwuWzZsiUHDhzIP/zDP6StrS1PPfVUPvWpT2VoaChf/vKXkySDg4O55JJLsnTp\
0txzzz158skn84lPfCInnXRSPv3pT9d4CwBg8muoVCqVWg/B5NbV1ZW77747//Zv/5Ykufvuu/O5\
z30ufX19aWxsTJLcdNNNefTRR7Nly5Yxv+/g4GBaWloyMDCQ5ubmcZkdYDzYf1FrPgJm3A0MDGT2\
7NnV5xs3bsx73/veavwlSUdHR7Zu3Zrf/e53tRgRAIoiABlXvb29+frXv56/+Zu/qS7r6+vL3Llz\
R6x38HlfX98h32t4eDiDg4MjHgDA6ycAGZObbropDQ0Nh328+uPbZ599Nn/2Z3+WD3/4w/nUpz71\
hmdYvXp1Wlpaqo8FCxa84fcEgBI5B5Ax2blzZ/793//9sOucccYZ1Y91d+zYkfe973256KKLct99\
92XKlP/4u8bHPvaxDA4O5tFHH60ue+yxx3LxxRfnxRdfzMknnzzq+w8PD2d4eLj6fHBwMAsWLHAO\
DVB3nANIrbkKmDGZM2dO5syZM6Z1n3322bz//e/PkiVLcu+9946IvyRpb2/P5z73uezbty9Tp05N\
kqxbty5nnXXWIeMvSZqamtLU1HT0GwEAJPERMMfYs88+m/e9731ZuHBhvvzlL2fnzp3p6+sbcW7f\
X//1X6exsTFXX311nn766Tz00EO58847s3LlyhpODgDlcASQY2rdunXp7e1Nb29v5s+fP+K1g2cb\
tLS05Pvf/35WrFiRJUuW5NRTT82tt97qHoAAMEGcA0jdcg4NUK/sv6g1HwEDABRGAAIAFEYAAgAU\
RgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYA\
AgAURgACABRGAAIAFEYAAgAURgACABRGAALAGPX29h7T9aBWBCAAjEF3d3e6urrS09Nz2PV6enrS\
1dWV7u7uCZoMXj8BCABH0Nvbm7Vr1yZJ1qxZc8gI7OnpyZo1a5Ika9eudSSQ45YABIAjaGtrS2dn\
Z/X5aBH4yvhLks7OzrS1tU3YjPB6CEAAGIOOjo5DRuBo8dfR0THhM8JYNVQqlUqth4CjMTg4mJaW\
lgwMDKS5ubnW4wCFeHXszZgxI0NDQ9XnY4k/+y9q7YRaDwAA9eRg3H3zrv8rz/Xuqi7/z3/yvzny\
R93wETAAvE4dHR158bd7Riz7w+8q4o+6IQAB4HV46vFn89m/vCPD+0YG4PZf9x/xFjFwvBCAAPA6\
fOsbD2XjL35Qfd54wolJklMXzDrsLWLgeCIAAWCMenp68pvf/zxTm96U09tOyi1fuS4/+MV/zy1f\
uS6zT5+R5PD3CYTjhYtAAGAMDl79O/v0GZl9+owRF3wc/Hnw6uCDP50TyPHKEUAAOILe3t4j3udv\
tPsE+iYQjlcCEACOoK2tLcuWLUty+Pv8vTICly1b5ptAOG65ETR1y41UgYnW29s7pqg70nr2X9Sa\
I4AAMEZjPaLnyB/HOwEIAFAYAQgAUBgBCABQGAEIAFAYAQgAUBgBCABQGAEIAFAYAQgAUBgBCABQ\
mBNqPQAcrYPfYjg4OFjjSQBen4P7Ld/GSq0IQOrW7t27kyQLFiyo8SQAR2f37t1paWmp9RgUqKHi\
rx/UqQMHDmTHjh2ZNWtWGhoaaj3OMTM4OJgFCxZk+/btk/pL4m3n5FHCNibHdjsrlUp2796defPm\
ZcoUZ2Mx8RwBpG5NmTIl8+fPr/UY46a5uXlS/8/0INs5eZSwjcmx205H/qglf+0AACiMAAQAKIwA\
hONMU1NTbrvttjQ1NdV6lHFlOyePErYxKWc7KYOLQAAACuMIIABAYQQgAEBhBCAAQGEEIABAYQQg\
HEe+8IUv5F3velemT5+ek046adR1tm3blssuuyzTp0/Paaedls9+9rP54x//OLGDvkF33XVX3vKW\
t+TEE0/MhRdemJ/85Ce1HukNefzxx/PBD34w8+bNS0NDQx599NERr1cqldx66605/fTTM23atCxd\
ujS//vWvazPsUVq9enXe+c53ZtasWTnttNNy+eWXZ+vWrSPW2bNnT1asWJFTTjklM2fOzBVXXJH+\
/v4aTXx07r777px33nnVmz23t7fnu9/9bvX1ybCNkAhAOK7s3bs3H/7wh3PNNdeM+vr+/ftz2WWX\
Ze/evfnRj36Ub33rW7nvvvty6623TvCkR++hhx7KypUrc9ttt+XnP/95zj///HR0dOT555+v9WhH\
bWhoKOeff37uuuuuUV+//fbb87WvfS333HNPnnjiicyYMSMdHR3Zs2fPBE969DZs2JAVK1bkxz/+\
cdatW5d9+/blkksuydDQUHWdG264Id3d3Xn44YezYcOG7NixI52dnTWc+vWbP39+vvSlL2XTpk35\
2c9+losvvjgf+tCH8vTTTyeZHNsISZIKcNy59957Ky0tLa9Z/p3vfKcyZcqUSl9fX3XZ3XffXWlu\
bq4MDw9P4IRH74ILLqisWLGi+nz//v2VefPmVVavXl3DqY6dJJVHHnmk+vzAgQOV1tbWSldXV3XZ\
rl27Kk1NTZUHHnigBhMeG88//3wlSWXDhg2VSuXlbZo6dWrl4Ycfrq7zq1/9qpKksnHjxlqNeUyc\
fPLJlW9+85uTehspjyOAUEc2btyYc889N3Pnzq0u6+joyODgYPUIxfFs79692bRpU5YuXVpdNmXK\
lCxdujQbN26s4WTj55lnnklfX9+IbW5pacmFF15Y19s8MDCQJJk9e3aSZNOmTdm3b9+I7Tz77LOz\
cOHCut3O/fv358EHH8zQ0FDa29sn5TZSrhNqPQAwdn19fSPiL0n1eV9fXy1Gel1eeOGF7N+/f9Rt\
2LJlS42mGl8H/1xG2+Z6+DMbzYEDB3L99dfn3e9+d972trcleXk7GxsbX3Puaj1u55NPPpn29vbs\
2bMnM2fOzCOPPJLFixdn8+bNk2YbwRFAGGc33XRTGhoaDvuYrPHD5LRixYo89dRTefDBB2s9yrg4\
66yzsnnz5jzxxBO55pprsnz58vzyl7+s9VhwTDkCCOPsxhtvzFVXXXXYdc4444wxvVdra+trrpg9\
eAVia2vrUc03kU499dS86U1ves1Vk/39/XUx/9E4uF39/f05/fTTq8v7+/vz9re/vUZTHb1rr702\
a9euzeOPP5758+dXl7e2tmbv3r3ZtWvXiCNk9fhn29jYmLa2tiTJkiVL8tOf/jR33nlnPvKRj0ya\
bQRHAGGczZkzJ2efffZhH42NjWN6r/b29jz55JMjrphdt25dmpubs3jx4vHahGOmsbExS5Ysyfr1\
66vLDhw4kPXr16e9vb2Gk42fRYsWpbW1dcQ2Dw4O5oknnqirba5UKrn22mvzyCOP5Ac/+EEWLVo0\
4vUlS5Zk6tSpI7Zz69at2bZtW11t52gOHDiQ4eHhSb2NlMcRQDiObNu2LS+++GK2bduW/fv3Z/Pm\
zUmStra2zJw5M5dcckkWL16cj370o7n99tvT19eXm2++OStWrEhTU1Nthx+jlStXZvny5XnHO96R\
Cy64IF/96lczNDSUj3/847Ue7ai99NJL6e3trT5/5plnsnnz5syePTsLFy7M9ddfn89//vN561vf\
mkWLFuWWW27JvHnzcvnll9du6NdpxYoVuf/++/Ptb387s2bNqp7z1tLSkmnTpqWlpSVXX311Vq5c\
mdmzZ6e5uTnXXXdd2tvbc9FFF9V4+rFbtWpVLr300ixcuDC7d+/O/fffnx/+8Ifp6emZNNsISdwG\
Bo4ny5cvryR5zeOxxx6rrvOb3/ymcumll1amTZtWOfXUUys33nhjZd++fbUb+ih8/etfryxcuLDS\
2NhYueCCCyo//vGPaz3SG/LYY4+N+ue2fPnySqXy8q1gbrnllsrcuXMrTU1NlQ984AOVrVu31nbo\
12m07UtSuffee6vr/OEPf6h85jOfqZx88smV6dOnV/78z/+88txzz9Vu6KPwiU98ovLmN7+50tjY\
WJkzZ07lAx/4QOX73/9+9fXJsI1QqVQqDZVKpTLx2QkAQK04BxAAoDACEACgMAIQAKAwAhAAoDAC\
EACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAA\
oDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAw\
AhAAoDACEACgMAIQAKAwAhAAoDD/H6VSUzkOMDChAAAAAElFTkSuQmCC\
"
  frames[3] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAIlZJREFUeJzt3X+M1PWd+PHXouwKwg6isCOyXPFotKSVTaZd3fauUUvhiNfo\
+SPtXa6uluh9vdUE1/ROUsXc91sPg01P26+F++bu1Ms3qPGbQLE5awlF/KMre24zntpCSs4eVJyF\
nmWHkjIgO98/CFMWl2WB3R1m349HMtH5zIfh9QlxfPLez+czdeVyuRwAACRjQrUHAABgbAlAAIDE\
CEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhA\
AIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACA\
xAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQI\
QACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAA\
gMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDEnF/tAeBM9Pf3x+7du2Pq\
1KlRV1dX7XEATlu5XI79+/fHrFmzYsIE6zGMLQFITdq9e3c0NzdXewyAs7Zr166YPXt2tccgMQKQ\
mjR16tSIOPrB2djYWOVpAE5fsViM5ubmyucZjCUBSE069mPfxsZGAQjUNKexUA1OOgAASIwABABI\
jAAEAEiMAAQASIwABABIjAAEAEiMAIQaUSgURnQ/ANIlAKEG9PT0xIYNGyKfzw+5Xz6fjw0bNkRP\
T8/YDAZATRKAcI4rFAqVoOvu7j5pBObz+eju7o6Io8FoJRCAkxGAcI7LZrPR2tpaeT5YBB4ffxER\
ra2tkc1mx2pEAGqMAIQa0NLSctIIHCz+WlpaxnhCAGqJ7wKGGnEs6o7FXnd3d7z55ptRKpUq+4g/\
AIbDCiDUkBNXAsUfAGfCCiDUmJaWlqMrf//vf1S2Ndy6RvwBMGxWAKHG5PP5ASt/EUdXAk91ixgA\
OEYAQg058YKPhvN+/9pQt4gBgOMJQKgRH7na9391Rfv630Xr/+qqbBOBAAyHAIQaMNStXoa6RQwA\
DEYAwjmuUCic8j5/g0WgbwIB4GQEIJzjstls5HK5iBj6Vi/HR2Aul/NNIACclNvAQA3I5XJx2WWX\
nTLqWlpaIpvNij8AhmQFkBG3evXquOqqq6KxsTEaGxujra0tXn755crrBw8ejI6Ojrj44otjypQp\
ccstt0Rvb28VJ64Nw4068QfAqQhARtzs2bPjsccei56ennjjjTfi+uuvjxtvvDHeeeediIi4//77\
46WXXooXX3wxtmzZErt3746bb765ylMDQDrqyuVyudpDMP5Nnz49Hn/88bj11ltjxowZsXbt2rj1\
1lsjImLbtm3xiU98Irq6uuKaa64Z1vsVi8XIZDLR19cXjY2Nozk6wKjwOUY1WQFkVB05ciSef/75\
OHDgQLS1tUVPT08cPnw4Fi5cWNnnyiuvjDlz5kRXV9cQ7wQwPMO9At6V8qTMRSCMirfeeiva2tri\
4MGDMWXKlFi3bl3Mnz8/8vl81NfXx7Rp0wbs39TUNOSHcalUGvD1Z8VicbRGB2pYT09P9PT0DHnF\
fMTv762Zy+UqV9lDSqwAMiquuOKKyOfzsXXr1rjnnnuivb09fvazn53x+61cuTIymUzl0dzcPILT\
AuNBoVCInp6eiBj6hujH31i9p6fHSiBJEoCMivr6+pg3b17kcrlYuXJlLFiwIJ588snIZrNx6NCh\
2Ldv34D9e3t7h7x6dfny5dHX11d57Nq1a5SPAKg12Wz2lN+KM9i36rhynhQJQMZEf39/lEqlyOVy\
MXHixNi0aVPlte3bt8fOnTujra3tpL++oaGhcluZYw+AEw311YhDfaUipMY5gIy45cuXx5IlS2LO\
nDmxf//+WLt2bbz66qvxyiuvRCaTiaVLl0ZnZ2dMnz49Ghsb47777ou2trZhXwEMMJRjUXcs9rq7\
u+PNN98ccB6x+CN1ApARt2fPnrj99tvj/fffj0wmE1dddVW88sor8cUvfjEiIv7hH/4hJkyYELfc\
ckuUSqVYvHhxfO9736vy1MB4cmIEij8YyH0AqUnunwUMx7PPPhudz71Ref7tP/90tLe3V3Gi3/M5\
RjU5BxCAcSmfzw9Y+Ys4uhJ4squDISUCEIBx58QLPurOm1j596FuEQOpcA4gAOPKifG36bGl0dLS\
MmD7sX86F5BUWQEEYNwY6lYvQ90iBlIjAAEYFwqFwinv8zdYBPomEFIkAAEYF7LZbOV7fYe61cvx\
EZjL5XwTCElyDiAA40Yul4vLLrvslFHX0tIS2WxW/JEsK4AAjCvDjTrxR8oEIABAYgQgAEBiBCAA\
QGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBi\
BCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQg\
AEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQg41qhUBjR/QBgPBCA\
jFs9PT2xYcOGyOfzQ+6Xz+djw4YN0dPTMzaDAUCVCUDGpUKhUAm67u7uk0ZgPp+P7u7uiDgajFYC\
AUiBAGRcymaz0draWnk+WAQeH38REa2trZHNZsdqRAComvOrPQCMlpaWloiISuQd+2fDV/48fn7w\
YLx18GBc+j//LiKOxt+x/QFgvLMCyIhbuXJlfOYzn4mpU6fGzJkz46abbort27cP2OfgwYPR0dER\
F198cUyZMiVuueWW6O3tHfFZWlpaPrISuL6vL946eLCyTfwBkBoByIjbsmVLdHR0xOuvvx4bN26M\
w4cPx6JFi+LAgQOVfe6///546aWX4sUXX4wtW7bE7t274+abbx6VeU6MwEPlcuXfxR8AKaorl4/7\
vyGMgr1798bMmTNjy5Yt8fnPfz76+vpixowZsXbt2rj11lsjImLbtm3xiU98Irq6uuKaa6455XsW\
i8XIZDLR19cXjY2Nw5rj2WefjVKpVHne0NAQ7e3tZ3ZQAGfpTD7HYKRYAWTU9fX1RUTE9OnTI+Lo\
1baHDx+OhQsXVva58sorY86cOdHV1TUqM+Tz+QHxFxFRKpVOeYsYABiPXATCqOrv749ly5bF5z73\
ufjkJz8ZEUdv0VJfXx/Tpk0bsG9TU9NJb8NSKpUGBFyxWBz2DCde7dvQ0FB5r2Pb/RgYgJRYAWRU\
dXR0xNtvvx3PP//8Wb3PypUrI5PJVB7Nzc3D+nWD3eqlvb39lLeIAYDxTAAyau699974wQ9+EJs3\
b47Zs2dXtmez2Th06FDs27dvwP69vb0nvQ/f8uXLo6+vr/LYtWvXKX//weLv2ErfYFcHi0AAUiEA\
GXHlcjnuvffeWLduXfz4xz+OuXPnDng9l8vFxIkTY9OmTZVt27dvj507d0ZbW9ug79nQ0BCNjY0D\
HkMpFAonjb9jBotA3wQCQAqcA8iI6+joiLVr18b3v//9mDp1aiWqMplMTJo0KTKZTCxdujQ6Oztj\
+vTp0djYGPfdd1+0tbUN6wrg4chms5HL5aKnp2fIW70cf7PoXC7nm0AASILbwDDi6urqBt3+9NNP\
xx133BERR28E/cADD8Rzzz0XpVIpFi9eHN/73veGHWDDvX1CoVAY1nsOdz+AkeI2MFSTAKQm+eAE\
ap3PMarJOYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkR\
gAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAA\
AIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJ\
EYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGA\
AACJEYAAAIkRgAAAiRGAjLjXXnstvvSlL8WsWbOirq4u1q9fP+D1crkcK1asiEsvvTQmTZoUCxcu\
jF/84hfVGRYAEiQAGXEHDhyIBQsWxFNPPTXo66tWrYrvfOc7sWbNmti6dWtceOGFsXjx4jh48OAY\
TwoAaTq/2gMw/ixZsiSWLFky6GvlcjmeeOKJeOihh+LGG2+MiIh//dd/jaampli/fn185StfGctR\
ASBJVgAZU++++24UCoVYuHBhZVsmk4mrr746urq6qjgZAKTDCiBjqlAoREREU1PTgO1NTU2V1wZT\
KpWiVCpVnheLxdEZEAASYAWQmrBy5crIZDKVR3Nzc7VHAoCaJQAZU9lsNiIient7B2zv7e2tvDaY\
5cuXR19fX+Wxa9euUZ0TAMYzAciYmjt3bmSz2di0aVNlW7FYjK1bt0ZbW9tJf11DQ0M0NjYOeAAA\
Z8Y5gIy43/72t7Fjx47K83fffTfy+XxMnz495syZE8uWLYtvfvOb8fGPfzzmzp0bDz/8cMyaNStu\
uumm6g0NAAkRgIy4N954I6677rrK887OzoiIaG9vj2eeeSb+5m/+Jg4cOBB333137Nu3L/7oj/4o\
fvjDH8YFF1xQrZEBICl15XK5XO0h4HQVi8XIZDLR19fnx8FATfI5RjU5BxAAIDECEAAgMQIQACAx\
AhAAIDECEGrQUF+bdyb7AZAWAQg1pqenJzZs2BD5fH7I/fL5fGzYsCF6enrGZjAAaoYAhBpSKBQq\
Qdfd3X3SCMzn89Hd3R0RR4PRSiAAxxOAUEOy2Wy0trZWng8WgcfHX0REa2vrkN+zDJya0y4YbwQg\
1JiWlpaTRuBg8dfS0jLGE8L44rQLxiNfBQc16FjUHYu97u7uePPNN6NUKlX2EX9w9k487SIiBv3v\
6sTTLi677DIr75zTrABCjTpxJVD8wchz2gXjlRVAqGEtLS2Vlb+/6/q7iIioO78ufnX3r6o8GYwf\
g624H9vutAtqlQCEGpbP5wes/EVElD8sRz6f9z8hGEFOu2C8EYBQo05ceag7vy7KH5YjYuhzlYAz\
c2IElkql2Ph//ndERDRPz8Tdd99drdHgtAlAqEGD/djpV3f/asB2EQgj7/jTLo4577wJcdlFmSpO\
BafPRSBQY4Y652ioW8QAZ2+w0y6OHOmP937TV6WJ4MxYAYQaUigUTnnC+WDnKmWzWVclwlk68S9f\
DQ0N8cW77x3wuhV3aoUVQKgh2Ww2crlcRAx9wvnxK4G5XE78wVkabOW9vb3dijs1ywog1JhcLjes\
m8y2tLRY+YMRcKrTLiIGv0UMnMusAEINGm7UiT84O8M97eLElUDfCcy5TgACwEk47YLxyo+AAWAI\
TrtgPLICCACn4LQLxhsBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgA\
kBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAY\
AQgAkBgBCACQGAEIAJAYAQgAkBgBSFU99dRT8bGPfSwuuOCCuPrqq6O7u7vaIwHAuCcAqZoXXngh\
Ojs745FHHomf/vSnsWDBgli8eHHs2bOn2qMBwLgmAKmab3/723HXXXfFnXfeGfPnz481a9bE5MmT\
41/+5V+qPRoAjGsCkKo4dOhQ9PT0xMKFCyvbJkyYEAsXLoyurq4qTgYA49/51R6ANP3617+OI0eO\
RFNT04DtTU1NsW3bto/sXyqVolQqVZ4Xi8VRnxEAxisrgNSElStXRiaTqTyam5urPRIA1CwBSFVc\
csklcd5550Vvb++A7b29vZHNZj+y//Lly6Ovr6/y2LVr11iNCgDjjgCkKurr6yOXy8WmTZsq2/r7\
+2PTpk3R1tb2kf0bGhqisbFxwAMAODPOAaRqOjs7o729PT796U9Ha2trPPHEE3HgwIG48847qz0a\
AIxrApCq+fKXvxx79+6NFStWRKFQiJaWlvjhD3/4kQtDAICRVVcul8vVHgJOV7FYjEwmE319fX4c\
DNQkn2NUk3MAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQAS\
IwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMA\
AQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEA\
EiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIj\
AAEAEiMAAQASIwABABIjABlxjz76aHz2s5+NyZMnx7Rp0wbdZ+fOnXHDDTfE5MmTY+bMmfH1r389\
Pvzww7EdFAASdX61B2D8OXToUNx2223R1tYW//zP//yR148cORI33HBDZLPZ+MlPfhLvv/9+3H77\
7TFx4sT4+7//+ypMDABpqSuXy+VqD8H49Mwzz8SyZcti3759A7a//PLL8ad/+qexe/fuaGpqioiI\
NWvWxN/+7d/G3r17o76+/pTvXSwWI5PJRF9fXzQ2No7G+ACjyucY1eRHwIy5rq6u+NSnPlWJv4iI\
xYsXR7FYjHfeeaeKkwFAGvwImDFXKBQGxF9EVJ4XCoVBf02pVIpSqVR5XiwWR29AABjnrAAyLA8+\
+GDU1dUN+di2bduo/f4rV66MTCZTeTQ3N4/a7wUA450VQIblgQceiDvuuGPIfS6//PJhvVc2m43u\
7u4B23p7eyuvDWb58uXR2dlZeV4sFkUgAJwhAciwzJgxI2bMmDEi79XW1haPPvpo7NmzJ2bOnBkR\
ERs3bozGxsaYP3/+oL+moaEhGhoaRuT3B4DUCUBG3M6dO+ODDz6InTt3xpEjRyKfz0dExLx582LK\
lCmxaNGimD9/fnz1q1+NVatWRaFQiIceeig6OjpEHgCMAbeBYcTdcccd8eyzz35k++bNm+Paa6+N\
iIj/+q//invuuSdeffXVuPDCC6O9vT0ee+yxOP/84f2dxO0TgFrnc4xqEoDUJB+cQK3zOUY1uQoY\
ACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAg\
MQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDEC\
EAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAA\
IDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAx\
AhAAIDECkBH1y1/+MpYuXRpz586NSZMmxR/+4R/GI488EocOHRqw33/8x3/EH//xH8cFF1wQzc3N\
sWrVqipNDADpOb/aAzC+bNu2Lfr7++Mf//EfY968efH222/HXXfdFQcOHIhvfetbERFRLBZj0aJF\
sXDhwlizZk289dZb8bWvfS2mTZsWd999d5WPAADGv7pyuVyu9hCMb48//nisXr06/vM//zMiIlav\
Xh3f+MY3olAoRH19fUREPPjgg7F+/frYtm3bsN6zWCxGJpOJvr6+aGxsHLXZAUaLzzGqyY+AGXV9\
fX0xffr0yvOurq74/Oc/X4m/iIjFixfH9u3b4ze/+U01RgSApAhARtWOHTviu9/9bvzVX/1VZVuh\
UIimpqYB+x17XigUBn2fUqkUxWJxwAMAODMCkGF58MEHo66ubsjHiT++fe+99+JP/uRP4rbbbou7\
7rrrrH7/lStXRiaTqTyam5vP6v0AIGXOAWRY9u7dG//93/895D6XX3555ce6u3fvjmuvvTauueaa\
eOaZZ2LChN//XeP222+PYrEY69evr2zbvHlzXH/99fHBBx/ERRdd9JH3LpVKUSqVKs+LxWI0Nzc7\
dwaoWc4BpJpcBcywzJgxI2bMmDGsfd9777247rrrIpfLxdNPPz0g/iIi2tra4hvf+EYcPnw4Jk6c\
GBERGzdujCuuuGLQ+IuIaGhoiIaGhrM7CAAgIvwImBH23nvvxbXXXhtz5syJb33rW7F3794oFAoD\
zu37i7/4i6ivr4+lS5fGO++8Ey+88EI8+eST0dnZWcXJASAdVgAZURs3bowdO3bEjh07Yvbs2QNe\
O3a2QSaTiR/96EfR0dERuVwuLrnkklixYoV7AALAGHEOIDXJuTNArfM5RjX5ETAAQGIEIABAYgQg\
AEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABA\
YgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAJyGQqEwovtBNQhAABimnp6e2LBhQ+Tz\
+SH3y+fzsWHDhujp6RmbweA0CUAAGIZCoVAJuu7u7pNGYD6fj+7u7og4GoxWAjkXCUAAGIZsNhut\
ra2V54NF4PHxFxHR2toa2Wx2rEaEYROAADBMLS0tJ43AweKvpaVljCeE4Tm/2gMAQC05FnXHYq+7\
uzvefPPNKJVKlX3EH+c6AQgAp+n4CNz8f7dVtl/3l1eKP2qCHwEDwBloaWmJhoaGAdsaGhrEHzVB\
AALAGcjn8wN+7BsRUSqVTnmLGDgX+BEwAJym4y/4uO4vr4yGhoZKDB7bbiWQc5kVQAA4DYNd7dve\
3n7KW8TAuUQAAsAwDXWrl6FuEQPnGgEIAMNQKBROeZ+/wSLQN4FwLhKAADAM2Ww2crlcRAx9n7/j\
IzCXy/kmEM5JLgIBgGHK5XJx2WWXnTLqWlpaIpvNij/OWVYAAeA0DDfqxB/nMgEIAJAYAQgAkBgB\
CACQGAEIAJAYAQgAkBgBCACQGAEIAJAYN4KmJpXL5YiIKBaLVZ4E4Mwc+/w69nkGY0kAUpP2798f\
ERHNzc1VngTg7Ozfvz8ymUy1xyAxdWV/9aAG9ff3x+7du2Pq1KlRV1dX7XFGVLFYjObm5ti1a1c0\
NjZWe5xR4zjHF8d5+srlcuzfvz9mzZoVEyY4I4uxZQWQmjRhwoSYPXt2tccYVY2NjeP6f6THOM7x\
xXGeHit/VIu/cgAAJEYAAgAkRgDCOaahoSEeeeSRaGhoqPYoo8pxji+OE2qLi0AAABJjBRAAIDEC\
EAAgMQIQACAxAhAAIDECEM4hjz76aHz2s5+NyZMnx7Rp0wbdZ+fOnXHDDTfE5MmTY+bMmfH1r389\
Pvzww7Ed9Cw99dRT8bGPfSwuuOCCuPrqq6O7u7vaI5211157Lb70pS/FrFmzoq6uLtavXz/g9XK5\
HCtWrIhLL700Jk2aFAsXLoxf/OIX1Rn2DK1cuTI+85nPxNSpU2PmzJlx0003xfbt2wfsc/Dgwejo\
6IiLL744pkyZErfcckv09vZWaeIzs3r16rjqqqsqN3tua2uLl19+ufL6eDhGEIBwDjl06FDcdttt\
cc899wz6+pEjR+KGG26IQ4cOxU9+8pN49tln45lnnokVK1aM8aRn7oUXXojOzs545JFH4qc//Wks\
WLAgFi9eHHv27Kn2aGflwIEDsWDBgnjqqacGfX3VqlXxne98J9asWRNbt26NCy+8MBYvXhwHDx4c\
40nP3JYtW6KjoyNef/312LhxYxw+fDgWLVoUBw4cqOxz//33x0svvRQvvvhibNmyJXbv3h0333xz\
Fac+fbNnz47HHnssenp64o033ojrr78+brzxxnjnnXciYnwcI0QZOOc8/fTT5Uwm85Ht//Zv/1ae\
MGFCuVAoVLatXr263NjYWC6VSmM44ZlrbW0td3R0VJ4fOXKkPGvWrPLKlSurONXIiojyunXrKs/7\
+/vL2Wy2/Pjjj1e27du3r9zQ0FB+7rnnqjDhyNizZ085Ispbtmwpl8tHj2nixInlF198sbLPz3/+\
83JElLu6uqo15oi46KKLyv/0T/80ro+RtFgBhBrS1dUVn/rUp6KpqamybfHixVEsFiurE+eyQ4cO\
RU9PTyxcuLCybcKECbFw4cLo6uqq4mSj6913341CoTDguDOZTFx99dU1fdx9fX0RETF9+vSIiOjp\
6YnDhw8POM4rr7wy5syZU7PHeeTIkXj++efjwIED0dbWNi6PkTSdX+0BgOErFAoD4i8iKs8LhUI1\
Rjotv/71r+PIkSODHsO2bduqNNXoO/ZnM9hx18Kf22D6+/tj2bJl8bnPfS4++clPRsTR46yvr//I\
+au1eJxvvfVWtLW1xcGDB2PKlCmxbt26mD9/fuTz+XFzjKTNCiCMsgcffDDq6uqGfIzn+GF86ujo\
iLfffjuef/75ao8yKq644orI5/OxdevWuOeee6K9vT1+9rOfVXssGDFWAGGUPfDAA3HHHXcMuc/l\
l18+rPfKZrMfuWL22NWH2Wz2jOYbS5dcckmcd955H7lisre3tybmP1PHjq23tzcuvfTSyvbe3t5o\
aWmp0lRn7t57740f/OAH8dprr8Xs2bMr27PZbBw6dCj27ds3YIWsFv986+vrY968eRERkcvl4t//\
/d/jySefjC9/+cvj5hhJmxVAGGUzZsyIK6+8cshHfX39sN6rra0t3nrrrQFXzG7cuDEaGxtj/vz5\
o3UII6a+vj5yuVxs2rSpsq2/vz82bdoUbW1tVZxsdM2dOzey2eyA4y4Wi7F169aaOu5yuRz33ntv\
rFu3Ln784x/H3LlzB7yey+Vi4sSJA45z+/btsXPnzpo6zsH09/dHqVQa18dIWqwAwjlk586d8cEH\
H8TOnTvjyJEjkc/nIyJi3rx5MWXKlFi0aFHMnz8/vvrVr8aqVauiUCjEQw89FB0dHdHQ0FDd4Yep\
s7Mz2tvb49Of/nS0trbGE088EQcOHIg777yz2qOdld/+9rexY8eOyvN333038vl8TJ8+PebMmRPL\
li2Lb37zm/Hxj3885s6dGw8//HDMmjUrbrrppuoNfZo6Ojpi7dq18f3vfz+mTp1aOectk8nEpEmT\
IpPJxNKlS6OzszOmT58ejY2Ncd9990VbW1tcc801VZ5++JYvXx5LliyJOXPmxP79+2Pt2rXx6quv\
xiuvvDJujhHcBgbOIe3t7eWI+Mhj8+bNlX1++ctflpcsWVKeNGlS+ZJLLik/8MAD5cOHD1dv6DPw\
3e9+tzxnzpxyfX19ubW1tfz6669Xe6Sztnnz5kH/7Nrb28vl8tFbwTz88MPlpqamckNDQ/kLX/hC\
efv27dUd+jQNdnwRUX766acr+/zud78r//Vf/3X5oosuKk+ePLn8Z3/2Z+X333+/ekOfga997Wvl\
P/iDPyjX19eXZ8yYUf7CF75Q/tGPflR5fTwcI9SVy+Xy2GcnAADV4hxAAIDECEAAgMQIQACAxAhA\
AIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACA\
xAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQI\
QACAxAhAAIDECEAAgMQIQACAxAhAAIDE/H9y3pGjpRPbhwAAAABJRU5ErkJggg==\
"
  frames[4] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAIndJREFUeJzt3X+M1PWd+PHXUtgVHGYQhZ1dWK54NFrSShPqj23vGms5KPEa\
PX+cl8u3oiX24q0miOmdXBXz/aYWo81V21i45O60l2+ofv1+A/1qzlq+FDH5dsVKv/TUHpuSswfZ\
3VnoWXZYUhaWne8fhjkWl2WB3R1m3o9HMsH5zIfh9QlxeO57PvOZulKpVAoAAJIxqdIDAAAwsQQg\
AEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABA\
YgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIE\
IABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAA\
QGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBi\
BCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiJld6ADgXg4OD0dXV\
FdOnT4+6urpKjwNw1kqlUhw6dCiam5tj0iTrMUwsAUhV6urqipaWlkqPAXDe9u3bF3Pnzq30GCRG\
AFKVpk+fHhEfvHBms9kKTwNw9orFYrS0tJRfz2AiCUCq0om3fbPZrAAEqprTWKgEJx0AACRGAAIA\
JEYAAgAkRgACACRGAAIAJEYAAgAkRgBClejr6xvT/QBIlwCEKtDV1RUdHR1RKBRG3K9QKERHR0d0\
dXVN0GQAVCMBCBe4vr6+6O7ujoiIzs7O00ZgoVCIzs7OiIjo7u62EgjAaQlAuMBlMpmYM2dO+f5w\
EXhy/EVEzJkzJzKZzITNCEB1EYBQBfL5/GkjcLj4y+fzEz4jANXDdwFDlTgRdSdir7OzM3p6emJg\
YKC8j/gDYDSsAEIVOXUlUPwBcC6sAEKVyefzH6z8PfPZ8rbJbf9X/AEwalYAocoUCoUhK38RH6wE\
nukSMQBwggCEKnLqBz4mn/R/8EiXiAGAk3kLGKrEhz7t+9/2RD6fH7L9xK/eDgZgJFYAoQqMdKmX\
kS4RAwDDEYBwgevr6zvjdf6Gi0DfBALA6QhAuMBlMploamqKiJEv9XJyBDY1NfkmEABOyzmAUAWa\
m5sjm82eMery+XxkMhnxB8CIrAAy5tavXx9XXXVVZLPZyGaz0draGq+88kr58SNHjkRbW1tceuml\
kclk4tZbb42enp4KTlwdRht14g+AMxGAjLm5c+fG448/Hjt37oy33norbrjhhrjpppvi3XffjYiI\
Bx54IF566aV48cUXY/v27dHV1RW33HJLhacGgHTUlUqlUqWHoPbNnDkznnzyybjtttti1qxZsXHj\
xrjtttsiImL37t3x8Y9/PNrb2+O6664b1fMVi8XI5XLR29sb2Wx2PEcHGBdex6gkK4CMq+PHj8fz\
zz8fhw8fjtbW1ti5c2ccO3YslixZUt7nyiuvjHnz5kV7e3sFJwVqxWg/Ae+T8qTMh0AYF2+//Xa0\
trbGkSNHIpPJxKZNm2LhwoWxa9euqK+vjxkzZgzZv7GxccRr1/X390d/f3/5frFYHK/RgSrW1dUV\
3d3dI35iPuI/r63Z1NQUzc3NEzghXBisADIurrjiiti1a1fs2LEj7r333lixYkX88pe/POfnW7du\
XeRyufKtpaVlDKcFakFfX190d3dHxMgXRD/5wurd3d1WAkmSAGRc1NfXx4IFC2Lx4sWxbt26WLRo\
UTz99NORz+fj6NGjcfDgwSH79/T0jPjT+po1a6K3t7d827dv3zgfAVBtMpnMGb8VZ7hv1fHJeVIk\
AJkQg4OD0d/fH4sXL44pU6bE1q1by491dHTE3r17o7W19bS/v6GhoXxZmRM3gFON9NWII32lIqTG\
OYCMuTVr1sTy5ctj3rx5cejQodi4cWO89tpr8eqrr0Yul4uVK1fG6tWrY+bMmZHNZuP++++P1tbW\
UX8CGGAkJ6LuROx1dnZGT09PDAwMlPcRf6ROADLm9u/fH3feeWd0d3dHLpeLq666Kl599dX4oz/6\
o4iI+Pa3vx2TJk2KW2+9Nfr7+2PZsmXxve99r8JTA7Xk1AgUfzCU6wBSlVw/CxiNX/ziF/HFb79W\
vv+jB66PRYsWVWyek3kdo5KcAwhATSoUCkNW/iI+WAkc6ZJTkAoBCEDNOfUDH3WT/vOfu5EuEQOp\
cA4gADXl1Pj7f4/fEfl8fsj2E786F5BUWQEEoGaMdKmXkS4RA6kRgADUhL6+vjNe52+4CPRNIKRI\
AAJQEzKZTDQ1NUXEyJd6OTkCm5qafBMISXIOIAA1o7m5ObLZ7BmjLp/PRyaTEX8kywogADVltFEn\
/kiZAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABI\
jAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwA\
BABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQA\
SIwApKb19fWN6X4AUAsEIDWrq6srOjo6olAojLhfoVCIjo6O6OrqmqDJAKCyBCA1qa+vL7q7uyMi\
orOz87QRWCgUorOzMyIiuru7rQQCkAQBSE3KZDIxZ86c8v3hIvDk+IuImDNnTmQymQmbEQAqZXKl\
B4Dxks/nIyLKkXfi199e//k4MDAQ+wcGYv7/+p8R8UH8ndgfAGqdFUDG3Lp16+Lqq6+O6dOnx+zZ\
s+Pmm2+Ojo6OIfscOXIk2tra4tJLL41MJhO33npr9PT0jPks+Xz+QyuBu48cif0DA+Vt4g+A1AhA\
xtz27dujra0t3njjjdiyZUscO3Ysli5dGocPHy7v88ADD8RLL70UL774Ymzfvj26urrilltuGZd5\
To3A4yc9Jv4ASFFdqVQqVXoIatuBAwdi9uzZsX379vjc5z4Xvb29MWvWrNi4cWPcdtttERGxe/fu\
+PjHPx7t7e1x3XXXnfE5i8Vi5HK56O3tjWw2O6o5fvGLX8TASSt/kydPjkWLFp3bQQGcp3N5HYOx\
YgWQcdfb2xsRETNnzoyIiJ07d8axY8diyZIl5X2uvPLKmDdvXrS3t4/LDIVCYUj8RUQMDAyc8RIx\
AFCLfAiEcTU4OBirVq2Kz372s/GJT3wiIj6Isfr6+pgxY8aQfRsbG08bZP39/dHf31++XywWRz3D\
qZ/2nTx5cjkGT2z3NjAAKbECyLhqa2uLd955J55//vnzep5169ZFLpcr31paWkb1+4a71MuiRYvO\
eIkYAKhlApBxc99998XLL78c27Zti7lz55a35/P5OHr0aBw8eHDI/j09PaddiVuzZk309vaWb/v2\
7Tvjnz9c/J14/uE+HSwCAUiFAGTMlUqluO+++2LTpk3xk5/8JObPnz/k8cWLF8eUKVNi69at5W0d\
HR2xd+/eaG1tHfY5GxoaIpvNDrmNpK+v77Txd8JwEeibQABIgXMAGXNtbW2xcePG+OEPfxjTp08v\
r6zlcrmYOnVq5HK5WLlyZaxevTpmzpwZ2Ww27r///mhtbR3VJ4BHI5PJRFNTU3R3d494qZeTLxbd\
1NTkm0AASILLwDDm6urqht3+7LPPxl133RURH1wI+sEHH4wf/OAH0d/fH8uWLYvvfe97o/4wxmgv\
n9DX1zeqqBvtfgBjxWVgqCQBSFXywglUO69jVJJzAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwAB\
ABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQAS\
IwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMA\
AQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEA\
EiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwAZc6+//np86Utfiubm5qirq4vN\
mzcPebxUKsXatWujqakppk6dGkuWLIlf/epXlRkWABIkABlzhw8fjkWLFsUzzzwz7ONPPPFEfOc7\
34kNGzbEjh074uKLL45ly5bFkSNHJnhSAEjT5EoPQO1Zvnx5LF++fNjHSqVSPPXUU/Hwww/HTTfd\
FBER//RP/xSNjY2xefPm+LM/+7OJHBUAkmQFkAn13nvvRaFQiCVLlpS35XK5uPbaa6O9vb2CkwFA\
OqwAMqEKhUJERDQ2Ng7Z3tjYWH5sOP39/dHf31++XywWx2dAAEiAFUCqwrp16yKXy5VvLS0tlR4J\
AKqWAGRC5fP5iIjo6ekZsr2np6f82HDWrFkTvb295du+ffvGdU4AqGUCkAk1f/78yOfzsXXr1vK2\
YrEYO3bsiNbW1tP+voaGhshms0NuAMC5cQ4gY66vry/27NlTvv/ee+/Frl27YubMmTFv3rxYtWpV\
fOMb34iPfexjMX/+/HjkkUeiubk5br755soNDQAJEYCMubfeeis+//nPl++vXr06IiJWrFgRzz33\
XPzVX/1VHD58OL761a/GwYMH4w/+4A/iRz/6UVx00UWVGhkAklJXKpVKlR4CzlaxWIxcLhe9vb3e\
DgaqktcxKsk5gAAAiRGAAACJEYAAAIkRgAAAiRGAUIX6+vrGdD8A0iIAocp0dXVFR0fHiN+dHPHB\
9y53dHREV1fXBE0GQLUQgFBF+vr6oru7OyIiOjs7TxuBhUIhOjs7IyKiu7vbSiAAQwhAqCKZTCbm\
zJlTvj9cBJ4cfxERc+bMiUwmM2EzQi1y2gW1RgBClcnn86eNwOHiL5/PT/iMUEucdkEt8lVwUIVO\
RN2J2Ovs7Iyenp4YGBgo7yP+4PydetpFRAz7/9Wpp11ks1kr71zQrABClTp1JVD8wdhz2gW1ygog\
VLF8Pl9e+bvj5Ts+2DgpYs8jeyo7GNSQ4VbcT2x32gXVSgBCFSsUCkNW/iIiYvCD7f4RgrHjtAtq\
jQCEKnXqykNMiojBD/5zpHOVgHNzagQODAzEf39oVUREZKc2xH/93/+nUqPBWROAUIWGe9tpzyN7\
hmwXgTD2Tj7t4oRJk+oiO/WiCk4FZ8+HQKDKjHTO0UiXiAHO33CnXQwOlqL4uyMVmgjOjRVAqCJ9\
fX1nPOF8uHOVMpmMTyXCeTr1h6/JkyfHf3n8qSGPW3GnWlgBhCqSyWSiqakpIkY+4fzklcCmpibx\
B+dpuJX3RYsWWXGnalkBhCrT3Nw8qovM5vN5K38wBs502kXE8JeIgQuZFUCoQqONOvEH52e0p12c\
uhLoO4G50AlAADgNp11Qq7wFDAAjcNoFtcgKIACcgdMuqDUCEAAgMQIQACAxAhAAIDECEAAgMQIQ\
ACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAg\
MQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECkIp65pln4qMf/WhcdNFF\
ce2118abb75Z6ZEAoOYJQCrmhRdeiNWrV8ejjz4aP//5z2PRokWxbNmy2L9/f6VHA4CaJgCpmL/9\
27+Ne+65J+6+++5YuHBhbNiwIaZNmxb/+I//WOnRAKCmCUAq4ujRo7Fz585YsmRJedukSZNiyZIl\
0d7eXsHJAKD2Ta70AKTpN7/5TRw/fjwaGxuHbG9sbIzdu3d/aP/+/v7o7+8v3y8Wi+M+IwDUKiuA\
VIV169ZFLpcr31paWio9EgBULQFIRVx22WXxkY98JHp6eoZs7+npiXw+/6H916xZE729veXbvn37\
JmpUAKg5ApCKqK+vj8WLF8fWrVvL2wYHB2Pr1q3R2tr6of0bGhoim80OuQEA58Y5gFTM6tWrY8WK\
FfHpT386rrnmmnjqqafi8OHDcffdd1d6NACoaQKQirnjjjviwIEDsXbt2igUCvGpT30qfvSjH33o\
gyEAwNiqK5VKpUoPAWerWCxGLpeL3t5ebwcDVcnrGJXkHEAAgMQIQACAxAhAAIDECEAAgMQIQACA\
xAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQI\
QACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAA\
gMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDE\
CEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAxtxjjz0Wn/nMZ2LatGkx\
Y8aMYffZu3dv3HjjjTFt2rSYPXt2fO1rX4uBgYGJHRQAEjW50gNQe44ePRq33357tLa2xj/8wz98\
6PHjx4/HjTfeGPl8Pn76059Gd3d33HnnnTFlypT45je/WYGJASAtdaVSqVTpIahNzz33XKxatSoO\
Hjw4ZPsrr7wSf/zHfxxdXV3R2NgYEREbNmyIv/7rv44DBw5EfX39GZ+7WCxGLpeL3t7eyGaz4zE+\
wLjyOkYleQuYCdfe3h6f/OQny/EXEbFs2bIoFovx7rvvVnAyAEiDt4CZcIVCYUj8RUT5fqFQGPb3\
9Pf3R39/f/l+sVgcvwEBoMZZAWRUHnrooairqxvxtnv37nH789etWxe5XK58a2lpGbc/CwBqnRVA\
RuXBBx+Mu+66a8R9Lr/88lE9Vz6fjzfffHPItp6envJjw1mzZk2sXr26fL9YLIpAADhHApBRmTVr\
VsyaNWtMnqu1tTUee+yx2L9/f8yePTsiIrZs2RLZbDYWLlw47O9paGiIhoaGMfnzASB1ApAxt3fv\
3nj//fdj7969cfz48di1a1dERCxYsCAymUwsXbo0Fi5cGF/+8pfjiSeeiEKhEA8//HC0tbWJPACY\
AC4Dw5i766674vvf//6Htm/bti2uv/76iIj493//97j33nvjtddei4svvjhWrFgRjz/+eEyePLqf\
SVw+Aah2XseoJAFIVfLCCVQ7r2NUkk8BAwAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAk\
RgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYA\
AgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIA\
JEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRG\
AAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGADKmfv3rX8fKlStj/vz5MXXq1Pj93//9ePTR\
R+Po0aND9vuXf/mX+MM//MO46KKLoqWlJZ544okKTQwA6Zlc6QGoLbt3747BwcH4u7/7u1iwYEG8\
8847cc8998Thw4fjW9/6VkREFIvFWLp0aSxZsiQ2bNgQb7/9dnzlK1+JGTNmxFe/+tUKHwEA1L66\
UqlUqvQQ1LYnn3wy1q9fH//2b/8WERHr16+Pr3/961EoFKK+vj4iIh566KHYvHlz7N69e1TPWSwW\
I5fLRW9vb2Sz2XGbHWC8eB2jkrwFzLjr7e2NmTNnlu+3t7fH5z73uXL8RUQsW7YsOjo64re//W0l\
RgSApAhAxtWePXviu9/9bvzFX/xFeVuhUIjGxsYh+524XygUhn2e/v7+KBaLQ24AwLkRgIzKQw89\
FHV1dSPeTn37trOzM774xS/G7bffHvfcc895/fnr1q2LXC5XvrW0tJzX8wFAypwDyKgcOHAg/uM/\
/mPEfS6//PLy27pdXV1x/fXXx3XXXRfPPfdcTJr0nz9r3HnnnVEsFmPz5s3lbdu2bYsbbrgh3n//\
/bjkkks+9Nz9/f3R399fvl8sFqOlpcW5M0DVcg4gleRTwIzKrFmzYtasWaPat7OzMz7/+c/H4sWL\
49lnnx0SfxERra2t8fWvfz2OHTsWU6ZMiYiILVu2xBVXXDFs/EVENDQ0RENDw/kdBAAQEd4CZox1\
dnbG9ddfH/PmzYtvfetbceDAgSgUCkPO7fvzP//zqK+vj5UrV8a7774bL7zwQjz99NOxevXqCk4O\
AOmwAsiY2rJlS+zZsyf27NkTc+fOHfLYibMNcrlc/PjHP462trZYvHhxXHbZZbF27VrXAASACeIc\
QKqSc2eAaud1jEryFjAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBi\
BCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQg\
AJyFvr6+Md0PKkEAAsAodXV1RUdHRxQKhRH3KxQK0dHREV1dXRM0GZwdAQgAo9DX1xfd3d0REdHZ\
2XnaCCwUCtHZ2RkREd3d3VYCuSAJQAAYhUwmE3PmzCnfHy4CT46/iIg5c+ZEJpOZsBlhtAQgAIxS\
Pp8/bQQOF3/5fH7CZ4TRmFzpAQCgmpyIuhOx19nZGT09PTEwMFDeR/xxoROAAHCWTo7A//HNn5W3\
/+nfXC3+qAreAgaAc5DP52Py5KHrKJMnTxZ/VAUBCADnoFAoDHnbNyJiYGDgjJeIgQuBt4AB4Cyd\
/IGPP/2bq2Py5MnlGDyx3UogFzIrgABwFob7tO+iRYvOeIkYuJAIQAAYpZEu9TLSJWLgQiMAAWAU\
+vr6znidv+Ei0DeBcCESgAAwCplMJpqamiJi5Ov8nRyBTU1NvgmEC5IPgQDAKDU3N0c2mz1j1OXz\
+chkMuKPC5YVQAA4C6ONOvHHhUwAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkxoWg\
qUqlUikiIorFYoUnATg3J16/TryewUQSgFSlQ4cORURES0tLhScBOD+HDh2KXC5X6TFITF3Jjx5U\
ocHBwejq6orp06dHXV1dpccZU8ViMVpaWmLfvn2RzWYrPc64cZy1xXGevVKpFIcOHYrm5uaYNMkZ\
WUwsK4BUpUmTJsXcuXMrPca4ymazNf0P6QmOs7Y4zrNj5Y9K8SMHAEBiBCAAQGIEIFxgGhoa4tFH\
H42GhoZKjzKuHGdtcZxQXXwIBAAgMVYAAQASIwABABIjAAEAEiMAAQASIwDhAvLYY4/FZz7zmZg2\
bVrMmDFj2H327t0bN954Y0ybNi1mz54dX/va12JgYGBiBz1PzzzzTHz0ox+Niy66KK699tp48803\
Kz3SeXv99dfjS1/6UjQ3N0ddXV1s3rx5yOOlUinWrl0bTU1NMXXq1FiyZEn86le/qsyw52jdunVx\
9dVXx/Tp02P27Nlx8803R0dHx5B9jhw5Em1tbXHppZdGJpOJW2+9NXp6eio08blZv359XHXVVeWL\
Pbe2tsYrr7xSfrwWjhEEIFxAjh49Grfffnvce++9wz5+/PjxuPHGG+Po0aPx05/+NL7//e/Hc889\
F2vXrp3gSc/dCy+8EKtXr45HH300fv7zn8eiRYti2bJlsX///kqPdl4OHz4cixYtimeeeWbYx594\
4on4zne+Exs2bIgdO3bExRdfHMuWLYsjR45M8KTnbvv27dHW1hZvvPFGbNmyJY4dOxZLly6Nw4cP\
l/d54IEH4qWXXooXX3wxtm/fHl1dXXHLLbdUcOqzN3fu3Hj88cdj586d8dZbb8UNN9wQN910U7z7\
7rsRURvHCFECLjjPPvtsKZfLfWj7P//zP5cmTZpUKhQK5W3r168vZbPZUn9//wROeO6uueaaUltb\
W/n+8ePHS83NzaV169ZVcKqxFRGlTZs2le8PDg6W8vl86cknnyxvO3jwYKmhoaH0gx/8oAITjo39\
+/eXIqK0ffv2Uqn0wTFNmTKl9OKLL5b3+dd//ddSRJTa29srNeaYuOSSS0p///d/X9PHSFqsAEIV\
aW9vj09+8pPR2NhY3rZs2bIoFovl1YkL2dGjR2Pnzp2xZMmS8rZJkybFkiVLor29vYKTja/33nsv\
CoXCkOPO5XJx7bXXVvVx9/b2RkTEzJkzIyJi586dcezYsSHHeeWVV8a8efOq9jiPHz8ezz//fBw+\
fDhaW1tr8hhJ0+RKDwCMXqFQGBJ/EVG+XygUKjHSWfnNb34Tx48fH/YYdu/eXaGpxt+Jv5vhjrsa\
/t6GMzg4GKtWrYrPfvaz8YlPfCIiPjjO+vr6D52/Wo3H+fbbb0dra2scOXIkMplMbNq0KRYuXBi7\
du2qmWMkbVYAYZw99NBDUVdXN+KtluOH2tTW1hbvvPNOPP/885UeZVxcccUVsWvXrtixY0fce++9\
sWLFivjlL39Z6bFgzFgBhHH24IMPxl133TXiPpdffvmoniufz3/oE7MnPn2Yz+fPab6JdNlll8VH\
PvKRD31isqenpyrmP1cnjq2npyeamprK23t6euJTn/pUhaY6d/fdd1+8/PLL8frrr8fcuXPL2/P5\
fBw9ejQOHjw4ZIWsGv9+6+vrY8GCBRERsXjx4vjZz34WTz/9dNxxxx01c4ykzQogjLNZs2bFlVde\
OeKtvr5+VM/V2toab7/99pBPzG7ZsiWy2WwsXLhwvA5hzNTX18fixYtj69at5W2Dg4OxdevWaG1t\
reBk42v+/PmRz+eHHHexWIwdO3ZU1XGXSqW47777YtOmTfGTn/wk5s+fP+TxxYsXx5QpU4YcZ0dH\
R+zdu7eqjnM4g4OD0d/fX9PHSFqsAMIFZO/evfH+++/H3r174/jx47Fr166IiFiwYEFkMplYunRp\
LFy4ML785S/HE088EYVCIR5++OFoa2uLhoaGyg4/SqtXr44VK1bEpz/96bjmmmviqaeeisOHD8fd\
d99d6dHOS19fX+zZs6d8/7333otdu3bFzJkzY968ebFq1ar4xje+ER/72Mdi/vz58cgjj0Rzc3Pc\
fPPNlRv6LLW1tcXGjRvjhz/8YUyfPr18zlsul4upU6dGLpeLlStXxurVq2PmzJmRzWbj/vvvj9bW\
1rjuuusqPP3orVmzJpYvXx7z5s2LQ4cOxcaNG+O1116LV199tWaOEVwGBi4gK1asKEXEh27btm0r\
7/PrX/+6tHz58tLUqVNLl112WenBBx8sHTt2rHJDn4Pvfve7pXnz5pXq6+tL11xzTemNN96o9Ejn\
bdu2bcP+3a1YsaJUKn1wKZhHHnmk1NjYWGpoaCh94QtfKHV0dFR26LM03PFFROnZZ58t7/O73/2u\
9Jd/+ZelSy65pDRt2rTSn/zJn5S6u7srN/Q5+MpXvlL6vd/7vVJ9fX1p1qxZpS984QulH//4x+XH\
a+EYoa5UKpUmPjsBAKgU5wACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYA\
AgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIA\
JEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACTm\
/wM/8peVg/PuJwAAAABJRU5ErkJggg==\
"


    /* set a timeout to make sure all the above elements are created before
       the object is initialized. */
    setTimeout(function() {
        animbf18fa8feeef42df9ff1917d1946c4bf = new Animation(frames, img_id, slider_id, 500.0,
                                 loop_select_id);
    }, 0);
  })()
</script>
</div>
</div>
</section>
<section id="running-the-algorithm-on-the-gpu" class="level2">
<h2 class="anchored" data-anchor-id="running-the-algorithm-on-the-gpu">Running the Algorithm on the GPU</h2>
<p>Instead of updating one data point at a time:</p>
<div class="sourceCode" id="cb91" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><span class="kw" style="color: #003B4F;">def</span> one_update(X):</span>
<span id="cb91-2">    <span class="cf" style="color: #003B4F;">for</span> i, x <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(X):</span>
<span id="cb91-3">        dist <span class="op" style="color: #5E5E5E;">=</span> torch.sqrt(((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb91-4">        weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist, <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb91-5">        X[i] <span class="op" style="color: #5E5E5E;">=</span> (weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">/</span>weight.<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<p>What if we updates one batch at a time on the GPU?</p>
<div class="cell" data-outputid="4e4708eb-f6ad-4c71-9a8b-dc5ec04ab5b7" data-execution_count="74">
<div class="sourceCode cell-code" id="cb92" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1">bs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb92-2">X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb92-3">x <span class="op" style="color: #5E5E5E;">=</span> X[:bs]</span>
<span id="cb92-4">x.shape,X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>(torch.Size([5, 2]), torch.Size([1500, 2]))</code></pre>
</div>
</div>
<p>To calculate the distance between the two, we have to first subtract them. To do this subtraction, the current dimensions won’t work (as 1500 is not compatible with 5):</p>
<div class="cell" data-outputid="50d7fd6a-10a3-4dba-bd94-73a600ac094a" data-execution_count="75">
<div class="sourceCode cell-code" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1">x<span class="op" style="color: #5E5E5E;">-</span>X</span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: The size of tensor a (5) must match the size of tensor b (1500) at non-singleton dimension 0</code></pre>
</div>
</div>
<p>Let’s think about what we are trying to do here. We want to subtract from each point in the batch <code>x</code> every point in the full set <code>X</code>. So each pair of 1500 coordinates need to be subtracted from each pair of 5 coordinates.</p>
<p>I find it easier to start with “just making the dimensions work” for broadcasting.</p>
<div class="cell" data-outputid="ebd280c5-981b-49d5-b4b1-465cf4cb2c59" data-execution_count="76">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">x[<span class="va" style="color: #111111;">None</span>].shape, X[:,<span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>(torch.Size([1, 5, 2]), torch.Size([1500, 1, 2]))</code></pre>
</div>
</div>
<p>Going right to left: the last dimension matches (2), 1 is compatible with 5 and 1 is compatible with 1500. We can subtract these two tensors.</p>
<div class="cell" data-outputid="b6a5c8c5-dd00-4747-c663-f38bc965afc1" data-execution_count="77">
<div class="sourceCode cell-code" id="cb98" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1">(x[<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">-</span>X[:,<span class="va" style="color: #111111;">None</span>]).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>torch.Size([1500, 5, 2])</code></pre>
</div>
</div>
<p>The result is 1500 sets of 5 coordinate pairs. The 5 coordinate pairs are the difference between the coordinates in batch <code>x</code> and a coordinate in <code>X</code>.</p>
<p>Checking this manually, let’s take the first point in <code>x</code>.</p>
<div class="cell" data-outputid="d5f5ddfb-e497-4742-c175-ebf6db35494a" data-execution_count="78">
<div class="sourceCode cell-code" id="cb100" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1">x[<span class="dv" style="color: #AD0000;">0</span>,:].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>torch.Size([2])</code></pre>
</div>
</div>
<p>The dimension of 2 is compatible with the last dimension of <code>X</code> so we can subtract these shapes directly.</p>
<div class="cell" data-outputid="a293bd2c-da84-4dbe-868c-f2a776042d98" data-execution_count="79">
<div class="sourceCode cell-code" id="cb102" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1">(x[<span class="dv" style="color: #AD0000;">0</span>,:] <span class="op" style="color: #5E5E5E;">-</span> X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<p>This difference is equal to the first item of the batch in the broadcasted version.</p>
<div class="cell" data-outputid="2effa53b-6762-4b72-9419-c7105cf63f07" data-execution_count="81">
<div class="sourceCode cell-code" id="cb104" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1">((x[<span class="dv" style="color: #AD0000;">0</span>,:] <span class="op" style="color: #5E5E5E;">-</span> X) <span class="op" style="color: #5E5E5E;">==</span> (x[<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">-</span>X[:,<span class="va" style="color: #111111;">None</span>])[:,<span class="dv" style="color: #AD0000;">0</span>,:]).<span class="bu" style="color: null;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>tensor(1.)</code></pre>
</div>
</div>
<p>With that under my belt, I’ll now visualize the broadcasting operation to better understand why the dimensions “just work”.</p>
<p>Adding the unit axis to <code>x</code> (our batch of 5 coordinates) as the first dimension is not as intuitive visually as it just adds a pair of brackets to the outside of the 5 coordinates. However, what this does is allow the set of 5 coordinates (as a group) to be broadcasted across another dimension of any size.</p>
<div class="cell" data-outputid="892f60a0-7101-4652-94b9-267b74ed5f4e" data-execution_count="82">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<pre><code>tensor([[29.764, 26.161],
        [28.472, 30.493],
        [27.549, 23.130],
        [23.500, 26.879],
        [27.327, 28.650]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ac571ee7-26d4-40e7-b3a8-08e0e5df58b3" data-execution_count="83">
<div class="sourceCode cell-code" id="cb108" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1">x[<span class="va" style="color: #111111;">None</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>tensor([[[29.764, 26.161],
         [28.472, 30.493],
         [27.549, 23.130],
         [23.500, 26.879],
         [27.327, 28.650]]])</code></pre>
</div>
</div>
<p>Adding the unit axis as the second dimension to <code>X</code> (our full set of 1500 coordinates) is more visually intuitive—we’ve added a pair of brackets around each pair of coordinates, making them broadcastable to any other dimension.</p>
<div class="cell" data-outputid="c12a9c8b-b0ff-41a4-9fde-23d5d1f6a456" data-execution_count="84">
<div class="sourceCode cell-code" id="cb110" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1">X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>tensor([[29.764, 26.161],
        [28.472, 30.493],
        [27.549, 23.130],
        ...,
        [32.214,  4.997],
        [30.872,  4.339],
        [28.347,  4.248]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e7b438ba-fae5-44fb-91bd-8cb7b9df97af" data-execution_count="86">
<div class="sourceCode cell-code" id="cb112" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1">X[:,<span class="va" style="color: #111111;">None</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>tensor([[[29.764, 26.161]],

        [[28.472, 30.493]],

        [[27.549, 23.130]],

        ...,

        [[32.214,  4.997]],

        [[30.872,  4.339]],

        [[28.347,  4.248]]])</code></pre>
</div>
</div>
<p>So our batch of 5 coordinates <code>x</code> can now be broadcasted as many times as needed, and each pair of coordinates in <code>X</code> can also be broadcasted as many times as needed.</p>
<p>The result: each pair of coordinates in <code>X</code> is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch. And the batch is broadcasted 1500 times so that each pair of coordinates in <code>X</code> can be subtracted from it.</p>
<p>Looking at each of those statements visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Each pair of coordinates in X is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Each pair of coordinates in X is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="The batch x is broadcasted 1500 times so that each pair of coordinates in X can be subtracted from it."><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/3.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">The batch <code>x</code> is broadcasted 1500 times so that each pair of coordinates in <code>X</code> can be subtracted from it.</figcaption><p></p>
</figure>
</div>
<p>With the understood, I can now continue with the batched implementation of the algorithm. With the correct shapes, thanks to adding unit axes, we can create a batched distance function:</p>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb114" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><span class="kw" style="color: #003B4F;">def</span> dist_b(a,b): <span class="cf" style="color: #003B4F;">return</span> (((a[<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">-</span>b[:,<span class="va" style="color: #111111;">None</span>])<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">2</span>)).sqrt()</span></code></pre></div>
</div>
<div class="cell" data-outputid="ce2e61e4-4895-472b-d120-d0844f6fbe51" data-execution_count="90">
<div class="sourceCode cell-code" id="cb115" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1">dist_b(x,X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>torch.Size([1500, 5])</code></pre>
</div>
</div>
<p>We now have 5 distances for each of the 1500 items in the dataset.</p>
<div class="cell" data-outputid="46dc7bba-8d45-40f6-c502-90d9438dba39" data-execution_count="91">
<div class="sourceCode cell-code" id="cb117" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1">dist_b(x,X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>tensor([[ 0.000,  4.521,  3.754,  6.305,  3.483],
        [ 4.521,  0.000,  7.421,  6.148,  2.170],
        [ 3.754,  7.421,  0.000,  5.518,  5.524],
        ...,
        [21.305, 25.769, 18.724, 23.553, 24.152],
        [21.850, 26.264, 19.083, 23.714, 24.568],
        [21.958, 26.246, 18.899, 23.144, 24.423]])</code></pre>
</div>
</div>
<p>The first row are the distances between the first coordinate pair in <code>X</code> and each of the coordinate pairs in the batch. The second row contains distances between the <em>second</em> coordinate pair in `X and each of the batch coordinate pairs. And so on an so forth for 1500 rows. Each with 5 distances representing the distances to the batch items.</p>
<p>We pass this tensor into our <code>gaussian</code> and get back our weights.</p>
<div class="cell" data-outputid="97cadee8-dfa3-4e93-cace-bc52cf9d31bc" data-execution_count="92">
<div class="sourceCode cell-code" id="cb119" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1">weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist_b(x, X), <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb119-2">weight, weight.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>(tensor([[    0.160,     0.031,     0.052,     0.007,     0.060],
         [    0.031,     0.160,     0.002,     0.008,     0.109],
         [    0.052,     0.002,     0.160,     0.014,     0.014],
         ...,
         [    0.000,     0.000,     0.000,     0.000,     0.000],
         [    0.000,     0.000,     0.000,     0.000,     0.000],
         [    0.000,     0.000,     0.000,     0.000,     0.000]]),
 torch.Size([1500, 5]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="09929ac2-c816-45e0-ea6c-fd4a2dff55d1" data-execution_count="93">
<div class="sourceCode cell-code" id="cb121" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1">weight[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>tensor([[0.160, 0.031, 0.052, 0.007, 0.060],
        [0.031, 0.160, 0.002, 0.008, 0.109],
        [0.052, 0.002, 0.160, 0.014, 0.014],
        [0.007, 0.008, 0.014, 0.160, 0.038],
        [0.060, 0.109, 0.014, 0.038, 0.160]])</code></pre>
</div>
</div>
<p>Looking at the first 5 rows of our weights we have a square matrix—the weights between the first 5 points (i.e.&nbsp;the points in our batch). From row 6 we have the weights from these 5 points to point 6.</p>
<p>Technically we could have a batch size of 1500 and the weights in full would be a square matrix.</p>
<p>Now for the fun part! Understanding broadcasting so we can perform the weighted average, which starts with an elementwise multiplication betwee the weights and the data points.</p>
<p>Conceptually we want something like this (example shown for the first two batch items’ weights)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Multiplying weights by X and summing down the columns to get a pair of coordinates"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/4.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Multiplying weights by <code>X</code> and summing down the columns to get a pair of coordinates</figcaption><p></p>
</figure>
</div>
<div class="cell" data-outputid="e2bc5d14-794d-431b-9fc9-36f9f77748ff" data-execution_count="94">
<div class="sourceCode cell-code" id="cb123" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1">weight.shape,X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>(torch.Size([1500, 5]), torch.Size([1500, 2]))</code></pre>
</div>
</div>
<p>The last dimension of each tensor is not compatible (5 and 2). We need to introduce a unit axis so that we can broadcast the 5 batch items to each of the 1500 coordinate pairs.</p>
<p>We’ll again start by “just making the dimensions work”, adding a unit axis to the end of <code>weight</code> and the beginning of <code>X</code>. Scanning the dimensions left to right: 1 and 2 are compatible, 5 and 1 are compatible, 1500 and 1500 are compatible.</p>
<div class="cell" data-outputid="eb218202-3664-40fd-878b-e5edefae4afb" data-execution_count="96">
<div class="sourceCode cell-code" id="cb125" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1">weight[...,<span class="va" style="color: #111111;">None</span>].shape, X[:,<span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="96">
<pre><code>(torch.Size([1500, 5, 1]), torch.Size([1500, 1, 2]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="88879916-329f-4984-a4ea-b78bb04ae309" data-execution_count="98">
<div class="sourceCode cell-code" id="cb127" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>]).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>torch.Size([1500, 5, 2])</code></pre>
</div>
</div>
<p>We’ll sum down the first dimension to get 5 pairs of coordinate.</p>
<div class="cell" data-outputid="799cde40-d374-42b5-90e3-71df21d6f19a" data-execution_count="100">
<div class="sourceCode cell-code" id="cb129" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>]).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>The first pair of coordinates <code>[296.880, 291.612]</code> are the sum of the first pair of elementwise products in each set of 5 batched items in each of the 1500 rows.</p>
<div class="cell" data-outputid="38638dce-e5bb-4d73-d797-f327004f65b2" data-execution_count="102">
<div class="sourceCode cell-code" id="cb131" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>tensor([[[    4.750,     4.175],
         [    0.926,     0.814],
         [    1.539,     1.352],
         [    0.197,     0.174],
         [    1.799,     1.581]],

        [[    0.886,     0.948],
         [    4.544,     4.866],
         [    0.055,     0.059],
         [    0.221,     0.237],
         [    3.117,     3.338]],

        [[    1.424,     1.196],
         [    0.054,     0.045],
         [    4.396,     3.691],
         [    0.385,     0.323],
         [    0.383,     0.321]],

        ...,

        [[    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000]],

        [[    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000]],

        [[    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000]]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="8b9975f5-7a26-4b50-c422-516c074f1457" data-execution_count="101">
<div class="sourceCode cell-code" id="cb133" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>])[:, <span class="dv" style="color: #AD0000;">0</span>,:]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>tensor([[    4.750,     4.175],
        [    0.886,     0.948],
        [    1.424,     1.196],
        ...,
        [    0.000,     0.000],
        [    0.000,     0.000],
        [    0.000,     0.000]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e933a913-9612-43f7-b045-e1cdfa54246c" data-execution_count="103">
<div class="sourceCode cell-code" id="cb135" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>])[:, <span class="dv" style="color: #AD0000;">0</span>,:].<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="103">
<pre><code>tensor([296.880, 291.612])</code></pre>
</div>
</div>
<p>Looking at this visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="5.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Elementwise multiplication of weight[...,None] and X[None] followed by sum(0) down the columns"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/5.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Elementwise multiplication of <code>weight[...,None]</code> and <code>X[None]</code> followed by <code>sum(0)</code> down the columns</figcaption><p></p>
</figure>
</div>
<div class="cell" data-outputid="24c589bb-5afd-4a22-b782-d02fda9014d0" data-execution_count="104">
<div class="sourceCode cell-code" id="cb137" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1">num <span class="op" style="color: #5E5E5E;">=</span> (weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>]).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb137-2">num.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<pre><code>torch.Size([5, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="c2cd5385-3d97-4466-f358-1909a3052608" data-execution_count="105">
<div class="sourceCode cell-code" id="cb139" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1">num</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="105">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>Since we are performing an elementwise multiplication follow by a sum, we can use Einstein Summation!</p>
<div class="cell" data-outputid="351261a0-1f6c-42c0-b9a3-59ba6a9d018b" data-execution_count="106">
<div class="sourceCode cell-code" id="cb141" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1">torch.einsum(<span class="st" style="color: #20794D;">'ij,ik-&gt;jk'</span>, weight, X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="106">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>Similary, we can also use matrix multiplication:</p>
<div class="cell" data-outputid="6ac52bec-aa75-4dcf-e09a-b109ceb88075" data-execution_count="107">
<div class="sourceCode cell-code" id="cb143" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1">weight.T<span class="op" style="color: #5E5E5E;">@</span>X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="107">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>To get our weighted average, we divide by the sum of weights.</p>
<div class="cell" data-outputid="c26dfad0-c4fe-41b3-c3a6-90e2bd57224b" data-execution_count="108">
<div class="sourceCode cell-code" id="cb145" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1">div <span class="op" style="color: #5E5E5E;">=</span> weight.<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>, keepdim<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>).T</span>
<span id="cb145-2">div.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>torch.Size([5, 1])</code></pre>
</div>
</div>
<p>We want to perform an elementwise division (each coordinate needs to be divided by the sum of weights) so we <code>keepdim</code>.</p>
<div class="cell" data-outputid="2faf142c-34ee-4d90-9960-0e47b687e9f1" data-execution_count="109">
<div class="sourceCode cell-code" id="cb147" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1">div</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="109">
<pre><code>tensor([[10.558],
        [17.315],
        [ 5.167],
        [10.983],
        [21.347]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ff53f7c2-c478-48b9-d730-25c8998caf58" data-execution_count="110">
<div class="sourceCode cell-code" id="cb149" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1">num<span class="op" style="color: #5E5E5E;">/</span>div</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>tensor([[28.118, 27.619],
        [27.519, 29.689],
        [27.145, 26.016],
        [25.334, 27.974],
        [27.047, 28.810]])</code></pre>
</div>
</div>
<p>Wrapping this into a new <code>meanshift</code> function. Each step now performs batched calculations.</p>
<div class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb151" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><span class="kw" style="color: #003B4F;">def</span> meanshift(data, bs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">500</span>):</span>
<span id="cb151-2">    n <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(data)</span>
<span id="cb151-3">    X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb151-4">    <span class="cf" style="color: #003B4F;">for</span> it <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb151-5">        <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">0</span>, n, bs):</span>
<span id="cb151-6">            s <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">slice</span>(i, <span class="bu" style="color: null;">min</span>(i<span class="op" style="color: #5E5E5E;">+</span>bs,n))</span>
<span id="cb151-7">            weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist_b(X[s], X), <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb151-8">            div <span class="op" style="color: #5E5E5E;">=</span> weight.<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>, keepdim<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>).T</span>
<span id="cb151-9">            X[s] <span class="op" style="color: #5E5E5E;">=</span> weight.T<span class="op" style="color: #5E5E5E;">@</span>X<span class="op" style="color: #5E5E5E;">/</span>div</span>
<span id="cb151-10">    <span class="cf" style="color: #003B4F;">return</span> X</span></code></pre></div>
</div>
<p>We can now utilize the GPU (since we’re doing batched calculations)</p>
<div class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb152" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1">data <span class="op" style="color: #5E5E5E;">=</span> data.cuda()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb153" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1">X <span class="op" style="color: #5E5E5E;">=</span> meanshift(data).cpu()</span></code></pre></div>
</div>
<div class="cell" data-outputid="e3206486-deea-434b-f00b-1c99fa7dc777" data-execution_count="117">
<div class="sourceCode cell-code" id="cb154" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">5</span> _<span class="op" style="color: #5E5E5E;">=</span>meanshift(data, <span class="dv" style="color: #AD0000;">1250</span>).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.37 ms ± 43.1 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)</code></pre>
</div>
</div>
<p>Using the GPU we cut the execution time from 1.5 seconds to 6 milliseconds to achieve the same result.</p>
<div class="cell" data-outputid="78b63bcb-5b59-428e-86a8-4ecb22c7b14c" data-execution_count="118">
<div class="sourceCode cell-code" id="cb156" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><span class="dv" style="color: #AD0000;">1500</span><span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">6</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>250.0</code></pre>
</div>
</div>
<div class="cell" data-outputid="5e20a9d4-31f5-49c6-a56c-3789affd7708" data-execution_count="119">
<div class="sourceCode cell-code" id="cb158" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1">plot_data(centroids, X, n_samples)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-92-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-92-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>If we perform the unbatched calculation using the GPU, we don’t see this speed up.</p>
<div class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb159" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><span class="kw" style="color: #003B4F;">def</span> meanshift(data, n<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb159-2">    X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb159-3">    <span class="cf" style="color: #003B4F;">for</span> it <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(n): one_update(X)</span>
<span id="cb159-4">    <span class="cf" style="color: #003B4F;">return</span> X</span></code></pre></div>
</div>
<div class="cell" data-outputid="b21cd686-b3e1-43ca-a8c3-7d419ab3633c" data-execution_count="122">
<div class="sourceCode cell-code" id="cb160" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><span class="op" style="color: #5E5E5E;">%</span>time X <span class="op" style="color: #5E5E5E;">=</span> meanshift(data.cuda()).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.33 s, sys: 969 µs, total: 1.33 s
Wall time: 1.33 s</code></pre>
</div>
</div>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Implementing mean shift clustering become an exercise in understanding broadcasting! The weighted average (elementwise multiplication followed by a summation down an axis) is well suited for broadcasting, Einstein Summation and matrix multiplication. Seeing the relationships between dimensions, and seeing how adding unit axes in a particular spot to allow for broadcasting gave me a deeper understanding of how tensor calculations work. We also saw a clear example of how the GPU only gives you a speedup if you perform batch operations on it.</p>
<p>I’m trying to grow my YouTube channel so if you’re interesting in this type of content, <a href="https://www.youtube.com/@vishal_learner">please subscribe!</a></p>


</section>

 ]]></description>
  <category>python</category>
  <category>machine learning</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index.html</guid>
  <pubDate>Sat, 31 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/1.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Exploring Precision in ColBERT Indexing and Retrieval</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-25-Exploring-ColBERT-Precision/index.html</link>
  <description><![CDATA[ 



<div class="cell" data-execution_count="4">
<details>
<summary>Ensure faiss-gpu is correctly installed</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> faiss</span>
<span id="cb1-2"><span class="bu" style="color: null;">hasattr</span>(faiss, <span class="st" style="color: #20794D;">"StandardGpuResources"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<details>
<summary>Show imports</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb3-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="im" style="color: #00769E;">from</span> colbert.data <span class="im" style="color: #00769E;">import</span> Queries</span>
<span id="cb3-5"><span class="im" style="color: #00769E;">from</span> colbert.infra <span class="im" style="color: #00769E;">import</span> Run, RunConfig, ColBERTConfig</span>
<span id="cb3-6"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Searcher</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb3-9"><span class="im" style="color: #00769E;">import</span> numpy</span>
<span id="cb3-10"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb3-11"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb3-12"><span class="im" style="color: #00769E;">import</span> tqdm</span>
<span id="cb3-13"><span class="im" style="color: #00769E;">import</span> glob</span>
<span id="cb3-14"><span class="im" style="color: #00769E;">import</span> re</span>
<span id="cb3-15"><span class="im" style="color: #00769E;">import</span> pytrec_eval</span>
<span id="cb3-16"><span class="im" style="color: #00769E;">import</span> pickle</span></code></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Show indexing + memory profiling script</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;">import</span> colbert</span>
<span id="cb4-2"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Indexer, Searcher</span>
<span id="cb4-3"><span class="im" style="color: #00769E;">from</span> colbert.infra <span class="im" style="color: #00769E;">import</span> Run, RunConfig, ColBERTConfig</span>
<span id="cb4-4"><span class="im" style="color: #00769E;">from</span> colbert.data <span class="im" style="color: #00769E;">import</span> Queries, Collection</span>
<span id="cb4-5"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb4-6"><span class="im" style="color: #00769E;">import</span> threading</span>
<span id="cb4-7"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb4-8"><span class="im" style="color: #00769E;">import</span> psutil</span>
<span id="cb4-9"><span class="im" style="color: #00769E;">from</span> datetime <span class="im" style="color: #00769E;">import</span> datetime</span>
<span id="cb4-10"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb4-11"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb4-12"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb4-13"><span class="im" style="color: #00769E;">import</span> argparse </span>
<span id="cb4-14"><span class="im" style="color: #00769E;">import</span> pynvml</span>
<span id="cb4-15"></span>
<span id="cb4-16"><span class="kw" style="color: #003B4F;">def</span> memory_monitor(stop_event, cpu_readings, gpu_readings):</span>
<span id="cb4-17">    pynvml.nvmlInit()</span>
<span id="cb4-18">    handle <span class="op" style="color: #5E5E5E;">=</span> pynvml.nvmlDeviceGetHandleByIndex(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb4-19">    </span>
<span id="cb4-20">    <span class="cf" style="color: #003B4F;">while</span> <span class="kw" style="color: #003B4F;">not</span> stop_event.is_set():</span>
<span id="cb4-21">        mem_cpu <span class="op" style="color: #5E5E5E;">=</span> psutil.Process().memory_info().rss <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb4-22">        info <span class="op" style="color: #5E5E5E;">=</span> pynvml.nvmlDeviceGetMemoryInfo(handle)</span>
<span id="cb4-23">        mem_gpu <span class="op" style="color: #5E5E5E;">=</span> info.used <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb4-24">        </span>
<span id="cb4-25">        cpu_readings.append((datetime.now(), mem_cpu))</span>
<span id="cb4-26">        gpu_readings.append((datetime.now(), mem_gpu))</span>
<span id="cb4-27">        time.sleep(<span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb4-28"></span>
<span id="cb4-29"><span class="kw" style="color: #003B4F;">def</span> log_memory(index_name, passages):</span>
<span id="cb4-30">    stop_event <span class="op" style="color: #5E5E5E;">=</span> threading.Event()</span>
<span id="cb4-31">    cpu_readings <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-32">    gpu_readings <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-33">    monitor_thread <span class="op" style="color: #5E5E5E;">=</span> threading.Thread(target<span class="op" style="color: #5E5E5E;">=</span>memory_monitor, args<span class="op" style="color: #5E5E5E;">=</span>(stop_event, cpu_readings, gpu_readings))</span>
<span id="cb4-34">    monitor_thread.start()</span>
<span id="cb4-35"></span>
<span id="cb4-36">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb4-37">        <span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, rank<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)):</span>
<span id="cb4-38">            config <span class="op" style="color: #5E5E5E;">=</span> ColBERTConfig(</span>
<span id="cb4-39">                doc_maxlen<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">220</span>,</span>
<span id="cb4-40">                nbits<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>,</span>
<span id="cb4-41">                dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">96</span>,</span>
<span id="cb4-42">                kmeans_niters<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb4-43">                index_bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32</span>,</span>
<span id="cb4-44">                bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb4-45">                checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>,</span>
<span id="cb4-46">                avoid_fork_if_possible<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span></span>
<span id="cb4-47">            )</span>
<span id="cb4-48">        </span>
<span id="cb4-49">            indexer <span class="op" style="color: #5E5E5E;">=</span> Indexer(checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>, config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb4-50">            index_path <span class="op" style="color: #5E5E5E;">=</span> indexer.index(name<span class="op" style="color: #5E5E5E;">=</span>index_name, collection<span class="op" style="color: #5E5E5E;">=</span>passages[<span class="st" style="color: #20794D;">"text"</span>], overwrite<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb4-51">    <span class="cf" style="color: #003B4F;">finally</span>:</span>
<span id="cb4-52">        stop_event.<span class="bu" style="color: null;">set</span>()</span>
<span id="cb4-53">        monitor_thread.join()</span>
<span id="cb4-54">    </span>
<span id="cb4-55">    <span class="cf" style="color: #003B4F;">return</span> cpu_readings, gpu_readings</span>
<span id="cb4-56"></span>
<span id="cb4-57"><span class="kw" style="color: #003B4F;">def</span> main():</span>
<span id="cb4-58">    parser <span class="op" style="color: #5E5E5E;">=</span> argparse.ArgumentParser(description<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'fp'</span>)</span>
<span id="cb4-59">    parser.add_argument(<span class="st" style="color: #20794D;">'--fp'</span>, <span class="bu" style="color: null;">type</span><span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span>, default<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"fp32"</span>, <span class="bu" style="color: null;">help</span><span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Floating point precision used'</span>)</span>
<span id="cb4-60">    args <span class="op" style="color: #5E5E5E;">=</span> parser.parse_args()</span>
<span id="cb4-61">    fp <span class="op" style="color: #5E5E5E;">=</span> args.fp</span>
<span id="cb4-62">        </span>
<span id="cb4-63">    dataset_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"ConditionalQA"</span></span>
<span id="cb4-64">    index_name <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'ColBERT_</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb4-65">    passages <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-corpus"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb4-66"></span>
<span id="cb4-67">    cpu_readings, gpu_readings <span class="op" style="color: #5E5E5E;">=</span> log_memory(index_name, passages)</span>
<span id="cb4-68"></span>
<span id="cb4-69">    <span class="co" style="color: #5E5E5E;"># CPU RAM artifacts</span></span>
<span id="cb4-70">    start_time <span class="op" style="color: #5E5E5E;">=</span> cpu_readings[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb4-71">    index <span class="op" style="color: #5E5E5E;">=</span> [(t <span class="op" style="color: #5E5E5E;">-</span> start_time).total_seconds() <span class="cf" style="color: #003B4F;">for</span> t, _ <span class="kw" style="color: #003B4F;">in</span> cpu_readings]</span>
<span id="cb4-72">    cpu_readings <span class="op" style="color: #5E5E5E;">=</span> pd.Series([mem <span class="cf" style="color: #003B4F;">for</span> _, mem <span class="kw" style="color: #003B4F;">in</span> cpu_readings], index<span class="op" style="color: #5E5E5E;">=</span>index, name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"mem_gb"</span> )</span>
<span id="cb4-73">    cpu_readings.index.name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"time_secs"</span></span>
<span id="cb4-74">    cpu_readings.plot(title<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f'ColBERT CPU RAM (</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">)'</span>, xlabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Time (sec)'</span>, ylabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Memory (GB)'</span>)</span>
<span id="cb4-75">    plt.tight_layout()</span>
<span id="cb4-76">    plt.savefig(<span class="ss" style="color: #20794D;">f'colbert_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_cpu_readings.png'</span>)</span>
<span id="cb4-77">    plt.close()</span>
<span id="cb4-78">    cpu_readings.to_csv(<span class="ss" style="color: #20794D;">f"colbert_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_cpu_readings.csv"</span>)</span>
<span id="cb4-79"></span>
<span id="cb4-80">    <span class="co" style="color: #5E5E5E;"># GPU RAM artifacts</span></span>
<span id="cb4-81">    start_time <span class="op" style="color: #5E5E5E;">=</span> gpu_readings[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb4-82">    index <span class="op" style="color: #5E5E5E;">=</span> [(t <span class="op" style="color: #5E5E5E;">-</span> start_time).total_seconds() <span class="cf" style="color: #003B4F;">for</span> t, _ <span class="kw" style="color: #003B4F;">in</span> gpu_readings]</span>
<span id="cb4-83">    gpu_readings <span class="op" style="color: #5E5E5E;">=</span> pd.Series([mem <span class="cf" style="color: #003B4F;">for</span> _, mem <span class="kw" style="color: #003B4F;">in</span> gpu_readings], index<span class="op" style="color: #5E5E5E;">=</span>index, name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"mem_gb"</span> )</span>
<span id="cb4-84">    gpu_readings.index.name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"time_secs"</span></span>
<span id="cb4-85">    gpu_readings.plot(title<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f'ColBERT GPU RAM (</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">)'</span>, xlabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Time (sec)'</span>, ylabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Memory (GB)'</span>)</span>
<span id="cb4-86">    plt.tight_layout()</span>
<span id="cb4-87">    plt.savefig(<span class="ss" style="color: #20794D;">f'colbert_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_gpu_readings.png'</span>)</span>
<span id="cb4-88">    plt.close()</span>
<span id="cb4-89">    gpu_readings.to_csv(<span class="ss" style="color: #20794D;">f"colbert_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_gpu_readings.csv"</span>)</span>
<span id="cb4-90"></span>
<span id="cb4-91"><span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">__name__</span> <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"__main__"</span>:</span>
<span id="cb4-92">    main()</span></code></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Show Recall calculation script</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb5-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="im" style="color: #00769E;">from</span> colbert.data <span class="im" style="color: #00769E;">import</span> Queries</span>
<span id="cb5-5"><span class="im" style="color: #00769E;">from</span> colbert.infra <span class="im" style="color: #00769E;">import</span> Run, RunConfig, ColBERTConfig</span>
<span id="cb5-6"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Searcher</span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb5-9"><span class="im" style="color: #00769E;">import</span> numpy</span>
<span id="cb5-10"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb5-11"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb5-12"><span class="im" style="color: #00769E;">import</span> tqdm</span>
<span id="cb5-13"><span class="im" style="color: #00769E;">import</span> glob</span>
<span id="cb5-14"><span class="im" style="color: #00769E;">import</span> re</span>
<span id="cb5-15"><span class="im" style="color: #00769E;">import</span> pytrec_eval</span>
<span id="cb5-16"><span class="im" style="color: #00769E;">import</span> argparse </span>
<span id="cb5-17"><span class="im" style="color: #00769E;">import</span> pickle</span>
<span id="cb5-18"></span>
<span id="cb5-19"><span class="kw" style="color: #003B4F;">def</span> get_qrels(qrels_rows):</span>
<span id="cb5-20">    qrels <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb5-21">    <span class="cf" style="color: #003B4F;">for</span> qrel_row <span class="kw" style="color: #003B4F;">in</span> qrels_rows:</span>
<span id="cb5-22">        qid <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"query_id"</span>]</span>
<span id="cb5-23">        pid <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"corpus_id"</span>]</span>
<span id="cb5-24">        rel <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"score"</span>]</span>
<span id="cb5-25">        qrels.setdefault(qid, {})</span>
<span id="cb5-26">        qrels[qid][pid] <span class="op" style="color: #5E5E5E;">=</span> rel</span>
<span id="cb5-27">    </span>
<span id="cb5-28">    <span class="cf" style="color: #003B4F;">return</span> qrels</span>
<span id="cb5-29"></span>
<span id="cb5-30"><span class="kw" style="color: #003B4F;">def</span> _recall(qrels, res):</span>
<span id="cb5-31">    evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb5-32">    metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(res)</span>
<span id="cb5-33">    <span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb5-34"></span>
<span id="cb5-35">    mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb5-36">    <span class="cf" style="color: #003B4F;">return</span> mean_recall</span>
<span id="cb5-37"></span>
<span id="cb5-38"></span>
<span id="cb5-39">dataset_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"ConditionalQA"</span></span>
<span id="cb5-40">queries <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-queries"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb5-41">passages <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-corpus"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb5-42">qrels_rows <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-qrels"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb5-43">qrels <span class="op" style="color: #5E5E5E;">=</span> get_qrels(qrels_rows)</span>
<span id="cb5-44"><span class="bu" style="color: null;">print</span>(dataset_name)</span>
<span id="cb5-45"></span>
<span id="cb5-46">queries_dict <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb5-47"><span class="cf" style="color: #003B4F;">for</span> item <span class="kw" style="color: #003B4F;">in</span> queries: queries_dict[item[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> item[<span class="st" style="color: #20794D;">'text'</span>]</span>
<span id="cb5-48"></span>
<span id="cb5-49"><span class="kw" style="color: #003B4F;">def</span> main():</span>
<span id="cb5-50">    parser <span class="op" style="color: #5E5E5E;">=</span> argparse.ArgumentParser(description<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'index'</span>)</span>
<span id="cb5-51">    parser.add_argument(<span class="st" style="color: #20794D;">'--index'</span>, <span class="bu" style="color: null;">type</span><span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span>, default<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">""</span>, <span class="bu" style="color: null;">help</span><span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Index name'</span>)</span>
<span id="cb5-52">    args <span class="op" style="color: #5E5E5E;">=</span> parser.parse_args()</span>
<span id="cb5-53">    index <span class="op" style="color: #5E5E5E;">=</span> args.index</span>
<span id="cb5-54">    </span>
<span id="cb5-55">    <span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb5-56">        searcher <span class="op" style="color: #5E5E5E;">=</span> Searcher(</span>
<span id="cb5-57">            index<span class="op" style="color: #5E5E5E;">=</span>index,</span>
<span id="cb5-58">            config<span class="op" style="color: #5E5E5E;">=</span>ColBERTConfig(</span>
<span id="cb5-59">                    ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb5-60">                    centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.45</span>,</span>
<span id="cb5-61">                    ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb5-62">                )</span>
<span id="cb5-63">        )</span>
<span id="cb5-64">    </span>
<span id="cb5-65">        _queries <span class="op" style="color: #5E5E5E;">=</span> Queries(data<span class="op" style="color: #5E5E5E;">=</span>queries_dict)</span>
<span id="cb5-66">        ranking <span class="op" style="color: #5E5E5E;">=</span> searcher.search_all(_queries, k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb5-67"></span>
<span id="cb5-68">    colbert_results <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb5-69"></span>
<span id="cb5-70">    <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> ranking.todict().keys():</span>
<span id="cb5-71">        colbert_scores <span class="op" style="color: #5E5E5E;">=</span> ranking.todict()[qid]</span>
<span id="cb5-72">        colbert_results[qid] <span class="op" style="color: #5E5E5E;">=</span> {passages[idx][<span class="st" style="color: #20794D;">'_id'</span>]: score <span class="cf" style="color: #003B4F;">for</span> idx, _, score <span class="kw" style="color: #003B4F;">in</span> colbert_scores}</span>
<span id="cb5-73"></span>
<span id="cb5-74">    <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"colbert_results_</span><span class="sc" style="color: #5E5E5E;">{</span>index<span class="sc" style="color: #5E5E5E;">.</span>split(<span class="st" style="color: #20794D;">'_'</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">.pkl"</span>, <span class="st" style="color: #20794D;">'wb'</span>) <span class="im" style="color: #00769E;">as</span> <span class="bu" style="color: null;">file</span>: pickle.dump(colbert_results, <span class="bu" style="color: null;">file</span>)</span>
<span id="cb5-75">    <span class="bu" style="color: null;">print</span>(_recall(qrels, colbert_results))</span>
<span id="cb5-76"></span>
<span id="cb5-77"><span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">__name__</span> <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"__main__"</span>:</span>
<span id="cb5-78">    main()</span></code></pre></div>
</details>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I ran an experiment to explore the differences between FP32 full precision and mixed precision in ColBERT indexing and retrieval. This was purely a curiosity-driven exploration - not claiming this is best practice, just wanted to see if there were any differences. This notebook shares my findings. I use the <a href="https://huggingface.co/datasets/UKPLab/dapr/viewer/ConditionalQA-docs">UKPLab/DAPR ConditionalQA dataset</a> for this exercise.</p>
<p><strong>What I did:</strong></p>
<ul>
<li>Created <a href="https://github.com/vishalbakshi/ColBERT/commits/mixed_precision_false/">a fork of ColBERT</a> and turned off all mixed precision conversions</li>
<li>Used Claude and ChatGPT to help identify all the places that needed changes (including CUDA kernels)</li>
<li>Ran indexing experiments on the UKPLab’s ConditionalQA dataset (70k documents)</li>
<li>Tracked memory usage during indexing (see script above)</li>
<li>Compared recall performance and retrieved passages (see script above)</li>
<li>Analyzed the resulting index artifacts</li>
</ul>
<p><strong>Key findings:</strong></p>
<ul>
<li>Mixed precision took 2.5x longer to index (180s vs 70s) - wasn’t expecting that</li>
<li>Mixed precision used slightly more GPU memory, full precision used more CPU memory</li>
<li>Full precision gave a tiny 0.3% recall boost (basically negligible)</li>
<li>14% of retrieved passages were different between the two approaches</li>
<li>The centroids created during indexing were significantly different</li>
<li>Different mappings between passage IDs and centroids</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aiNQ4I8YaD0?si=OKvaUtumf7q1qGYf" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="indexing-time" class="level2">
<h2 class="anchored" data-anchor-id="indexing-time">Indexing Time</h2>
<p>I was surprised to see that using mixed precision resulted in a much longer indexing time. I wonder if that would still hold over multiple iterations of indexing.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Indexing Time (seconds)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">fp32</td>
<td style="text-align: center;">70</td>
</tr>
<tr class="even">
<td style="text-align: center;">amp</td>
<td style="text-align: center;">180</td>
</tr>
</tbody>
</table>
</section>
<section id="maximum-memory-usage" class="level2">
<h2 class="anchored" data-anchor-id="maximum-memory-usage">Maximum Memory Usage</h2>
<p>Another surprise—mixed precision actually uses <em>more</em> GPU memory than full precision.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Max GPU Mem (GB)</th>
<th style="text-align: center;">Max CPU Mem (GB)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">fp32</td>
<td style="text-align: center;">5.51</td>
<td style="text-align: center;">0.824</td>
</tr>
<tr class="even">
<td style="text-align: center;">amp</td>
<td style="text-align: center;">5.78</td>
<td style="text-align: center;">0.814</td>
</tr>
</tbody>
</table>
</section>
<section id="recall10" class="level2">
<h2 class="anchored" data-anchor-id="recall10">Recall@10</h2>
<p>The differences in Recall@10 is negligible, the full precision index has a slight advantage.</p>
<p>fp32: 0.13034885692197787</p>
<p>amp: 0.1299388528219369</p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">(<span class="fl" style="color: #AD0000;">0.13034885692197787</span> <span class="op" style="color: #5E5E5E;">-</span> <span class="fl" style="color: #AD0000;">0.1299388528219369</span>)<span class="op" style="color: #5E5E5E;">/</span><span class="fl" style="color: #AD0000;">0.1299388528219369</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>0.003155361857802613</code></pre>
</div>
</div>
</section>
<section id="comparing-retrieved-passages-and-scores" class="level2">
<h2 class="anchored" data-anchor-id="comparing-retrieved-passages-and-scores">Comparing Retrieved Passages and Scores</h2>
<p>Out of the 2710 total passages retrieved, 388 passages were retrieved using one index but not the other—that’s about a 14% difference in retrieved passages due to a difference in precision.</p>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'colbert_results_fp32.pkl'</span>, <span class="st" style="color: #20794D;">'rb'</span>) <span class="im" style="color: #00769E;">as</span> <span class="bu" style="color: null;">file</span>: colbert_results_fp32 <span class="op" style="color: #5E5E5E;">=</span> pickle.load(<span class="bu" style="color: null;">file</span>)</span>
<span id="cb8-2"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'colbert_results_amp.pkl'</span>, <span class="st" style="color: #20794D;">'rb'</span>) <span class="im" style="color: #00769E;">as</span> <span class="bu" style="color: null;">file</span>: colbert_results_amp <span class="op" style="color: #5E5E5E;">=</span> pickle.load(<span class="bu" style="color: null;">file</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">colbert_results_fp32.keys() <span class="op" style="color: #5E5E5E;">==</span> colbert_results_amp.keys()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">colbert_results_fp32[<span class="st" style="color: #20794D;">'dev-0'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>{'265-59': 29.345699310302734,
 '8-116': 29.341297149658203,
 '8-118': 29.336307525634766,
 '8-67': 29.32498550415039,
 '8-9': 29.2913875579834,
 '8-70': 29.290199279785156,
 '270-51': 29.28421401977539,
 '40-29': 29.28375244140625,
 '107-110': 29.282079696655273,
 '459-115': 29.28005599975586}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">n_diffs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb13-2"><span class="cf" style="color: #003B4F;">for</span> qid, fp32_res <span class="kw" style="color: #003B4F;">in</span> colbert_results_fp32.items():</span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;">for</span> pid <span class="kw" style="color: #003B4F;">in</span> fp32_res.keys():</span>
<span id="cb13-4">        <span class="cf" style="color: #003B4F;">if</span> pid <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> colbert_results_amp[qid].keys(): </span>
<span id="cb13-5">            n_diffs <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb13-6"> </span>
<span id="cb13-7"><span class="cf" style="color: #003B4F;">for</span> qid, amp_res <span class="kw" style="color: #003B4F;">in</span> colbert_results_amp.items():</span>
<span id="cb13-8">    <span class="cf" style="color: #003B4F;">for</span> pid <span class="kw" style="color: #003B4F;">in</span> amp_res.keys():</span>
<span id="cb13-9">        <span class="cf" style="color: #003B4F;">if</span> pid <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> colbert_results_fp32[qid].keys(): </span>
<span id="cb13-10">            n_diffs <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb13-11"></span>
<span id="cb13-12">n_diffs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>388</code></pre>
</div>
</div>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">n_diffs<span class="op" style="color: #5E5E5E;">/</span>(<span class="dv" style="color: #AD0000;">271</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>0.14317343173431735</code></pre>
</div>
</div>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">colbert_results_fp32[<span class="st" style="color: #20794D;">'dev-0'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>{'265-59': 29.345699310302734,
 '8-116': 29.341297149658203,
 '8-118': 29.336307525634766,
 '8-67': 29.32498550415039,
 '8-9': 29.2913875579834,
 '8-70': 29.290199279785156,
 '270-51': 29.28421401977539,
 '40-29': 29.28375244140625,
 '107-110': 29.282079696655273,
 '459-115': 29.28005599975586}</code></pre>
</div>
</div>
<p>Overall, the full precision index results in a slightly lower retrieved passage score.</p>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">total_amp_score <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb19-2"><span class="cf" style="color: #003B4F;">for</span> qid, amp_res <span class="kw" style="color: #003B4F;">in</span> colbert_results_amp.items():</span>
<span id="cb19-3">    <span class="cf" style="color: #003B4F;">for</span> score <span class="kw" style="color: #003B4F;">in</span> amp_res.values(): total_amp_score <span class="op" style="color: #5E5E5E;">+=</span> score</span>
<span id="cb19-4">total_amp_score</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>80438.375</code></pre>
</div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">total_fp32_score <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb21-2"><span class="cf" style="color: #003B4F;">for</span> qid, fp32_res <span class="kw" style="color: #003B4F;">in</span> colbert_results_fp32.items():</span>
<span id="cb21-3">    <span class="cf" style="color: #003B4F;">for</span> score <span class="kw" style="color: #003B4F;">in</span> fp32_res.values(): total_fp32_score <span class="op" style="color: #5E5E5E;">+=</span> score</span>
<span id="cb21-4">total_fp32_score</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>80435.61682701111</code></pre>
</div>
</div>
</section>
<section id="comparing-index-artifacts" class="level2">
<h2 class="anchored" data-anchor-id="comparing-index-artifacts">Comparing Index Artifacts</h2>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">colbert_fp32_root <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"./experiments/default/indexes/ColBERT_ConditionalQA_fp32"</span></span>
<span id="cb23-2">colbert_amp_root  <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"./experiments/default/indexes/ColBERT_ConditionalQA_amp"</span></span></code></pre></div>
</div>
<section id="metadata.json" class="level3">
<h3 class="anchored" data-anchor-id="metadata.json">metadata.json</h3>
<p>Both indexes (full precision and mixed precision) produce the same metadata.json.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">params <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb24-2">    <span class="st" style="color: #20794D;">"index_bsize"</span>,</span>
<span id="cb24-3">    <span class="st" style="color: #20794D;">"nbits"</span>,</span>
<span id="cb24-4">    <span class="st" style="color: #20794D;">"kmeans_niters"</span>,</span>
<span id="cb24-5">    <span class="st" style="color: #20794D;">"dim"</span>,</span>
<span id="cb24-6">    <span class="st" style="color: #20794D;">"rank"</span>,</span>
<span id="cb24-7">    <span class="st" style="color: #20794D;">"gpus"</span>,</span>
<span id="cb24-8">    <span class="st" style="color: #20794D;">"nranks"</span>,</span>
<span id="cb24-9">    <span class="st" style="color: #20794D;">"num_chunks"</span>,</span>
<span id="cb24-10">    <span class="st" style="color: #20794D;">"num_partitions"</span>,</span>
<span id="cb24-11">    <span class="st" style="color: #20794D;">"num_embeddings"</span>,</span>
<span id="cb24-12">    <span class="st" style="color: #20794D;">"avg_doclen"</span></span>
<span id="cb24-13">    ]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_fp32_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f: colbert_fp32_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb25-2"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_amp_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f: colbert_amp_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> params:</span>
<span id="cb26-2">    <span class="cf" style="color: #003B4F;">if</span> p <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> [<span class="st" style="color: #20794D;">"num_chunks"</span>, <span class="st" style="color: #20794D;">"num_partitions"</span>, <span class="st" style="color: #20794D;">"num_embeddings"</span>, <span class="st" style="color: #20794D;">"avg_doclen"</span>]: <span class="cf" style="color: #003B4F;">assert</span> colbert_fp32_metadata[<span class="st" style="color: #20794D;">'config'</span>][p] <span class="op" style="color: #5E5E5E;">==</span> colbert_amp_metadata[<span class="st" style="color: #20794D;">'config'</span>][p], p</span>
<span id="cb26-3">    <span class="cf" style="color: #003B4F;">elif</span> p <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"avg_doclen"</span>: <span class="cf" style="color: #003B4F;">assert</span> (colbert_fp32_metadata[p] <span class="op" style="color: #5E5E5E;">-</span> colbert_amp_metadata[p]) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="fl" style="color: #AD0000;">1e-7</span></span>
<span id="cb26-4">    <span class="cf" style="color: #003B4F;">else</span>: <span class="cf" style="color: #003B4F;">assert</span> colbert_fp32_metadata[p] <span class="op" style="color: #5E5E5E;">==</span> colbert_amp_metadata[p], p</span></code></pre></div>
</div>
</section>
<section id="centroids.pt" class="level3">
<h3 class="anchored" data-anchor-id="centroids.pt">centroids.pt</h3>
<p>There is a significant difference in centroids—meaning that the sampled document token embeddings and their clusters are different based on the type of precision used.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">colbert_fp32_centroids <span class="op" style="color: #5E5E5E;">=</span> torch.load(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_fp32_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/centroids.pt"</span>)</span>
<span id="cb27-2">colbert_amp_centroids <span class="op" style="color: #5E5E5E;">=</span> torch.load(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_amp_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/centroids.pt"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">torch.allclose(colbert_fp32_centroids, colbert_amp_centroids.<span class="bu" style="color: null;">float</span>())</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>False</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">torch.allclose(colbert_fp32_centroids.half(), colbert_amp_centroids)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>False</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">torch.allclose(colbert_fp32_centroids, colbert_amp_centroids.<span class="bu" style="color: null;">float</span>(), atol<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1e-0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">colbert_fp32_centroids.flatten().shape, colbert_amp_centroids.flatten().shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>(torch.Size([1572864]), torch.Size([1572864]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">plt.scatter(colbert_fp32_centroids.flatten().cpu().numpy(), colbert_amp_centroids.flatten().cpu().numpy(), s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-24-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-25-Exploring-ColBERT-Precision/index_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="ivf.pid.pt" class="level3">
<h3 class="anchored" data-anchor-id="ivf.pid.pt">ivf.pid.pt</h3>
<p>Finally, there is a difference in mappings between passages IDs and centroid IDs. Interestingly, mixed precision results in more passage IDs mapped to centroids.</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">colbert_fp32_ivf <span class="op" style="color: #5E5E5E;">=</span> torch.load(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_fp32_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/ivf.pid.pt"</span>)</span>
<span id="cb37-2">colbert_amp_ivf  <span class="op" style="color: #5E5E5E;">=</span> torch.load(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_amp_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/ivf.pid.pt"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">colbert_fp32_ivf[<span class="dv" style="color: #AD0000;">0</span>].shape, colbert_amp_ivf[<span class="dv" style="color: #AD0000;">0</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>(torch.Size([963143]), torch.Size([975457]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">colbert_amp_ivf[<span class="dv" style="color: #AD0000;">0</span>].shape[<span class="dv" style="color: #AD0000;">0</span>]<span class="op" style="color: #5E5E5E;">-</span>colbert_fp32_ivf[<span class="dv" style="color: #AD0000;">0</span>].shape[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>12314</code></pre>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">colbert_fp32_ivf[<span class="dv" style="color: #AD0000;">1</span>].shape, colbert_amp_ivf[<span class="dv" style="color: #AD0000;">1</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>(torch.Size([16384]), torch.Size([16384]))</code></pre>
</div>
</div>
</section>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>This is just one small dataset with short documents (avg 15 tokens). Sample size of one. I also might have missed some precision conversions in my implementation. Don’t take this as definitive - just an interesting exploration of how precision affects the ColBERT pipeline. Here’s a summary again of my key findings:</p>
<ul>
<li>Mixed precision took 2.5x longer to index (180s vs 70s) - wasn’t expecting that</li>
<li>Mixed precision used slightly more GPU memory, full precision used more CPU memory</li>
<li>Full precision gave a tiny 0.3% recall boost (basically negligible)</li>
<li>14% of retrieved passages were different between the two approaches</li>
<li>The centroids created during indexing were significantly different</li>
<li>Different mappings between passage IDs and centroids</li>
</ul>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>ColBERT</category>
  <category>information retrieval</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-25-Exploring-ColBERT-Precision/index.html</guid>
  <pubDate>Sun, 25 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>The Evolution of Matrix Multiplication (fastai course Part 2 Lessons 11 and 12)</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/index.html</link>
  <description><![CDATA[ 



<div class="cell" data-outputid="47621598-8fd6-4b6a-9893-4dc62cc9ee45" data-execution_count="2">
<details>
<summary>Show setup code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># !conda install -y -c nvidia/label/cuda-12.8.0 cuda-toolkit</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;"># !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;"># !conda install -y numba</span></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;"># !conda install -y fastcore -c fastai</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> pickle, gzip, math, os, time, shutil</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> urllib.request <span class="im" style="color: #00769E;">import</span> urlretrieve</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> tensor</span>
<span id="cb1-11"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-12"><span class="im" style="color: #00769E;">from</span> numba <span class="im" style="color: #00769E;">import</span> njit</span>
<span id="cb1-13"><span class="im" style="color: #00769E;">from</span> numpy <span class="im" style="color: #00769E;">import</span> array</span>
<span id="cb1-14"><span class="im" style="color: #00769E;">from</span> fastcore.test <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="im" style="color: #00769E;">from</span> numba <span class="im" style="color: #00769E;">import</span> cuda</span>
<span id="cb1-17"></span>
<span id="cb1-18">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb1-19">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>)</span>
<span id="cb1-20"></span>
<span id="cb1-21">MNIST_URL<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'</span></span>
<span id="cb1-22">path_data <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'data'</span>)</span>
<span id="cb1-23">path_data.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb1-24">path_gz <span class="op" style="color: #5E5E5E;">=</span> path_data<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'mnist.pkl.gz'</span></span>
<span id="cb1-25"></span>
<span id="cb1-26"></span>
<span id="cb1-27"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> path_gz.exists(): urlretrieve(MNIST_URL, path_gz)</span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="cf" style="color: #003B4F;">with</span> gzip.<span class="bu" style="color: null;">open</span>(path_gz, <span class="st" style="color: #20794D;">'rb'</span>) <span class="im" style="color: #00769E;">as</span> f: ((x_train, y_train), (x_valid, y_valid), _) <span class="op" style="color: #5E5E5E;">=</span> pickle.load(f, encoding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'latin-1'</span>)</span>
<span id="cb1-30"></span>
<span id="cb1-31">x_train,y_train,x_valid,y_valid <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(tensor, (x_train,y_train,x_valid,y_valid))</span>
<span id="cb1-32">x_train.shape</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>torch.Size([50000, 784])</code></pre>
</div>
</div>
<div class="cell" data-outputid="a4f3c78a-4f61-4f8c-cf21-4c103270afd9" data-execution_count="3">
<details>
<summary>Show setup code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb3-2">weights <span class="op" style="color: #5E5E5E;">=</span> torch.randn(<span class="dv" style="color: #AD0000;">784</span>,<span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb3-3">bias <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(<span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb3-4"></span>
<span id="cb3-5">m1 <span class="op" style="color: #5E5E5E;">=</span> x_valid[:<span class="dv" style="color: #AD0000;">5</span>]</span>
<span id="cb3-6">m2 <span class="op" style="color: #5E5E5E;">=</span> weights</span>
<span id="cb3-7"></span>
<span id="cb3-8">m1.shape,m2.shape</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>(torch.Size([5, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/iV63qy4ETJQ?si=RVTeCMWgSHf_IHq0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<section id="digit-subset" class="level3">
<h3 class="anchored" data-anchor-id="digit-subset">5-digit Subset</h3>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">18.1 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">69.2 μs</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">83.1 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Cuda</td>
<td style="text-align: center;">108 μs</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">108 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">203 μs</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">542 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>torch.dot</code></td>
<td style="text-align: center;">1.19 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Element-wise PyTorch Ops</td>
<td style="text-align: center;">1.49 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Nested for-loops</td>
<td style="text-align: center;">604 ms</td>
</tr>
</tbody>
</table>
</section>
<section id="full-dataset-50k-images" class="level3">
<h3 class="anchored" data-anchor-id="full-dataset-50k-images">Full Dataset (50k images)</h3>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>cuda</code></td>
<td style="text-align: center;">541 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">3.91 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">5.8 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">5.87 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">663 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">1.26 s</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">3.71 s</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="version-0-nested-for-loops" class="level2">
<h2 class="anchored" data-anchor-id="version-0-nested-for-loops">Version 0: Nested For-Loops</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" title="Excalidraw diagram showing nested for-loop implementation of matrix multiplication" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Excalidraw diagram showing nested for-loop implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<div class="cell" data-outputid="f1b07e28-eb6a-42f0-9863-d962b0843dff" data-execution_count="70">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">ar,ac <span class="op" style="color: #5E5E5E;">=</span> m1.shape <span class="co" style="color: #5E5E5E;"># n_rows * n_cols</span></span>
<span id="cb5-2">br,bc <span class="op" style="color: #5E5E5E;">=</span> m2.shape</span>
<span id="cb5-3">(ar,ac),(br,bc)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>((5, 784), (784, 10))</code></pre>
</div>
</div>
<div class="cell" data-outputid="50202d80-fbe0-4ea8-aa39-4fe0691cb4b0" data-execution_count="71">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">t1 <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb7-2">t1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):         <span class="co" style="color: #5E5E5E;"># 5</span></span>
<span id="cb9-2">    <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc):     <span class="co" style="color: #5E5E5E;"># 10</span></span>
<span id="cb9-3">        <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ac): <span class="co" style="color: #5E5E5E;"># 784</span></span>
<span id="cb9-4">            t1[i,j] <span class="op" style="color: #5E5E5E;">+=</span> m1[i,k] <span class="op" style="color: #5E5E5E;">*</span> m2[k,j]</span></code></pre></div>
</div>
<div class="cell" data-outputid="de65336e-e04e-4d55-81aa-228a6f7bf7bf" data-execution_count="73">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">t1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div class="cell" data-outputid="a46dd7f0-06d7-4d86-aa3a-577743471963" data-execution_count="74">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],
        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],
        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],
        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],
        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb14-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb14-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb14-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb14-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc):</span>
<span id="cb14-6">            <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ac): c[i,j] <span class="op" style="color: #5E5E5E;">+=</span> a[i,k] <span class="op" style="color: #5E5E5E;">*</span> b[k,j]</span>
<span id="cb14-7">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-outputid="75bfe38a-2fc3-4f8d-8934-7fbd7c8036e4" data-execution_count="81">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="op" style="color: #5E5E5E;">%</span>time _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 675 ms, sys: 0 ns, total: 675 ms
Wall time: 674 ms</code></pre>
</div>
</div>
</section>
<section id="version-1-numba-dot-product" class="level2">
<h2 class="anchored" data-anchor-id="version-1-numba-dot-product">Version 1: Numba Dot Product</h2>
<p>Replacing the inner-most for-loop with a numba dot-product implementation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" title="Excalidraw diagram showing dot-product implementation of matrix multiplication" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Excalidraw diagram showing dot-product implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb17-2"><span class="kw" style="color: #003B4F;">def</span> dot(a,b):</span>
<span id="cb17-3">    res <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.</span></span>
<span id="cb17-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(a)): res<span class="op" style="color: #5E5E5E;">+=</span>a[i]<span class="op" style="color: #5E5E5E;">*</span>b[i]</span>
<span id="cb17-5">    <span class="cf" style="color: #003B4F;">return</span> res</span></code></pre></div>
</div>
<div class="cell" data-outputid="217464df-4573-40a9-f926-37186bb47d53" data-execution_count="83">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="op" style="color: #5E5E5E;">%</span>time dot(array([<span class="fl" style="color: #AD0000;">1.</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>]),array([<span class="fl" style="color: #AD0000;">2.</span>,<span class="dv" style="color: #AD0000;">3</span>,<span class="dv" style="color: #AD0000;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 124 ms, sys: 0 ns, total: 124 ms
Wall time: 123 ms</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>20.0</code></pre>
</div>
</div>
<div class="cell" data-outputid="64bc96a7-7cc1-404a-c47b-6b8a54d5c6b6" data-execution_count="84">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="op" style="color: #5E5E5E;">%</span>time dot(array([<span class="fl" style="color: #AD0000;">1.</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>]),array([<span class="fl" style="color: #AD0000;">2.</span>,<span class="dv" style="color: #AD0000;">3</span>,<span class="dv" style="color: #AD0000;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 26 μs, sys: 2 μs, total: 28 μs
Wall time: 32.4 μs</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>20.0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb24-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb24-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb24-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb24-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> dot(a[i,:], b[:,j])</span>
<span id="cb24-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">m1a,m2a <span class="op" style="color: #5E5E5E;">=</span> m1.numpy(),m2.numpy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div class="cell" data-outputid="10968392-3789-4272-b708-9a99560bad48" data-execution_count="91">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> matmul(m1a,m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>495 μs ± 39.4 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-2-element-wise-operations" class="level2">
<h2 class="anchored" data-anchor-id="version-2-element-wise-operations">Version 2: Element-wise Operations</h2>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb29-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb29-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb29-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb29-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:] <span class="op" style="color: #5E5E5E;">*</span> b[:,j]).<span class="bu" style="color: null;">sum</span>()</span>
<span id="cb29-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="fc775c33-b82e-4076-ef1b-5eb260224b56" data-execution_count="94">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.48 ms ± 354 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-3-torch.dot" class="level2">
<h2 class="anchored" data-anchor-id="version-3-torch.dot">Version 3: <code>torch.dot</code></h2>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb33-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb33-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb33-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb33-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> torch.dot(a[i,:], b[:,j])</span>
<span id="cb33-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="b97d9eea-9c0f-4ac5-9db1-c73b3661cfec" data-execution_count="97">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.23 ms ± 380 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-4-pytorch-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="version-4-pytorch-broadcasting">Version 4: PyTorch Broadcasting</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" title="Excalidraw diagram showing broadcasting implementation of matrix multiplication" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/3.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Excalidraw diagram showing broadcasting implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb37-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb37-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb37-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb37-5">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="2acf0524-81f2-4fab-e67d-b2354bacbf36" data-execution_count="109">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>314 μs ± 92.1 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-5-numba-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="version-5-numba-broadcasting">Version 5: Numba Broadcasting</h2>
<div class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb41-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb41-3">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb41-4">    c <span class="op" style="color: #5E5E5E;">=</span> np.zeros((ar, bc))</span>
<span id="cb41-5">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb41-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div class="cell" data-outputid="1d46ad9d-a40d-4643-c1cf-f535fa528a2f" data-execution_count="121">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1a, m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>69 μs ± 1.96 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-6-einstein-summation" class="level2">
<h2 class="anchored" data-anchor-id="version-6-einstein-summation">Version 6: Einstein Summation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="4.png" class="lightbox" title="Excalidraw diagram showing einsum implementation of matrix multiplication" data-gallery="quarto-lightbox-gallery-4"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/4.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Excalidraw diagram showing einsum implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b): <span class="cf" style="color: #003B4F;">return</span> torch.einsum(<span class="st" style="color: #20794D;">'ik,kj-&gt;ij'</span>, a, b)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="65bbe1b5-0ab3-4162-ef3f-bdeaeb96f800" data-execution_count="124">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>80.8 μs ± 4.18 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-7-pytorch-operator" class="level2">
<h2 class="anchored" data-anchor-id="version-7-pytorch-operator">Version 7: PyTorch <code>@</code> Operator</h2>
<div class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">test_close(t1,m1<span class="op" style="color: #5E5E5E;">@</span>m2)</span></code></pre></div>
</div>
<div class="cell" data-outputid="0bdd14b8-2dbf-42d9-f565-0746be389f63" data-execution_count="126">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>m1<span class="op" style="color: #5E5E5E;">@</span>m2</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>16.7 μs ± 1.96 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-8-numba-cuda" class="level2">
<h2 class="anchored" data-anchor-id="version-8-numba-cuda">Version 8: Numba CUDA</h2>
<div class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="at" style="color: #657422;">@cuda.jit</span></span>
<span id="cb52-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b,c):</span>
<span id="cb52-3">    i, j <span class="op" style="color: #5E5E5E;">=</span> cuda.grid(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb52-4">    <span class="cf" style="color: #003B4F;">if</span> i <span class="op" style="color: #5E5E5E;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;">0</span>] <span class="kw" style="color: #003B4F;">and</span> j <span class="op" style="color: #5E5E5E;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;">1</span>]:</span>
<span id="cb52-5">        tmp <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.</span></span>
<span id="cb52-6">        <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(a.shape[<span class="dv" style="color: #AD0000;">1</span>]): tmp <span class="op" style="color: #5E5E5E;">+=</span> a[i, k] <span class="op" style="color: #5E5E5E;">*</span> b[k, j]</span>
<span id="cb52-7">        c[i,j] <span class="op" style="color: #5E5E5E;">=</span> tmp</span></code></pre></div>
</div>
<div class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="kw" style="color: #003B4F;">def</span> launch_kernel(kernel, grid_x, grid_y, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb53-2">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(grid_x):</span>
<span id="cb53-3">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(grid_y): kernel((i,j), <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1">r <span class="op" style="color: #5E5E5E;">=</span> np.zeros(t1.shape)</span>
<span id="cb54-2">m1g,m2g,rg <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(cuda.to_device, (m1,m2,r))</span></code></pre></div>
</div>
<div class="cell" data-outputid="2852ccb1-8bed-450f-8864-1928e10117f2" data-execution_count="130">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">m1g.shape, m2g.shape, rg.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="130">
<pre><code>((5, 784), (784, 10), (5, 10))</code></pre>
</div>
</div>
<div class="cell" data-outputid="d4e0a549-a04f-43db-9d1f-c96e9a6026e7" data-execution_count="131">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">TPB <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">16</span></span>
<span id="cb57-2">rr,rc <span class="op" style="color: #5E5E5E;">=</span> r.shape</span>
<span id="cb57-3">blockspergrid <span class="op" style="color: #5E5E5E;">=</span> (math.ceil(rr <span class="op" style="color: #5E5E5E;">/</span> TPB), math.ceil(rc <span class="op" style="color: #5E5E5E;">/</span> TPB))</span>
<span id="cb57-4">blockspergrid</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="131">
<pre><code>(1, 1)</code></pre>
</div>
</div>
<div class="cell" data-outputid="bf632387-a756-4efb-ec6a-ce589b1c023a" data-execution_count="132">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)</span>
<span id="cb59-2">r <span class="op" style="color: #5E5E5E;">=</span> rg.copy_to_host()</span>
<span id="cb59-3">test_close(t1, r, eps<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/mnt/my4tb/vishal_data/miniconda3/envs/course-numba/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.
  warn(NumbaPerformanceWarning(msg))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><span class="op" style="color: #5E5E5E;">%%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb61-2">matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)</span>
<span id="cb61-3">r <span class="op" style="color: #5E5E5E;">=</span> rg.copy_to_host()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>245 μs ± 47.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-9-pytorch-.cuda" class="level2">
<h2 class="anchored" data-anchor-id="version-9-pytorch-.cuda">Version 9: PyTorch <code>.cuda</code></h2>
<div class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">m1c,m2c <span class="op" style="color: #5E5E5E;">=</span> m1.cuda(),m2.cuda()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">r<span class="op" style="color: #5E5E5E;">=</span>(m1c<span class="op" style="color: #5E5E5E;">@</span>m2c).cpu()</span>
<span id="cb64-2">test_close(t1, r)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span> r<span class="op" style="color: #5E5E5E;">=</span>(m1c<span class="op" style="color: #5E5E5E;">@</span>m2c).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>113 μs ± 26.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="comparing-fastest-versions-on-full-dataset" class="level2">
<h2 class="anchored" data-anchor-id="comparing-fastest-versions-on-full-dataset">Comparing Fastest Versions on Full Dataset</h2>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>cuda</code></td>
<td style="text-align: center;">541 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">3.91 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">5.8 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">5.87 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">663 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">1.26 s</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">3.71 s</td>
</tr>
</tbody>
</table>
<section id="numba-dot-product" class="level3">
<h3 class="anchored" data-anchor-id="numba-dot-product">Numba Dot Product</h3>
<div class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb67-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb67-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb67-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb67-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> dot(a[i,:], b[:,j])</span>
<span id="cb67-6">    <span class="cf" style="color: #003B4F;">return</span> c</span>
<span id="cb67-7"></span>
<span id="cb67-8">x_train_a,weights_a <span class="op" style="color: #5E5E5E;">=</span> x_train.numpy(),weights.numpy()</span>
<span id="cb67-9"><span class="op" style="color: #5E5E5E;">%</span>timeit _ <span class="op" style="color: #5E5E5E;">=</span> matmul(x_train_a, weights_a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.71 s ± 20.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
</section>
<section id="pytorch-broadcasting" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-broadcasting">PyTorch Broadcasting</h3>
<div class="cell" data-execution_count="197">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb69-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb69-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb69-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb69-5">    <span class="cf" style="color: #003B4F;">return</span> c</span>
<span id="cb69-6"></span>
<span id="cb69-7"><span class="op" style="color: #5E5E5E;">%</span>timeit _ <span class="op" style="color: #5E5E5E;">=</span> matmul(x_train, weights)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.26 s ± 1.42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1">x_train.shape, weights.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="198">
<pre><code>(torch.Size([50000, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="200">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><span class="op" style="color: #5E5E5E;">%</span>timeit _ <span class="op" style="color: #5E5E5E;">=</span> matmul(x_train.cuda(), weights.cuda())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.86 s ± 4.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>Interestingly, putting the tensors on the GPU and then broadcasting is slower than the CPU.</p>
</section>
<section id="numba-cuda" class="level3">
<h3 class="anchored" data-anchor-id="numba-cuda">Numba Cuda</h3>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><span class="at" style="color: #657422;">@cuda.jit</span></span>
<span id="cb75-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b,c):</span>
<span id="cb75-3">    i, j <span class="op" style="color: #5E5E5E;">=</span> cuda.grid(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb75-4">    <span class="cf" style="color: #003B4F;">if</span> i <span class="op" style="color: #5E5E5E;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;">0</span>] <span class="kw" style="color: #003B4F;">and</span> j <span class="op" style="color: #5E5E5E;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;">1</span>]:</span>
<span id="cb75-5">        tmp <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.</span></span>
<span id="cb75-6">        <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(a.shape[<span class="dv" style="color: #AD0000;">1</span>]): tmp <span class="op" style="color: #5E5E5E;">+=</span> a[i, k] <span class="op" style="color: #5E5E5E;">*</span> b[k, j]</span>
<span id="cb75-7">        c[i,j] <span class="op" style="color: #5E5E5E;">=</span> tmp</span></code></pre></div>
</div>
<div class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1">r <span class="op" style="color: #5E5E5E;">=</span> np.zeros((<span class="dv" style="color: #AD0000;">50000</span>, <span class="dv" style="color: #AD0000;">10</span>))</span>
<span id="cb76-2">m1g,m2g,rg <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(cuda.to_device, (x_train,weights,r))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1">TPB <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">16</span></span>
<span id="cb77-2">rr,rc <span class="op" style="color: #5E5E5E;">=</span> r.shape</span>
<span id="cb77-3">blockspergrid <span class="op" style="color: #5E5E5E;">=</span> (math.ceil(rr <span class="op" style="color: #5E5E5E;">/</span> TPB), math.ceil(rc <span class="op" style="color: #5E5E5E;">/</span> TPB))</span>
<span id="cb77-4">blockspergrid</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="142">
<pre><code>(3125, 1)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb79" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><span class="op" style="color: #5E5E5E;">%%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb79-2">matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)</span>
<span id="cb79-3">r <span class="op" style="color: #5E5E5E;">=</span> rg.copy_to_host()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.91 ms ± 68.6 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="pytorch-cuda" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-cuda">PyTorch <code>cuda</code></h3>
<div class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">m1c,m2c <span class="op" style="color: #5E5E5E;">=</span> x_train.cuda(),weights.cuda()</span>
<span id="cb81-2"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span> r<span class="op" style="color: #5E5E5E;">=</span>(m1c<span class="op" style="color: #5E5E5E;">@</span>m2c).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>541 μs ± 6.82 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="einstein-summation" class="level3">
<h3 class="anchored" data-anchor-id="einstein-summation">Einstein Summation</h3>
<div class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b): <span class="cf" style="color: #003B4F;">return</span> torch.einsum(<span class="st" style="color: #20794D;">'ik,kj-&gt;ij'</span>, a, b)</span>
<span id="cb83-2"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train, weights)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.87 ms ± 229 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="numba-broadcasting" class="level3">
<h3 class="anchored" data-anchor-id="numba-broadcasting">Numba Broadcasting</h3>
<div class="cell" data-execution_count="191">
<div class="sourceCode cell-code" id="cb85" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb85-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb85-3">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb85-4">    c <span class="op" style="color: #5E5E5E;">=</span> np.zeros((ar, bc))</span>
<span id="cb85-5">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb85-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="192">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1">_<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train.numpy(), weights.numpy())</span></code></pre></div>
</div>
<div class="cell" data-execution_count="193">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><span class="op" style="color: #5E5E5E;">%</span>timeit _<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train.numpy(), weights.numpy())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>663 ms ± 378 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
</section>
<section id="pytorch-op" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-op">PyTorch <code>@</code> Op</h3>
<div class="cell" data-execution_count="194">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span> _<span class="op" style="color: #5E5E5E;">=</span>x_train<span class="op" style="color: #5E5E5E;">@</span>weights</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.8 ms ± 212 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
</section>
<section id="comparing-5-digit-subset-to-full-dataset-times" class="level2">
<h2 class="anchored" data-anchor-id="comparing-5-digit-subset-to-full-dataset-times">Comparing 5-digit Subset to Full Dataset Times</h2>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Full Dataset Time</th>
<th style="text-align: center;">5-digit Subset Time/Rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>cuda</code></td>
<td style="text-align: center;">541 μs</td>
<td style="text-align: center;">108 μs (4)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">3.91 ms</td>
<td style="text-align: center;">108 μs (4)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">5.8 ms</td>
<td style="text-align: center;">18.1 μs (1)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">5.87 ms</td>
<td style="text-align: center;">83.1 μs (3)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">663 ms</td>
<td style="text-align: center;">69.2 μs (2)</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">1.26 s</td>
<td style="text-align: center;">203 μs (6)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">3.71 s</td>
<td style="text-align: center;">542 μs (7)</td>
</tr>
</tbody>
</table>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>I initially ran into some problems on Colab when implementing <code>@cuda.jit</code> (an error about compute compatibility) so I switched to an RTX 3090 machine and installed the following, which let me successfully run this notebook:</p>
<pre><code>conda install -y -c nvidia/label/cuda-12.8.0 cuda-toolkit
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
conda install -y numba
conda install -y fastcore -c fastai</code></pre>
<p>The glaring takeaway from this exercise is that these methods all scale differently. For the 5-digit subset, PyTorch <code>cuda</code> was about 9 times slower than PyTorch CPU (when using the <code>@</code> operator). Numba cuda and PyTorch <code>cuda</code> were tied for the small subset, but PyTorch <code>cuda</code> was 8 times faster for the larger dataset. I don’t yet understand <em>why</em> these differences exist, so that’s something I’ll keep an eye out for as I learn more about how GPUs work!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>fastai</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/index.html</guid>
  <pubDate>Wed, 21 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/1.png" medium="image" type="image/png" height="51" width="144"/>
</item>
<item>
  <title>DataInspector with BinPackCollator: Inspecting Packed Dataloader Items</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<iframe width="560" height="315" src="https://www.youtube.com/embed/DUwJ9o-Ut5g?si=G8QiwIx_Y7W_LRZF" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<p>I recently learned (via a desperation google search “llm foundry sequence packing”) that LLM-Foundry has a built-in sequence packer called <a href="https://github.com/mosaicml/llm-foundry/blob/dedcfe3b760b847091642526e9fb303f39742a51/llmfoundry/data/packing.py#L24"><code>BinPackCollator</code></a>. To use it, you simply set two values in the training YAML: <code>train_loader.name=finetuning</code> and <code>train_loader.dataset.packing_ratio</code> to <code>auto</code> or a number greater than <code>1.0</code>. I haven’t fully/thoroughly understood/traced how <code>BinPackCollator</code> is activated, but here’s what I have found:</p>
<ul>
<li><a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/data/finetuning/dataloader.py#L668"><code>build_collate_fn</code></a> uses the <code>packing_ratio</code> config value. If <code>packing_ratio</code> is <code>1.0</code> it returns the <code>Seq2SeqFinetuningCollator</code>. If it’s <code>auto</code>, it calls the function <a href="https://github.com/mosaicml/llm-foundry/blob/dedcfe3b760b847091642526e9fb303f39742a51/llmfoundry/data/packing.py#L364"><code>auto_packing_ratio</code></a> which profiles the dataset to determine the optimal <code>packing_ratio</code> (a <code>packing_ratio</code> with zero waste). If <code>packing_ratio</code> is greater than <code>1.0</code>, it then <a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/data/finetuning/dataloader.py#L705">instantiates <code>BinPackCollator</code></a> as the <code>collate_fn</code>.</li>
<li><a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/data/finetuning/dataloader.py#L235"><code>build_finetuning_dataloader</code></a> constructs the <code>collate_fn</code> from <code>registry.collators</code> (tbh, I haven’t yet grasped the concept of registry and how it works in LLM-Foundry, on my to-do list).</li>
<li>The main training script, command_utils/train.py <a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/command_utils/train.py#L461">uses <code>build_dataloader</code></a> which takes the training loader config and uses <a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/data/dataloader.py#L32">the <code>name</code> attribute in the config (which is <code>finetuning</code> in our case)</a> to <code>construct_from_registry</code> which I do not understand how it works yet.</li>
</ul>
<p>Here’s an example YAML snippet which shows the necessary attributes (<code>name</code> and <code>packing_ratio</code>) to utilize <code>BinPackCollator</code>:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb1-1"><span class="fu" style="color: #4758AB;">train_loader</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">name</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> finetuning</span></span>
<span id="cb1-3"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">dataset</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-4"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">streams</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-5"><span class="at" style="color: #657422;">      </span><span class="fu" style="color: #4758AB;">my_data</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-6"><span class="at" style="color: #657422;">        </span><span class="fu" style="color: #4758AB;">local</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ${variables.data_local}</span></span>
<span id="cb1-7"><span class="at" style="color: #657422;">        </span><span class="fu" style="color: #4758AB;">remote</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ${variables.data_remote}</span></span>
<span id="cb1-8"><span class="at" style="color: #657422;">        </span><span class="fu" style="color: #4758AB;">split</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> train</span></span>
<span id="cb1-9"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">shuffle</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">true</span></span>
<span id="cb1-10"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">max_seq_len</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ${variables.max_seq_len}</span></span>
<span id="cb1-11"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">shuffle_seed</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ${variables.global_seed}</span></span>
<span id="cb1-12"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">decoder_only_format</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">true</span></span>
<span id="cb1-13"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">packing_ratio</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="fl" style="color: #AD0000;">5.0</span></span></code></pre></div>
<p>In this blog post, I’m going to share a custom Composer callback I wrote to inspect data during training and ensure that sequences are being packed!</p>
</section>
<section id="datainspector" class="level2">
<h2 class="anchored" data-anchor-id="datainspector"><code>DataInspector</code></h2>
<p>I’ll start by sharing the full code for my callback:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">class</span> DataInspector(Callback):</span>
<span id="cb2-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, save_path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/model-checkpoints/binpackcollator"</span>):</span>
<span id="cb2-3">        <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">=</span> Path(save_path)</span>
<span id="cb2-4">        <span class="va" style="color: #111111;">self</span>.log <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'log'</span>: {}}</span>
<span id="cb2-5"></span>
<span id="cb2-6">    <span class="kw" style="color: #003B4F;">def</span> after_dataloader(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-7">        <span class="va" style="color: #111111;">self</span>._log(</span>
<span id="cb2-8">            state, </span>
<span id="cb2-9">            <span class="st" style="color: #20794D;">"after_dataloader"</span>, </span>
<span id="cb2-10">            <span class="bu" style="color: null;">str</span>(state.timestamp.batch.value), </span>
<span id="cb2-11">            [</span>
<span id="cb2-12">                (<span class="st" style="color: #20794D;">'collate_fn'</span>, <span class="bu" style="color: null;">str</span>(state.dataloader.collate_fn.base_collator)),</span>
<span id="cb2-13">                (<span class="st" style="color: #20794D;">'input_ids_shape'</span>, <span class="bu" style="color: null;">str</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>].shape)), </span>
<span id="cb2-14">                (<span class="st" style="color: #20794D;">'total_tokens'</span>, <span class="bu" style="color: null;">str</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>].shape[<span class="dv" style="color: #AD0000;">1</span>])),</span>
<span id="cb2-15">                (<span class="st" style="color: #20794D;">'decoded_tokens'</span>, <span class="bu" style="color: null;">str</span>(state.model.tokenizer.decode(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]))),</span>
<span id="cb2-16">                (<span class="st" style="color: #20794D;">'padding_tokens'</span>, <span class="bu" style="color: null;">str</span>(<span class="bu" style="color: null;">len</span>([o <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">list</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]) <span class="cf" style="color: #003B4F;">if</span> o.item() <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>]))),</span>
<span id="cb2-17">                (<span class="st" style="color: #20794D;">'non_padding_tokens'</span>, <span class="bu" style="color: null;">str</span>(<span class="bu" style="color: null;">len</span>([o <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">list</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]) <span class="cf" style="color: #003B4F;">if</span> o.item() <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">0</span>]))),</span>
<span id="cb2-18">                (<span class="st" style="color: #20794D;">'input_ids[0]'</span>, <span class="bu" style="color: null;">str</span>(<span class="bu" style="color: null;">list</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]))),</span>
<span id="cb2-19">                </span>
<span id="cb2-20">            ])</span>
<span id="cb2-21"></span>
<span id="cb2-22">    <span class="kw" style="color: #003B4F;">def</span> _log(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>, batch_num: <span class="bu" style="color: null;">str</span>, values: <span class="bu" style="color: null;">list</span>[<span class="bu" style="color: null;">str</span>]) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-23">        <span class="cf" style="color: #003B4F;">for</span> label, value <span class="kw" style="color: #003B4F;">in</span> values: <span class="va" style="color: #111111;">self</span>.log[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_</span><span class="sc" style="color: #5E5E5E;">{</span>batch_num<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_</span><span class="sc" style="color: #5E5E5E;">{</span>label<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>] <span class="op" style="color: #5E5E5E;">=</span> value</span>
<span id="cb2-24">        <span class="va" style="color: #111111;">self</span>._save()</span>
<span id="cb2-25"></span>
<span id="cb2-26">    <span class="kw" style="color: #003B4F;">def</span> _save(<span class="va" style="color: #111111;">self</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-27">        os.makedirs(<span class="va" style="color: #111111;">self</span>.save_path, exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-28">        log_file <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">/</span> <span class="st" style="color: #20794D;">"datainspector_logs.json"</span></span>
<span id="cb2-29">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(log_file, <span class="st" style="color: #20794D;">'w'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb2-30">            json.dump(<span class="va" style="color: #111111;">self</span>.log, f, indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<p>I started testing the callback by writing a very basic version first:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">class</span> DataInspector(Callback):</span>
<span id="cb3-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, save_path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/model-checkpoints/binpackcollator"</span>):</span>
<span id="cb3-3">        <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">=</span> Path(save_path)</span>
<span id="cb3-4">        <span class="va" style="color: #111111;">self</span>.log <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'log'</span>: {}}</span>
<span id="cb3-5"></span>
<span id="cb3-6">    <span class="kw" style="color: #003B4F;">def</span> after_dataloader(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb3-7">        <span class="va" style="color: #111111;">self</span>._log(state, <span class="st" style="color: #20794D;">"after_dataloader"</span>, <span class="st" style="color: #20794D;">"some value"</span>)</span>
<span id="cb3-8"></span>
<span id="cb3-9">    <span class="kw" style="color: #003B4F;">def</span> _log(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>, value: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb3-10">        <span class="va" style="color: #111111;">self</span>.log[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>] <span class="op" style="color: #5E5E5E;">=</span> value</span>
<span id="cb3-11">        <span class="va" style="color: #111111;">self</span>._save()</span>
<span id="cb3-12"></span>
<span id="cb3-13">    <span class="kw" style="color: #003B4F;">def</span> _save(<span class="va" style="color: #111111;">self</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb3-14">        os.makedirs(<span class="va" style="color: #111111;">self</span>.save_path, exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb3-15">        log_file <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">/</span> <span class="st" style="color: #20794D;">"datainspector_logs.json"</span></span>
<span id="cb3-16">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(log_file, <span class="st" style="color: #20794D;">'w'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb3-17">            json.dump(<span class="va" style="color: #111111;">self</span>.log, f, indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<p>The <code>__init__</code> and <code>_save</code> methods are pretty straigtforward, as they instantiate the <code>save_path</code> and <code>log</code> and then save to the <code>log</code> at that <code>save_path</code>. I could have chosen any number of events to trigger logging, but I chose <code>after_loader</code> since I wanted to inspect the data after the dataloader was constructed. The <code>_log</code> basically takes in as input the strings you want to save in the <code>self.log</code> dictionary. Once this initial functionality was working, I added different items for logging one at a time, starting with <code>input_ids</code>, <code>non_padding_tokens</code> and <code>padding_tokens</code> (which are counts of tokens), inspecting the logs visually before I moved on to the next item. Along the way I learned that the dataloader’s <code>collate_fn</code> was <code>LossGeneratingTokensCollatorWrapper</code> and that its <code>base_collator</code> function was <code>BinPackCollator</code>.</p>
<p>Here’s a snippet of the log:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb4-1"><span class="er" style="color: #AD0000;">"log":</span> <span class="fu" style="color: #4758AB;">{</span></span>
<span id="cb4-2">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_collate_fn"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"&lt;llmfoundry.data.packing.BinPackCollator object at 0x2ad36237cc20&gt;"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-3">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_input_ids_shape"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"torch.Size([4, 2048])"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-4">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_total_tokens"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"2048"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-5">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_padding_tokens"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"102"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-6">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_non_padding_tokens"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"1946"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-7">    <span class="er" style="color: #AD0000;">...</span></span></code></pre></div>
<p>Here are screenshots of the actual log, first <strong>without</strong> using <code>BinPackCollator</code>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" title="log without using BinPackCollator. Note that the number of padding tokens represent ~90% of the max sequence length of 2048" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">log without using <code>BinPackCollator</code>. Note that the number of padding tokens represent ~90% of the max sequence length of 2048</figcaption><p></p>
</figure>
</div>
<p>And with using <code>BinPackCollator</code>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" title="log when using BinPackCollator. Now the non-padding token represent 90% of the sequence length" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">log when using <code>BinPackCollator</code>. Now the non-padding token represent 90% of the sequence length</figcaption><p></p>
</figure>
</div>
<p>Using <code>BinPackCollator</code>, we are now using more than 90% of the maximum sequence length with loss generating tokens!</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>This is the fourth or fifth custom Composer callback I’ve written and I am really enjoyin writing and using them! The callback system makes it so easy to “look at your data”, and visually inspect and confirm that the model and/or data artifacts are correct. Expect more blog posts around Composer callbacks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ChatGPT generated graphic for `DataInspector`.png" class="lightbox" title="3.png" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/ChatGPT generated graphic for `DataInspector`.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">3.png</figcaption><p></p>
</figure>
</div>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>LLM-Foundry</category>
  <category>Custom Composer Callback</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/index.html</guid>
  <pubDate>Tue, 13 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/1.png" medium="image" type="image/png" height="85" width="144"/>
</item>
<item>
  <title>Comparing RAGatouille and ColBERT Indexes and Search Results</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-10-RAGatouille-ColBERT-Comparisons/index.html</link>
  <description><![CDATA[ 



<div class="cell">
<details>
<summary>Show setup</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> faiss</span>
<span id="cb1-2"><span class="bu" style="color: null;">hasattr</span>(faiss, <span class="st" style="color: #20794D;">"StandardGpuResources"</span>)</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> ragatouille <span class="im" style="color: #00769E;">import</span> RAGPretrainedModel</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> pytrec_eval</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> ranx <span class="im" style="color: #00769E;">import</span> evaluate</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">from</span> ranx <span class="im" style="color: #00769E;">import</span> Qrels, Run</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">import</span> pickle</span>
<span id="cb1-11"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb1-12"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-13"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-14"><span class="im" style="color: #00769E;">import</span> srsly</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Indexer</span>
<span id="cb1-17"><span class="im" style="color: #00769E;">from</span> colbert.infra <span class="im" style="color: #00769E;">import</span> RunConfig, ColBERTConfig</span>
<span id="cb1-18"><span class="im" style="color: #00769E;">from</span> colbert.infra.run <span class="im" style="color: #00769E;">import</span> Run</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="im" style="color: #00769E;">from</span> colbert.data <span class="im" style="color: #00769E;">import</span> Queries</span>
<span id="cb1-21"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Searcher</span></code></pre></div>
</details>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this notebook I am trying to answer two questions:</p>
<ol type="1">
<li>For a given document collection and indexing configuration, do RAGatouille and ColBERT produce the same index?</li>
<li>For a given index and search configuration, do RAGatouille and ColBERT retrieve the same passages/Recall@10?</li>
</ol>
<p>For this exercise, I’m using the UKPLab/DAPR’s ConditionalQA document collection which is 69k rows. If this exercise is successful, I’ll scale to larger document collections.</p>
<p>Here’s my rough plan:</p>
<ol type="1">
<li>Index the ConditionalQA document collection using RAGatouille and ColBERT. Be very thorough in ensuring the same configuration values are used.</li>
<li>Compare artifacts of the index (json and pt files). Document differences.</li>
<li>If successful, I would expect both indexes to largely be identical. If not, that’s a deeper dive.</li>
<li>Assuming successful equality of indexes, I’ll then perform search on the index using each framework, and compare retrieved passages and Recall@10. Initially, I’ll use RAGatouille search on the RAGatouille index, and ColBERT search on the ColBERT index. If that goes well, I might use one framework to search on the other’s index. RAGatouille requires some additional files so I’ll likely have to create them manually from the ColBERT index artifacts.</li>
<li>If I get similar Recall@10 and retrieved passages, great! If not, that’s a deeper dive.</li>
</ol>
</section>
<section id="load-the-data" class="level2">
<h2 class="anchored" data-anchor-id="load-the-data">Load the Data</h2>
<div class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">dataset_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"ConditionalQA"</span></span>
<span id="cb2-2">dataset_name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="150">
<pre><code>'ConditionalQA'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="292">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">passages <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-corpus"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb4-2">queries <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-queries"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb4-3">qrels_rows <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-qrels"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span></code></pre></div>
</div>
</section>
<section id="create-ragatouille-index-1k-subset" class="level2">
<h2 class="anchored" data-anchor-id="create-ragatouille-index-1k-subset">Create RAGatouille Index (1k subset)</h2>
<div class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">RAG <span class="op" style="color: #5E5E5E;">=</span> RAGPretrainedModel.from_pretrained(<span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="153">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">n_items <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1000</span></span>
<span id="cb6-2">n_items</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="153">
<pre><code>1000</code></pre>
</div>
</div>
<p>Notes about <code>RAG.model.config</code> before indexing:</p>
<ul>
<li>The following values are <code>None</code>: <code>ncells</code>, <code>centroid_score_threshold</code>, <code>ndocs</code></li>
<li><code>kmeans_niters=4</code></li>
<li><code>nbits=1</code></li>
<li><code>index_bsize=64</code></li>
<li><code>bsize=32</code></li>
<li><code>dim=96</code></li>
<li><code>doc_maxlen=300</code></li>
<li><code>rank=0</code></li>
<li><code>nranks=4</code></li>
<li><code>gpus=4</code></li>
</ul>
<div class="cell" data-execution_count="154">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">RAG.model.config</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="154">
<pre><code>ColBERTConfig(query_token_id='[unused0]', doc_token_id='[unused1]', query_token='[Q]', doc_token='[D]', ncells=None, centroid_score_threshold=None, ndocs=None, load_index_with_mmap=False, index_path=None, index_bsize=64, nbits=1, kmeans_niters=4, resume=False, pool_factor=1, clustering_mode='hierarchical', protected_tokens=0, similarity='cosine', bsize=32, accumsteps=1, lr=1e-05, maxsteps=15626, save_every=None, warmup=781, warmup_bert=None, relu=False, nway=32, use_ib_negatives=False, reranker=False, distillation_alpha=1.0, ignore_scores=False, model_name='answerdotai/AnswerAI-ColBERTv2.5-small', query_maxlen=32, attend_to_mask_tokens=False, interaction='colbert', dim=96, doc_maxlen=300, mask_punctuation=True, checkpoint='/home/vishal/.cache/huggingface/hub/models--answerdotai--answerai-colbert-small-v1/snapshots/be1703c55532145a844da800eea4c9a692d7e267/', triples='/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl', collection='/home/bclavie/colbertv2.5_en/data/msmarco/collection.tsv', queries='/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv', index_name=None, overwrite=False, root='.ragatouille/', experiment='colbert', index_root=None, name='2024-08/07/08.16.20', rank=0, nranks=4, amp=True, gpus=4, avoid_fork_if_possible=False)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="155">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;">#!rm -rf .ragatouille/colbert/indexes/ConditionalQA_RAGatouille_index_1k</span></span></code></pre></div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">RAG_index_path <span class="op" style="color: #5E5E5E;">=</span> RAG.index(</span>
<span id="cb11-2">    index_name<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_RAGatouille_index_1k"</span>,</span>
<span id="cb11-3">    collection<span class="op" style="color: #5E5E5E;">=</span>passages[:n_items][<span class="st" style="color: #20794D;">"text"</span>],</span>
<span id="cb11-4">    document_ids<span class="op" style="color: #5E5E5E;">=</span>passages[:n_items][<span class="st" style="color: #20794D;">"_id"</span>],</span>
<span id="cb11-5">    use_faiss<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span> <span class="co" style="color: #5E5E5E;"># to match ColBERT</span></span>
<span id="cb11-6">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="157">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="op" style="color: #5E5E5E;">!</span>du <span class="op" style="color: #5E5E5E;">-</span>sh {RAG_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.2M    .ragatouille/colbert/indexes/ConditionalQA_RAGatouille_index_1k</code></pre>
</div>
</div>
<div class="cell" data-execution_count="158">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="op" style="color: #5E5E5E;">!</span>ls {RAG_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.codes.pt   avg_residual.pt  collection.json  metadata.json
0.metadata.json  buckets.pt   doclens.0.json   pid_docid_map.json
0.residuals.pt   centroids.pt     ivf.pid.pt       plan.json</code></pre>
</div>
</div>
<p>Notes about <code>metadata.json</code> <em>after</em> indexing:</p>
<ul>
<li>The following values are still <code>None</code>: <code>ncells</code>, <code>centroid_score_threshold</code>, <code>ndocs</code></li>
<li><code>kmeans_niters=20</code> (up from 4)</li>
<li><code>nbits=4</code> (up from 1)</li>
<li><code>index_bsize=64</code></li>
<li><code>bsize=64</code> (up from 32)</li>
<li><code>dim=96</code></li>
<li><code>doc_maxlen=256</code> (down from 300)</li>
<li><code>rank=0</code></li>
<li><code>nranks=1</code> (down from 4)</li>
<li><code>gpus=1</code> (down from 4)</li>
<li><code>'num_partitions'=1024</code> (not in original config)</li>
</ul>
<p>Inspecting the RAGatouille metadata:</p>
<div class="cell" data-scrolled="true" data-execution_count="159">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb16-2">    RAG_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb16-3">RAG_metadata</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="159">
<pre><code>{'config': {'query_token_id': '[unused0]',
  'doc_token_id': '[unused1]',
  'query_token': '[Q]',
  'doc_token': '[D]',
  'ncells': None,
  'centroid_score_threshold': None,
  'ndocs': None,
  'load_index_with_mmap': False,
  'index_path': None,
  'index_bsize': 32,
  'nbits': 4,
  'kmeans_niters': 20,
  'resume': False,
  'pool_factor': 1,
  'clustering_mode': 'hierarchical',
  'protected_tokens': 0,
  'similarity': 'cosine',
  'bsize': 64,
  'accumsteps': 1,
  'lr': 1e-05,
  'maxsteps': 15626,
  'save_every': None,
  'warmup': 781,
  'warmup_bert': None,
  'relu': False,
  'nway': 32,
  'use_ib_negatives': False,
  'reranker': False,
  'distillation_alpha': 1.0,
  'ignore_scores': False,
  'model_name': 'answerdotai/AnswerAI-ColBERTv2.5-small',
  'query_maxlen': 32,
  'attend_to_mask_tokens': False,
  'interaction': 'colbert',
  'dim': 96,
  'doc_maxlen': 256,
  'mask_punctuation': True,
  'checkpoint': 'answerdotai/answerai-colbert-small-v1',
  'triples': '/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl',
  'collection': ['list with 1000 elements starting with...',
   ['Overview',
    'You can only make a claim for Child Tax Credit if you already get Working Tax Credit.',
    'If you cannot apply for Child Tax Credit, you can apply for Universal Credit instead.']],
  'queries': '/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv',
  'index_name': 'ConditionalQA_RAGatouille_index_1k',
  'overwrite': False,
  'root': '.ragatouille/',
  'experiment': 'colbert',
  'index_root': None,
  'name': '2025-05/09/10.30.23',
  'rank': 0,
  'nranks': 1,
  'amp': True,
  'gpus': 1,
  'avoid_fork_if_possible': False},
 'num_chunks': 1,
 'num_partitions': 1024,
 'num_embeddings': 15198,
 'avg_doclen': 15.198,
 'RAGatouille': {'index_config': {'index_type': 'PLAID',
   'index_name': 'ConditionalQA_RAGatouille_index_1k'}}}</code></pre>
</div>
</div>
<table class="table">
<colgroup>
<col style="width: 22%">
<col style="width: 32%">
<col style="width: 30%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Before Indexing</th>
<th>After Indexing</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>kmeans_niters</code></td>
<td>4</td>
<td>20</td>
<td>5× more iterations for clustering</td>
</tr>
<tr class="even">
<td><code>nbits</code></td>
<td>1</td>
<td>4</td>
<td>4× more bits for residual compression</td>
</tr>
<tr class="odd">
<td><code>bsize</code></td>
<td>32</td>
<td>64</td>
<td>Doubled batch size</td>
</tr>
<tr class="even">
<td><code>doc_maxlen</code></td>
<td>300</td>
<td>256</td>
<td>Reduced document length limit</td>
</tr>
<tr class="odd">
<td><code>nranks</code></td>
<td>4</td>
<td>1</td>
<td>Changed to single-process execution</td>
</tr>
<tr class="even">
<td><code>gpus</code></td>
<td>4</td>
<td>1</td>
<td>Changed to single-GPU execution</td>
</tr>
<tr class="odd">
<td><code>num_partitions</code></td>
<td>(not set)</td>
<td>1024</td>
<td>New parameter added during indexing</td>
</tr>
</tbody>
</table>
<p>The following are search parameters so they are not set/used for indexing: <code>ncells</code>, <code>centroid_score_threshold</code>, <code>ndocs</code>.</p>
</section>
<section id="create-vanilla-colbert-index-1k-subset" class="level2">
<h2 class="anchored" data-anchor-id="create-vanilla-colbert-index-1k-subset">Create Vanilla ColBERT Index (1k subset)</h2>
<p>Next, I’ll index the same document collection using vanilla ColBERT (which is installed with RAGatouille).</p>
<div class="cell" data-execution_count="160">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">dataset_name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="160">
<pre><code>'ConditionalQA'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="161">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">ColBERTConfig()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="161">
<pre><code>ColBERTConfig(query_token_id='[unused0]', doc_token_id='[unused1]', query_token='[Q]', doc_token='[D]', ncells=None, centroid_score_threshold=None, ndocs=None, load_index_with_mmap=False, index_path=None, index_bsize=64, nbits=1, kmeans_niters=4, resume=False, pool_factor=1, clustering_mode='hierarchical', protected_tokens=0, similarity='cosine', bsize=32, accumsteps=1, lr=3e-06, maxsteps=500000, save_every=None, warmup=None, warmup_bert=None, relu=False, nway=2, use_ib_negatives=False, reranker=False, distillation_alpha=1.0, ignore_scores=False, model_name=None, query_maxlen=32, attend_to_mask_tokens=False, interaction='colbert', dim=128, doc_maxlen=220, mask_punctuation=True, checkpoint=None, triples=None, collection=None, queries=None, index_name=None, overwrite=False, root='/mnt/my4tb/vishal_data/SuperPassage/experiments', experiment='default', index_root=None, name='2025-05/09/10.30.23', rank=0, nranks=1, amp=True, gpus=1, avoid_fork_if_possible=False)</code></pre>
</div>
</div>
<p>Key differences from this initial config and RAGatouille’s post-indexing metadata:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">RAGatouille value</th>
<th style="text-align: center;">ColBERT value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>kmeans_iter</code></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>nbits</code></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>dim</code></td>
<td style="text-align: center;">96</td>
<td style="text-align: center;">128</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>doc_maxlen</code></td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">220</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>index_bsize</code></td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">64</td>
</tr>
</tbody>
</table>
<p>I will set these explicitly in the ColBERTConfig before indexing.</p>
<div class="cell" data-execution_count="162">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">n_items</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="162">
<pre><code>1000</code></pre>
</div>
</div>
<p>The following environmental variable needs to be set otherwise the script won’t run.</p>
<div class="cell" data-execution_count="189">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">os.environ[<span class="st" style="color: #20794D;">"MKL_SERVICE_FORCE_INTEL"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"1"</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;">#!rm -rf /mnt/my4tb/vishal_data/SuperPassage/.ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_1k</span></span></code></pre></div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb26-2">    config <span class="op" style="color: #5E5E5E;">=</span> ColBERTConfig(</span>
<span id="cb26-3">        doc_maxlen<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>,      </span>
<span id="cb26-4">        nbits<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,             </span>
<span id="cb26-5">        dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">96</span>,             </span>
<span id="cb26-6">        kmeans_niters<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">20</span>,</span>
<span id="cb26-7">        index_bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32</span>,</span>
<span id="cb26-8">        bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb26-9">        checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>,</span>
<span id="cb26-10">    )</span>
<span id="cb26-11">    </span>
<span id="cb26-12">    indexer <span class="op" style="color: #5E5E5E;">=</span> Indexer(checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>, config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb26-13">    indexer.index(name<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_ColBERT_index_1k"</span>, collection<span class="op" style="color: #5E5E5E;">=</span>passages[:n_items][<span class="st" style="color: #20794D;">"text"</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">ColBERT_index_path <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">".ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_1k"</span></span></code></pre></div>
</div>
<p>The ColBERT index is a tiny bit smaller than RAGatouille, likely because it doesn’t store the collection as a JSON file and doesn’t store pid to docid map as a JSON file (which RAGatouille does—something we’ll encounter later on during search).</p>
<div class="cell" data-execution_count="168">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="op" style="color: #5E5E5E;">!</span>du <span class="op" style="color: #5E5E5E;">-</span>sh {ColBERT_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.1M    .ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_1k</code></pre>
</div>
</div>
<div class="cell" data-execution_count="169">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="op" style="color: #5E5E5E;">!</span>ls {ColBERT_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.codes.pt   0.residuals.pt   buckets.pt    doclens.0.json  metadata.json
0.metadata.json  avg_residual.pt  centroids.pt  ivf.pid.pt  plan.json</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="170">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb32-2">    ColBERT_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb32-3">ColBERT_metadata</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="170">
<pre><code>{'config': {'query_token_id': '[unused0]',
  'doc_token_id': '[unused1]',
  'query_token': '[Q]',
  'doc_token': '[D]',
  'ncells': None,
  'centroid_score_threshold': None,
  'ndocs': None,
  'load_index_with_mmap': False,
  'index_path': None,
  'index_bsize': 32,
  'nbits': 4,
  'kmeans_niters': 20,
  'resume': False,
  'pool_factor': 1,
  'clustering_mode': 'hierarchical',
  'protected_tokens': 0,
  'similarity': 'cosine',
  'bsize': 64,
  'accumsteps': 1,
  'lr': 1e-05,
  'maxsteps': 15626,
  'save_every': None,
  'warmup': 781,
  'warmup_bert': None,
  'relu': False,
  'nway': 32,
  'use_ib_negatives': False,
  'reranker': False,
  'distillation_alpha': 1.0,
  'ignore_scores': False,
  'model_name': 'answerdotai/AnswerAI-ColBERTv2.5-small',
  'query_maxlen': 32,
  'attend_to_mask_tokens': False,
  'interaction': 'colbert',
  'dim': 96,
  'doc_maxlen': 256,
  'mask_punctuation': True,
  'checkpoint': 'answerdotai/answerai-colbert-small-v1',
  'triples': '/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl',
  'collection': ['list with 1000 elements starting with...',
   ['Overview',
    'You can only make a claim for Child Tax Credit if you already get Working Tax Credit.',
    'If you cannot apply for Child Tax Credit, you can apply for Universal Credit instead.']],
  'queries': '/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv',
  'index_name': 'ConditionalQA_ColBERT_index_1k',
  'overwrite': False,
  'root': '.ragatouille/',
  'experiment': 'colbert',
  'index_root': None,
  'name': '2025-05/09/10.30.23',
  'rank': 0,
  'nranks': 1,
  'amp': True,
  'gpus': 1,
  'avoid_fork_if_possible': False},
 'num_chunks': 1,
 'num_partitions': 1024,
 'num_embeddings': 15198,
 'avg_doclen': 15.198}</code></pre>
</div>
</div>
</section>
<section id="comparing-1k-subset-index-artifacts" class="level2">
<h2 class="anchored" data-anchor-id="comparing-1k-subset-index-artifacts">Comparing 1k subset Index Artifacts</h2>
<p>RAGatouille files:</p>
<ul>
<li>0.codes.pt<br>
</li>
<li>0.residuals.pt</li>
<li>buckets.pt<br>
</li>
<li>doclens.0.json</li>
<li>metadata.json</li>
<li>0.metadata.json</li>
<li>avg_residual.pt</li>
<li>centroids.pt</li>
<li>ivf.pid.pt</li>
<li>plan.json</li>
<li>collection.json (unique to RAGatouille)</li>
<li>pid_docid_map.json (unique to RAGatouille)</li>
</ul>
<p>ColBERT files:</p>
<ul>
<li>0.codes.pt</li>
<li>0.residuals.pt</li>
<li>buckets.pt</li>
<li>doclens.0.json</li>
<li>metadata.json</li>
<li>0.metadata.json</li>
<li>avg_residual.pt</li>
<li>centroids.pt<br>
</li>
<li>ivf.pid.pt<br>
</li>
<li>plan.json</li>
</ul>
<p>All parameters relevant to indexing are matching in the corresponding metadata.json files:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">Parameter</th>
<th style="text-align: left;">Value</th>
<th style="text-align: center;">Status</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>index_bsize</code></td>
<td style="text-align: left;">32</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>nbits</code></td>
<td style="text-align: left;">4</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>kmeans_niters</code></td>
<td style="text-align: left;">20</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>dim</code></td>
<td style="text-align: left;">96</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>doc_maxlen</code></td>
<td style="text-align: left;">256</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>num_partitions</code></td>
<td style="text-align: left;">1024</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>num_embeddings</code></td>
<td style="text-align: left;">15198</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>avg_doclen</code></td>
<td style="text-align: left;">15.198</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>checkpoint</code></td>
<td style="text-align: left;">‘answerdotai/answerai-colbert-small-v1’</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
</tbody>
</table>
<p>Walking through each file and comparing contents:</p>
<div class="cell" data-execution_count="171">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="kw" style="color: #003B4F;">def</span> _compare_pt(r_path, c_path):</span>
<span id="cb34-2">    r <span class="op" style="color: #5E5E5E;">=</span> torch.load(r_path)</span>
<span id="cb34-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.load(c_path)</span>
<span id="cb34-4">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(r,<span class="bu" style="color: null;">tuple</span>):</span>
<span id="cb34-5">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"0 shape:"</span>, r[<span class="dv" style="color: #AD0000;">0</span>].shape, c[<span class="dv" style="color: #AD0000;">0</span>].shape)</span>
<span id="cb34-6">        <span class="bu" style="color: null;">print</span>(r[<span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb34-7">        <span class="bu" style="color: null;">print</span>(c[<span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb34-8">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-9">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"0 match: "</span>, (r[<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">0</span>]).<span class="bu" style="color: null;">float</span>().mean())</span>
<span id="cb34-10">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-11">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'#'</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">30</span>)</span>
<span id="cb34-12">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-13">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"1 shape:"</span>, r[<span class="dv" style="color: #AD0000;">1</span>].shape, c[<span class="dv" style="color: #AD0000;">1</span>].shape)</span>
<span id="cb34-14">        <span class="bu" style="color: null;">print</span>(r[<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb34-15">        <span class="bu" style="color: null;">print</span>(c[<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb34-16">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-17">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"1 match: "</span>, (r[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">1</span>]).<span class="bu" style="color: null;">float</span>().mean())</span>
<span id="cb34-18">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb34-19">        <span class="bu" style="color: null;">print</span>(r)</span>
<span id="cb34-20">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-21">        <span class="bu" style="color: null;">print</span>(c)</span>
<span id="cb34-22">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-23">        <span class="bu" style="color: null;">print</span>(r.shape, c.shape)</span>
<span id="cb34-24">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-25">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"match: "</span>,(r <span class="op" style="color: #5E5E5E;">==</span> c).<span class="bu" style="color: null;">float</span>().mean())</span></code></pre></div>
</div>
<section id="codes.pt" class="level3">
<h3 class="anchored" data-anchor-id="codes.pt">0.codes.pt</h3>
<div class="cell" data-execution_count="173">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/0.codes.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/0.codes.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([345, 288, 647,  ..., 232, 767,  29], dtype=torch.int32)


tensor([345, 288, 647,  ..., 232, 767,  29], dtype=torch.int32)


torch.Size([15198]) torch.Size([15198])


match:  tensor(1.)</code></pre>
</div>
</div>
</section>
<section id="residuals.pt" class="level3">
<h3 class="anchored" data-anchor-id="residuals.pt">0.residuals.pt</h3>
<div class="cell" data-execution_count="175">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/0.residuals.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/0.residuals.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 30, 225, 225,  ..., 238, 238,  30],
        [238, 238, 238,  ..., 238, 238, 238],
        [240, 254, 253,  ..., 175, 240, 128],
        ...,
        [ 99, 105, 231,  ...,  40,  95,  48],
        [ 85, 241,  87,  ..., 128,   8, 179],
        [ 89, 106, 150,  ..., 162, 238,  22]], dtype=torch.uint8)


tensor([[ 30, 225, 225,  ..., 238, 238,  30],
        [238, 238, 238,  ..., 238, 238, 238],
        [240, 254, 253,  ..., 175, 240, 128],
        ...,
        [ 99, 105, 231,  ...,  40,  95,  48],
        [ 85, 241,  87,  ..., 128,   8, 179],
        [ 89, 106, 150,  ..., 162, 238,  22]], dtype=torch.uint8)


torch.Size([15198, 48]) torch.Size([15198, 48])


match:  tensor(1.)</code></pre>
</div>
</div>
</section>
<section id="centroids.pt" class="level3">
<h3 class="anchored" data-anchor-id="centroids.pt">centroids.pt</h3>
<div class="cell" data-execution_count="176">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/centroids.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/centroids.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[-0.0701,  0.0035, -0.0785,  ...,  0.1628,  0.0201, -0.0419],
        [-0.0350, -0.0082, -0.0715,  ...,  0.1119, -0.0159, -0.1164],
        [-0.0753,  0.0172, -0.0513,  ...,  0.1070,  0.1476, -0.0699],
        ...,
        [-0.1425,  0.1393, -0.2316,  ...,  0.0169,  0.0897, -0.0431],
        [-0.0690,  0.0513, -0.0935,  ...,  0.1311,  0.0324, -0.0705],
        [-0.0812,  0.0511, -0.0482,  ...,  0.1010,  0.0365, -0.0582]],
       device='cuda:0', dtype=torch.float16)


tensor([[-0.0701,  0.0035, -0.0785,  ...,  0.1628,  0.0201, -0.0419],
        [-0.0350, -0.0082, -0.0715,  ...,  0.1119, -0.0159, -0.1164],
        [-0.0753,  0.0172, -0.0513,  ...,  0.1070,  0.1476, -0.0699],
        ...,
        [-0.1425,  0.1393, -0.2316,  ...,  0.0169,  0.0897, -0.0431],
        [-0.0690,  0.0513, -0.0935,  ...,  0.1311,  0.0324, -0.0705],
        [-0.0812,  0.0511, -0.0482,  ...,  0.1010,  0.0365, -0.0582]],
       device='cuda:0', dtype=torch.float16)


torch.Size([1024, 96]) torch.Size([1024, 96])


match:  tensor(1., device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="ivf.pid.pt" class="level3">
<h3 class="anchored" data-anchor-id="ivf.pid.pt">ivf.pid.pt</h3>
<div class="cell" data-execution_count="177">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/ivf.pid.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/ivf.pid.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0 shape: torch.Size([11696]) torch.Size([11696])
tensor([889, 894, 916,  ...,   0,   0,   0], dtype=torch.int32)
tensor([889, 894, 916,  ...,   0,   0,   0], dtype=torch.int32)


0 match:  tensor(1.)


##############################


1 shape: torch.Size([1024]) torch.Size([1024])
tensor([ 5, 46, 16,  ...,  7, 11,  3])
tensor([ 5, 46, 16,  ...,  7, 11,  3])


1 match:  tensor(1.)</code></pre>
</div>
</div>
</section>
<section id="buckets.pt" class="level3">
<h3 class="anchored" data-anchor-id="buckets.pt">buckets.pt</h3>
<div class="cell" data-execution_count="178">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/buckets.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/buckets.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0 shape: torch.Size([15]) torch.Size([15])
tensor([-0.0310, -0.0208, -0.0148, -0.0101, -0.0065, -0.0037, -0.0015,  0.0000,
         0.0016,  0.0037,  0.0067,  0.0103,  0.0150,  0.0210,  0.0312],
       device='cuda:0')
tensor([-0.0310, -0.0208, -0.0148, -0.0101, -0.0065, -0.0037, -0.0015,  0.0000,
         0.0016,  0.0037,  0.0067,  0.0103,  0.0150,  0.0210,  0.0312],
       device='cuda:0')


0 match:  tensor(1., device='cuda:0')


##############################


1 shape: torch.Size([16]) torch.Size([16])
tensor([-0.0417, -0.0248, -0.0175, -0.0123, -0.0082, -0.0050, -0.0025, -0.0006,
         0.0007,  0.0026,  0.0051,  0.0084,  0.0125,  0.0178,  0.0251,  0.0417],
       device='cuda:0', dtype=torch.float16)
tensor([-0.0417, -0.0248, -0.0175, -0.0123, -0.0082, -0.0050, -0.0025, -0.0006,
         0.0007,  0.0026,  0.0051,  0.0084,  0.0125,  0.0178,  0.0251,  0.0417],
       device='cuda:0', dtype=torch.float16)


1 match:  tensor(1., device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="avg_residual.pt" class="level3">
<h3 class="anchored" data-anchor-id="avg_residual.pt">avg_residual.pt</h3>
<div class="cell" data-execution_count="179">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/avg_residual.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/avg_residual.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(0.0150, device='cuda:0', dtype=torch.float16)


tensor(0.0150, device='cuda:0', dtype=torch.float16)


torch.Size([]) torch.Size([])


match:  tensor(1., device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="doclens.0.json" class="level3">
<h3 class="anchored" data-anchor-id="doclens.0.json">doclens.0.json</h3>
<div class="cell" data-execution_count="180">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/doclens.0.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb47-2">    RAGatouille_doclens <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb47-3">RAGatouille_doclens[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="180">
<pre><code>[4, 20, 18, 23, 8]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="181">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/doclens.0.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb49-2">    ColBERT_doclens <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb49-3">ColBERT_doclens[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="181">
<pre><code>[4, 20, 18, 23, 8]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="182">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">RAGatouille_doclens <span class="op" style="color: #5E5E5E;">==</span> ColBERT_doclens</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="182">
<pre><code>True</code></pre>
</div>
</div>
<p>Based on these comparisons, I can conclude that ColBERT and RAGatouille do indeed produce identical index artifacts given the same configuration and document collection!</p>
</section>
</section>
<section id="indexing-full-conditionalqa-comparing-artifacts" class="level2">
<h2 class="anchored" data-anchor-id="indexing-full-conditionalqa-comparing-artifacts">Indexing Full ConditionalQA + Comparing Artifacts</h2>
<p>With a 1k subset confirmed, I’ll now index the full ConditionalQA document collection, which contains ~70k rows.</p>
<div class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">dataset_name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="183">
<pre><code>'ConditionalQA'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="186">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="bu" style="color: null;">len</span>(passages)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="186">
<pre><code>69199</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">RAG <span class="op" style="color: #5E5E5E;">=</span> RAGPretrainedModel.from_pretrained(<span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>)</span>
<span id="cb57-2">RAG_index_path <span class="op" style="color: #5E5E5E;">=</span> RAG.index(</span>
<span id="cb57-3">    index_name<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_RAGatouille_index_full"</span>,</span>
<span id="cb57-4">    collection<span class="op" style="color: #5E5E5E;">=</span>passages[<span class="st" style="color: #20794D;">"text"</span>],</span>
<span id="cb57-5">    document_ids<span class="op" style="color: #5E5E5E;">=</span>passages[<span class="st" style="color: #20794D;">"_id"</span>],</span>
<span id="cb57-6">    use_faiss<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span> <span class="co" style="color: #5E5E5E;"># to match ColBERT</span></span>
<span id="cb57-7">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="187">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><span class="op" style="color: #5E5E5E;">!</span>du <span class="op" style="color: #5E5E5E;">-</span>sh {RAG_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>45M .ragatouille/colbert/indexes/ConditionalQA_RAGatouille_index_full</code></pre>
</div>
</div>
<div class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><span class="op" style="color: #5E5E5E;">!</span>ls {RAG_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.codes.pt   1.residuals.pt   buckets.pt       doclens.2.json
0.metadata.json  2.codes.pt   centroids.pt     ivf.pid.pt
0.residuals.pt   2.metadata.json  collection.json  metadata.json
1.codes.pt   2.residuals.pt   doclens.0.json   pid_docid_map.json
1.metadata.json  avg_residual.pt  doclens.1.json   plan.json</code></pre>
</div>
</div>
<div class="cell" data-execution_count="196">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><span class="co" style="color: #5E5E5E;">#!rm -rf .ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_full</span></span></code></pre></div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">os.environ[<span class="st" style="color: #20794D;">"MKL_SERVICE_FORCE_INTEL"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"1"</span></span>
<span id="cb63-2"><span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb63-3">    config <span class="op" style="color: #5E5E5E;">=</span> ColBERTConfig(</span>
<span id="cb63-4">        doc_maxlen<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>,      </span>
<span id="cb63-5">        nbits<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>,  <span class="co" style="color: #5E5E5E;"># to match RAGatouille           </span></span>
<span id="cb63-6">        dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">96</span>,             </span>
<span id="cb63-7">        kmeans_niters<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>, <span class="co" style="color: #5E5E5E;"># to match RAGatouille</span></span>
<span id="cb63-8">        index_bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32</span>,</span>
<span id="cb63-9">        bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb63-10">        checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>,</span>
<span id="cb63-11">    )</span>
<span id="cb63-12">    </span>
<span id="cb63-13">    indexer <span class="op" style="color: #5E5E5E;">=</span> Indexer(checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>, config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb63-14">    indexer.index(name<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_ColBERT_index_full"</span>, collection<span class="op" style="color: #5E5E5E;">=</span>passages[<span class="st" style="color: #20794D;">"text"</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">ColBERT_index_path <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">".ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_full"</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="199">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="op" style="color: #5E5E5E;">!</span>du <span class="op" style="color: #5E5E5E;">-</span>sh {ColBERT_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>38M .ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_full</code></pre>
</div>
</div>
<div class="cell" data-execution_count="200">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="op" style="color: #5E5E5E;">!</span>ls {ColBERT_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.codes.pt   1.residuals.pt   buckets.pt      ivf.pid.pt
0.metadata.json  2.codes.pt   centroids.pt    metadata.json
0.residuals.pt   2.metadata.json  doclens.0.json  plan.json
1.codes.pt   2.residuals.pt   doclens.1.json
1.metadata.json  avg_residual.pt  doclens.2.json</code></pre>
</div>
</div>
<section id="comparing-metadata" class="level3">
<h3 class="anchored" data-anchor-id="comparing-metadata">Comparing Metadata</h3>
<p>All key metadata parameters are equivalent between the RAGatouille and ColBERT indexes.</p>
<div class="cell" data-execution_count="221">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1">params <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"index_bsize"</span>, <span class="st" style="color: #20794D;">"nbits"</span>, <span class="st" style="color: #20794D;">"kmeans_niters"</span>, <span class="st" style="color: #20794D;">"bsize"</span>, <span class="st" style="color: #20794D;">"dim"</span>, <span class="st" style="color: #20794D;">"rank"</span>, <span class="st" style="color: #20794D;">"gpus"</span>, <span class="st" style="color: #20794D;">"nranks"</span>, <span class="st" style="color: #20794D;">"num_chunks"</span>, <span class="st" style="color: #20794D;">"num_partitions"</span>, <span class="st" style="color: #20794D;">"num_embeddings"</span>, <span class="st" style="color: #20794D;">"avg_doclen"</span>]</span></code></pre></div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="222">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb70-2">    RAG_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="223">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb71-2">    ColBERT_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="232">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> params: </span>
<span id="cb72-2">    <span class="cf" style="color: #003B4F;">if</span> p <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> [<span class="st" style="color: #20794D;">"num_chunks"</span>, <span class="st" style="color: #20794D;">"num_partitions"</span>, <span class="st" style="color: #20794D;">"num_embeddings"</span>, <span class="st" style="color: #20794D;">"avg_doclen"</span>]: <span class="cf" style="color: #003B4F;">assert</span> RAG_metadata[<span class="st" style="color: #20794D;">'config'</span>][p] <span class="op" style="color: #5E5E5E;">==</span> ColBERT_metadata[<span class="st" style="color: #20794D;">'config'</span>][p], p</span>
<span id="cb72-3">    <span class="cf" style="color: #003B4F;">elif</span> p <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"avg_doclen"</span>: <span class="cf" style="color: #003B4F;">assert</span> (RAG_metadata[p] <span class="op" style="color: #5E5E5E;">-</span> ColBERT_metadata[p]) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="fl" style="color: #AD0000;">1e-7</span></span>
<span id="cb72-4">    <span class="cf" style="color: #003B4F;">else</span>: <span class="cf" style="color: #003B4F;">assert</span> RAG_metadata[p] <span class="op" style="color: #5E5E5E;">==</span> ColBERT_metadata[p], p</span></code></pre></div>
</div>
</section>
<section id="comparing-index-artifacts" class="level3">
<h3 class="anchored" data-anchor-id="comparing-index-artifacts">Comparing Index Artifacts</h3>
<div class="cell" data-execution_count="236">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><span class="kw" style="color: #003B4F;">def</span> _compare_pt(r_path, c_path):</span>
<span id="cb73-2">    r <span class="op" style="color: #5E5E5E;">=</span> torch.load(r_path)</span>
<span id="cb73-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.load(c_path)</span>
<span id="cb73-4">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(r,<span class="bu" style="color: null;">tuple</span>):</span>
<span id="cb73-5">        <span class="cf" style="color: #003B4F;">assert</span> r[<span class="dv" style="color: #AD0000;">0</span>].shape <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">0</span>].shape</span>
<span id="cb73-6">        <span class="cf" style="color: #003B4F;">assert</span> (r[<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">0</span>]).<span class="bu" style="color: null;">float</span>().mean() <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb73-7">        <span class="cf" style="color: #003B4F;">assert</span> (r[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">1</span>]).<span class="bu" style="color: null;">float</span>().mean() <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb73-8">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb73-9">        <span class="cf" style="color: #003B4F;">assert</span> r.shape <span class="op" style="color: #5E5E5E;">==</span> c.shape</span>
<span id="cb73-10">        <span class="cf" style="color: #003B4F;">assert</span> (r <span class="op" style="color: #5E5E5E;">==</span> c).<span class="bu" style="color: null;">float</span>().mean() <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="237">
<div class="sourceCode cell-code" id="cb74" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1">files <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb74-2">    <span class="st" style="color: #20794D;">"0.codes.pt"</span>,</span>
<span id="cb74-3">    <span class="st" style="color: #20794D;">"0.residuals.pt"</span>,</span>
<span id="cb74-4">    <span class="st" style="color: #20794D;">"centroids.pt"</span>,</span>
<span id="cb74-5">    <span class="st" style="color: #20794D;">"ivf.pid.pt"</span>,</span>
<span id="cb74-6">    <span class="st" style="color: #20794D;">"buckets.pt"</span>,</span>
<span id="cb74-7">    <span class="st" style="color: #20794D;">"avg_residual.pt"</span>,</span>
<span id="cb74-8">    <span class="st" style="color: #20794D;">"doclens.0.json"</span></span>
<span id="cb74-9">]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="241">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><span class="cf" style="color: #003B4F;">for</span> f <span class="kw" style="color: #003B4F;">in</span> files:</span>
<span id="cb75-2">    <span class="cf" style="color: #003B4F;">if</span> f <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"doclens.0.json"</span>: </span>
<span id="cb75-3">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{</span>f<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> _f: RAG_doclens <span class="op" style="color: #5E5E5E;">=</span> json.load(_f)</span>
<span id="cb75-4">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{</span>f<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> _f: ColBERT_doclens <span class="op" style="color: #5E5E5E;">=</span> json.load(_f)</span>
<span id="cb75-5">        <span class="cf" style="color: #003B4F;">assert</span> RAG_doclens <span class="op" style="color: #5E5E5E;">==</span> ColBERT_doclens</span>
<span id="cb75-6">    <span class="cf" style="color: #003B4F;">else</span>: _compare_pt(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{</span>f<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{</span>f<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
</div>
<p>All index artifacts are equivalent! This further confirms the equivalency of the indexes created by RAGatouille and ColBERT.</p>
</section>
</section>
<section id="comparing-search-results" class="level2">
<h2 class="anchored" data-anchor-id="comparing-search-results">Comparing Search Results</h2>
<p>To reset, I had started this exploration with two questions:</p>
<ol type="1">
<li>For a given document collection and indexing configuration, do RAGatouille and ColBERT produce the same index?</li>
<li>For a given index and search configuration, do RAGatouille and ColBERT retrieve the same passages/Recall@10?</li>
</ol>
<p>The answer to the first question is YES. Let’s move on to answering the second question, starting by searching the RAGatouille index with RAGatouille.</p>
<section id="searching-ragatouille-index-with-ragatouille" class="level3">
<h3 class="anchored" data-anchor-id="searching-ragatouille-index-with-ragatouille">Searching RAGatouille Index with RAGatouille</h3>
<p>I will explicitly set search parameters for RAGatouille, even though they get set based on document collection size in <a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L266"><code>PLAIDModelIndex._load_searcher</code></a>:</p>
<div class="sourceCode" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> force_fast:</span>
<span id="cb76-2">    <span class="va" style="color: #111111;">self</span>.searcher.configure(ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span>)</span>
<span id="cb76-3">    <span class="va" style="color: #111111;">self</span>.searcher.configure(ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb76-4">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(<span class="va" style="color: #111111;">self</span>.searcher.collection) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">10000</span>:</span>
<span id="cb76-5">        <span class="va" style="color: #111111;">self</span>.searcher.configure(ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>)</span>
<span id="cb76-6">        <span class="va" style="color: #111111;">self</span>.searcher.configure(centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.4</span>)</span>
<span id="cb76-7">    <span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">len</span>(<span class="va" style="color: #111111;">self</span>.searcher.collection) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">100000</span>:</span>
<span id="cb76-8">        <span class="va" style="color: #111111;">self</span>.searcher.configure(ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>)</span>
<span id="cb76-9">        <span class="va" style="color: #111111;">self</span>.searcher.configure(centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.45</span>)</span>
<span id="cb76-10">    <span class="co" style="color: #5E5E5E;"># Otherwise, use defaults for k</span></span>
<span id="cb76-11"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb76-12">    <span class="co" style="color: #5E5E5E;"># Use fast settingss</span></span>
<span id="cb76-13">    <span class="va" style="color: #111111;">self</span>.searcher.configure(ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb76-14">    <span class="va" style="color: #111111;">self</span>.searcher.configure(centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>)</span>
<span id="cb76-15">    <span class="va" style="color: #111111;">self</span>.searcher.configure(ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>)</span></code></pre></div>
<div class="cell" data-execution_count="244">
<div class="sourceCode cell-code" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1">RAG.model.config.ncells <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb77-2">RAG.model.config.centroid_score_threshold <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.45</span></span>
<span id="cb77-3">RAG.model.config.ndocs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb77-4">RAG.model.config</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="244">
<pre><code>ColBERTConfig(query_token_id='[unused0]', doc_token_id='[unused1]', query_token='[Q]', doc_token='[D]', ncells=4, centroid_score_threshold=0.45, ndocs=1024, load_index_with_mmap=False, index_path=None, index_bsize=32, nbits=2, kmeans_niters=10, resume=False, pool_factor=1, clustering_mode='hierarchical', protected_tokens=0, similarity='cosine', bsize=32, accumsteps=1, lr=1e-05, maxsteps=15626, save_every=None, warmup=781, warmup_bert=None, relu=False, nway=32, use_ib_negatives=False, reranker=False, distillation_alpha=1.0, ignore_scores=False, model_name='answerdotai/AnswerAI-ColBERTv2.5-small', query_maxlen=32, attend_to_mask_tokens=False, interaction='colbert', dim=96, doc_maxlen=256, mask_punctuation=True, checkpoint='/home/vishal/.cache/huggingface/hub/models--answerdotai--answerai-colbert-small-v1/snapshots/be1703c55532145a844da800eea4c9a692d7e267/', triples='/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl', collection='/home/bclavie/colbertv2.5_en/data/msmarco/collection.tsv', queries='/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv', index_name=None, overwrite=False, root='.ragatouille/colbert/indexes', experiment='colbert', index_root=None, name='2024-08/07/08.16.20', rank=0, nranks=4, amp=True, gpus=4, avoid_fork_if_possible=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="422">
<div class="sourceCode cell-code" id="cb79" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1">ragatouille_results <span class="op" style="color: #5E5E5E;">=</span> {}</span></code></pre></div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="423">
<div class="sourceCode cell-code" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><span class="cf" style="color: #003B4F;">for</span> q <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb80-2">    results <span class="op" style="color: #5E5E5E;">=</span> RAG.search(q[<span class="st" style="color: #20794D;">'text'</span>], k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb80-3">    ragatouille_results[q[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> {result[<span class="st" style="color: #20794D;">'document_id'</span>]: <span class="bu" style="color: null;">float</span>(result[<span class="st" style="color: #20794D;">'score'</span>]) <span class="cf" style="color: #003B4F;">for</span> result <span class="kw" style="color: #003B4F;">in</span> results}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="424">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">ragatouille_results[<span class="st" style="color: #20794D;">'dev-0'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="424">
<pre><code>{'107-242': 69.9375,
 '496-116': 69.9375,
 '86-28': 69.875,
 '254-4': 69.875,
 '107-103': 69.875,
 '8-67': 69.8125,
 '98-46': 69.8125,
 '8-80': 69.8125,
 '8-116': 69.8125,
 '107-43': 69.8125}</code></pre>
</div>
</div>
<p>The mean Recall@10 for all 271 queries is 0.29.</p>
<div class="cell" data-execution_count="429">
<div class="sourceCode cell-code" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1">qrels <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb83-2"><span class="cf" style="color: #003B4F;">for</span> qrel_row <span class="kw" style="color: #003B4F;">in</span> qrels_rows:</span>
<span id="cb83-3">    qid <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"query_id"</span>]</span>
<span id="cb83-4">    pid <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"corpus_id"</span>]</span>
<span id="cb83-5">    rel <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"score"</span>]</span>
<span id="cb83-6">    qrels.setdefault(qid, {})</span>
<span id="cb83-7">    qrels[qid][pid] <span class="op" style="color: #5E5E5E;">=</span> rel</span></code></pre></div>
</div>
<div class="cell" data-execution_count="430">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1">evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb84-2">metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(ragatouille_results)</span>
<span id="cb84-3"><span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb84-4"></span>
<span id="cb84-5">mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb84-6">mean_recall</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="430">
<pre><code>0.2855810510889169</code></pre>
</div>
</div>
</section>
<section id="searching-the-colbert-index-with-colbert" class="level3">
<h3 class="anchored" data-anchor-id="searching-the-colbert-index-with-colbert">Searching the ColBERT Index with ColBERT</h3>
<p>Next, I’ll search the ColBERT index with ColBERT, setting the same configuration values as RAGatouille.</p>
<div class="cell" data-execution_count="297">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1">RAG.model.config.ncells, <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb86-2">RAG.model.config.centroid_score_threshold, <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb86-3">RAG.model.config.ndocs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="297">
<pre><code>(4, 0.45, 1024)</code></pre>
</div>
</div>
<p>ColBERT expects the queries to be structured as a dictionary, so I’ll prepare that accordingly:</p>
<div class="cell" data-execution_count="425">
<div class="sourceCode cell-code" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1">queries_dict <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb88-2"><span class="cf" style="color: #003B4F;">for</span> item <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb88-3">    queries_dict[item[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> item[<span class="st" style="color: #20794D;">'text'</span>]</span>
<span id="cb88-4"></span>
<span id="cb88-5"><span class="bu" style="color: null;">len</span>(queries_dict)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="425">
<pre><code>271</code></pre>
</div>
</div>
<p>I was posting on Twitter about how I wasn’t getting the same search results when using RAGatouille and vanilla ColBERT given the same index. <a href="https://ben.clavie.eu/">Benjamin Clavie</a>, the author of RAGatouille, kindly took some time to explain a core difference in how RAGatouille and ColBERT process queries:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Oh that'll be because ragatouille has a policy to never truncate queries so it updates the querylen to be <em>at least</em> the actual query length (further tests show it should be querylen + 8 at least, to get better augmentation). Your colbert (stanford) config is truncating to 32…
</p>
— Ben Clavié (<span class="citation" data-cites="bclavie">@bclavie</span>) <a href="https://twitter.com/bclavie/status/1921056639739678751?ref_src=twsrc%5Etfw">May 10, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>As was shared in his tweet, <a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L298">RAGatouille uses a larger maximum query length than ColBERT</a>. ColBERT uses a default of 32. So to replicate the same scores (and therefore the same top-k retrieved passages) I needed to mimic RAGatouille’s query length maximum.</p>
<p>Note that ColBERT doesn’t store original passage <code>_id</code>s like RAGatouille does, so I have to extract it from the original <code>passages</code> with <code>passages[idx]['_id']</code>.</p>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb90" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1">current_dir <span class="op" style="color: #5E5E5E;">=</span> os.path.abspath(<span class="st" style="color: #20794D;">"."</span>)</span>
<span id="cb90-2">index_root <span class="op" style="color: #5E5E5E;">=</span> os.path.join(current_dir, <span class="st" style="color: #20794D;">".ragatouille"</span>, <span class="st" style="color: #20794D;">"colbert"</span>, <span class="st" style="color: #20794D;">"indexes"</span>)</span>
<span id="cb90-3">colbert_results <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb90-4"></span>
<span id="cb90-5"><span class="cf" style="color: #003B4F;">for</span> q <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb90-6">    query_length <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(<span class="bu" style="color: null;">len</span>(q[<span class="st" style="color: #20794D;">'text'</span>].split(<span class="st" style="color: #20794D;">" "</span>)) <span class="op" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">1.35</span>) <span class="co" style="color: #5E5E5E;"># this lines comes from RAGatouille</span></span>
<span id="cb90-7">    <span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb90-8">        searcher <span class="op" style="color: #5E5E5E;">=</span> Searcher(</span>
<span id="cb90-9">            index<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ConditionalQA_ColBERT_index_full"</span>,</span>
<span id="cb90-10">            index_root<span class="op" style="color: #5E5E5E;">=</span>index_root,  </span>
<span id="cb90-11">            config<span class="op" style="color: #5E5E5E;">=</span>ColBERTConfig(</span>
<span id="cb90-12">                ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb90-13">                centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.45</span>,</span>
<span id="cb90-14">                ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span>,</span>
<span id="cb90-15">                query_maxlen<span class="op" style="color: #5E5E5E;">=</span>query_length</span>
<span id="cb90-16">            )</span>
<span id="cb90-17">        )</span>
<span id="cb90-18">    </span>
<span id="cb90-19">        ranking <span class="op" style="color: #5E5E5E;">=</span> searcher.search(q[<span class="st" style="color: #20794D;">'text'</span>], k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb90-20">        colbert_results[q[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> {passages[idx][<span class="st" style="color: #20794D;">'_id'</span>]: score <span class="cf" style="color: #003B4F;">for</span> idx, score <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">list</span>(<span class="bu" style="color: null;">zip</span>(ranking[<span class="dv" style="color: #AD0000;">0</span>], ranking[<span class="dv" style="color: #AD0000;">2</span>]))}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="427">
<div class="sourceCode cell-code" id="cb91" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1">evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb91-2">metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(colbert_results)</span>
<span id="cb91-3"><span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb91-4"></span>
<span id="cb91-5">mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb91-6">mean_recall</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="427">
<pre><code>0.2855810510889169</code></pre>
</div>
</div>
<p>With the maximum query length adjusted, ColBERT yields the same Recall@10 as RAGatouille! This makes sense because as Benjamin said in another tweet reply:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
It's most likely down to the default search settings in ragatouille being a bit more aggressive, so you end up with better results. If you change ncells/score_thresh/ndocs to more aggressive values I reckon the colbert library would match it? All ragatouille does under the hood is wrap things with strong defaults/abstractions 😄
</p>
— Ben Clavié (<span class="citation" data-cites="bclavie">@bclavie</span>) <a href="https://twitter.com/bclavie/status/1921052397314732447?ref_src=twsrc%5Etfw">May 10, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>While the exact same recall is a good check, I’ll double check that for each query, the retrieved passage IDs and scores are identical between RAGatouille and ColBERT.</p>
<div class="cell" data-execution_count="428">
<div class="sourceCode cell-code" id="cb93" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> colbert_results.keys():</span>
<span id="cb93-2">    <span class="cf" style="color: #003B4F;">for</span> pid, score <span class="kw" style="color: #003B4F;">in</span> colbert_results[i].items():</span>
<span id="cb93-3">        <span class="cf" style="color: #003B4F;">assert</span> ragatouille_results[i][pid] <span class="op" style="color: #5E5E5E;">==</span> score</span></code></pre></div>
</div>
</section>
<section id="searching-ragatouille-index-with-colbert-and-vice-versa" class="level3">
<h3 class="anchored" data-anchor-id="searching-ragatouille-index-with-colbert-and-vice-versa">Searching RAGatouille Index with ColBERT (and vice versa)</h3>
<p>As a final check of consistency, I’ll search the RAGatouille index with ColBERT and search the ColBERT index with RAGatouille and confirm that they yield the same retrieved passages and Recall@10.</p>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1">current_dir <span class="op" style="color: #5E5E5E;">=</span> os.path.abspath(<span class="st" style="color: #20794D;">"."</span>)</span>
<span id="cb94-2">index_root <span class="op" style="color: #5E5E5E;">=</span> os.path.join(current_dir, <span class="st" style="color: #20794D;">".ragatouille"</span>, <span class="st" style="color: #20794D;">"colbert"</span>, <span class="st" style="color: #20794D;">"indexes"</span>)</span>
<span id="cb94-3">colbert_results2 <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb94-4"></span>
<span id="cb94-5"><span class="cf" style="color: #003B4F;">for</span> q <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb94-6">    query_length <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(<span class="bu" style="color: null;">len</span>(q[<span class="st" style="color: #20794D;">'text'</span>].split(<span class="st" style="color: #20794D;">" "</span>)) <span class="op" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">1.35</span>)</span>
<span id="cb94-7">    <span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb94-8">        searcher <span class="op" style="color: #5E5E5E;">=</span> Searcher(</span>
<span id="cb94-9">            index<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ConditionalQA_RAGatouille_index_full"</span>,</span>
<span id="cb94-10">            index_root<span class="op" style="color: #5E5E5E;">=</span>index_root,  </span>
<span id="cb94-11">            config<span class="op" style="color: #5E5E5E;">=</span>ColBERTConfig(</span>
<span id="cb94-12">                ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb94-13">                centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.45</span>,</span>
<span id="cb94-14">                ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span>,</span>
<span id="cb94-15">                query_maxlen<span class="op" style="color: #5E5E5E;">=</span>query_length</span>
<span id="cb94-16">            )</span>
<span id="cb94-17">        )</span>
<span id="cb94-18">    </span>
<span id="cb94-19">        ranking <span class="op" style="color: #5E5E5E;">=</span> searcher.search(q[<span class="st" style="color: #20794D;">'text'</span>], k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb94-20">        colbert_results2[q[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> {passages[idx][<span class="st" style="color: #20794D;">'_id'</span>]: score <span class="cf" style="color: #003B4F;">for</span> idx, score <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">list</span>(<span class="bu" style="color: null;">zip</span>(ranking[<span class="dv" style="color: #AD0000;">0</span>], ranking[<span class="dv" style="color: #AD0000;">2</span>]))}</span></code></pre></div>
</div>
<p>We get the same results as searching the ColBERT index with ColBERT! This again further proves that these two frameworks produce the same indexes (which is to be expected).</p>
<div class="cell" data-execution_count="432">
<div class="sourceCode cell-code" id="cb95" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> colbert_results.keys():</span>
<span id="cb95-2">    <span class="cf" style="color: #003B4F;">for</span> pid, score <span class="kw" style="color: #003B4F;">in</span> colbert_results[i].items():</span>
<span id="cb95-3">        <span class="cf" style="color: #003B4F;">assert</span> colbert_results2[i][pid] <span class="op" style="color: #5E5E5E;">==</span> score</span></code></pre></div>
</div>
<div class="cell" data-execution_count="433">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb96-2">metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(colbert_results2)</span>
<span id="cb96-3"><span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb96-4"></span>
<span id="cb96-5">mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb96-6">mean_recall</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="433">
<pre><code>0.2855810510889169</code></pre>
</div>
</div>
<p>Finally, as the last piece of this exercise, I’ll search the ColBERT index with RAGatouille and see if I get the same result. I certainly expect to!</p>
</section>
<section id="searching-colbert-index-with-ragatouille" class="level3">
<h3 class="anchored" data-anchor-id="searching-colbert-index-with-ragatouille">Searching ColBERT Index with RAGatouille</h3>
<p>RAGatouille creates two files (collection.json and pid_docid_map.json) which ColBERT does not, so we have to create them manually for RAGatouille to search the ColBERT Index.</p>
<p>collection.json is just a list of the document collection text.</p>
<div class="cell" data-execution_count="434">
<div class="sourceCode cell-code" id="cb98" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/collection.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb98-2">    RAG_collection <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="435">
<div class="sourceCode cell-code" id="cb99" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><span class="bu" style="color: null;">len</span>(RAG_collection)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="435">
<pre><code>69199</code></pre>
</div>
</div>
<div class="cell" data-execution_count="436">
<div class="sourceCode cell-code" id="cb101" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1">RAG_collection[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="436">
<pre><code>['Overview',
 'You can only make a claim for Child Tax Credit if you already get Working Tax Credit.',
 'If you cannot apply for Child Tax Credit, you can apply for Universal Credit instead.',
 'You might be able to apply for Pension Credit if you and your partner are State Pension age or over.',
 'What you’ll get']</code></pre>
</div>
</div>
<p>pid_docid_map.json is a dictionary where the keys are the index in the collection and the values are the dataset’s defined <code>_id</code> string.</p>
<div class="cell" data-execution_count="437">
<div class="sourceCode cell-code" id="cb103" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/pid_docid_map.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb103-2">    RAG_pid_docid_map <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="438">
<div class="sourceCode cell-code" id="cb104" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><span class="bu" style="color: null;">list</span>(RAG_pid_docid_map.items())[<span class="dv" style="color: #AD0000;">0</span>], <span class="bu" style="color: null;">list</span>(RAG_pid_docid_map.items())[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="438">
<pre><code>(('0', '0-0'), ('69198', '651-91'))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="439">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1">passages[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="439">
<pre><code>{'_id': '651-91',
 'text': 'Trade union reps can be on picket lines at different workplaces if they’re responsible for organising workers in those workplaces.',
 'title': 'Taking part in industrial action and strikes',
 'doc_id': '651',
 'paragraph_no': 91,
 'total_paragraphs': 92,
 'is_candidate': True}</code></pre>
</div>
</div>
<p>Saving the collection as a JSON is simple enough, I just dump <code>passages['text']</code> into a JSON file.</p>
<div class="cell" data-execution_count="289">
<div class="sourceCode cell-code" id="cb108" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1">srsly.write_json(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/collection.json"</span>, passages[<span class="st" style="color: #20794D;">'text'</span>])</span></code></pre></div>
</div>
<p>Creating pid_docid_map.json is also quite straightforward. I map from the index of the passage item to its <code>_id</code>.</p>
<div class="cell" data-execution_count="440">
<div class="sourceCode cell-code" id="cb109" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1">pid_docid_map <span class="op" style="color: #5E5E5E;">=</span> {<span class="bu" style="color: null;">str</span>(i): p[<span class="st" style="color: #20794D;">'_id'</span>] <span class="cf" style="color: #003B4F;">for</span> i,p <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(passages)}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="441">
<div class="sourceCode cell-code" id="cb110" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><span class="bu" style="color: null;">list</span>(pid_docid_map.items())[<span class="dv" style="color: #AD0000;">0</span>], <span class="bu" style="color: null;">list</span>(pid_docid_map.items())[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="441">
<pre><code>(('0', '0-0'), ('69198', '651-91'))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="287">
<div class="sourceCode cell-code" id="cb112" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1">srsly.write_json(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/pid_docid_map.json"</span>, pid_docid_map)</span></code></pre></div>
</div>
<p>Let’s make sure these match the RAGatouille-built artifacts:</p>
<div class="cell" data-execution_count="442">
<div class="sourceCode cell-code" id="cb113" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><span class="cf" style="color: #003B4F;">for</span> i, _id <span class="kw" style="color: #003B4F;">in</span> RAG_pid_docid_map.items(): <span class="cf" style="color: #003B4F;">assert</span> _id <span class="op" style="color: #5E5E5E;">==</span> pid_docid_map[i]</span>
<span id="cb113-2"><span class="cf" style="color: #003B4F;">for</span> i, _id <span class="kw" style="color: #003B4F;">in</span> pid_docid_map.items(): <span class="cf" style="color: #003B4F;">assert</span> _id <span class="op" style="color: #5E5E5E;">==</span> RAG_pid_docid_map[i]</span></code></pre></div>
</div>
<p>With those two files created, I can now create a <code>RAGPretrainedModel</code> object <code>from_index</code> using the ColBERT index.</p>
<div class="cell" data-execution_count="443">
<div class="sourceCode cell-code" id="cb114" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1">RAG2 <span class="op" style="color: #5E5E5E;">=</span> RAGPretrainedModel.from_index(ColBERT_index_path)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Constructing default index configuration for index `None` as it does not contain RAGatouille specific metadata.</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb116" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1">RAG2.model.config.ncells <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb116-2">RAG2.model.config.centroid_score_threshold <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.45</span></span>
<span id="cb116-3">RAG2.model.config.ndocs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb116-4"></span>
<span id="cb116-5">ragatouille_results2 <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb116-6"></span>
<span id="cb116-7"></span>
<span id="cb116-8"><span class="cf" style="color: #003B4F;">for</span> q <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb116-9">    results <span class="op" style="color: #5E5E5E;">=</span> RAG2.search(q[<span class="st" style="color: #20794D;">'text'</span>], k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb116-10">    ragatouille_results2[q[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> {result[<span class="st" style="color: #20794D;">'document_id'</span>]: <span class="bu" style="color: null;">float</span>(result[<span class="st" style="color: #20794D;">'score'</span>]) <span class="cf" style="color: #003B4F;">for</span> result <span class="kw" style="color: #003B4F;">in</span> results}</span></code></pre></div>
</div>
<p>We get the same results as searching the RAGatouille index with RAGatouille, searching the ColBERT index with ColBERT and searching the RAGatouille index with ColBERT!</p>
<div class="cell" data-execution_count="445">
<div class="sourceCode cell-code" id="cb117" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> colbert_results.keys():</span>
<span id="cb117-2">    <span class="cf" style="color: #003B4F;">for</span> pid, score <span class="kw" style="color: #003B4F;">in</span> colbert_results[i].items():</span>
<span id="cb117-3">        <span class="cf" style="color: #003B4F;">assert</span> ragatouille_results2[i][pid] <span class="op" style="color: #5E5E5E;">==</span> score</span></code></pre></div>
</div>
<div class="cell" data-execution_count="446">
<div class="sourceCode cell-code" id="cb118" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1">evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb118-2">metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(ragatouille_results2)</span>
<span id="cb118-3"><span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb118-4"></span>
<span id="cb118-5">mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb118-6">mean_recall</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="446">
<pre><code>0.2855810510889169</code></pre>
</div>
</div>
</section>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Every interaction I’ve had with RAGatouille and ColBERT has been an awesome learning experience. I feel like inspecting their behavior and artifacts as left me with a better understanding of information retrieval in general. One small learning that I left out: ColBERT uses FAISS for k-means clustering while for small document collections (such as my initial 1k subset) RAGatouille uses a PyTorch implementation. This difference, even though all relevant configuration parameters were equal, resulted in different index artifacts. There was only about a 15% overlap between the <code>centroids.pt</code> tensors of the resulting RAGatouille and ColBERT indexes.</p>
<p>Another piece of motivation for me is that I needed to use both RAGatouille and ColBERT for indexing the full set of UKPLab/DAPR document collections, as ColBERT was able to index the larger collections (6M+) without crashing the kernel, while RAGatouille was not. In some initial experiments I was getting different mean Recall@10 values when using RAGatouille versus when using ColBERT (because I hadn’t incorporated the max query length code and probably had different configs). So I felt like this was a good opportunity, once and for all, to answer the two questions I listed at the start of this notebook:</p>
<ol type="1">
<li>For a given document collection and indexing configuration, do RAGatouille and ColBERT produce the same index?</li>
<li>For a given index and search configuration, do RAGatouille and ColBERT retrieve the same passages/Recall@10?</li>
</ol>
<p>The answer for both, is a resounding yes! With this knowledge in my belt, I can now move forward with indexing and searching with either library as I please.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>information retrieval</category>
  <category>RAGatouille</category>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-10-RAGatouille-ColBERT-Comparisons/index.html</guid>
  <pubDate>Sat, 10 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TIL: Resolving RAGatouille OOM Error and faiss-gpu Warning</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-08-TIL-RAGatouille/index.html</link>
  <description><![CDATA[ 



<p>I’m in the process of indexing the UKPLab/DAPR datasets, which span in size from ~70k to ~32M documents. Using a RTX3090, I ran into an OOM error (during search) and a warning stating that faiss-cpu was being used instead of faiss-gpu, causing the indexing process to take longer.</p>
<p>I found <a href="https://github.com/AnswerDotAI/RAGatouille/issues/177">this RAGatouille GitHub issue</a> which recommended lowering the <code>batch_size</code> in ColBERT’s <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L121"><code>IndexScorer.score_pids</code> method</a>. I made that change (from 2^20 to 2^16) and that resolved the OOM error, at least for the 2.68M document collection (NaturalQuestions).</p>
<p>When I was using Google Colab GPUs, the following install commands correctly installed faiss-gpu after installing RAGatouille:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">pip uninstall <span class="op" style="color: #5E5E5E;">-</span>y faiss<span class="op" style="color: #5E5E5E;">-</span>cpu</span>
<span id="cb1-2">pip install faiss<span class="op" style="color: #5E5E5E;">-</span>gpu<span class="op" style="color: #5E5E5E;">-</span>cu12</span></code></pre></div>
<p>Using an RTX3090 (not on Colab), this was not correctly installing faiss-gpu, leading to the following RAGatouille warning during indexing, and as a result, using the CPU for indexing (which eventually crashed the kernel):</p>
<pre><code>________________________________________________________________________________
WARNING! You have a GPU available, but only `faiss-cpu` is currently installed.
This means that indexing will be slow. To make use of your GPU
Please install `faiss-gpu` by running:
pip uninstall --y faiss-cpu &amp; pip install faiss-gpu
________________________________________________________________________________</code></pre>
<p>This warning is thrown in RAGatouille’s <a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L226"><code>PLAIDModelIndex.build</code></a> if <code>hasattr(faiss, "StandardGpuResources")</code> is <code>False</code>.</p>
<p>Looking at the <a href="https://github.com/facebookresearch/faiss/tree/main#:~:text=faiss%2Dcpu%2C-,faiss%2Dgpu,-and%20faiss%2Dgpu">faiss repo</a>, they recommend using conda for installation. I ran <code>conda install pytorch::faiss-gpu</code>, restarted the kernel, confirmed that <code>hasattr(faiss, "StandardGpuResources")</code> returns <code>True</code> and was successfully able to circumvent that warning. As a result, RAGatouille was able to use faiss-gpu and it was able to index 2M document.</p>
<p>It’s still TBD if this allows me to finish indexing all of my datasets (especially the 13M and 32M ones).</p>
<p>In a conversation with Claude, I outlined a few different scenarios that I may have to (get to) pursue:</p>
<blockquote class="blockquote">
<p>Since both repos are open sourced, I can fork them (which I have) and add print statements/modify code to debug as needed.</p>
<p>I am running into a couple issues that I’m trying to resolve. I don’t want you to suggest any code yet, let’s think this through.</p>
<ol type="1">
<li>When performing retrieval on a 2.6M document collection on an RTX3090, RAGatouille.search throws an OOM error.</li>
<li>So I chose to run retrieval on the RAGatouille index using vanilla ColBERT and it did not run out of memory.</li>
<li>However, the retrieval results are <em>significantly</em> different between ColBERT and RAGatouille.</li>
</ol>
<p>Each of these gives me a uniquely interesting direction to pursue:</p>
<ol type="1">
<li>Why does RAGatouille throw the OOM error? 2.6M documents (index with 8.5GB disk space) is not small, but not terribly large. There’s an issue open in RAGatouille where they note that changing batch_size in score_pids in IndexScorer resolves an OOM error during search. I want to give this a try!</li>
<li>Why does ColBERT not run out of memory? But RAGatouille does?</li>
<li>Why are the retrieval results between RAGatouille and ColBERT different? The RAGatouille documentation says the following, which leads me to believe they should yield the same results:</li>
</ol>
<p>If you’d like to use more than RAGatouille, ColBERT has a growing number of integrations, and they all fully support models trained or fine-tuned with RAGatouille! The official ColBERT implementation has a built-in query server (using Flask), which you can easily query via API requests and does support indexes generated with RAGatouille! This should be enough for most small applications, so long as you can persist the index on disk.</p>
<p>Each of these explorations are fascinating, and I think I’m going to pursue each one.</p>
<ol type="1">
<li>resolving the RAGatouille OOM error would solve my immediate problem. ideally I tackle this first.</li>
<li>Understanding memory usage between RAGatouille and ColBERT has been an ongoing interest of mine. I have memory profiled both before during indexing, but not during search. This would be a very interesting research task.</li>
<li>Debugging the searching/scoring difference would be probably the hardest task. I would likely have to trace down all function calls, checking intermedite values, comparing them between the two frameworks. Absolutely fascinating and would learn a ton. Would also be a significant achievement to resolve the discrepancy (maybe something in the Config? Maybe something more fundamental?)</li>
</ol>
</blockquote>
<p>TBD on whether I pursue points 2 and 3.</p>



 ]]></description>
  <category>information retrieval</category>
  <category>deep learning</category>
  <category>RAGatouille</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-08-TIL-RAGatouille/index.html</guid>
  <pubDate>Thu, 08 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>DataInspector: Inspecting input_ids Token Statistics in LLM-Foundry with packing_ratio=5.0</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-08-DataInspector/index.html</link>
  <description><![CDATA[ 






 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-08-DataInspector/index.html</guid>
  <pubDate>Thu, 08 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Understanding Sequence Packing - Initial Musings</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-04-Understanding-Sequence-Packing/index.html</link>
  <description><![CDATA[ 



<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<div class="cell">
<details>
<summary>Show pip installs and imports</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;">!</span>pip install <span class="op" style="color: #5E5E5E;">-</span>qq <span class="op" style="color: #5E5E5E;">-</span>U flash<span class="op" style="color: #5E5E5E;">-</span>attn <span class="op" style="color: #5E5E5E;">--</span>no<span class="op" style="color: #5E5E5E;">-</span>build<span class="op" style="color: #5E5E5E;">-</span>isolation</span>
<span id="cb1-2"><span class="op" style="color: #5E5E5E;">!</span>pip uninstall transformers <span class="op" style="color: #5E5E5E;">-</span>y</span>
<span id="cb1-3"><span class="op" style="color: #5E5E5E;">!</span>pip install git<span class="op" style="color: #5E5E5E;">+</span>https:<span class="op" style="color: #5E5E5E;">//</span>github.com<span class="op" style="color: #5E5E5E;">/</span>vishalbakshi<span class="op" style="color: #5E5E5E;">/</span>transformers.git <span class="op" style="color: #5E5E5E;">-</span>qq</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> inspect</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">import</span> torch.nn.functional <span class="im" style="color: #00769E;">as</span> F</span>
<span id="cb1-9"></span>
<span id="cb1-10">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span></span>
<span id="cb1-11"></span>
<span id="cb1-12">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb1-13">    model_name,</span>
<span id="cb1-14">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb1-15">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span>torch.bfloat16,</span>
<span id="cb1-16">    device_map<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"auto"</span>)</span>
<span id="cb1-17"></span>
<span id="cb1-18">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(model_name)</span></code></pre></div>
</details>
</div>
</section>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post, I’m walking through <code>transformers</code> code to start exploring functionality between sequence packing and Flash Attention. I’m new to both concepts, so this is purely an exploratory exercise.</p>
<p>To assist my exploration, I’ve forked the Transformers library and added print statements at key junctures related to sequence packing and FA2. Referencing the original repo here’s where I’ve inserted print statements:</p>
<ul>
<li>Right after the function signature for <code>flash_attention_forward</code> in <a href="https://github.com/huggingface/transformers/blob/2932f318a20d9e54cc7aea052e040164d85de7d6/src/transformers/integrations/flash_attention.py#L22">src/transformers/integrations/flash_attention.py</a> (which is called from inside <code>model.model.layers[0].self_attn.forward</code>).</li>
</ul>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">=== FLASH_ATTENTION_FORWARD ENTRY ==="</span>)</span>
<span id="cb2-2"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"kwargs received: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">list</span>(kwargs.keys())<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<ul>
<li>Right after the function signature/docstring for <code>_flash_attention_forward</code> in <a href="https://github.com/huggingface/transformers/blob/2932f318a20d9e54cc7aea052e040164d85de7d6/src/transformers/modeling_flash_attention_utils.py#L324">src/transformers/modeling_flash_attention_utils.py</a>:</li>
</ul>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">=== _FLASH_ATTENTION_FORWARD ENTRY ==="</span>)</span>
<span id="cb3-2"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"kwargs received: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">list</span>(kwargs.keys())<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;"> attention_mask"</span>)</span>
<span id="cb3-5"><span class="bu" style="color: null;">print</span>(attention_mask)</span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;"> position_ids"</span>)</span>
<span id="cb3-8"><span class="bu" style="color: null;">print</span>(position_ids)</span></code></pre></div>
<p>In the same file, later on:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Contains at least one padding token in the sequence</span></span>
<span id="cb4-2"><span class="cf" style="color: #003B4F;">if</span> attention_mask <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-3">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"attention_mask is not None"</span>)</span>
<span id="cb4-4">    ...</span></code></pre></div>
<p>and later on further in the <code>_flash_attention_forward</code> function definition:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="cf" style="color: #003B4F;">elif</span> position_ids <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> (</span>
<span id="cb5-2">    max_length_q <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> (query_length <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="kw" style="color: #003B4F;">and</span> <span class="kw" style="color: #003B4F;">not</span> (torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">&gt;=</span> <span class="dv" style="color: #AD0000;">0</span>).<span class="bu" style="color: null;">all</span>())</span>
<span id="cb5-3">):</span>
<span id="cb5-4">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"position_ids is not None and max_length_q check"</span>)</span>
<span id="cb5-5">    batch_size <span class="op" style="color: #5E5E5E;">=</span> query_states.size(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb5-6"></span>
<span id="cb5-7">    <span class="cf" style="color: #003B4F;">if</span> cu_seq_lens_q <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> cu_seq_lens_k <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb5-8">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"cu_seq_lens_q is None: </span><span class="sc" style="color: #5E5E5E;">{</span>cu_seq_lens_q <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb5-9">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"cu_seq_lens_k is None: </span><span class="sc" style="color: #5E5E5E;">{</span>cu_seq_lens_q <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb5-10">        query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb5-11">            prepare_fa2_from_position_ids(query_states, key_states, value_states, position_ids)</span>
<span id="cb5-12">        )</span>
<span id="cb5-13"></span>
<span id="cb5-14">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;"> cu_seq_lens"</span>)</span>
<span id="cb5-15">        <span class="bu" style="color: null;">print</span>(cu_seq_lens)</span>
<span id="cb5-16">        cu_seq_lens_q, cu_seq_lens_k <span class="op" style="color: #5E5E5E;">=</span> cu_seq_lens</span>
<span id="cb5-17">        max_length_q, max_length_k <span class="op" style="color: #5E5E5E;">=</span> max_seq_lens</span>
<span id="cb5-18"></span>
<span id="cb5-19">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb5-20">        ...</span></code></pre></div>
<p>I originally identified these functions by using the <code>inspect</code> library, e.g.:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="bu" style="color: null;">print</span>(inspect.getsource(model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.forward))</span></code></pre></div>
<p>The goal of these print functions initially was to understand how <code>cu_seqlens</code> is utilized (if at all) and then after realizing it wasn’t being used, my goal became to understand which function form <code>flash_attn</code> is being used: <code>flash_attn_func</code> or <code>flash_attn_varlen_func</code>?</p>
</section>
<section id="initial-example-passing-in-input_ids-cu_seqlens-and-max_seqlen-to-the-smollm2-135m-forward-pass" class="level2">
<h2 class="anchored" data-anchor-id="initial-example-passing-in-input_ids-cu_seqlens-and-max_seqlen-to-the-smollm2-135m-forward-pass">Initial Example: Passing in <code>input_ids</code>, <code>cu_seqlens</code> and <code>max_seqlen</code> to the SmolLM2-135M Forward Pass</h2>
<p>At first, based on a Claude-generated example, I passed in the following fake input data.</p>
<div class="cell" data-outputid="6bc4c7d5-d953-4f4b-911c-b1b2936fbb5c" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb7-2">test_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb7-3">    <span class="st" style="color: #20794D;">'input_ids'</span>: torch.randint(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">10</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">10</span>)).to(<span class="st" style="color: #20794D;">"cuda"</span>),</span>
<span id="cb7-4">    <span class="st" style="color: #20794D;">'cu_seqlens'</span>: [torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32).to(<span class="st" style="color: #20794D;">"cuda"</span>)],</span>
<span id="cb7-5">    <span class="st" style="color: #20794D;">'max_seqlen'</span>: [<span class="dv" style="color: #AD0000;">10</span>]</span>
<span id="cb7-6">}</span>
<span id="cb7-7">test_params</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>{'input_ids': tensor([[7, 6, 8, 5, 1, 3, 8, 6, 5, 3]], device='cuda:0'),
 'cu_seqlens': [tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32)],
 'max_seqlen': [10]}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb9-2"><span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): output <span class="op" style="color: #5E5E5E;">=</span> model(<span class="op" style="color: #5E5E5E;">**</span>test_params)</span></code></pre></div>
</div>
<p>The following was printed out for each attention mechanism call in each of the model’s 30 layers:</p>
<pre><code>=== FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['position_ids', 'output_attentions', 'use_cache', 'cu_seqlens', 'max_seqlen']

=== _FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['output_attentions', 'use_cache', 'cu_seqlens', 'max_seqlen']

 attention_mask
None

 position_ids
tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], device='cuda:0')
flash_attn_func is called
flash_kwargs received: ['deterministic']</code></pre>
<p>I was surprised to see that <code>flash_attn_func</code> was called, because IIUC that doesn’t handle sequence packed inputs. Looking at <a href="https://github.com/Dao-AILab/flash-attention/blob/fd2fc9d85c8e54e5c20436465bca709bc1a6c5a1/hopper/flash_attn_interface.py#L501">its function signature</a>, there’s no <code>cu_seqlens</code> or similar parameter:</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="kw" style="color: #003B4F;">def</span> flash_attn_func(</span>
<span id="cb11-2">    q,</span>
<span id="cb11-3">    k,</span>
<span id="cb11-4">    v,</span>
<span id="cb11-5">    softmax_scale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb11-6">    causal<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb11-7">    qv<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb11-8">    q_descale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, k_descale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, v_descale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb11-9">    window_size<span class="op" style="color: #5E5E5E;">=</span>(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>),</span>
<span id="cb11-10">    attention_chunk<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb11-11">    softcap<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.0</span>,</span>
<span id="cb11-12">    num_splits<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb11-13">    pack_gqa<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb11-14">    deterministic<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb11-15">    sm_margin<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb11-16">)</span></code></pre></div>
<p>Additionally, <code>position_ids</code> is defined even though I didn’t pass it in. IIUC, that’s done in the model’s forward pass with the line:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="cf" style="color: #003B4F;">if</span> position_ids <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb12-2">    position_ids <span class="op" style="color: #5E5E5E;">=</span> cache_position.unsqueeze(<span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<p>Where <code>cache_position</code> is defined earlier in that forward pass. This can be observed by running:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">forward_method <span class="op" style="color: #5E5E5E;">=</span> inspect.getsource(model.model.forward)</span>
<span id="cb13-2"><span class="bu" style="color: null;">print</span>(forward_method)</span></code></pre></div>
</section>
<section id="second-attempt-passing-in-position_ids-to-the-forward-pass-as-well" class="level2">
<h2 class="anchored" data-anchor-id="second-attempt-passing-in-position_ids-to-the-forward-pass-as-well">Second Attempt: Passing in <code>position_ids</code> to the Forward Pass as Well</h2>
<p>Claude helped me understand that what triggers the function call of <code>flash_attn_varlen_func</code> is the following conditional in <a href="https://github.com/huggingface/transformers/blob/2932f318a20d9e54cc7aea052e040164d85de7d6/src/transformers/modeling_flash_attention_utils.py#L378"><code>_flash_attention_forward</code></a>:</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="cf" style="color: #003B4F;">elif</span> position_ids <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> (</span>
<span id="cb14-2">        max_length_q <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> (query_length <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="kw" style="color: #003B4F;">and</span> <span class="kw" style="color: #003B4F;">not</span> (torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">&gt;=</span> <span class="dv" style="color: #AD0000;">0</span>).<span class="bu" style="color: null;">all</span>())</span>
<span id="cb14-3">    )</span></code></pre></div>
<p>In particular, this line was of interest: <code>torch.diff(position_ids, dim=-1) &gt;= 0</code></p>
<p>In the following contrived example, <code>position_ids</code> is not a list of consecutive numbers (which seems to be the default value constructed is no <code>position_ids</code> value is passed to the model’s forward pass).</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">input_ids <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">10</span>, <span class="dv" style="color: #AD0000;">11</span>, <span class="dv" style="color: #AD0000;">12</span>, <span class="dv" style="color: #AD0000;">13</span>, <span class="dv" style="color: #AD0000;">14</span>, <span class="dv" style="color: #AD0000;">15</span>, <span class="dv" style="color: #AD0000;">16</span>]]).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb15-2">position_ids <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">6</span>]]).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb15-3">cu_seqlens <span class="op" style="color: #5E5E5E;">=</span> [torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32).to(<span class="st" style="color: #20794D;">"cuda"</span>)]</span></code></pre></div>
</div>
<div class="cell" data-outputid="46c76718-2cd2-411b-eb4e-5822cb0d73d7" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">(torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">&gt;=</span> <span class="dv" style="color: #AD0000;">0</span>).<span class="bu" style="color: null;">all</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor(False, device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="5bed5591-9d67-4d15-cb42-8b1ab15f3089" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">&gt;=</span> <span class="dv" style="color: #AD0000;">0</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([[ True,  True, False,  True,  True,  True,  True,  True,  True]],
       device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="d15b4b7a-5cee-4651-e5b3-861f7c4d03b6" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([[ 1,  1, -2,  1,  1,  1,  1,  1,  1]], device='cuda:0')</code></pre>
</div>
</div>
<p>Some diffs between consecutive elements in <code>position_ids</code> are negative (because we are defining two sequences’ position ids).</p>
<p>I would now expect <code>flash_attn_varlen_func</code> to be called.</p>
<div class="cell" data-outputid="bbd565ce-415c-4756-98f0-364a438ed5ed" data-execution_count="43">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb22-2">test_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb22-3">    <span class="st" style="color: #20794D;">'input_ids'</span>: torch.randint(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">10</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">10</span>)).to(<span class="st" style="color: #20794D;">"cuda"</span>),</span>
<span id="cb22-4">    <span class="st" style="color: #20794D;">'position_ids'</span>: torch.tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">6</span>]]).to(<span class="st" style="color: #20794D;">"cuda"</span>),</span>
<span id="cb22-5">    <span class="st" style="color: #20794D;">'cu_seqlens'</span>: [torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32).to(<span class="st" style="color: #20794D;">"cuda"</span>)],</span>
<span id="cb22-6">    <span class="st" style="color: #20794D;">'max_seqlen'</span>: [<span class="dv" style="color: #AD0000;">7</span>]</span>
<span id="cb22-7">}</span>
<span id="cb22-8">test_params</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>{'input_ids': tensor([[7, 6, 8, 5, 1, 3, 8, 6, 5, 3]], device='cuda:0'),
 'position_ids': tensor([[0, 1, 2, 0, 1, 2, 3, 4, 5, 6]], device='cuda:0'),
 'cu_seqlens': [tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32)],
 'max_seqlen': [7]}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb24-2"><span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): output <span class="op" style="color: #5E5E5E;">=</span> model(<span class="op" style="color: #5E5E5E;">**</span>test_params)</span></code></pre></div>
</div>
<p>Passing <code>test_params</code> through the model’s forward pass yields:</p>
<pre><code>=== FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['position_ids', 'output_attentions', 'use_cache', 'cu_seqlens', 'max_seqlen']

=== _FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['output_attentions', 'use_cache', 'cu_seqlens', 'max_seqlen']

 attention_mask
None

 position_ids
tensor([[0, 1, 2, 0, 1, 2, 3, 4, 5, 6]], device='cuda:0')
position_ids is not None and max_length_q check
cu_seq_lens_q is None: True
cu_seq_lens_k is None: True

 cu_seq_lens
(tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32), tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32))</code></pre>
<p>The <code>position_ids</code> are as passed in. However, it does not use <code>cu_seqlens</code> directly from <code>kwargs</code>. Instead it builds it <a href="https://github.com/huggingface/transformers/blob/2932f318a20d9e54cc7aea052e040164d85de7d6/src/transformers/modeling_flash_attention_utils.py#L383">in the following line</a>:</p>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb26-2">    prepare_fa2_from_position_ids(query_states, key_states, value_states, position_ids)</span>
<span id="cb26-3">)</span></code></pre></div>
<p>The value of <code>cu_seqlens</code> is the tuple:</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">(tensor([ <span class="dv" style="color: #AD0000;">0</span>,  <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cuda:0'</span>, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32), tensor([ <span class="dv" style="color: #AD0000;">0</span>,  <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cuda:0'</span>, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32))</span></code></pre></div>
<p>Which is deconstructed into <code>cu_seq_lens_q</code> and <code>cu_seql_lens_k</code> which are then passed as arguments to <code>flash_attn_varlen_func</code>.</p>
<p>The main takeaway from this: Flash Attention will not handle sequence packing correctly unless you pass in <code>position_ids</code>.</p>
</section>
<section id="packed-sequence-loss" class="level2">
<h2 class="anchored" data-anchor-id="packed-sequence-loss">Packed Sequence Loss</h2>
<p>In the remaining sections of this blog post, I’ll explore how to correctly handle calculating loss for a packed sequence.</p>
<div class="cell" data-outputid="05592fff-ecf2-4adf-e347-a4526778898f" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">output.logits.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>torch.Size([1, 10, 49152])</code></pre>
</div>
</div>
<p>Following how labels are constructed in HuggingFace’s <a href="https://github.com/RhuiDih/transformers/blob/90305596c1f14376bb2049f408a4c53e024b2450/src/transformers/data/data_collator.py#L1643"><code>DataCollatorWithFlattening</code></a>, the first token in each sequence is replaced with <code>-100</code>. This is because the HuggingFace CausalLM loss function handles the shifting of labels to allow next-token prediction.</p>
<div class="cell" data-outputid="0df22f75-897e-4207-8285-5b4edffc30c7" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">labels <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">3</span>]).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb30-2">labels</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([-100,    6,    8, -100,    1,    3,    8,    6,    5,    3],
       device='cuda:0')</code></pre>
</div>
</div>
<p>The following two lines are taken from the model’s loss function which can be inspected with <code>print(inspect.getsource(model.loss_function))</code>:</p>
<div class="cell" data-outputid="19309094-2315-487f-badc-574c5b8fab60" data-execution_count="20">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">_labels <span class="op" style="color: #5E5E5E;">=</span> torch.nn.functional.pad(labels, (<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb32-2">shift_labels <span class="op" style="color: #5E5E5E;">=</span> _labels[..., <span class="dv" style="color: #AD0000;">1</span>:].contiguous()</span>
<span id="cb32-3">shift_labels</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([   6,    8, -100,    1,    3,    8,    6,    5,    3, -100],
       device='cuda:0')</code></pre>
</div>
</div>
<p>We can see that the labels have been shifted to the left by 1 element, and a <code>-100</code> ignore index has been added to the right, which is needed because the last token in the input doesn’t predict anything.</p>
<p>Calculating the loss using <code>F.cross_entropy</code> directly and the model’s <code>loss_function</code> (providing it unshifted <code>labels</code>):</p>
<div class="cell" data-outputid="d77b6fcb-8635-4fc2-dc2b-e767fd428d7c" data-execution_count="21">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">loss <span class="op" style="color: #5E5E5E;">=</span> F.cross_entropy(</span>
<span id="cb34-2">    output.logits.reshape(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, output.logits.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)).<span class="bu" style="color: null;">float</span>(),</span>
<span id="cb34-3">    shift_labels.reshape(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb34-4">)</span>
<span id="cb34-5">loss</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor(20.2832, device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="91c2e8da-2901-44a0-e234-5dbe77787361" data-execution_count="22">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">model.loss_function(output.logits, labels, <span class="dv" style="color: #AD0000;">49152</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor(20.2832, device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="padded-batch-loss" class="level2">
<h2 class="anchored" data-anchor-id="padded-batch-loss">Padded Batch Loss</h2>
<p>Sequence packing shouldn’t change the loss value of a given input batch. To test this, I’ll construct a padded batch from our fake data and calculate its outputs, labels and loss.</p>
<div class="cell" data-outputid="e7066f5a-18f6-43b6-a247-bf162df07b79" data-execution_count="23">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">input_ids <span class="op" style="color: #5E5E5E;">=</span> test_params[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb38-2">input_ids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([7, 6, 8, 5, 1, 3, 8, 6, 5, 3], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="8c2cc60a-1319-480c-e975-b60ea1e94a7a" data-execution_count="24">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">cu_seqlens <span class="op" style="color: #5E5E5E;">=</span> test_params[<span class="st" style="color: #20794D;">'cu_seqlens'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb40-2">cu_seqlens</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32)</code></pre>
</div>
</div>
<div class="cell" data-outputid="bbb44c85-d6d9-4d4a-d91d-7ced9a893f42" data-execution_count="25">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">seq_boundaries <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">list</span>(<span class="bu" style="color: null;">zip</span>(cu_seqlens[:<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>], cu_seqlens[<span class="dv" style="color: #AD0000;">1</span>:]))</span>
<span id="cb42-2">seq_boundaries</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>[(tensor(0, device='cuda:0', dtype=torch.int32),
  tensor(3, device='cuda:0', dtype=torch.int32)),
 (tensor(3, device='cuda:0', dtype=torch.int32),
  tensor(10, device='cuda:0', dtype=torch.int32))]</code></pre>
</div>
</div>
<div class="cell" data-outputid="eca4d729-ec35-4d60-b6d3-0504fd4cda7a" data-execution_count="26">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">seq1 <span class="op" style="color: #5E5E5E;">=</span> input_ids[seq_boundaries[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]: seq_boundaries[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">1</span>]]</span>
<span id="cb44-2">seq2 <span class="op" style="color: #5E5E5E;">=</span> input_ids[seq_boundaries[<span class="dv" style="color: #AD0000;">1</span>][<span class="dv" style="color: #AD0000;">0</span>]: seq_boundaries[<span class="dv" style="color: #AD0000;">1</span>][<span class="dv" style="color: #AD0000;">1</span>]]</span>
<span id="cb44-3">seq1, seq2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>(tensor([7, 6, 8], device='cuda:0'),
 tensor([5, 1, 3, 8, 6, 5, 3], device='cuda:0'))</code></pre>
</div>
</div>
<p>The first item in the batch has 3 elements, and the second item in the batch has 7 elements. We need to pad the first item so it’s 7 elements long.</p>
<div class="cell" data-outputid="2260cb77-daca-41dc-9d40-5fce0bf2d638" data-execution_count="27">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">seq1 <span class="op" style="color: #5E5E5E;">=</span> torch.cat([seq1, torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>]).to(<span class="st" style="color: #20794D;">"cuda"</span>)])</span>
<span id="cb46-2">seq1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([7, 6, 8, 0, 0, 0, 0], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="99b50860-f6ea-472e-b244-0424fa99d756" data-execution_count="28">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1">padded_batch <span class="op" style="color: #5E5E5E;">=</span> torch.stack([seq1, seq2], dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb48-2">padded_batch, padded_batch.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>(tensor([[7, 6, 8, 0, 0, 0, 0],
         [5, 1, 3, 8, 6, 5, 3]], device='cuda:0'),
 torch.Size([2, 7]))</code></pre>
</div>
</div>
<p>Similarly, we need to construct <code>labels</code> such that the last four elements in the first batch item are ignored.</p>
<div class="cell" data-outputid="79c4035c-71f7-4d78-f722-05623c1f5c7f" data-execution_count="29">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">seq1 <span class="op" style="color: #5E5E5E;">=</span> input_ids[seq_boundaries[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]: seq_boundaries[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">1</span>]]</span>
<span id="cb50-2">seq2 <span class="op" style="color: #5E5E5E;">=</span> input_ids[seq_boundaries[<span class="dv" style="color: #AD0000;">1</span>][<span class="dv" style="color: #AD0000;">0</span>]: seq_boundaries[<span class="dv" style="color: #AD0000;">1</span>][<span class="dv" style="color: #AD0000;">1</span>]]</span>
<span id="cb50-3">seq1, seq2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>(tensor([7, 6, 8], device='cuda:0'),
 tensor([5, 1, 3, 8, 6, 5, 3], device='cuda:0'))</code></pre>
</div>
</div>
<div class="cell" data-outputid="ea05103b-0a1e-4a5d-89ca-a7e243c5f66a" data-execution_count="30">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1">seq1 <span class="op" style="color: #5E5E5E;">=</span> torch.cat([seq1, torch.tensor([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>]).to(<span class="st" style="color: #20794D;">"cuda"</span>)])</span>
<span id="cb52-2">seq1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor([   7,    6,    8, -100, -100, -100, -100], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="bf8a766d-0c21-4ce8-c288-7d654906f228" data-execution_count="31">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1">padded_labels <span class="op" style="color: #5E5E5E;">=</span> torch.stack([seq1, seq2], dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb54-2">padded_labels</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor([[   7,    6,    8, -100, -100, -100, -100],
        [   5,    1,    3,    8,    6,    5,    3]], device='cuda:0')</code></pre>
</div>
</div>
<p>Calculating the logits:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1">model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb56-2"><span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): padded_output <span class="op" style="color: #5E5E5E;">=</span> model(input_ids<span class="op" style="color: #5E5E5E;">=</span>padded_batch)</span></code></pre></div>
</div>
<p>Noting that I haven’t pass any <code>position_ids</code> and the printed output shows us that <code>flash_attn_func</code> is indeed the “vanilla” implementation of Flash Attention for padded batches:</p>
<pre><code>=== FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['position_ids', 'output_attentions', 'use_cache']

=== _FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['output_attentions', 'use_cache']

 attention_mask
None

 position_ids
tensor([[0, 1, 2, 3, 4, 5, 6]], device='cuda:0')
flash_attn_func is called
flash_kwargs received: ['deterministic']</code></pre>
<p>Comparing the packed output logits with the padded output logits. The shapes are different but the values are the same.</p>
<div class="cell" data-outputid="3aadf767-b684-4d5a-b77d-c61d133baa74" data-execution_count="33">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">output.logits.shape, padded_output.logits.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>(torch.Size([1, 10, 49152]), torch.Size([2, 7, 49152]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="070e6ffd-013f-4ecd-befc-9ac8dae7cc91" data-execution_count="34">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1">(output.logits[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">3</span>, :] <span class="op" style="color: #5E5E5E;">==</span> padded_output.logits[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">3</span>, :]).<span class="bu" style="color: null;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor(1., device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="8598f24d-6e50-4bc8-ce46-e04918d5afc2" data-execution_count="35">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1">(output.logits[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>:, :] <span class="op" style="color: #5E5E5E;">==</span> padded_output.logits[<span class="dv" style="color: #AD0000;">1</span>, :, :]).<span class="bu" style="color: null;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor(1., device='cuda:0')</code></pre>
</div>
</div>
<p>Finally, calculating the padded batch’s loss gives us the same value as the sequence packed loss:</p>
<div class="cell" data-outputid="d4daac3a-2429-438a-deb4-c09d5bca924c" data-execution_count="36">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">padded_loss <span class="op" style="color: #5E5E5E;">=</span> model.loss_function(padded_output.logits, padded_labels, vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">49152</span>)</span>
<span id="cb64-2">padded_loss</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor(20.2832, device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="not-passing-in-position_ids-with-packed-sequence" class="level2">
<h2 class="anchored" data-anchor-id="not-passing-in-position_ids-with-packed-sequence">Not Passing in <code>position_ids</code> With Packed Sequence</h2>
<p>To confirm that not passing in position_ids does in indeed make HuggingFace use the wrong Flash Attention implementation for a packed sequence, I’ll compare the logits and loss:</p>
<div class="cell" data-outputid="990a6acb-870f-46fd-e6e1-8e9c49adde95" data-execution_count="50">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb66-2">test_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb66-3">    <span class="st" style="color: #20794D;">'input_ids'</span>: torch.randint(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">10</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">10</span>)).to(<span class="st" style="color: #20794D;">"cuda"</span>),</span>
<span id="cb66-4">    <span class="st" style="color: #20794D;">'cu_seqlens'</span>: [torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32).to(<span class="st" style="color: #20794D;">"cuda"</span>)],</span>
<span id="cb66-5">    <span class="st" style="color: #20794D;">'max_seqlen'</span>: [<span class="dv" style="color: #AD0000;">10</span>]</span>
<span id="cb66-6">}</span>
<span id="cb66-7">test_params</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>{'input_ids': tensor([[7, 6, 8, 5, 1, 3, 8, 6, 5, 3]], device='cuda:0'),
 'cu_seqlens': [tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32)],
 'max_seqlen': [10]}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1">model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb68-2"><span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): output2 <span class="op" style="color: #5E5E5E;">=</span> model(<span class="op" style="color: #5E5E5E;">**</span>test_params)</span></code></pre></div>
</div>
<p>The logits are not the same as when <code>flash_attn_varlen_func</code> is used.</p>
<div class="cell" data-outputid="91d780a7-01bb-4650-e622-6901fc72cc7b" data-execution_count="52">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1">(output.logits <span class="op" style="color: #5E5E5E;">==</span> output2.logits).<span class="bu" style="color: null;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>tensor(0.3012, device='cuda:0')</code></pre>
</div>
</div>
<p>It follows that the loss value is not the same either.</p>
<div class="cell" data-outputid="6ec37ab6-7dac-4d44-f171-901f927ad8b0" data-execution_count="40">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1">labels <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">3</span>]).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb71-2">model.loss_function(output.logits, labels, <span class="dv" style="color: #AD0000;">49152</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>tensor(17.4632, device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>I’ll reiterate that I’m not familiar with how sequence packing is implemented (in HuggingFace or ModernBERT) and even less familiar with how Flash Attention is implemented. That being said, this cursory investigation allowed me to understand high-level concepts of how these two interact. My key takeaway is that the correct <code>position_ids</code> need to be passed to the model otherwise HuggingFace will not use the correct <code>flash_attn_varlen_func</code> for sequence packed inputs and that will result in incorrect logits and loss values.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-04-Understanding-Sequence-Packing/index.html</guid>
  <pubDate>Sun, 04 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Initial Manual Scoring Results for TinyStories Models</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-01-TSL-Initial-Scoring-Results/index.html</link>
  <description><![CDATA[ 



<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">Recap</h2>
<p>In this post, I’m going to analyze the initial manual scoring results for my baseline models’ text generations given my 150 evaluation prompts across six scoring categories and 18 criteria. A quick recap of what I’ve done so far:</p>
<ul>
<li>Defined scoring criteria</li>
<li>Curated a set of eval prompts based on each scoring category</li>
<li>Created a fast HTML app where I can perform my scoring activities</li>
</ul>
<p>The raw scores analyzed in this blog post can be found in <a href="https://github.com/vishalbakshi/TinyScaleLab">my TinyScaleLab repo</a>.</p>
</section>
<section id="evaluation-categories" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-categories">Evaluation Categories</h2>
<p>I have six scoring categories that I’m evaluating my models on:</p>
<section id="foundational-language-capabilities" class="level3">
<h3 class="anchored" data-anchor-id="foundational-language-capabilities">Foundational language capabilities</h3>
<ul>
<li>Grammar</li>
<li>Context-Tracking (Consistency)</li>
</ul>
</section>
<section id="emergent-capabilities" class="level3">
<h3 class="anchored" data-anchor-id="emergent-capabilities">Emergent capabilities</h3>
<ul>
<li>Factual Knowledge</li>
<li>Reasoning</li>
<li>Creativity</li>
</ul>
</section>
<section id="story-related-capabilities" class="level3">
<h3 class="anchored" data-anchor-id="story-related-capabilities">Story-related capabilities</h3>
<ul>
<li>Plot</li>
</ul>
<p>My goal was to generate prompts that either isolate (Factual Knowledge, Reasoning, Context-Tracking) or elicit opportunities to exhibit (Plot, Creativity) scoring categories. I wanted to make the job easier first for myself, and then use that as a proxy of making the job of the LLM judge easier to evaluate scoring categories in a focused way.</p>
</section>
</section>
<section id="baseline-models" class="level2">
<h2 class="anchored" data-anchor-id="baseline-models">Baseline Models</h2>
<p>I’ve chosen three models as my baseline because they’re similar in size to the models that I’m going to be training in this project:</p>
<ul>
<li>TinyStories-1M (~3.7 million parameters)</li>
<li>TinyStories-8M (~20 million parameters)</li>
<li>TinyStories-28M (~60 million parameters)</li>
</ul>
</section>
<section id="generation-script" class="level2">
<h2 class="anchored" data-anchor-id="generation-script">Generation Script</h2>
<p>I’m using a pretty standard generation script. Things I want to highlight:</p>
<ul>
<li>Making sure the padding side is left so that we’re not generating tokens based on padding tokens</li>
<li><code>model.eval()</code> and <code>torch.no_grad()</code> are things that I always make sure to do so that it’s somewhat deterministic when it’s expected to be deterministic</li>
<li>I’m doing <code>do_sample=False</code> and <code>num_beams=5</code> because that was published by the authors as their parameters for generation</li>
<li>I have a minimum and maximum length, which I’ll talk about at the end about how I think that might change moving forward</li>
</ul>
</section>
<section id="eval-prompts" class="level2">
<h2 class="anchored" data-anchor-id="eval-prompts">Eval Prompts</h2>
<p>My current eval prompts set includes:</p>
<ul>
<li>25 unique prompts for Reasoning</li>
<li>25 unique prompts for Factual Knowledge</li>
<li>25 prompts each for Context-Tracking, Plot and Creativity (with some overlap)</li>
<li>25 prompts for Grammar (5 prompts sampled from the other 5 categories)</li>
</ul>
<p>That’s 150 total prompts.</p>
</section>
<section id="scoring-methodology" class="level2">
<h2 class="anchored" data-anchor-id="scoring-methodology">Scoring Methodology</h2>
<p>I have six categories across 18 criteria, evaluating generations from three models on 150 prompts each. The scores that I’m providing for each criteria are either 0, 0.5, and 1.0, taken from the Tiny Stories paper (though they didn’t quite use it the same way I’m using it), in Section 4.2 (Figures 9/10/11) where they use scoring levels success (green), failure (red), and partial success (yellow).</p>
</section>
<section id="overall-results" class="level2">
<h2 class="anchored" data-anchor-id="overall-results">Overall Results</h2>
<p>First, let’s look at the average value across all categories and criteria for each model:</p>
<table class="table">
<thead>
<tr class="header">
<th>model_name</th>
<th>score_value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>roneneneldan/TinyStories-1M</td>
<td>0.25</td>
</tr>
<tr class="even">
<td>roneneneldan/TinyStories-8M</td>
<td>0.49</td>
</tr>
<tr class="odd">
<td>roneneneldan/TinyStories-28M</td>
<td>0.61</td>
</tr>
</tbody>
</table>
<p>As I would expect, as model size increases, the average score value increases. The 1M parameter model (which actually has 3.7M parameters) has an average score of 0.25. The 8M parameter model (which is closer to 20M parameters) has an average score of about 0.5. And the 28M parameter model (which has about 60M parameters) has an average score of 0.61.</p>
<p>A parameter count <em>increase</em> of 4x (16.3M increase from 3.7M to 20M) yields an overall mean score <em>increase</em> of 1x (0.25 to 0.50). A parameter count <em>increase</em> of 2x (40M increase from 20M to 60M) yields an overall mean score <em>increase</em> of 25% (0.49 to 0.61). There are decreasing gains overall when increasing parameter count. For a 125M parameter model (that I’m planning to train), I would expect &lt;10% increase from a mean overall score of 0.61.</p>
</section>
<section id="scores-by-category" class="level2">
<h2 class="anchored" data-anchor-id="scores-by-category">Scores by Category</h2>
<p>Next, let’s look at how these models are doing for each of the categories overall:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Context-Tracking</td>
<td>0.14</td>
<td>0.51</td>
<td>0.63</td>
</tr>
<tr class="even">
<td>Creativity</td>
<td>0.12</td>
<td>0.16</td>
<td>0.32</td>
</tr>
<tr class="odd">
<td>Factual Knowledge</td>
<td>0.08</td>
<td>0.32</td>
<td>0.40</td>
</tr>
<tr class="even">
<td>Grammar</td>
<td>0.59</td>
<td>0.82</td>
<td>0.86</td>
</tr>
<tr class="odd">
<td>Plot</td>
<td>0.10</td>
<td>0.42</td>
<td>0.60</td>
</tr>
<tr class="even">
<td>Reasoning</td>
<td>0.20</td>
<td>0.44</td>
<td>0.70</td>
</tr>
</tbody>
</table>
<p>Some interesting things to point out:</p>
<p>The highest category by score for my 1M parameter model is grammar, by farL 0.59. That’s about three times as large as any other category. This is in line with what I read in the TinyStories paper, that grammar appears first as a capability.</p>
<p>The worst categories, even for the largest model that I tested, were Creativity and Factual Knowledge. Creativity in particular was the lowest scoring, and this also tracks with the TinyStories paper, because they had shown that creativity only really appears at large hidden dimension sizes. And even then, the maximum value of creativity (8s and 9s out of 10) was only available for models like GPT-4.</p>
<p>Factual Knowledge was also significantly lower than the other four categories.</p>
<p>The other category I want to highlight is Reasoning. The Reasoning score for the smallest model is 0.2, it doubles to 0.44 at 8M, and then it goes up by another 60 percent to 0.7 for the 28M model. That’s pretty solid! 70%, 7 out of 10. So, if we were talking about school grades, a 70 percent is passing. Very cool to see reasoning potential, even for the tiniest model evaluated.</p>
<p>In every case, there is an increase as we go from 1M to 8M to 28M model name. In some cases, the jump comes later, such as for Creativity. In most cases, the jump happens between the 1M and 8M models.</p>
</section>
<section id="scoring-by-criteria" class="level2">
<h2 class="anchored" data-anchor-id="scoring-by-criteria">Scoring by Criteria</h2>
<p>Now let’s look at each criteria for each category:</p>
<section id="emergent-capabilities-creativity-factual-knowledge-and-reasoning" class="level3">
<h3 class="anchored" data-anchor-id="emergent-capabilities-creativity-factual-knowledge-and-reasoning">Emergent Capabilities: Creativity, Factual Knowledge and Reasoning</h3>
<table class="table">
<colgroup>
<col style="width: 78%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
</colgroup>
<thead>
<tr class="header">
<th>Factual Knowledge</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Completion contains only correct factual information relevant to the prompt</td>
<td>0.08</td>
<td>0.32</td>
<td>0.4</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 79%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th>Reasoning</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Completion demonstrates correct logical reasoning relevant to the prompt</td>
<td>0.2</td>
<td>0.44</td>
<td>0.7</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 73%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th>Creativity</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Character behavioral and emotional responses are innovative</td>
<td>0.00</td>
<td>0.04</td>
<td>0.22</td>
</tr>
<tr class="even">
<td>The completion contains unique details to the story world</td>
<td>0.02</td>
<td>0.12</td>
<td>0.34</td>
</tr>
<tr class="odd">
<td>The completion creates fresh situations</td>
<td>0.00</td>
<td>0.08</td>
<td>0.20</td>
</tr>
<tr class="even">
<td>The completion offers unexpected or novel elements</td>
<td>0.48</td>
<td>0.42</td>
<td>0.50</td>
</tr>
</tbody>
</table>
<p>Factual Knowledge and Reasoning only had one criteria each. For Factual Knowledge, I was assessing if the completion contains only correct factual information relevant to the prompt. For Reasoning, I was assessing if the completion demonstrates correct logical reasoning relevant to the prompt.</p>
<p>For Creativity, note that the smallest model performs well for the criteria “The completion offers unexpected or novel elements.” Since I was isolating Grammar, Plot and Context-Tracking from Creativity, the tiniest model could deviate from Plot/Context and still get a high score for this criterion, making it the lowest bar to cross. For the other three Creativity criteria, the 1M model has negligible skill.</p>
</section>
<section id="foundational-language-capabilities-grammar-and-context-tracking" class="level3">
<h3 class="anchored" data-anchor-id="foundational-language-capabilities-grammar-and-context-tracking">Foundational Language Capabilities: Grammar and Context-Tracking</h3>
<table class="table">
<colgroup>
<col style="width: 73%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th>Grammar</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Age-appropriate vocabulary usage</td>
<td>1.00</td>
<td>1.00</td>
<td>0.98</td>
</tr>
<tr class="even">
<td>Dialogue formatting and punctuation</td>
<td>1.00</td>
<td>0.96</td>
<td>0.98</td>
</tr>
<tr class="odd">
<td>Proper use of pronouns and referents</td>
<td>0.56</td>
<td>0.88</td>
<td>0.90</td>
</tr>
<tr class="even">
<td>Sentence structure logic, clarity and completion</td>
<td>0.14</td>
<td>0.62</td>
<td>0.70</td>
</tr>
<tr class="odd">
<td>Tense consistency throughout the completion</td>
<td>0.26</td>
<td>0.66</td>
<td>0.74</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 79%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th>Context-Tracking</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Completion maintains complete coherence with prompt</td>
<td>0.20</td>
<td>0.62</td>
<td>0.64</td>
</tr>
<tr class="even">
<td>Correctly references/tracks all objects, characters, and their attributes</td>
<td>0.20</td>
<td>0.52</td>
<td>0.68</td>
</tr>
<tr class="odd">
<td>Maintains consistent narrative flow</td>
<td>0.02</td>
<td>0.40</td>
<td>0.56</td>
</tr>
</tbody>
</table>
<p>For Grammar, the age-appropriate vocabulary usage was the easiest to score. These models don’t really generate anything that’s not within the TinyStories dataset.</p>
<p>Sentence structure, logic, clarity, and completion had the biggest jump from 1M to 8M, going from 0.14 to 0.62. That matches my experiencing scoring: the small model had terrible structure, logic, clarity, and completion in its completions.</p>
<p>For context tracking, I was looking at three criteria. The biggest jump is from 2% to 40% for maintaining a consistent narrative flow. The medium-sized models were definitely not perfect, but was much better at following the narrative flow of the story.</p>
</section>
<section id="story-related-capabilities-plot" class="level3">
<h3 class="anchored" data-anchor-id="story-related-capabilities-plot">Story-Related Capabilities: Plot</h3>
<table class="table">
<colgroup>
<col style="width: 81%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th>Plot</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Conflicts are addressed rather than abandoned</td>
<td>0.00</td>
<td>0.42</td>
<td>0.60</td>
</tr>
<tr class="even">
<td>The pacing is appropriate (not too rushed or dragging)</td>
<td>0.00</td>
<td>0.14</td>
<td>0.24</td>
</tr>
<tr class="odd">
<td>The story has a clear beginning, middle, and end appropriate to age level</td>
<td>0.26</td>
<td>0.50</td>
<td>0.72</td>
</tr>
<tr class="even">
<td>The story maintains focus on the central conflict/theme without random diversions</td>
<td>0.12</td>
<td>0.64</td>
<td>0.84</td>
</tr>
</tbody>
</table>
<p>For Plot, I found the pacing to be the worst category across all models. This checks out with my experience as I was grading these stories - I didn’t really get a sense that there was a well-paced story. Either it was dragging and repeating itself slightly, or it was just one or two sentences and insufficient.</p>
<p>For “conflicts are addressed” we go from 0% to 42% from 1M to 8M. The smallest model simply ignored or abandoned conflicts that were in the premise and the prompt. The other big jump is for “focusing on the central theme” - the smallest to medium model had almost a 3x jump, and then there was still a considerable 30% jump from the medium to large model.</p>
</section>
</section>
<section id="comparison-to-tinystories-paper" class="level2">
<h2 class="anchored" data-anchor-id="comparison-to-tinystories-paper">Comparison to TinyStories Paper</h2>
<p>I’m going to revisit the targets that I established from Figure 4 of the TinyStories paper, where they showed the different scores based on hidden dimension and number of layers. I matched that up with the three models that I’m testing:</p>
<section id="creativity" class="level3">
<h3 class="anchored" data-anchor-id="creativity">Creativity</h3>
<p>The TinyStories paper reported:</p>
<ul>
<li>1M: 0.47</li>
<li>8M: 0.65</li>
<li>28M: 0.69</li>
</ul>
<p>My scores:</p>
<ul>
<li>1M: 0.12</li>
<li>8M: 0.16</li>
<li>28M: 0.32</li>
</ul>
<p>This was really interesting - I was expecting my assessment to be maybe a little lenient, but it turns out that’s not the case. My scores were significantly lower. The 28M parameter model (which is actually 60M) got 70% for creativity in the paper, while mine was at 30%. I might have to change that criteria over the course of this project, or it might turn out that for creativity, I have a stricter judge.</p>
</section>
<section id="grammar" class="level3">
<h3 class="anchored" data-anchor-id="grammar">Grammar</h3>
<p>TinyStories:</p>
<ul>
<li>1M: 0.61</li>
<li>8M: 0.77</li>
<li>28M: 0.83</li>
</ul>
<p>My scores:</p>
<ul>
<li>1M: 0.59</li>
<li>8M: 0.82</li>
<li>28M: 0.86</li>
</ul>
<p>This matched out pretty well! 61%/59%, 77%/82%, and 83%/86%. The most common baseline capability matches between the targets and my relatively rough evaluation, so thumbs up!</p>
</section>
<section id="context-tracking-consistency" class="level3">
<h3 class="anchored" data-anchor-id="context-tracking-consistency">Context-Tracking (Consistency)</h3>
<p>TinyStories:</p>
<ul>
<li>1M: 0.45</li>
<li>8M: 0.80</li>
<li>28M: 0.90</li>
</ul>
<p>My scores:</p>
<ul>
<li>1M: 0.14</li>
<li>8M: 0.51</li>
<li>28M: 0.63</li>
</ul>
<p>Similar to creativity, it turns out that my criteria or my judging is a lot stricter than the GPT-4 evaluator used in the paper. The highest score in the paper was 90%, whereas mine was 63%. I’m not too worried about this - I would much rather be stricter than not. However, I’ll be open to changing my approach later on if that turns out to be a problem.</p>
</section>
<section id="plot" class="level3">
<h3 class="anchored" data-anchor-id="plot">Plot</h3>
<p>TinyStories: - 1M: 0.44 - 8M: 0.72 - 28M: 0.73</p>
<p>My scores: - 1M: 0.10 - 8M: 0.42 - 28M: 0.60</p>
<p>The 28M scores for Plot are in the same range but medium-sized and small model scores are significantly different.</p>
<p>Factual Knowledge and Reasoning were not quantitatively assessed in the TinyStories paper in the way that these other scores were listed, so I don’t have those reference points for my evaluation.</p>
</section>
</section>
<section id="observations-from-manual-scoring" class="level2">
<h2 class="anchored" data-anchor-id="observations-from-manual-scoring">Observations From Manual Scoring</h2>
<p>After manually scoring 450 stories, I have some observations:</p>
<ol type="1">
<li><p>Judging quality improves (and changes) over time</p>
<ul>
<li>Implicit judging criteria surfaces over time.</li>
<li>By the time I was doing the last hundred, I realized that I was a lot more definitive in giving 0s, 0.5s, and 1s.</li>
<li>Thee largest model likely has the strictest scores (it was graded last).</li>
</ul></li>
<li><p>Phrasing of scoring criteria improved</p>
<ul>
<li>I wanted to be able to answer the question as fast as I could (450 stories to get through!) with a quick yes, no, maybe (1, 0, 0.5).</li>
<li>Initially, some of the criteria were phrased as questions, requiring more cognitive work. I expect that rephrasing the criteria as statements will also ease the “cognitive load” for my LLM judge.</li>
</ul></li>
<li><p>I identified one duplicate prompt and replaced it</p></li>
<li><p>Pros and cons of isolating scoring categories</p>
<ul>
<li>I scored each category in isolation.</li>
<li>More times than not, I found this very liberating—I could assess Creativity without worrying about Context-Tracking or Plot.</li>
<li>However, language is very difficult to compartmentalize. If something’s not factually correct, it will be a distraction when assessing Reasoning. If the context is not being tracked, it makes it harder to assess plot.</li>
<li>Regardless, I thought this isolation of scoring categories overall benefited my approach</li>
</ul></li>
</ol>
</section>
<section id="exciting-discoveries" class="level2">
<h2 class="anchored" data-anchor-id="exciting-discoveries">Exciting Discoveries</h2>
<p>The main takeaway for me, which was very cool to see, is that Reasoning and Factual Knowledge capabilities exists even for the smallest model. The 1M model scored 20% on Reasoning - that’s not nothing!</p>
<p>The fact that there are non-zero values for these tiny models is really mind-blowing to me. It’s really exciting because there’s potential. We can do something with this, especially as these are just pre-trained models—we haven’t fine-tuned them yet. What can we do with this Reasoning and Factual Knowledge capability? That’s what really excites me moving forward.</p>
</section>
<section id="process-improvements" class="level2">
<h2 class="anchored" data-anchor-id="process-improvements">Process Improvements</h2>
<p>When generating completions for my Reasoning and Factual Knowledge, I want to remove the <code>min_length</code> parameter for <code>model.generate()</code> because I don’t want there to be a minimum generation length when the answer can be a few tokens, forcing the model to uneccesarily elongate the story. However, I won’t make this change for my LLM judge as I want to compare its scores with mine for the same prompt/completion pairs.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>With a full eval set scored, I can now move on to prompt engineering an LLM judge (I’ll be using Gemini 2.5 Flash and Claude Haiku 3.5). My goal is for a 90%+ alignment between my scores and the LLM judge before I choose to use it for future experiments.</p>
<p>Follow along this project (and others) in my <a href="https://www.youtube.com/@vishal_learner">YouTube channel!</a>.</p>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-01-TSL-Initial-Scoring-Results/index.html</guid>
  <pubDate>Thu, 01 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Curating Evaluation Prompts, Defining Scoring Criteria, and Designing an LLM Judge Prompt Template</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/index.html</link>
  <description><![CDATA[ 



<section id="recap-and-initial-approach" class="level2">
<h2 class="anchored" data-anchor-id="recap-and-initial-approach">Recap and Initial Approach</h2>
<p>Initially, I planned to use the 44 evaluation prompts from the Tiny Stories dataset HuggingFace repo. These were the same prompts used in the paper to evaluate various model sizes.</p>
<p>I also documented the target scores for evaluation based on the TinyStories’ 10-point scoring rubric for my TinyScaleLab architectures:</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Similar to</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Num Layers</th>
<th style="text-align: center;">Eval Loss</th>
<th style="text-align: center;">Creativity</th>
<th style="text-align: center;">Grammar</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Plot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">TSL-5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">2.02</td>
<td style="text-align: center;">4.84</td>
<td style="text-align: center;">6.19</td>
<td style="text-align: center;">4.75</td>
<td style="text-align: center;">4.39</td>
</tr>
<tr class="even">
<td style="text-align: center;">TSL-25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.38</td>
<td style="text-align: center;">6.54</td>
<td style="text-align: center;">7.72</td>
<td style="text-align: center;">8.02</td>
<td style="text-align: center;">7.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;">TSL-60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">Average of 4 and 8 scores</td>
<td style="text-align: center;">1.23</td>
<td style="text-align: center;">6.8</td>
<td style="text-align: center;">8.35</td>
<td style="text-align: center;">8.7</td>
<td style="text-align: center;">7.31</td>
</tr>
<tr class="even">
<td style="text-align: center;">TSL-125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.18</td>
<td style="text-align: center;">7.02</td>
<td style="text-align: center;">8.62</td>
<td style="text-align: center;">9.34</td>
<td style="text-align: center;">7.34</td>
</tr>
</tbody>
</table>
<p>I am particularly interested in matching the scores shown in the table above, which presents results from GPT-4 evaluations of models with different hidden dimensions and layer counts.</p>
</section>
<section id="one-prompt-to-score-them-all" class="level2">
<h2 class="anchored" data-anchor-id="one-prompt-to-score-them-all">One Prompt to Score them All?</h2>
<p>The Tiny Stories paper used distinct approaches for different capabilities in Section 4.2 (“Knowledge, reasoning and context-tracking”):</p>
<ul>
<li><strong>Factual prompts</strong> - testing models’ knowledge of common sense facts</li>
<li><strong>Reasoning prompts</strong> - testing basic reasoning abilities</li>
<li><strong>Consistency (context-tracking) prompts</strong> - testing models’ ability to maintain coherence</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Knowledge, Reasoning and Context-Tracking Section"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Knowledge, Reasoning and Context-Tracking Section</figcaption><p></p>
</figure>
</div>
<p>What caught my attention was how they assessed these differently, using qualitative measures (success, failure, or partial success) rather than the numerical scores used for other categories.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Performance Table Example"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Performance Table Example</figcaption><p></p>
</figure>
</div>
</section>
<section id="analyzing-the-44-prompts" class="level2">
<h2 class="anchored" data-anchor-id="analyzing-the-44-prompts">Analyzing the 44 Prompts</h2>
<p>I asked Claude to analyze the 44 prompts from the dataset repository to identify which ones were good evaluators for factual knowledge, reasoning, and context-tracking capabilities.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Claude Prompt Analysis"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/3.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Claude Prompt Analysis</figcaption><p></p>
</figure>
</div>
<p>When Claude assessed the prompts, I noticed:</p>
<ol type="1">
<li>Factual knowledge prompts were the most specific/easiest to isolate.</li>
<li>Context-tracking prompts were dime a dozen (found everywhere).</li>
<li>Reasoning was hard to isolate from context-tracking.</li>
</ol>
<p>This led me to an important realization: <strong>I needed to curate specific prompts for each scoring category rather than using one set for all</strong>.</p>
</section>
<section id="prompts-for-creativity-and-plot" class="level2">
<h2 class="anchored" data-anchor-id="prompts-for-creativity-and-plot">Prompts for Creativity and Plot</h2>
<p>For creativity and plot, the challenge was different. Here, I needed prompts that <strong>provided opportunities</strong> for models to exhibit these capabilities.</p>
<p>When flagging good candidates for creativity, I looked for prompts that allowed creative responses <strong>without sacrificing consistency or plot</strong>. Not all prompts are equal in this regard.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Creativity Example"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/4.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Creativity Example</figcaption><p></p>
</figure>
</div>
<p>For plot, I sought prompts that provided strong opportunities to resolve conflict or pursue adventure—elements that test a model’s ability to construct a coherent narrative arc.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="5.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Plot Example"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/5.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Plot Example</figcaption><p></p>
</figure>
</div>
</section>
<section id="curating-category-specific-prompts" class="level2">
<h2 class="anchored" data-anchor-id="curating-category-specific-prompts">Curating Category-Specific Prompts</h2>
<p>Using the factual and reasoning prompts from the paper as a foundation, I worked with Claude to generate additional prompts for each category. Here are examples for factual knowledge:</p>
<ul>
<li>Alice was so tired when she got back home so she went</li>
<li>Jack and Lily saw a rain- bow after a rainy day. They were amazed by the colors. Jack said, “Look, Lily. A rainbow has</li>
<li>Jack and Lily liked to watch the moon at night. They noticed that the moon changed its shape every night. Sometimes the moon was big and round, and sometimes it was</li>
<li>Jack wanted to read a book, so he went to</li>
</ul>
<p>And reasoning prompts:</p>
<ul>
<li>Lily likes cats and dogs. She asked her mom for a dog and her mom said no, so instead she asked</li>
<li>Jack told Mary, ‘If you give me your banana, I’ll give you my apple’. Mary gave Jack her banana so</li>
<li>On weekends Jack went to visit his grandmother whereas on weekdays he would go to school. Last weekend, when Jack was on his way to</li>
<li>Lily and Ben were having an argument. Ben said that cake is much better than ice cream and Lily said that</li>
<li>Lily and Ben are having an argument. They are trying to decide between the park and the swimming pool. Ben says, ‘I want to go to the park’. Lily says</li>
</ul>
<p>I followed a similar process for plot prompts:</p>
<ul>
<li>Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend’s house, she realized she’s starting to feel sick. She was so weak she could</li>
<li>One day a girl walked into the living room and noticed something very strange. There was a huge cabinet standing in the corner. It looked very old and heavy. She walked over and tried to open it, when suddenly</li>
<li>Once upon a time, there lived a hamster in the forest. Every day, he would walked around the forest looking for adventures. One day, he heard someone calling out from behind the bushes. The hamster listened carefully. He realised that it was a small mouse calling out for help. It got stuck under a heavy log and couldn’t get out. The hamster immediately realized that</li>
<li>Alice walked into the kitchen and saw Ben who was looking for something but looked frustrated. She said, “Ben, why are you</li>
</ul>
<p>And creativity:</p>
<ul>
<li>One day a girl walked into the living room and noticed something very strange. There was a huge cabinet standing in the corner. It looked very old and heavy. She walked over and tried to open it, when suddenly</li>
<li>Once upon a time, there was tiger who liked to play the guitar. One day, a bunny heard the guitar from a distance and</li>
<li>One day, a bird was flying high over the sea. At some point the bird noticed small boat with a boy sitting inside. The boy looked lost so</li>
</ul>
<p>I used most of the original 44 prompts for context-tracking, and sampled 5 from each of the non-Grammar categories for Grammar.</p>
</section>
<section id="current-evaluation-prompt-set" class="level2">
<h2 class="anchored" data-anchor-id="current-evaluation-prompt-set">Current Evaluation Prompt Set</h2>
<p>My final evaluation set includes: - 25 unique prompts for Reasoning - 25 unique prompts for Factual Knowledge - 25 prompts each for Context-Tracking, Plot, and Creativity (with some overlap) - 25 prompts for Grammar (5 prompts sampled from the other 5 categories)</p>
<p>This gives me a total of 150 prompts—significantly more than the original 44, but with targeted coverage of each capability.</p>
</section>
<section id="scoring-category-rubrics" class="level2">
<h2 class="anchored" data-anchor-id="scoring-category-rubrics">Scoring Category Rubrics</h2>
<p>For each scoring category, I developed specific rubrics, taking many of them wholesale from the TinyHackathon competition I recently participated in:</p>
<section id="grammar" class="level3">
<h3 class="anchored" data-anchor-id="grammar">Grammar</h3>
<ul>
<li>Dialogue formatting and punctuation</li>
<li>Tense consistency throughout the narrative</li>
<li>Sentence structure logic, clarity and completion</li>
<li>Age-appropriate vocabulary usage</li>
<li>Proper use of pronouns and referents</li>
</ul>
</section>
<section id="creativity" class="level3">
<h3 class="anchored" data-anchor-id="creativity">Creativity</h3>
<ul>
<li>Does the completion offer unexpected or novel elements?</li>
<li>Are character behavioral and emotional responses predictable or innovative?</li>
<li>Does the story rely on cliches or create fresh situations?</li>
<li>Does the writer add unique details to the story world?</li>
</ul>
</section>
<section id="plot" class="level3">
<h3 class="anchored" data-anchor-id="plot">Plot</h3>
<ul>
<li>Is there a clear beginning, middle, and end appropriate to age level?</li>
<li>Are conflicts addressed rather than abandoned?</li>
<li>Is the pacing appropriate (not too rushed or dragging)?</li>
<li>Does the story maintain focus on the central conflict/theme without random diversions?</li>
</ul>
</section>
<section id="factual-knowledge" class="level3">
<h3 class="anchored" data-anchor-id="factual-knowledge">Factual Knowledge</h3>
<ul>
<li>Completion contains only correct factual information relevant to the prompt</li>
</ul>
</section>
</section>
<section id="reasoning" class="level2">
<h2 class="anchored" data-anchor-id="reasoning">Reasoning</h2>
<ul>
<li>Completion demonstrates correct logical reasoning relevant to the prompt</li>
</ul>
<section id="context-tracking" class="level3">
<h3 class="anchored" data-anchor-id="context-tracking">Context-Tracking</h3>
<ul>
<li>Competion maintains complete coherence with prompt</li>
<li>Correctly references/tracks all objects, characters, and their attributes</li>
<li>Maintains consistent narrative flow</li>
</ul>
<p>Notice that different categories have different numbers of criteria:</p>
<ul>
<li>Grammar: 5 criteria</li>
<li>Creativity: 4 criteria</li>
<li>Plot: 4 criteria</li>
<li>Context-tracking: 3 criteria</li>
<li>Factual knowledge: 1 criterion</li>
<li>Reasoning: 1 criterion</li>
</ul>
<p>This means raw scores aren’t directly comparable across categories, which will require normalization during analysis.</p>
</section>
</section>
<section id="llm-judge-prompt-template" class="level2">
<h2 class="anchored" data-anchor-id="llm-judge-prompt-template">LLM Judge Prompt Template</h2>
<p>Instead of using one prompt for all categories, I created a specific judge prompt template for each category:</p>
<pre><code>&lt;instruction-prompt id="Evaluation"&gt;
&lt;instruction&gt;
You are an expert evaluator for tiny language models trained on children's stories. Your task is to score the given model completion (generated using the provided prompt) using the rubric below. Provide a detailed assessment followed by a final total score.
&lt;/instruction&gt;

&lt;rubric&gt;
&lt;criteria&gt;
&lt;criterion id="A"&gt;&lt;/criterion&gt;
&lt;criterion id="B"&gt;&lt;/criterion&gt;
&lt;criterion id="C"&gt;&lt;/criterion&gt;
&lt;criterion id="D"&gt;&lt;/criterion&gt;
&lt;criterion id="E"&gt;&lt;/criterion&gt;
&lt;/criteria&gt;

&lt;scoring-scale&gt;
&lt;level value="1.0"&gt;Criterion is fully satisfied&lt;/level&gt;
&lt;level value="0.5"&gt;Criterion is partially satisfied&lt;/level&gt;
&lt;level value="0.0"&gt;Criterion is not satisfied&lt;/level&gt;
&lt;/scoring-scale&gt;

&lt;scoring-instructions&gt;
For each criterion A-E, assign a score of 1.0, 0.5, or 0.0 based on how well the completion satisfies that criterion. The final score is the sum of all criterion scores.
&lt;/scoring-instructions&gt;
&lt;/rubric&gt;

&lt;generation-prompt&gt;
{prompt}
&lt;/generation-prompt&gt;

&lt;completion&gt;
{completion}
&lt;/completion&gt;

&lt;response-format&gt;
Provide your assessment of each criterion with specific examples from the text, then calculate the final score (sum of all criterion scores).

Format your response as:
&lt;evaluation&gt;
&lt;criterion-A-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-A-score&gt;
&lt;criterion-A-explanation&gt;Your explanation here&lt;/criterion-A-explanation&gt;

&lt;criterion-B-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-B-score&gt;
&lt;criterion-B-explanation&gt;Your explanation here&lt;/criterion-B-explanation&gt;

&lt;criterion-C-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-C-score&gt;
&lt;criterion-C-explanation&gt;Your explanation here&lt;/criterion-C-explanation&gt;

&lt;criterion-D-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-D-score&gt;
&lt;criterion-D-explanation&gt;Your explanation here&lt;/criterion-D-explanation&gt;

&lt;criterion-E-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-E-score&gt;
&lt;criterion-E-explanation&gt;Your explanation here&lt;/criterion-E-explanation&gt;

&lt;final-score&gt;[Sum of all criterion scores, between #.# and #.#]&lt;/final-score&gt;
&lt;/evaluation&gt;
&lt;/response-format&gt;
&lt;/instruction-prompt&gt;</code></pre>
<p>The template includes:</p>
<ul>
<li>Instructions for the judge</li>
<li>Criteria specific to the category being evaluated</li>
<li>Scoring scale (0, 0.5, 1.0)</li>
<li>Scoring instructions</li>
<li>Response format</li>
</ul>
</section>
<section id="initial-testing" class="level2">
<h2 class="anchored" data-anchor-id="initial-testing">Initial Testing</h2>
<p>I tested the approach with Claude Haiku 3.5, and the results were promising. When evaluating grammar, it gave a weaker model a score of 3.5/5. When I gave it a larger model’s completion, it scored it 5/5. This suggests the approach can successfully differentiate between model capabilities.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>My immediate next steps are:</p>
<ol type="1">
<li>Generate 150 completions, one for each the 150 prompts, per TinyStories model (1M, 8M, 28M).</li>
<li>Build an evaluation interface to help grade model responses using FastHTML.</li>
<li>Score all completions using the 0/0.5/1.0 methodology.</li>
<li>Compare results with the targets from the Tiny Stories paper.</li>
<li>Refine scoring rubric if needed.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="6.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Evaluation Interface Mockup"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/6.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Evaluation Interface Mockup</figcaption><p></p>
</figure>
</div>
<p>I expect this to take several days as generating completions, building the interface, and evaluating 450 prompts (150 for each of three models) is no small task! Thankfully, it’s terribly large either.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The journey from a simple plan to use 44 prompts to a comprehensive evaluation approach with 150 category-specific prompts shows how even “squishy” concepts like language can be systematically evaluated with the right structure.</p>
<p>By distinguishing between capabilities that need to be isolated (factual knowledge, reasoning, context-tracking) and those that need opportunities to be exhibited (creativity and plot), I’ve created what I believe is a robust evaluation methodology. Obviously, time, very quickly and definitely, will tell.</p>
<p>I’m excited to see if this approach gives me scores comparable to those in the Tiny Stories paper. Stay tuned for the results!</p>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/index.html</guid>
  <pubDate>Mon, 28 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/1.png" medium="image" type="image/png" height="46" width="144"/>
</item>
<item>
  <title>TinyScaleLab Update: Training Cost Analysis and Evaluation Infrastructure Plans</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-27-TSL-Initial-Training-Runs/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this notebook I’ll share results from some quick and dirty training runs executed so I get a rough but reasonable estimate of training time and costs using L4 and A100 GPUs on Google Colab Pro.</p>
</section>
<section id="model-sizes" class="level2">
<h2 class="anchored" data-anchor-id="model-sizes">Model Sizes</h2>
<p>In these experiments, I’m training four model sizes: 5M, 25M, 60M and 125M. I’ve chosen to roughly follow the TinyStories models, using the hidden dimension and intermediate dimension for the TinyStories-1M, -8M, -28M and -33M models, in each case there is a 4x increase from hidden to intermediate dimension in the MLP layers. These are just initial architectural choices which might change over the course of the project as I learn more about what results in a better performing model.</p>
<p>For now, I’m using 8 attention heads (for all models) and the Llama-2 tokenizer with a 32000 vocab size.</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Intermediate Dim</th>
<th style="text-align: center;">Number of Layers</th>
<th style="text-align: center;">Number of Params</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">4_949_696</td>
</tr>
<tr class="even">
<td style="text-align: center;">25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">24_776_960</td>
</tr>
<tr class="odd">
<td style="text-align: center;">60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">57_940_480</td>
</tr>
<tr class="even">
<td style="text-align: center;">125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">124_662_528</td>
</tr>
</tbody>
</table>
</section>
<section id="training-dataset" class="level2">
<h2 class="anchored" data-anchor-id="training-dataset">Training Dataset</h2>
<p>I’ve tokenized the <a href="https://huggingface.co/datasets/roneneldan/TinyStories/blob/main/TinyStories_all_data.tar.gz">TinyStories_all_data.tar.gz</a> dataset which contains 4.9M stories generated by GPT3.5 and GPT4, using the <code>meta-llama/Llama-2-7b-hf</code> tokenizer. I haven’t performed any data cleaning (yet). The total number of tokens in this dataset is little over 1B: <strong>1_028_013_532</strong>.</p>
</section>
<section id="training-duration" class="level2">
<h2 class="anchored" data-anchor-id="training-duration">Training Duration</h2>
<p>I’m training all initial runs for 1 epoch.</p>
</section>
<section id="training-gpus" class="level2">
<h2 class="anchored" data-anchor-id="training-gpus">Training GPUs</h2>
<p>I trained the 5M and 25M models on both L4 (22.5 GB VRAM) and A100 (40GB VRAM) GPUs. I trained the 60M and 125M models on the A100 GPU.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>All models are trained for 1 epoch (1.03 tokens):</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Hardware</th>
<th style="text-align: center;">Model Size</th>
<th style="text-align: center;">Time (hr)</th>
<th style="text-align: center;">Batch Size</th>
<th style="text-align: center;">Max Memory</th>
<th style="text-align: center;">Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">L4</td>
<td style="text-align: center;">5M</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">384</td>
<td style="text-align: center;">20%</td>
<td style="text-align: center;">$0.18</td>
</tr>
<tr class="even">
<td style="text-align: center;">L4</td>
<td style="text-align: center;">25M</td>
<td style="text-align: center;">1.45</td>
<td style="text-align: center;">288</td>
<td style="text-align: center;">65%</td>
<td style="text-align: center;">$0.30</td>
</tr>
<tr class="odd">
<td style="text-align: center;">A100-40GB</td>
<td style="text-align: center;">5M</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">78%</td>
<td style="text-align: center;">$0.25</td>
</tr>
<tr class="even">
<td style="text-align: center;">A100-40GB</td>
<td style="text-align: center;">25M</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">1536</td>
<td style="text-align: center;">98%</td>
<td style="text-align: center;">$0.27</td>
</tr>
<tr class="odd">
<td style="text-align: center;">A100-40GB</td>
<td style="text-align: center;">60M</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">1152</td>
<td style="text-align: center;">86%</td>
<td style="text-align: center;">$0.41</td>
</tr>
<tr class="even">
<td style="text-align: center;">A100-40GB</td>
<td style="text-align: center;">125M</td>
<td style="text-align: center;">1.10</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">99%</td>
<td style="text-align: center;">$0.84</td>
</tr>
</tbody>
</table>
</section>
<section id="takeaways" class="level2">
<h2 class="anchored" data-anchor-id="takeaways">Takeaways</h2>
<p>From this analysis, only the 5M model makes sense to train on the L4. It’s 3 cents cheaper per hour to train the 25M model on the A100, though I’m flirting with OOM so I should reduce the batch size.</p>
<p>I’ll need to perform longer trainings to get a sense of how many full epochs I need to produce coherent language-generating models, but from my TinyHackathon experience, it took 20 epochs for the 60M model to perform decently (3/5 LLM Judge overall score). I would expect the 125M model to require less epochs, and the smaller models more epochs, to achieve comparable performance. But we’ll see!</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<p>Here are the <code>LlamaConfig</code> objects for each model:</p>
<section id="m" class="level3">
<h3 class="anchored" data-anchor-id="m">5M</h3>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">config <span class="op" style="color: #5E5E5E;">=</span> LlamaConfig(</span>
<span id="cb1-2">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>,</span>
<span id="cb1-3">    hidden_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb1-4">    intermediate_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>,</span>
<span id="cb1-5">    num_hidden_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">13</span>,</span>
<span id="cb1-6">    num_attention_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb1-7">    max_position_embeddings<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb1-8">    rope_theta<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10000.0</span>,</span>
<span id="cb1-9">    attention_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb1-10">    mlp_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb1-11">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb1-12">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"bfloat16"</span></span>
<span id="cb1-13">)</span></code></pre></div>
</section>
<section id="m-1" class="level3">
<h3 class="anchored" data-anchor-id="m-1">25M</h3>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">config <span class="op" style="color: #5E5E5E;">=</span> LlamaConfig(</span>
<span id="cb2-2">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>,</span>
<span id="cb2-3">    hidden_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>,</span>
<span id="cb2-4">    intermediate_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span>,</span>
<span id="cb2-5">    num_hidden_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb2-6">    num_attention_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb2-7">    max_position_embeddings<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb2-8">    rope_theta<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10000.0</span>,</span>
<span id="cb2-9">    attention_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb2-10">    mlp_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb2-11">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb2-12">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"bfloat16"</span></span>
<span id="cb2-13">)</span></code></pre></div>
</section>
<section id="m-2" class="level3">
<h3 class="anchored" data-anchor-id="m-2">60M</h3>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">config <span class="op" style="color: #5E5E5E;">=</span> LlamaConfig(</span>
<span id="cb3-2">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>,</span>
<span id="cb3-3">    hidden_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb3-4">    intermediate_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2048</span>,</span>
<span id="cb3-5">    num_hidden_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span>,</span>
<span id="cb3-6">    num_attention_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb3-7">    max_position_embeddings<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb3-8">    rope_theta<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10000.0</span>,</span>
<span id="cb3-9">    attention_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb3-10">    mlp_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb3-11">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb3-12">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"bfloat16"</span></span>
<span id="cb3-13">)</span></code></pre></div>
</section>
<section id="m-3" class="level3">
<h3 class="anchored" data-anchor-id="m-3">125M</h3>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">config <span class="op" style="color: #5E5E5E;">=</span> LlamaConfig(</span>
<span id="cb4-2">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>,</span>
<span id="cb4-3">    hidden_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">768</span>,</span>
<span id="cb4-4">    intermediate_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3072</span>,</span>
<span id="cb4-5">    num_hidden_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb4-6">    num_attention_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb4-7">    max_position_embeddings<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb4-8">    rope_theta<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10000.0</span>,</span>
<span id="cb4-9">    attention_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb4-10">    mlp_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb4-11">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb4-12">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"bfloat16"</span></span>
<span id="cb4-13">)</span></code></pre></div>


</section>
</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-27-TSL-Initial-Training-Runs/index.html</guid>
  <pubDate>Sun, 27 Apr 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TinyScale Lab Update: Setting Eval Targets and Generating Completions for LLM Judge Development</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-27-TSL-Setting-Eval-Targets/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this notebook I’m going to generate story completions using the TinyStories 1M, 8M, 28M models. The actual HF model size for these models is 3.7M, 19.7M and 52M, respectively. Since I’m training 5M, 25M, 60M and 125M models, these three TinyStories models will serve as proxies for my first three sizes, and I will expect my 125M model to generate stories that receive higher scores than my 60M (by how much higher is TBD).</p>
<p>Ronen Eldan, the TinyStories paper author, has listed on <a href="https://huggingface.co/roneneldan/TinyStories-33M/discussions/9#64f94b050a2884a831b29eb6">this HF model card discussion forum</a>:</p>
<blockquote class="blockquote">
<p>we used temp=0, beams=5</p>
</blockquote>
<p>So I’ll be using those two settings during inference.</p>
<p>Here are some key architectural details for my initial quick-and-dirty models:</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Intermediate Dim</th>
<th style="text-align: center;">Number of Layers</th>
<th style="text-align: center;">Number of Params</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">4_949_696</td>
</tr>
<tr class="even">
<td style="text-align: center;">25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">24_776_960</td>
</tr>
<tr class="odd">
<td style="text-align: center;">60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">57_940_480</td>
</tr>
<tr class="even">
<td style="text-align: center;">125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">124_662_528</td>
</tr>
</tbody>
</table>
<p>Here are my initial scoring categories, based on type of language model capability:</p>
<ul>
<li><strong>Foundational language capabilities</strong>: Grammar and Context-Tracking (Consistency)</li>
<li><strong>Emergent capabilities</strong>: Factual Knowledge, Reasoning, Creativity</li>
<li><strong>Story-related capabilities</strong>: Plot</li>
</ul>
<p>Referencing Figure 4 in the <a href="https://arxiv.org/abs/2305.07759">TinyStories paper</a> I would expect to achieve LLM Judge for these models close to the following (TSL = TinyScale Lab):</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Similar to</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Num Layers</th>
<th style="text-align: center;">Eval Loss</th>
<th style="text-align: center;">Creativity</th>
<th style="text-align: center;">Grammar</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Plot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">TSL-5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">2.02</td>
<td style="text-align: center;">4.84</td>
<td style="text-align: center;">6.19</td>
<td style="text-align: center;">4.75</td>
<td style="text-align: center;">4.39</td>
</tr>
<tr class="even">
<td style="text-align: center;">TSL-25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.38</td>
<td style="text-align: center;">6.54</td>
<td style="text-align: center;">7.72</td>
<td style="text-align: center;">8.02</td>
<td style="text-align: center;">7.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;">TSL-60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">Average of 4 and 8 scores</td>
<td style="text-align: center;">1.23</td>
<td style="text-align: center;">6.8</td>
<td style="text-align: center;">8.35</td>
<td style="text-align: center;">8.7</td>
<td style="text-align: center;">7.31</td>
</tr>
<tr class="even">
<td style="text-align: center;">TSL-125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.18</td>
<td style="text-align: center;">7.02</td>
<td style="text-align: center;">8.62</td>
<td style="text-align: center;">9.34</td>
<td style="text-align: center;">7.34</td>
</tr>
</tbody>
</table>
<p>Mapping the Figure 4 scores to the official 1M, 8M and 28M models directly:</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">TinyStories</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Num Layers</th>
<th style="text-align: center;">Eval Loss</th>
<th style="text-align: center;">Creativity</th>
<th style="text-align: center;">Grammar</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Plot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">2.08</td>
<td style="text-align: center;">4.68</td>
<td style="text-align: center;">6.14</td>
<td style="text-align: center;">4.45</td>
<td style="text-align: center;">4.40</td>
</tr>
<tr class="even">
<td style="text-align: center;">8M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.38</td>
<td style="text-align: center;">6.54</td>
<td style="text-align: center;">7.72</td>
<td style="text-align: center;">8.02</td>
<td style="text-align: center;">7.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;">28M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.20</td>
<td style="text-align: center;">6.85</td>
<td style="text-align: center;">8.34</td>
<td style="text-align: center;">8.95</td>
<td style="text-align: center;">7.26</td>
</tr>
</tbody>
</table>
<p>The two scoring categories I’m using that are not assessed quantitatively in the TinyStories paper: Factual Knowledge and Reasoning. If my LLM Judge scores match Figure 4 for the other four categories and match my manual evaluations for all six categories, I should expect the LLM Judge to assess these two categories correctly.</p>
</section>
<section id="evaluation-prompts" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-prompts">Evaluation Prompts</h2>
<p>Lucky for me, the TinyStories authors have published their <a href="https://huggingface.co/datasets/roneneldan/TinyStories/blob/main/Evaluation%20prompts.yaml">evaluation prompts</a>.</p>
<div class="cell" data-outputid="6457a149-b8a1-44fe-9171-592115dbf3af" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> requests</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> yaml</span>
<span id="cb1-3">url <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"https://huggingface.co/datasets/roneneldan/TinyStories/raw/main/Evaluation%20prompts.yaml"</span></span>
<span id="cb1-4">response <span class="op" style="color: #5E5E5E;">=</span> requests.get(url)</span>
<span id="cb1-5">data <span class="op" style="color: #5E5E5E;">=</span> yaml.safe_load(response.text)</span>
<span id="cb1-6"><span class="bu" style="color: null;">len</span>(data)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>44</code></pre>
</div>
</div>
<div class="cell" data-outputid="c65bbed1-af12-43b2-98a4-a8a702fa16e4" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">data[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could"</code></pre>
</div>
</div>
</section>
<section id="generating-story-completions" class="level2">
<h2 class="anchored" data-anchor-id="generating-story-completions">Generating Story Completions</h2>
<p>I’ll walk through some basic generation code to make sure it works before I apply it to the full dataset.</p>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoTokenizer, AutoModelForCausalLM</span>
<span id="cb5-2"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb5-3"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;">"roneneldan/TinyStories-1M"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb6-2">tokz <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;">"roneneldan/TinyStories-1M"</span>)</span>
<span id="cb6-3">tokz.pad_token_id</span></code></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">tokz.pad_token <span class="op" style="color: #5E5E5E;">=</span> tokz.eos_token</span></code></pre></div>
</div>
<p>To my knowledge, you want tokz.padding_side to be “left” during batched inference, and the default here is “right”. Examples of difference shown for batched prompts. Padding right starts the next token prediction with the pad token, padding left with the last tok in prompt.</p>
<div class="cell" data-outputid="91b9d304-8ca3-4080-a601-60ec83e1e0a6" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">tokz.bos_token_id, tokz.eos_token_id, tokz.pad_token_id, tokz.padding_side</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>(50256, 50256, 50256, 'right')</code></pre>
</div>
</div>
<div class="cell" data-outputid="cf22cd11-a1b7-4458-e2f4-a8fc94b411b1" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">inputs <span class="op" style="color: #5E5E5E;">=</span> tokz(data, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb10-2">tokz.decode(inputs.input_ids[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;"</code></pre>
</div>
</div>
<div class="cell" data-outputid="bb4b5968-acbe-43dc-a4dc-952fad6e2b5c" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">tokz.padding_side <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"left"</span></span>
<span id="cb12-2">inputs <span class="op" style="color: #5E5E5E;">=</span> tokz(data, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb12-3">tokz.decode(inputs.input_ids[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>"&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could"</code></pre>
</div>
</div>
<div class="cell" data-outputid="8cab2d05-e8e7-4b77-e76c-5b1df238f698" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">inputs.input_ids[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256,  7454,  2402,   257,   640,    11,
          612,  5615,   257, 44915,   287,   257,  2214,    13,  2332,  1438,
          373, 22162,    13, 22162,  6151,   284,   423,   730,  5773,   290,
         4671,   351,   607, 44915,  2460,    13,  1881,  1110,    11,   618,
        22162,   373,   546,   284,  2666,   329,   257, 26951,   379,   257,
         1545,   338,  2156,    11,   673,  6939,   673,   338,  3599,   284,
         1254,  6639,    13,  1375,   373,   523,  4939,   673,   714],
       device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="947c8522-53fd-489f-e333-d53212214fb0" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">inputs.attention_mask[<span class="dv" style="color: #AD0000;">0</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>torch.Size([119])</code></pre>
</div>
</div>
<p>Reusing the generation code I used for the TinyHackthon competition, but setting <code>do_sample=False</code> and <code>num_beams=5</code>:</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="kw" style="color: #003B4F;">def</span> _generate(model, prompts, max_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">384</span>, min_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">120</span>):</span>
<span id="cb18-2">    tokz.padding_side <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"left"</span></span>
<span id="cb18-3">    inputs <span class="op" style="color: #5E5E5E;">=</span> tokz(prompts, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb18-4"></span>
<span id="cb18-5">    model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb18-6">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb18-7">        outputs <span class="op" style="color: #5E5E5E;">=</span> model.generate(</span>
<span id="cb18-8">            inputs.input_ids,</span>
<span id="cb18-9">            attention_mask<span class="op" style="color: #5E5E5E;">=</span>inputs.attention_mask,</span>
<span id="cb18-10">            max_length<span class="op" style="color: #5E5E5E;">=</span>max_length,</span>
<span id="cb18-11">            min_length<span class="op" style="color: #5E5E5E;">=</span>min_length,</span>
<span id="cb18-12">            num_beams<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>,</span>
<span id="cb18-13">            do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb18-14">            pad_token_id<span class="op" style="color: #5E5E5E;">=</span>tokz.eos_token_id</span>
<span id="cb18-15">        )</span>
<span id="cb18-16"></span>
<span id="cb18-17">        input_length <span class="op" style="color: #5E5E5E;">=</span> inputs.input_ids[<span class="dv" style="color: #AD0000;">0</span>].size(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb18-18">        completion_tokens <span class="op" style="color: #5E5E5E;">=</span> outputs[<span class="dv" style="color: #AD0000;">0</span>][input_length:]</span>
<span id="cb18-19">        completion_text <span class="op" style="color: #5E5E5E;">=</span> tokz.decode(completion_tokens, skip_special_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb18-20"></span>
<span id="cb18-21">        completions <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb18-22"></span>
<span id="cb18-23">        <span class="cf" style="color: #003B4F;">for</span> j, output <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(outputs):</span>
<span id="cb18-24">            input_length <span class="op" style="color: #5E5E5E;">=</span> inputs.input_ids[j].size(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb18-25">            completion_tokens <span class="op" style="color: #5E5E5E;">=</span> output[input_length:]</span>
<span id="cb18-26">            completion_text <span class="op" style="color: #5E5E5E;">=</span> tokz.decode(completion_tokens, skip_special_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb18-27">            completions.append(completion_text)</span>
<span id="cb18-28"></span>
<span id="cb18-29">        <span class="cf" style="color: #003B4F;">assert</span> outputs.shape[<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(prompts)</span>
<span id="cb18-30">        <span class="cf" style="color: #003B4F;">assert</span> outputs.shape[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> max_length</span>
<span id="cb18-31">        <span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(completions) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(prompts)</span>
<span id="cb18-32">        <span class="cf" style="color: #003B4F;">return</span> completions</span>
<span id="cb18-33"></span>
<span id="cb18-34">completions <span class="op" style="color: #5E5E5E;">=</span> _generate(model, data)</span></code></pre></div>
</div>
<div class="cell" data-outputid="5bb67862-93ee-47f1-ff95-0996af4f1843" data-execution_count="41">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="bu" style="color: null;">print</span>(completions[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> not sleep.

Lucy asked her mom, "What's wrong, Mommy?" Her mom replied, "It's okay, sweetie. I'll help you."

Lucy smiled and said, "I'm sorry, Mommy. I'll help you." Her mom smiled and said, "It's okay, Lucy. I'm glad you're safe."

Lucy smiled and said, "Thank you, Mommy. I love you." Her mom smiled and said, "I love you too, Lucy."
</code></pre>
</div>
</div>
<div class="cell" data-outputid="c303089b-c591-4950-c77a-9f0b9ba2a294" data-execution_count="42">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="bu" style="color: null;">print</span>(completions[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> go to the hospital. The little boy was very sad and he didn't want to go to the hospital. 

His mom said, "Don't worry, I'll help you." But the little boy didn't listen. He said, "I'm sorry, mom. I won't do it again." 

His mom smiled and said, "It's okay, I'll help you." 

The little boy was so happy and thanked his mom. From that day on, he always made sure to always be careful when playing outside.
</code></pre>
</div>
</div>
<div class="cell" data-outputid="1e8db0c5-13bc-4dee-b57e-1f6088dee7e6" data-execution_count="43">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="bu" style="color: null;">print</span>(completions[<span class="dv" style="color: #AD0000;">22</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> room. 

The little girl asked her daddy, "Daddy, can you help me?" 

Daddy said, "Yes, I can help you." 

The little girl was so happy. She said, "Thank you, Daddy!" 

Daddy smiled and said, "You're welcome, sweetheart. I'm glad you're safe." 

The little girl smiled and said, "Thank you, Daddy!"

Daddy smiled and said, "You're welcome, sweetheart. I'm glad you're safe." 

The little girl smiled and said, "I'm glad you're safe."
</code></pre>
</div>
</div>
<p>I’ll now iterate through a list of all three models, generate story completions, and save it to CSV for evaluation.</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">model_names <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"roneneldan/TinyStories-1M"</span>, <span class="st" style="color: #20794D;">"roneneldan/TinyStories-8M"</span>, <span class="st" style="color: #20794D;">"roneneldan/TinyStories-28M"</span>]</span></code></pre></div>
</div>
<div class="cell" data-outputid="856cc1fd-21ca-4452-a8d1-afd4664a0f18" data-execution_count="52">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;">"prompt"</span>: data, <span class="st" style="color: #20794D;">"1M"</span>: [<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span><span class="bu" style="color: null;">len</span>(data), <span class="st" style="color: #20794D;">"8M"</span>: [<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span><span class="bu" style="color: null;">len</span>(data), <span class="st" style="color: #20794D;">"28M"</span>: [<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span><span class="bu" style="color: null;">len</span>(data)})</span>
<span id="cb26-2">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">


  <div id="df-d3226fdd-e225-4ef3-a087-845fa3564beb" class="colab-df-container">
    <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>prompt</th>
      <th>1M</th>
      <th>8M</th>
      <th>28M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Once upon a time, there lived a bunny in a fie...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>One day a girl walked into the living room and...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Once upon a time, there lived a hamster in the...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jack asked his mom if he could ride the bike a...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Alice was bored and wanted to find some advent...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-d3226fdd-e225-4ef3-a087-845fa3564beb')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-d3226fdd-e225-4ef3-a087-845fa3564beb button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-d3226fdd-e225-4ef3-a087-845fa3564beb');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-1cd2bf3d-8fce-4357-9c1a-a3becd941453">
      <button class="colab-df-quickchart" onclick="quickchart('df-1cd2bf3d-8fce-4357-9c1a-a3becd941453')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-1cd2bf3d-8fce-4357-9c1a-a3becd941453 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="cf" style="color: #003B4F;">for</span> name <span class="kw" style="color: #003B4F;">in</span> model_names:</span>
<span id="cb27-2">    model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(name).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb27-3">    tokz <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(name)</span>
<span id="cb27-4">    tokz.pad_token <span class="op" style="color: #5E5E5E;">=</span> tokz.eos_token</span>
<span id="cb27-5">    completions <span class="op" style="color: #5E5E5E;">=</span> _generate(model, data)</span>
<span id="cb27-6">    df[name.split(<span class="st" style="color: #20794D;">"-"</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]] <span class="op" style="color: #5E5E5E;">=</span> completions</span></code></pre></div>
</div>
<div class="cell" data-outputid="7a079003-5f3c-4bda-f762-87b14b3f333a" data-execution_count="55">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">


  <div id="df-46266037-47c6-4550-91a9-93f2cb686066" class="colab-df-container">
    <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>prompt</th>
      <th>1M</th>
      <th>8M</th>
      <th>28M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Once upon a time, there lived a bunny in a fie...</td>
      <td>not sleep.\n\nLucy asked her mom, "What's wro...</td>
      <td>hardly move.\n\nLucy's friend, a wise old owl...</td>
      <td>barely move. \n\nLucy's bunny friends noticed...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>One day a girl walked into the living room and...</td>
      <td>, she heard a voice.\n\n"What are you doing he...</td>
      <td>she heard a voice.\n\n"Who are you?" the voic...</td>
      <td>a voice came from behind her.\n\n"What do you...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Once upon a time, there lived a hamster in the...</td>
      <td>it was too late.\n\nThe next day, the hamster...</td>
      <td>the mouse was trying to help him.\n\nThe hams...</td>
      <td>he had to help the mouse.\n\nHe used all his ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jack asked his mom if he could ride the bike a...</td>
      <td>thank you" to his daughter.\n\nThe next day, J...</td>
      <td>no" and he knew that he had to be careful.\n\n...</td>
      <td>Don't ride too fast, be careful!"\n\nSo Jack s...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Alice was bored and wanted to find some advent...</td>
      <td>go to the park?"\n\nTom said, "I don't want t...</td>
      <td>go on an adventure together?"\n\nBen smiled a...</td>
      <td>go on an adventure?"\n\nBen thought for a mom...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-46266037-47c6-4550-91a9-93f2cb686066')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-46266037-47c6-4550-91a9-93f2cb686066 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-46266037-47c6-4550-91a9-93f2cb686066');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-de0c88ef-903d-4b9a-9c0a-53db68fe08e1">
      <button class="colab-df-quickchart" onclick="quickchart('df-de0c88ef-903d-4b9a-9c0a-53db68fe08e1')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-de0c88ef-903d-4b9a-9c0a-53db68fe08e1 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">df.to_csv(<span class="st" style="color: #20794D;">"2025-04-27-evals.csv"</span>, index<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
</div>
<p>While we’re, I’ll calculat the average prompt and completion length in tokens.</p>
<div class="cell" data-outputid="223dae72-f5c1-45a8-f350-e998d5714008" data-execution_count="57">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">tokz(data[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>{'input_ids': [7454, 2402, 257, 640, 11, 612, 5615, 257, 44915, 287, 257, 2214, 13, 2332, 1438, 373, 22162, 13, 22162, 6151, 284, 423, 730, 5773, 290, 4671, 351, 607, 44915, 2460, 13, 1881, 1110, 11, 618, 22162, 373, 546, 284, 2666, 329, 257, 26951, 379, 257, 1545, 338, 2156, 11, 673, 6939, 673, 338, 3599, 284, 1254, 6639, 13, 1375, 373, 523, 4939, 673, 714], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<div class="cell" data-outputid="e14c1c7a-3e2e-4a00-91b6-66ab4f19762d" data-execution_count="61">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">toks <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb32-2"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> data: toks <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">len</span>(tokz(p).input_ids)</span>
<span id="cb32-3">toks<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">44</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>62</code></pre>
</div>
</div>
<div class="cell" data-outputid="a64f24ca-762c-4043-a601-d3b5949cc900" data-execution_count="62">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">toks <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb34-2"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> df[<span class="st" style="color: #20794D;">"1M"</span>]: toks <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">len</span>(tokz(p).input_ids)</span>
<span id="cb34-3">toks<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">44</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>164</code></pre>
</div>
</div>
<div class="cell" data-outputid="eeef388e-08ab-436e-c300-a30cc625ec66" data-execution_count="63">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">toks <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb36-2"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> df[<span class="st" style="color: #20794D;">"8M"</span>]: toks <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">len</span>(tokz(p).input_ids)</span>
<span id="cb36-3">toks<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">44</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>153</code></pre>
</div>
</div>
<div class="cell" data-outputid="057638d1-c550-43af-ef0c-afd026dd85cc" data-execution_count="64">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">toks <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb38-2"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> df[<span class="st" style="color: #20794D;">"28M"</span>]: toks <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">len</span>(tokz(p).input_ids)</span>
<span id="cb38-3">toks<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">44</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>140</code></pre>
</div>
</div>
<div class="cell" data-outputid="a85210bb-79b9-45c3-fb4a-b1ee8c4a7ca6" data-execution_count="65">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="dv" style="color: #AD0000;">62</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">164</span>, <span class="dv" style="color: #AD0000;">64</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">153</span>, <span class="dv" style="color: #AD0000;">64</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">140</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>(226, 217, 204)</code></pre>
</div>
</div>
<p>The prompt (62) and completions (140, 153, 164) average about 200 tokens in length. This is a different tokenizer than I’m using so results will vary for my trained models</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>I have established two key elements for my evals:</p>
<ul>
<li>Targets based on the literature (for my reference models and experiment models)</li>
</ul>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">TinyStories</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Num Layers</th>
<th style="text-align: center;">Eval Loss</th>
<th style="text-align: center;">Creativity</th>
<th style="text-align: center;">Grammar</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Plot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">2.08</td>
<td style="text-align: center;">4.68</td>
<td style="text-align: center;">6.14</td>
<td style="text-align: center;">4.45</td>
<td style="text-align: center;">4.40</td>
</tr>
<tr class="even">
<td style="text-align: center;">8M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.38</td>
<td style="text-align: center;">6.54</td>
<td style="text-align: center;">7.72</td>
<td style="text-align: center;">8.02</td>
<td style="text-align: center;">7.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;">28M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.20</td>
<td style="text-align: center;">6.85</td>
<td style="text-align: center;">8.34</td>
<td style="text-align: center;">8.95</td>
<td style="text-align: center;">7.26</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Intermediate Dim</th>
<th style="text-align: center;">Number of Layers</th>
<th style="text-align: center;">Number of Params</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">4_949_696</td>
</tr>
<tr class="even">
<td style="text-align: center;">25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">24_776_960</td>
</tr>
<tr class="odd">
<td style="text-align: center;">60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">57_940_480</td>
</tr>
<tr class="even">
<td style="text-align: center;">125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">124_662_528</td>
</tr>
</tbody>
</table>
<ul>
<li>Generations using reference models for evaluation prompts from literature
<ul>
<li>44 prompts (62 tokens on average)</li>
</ul></li>
</ul>
<p>My next steps:</p>
<ul>
<li>Evaluate a sample of prompts from each model by hand for my six scoring categories:
<ul>
<li><strong>Foundational language capabilities</strong>: Grammar and Context-Tracking (Consistency)</li>
<li><strong>Emergent capabilities</strong>: Factual Knowledge, Reasoning, Creativity</li>
<li><strong>Story-related capabilities</strong>: Plot</li>
</ul></li>
<li>Prompt different LLMs, iterating on prompts until LLM Judge scores match mine 90%+ of the time.</li>
</ul>
<p>Both steps will take considerable, so I’ll break them down to smaller steps and publish blog posts and videos along the way. Make sure to subscribe to my YouTube channel or check the <a href="https://www.youtube.com/playlist?list=PLVaenshL7UUD8iFmDDUpLCcuB-K_72mwI">TinyScale Lab playlist</a> for latest content!</p>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-27-TSL-Setting-Eval-Targets/index.html</guid>
  <pubDate>Sun, 27 Apr 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TinyScaleLab: Bridging Training Dynamics and Model Capabilities</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/index.html</link>
  <description><![CDATA[ 



<iframe width="560" height="315" src="https://www.youtube.com/embed/82mE39Ef5eY?si=5h9fdvnAF0071VcA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>I’m excited to announce the kickoff of TinyScale Lab, a research project focused on exploring the connection between training dynamics and model capabilities. This research is motivated by two papers that I’ve studied in detail: <a href="https://arxiv.org/abs/2305.07759">“TinyStories: How Small Can Language Models Be and Still Speak Coherent English?” by Ronen Eldan and Yuanzhi Li</a>, and <a href="https://arxiv.org/abs/2309.14322">“Small-scale proxies for Large-scale Transformer Training Instabilities” by Wortsman, et al</a>.</p>
<p>Most LLM training-related research requires computational resources that are financially out of reach for individual researchers or small teams. At the same time, recent work has shown that tiny models exhibit emergent capabilities (as demonstrated in the TinyStories paper) and exhibit large-scale training dynamics (as shown in the Small-scale proxies paper).</p>
<p>While I don’t claim to be creating a definitive blueprint, I believe this approach—using tiny models as proxies to study phenomena relevant to models of all sizes—represents an underexplored path that could benefit other resource-constrained researchers.</p>
<p>I think this is how most of the world’s potential researchers would need to work. Making ML research accessible to resource-constrained environments isn’t trivial - it’s essential for the field’s diversity and progress.</p>
</section>
<section id="research-hypotheses" class="level2">
<h2 class="anchored" data-anchor-id="research-hypotheses">Research Hypotheses</h2>
<p>I’ve developed four main hypotheses that will guide my research:</p>
<ol type="1">
<li><strong>H1</strong>: Training stability directly affects specific model capabilities in predictable ways.</li>
<li><strong>H2</strong>: Different model capabilities (like grammar or consistency) respond differently to training adjustments.</li>
<li><strong>H3</strong>: Early training signals can predict which capabilities a model will or won’t develop before training is complete.</li>
<li><strong>H4</strong>: Techniques that stabilize training will have varying effects on different types of model capabilities.</li>
</ol>
<p>I’ve kept these hypotheses general at a high level because I really don’t know what I’m going to learn, but I do have a sense based on the TinyStories and Small-scale proxies papers that there is something around these four elements that I’m going to experience, and I expect to see some relationships.</p>
<p>I want to bridge the TinyStories paper analysis on emergent capabilities (grammar, consistency, factual knowledge, reasoning, etc.) with the Small-scale proxies paper training dynamics analysis (attention logits, training instabilities, learning rates, etc.).</p>
</section>
<section id="experimental-design" class="level2">
<h2 class="anchored" data-anchor-id="experimental-design">Experimental Design</h2>
<p>For my experimental design, I’ve decided to focus on four model sizes:</p>
<ul>
<li>~3M parameters</li>
<li>~20M parameters</li>
<li>~60M parameters</li>
<li>~120M parameters</li>
</ul>
<p>This follows the TinyStories paper closely, with the addition of a 120M parameter model.</p>
<p>I’ll use the same learning rates as the Small-scale proxies paper, ranging from 3e-4 to 3e-1 with seven learning rates in total: <code>{3e-4, 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1}</code></p>
<p>I’ll implement two stability techniques from the Small-scale proxies paper:</p>
<ul>
<li>QK layer norm (to mitigate attention logit growth)</li>
<li>Z loss (to mitigate output logit divergence)</li>
</ul>
<p>What will remain fixed across all training runs are the datasets, the number of training steps, and other hyperparameters like weight decay and warm-up steps.</p>
<p>The training dynamics I’ll log throughout training include:</p>
<ul>
<li>Logits</li>
<li>Gradients</li>
<li>Parameters</li>
<li>Loss</li>
</ul>
<p>For each of these, I’ll capture norms, means, maximum values, and RMS values.</p>
<p>The capabilities I want to evaluate are split into three categories:</p>
<ol type="1">
<li><strong>Foundational language</strong>: Grammar and context-tracking (consistency)</li>
<li><strong>Emergent capabilities</strong>: Factual knowledge, reasoning, and creativity</li>
<li><strong>Story-related</strong>: Plot</li>
</ol>
<p>The relationship between these training dynamics and capabilities is what I want to explore.</p>
</section>
<section id="success-criteria" class="level2">
<h2 class="anchored" data-anchor-id="success-criteria">Success Criteria</h2>
<p>My success criteria are simple but not easy: establishing clear connections between training dynamics and tiny model capabilities. This work is exploratory, and I’m open to discovering that the relationships might be more complex or different than initially hypothesized.</p>
</section>
<section id="risk-assessment" class="level2">
<h2 class="anchored" data-anchor-id="risk-assessment">Risk Assessment</h2>
<p>I’ve identified several risks that could impact this project:</p>
<ol type="1">
<li>Lack of connection between training dynamics and tiny model capabilities</li>
<li>Technical challenges in monitoring complex training dynamics</li>
<li>Sub-optimal parameter usage</li>
<li>Compute and inference costs ballooning beyond budget</li>
</ol>
</section>
<section id="risk-mitigation" class="level2">
<h2 class="anchored" data-anchor-id="risk-mitigation">Risk Mitigation</h2>
<p>To mitigate these risks, I plan to:</p>
<ol type="1">
<li>Shorten the iteration loop</li>
<li>Ensure evaluations are robust from the start</li>
<li>Start at the tiniest scale and progressively increase model size</li>
<li>Implement early stopping to avoid wasting compute</li>
</ol>
<p>I learned from the fastAI course and community that you want to shorten the iteration loop and ensure that evals are robust from the start. This gives you quick, immediate, robust, clear signal when you get feedback on how your model is performing.</p>
</section>
<section id="deliverables" class="level2">
<h2 class="anchored" data-anchor-id="deliverables">Deliverables</h2>
<p>My commitment is to produce:</p>
<ol type="1">
<li>Comprehensive research repositories including code, trained models, and detailed datasets (training dynamics and LLM Judge scores)</li>
<li>Weekly video content and blog posts</li>
<li>Technical report</li>
<li>Interactive visualizations</li>
</ol>
<p>The main thing I want to emphasize is that I’ll be doing this publicly and open-source. All models, code, and findings will be freely available to enable broader participation in ML research.</p>
</section>
<section id="timeline-and-budget" class="level2">
<h2 class="anchored" data-anchor-id="timeline-and-budget">Timeline and Budget</h2>
<p>I’ve broken the project into four phases:</p>
<ol type="1">
<li><strong>Phase 1</strong>: Eval/Logging Setup, Initial Training Runs (2-3 months)</li>
<li><strong>Phase 2</strong>: Experimental Implementation (3-4 months)</li>
<li><strong>Phase 3</strong>: Analysis &amp; Synthesis (2-3 months)</li>
<li><strong>Phase 4</strong>: Documentation &amp; Finalization (1 month)</li>
</ol>
<p>At minimum, I think this work will take eight months, and it could go well past a year.</p>
<p>For the budget, I’m estimating: - <strong>Training</strong>: $1700 (approximately 100 training runs on 25B tokens) - <strong>Inference</strong>: $200 (using Gemini 2.5 Flash for LLM Judge scoring) - <strong>Total</strong>: $2000</p>
<p>At this point, I’m considering whether it makes sense to buy my own GPU rig. If this is going to cost $2,000, why not spend a little more or twice as much and get a GPU rig that I can own? There are a lot of variables when it comes to budget and timeline, so I’m going to take it one week at a time and make adjustments as necessary.</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>To recap, TinyScale Lab aims to:</p>
<ol type="1">
<li>Bridge training dynamics and model capabilities to understand what makes tiny models effective</li>
<li>Create a systematic framework for understanding how training choices affect specific model capabilities</li>
<li>Demonstrate that meaningful ML research is accessible with modest computational resources</li>
<li>Open-source all models, code, and findings to enable broader participation in ML research</li>
</ol>
<p>As Nick Sirianni (championship winning coach of the Philadelphia Eagles) said, “You cannot be great without the greatness of others.” I truly stand on the shoulders of giants, especially the authors of the TinyStories and Small-scale proxies papers. Without their work and contributions in the open source space, I would not be able to even approach this kind of research.</p>
<p>If someone with similar interests sees this work and it inspires them, or they can use something I built that saves them time, saves them money, or gives them insight–that would be the best reward that comes out of this work.</p>
<p>I hope you’ll follow along with this journey. I’ll be keeping everything in the <a href="https://www.youtube.com/playlist?list=PLVaenshL7UUD8iFmDDUpLCcuB-K_72mwI">TinyScale Lab playlist on my YouTube</a> and will tag related posts on my blog.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" title="TinyScale-Lab bridges the gap between tiny model capabilities and training dynamics" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">TinyScale-Lab bridges the gap between tiny model capabilities and training dynamics</figcaption><p></p>
</figure>
</div>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/index.html</guid>
  <pubDate>Sat, 26 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/1.png" medium="image" type="image/png" height="216" width="144"/>
</item>
<item>
  <title>LossInspector: A Deep Dive Into LLM-Foundry’s Next-Token Prediction with a Custom Composer Callback</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-22-LossInspector/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I’m working on a research project where we’ll be fine-tuning small models with various techniques and datasets using LLM-Foundry. As part of our infrastructure setup, we wanted to make sure that we thoroughly understood how a batch of data is prepared by LLM-Foundry, and how the outputs of a model, along with the labels, are passed to the loss function to calculate the loss. To do so, with the help of Claude, I wrote up a custom Composer Callback. This is the third custom callback I’ve written for Composer/LLM-Foundry, you can read more about <a href="https://vishalbakshi.github.io/blog/posts/2025-03-30-Composer-Callback/">my first</a> and <a href="https://vishalbakshi.github.io/blog/posts/2025-04-02-Composer-Callback-Logging-dtypes/">second</a> callbacks.</p>
<p>I was initially going to have two or three callbacks: one to inspect inputs/outputs to the embedding, one to inspect the input/outputs to the model’s forward pass, and one to inspect the loss function. 27 commits later, I had a relatively lean single callback that gave me all the information I needed.</p>
<p>I focused on three events during Composer’s <a href="https://docs.mosaicml.com/projects/composer/en/stable/trainer/events.html">training loop</a>:</p>
<ul>
<li><code>before_loss</code>: to store the “untouched” batch from Composer’s <code>state</code>.</li>
<li><code>before_forward</code>: to store the untouched <code>input_ids</code> and <code>labels</code> from the state’s batch.</li>
<li><code>after_loss</code>: to both capture the calculated loss and “manually” calculate the loss using the model’s loss function.</li>
</ul>
<p>Before we go further into detail, here’s the callback code (and necessary imports):</p>
<p>Here’s my video walkthrough of the code in this notebook:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/9ffnmeiDF_M?si=DVAZhHFDfxkuzG6n" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="lossinspector-callback" class="level2">
<h2 class="anchored" data-anchor-id="lossinspector-callback"><code>LossInspector</code> Callback</h2>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> composer.core.callback <span class="im" style="color: #00769E;">import</span> Callback</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> composer.core <span class="im" style="color: #00769E;">import</span> State</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> composer.loggers <span class="im" style="color: #00769E;">import</span> Logger</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-5"></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;">class</span> LossInspector(Callback):       </span>
<span id="cb1-8">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb1-9">        <span class="bu" style="color: null;">super</span>().<span class="fu" style="color: #4758AB;">__init__</span>()</span>
<span id="cb1-10">        <span class="va" style="color: #111111;">self</span>.inspected <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb1-11">        <span class="va" style="color: #111111;">self</span>.input_ids <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb1-12">        <span class="va" style="color: #111111;">self</span>.labels <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb1-13">    </span>
<span id="cb1-14">    <span class="kw" style="color: #003B4F;">def</span> before_loss(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-15">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.inspected:</span>
<span id="cb1-16">            <span class="cf" style="color: #003B4F;">return</span></span>
<span id="cb1-17">        <span class="va" style="color: #111111;">self</span>.state_outputs <span class="op" style="color: #5E5E5E;">=</span> state.outputs</span>
<span id="cb1-18">        <span class="va" style="color: #111111;">self</span>.state_batch <span class="op" style="color: #5E5E5E;">=</span> state.batch</span>
<span id="cb1-19">        </span>
<span id="cb1-20"></span>
<span id="cb1-21">    <span class="kw" style="color: #003B4F;">def</span> before_forward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-22">        <span class="co" style="color: #5E5E5E;"># check that input_ids and labels are the same as after loss</span></span>
<span id="cb1-23">        <span class="va" style="color: #111111;">self</span>.input_ids <span class="op" style="color: #5E5E5E;">=</span> state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>].detach().cpu()</span>
<span id="cb1-24">        <span class="va" style="color: #111111;">self</span>.labels <span class="op" style="color: #5E5E5E;">=</span> state.batch[<span class="st" style="color: #20794D;">'labels'</span>][<span class="dv" style="color: #AD0000;">0</span>].detach().cpu()</span>
<span id="cb1-25">    </span>
<span id="cb1-26">    <span class="kw" style="color: #003B4F;">def</span> after_loss(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-27">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.inspected:</span>
<span id="cb1-28">            <span class="cf" style="color: #003B4F;">return</span></span>
<span id="cb1-29">            </span>
<span id="cb1-30">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">=== LOSS CALCULATION INSPECTION ==="</span>)</span>
<span id="cb1-31">        </span>
<span id="cb1-32">        <span class="co" style="color: #5E5E5E;"># Get the framework loss from state</span></span>
<span id="cb1-33">        framework_loss <span class="op" style="color: #5E5E5E;">=</span> state.loss.item()</span>
<span id="cb1-34">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Framework loss: </span><span class="sc" style="color: #5E5E5E;">{</span>framework_loss<span class="sc" style="color: #5E5E5E;">:.6f}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-35">        </span>
<span id="cb1-36">        <span class="co" style="color: #5E5E5E;"># Access model's loss_function directly</span></span>
<span id="cb1-37">        logits <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.state_outputs[<span class="st" style="color: #20794D;">'logits'</span>]</span>
<span id="cb1-38">        labels <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.state_batch[<span class="st" style="color: #20794D;">'labels'</span>]</span>
<span id="cb1-39">        vocab_size <span class="op" style="color: #5E5E5E;">=</span> state.model.model.config.vocab_size</span>
<span id="cb1-40">        </span>
<span id="cb1-41">        direct_loss <span class="op" style="color: #5E5E5E;">=</span> state.model.model.loss_function(</span>
<span id="cb1-42">            logits<span class="op" style="color: #5E5E5E;">=</span>logits,</span>
<span id="cb1-43">            labels<span class="op" style="color: #5E5E5E;">=</span>labels,</span>
<span id="cb1-44">            vocab_size<span class="op" style="color: #5E5E5E;">=</span>vocab_size</span>
<span id="cb1-45">        )</span>
<span id="cb1-46">        </span>
<span id="cb1-47">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Direct call to model.loss_function: </span><span class="sc" style="color: #5E5E5E;">{</span>direct_loss<span class="sc" style="color: #5E5E5E;">.</span>item()<span class="sc" style="color: #5E5E5E;">:.6f}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-48">        </span>
<span id="cb1-49">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">-------- input_ids --------"</span>)</span>
<span id="cb1-50">        input_ids <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.state_batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>].detach().cpu()</span>
<span id="cb1-51">        <span class="bu" style="color: null;">print</span>(input_ids.tolist())</span>
<span id="cb1-52">        decoded_input <span class="op" style="color: #5E5E5E;">=</span> state.model.tokenizer.decode(input_ids)</span>
<span id="cb1-53">        <span class="bu" style="color: null;">print</span>(decoded_input[:<span class="dv" style="color: #AD0000;">1000</span>])</span>
<span id="cb1-54">        </span>
<span id="cb1-55">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">-------- labels --------"</span>)</span>
<span id="cb1-56">        labels <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.state_batch[<span class="st" style="color: #20794D;">'labels'</span>][<span class="dv" style="color: #AD0000;">0</span>].detach().cpu()</span>
<span id="cb1-57">        <span class="bu" style="color: null;">print</span>(labels.tolist())</span>
<span id="cb1-58">        valid_labels <span class="op" style="color: #5E5E5E;">=</span> labels[labels <span class="op" style="color: #5E5E5E;">!=</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>]</span>
<span id="cb1-59">        decoded_labels <span class="op" style="color: #5E5E5E;">=</span> state.model.tokenizer.decode(valid_labels)</span>
<span id="cb1-60">        <span class="bu" style="color: null;">print</span>(decoded_labels)</span>
<span id="cb1-61"></span>
<span id="cb1-62">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">-------- matches before_forward values? --------"</span>)</span>
<span id="cb1-63">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"input_ids: </span><span class="sc" style="color: #5E5E5E;">{</span>torch<span class="sc" style="color: #5E5E5E;">.</span>allclose(input_ids, <span class="va" style="color: #111111;">self</span>.input_ids)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-64">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"labels: </span><span class="sc" style="color: #5E5E5E;">{</span>torch<span class="sc" style="color: #5E5E5E;">.</span>allclose(labels, <span class="va" style="color: #111111;">self</span>.labels)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-65">        </span>
<span id="cb1-66">        <span class="va" style="color: #111111;">self</span>.inspected <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span></code></pre></div>
<p>The callback is then appended to the <code>callbacks</code> list before passed to the Composer trainer.</p>
</section>
<section id="smollm2-135m-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="smollm2-135m-loss-function">SmolLM2-135M Loss Function</h2>
<p>It was surprisingly difficult to inspect the loss function. Or rather my lack of Composer/HuggingFace internals knowledge immediately surfaced with this task! Looking through the Composer GitHub repo and documentation, I found the following references to the model’s loss function—all quite helpful but too general:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">loss <span class="op" style="color: #5E5E5E;">=</span> model.loss(outputs, targets)</span></code></pre></div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;">for</span> epoch <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(NUM_EPOCHS):</span>
<span id="cb3-2">    <span class="cf" style="color: #003B4F;">for</span> inputs, targets <span class="kw" style="color: #003B4F;">in</span> dataloader:</span>
<span id="cb3-3">        outputs <span class="op" style="color: #5E5E5E;">=</span> model.forward(inputs)</span>
<span id="cb3-4">        loss <span class="op" style="color: #5E5E5E;">=</span> model.loss(outputs, targets)</span>
<span id="cb3-5">        loss.backward()</span>
<span id="cb3-6">        optimizer.step()</span>
<span id="cb3-7">        optimizer.zero_grad()</span></code></pre></div>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;">def</span> loss(<span class="va" style="color: #111111;">self</span>, outputs, batch):</span>
<span id="cb4-2">    <span class="co" style="color: #5E5E5E;"># pass batches and `forward` outputs to the loss</span></span>
<span id="cb4-3">    _, targets <span class="op" style="color: #5E5E5E;">=</span> batch</span>
<span id="cb4-4">    <span class="cf" style="color: #003B4F;">return</span> F.cross_entropy(outputs, targets)</span></code></pre></div>
<p>I looked at their MixUp algorithm’s source code in hopes for more detail but found none—though it did help me confirm how batches are handled:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;">class</span> MixUp(Algorithm):</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;">def</span> match(<span class="va" style="color: #111111;">self</span>, event: Event, state: State) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="bu" style="color: null;">bool</span>:</span>
<span id="cb5-3">        <span class="co" style="color: #5E5E5E;">"""Determines whether the algorithm should run on a given event."""</span></span>
<span id="cb5-4">        <span class="cf" style="color: #003B4F;">return</span> event <span class="kw" style="color: #003B4F;">in</span> [Event.AFTER_DATALOADER, Event.AFTER_LOSS]</span>
<span id="cb5-5"></span>
<span id="cb5-6">    <span class="kw" style="color: #003B4F;">def</span> <span class="bu" style="color: null;">apply</span>(<span class="va" style="color: #111111;">self</span>, event: Event, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb5-7">        <span class="co" style="color: #5E5E5E;">"""Run the algorithm by modifying the State."""</span></span>
<span id="cb5-8">        <span class="bu" style="color: null;">input</span>, target <span class="op" style="color: #5E5E5E;">=</span> state.batch</span>
<span id="cb5-9"></span>
<span id="cb5-10">        <span class="cf" style="color: #003B4F;">if</span> event <span class="op" style="color: #5E5E5E;">==</span> Event.AFTER_DATALOADER:</span>
<span id="cb5-11">            new_input, <span class="va" style="color: #111111;">self</span>.permuted_target, <span class="va" style="color: #111111;">self</span>.mixing <span class="op" style="color: #5E5E5E;">=</span> mixup_batch(<span class="bu" style="color: null;">input</span>, target, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>)</span>
<span id="cb5-12">            state.batch <span class="op" style="color: #5E5E5E;">=</span> (new_input, target)</span>
<span id="cb5-13"></span>
<span id="cb5-14">        <span class="cf" style="color: #003B4F;">if</span> event <span class="op" style="color: #5E5E5E;">==</span> Event.AFTER_LOSS:</span>
<span id="cb5-15">            modified_batch <span class="op" style="color: #5E5E5E;">=</span> (<span class="bu" style="color: null;">input</span>, <span class="va" style="color: #111111;">self</span>.permuted_target)</span>
<span id="cb5-16">            new_loss <span class="op" style="color: #5E5E5E;">=</span> state.model.loss(state.outputs, modified_batch)</span>
<span id="cb5-17">            state.loss <span class="op" style="color: #5E5E5E;">*=</span> (<span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">-</span> <span class="va" style="color: #111111;">self</span>.mixing)</span>
<span id="cb5-18">            state.loss <span class="op" style="color: #5E5E5E;">+=</span> <span class="va" style="color: #111111;">self</span>.mixing <span class="op" style="color: #5E5E5E;">*</span> new_loss</span></code></pre></div>
<p>Looking at Composer’s <code>HuggingFaceModel</code> did not give me the necessary detail, but provided the key for the next step: the loss was stored in <code>outputs</code>.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;">def</span> loss(<span class="va" style="color: #111111;">self</span>, outputs, batch):</span>
<span id="cb6-2">    <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.config.use_return_dict:</span>
<span id="cb6-3">        <span class="cf" style="color: #003B4F;">return</span> outputs[<span class="st" style="color: #20794D;">'loss'</span>]</span>
<span id="cb6-4">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb6-5">        <span class="co" style="color: #5E5E5E;"># loss is at index 0 in the output tuple</span></span>
<span id="cb6-6">        <span class="cf" style="color: #003B4F;">return</span> outputs[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<p>Did this mean that the loss function was tucked away in the forward pass? Let’s take a look.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoModelForCausalLM, AutoTokenizer</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span></span>
<span id="cb8-2">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb8-3">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(model_name)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;">import</span> inspect</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">forward_method <span class="op" style="color: #5E5E5E;">=</span> inspect.getsource(model.forward)</span>
<span id="cb10-2"><span class="bu" style="color: null;">print</span>(forward_method)</span></code></pre></div>
</div>
<p>I won’t print out the whole forward method, but will highlight that tucked away in there was the loss function call!</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">loss <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb11-2"><span class="cf" style="color: #003B4F;">if</span> labels <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb11-3">    loss <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.loss_function(logits<span class="op" style="color: #5E5E5E;">=</span>logits, labels<span class="op" style="color: #5E5E5E;">=</span>labels, vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>.config.vocab_size, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
<p>Aha! The function in question is <code>loss_function</code>. Inspecting that in more detail:</p>
<div class="cell" data-outputid="d9ba0d35-319f-444b-e060-7842ce9c6ebf" data-execution_count="6">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="bu" style="color: null;">print</span>(<span class="bu" style="color: null;">hasattr</span>(model, <span class="st" style="color: #20794D;">'loss_function'</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<p>This was a great opportunity for a refresher on the next-token objective and auto-regressive nature of this model.</p>
<div class="cell" data-outputid="be12edc7-9551-4d19-99f6-16d6af06abe1" data-execution_count="16">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="bu" style="color: null;">print</span>(inspect.getsource(model.loss_function))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>def ForCausalLMLoss(
    logits,
    labels,
    vocab_size: int,
    num_items_in_batch: Optional[int] = None,
    ignore_index: int = -100,
    shift_labels: Optional[torch.Tensor] = None,
    **kwargs,
) -&gt; torch.Tensor:
    # Upcast to float if we need to compute the loss to avoid potential precision issues
    logits = logits.float()

    if shift_labels is None:
        # Shift so that tokens &lt; n predict n
        labels = nn.functional.pad(labels, (0, 1), value=ignore_index)
        shift_labels = labels[..., 1:].contiguous()

    # Flatten the tokens
    logits = logits.view(-1, vocab_size)
    shift_labels = shift_labels.view(-1)
    # Enable model parallelism
    shift_labels = shift_labels.to(logits.device)
    loss = fixed_cross_entropy(logits, shift_labels, num_items_in_batch, ignore_index, **kwargs)
    return loss
</code></pre>
</div>
</div>
<p>The key for understanding next-token prediction are the following lines:</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="cf" style="color: #003B4F;">if</span> shift_labels <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb16-2">    <span class="co" style="color: #5E5E5E;"># Shift so that tokens &lt; n predict n</span></span>
<span id="cb16-3">    labels <span class="op" style="color: #5E5E5E;">=</span> nn.functional.pad(labels, (<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=</span>ignore_index)</span>
<span id="cb16-4">    shift_labels <span class="op" style="color: #5E5E5E;">=</span> labels[..., <span class="dv" style="color: #AD0000;">1</span>:].contiguous()</span></code></pre></div>
<p><code>nn.functional.pad</code> adds padding tokens to <code>labels</code>, specifically <code>0</code> to the left-most end of the last dimension and <code>1</code> padding token to the right-most end. The token it uses as padding is <code>ignore_index</code>, which is <code>-100</code>.</p>
<p>Next, it <em>shifts</em> the labels by 1 element to the left with <code>labels[..., 1:]</code>. I took a moment to realize what this meant: the <code>input_ids</code> and <code>labels</code>, in terms of position, are the same! To align the <code>labels</code> with the <code>logits</code> (which are already “shifted” in the sense that the first position in <code>logits</code> corresponds to the first predicted token: the second token in the context) we have to shift the <code>labels</code> by 1. To ensure that the final token in <code>input_ids</code> doesn’t predict anything, we pad <code>labels</code> with <code>-100</code>, the value ignored in the loss calculation.</p>
<p>As a reminder, if the context we’re training our model on is “the cat sat on the table”, each next token is predicted based on all previous tokens:</p>
<pre><code>the --&gt; cat
the cat --&gt; sat
the cat sat --&gt; on
the cat sat on --&gt; the
the cat sat on the --&gt; table</code></pre>
<p>This is a good time to return to our callback and analyze its output, but before I do, here’s a quick demo of the label shifting operation:</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;">from</span> torch.nn.functional <span class="im" style="color: #00769E;">import</span> pad</span>
<span id="cb18-2"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> tensor</span></code></pre></div>
</div>
<div class="cell" data-outputid="71616038-3f2d-43e5-85f2-adcc9b90a766" data-execution_count="10">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">labels <span class="op" style="color: #5E5E5E;">=</span> tensor([<span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">2</span>])</span>
<span id="cb19-2">labels</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor([3, 6, 4, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="72be094b-fdd3-4317-fea6-53ce914d3b3d" data-execution_count="11">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">pad(labels, (<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([   3,    6,    4,    2, -100])</code></pre>
</div>
</div>
<div class="cell" data-outputid="1184fe03-3d4d-41db-e07f-3d0cf1de0823" data-execution_count="12">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">pad(labels, (<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">0</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor([-100,    3,    6,    4,    2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="5893adca-e559-46bd-c16c-c02c7a876779" data-execution_count="13">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">pad(labels, (<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([-100,    3,    6,    4,    2, -100])</code></pre>
</div>
</div>
<div class="cell" data-outputid="4d957eab-06ec-4c64-9c1e-54b4a13e8a59" data-execution_count="14">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">pad(labels, (<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)[...,<span class="dv" style="color: #AD0000;">1</span>:]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([   6,    4,    2, -100])</code></pre>
</div>
</div>
</section>
<section id="callback-logs" class="level2">
<h2 class="anchored" data-anchor-id="callback-logs">Callback Logs</h2>
<p>There were four key print statements of interest in my callback. I’ll display each and show their printed value:</p>
<ol type="1">
<li><code>print(f"Framework loss: {framework_loss:.6f}")</code></li>
</ol>
<pre><code>Framework loss: 1.067513</code></pre>
<ol start="2" type="1">
<li><code>print(f"Direct call to model.loss_function: {direct_loss.item():.6f}")</code></li>
</ol>
<pre><code>Direct call to model.loss_function: 1.067513</code></pre>
<ol start="3" type="1">
<li><code>print(input_ids.tolist())</code></li>
<li><code>print(labels.tolist())</code></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="input_ids (top) and labels (bottom) with the response highlighted in yellow"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-22-LossInspector/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption"><code>input_ids</code> (top) and <code>labels</code> (bottom) with the response highlighted in yellow</figcaption><p></p>
</figure>
</div>
<p>The first two print statements confirmed that I was calling <code>state.model.loss_function</code> correctly. It also confirmed that the loss function doesn’t take in the <code>input_ids</code>.</p>
<p>The last two print statements confirmed my understanding: positionally speaking, the <code>input_ids</code> and <code>labels</code> are the same. In <code>labels</code> the positions of <code>input_ids</code> tokens that contain the prompt (and EOS tokens) are replaced with <code>-100</code> and the tokens that represent the response are kept as is. For reference, here’s what <code>input_ids</code> looks like (both the prompt and the response) coming from an item of the MetaMathQA dataset (I have ommitted the hundreds of padding EOS tokens and formatted the text for clearer presentation):</p>
<pre><code>A box with a volume of 16 $\text{cm}^3$ can hold X paperclips.
How many paperclips could a box with a volume of 48 $\text{cm}^3$ hold?
If we know the answer to the above question is 150, what is the value of unknown variable X?

We are given that a box with a volume of 16 $\text{cm}^3$ can hold $X$ paperclips.
To find out how many paperclips a box with a volume of 48 $\text{cm}^3$ can hold, we can set up a proportion using the given information.
We can write the proportion as:
16 $\text{cm}^3$ / $X$ paperclips = 48 $\text{cm}^3$ / 150 paperclips
We can cross-multiply and solve for $X$:
16 * 150 = 48 * $X$
2400 = 48 * $X$
Dividing both sides by 48, we get:
$X$ = 50
The value of $X$ is 50.
The answer is: 50&lt;|endoftext|&gt;</code></pre>
<p><code>labels</code> has the prompt replaced with <code>-100</code>s, and the loss function then left-shifts the <code>labels</code> tokens by 1 spot to align with the logits for next-token prediction comparison.</p>
<p>Unsurprisingly, the <code>input_ids</code> and <code>labels</code> before the forward pass and after the loss calculation are the same:</p>
<pre><code>print("\n-------- matches before_forward values? --------")
print(f"input_ids: {torch.allclose(input_ids, self.input_ids)}")
print(f"labels: {torch.allclose(labels, self.labels)}")</code></pre>
<pre><code>-------- matches before_forward values? --------
input_ids: True
labels: True</code></pre>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>With this baseline established, I can use this callback everytime we have processed a new dataset for training, inspecting the tokens, decoded text and loss values to ensure that the training loop will run properly for next-token prediction, whether it’s a continued pretraining or instruction fine-tuning dataset! Working with LLM-Foundry is a steep learning curve but I am learning a TON.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-22-LossInspector/index.html</guid>
  <pubDate>Tue, 22 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-04-22-LossInspector/1.png" medium="image" type="image/png" height="70" width="144"/>
</item>
<item>
  <title>Optimizing Matrix Multiplication Using Numba and Broadcasting</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this notebook I’ll solidy the matrix multiplication concepts taught in Lesson 11 of the fastai course (part 2). Most importantly, I want to make sure I understand the use of broadcasting to make the matmul operation 7000x faster!</p>
<p>Here’s a summary of run times for the five methods explored in this blog post:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Images</th>
<th style="text-align: center;">Run Time (ms)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Python for-loops</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1090ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba-compiled Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.555ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Python Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.47ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.22ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.158ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba-compiled Broadcasting</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.0936ms</td>
</tr>
</tbody>
</table>
<p>Here’s my video walkthrough of the code in this notebook:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-t8b7Otfmjo?si=XxML2gDu0u2H9P0g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="load-the-data" class="level2">
<h2 class="anchored" data-anchor-id="load-the-data">Load the Data</h2>
<p>We’ll use the MNIST dataset for this exercise.</p>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> tensor</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> pickle, gzip, math, os, time, shutil, matplotlib <span class="im" style="color: #00769E;">as</span> mpl, matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> urllib.request <span class="im" style="color: #00769E;">import</span> urlretrieve</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">MNIST_URL<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'</span></span>
<span id="cb2-2">path_data <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'data'</span>)</span>
<span id="cb2-3">path_data.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-4">path_gz <span class="op" style="color: #5E5E5E;">=</span> path_data<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'mnist.pkl.gz'</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> path_gz.exists(): urlretrieve(MNIST_URL, path_gz)</span>
<span id="cb3-2"><span class="cf" style="color: #003B4F;">with</span> gzip.<span class="bu" style="color: null;">open</span>(path_gz, <span class="st" style="color: #20794D;">'rb'</span>) <span class="im" style="color: #00769E;">as</span> f: ((x_train, y_train), (x_valid, y_valid), _) <span class="op" style="color: #5E5E5E;">=</span> pickle.load(f, encoding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'latin-1'</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="314ea9fa-e0ee-4889-b82b-2fa6eb76da22" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="op" style="color: #5E5E5E;">!</span>ls <span class="op" style="color: #5E5E5E;">-</span>l data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>total 16656
-rw-r--r-- 1 root root 17051982 Apr 21 22:56 mnist.pkl.gz</code></pre>
</div>
</div>
<div class="cell" data-outputid="35f01f0b-da44-4f57-ecd7-0735437dd72e" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">x_train,y_train,x_valid,y_valid <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(tensor, (x_train,y_train,x_valid,y_valid))</span>
<span id="cb6-2">x_train.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>torch.Size([50000, 784])</code></pre>
</div>
</div>
<div class="cell" data-outputid="b485d5c3-2095-4a56-87d4-1aa1d0932eed" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">imgs <span class="op" style="color: #5E5E5E;">=</span> x_train.reshape((<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">28</span>,<span class="dv" style="color: #AD0000;">28</span>))</span>
<span id="cb8-2">imgs.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>torch.Size([50000, 28, 28])</code></pre>
</div>
</div>
<div class="cell" data-outputid="2bf4f561-0371-41b3-fae9-e322e1b8d812" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">plt.imshow(imgs[<span class="dv" style="color: #AD0000;">0</span>])<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-8-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/index_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>For our weights, we’ll create a set of random floats with shape 784 (rows) x 10 (columns). In an applied sense, these 10 outputs would be the logits associated with the ten possible digits (0-9) for each 28x28 image.</p>
<div class="cell" data-outputid="1f22c0e7-a087-4b0b-b0d1-dd41e8940ecb" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb11-2">weights <span class="op" style="color: #5E5E5E;">=</span> torch.randn(<span class="dv" style="color: #AD0000;">784</span>, <span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb11-3">weights.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>torch.Size([784, 10])</code></pre>
</div>
</div>
<p>For our inputs (which get multiplied by our weights) we’ll use the first 5 digits (28x28 images) from the validation set. These inputs and our weights are the two matrices we want to multiply!</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">m1 <span class="op" style="color: #5E5E5E;">=</span> x_valid[:<span class="dv" style="color: #AD0000;">5</span>]</span>
<span id="cb13-2">m2 <span class="op" style="color: #5E5E5E;">=</span> weights</span></code></pre></div>
</div>
<div class="cell" data-outputid="212a05d8-26bd-4556-860b-257409a0fee5" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">m1.shape,m2.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(torch.Size([5, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
</section>
<section id="initial-solution-python-for-loops" class="level2">
<h2 class="anchored" data-anchor-id="initial-solution-python-for-loops">Initial Solution: Python for-Loops</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Naive implementation of matrix multiplication"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Naive implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<p>For our first iteration, we’ll do a nested for-loop—the most naive implementation of matrix multiplication in this exercise.</p>
<p>We iterate through the 5 rows of our input matrix (images). For each row, we iterate through each column of our weights matrix. For each of the 784 elements in that row/column (i,j) combination, we take the dot product and store it in the output matrix. 5 images x 10 outputs x 784 elements = 39200 total items operated on.</p>
<div class="cell" data-outputid="cb867e65-bd14-4756-a67d-532d55b3abd1" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="dv" style="color: #AD0000;">5</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">10</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">784</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>39200</code></pre>
</div>
</div>
<div class="cell" data-outputid="60c72dc6-52ab-412f-a330-aa63684b44da" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">ar,ac <span class="op" style="color: #5E5E5E;">=</span> m1.shape <span class="co" style="color: #5E5E5E;"># n_rows * n_cols</span></span>
<span id="cb18-2">br,bc <span class="op" style="color: #5E5E5E;">=</span> m2.shape</span>
<span id="cb18-3">(ar,ac),(br,bc)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>((5, 784), (784, 10))</code></pre>
</div>
</div>
<div class="cell" data-outputid="8425c8be-f9b5-40d5-f2d0-d7d301d18c05" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">t1 <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc) <span class="co" style="color: #5E5E5E;"># resultant tensor</span></span>
<span id="cb20-2">t1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): <span class="co" style="color: #5E5E5E;">#5</span></span>
<span id="cb22-2">    <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): <span class="co" style="color: #5E5E5E;"># 10</span></span>
<span id="cb22-3">        <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ac): <span class="co" style="color: #5E5E5E;"># 784</span></span>
<span id="cb22-4">            t1[i,j] <span class="op" style="color: #5E5E5E;">+=</span> m1[i,k] <span class="op" style="color: #5E5E5E;">*</span> m2[k,j]</span></code></pre></div>
</div>
<p>The resulting matrix has 5 rows (1 for each image) and 10 columns (one for each “neuron” in our weights matrix).</p>
<div class="cell" data-outputid="237f3596-1c48-43c0-bb07-bae65246ac40" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb23-2">t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],
        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],
        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],
        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],
        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb25-2">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>)</span></code></pre></div>
</div>
<p>Wrapping this code into a function we can time it.</p>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb26-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb26-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb26-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb26-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc):</span>
<span id="cb26-6">            <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ac): c[i,j] <span class="op" style="color: #5E5E5E;">+=</span> a[i,k] <span class="op" style="color: #5E5E5E;">*</span> b[k,j]</span>
<span id="cb26-7">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-outputid="20110470-6efe-4296-fe08-6e37fb72d9aa" data-execution_count="137">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="op" style="color: #5E5E5E;">%</span>time _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.09 s, sys: 544 µs, total: 1.09 s
Wall time: 1.09 s</code></pre>
</div>
</div>
<p>It takes a whopping 1.09 seconds to perform this matrix multiplication for 5 images! Let’s optimize this with numba.</p>
</section>
<section id="compiling-the-dot-product-with-numba" class="level2">
<h2 class="anchored" data-anchor-id="compiling-the-dot-product-with-numba">Compiling the Dot Product with Numba</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Matrix multiplication using a numba-compiled dot product operation"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Matrix multiplication using a numba-compiled dot product operation</figcaption><p></p>
</figure>
</div>
<p>To reduce the number of python for-loops, we write the dot product (between the two 784-element vectors) in numba:</p>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="im" style="color: #00769E;">from</span> numba <span class="im" style="color: #00769E;">import</span> njit</span></code></pre></div>
</div>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb30-2"><span class="kw" style="color: #003B4F;">def</span> dot(a,b):</span>
<span id="cb30-3">    res <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.</span></span>
<span id="cb30-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(a)): res<span class="op" style="color: #5E5E5E;">+=</span>a[i]<span class="op" style="color: #5E5E5E;">*</span>b[i]</span>
<span id="cb30-5">    <span class="cf" style="color: #003B4F;">return</span> res</span></code></pre></div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="im" style="color: #00769E;">from</span> numpy <span class="im" style="color: #00769E;">import</span> array</span></code></pre></div>
</div>
<p>The first run of <code>dot</code> takes longer as it includes the compile time:</p>
<div class="cell" data-outputid="61b070bc-e64a-4931-eb9a-16dc74db549c" data-execution_count="141">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="op" style="color: #5E5E5E;">%</span>time dot(array([<span class="fl" style="color: #AD0000;">1.</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>]),array([<span class="fl" style="color: #AD0000;">2.</span>,<span class="dv" style="color: #AD0000;">3</span>,<span class="dv" style="color: #AD0000;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 123 ms, sys: 0 ns, total: 123 ms
Wall time: 124 ms</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="141">
<pre><code>20.0</code></pre>
</div>
</div>
<p>The second run is 250x times faster.</p>
<div class="cell" data-outputid="8b7c64a0-582c-4b7f-ba4c-fae8fbcf9c26" data-execution_count="143">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="fl" style="color: #AD0000;">0.124</span><span class="op" style="color: #5E5E5E;">/</span><span class="fl" style="color: #AD0000;">0.000489</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="143">
<pre><code>253.5787321063395</code></pre>
</div>
</div>
<div class="cell" data-outputid="30d7d3a4-c845-477c-9623-675a383c6fbb" data-execution_count="142">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="op" style="color: #5E5E5E;">%</span>time dot(array([<span class="fl" style="color: #AD0000;">1.</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>]),array([<span class="fl" style="color: #AD0000;">2.</span>,<span class="dv" style="color: #AD0000;">3</span>,<span class="dv" style="color: #AD0000;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 40 µs, sys: 5 µs, total: 45 µs
Wall time: 48.9 µs</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="142">
<pre><code>20.0</code></pre>
</div>
</div>
<p>We replace the third for-loop with our numba <code>dot</code> function:</p>
<div class="cell" data-execution_count="160">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb40-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb40-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb40-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb40-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> dot(a[i,:], b[:,j])</span>
<span id="cb40-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">m1a,m2a <span class="op" style="color: #5E5E5E;">=</span> m1.numpy(),m2.numpy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="im" style="color: #00769E;">from</span> fastcore.test <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span></code></pre></div>
</div>
<p>We test that it yields the same result:</p>
<div class="cell" data-execution_count="163">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div class="cell" data-outputid="b9655c05-775a-425e-8921-91505c5a4d48" data-execution_count="151">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> matmul(m1a,m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>555 µs ± 14.5 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
<p>Our numba-compiled <code>dot</code> operation makes our matrix multiplication 2000x faster!</p>
<div class="cell" data-outputid="5d850c83-dc19-43fb-a238-e613ef13bfc8" data-execution_count="152">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="fl" style="color: #AD0000;">1.09</span><span class="op" style="color: #5E5E5E;">/</span><span class="fl" style="color: #AD0000;">555e-6</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="152">
<pre><code>1963.963963963964</code></pre>
</div>
</div>
<p>The same operation can be done in Python:</p>
<div class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb48-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb48-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb48-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb48-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:] <span class="op" style="color: #5E5E5E;">*</span> b[:,j]).<span class="bu" style="color: null;">sum</span>()</span>
<span id="cb48-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<p>But it’s three times slower than numba:</p>
<div class="cell" data-outputid="e9b4fe5b-ca19-4d9c-ab52-6b6e5b7f5cc9" data-execution_count="166">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.47 ms ± 32.3 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
<p>Using <code>torch.dot</code> is a smidge faster than Python:</p>
<div class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb52-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb52-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb52-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb52-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> torch.dot(a[i,:], b[:,j])</span>
<span id="cb52-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="168">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="60fdda95-41de-4628-b901-bd94f407e572" data-execution_count="169">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.22 ms ± 39.1 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="faster-use-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="faster-use-broadcasting">Faster: Use Broadcasting!</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Using broadcasting to compute all image/weight dot products simultaneously!"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/3.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Using broadcasting to compute all image/weight dot products simultaneously!</figcaption><p></p>
</figure>
</div>
<p>Broadcasting effectively expands the smaller matrix to match the size of the larger one so that element-wise operations can take place.</p>
<p>Suppose we wanted to take the dot product between the first image and all 10 columns of weights. Adding a <code>None</code> during indexing adds a unit axis at that position:</p>
<div class="cell" data-outputid="2676c4cc-c732-4947-e7d1-851a3b0fadf1" data-execution_count="21">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1">m1[<span class="dv" style="color: #AD0000;">0</span>,:].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>torch.Size([784])</code></pre>
</div>
</div>
<div class="cell" data-outputid="bc6ed9d8-f7cc-48b8-b6e5-a0e3e5edcf7b" data-execution_count="22">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">m1[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>torch.Size([784, 1])</code></pre>
</div>
</div>
<div class="cell" data-outputid="8c97f11e-a361-4495-dc0e-1b02a7a41a11" data-execution_count="23">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1">m2.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>torch.Size([784, 10])</code></pre>
</div>
</div>
<p>Multiplying (element-wise) <code>m1[0, :, None]</code> with <code>m2</code> <em>broadcasts</em> <code>m1[0, :, None]</code> across the 10 columns of <code>m2</code>. In other words, each row of <code>m1[0]</code> is virtually copied over 10 times, one for each column of <code>m2</code>.</p>
<div class="cell" data-outputid="851cd77c-a7c6-47c4-b5ab-4cf31b2f3992" data-execution_count="25">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1">(m1[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> m2).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>torch.Size([784, 10])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ff7e2357-7bd5-4fcc-b145-209686989ebb" data-execution_count="36">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">m1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>torch.Size([5, 784])</code></pre>
</div>
</div>
<div class="cell" data-outputid="6d3005bf-b2b3-47df-ed78-974f090d94e6" data-execution_count="42">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1">m1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])</code></pre>
</div>
</div>
<p>Here’s a smaller example. <code>a</code> has 5 rows, “images”, each with 4 pixels.</p>
<div class="cell" data-outputid="a1c16304-fd94-4b01-e12c-dfe5d97511b6" data-execution_count="37">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1">a <span class="op" style="color: #5E5E5E;">=</span> torch.randint(low<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, high<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">5</span>,<span class="dv" style="color: #AD0000;">4</span>))</span>
<span id="cb68-2">a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([[1, 4, 3, 4],
        [1, 4, 1, 3],
        [3, 2, 2, 4],
        [3, 1, 3, 1],
        [2, 3, 1, 1]])</code></pre>
</div>
</div>
<p>We pluck out the first “image” with <code>0</code>, then add a unit axis at the end with <code>None</code> to make it “broadcastable”</p>
<div class="cell" data-outputid="917a5f84-282b-4c51-bf82-4860c08cc859" data-execution_count="38">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1">a[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([[1],
        [4],
        [3],
        [4]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="19287d6f-36f8-42e6-8136-36cb6881f1ff" data-execution_count="43">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1">a.shape, a[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>(torch.Size([5, 4]), torch.Size([4, 1]))</code></pre>
</div>
</div>
<p>Suppose we have weights <code>w</code> with 4 rows, each 10 columns wide.</p>
<div class="cell" data-outputid="2370ca54-9190-4415-d920-171c9c705707" data-execution_count="47">
<div class="sourceCode cell-code" id="cb74" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1">w <span class="op" style="color: #5E5E5E;">=</span> torch.randint(low<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, high<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">10</span>))</span>
<span id="cb74-2">w</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([[2, 2, 1, 1, 4, 3, 4, 2, 4, 3],
        [1, 2, 4, 2, 4, 1, 3, 1, 2, 1],
        [4, 3, 4, 3, 1, 2, 1, 3, 3, 4],
        [1, 3, 3, 3, 3, 1, 1, 1, 4, 4]])</code></pre>
</div>
</div>
<p>We broadcast the 4-vector <code>a[0, :, None]</code> across all 10 4-vectors in <code>w</code>:</p>
<div class="cell" data-outputid="73442351-22b9-46eb-cde5-d4ee374d2679" data-execution_count="48">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1">a[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> w</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([[ 2,  2,  1,  1,  4,  3,  4,  2,  4,  3],
        [ 4,  8, 16,  8, 16,  4, 12,  4,  8,  4],
        [12,  9, 12,  9,  3,  6,  3,  9,  9, 12],
        [ 4, 12, 12, 12, 12,  4,  4,  4, 16, 16]])</code></pre>
</div>
</div>
<p>Then take the sum down the columns (along the row axis) to get the 10 output “activations” for this “image”:</p>
<div class="cell" data-outputid="0795be2f-d5b5-42a7-91f8-13d352fc7a46" data-execution_count="49">
<div class="sourceCode cell-code" id="cb78" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1">(a[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> w).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>tensor([22, 31, 41, 30, 35, 17, 23, 19, 37, 35])</code></pre>
</div>
</div>
<p>Looking at the first value of <code>22</code>, it comes from the dot product between the first “image” in <code>a</code> and the first row of weights (the “neuron”) in <code>w</code>:</p>
<p>22 = 1*2 + 4*1 + 3*4 + 4*1 = 2 + 4 + 12 + 4</p>
<p>In this way, we have the dot product between the first image and all 10 columns. This is the first row of the matrix product between <code>a</code> and <code>w</code>.</p>
<p>We can then loop over the images, broadcasting it across the weight matrix, summing down the columns to get each subsequent row of our resultant matrix product:</p>
<div class="cell" data-outputid="db6f46a2-bfa0-48a7-b336-5f5c1332f01f" data-execution_count="51">
<div class="sourceCode cell-code" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1">(ar,ac),(wr,wc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,w.shape</span>
<span id="cb80-2">ar,ac,wr,wc</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>(5, 4, 4, 10)</code></pre>
</div>
</div>
<div class="cell" data-outputid="2b8330a8-6dbd-4092-8f5f-6aaeaf7ccdfb" data-execution_count="52">
<div class="sourceCode cell-code" id="cb82" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1">c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, wc)</span>
<span id="cb82-2">c.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ab5b28b8-b7be-4d85-da36-730fd8943ca4" data-execution_count="53">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb84-2">    c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i, :, <span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> w).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb84-3">c</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>tensor([[22., 31., 41., 30., 35., 17., 23., 19., 37., 35.],
        [13., 22., 30., 21., 30., 12., 20., 12., 27., 23.],
        [20., 28., 31., 25., 34., 19., 24., 18., 38., 35.],
        [20., 20., 22., 17., 22., 17., 19., 17., 27., 26.],
        [12., 16., 21., 14., 24., 12., 19., 11., 21., 17.]])</code></pre>
</div>
</div>
<p>In this way, we have performed matrix multiplication by taking the dot product of each row/column using broadcasting! Returning to our original dataset:</p>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb86-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb86-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb86-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i]  <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb86-5">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="dcb5e610-3ea9-4af8-83bf-c0390020cd2c" data-execution_count="58">
<div class="sourceCode cell-code" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>158 µs ± 15.1 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
<p>This gives us a 8x speedup from the numba-compiled dot product (1.22ms –&gt; 0.158 ms).</p>
<p>Now, instead of 5 images we can perform matmul with all 50k images in our dataset.</p>
<div class="cell" data-outputid="3877da3f-6cfe-433f-f7bc-6e70d2b80678" data-execution_count="59">
<div class="sourceCode cell-code" id="cb90" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1">tr <span class="op" style="color: #5E5E5E;">=</span> matmul(x_train, weights)</span>
<span id="cb90-2">tr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>tensor([[  0.96,  -2.96,  -2.11,  ..., -15.09, -17.69,   0.60],
        [  6.89,  -0.34,   0.79,  ..., -17.13, -25.36,  16.23],
        [-10.18,   7.38,   4.13,  ...,  -6.73,  -6.79,  -1.58],
        ...,
        [  7.40,   7.64,  -3.50,  ...,  -1.02, -16.22,   2.07],
        [  3.25,   9.52,  -9.37,  ...,   2.98, -19.58,  -1.96],
        [ 15.70,   4.12,  -5.62,  ...,   8.08, -12.21,   0.42]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="a96bae33-3c9c-4380-c4da-7df3c44e1cb3" data-execution_count="60">
<div class="sourceCode cell-code" id="cb92" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1">tr.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>torch.Size([50000, 10])</code></pre>
</div>
</div>
<p>This operation now takes less than two seconds!</p>
<div class="cell" data-outputid="9b5bb005-9613-4419-dfc5-af1c2b30c464" data-execution_count="63">
<div class="sourceCode cell-code" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><span class="op" style="color: #5E5E5E;">%</span>time _<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train, weights)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.62 s, sys: 0 ns, total: 1.62 s
Wall time: 1.63 s</code></pre>
</div>
</div>
</section>
<section id="fastest-numba-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="fastest-numba-broadcasting">Fastest: Numba Broadcasting</h2>
<div class="cell" data-outputid="4af16216-46bd-41a9-a893-aa5229bb6d54" data-execution_count="69">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">m1a.shape, m2a.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>((5, 784), (784, 10))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb98" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb98-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb98-3">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb98-4">    c <span class="op" style="color: #5E5E5E;">=</span> np.zeros((ar, bc))</span>
<span id="cb98-5">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb98-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb99" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div class="cell" data-outputid="13b4fff2-ef89-4c34-9bc9-0d77963e5334" data-execution_count="86">
<div class="sourceCode cell-code" id="cb100" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1a, m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>93.6 µs ± 9.26 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
<p>We can now perform matrix multiplication for all 50_000 images in less time than we could for 5 images using nested for-loops. AMAZING!</p>
<div class="cell" data-outputid="6f076764-93d6-41d6-a7bf-b82f5ee271a2" data-execution_count="91">
<div class="sourceCode cell-code" id="cb102" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><span class="op" style="color: #5E5E5E;">%</span>time _<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train.numpy(), weights.numpy())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 885 ms, sys: 0 ns, total: 885 ms
Wall time: 881 ms</code></pre>
</div>
</div>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>I’ve been busy with other ML projects over the past few months but I’m so glad I have gotten back in the driver’s seat for fastai course part 2! The videos, content, and potential projects/exercises that spring forth are absolutely delicious. Using relatively simple building blocks, I was able to understand matrix multiplication through Python loops, numba dot product, and Yorick-inspired PyTorch broadcasting. Creating the visuals (in excalidraw) was a <em>must</em> because I really needed to cement these concepts in my mind, as encouraged by Jeremy in the video.</p>
<p>Here’s the summary again of run times for each of the methods shown above:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Images</th>
<th style="text-align: center;">Run Time (ms)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Python for-loops</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1090ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba-compiled Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.555ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Python Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.47ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.22ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.158ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba-compiled Broadcasting</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.0936ms</td>
</tr>
</tbody>
</table>
<p>Using numba-compiled broadcasting, the 5-image matrix multiplication with weights experienced a 12000x speedup compared to the naive Python nested for-loop implementation! Amazing!!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/index.html</guid>
  <pubDate>Mon, 21 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/1.png" medium="image" type="image/png" height="49" width="144"/>
</item>
<item>
  <title>Logging Data Types for Activations, Gradients, Weights, Optimizer States and Loss during Training with LLM-Foundry</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-02-Composer-Callback-Logging-dtypes/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In a <a href="https://vishalbakshi.github.io/blog/posts/2025-03-30-Composer-Callback/">previous blog post</a> I shared my first couple of iterations of custom Composer callback used to log data types of different entities (activations, gradients, weights, optimizer states, and loss) during training with LLM-Foundry. In this blog post I’ll share my final callback iteration’s code, some lessons I learned along the way (i.e.&nbsp;LLaMA’s self-attention module doesn’t have positional arguments!) and analyze the logging results to observe entity data types throughout the training loop.</p>
</section>
<section id="composer-callback-walkthrough" class="level2">
<h2 class="anchored" data-anchor-id="composer-callback-walkthrough">Composer Callback Walkthrough</h2>
<p>The data types of entities (activations, gradients, weights, loss, and optimizer states) are logged during training with a custom Composer callback <code>DtypeLogger</code> passed to the Composer <code>Trainer</code>. This callback was built up and tested event-by-event using Claude. There is one event handler in the callback for each Composer event from <code>&lt;FIT_START&gt;</code> to <code>&lt;BATCH_END&gt;</code>:</p>
<pre><code># &lt;INIT&gt;
# &lt;BEFORE_LOAD&gt;
# &lt;AFTER_LOAD&gt;
# &lt;FIT_START&gt;
for epoch in range(NUM_EPOCHS):
    # &lt;EPOCH_START&gt;
    while True:
        # &lt;BEFORE_DATALOADER&gt;
        batch = next(dataloader)
        if batch is None:
            break
        inputs, targets = batch
        # &lt;AFTER_DATALOADER&gt;

        # &lt;BATCH_START&gt;

        # &lt;BEFORE_FORWARD&gt;
        outputs = model.forward(inputs)
        # &lt;AFTER_FORWARD&gt;

        # &lt;BEFORE_LOSS&gt;
        loss = model.loss(outputs, targets)
        # &lt;AFTER_LOSS&gt;

        # &lt;BEFORE_BACKWARD&gt;
        loss.backward()
        # &lt;AFTER_BACKWARD&gt;

        optimizer.step()
        optimizer.zero_grad()

        # &lt;BATCH_END&gt;
    # &lt;EPOCH_END&gt;</code></pre>
<p>There are four explicit logging functions:</p>
<ul>
<li><code>_log_model_weight_dtypes</code></li>
<li><code>_log_gradient_dtypes</code></li>
<li><code>_log_optimizer_state_dtypes</code></li>
<li><code>_log_loss_dtype</code></li>
</ul>
<p>Additionally, activations are logged using <code>register_forward_hook</code> for all modules except self-attention (more on that below). Self-attention inputs are logged using a monkey-patched forward pass.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">class</span> DtypeLogger(Callback):</span>
<span id="cb2-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, save_path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/model-checkpoints/dtype_tracking"</span>, log_interval<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>):</span>
<span id="cb2-3">        <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">=</span> Path(save_path)</span>
<span id="cb2-4">        <span class="va" style="color: #111111;">self</span>.dtype_logs <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'log'</span>: {}}</span>
<span id="cb2-5">        <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">=</span> log_interval</span>
<span id="cb2-6">        <span class="va" style="color: #111111;">self</span>.hooks <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb2-7">        </span>
<span id="cb2-8">    <span class="kw" style="color: #003B4F;">def</span> fit_start(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-9">        <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"fit_start"</span>)</span>
<span id="cb2-10">        <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-11">        </span>
<span id="cb2-12">    <span class="kw" style="color: #003B4F;">def</span> epoch_start(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-13">        <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"epoch_start"</span>)</span>
<span id="cb2-14">        <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-15">    </span>
<span id="cb2-16">    <span class="kw" style="color: #003B4F;">def</span> before_dataloader(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-17">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-18">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_dataloader"</span>)</span>
<span id="cb2-19">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-20">            </span>
<span id="cb2-21">    <span class="kw" style="color: #003B4F;">def</span> after_dataloader(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-22">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-23">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"after_dataloader"</span>)</span>
<span id="cb2-24">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-25">            </span>
<span id="cb2-26">    <span class="kw" style="color: #003B4F;">def</span> batch_start(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-27">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-28">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"batch_start"</span>)</span>
<span id="cb2-29">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-30">            </span>
<span id="cb2-31">    <span class="kw" style="color: #003B4F;">def</span> before_forward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-32">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-33">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_forward"</span>)</span>
<span id="cb2-34">            </span>
<span id="cb2-35">            <span class="co" style="color: #5E5E5E;"># Clear old hooks</span></span>
<span id="cb2-36">            <span class="cf" style="color: #003B4F;">for</span> hook <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.hooks:</span>
<span id="cb2-37">                hook.remove()</span>
<span id="cb2-38">            <span class="va" style="color: #111111;">self</span>.hooks <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb2-39">            </span>
<span id="cb2-40">            <span class="co" style="color: #5E5E5E;"># Get the model</span></span>
<span id="cb2-41">            model <span class="op" style="color: #5E5E5E;">=</span> state.model.model.base_model.model</span>
<span id="cb2-42">            transformer_model <span class="op" style="color: #5E5E5E;">=</span> model.model  <span class="co" style="color: #5E5E5E;"># This is the transformer part</span></span>
<span id="cb2-43">            batch_id <span class="op" style="color: #5E5E5E;">=</span> state.timestamp.batch.value</span>
<span id="cb2-44">            </span>
<span id="cb2-45">            <span class="co" style="color: #5E5E5E;"># Store original forward methods to restore later</span></span>
<span id="cb2-46">            <span class="va" style="color: #111111;">self</span>.original_forward_methods <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb2-47">            </span>
<span id="cb2-48">            <span class="kw" style="color: #003B4F;">def</span> hook_fn(layer_name, module_name):</span>
<span id="cb2-49">                <span class="kw" style="color: #003B4F;">def</span> _hook(module, inputs, outputs):</span>
<span id="cb2-50">                    <span class="co" style="color: #5E5E5E;"># Log input activation dtype</span></span>
<span id="cb2-51">                    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(inputs, <span class="bu" style="color: null;">tuple</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(inputs) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-52">                        <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:</span><span class="sc" style="color: #5E5E5E;">{</span>module_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>layer_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_input"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(inputs[<span class="dv" style="color: #AD0000;">0</span>].dtype)</span>
<span id="cb2-53">                    </span>
<span id="cb2-54">                    <span class="co" style="color: #5E5E5E;"># Log output activation dtype</span></span>
<span id="cb2-55">                    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(outputs, torch.Tensor):</span>
<span id="cb2-56">                        <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:</span><span class="sc" style="color: #5E5E5E;">{</span>module_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>layer_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_output"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(outputs.dtype)</span>
<span id="cb2-57">                    <span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">isinstance</span>(outputs, <span class="bu" style="color: null;">tuple</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(outputs) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-58">                        <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:</span><span class="sc" style="color: #5E5E5E;">{</span>module_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>layer_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_output"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(outputs[<span class="dv" style="color: #AD0000;">0</span>].dtype)</span>
<span id="cb2-59">                <span class="cf" style="color: #003B4F;">return</span> _hook</span>
<span id="cb2-60">            </span>
<span id="cb2-61">            <span class="co" style="color: #5E5E5E;"># Monkey patch self-attention modules</span></span>
<span id="cb2-62">            <span class="cf" style="color: #003B4F;">for</span> layer_idx, layer <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(transformer_model.layers):</span>
<span id="cb2-63">                <span class="co" style="color: #5E5E5E;"># Store the original forward method</span></span>
<span id="cb2-64">                original_forward <span class="op" style="color: #5E5E5E;">=</span> layer.self_attn.forward</span>
<span id="cb2-65">                <span class="va" style="color: #111111;">self</span>.original_forward_methods[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> original_forward</span>
<span id="cb2-66">                </span>
<span id="cb2-67">                <span class="co" style="color: #5E5E5E;"># Define a closure to capture the current layer_idx</span></span>
<span id="cb2-68">                <span class="kw" style="color: #003B4F;">def</span> make_patched_forward(layer_idx, orig_forward):</span>
<span id="cb2-69">                    <span class="kw" style="color: #003B4F;">def</span> patched_forward(self_attn, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb2-70">                        <span class="co" style="color: #5E5E5E;"># Log the hidden_states dtype</span></span>
<span id="cb2-71">                        <span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'hidden_states'</span> <span class="kw" style="color: #003B4F;">in</span> kwargs <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">hasattr</span>(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>], <span class="st" style="color: #20794D;">'dtype'</span>):</span>
<span id="cb2-72">                            <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:self_attn:layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_input"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>].dtype)</span>
<span id="cb2-73">                        </span>
<span id="cb2-74">                        <span class="co" style="color: #5E5E5E;"># Call the original method as a bound method</span></span>
<span id="cb2-75">                        <span class="co" style="color: #5E5E5E;"># This ensures 'self_attn' is correctly passed as 'self'</span></span>
<span id="cb2-76">                        <span class="cf" style="color: #003B4F;">return</span> orig_forward.<span class="fu" style="color: #4758AB;">__get__</span>(self_attn, <span class="bu" style="color: null;">type</span>(self_attn))(<span class="op" style="color: #5E5E5E;">**</span>kwargs)</span>
<span id="cb2-77">                    </span>
<span id="cb2-78">                    <span class="cf" style="color: #003B4F;">return</span> patched_forward</span>
<span id="cb2-79">                </span>
<span id="cb2-80">                <span class="co" style="color: #5E5E5E;"># Replace the forward method</span></span>
<span id="cb2-81">                layer.self_attn.forward <span class="op" style="color: #5E5E5E;">=</span> make_patched_forward(layer_idx, original_forward).<span class="fu" style="color: #4758AB;">__get__</span>(layer.self_attn, <span class="bu" style="color: null;">type</span>(layer.self_attn))</span>
<span id="cb2-82">            </span>
<span id="cb2-83">            <span class="co" style="color: #5E5E5E;"># Register hook for lm_head</span></span>
<span id="cb2-84">            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(model, <span class="st" style="color: #20794D;">'lm_head'</span>):</span>
<span id="cb2-85">                <span class="va" style="color: #111111;">self</span>.hooks.append(model.lm_head.register_forward_hook(hook_fn(<span class="st" style="color: #20794D;">"output"</span>, <span class="st" style="color: #20794D;">"lm_head"</span>)))</span>
<span id="cb2-86">            </span>
<span id="cb2-87">            <span class="co" style="color: #5E5E5E;"># Register hook for embedding layer</span></span>
<span id="cb2-88">            <span class="va" style="color: #111111;">self</span>.hooks.append(transformer_model.embed_tokens.register_forward_hook(hook_fn(<span class="st" style="color: #20794D;">"embeddings"</span>, <span class="st" style="color: #20794D;">"embed_tokens"</span>)))</span>
<span id="cb2-89">            </span>
<span id="cb2-90">            <span class="co" style="color: #5E5E5E;"># Register hooks for each transformer layer</span></span>
<span id="cb2-91">            <span class="cf" style="color: #003B4F;">for</span> layer_idx, layer <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(transformer_model.layers):</span>
<span id="cb2-92">                <span class="co" style="color: #5E5E5E;"># Self-attention components - we still register hooks for outputs</span></span>
<span id="cb2-93">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"self_attn"</span>)))</span>
<span id="cb2-94">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.q_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"q_proj"</span>)))</span>
<span id="cb2-95">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.k_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"k_proj"</span>)))</span>
<span id="cb2-96">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.v_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"v_proj"</span>)))</span>
<span id="cb2-97">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.o_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"o_proj"</span>)))</span>
<span id="cb2-98">                </span>
<span id="cb2-99">                <span class="co" style="color: #5E5E5E;"># MLP components</span></span>
<span id="cb2-100">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.mlp.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"mlp"</span>)))</span>
<span id="cb2-101">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.mlp.gate_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"gate_proj"</span>)))</span>
<span id="cb2-102">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.mlp.up_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"up_proj"</span>)))</span>
<span id="cb2-103">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.mlp.down_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"down_proj"</span>)))</span>
<span id="cb2-104">                </span>
<span id="cb2-105">                <span class="co" style="color: #5E5E5E;"># Layer norms</span></span>
<span id="cb2-106">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.input_layernorm.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"input_layernorm"</span>)))</span>
<span id="cb2-107">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.post_attention_layernorm.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"post_attention_layernorm"</span>)))</span>
<span id="cb2-108">            </span>
<span id="cb2-109">            <span class="co" style="color: #5E5E5E;"># Final layer norm</span></span>
<span id="cb2-110">            <span class="va" style="color: #111111;">self</span>.hooks.append(transformer_model.norm.register_forward_hook(hook_fn(<span class="st" style="color: #20794D;">"final"</span>, <span class="st" style="color: #20794D;">"norm"</span>)))</span>
<span id="cb2-111">            </span>
<span id="cb2-112">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-113">            </span>
<span id="cb2-114">    <span class="kw" style="color: #003B4F;">def</span> after_forward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-115">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-116">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"after_forward"</span>)</span>
<span id="cb2-117">            </span>
<span id="cb2-118">            <span class="co" style="color: #5E5E5E;"># Restore original forward methods</span></span>
<span id="cb2-119">            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(<span class="va" style="color: #111111;">self</span>, <span class="st" style="color: #20794D;">'original_forward_methods'</span>):</span>
<span id="cb2-120">                model <span class="op" style="color: #5E5E5E;">=</span> state.model.model.base_model.model</span>
<span id="cb2-121">                transformer_model <span class="op" style="color: #5E5E5E;">=</span> model.model</span>
<span id="cb2-122">                </span>
<span id="cb2-123">                <span class="cf" style="color: #003B4F;">for</span> layer_idx, original_forward <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.original_forward_methods.items():</span>
<span id="cb2-124">                    transformer_model.layers[layer_idx].self_attn.forward <span class="op" style="color: #5E5E5E;">=</span> original_forward</span>
<span id="cb2-125">                </span>
<span id="cb2-126">                <span class="va" style="color: #111111;">self</span>.original_forward_methods <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb2-127">            </span>
<span id="cb2-128">            <span class="co" style="color: #5E5E5E;"># Clear hooks</span></span>
<span id="cb2-129">            <span class="cf" style="color: #003B4F;">for</span> hook <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.hooks:</span>
<span id="cb2-130">                hook.remove()</span>
<span id="cb2-131">            <span class="va" style="color: #111111;">self</span>.hooks <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb2-132">            </span>
<span id="cb2-133">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-134">            </span>
<span id="cb2-135">    <span class="kw" style="color: #003B4F;">def</span> before_loss(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-136">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-137">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_loss"</span>)</span>
<span id="cb2-138">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-139">            </span>
<span id="cb2-140">    <span class="kw" style="color: #003B4F;">def</span> after_loss(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-141">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-142">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"after_loss"</span>)</span>
<span id="cb2-143">            <span class="va" style="color: #111111;">self</span>._log_loss_dtype(state, <span class="st" style="color: #20794D;">"after_loss"</span>)</span>
<span id="cb2-144">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-145">            </span>
<span id="cb2-146">    <span class="kw" style="color: #003B4F;">def</span> before_backward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-147">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-148">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_backward"</span>)</span>
<span id="cb2-149">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-150">            </span>
<span id="cb2-151">    <span class="kw" style="color: #003B4F;">def</span> after_backward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-152">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-153">            <span class="co" style="color: #5E5E5E;"># Log gradient dtypes as before</span></span>
<span id="cb2-154">            <span class="va" style="color: #111111;">self</span>._log_gradient_dtypes(state, <span class="st" style="color: #20794D;">"after_backward"</span>)</span>
<span id="cb2-155">            </span>
<span id="cb2-156">            <span class="co" style="color: #5E5E5E;"># Track weight dtypes before optimizer step</span></span>
<span id="cb2-157">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_optim_step"</span>)</span>
<span id="cb2-158">            </span>
<span id="cb2-159">            <span class="co" style="color: #5E5E5E;"># Log optimizer state dtypes</span></span>
<span id="cb2-160">            <span class="va" style="color: #111111;">self</span>._log_optimizer_state_dtypes(state, <span class="st" style="color: #20794D;">"optimizer_step"</span>)</span>
<span id="cb2-161">            </span>
<span id="cb2-162">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-163">                    </span>
<span id="cb2-164">    <span class="kw" style="color: #003B4F;">def</span> batch_end(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-165">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-166">            <span class="co" style="color: #5E5E5E;"># Track weight dtypes after optimizer step to detect precision changes</span></span>
<span id="cb2-167">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"after_optim_step"</span>)</span>
<span id="cb2-168">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-169"></span>
<span id="cb2-170">    <span class="kw" style="color: #003B4F;">def</span> epoch_end(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-171">        <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"epoch_end"</span>)</span>
<span id="cb2-172">        <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-173">        </span>
<span id="cb2-174">    <span class="kw" style="color: #003B4F;">def</span> _log_model_weight_dtypes(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-175">        model <span class="op" style="color: #5E5E5E;">=</span> state.model</span>
<span id="cb2-176">        <span class="cf" style="color: #003B4F;">for</span> name, param <span class="kw" style="color: #003B4F;">in</span> model.named_parameters():</span>
<span id="cb2-177">            name <span class="op" style="color: #5E5E5E;">=</span> name.removeprefix(<span class="st" style="color: #20794D;">"model.base_model.model.model."</span>)</span>
<span id="cb2-178">            <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:weights"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(param.dtype)</span>
<span id="cb2-179"></span>
<span id="cb2-180">    <span class="kw" style="color: #003B4F;">def</span> _log_gradient_dtypes(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-181">        model <span class="op" style="color: #5E5E5E;">=</span> state.model</span>
<span id="cb2-182">        <span class="cf" style="color: #003B4F;">for</span> name, param <span class="kw" style="color: #003B4F;">in</span> model.named_parameters():</span>
<span id="cb2-183">            name <span class="op" style="color: #5E5E5E;">=</span> name.removeprefix(<span class="st" style="color: #20794D;">"model.base_model.model.model."</span>)</span>
<span id="cb2-184">            <span class="cf" style="color: #003B4F;">if</span> param.grad <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>: <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">'log'</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:gradients"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(param.grad.dtype)</span>
<span id="cb2-185">            <span class="cf" style="color: #003B4F;">else</span>: <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">'log'</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:gradients"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"None"</span></span>
<span id="cb2-186">    </span>
<span id="cb2-187">    <span class="kw" style="color: #003B4F;">def</span> _log_loss_dtype(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-188">        <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(state, <span class="st" style="color: #20794D;">'loss'</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">hasattr</span>(state.loss, <span class="st" style="color: #20794D;">'dtype'</span>):</span>
<span id="cb2-189">            <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:loss"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(state.loss.dtype)</span>
<span id="cb2-190">            </span>
<span id="cb2-191">    <span class="kw" style="color: #003B4F;">def</span> _log_optimizer_state_dtypes(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-192">        <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(state, <span class="st" style="color: #20794D;">'optimizers'</span>) <span class="kw" style="color: #003B4F;">and</span> state.optimizers <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-193">            <span class="co" style="color: #5E5E5E;"># Handle single optimizer or list of optimizers</span></span>
<span id="cb2-194">            optimizers <span class="op" style="color: #5E5E5E;">=</span> state.optimizers <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(state.optimizers, <span class="bu" style="color: null;">list</span>) <span class="cf" style="color: #003B4F;">else</span> [state.optimizers]</span>
<span id="cb2-195">            </span>
<span id="cb2-196">            <span class="cf" style="color: #003B4F;">for</span> opt_idx, optimizer <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(optimizers):</span>
<span id="cb2-197">                <span class="co" style="color: #5E5E5E;"># Get optimizer state dict</span></span>
<span id="cb2-198">                opt_state <span class="op" style="color: #5E5E5E;">=</span> optimizer.state_dict()</span>
<span id="cb2-199">                </span>
<span id="cb2-200">                <span class="co" style="color: #5E5E5E;"># Check if 'state' exists in the optimizer state dict</span></span>
<span id="cb2-201">                <span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'state'</span> <span class="kw" style="color: #003B4F;">in</span> opt_state:</span>
<span id="cb2-202">                    <span class="cf" style="color: #003B4F;">for</span> param_id, param_state <span class="kw" style="color: #003B4F;">in</span> opt_state[<span class="st" style="color: #20794D;">'state'</span>].items():</span>
<span id="cb2-203">                        <span class="cf" style="color: #003B4F;">for</span> state_name, state_value <span class="kw" style="color: #003B4F;">in</span> param_state.items():</span>
<span id="cb2-204">                            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(state_value, torch.Tensor):</span>
<span id="cb2-205">                                <span class="co" style="color: #5E5E5E;"># Store dtype of optimizer state tensors (momentum buffers, etc.)</span></span>
<span id="cb2-206">                                key <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f"optimizer_</span><span class="sc" style="color: #5E5E5E;">{</span>opt_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_param_</span><span class="sc" style="color: #5E5E5E;">{</span>param_id<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_</span><span class="sc" style="color: #5E5E5E;">{</span>state_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span></span>
<span id="cb2-207">                                <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>key<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:optimizer_states"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(state_value.dtype)</span>
<span id="cb2-208">            </span>
<span id="cb2-209">    <span class="kw" style="color: #003B4F;">def</span> _save_logs(<span class="va" style="color: #111111;">self</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-210">        os.makedirs(<span class="va" style="color: #111111;">self</span>.save_path, exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-211">        log_file <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">/</span> <span class="st" style="color: #20794D;">"dtype_logs.json"</span></span>
<span id="cb2-212">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(log_file, <span class="st" style="color: #20794D;">'w'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb2-213">            json.dump(<span class="va" style="color: #111111;">self</span>.dtype_logs, f, indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<p>The most involved event handler is <code>before_forward</code> which involves creating a hook function (<code>hook_fn</code>) passed to PyTorch’s <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_forward_hook"><code>register_forward_hook</code></a> which exposes the positional inputs and outputs of a module’s <code>forward</code> pass. The hook function modifies <code>self.dtype_logs</code> directly by storing the data type string of inputs and outputs. <code>hook_fn</code> is used for all modules except self attention.</p>
<p>Self attention <a href="https://github.com/huggingface/transformers/issues/29247#issuecomment-1965894085">cannot utilize <code>register_forward_hook</code></a> because the <a href="https://github.com/huggingface/transformers/blob/bf41e54fc8242dafa31bf6203e3d505bcb907119/src/transformers/models/llama/modeling_llama.py#L345">LlamaDecoderLayer</a> does not call self attention forward pass with any positional arguments:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">hidden_states, self_attn_weights <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.self_attn(</span>
<span id="cb3-2">    hidden_states<span class="op" style="color: #5E5E5E;">=</span>hidden_states,</span>
<span id="cb3-3">    attention_mask<span class="op" style="color: #5E5E5E;">=</span>attention_mask,</span>
<span id="cb3-4">    position_ids<span class="op" style="color: #5E5E5E;">=</span>position_ids,</span>
<span id="cb3-5">    past_key_value<span class="op" style="color: #5E5E5E;">=</span>past_key_value,</span>
<span id="cb3-6">    output_attentions<span class="op" style="color: #5E5E5E;">=</span>output_attentions,</span>
<span id="cb3-7">    use_cache<span class="op" style="color: #5E5E5E;">=</span>use_cache,</span>
<span id="cb3-8">    cache_position<span class="op" style="color: #5E5E5E;">=</span>cache_position,</span>
<span id="cb3-9">    position_embeddings<span class="op" style="color: #5E5E5E;">=</span>position_embeddings,</span>
<span id="cb3-10">    <span class="op" style="color: #5E5E5E;">**</span>kwargs,</span>
<span id="cb3-11">)</span></code></pre></div>
<p>Contrast this with how the forward pass of other modules are called with positional arguments only:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># self attention sublayers</span></span>
<span id="cb4-2">query_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.q_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb4-3">key_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.k_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb4-4">value_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.v_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb4-5">attn_output <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.o_proj(attn_output)</span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;"># mlp sublayers</span></span>
<span id="cb4-8">down_proj <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.down_proj(<span class="va" style="color: #111111;">self</span>.act_fn(<span class="va" style="color: #111111;">self</span>.gate_proj(x)) <span class="op" style="color: #5E5E5E;">*</span> <span class="va" style="color: #111111;">self</span>.up_proj(x))</span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;"># non-self attention modules</span></span>
<span id="cb4-11">hidden_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.input_layernorm(hidden_states)</span>
<span id="cb4-12">hidden_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.post_attention_layernorm(hidden_states)</span>
<span id="cb4-13">hidden_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.mlp(hidden_states)</span>
<span id="cb4-14">hidden_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.norm(hidden_states)</span></code></pre></div>
<p>Since self-attention inputs can’t be captured by a hook I had to monkey patch its forward pass to log its inputs’ data type:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="cf" style="color: #003B4F;">for</span> layer_idx, layer <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(transformer_model.layers):</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;"># Store the original forward method</span></span>
<span id="cb5-3">    original_forward <span class="op" style="color: #5E5E5E;">=</span> layer.self_attn.forward</span>
<span id="cb5-4">    <span class="va" style="color: #111111;">self</span>.original_forward_methods[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> original_forward</span>
<span id="cb5-5">    </span>
<span id="cb5-6">    <span class="co" style="color: #5E5E5E;"># Define a closure to capture the current layer_idx</span></span>
<span id="cb5-7">    <span class="kw" style="color: #003B4F;">def</span> make_patched_forward(layer_idx, orig_forward):</span>
<span id="cb5-8">        <span class="kw" style="color: #003B4F;">def</span> patched_forward(self_attn, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb5-9">            <span class="co" style="color: #5E5E5E;"># Log the hidden_states dtype</span></span>
<span id="cb5-10">            <span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'hidden_states'</span> <span class="kw" style="color: #003B4F;">in</span> kwargs <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">hasattr</span>(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>], <span class="st" style="color: #20794D;">'dtype'</span>):</span>
<span id="cb5-11">                <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:self_attn:layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_input"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>].dtype)</span>
<span id="cb5-12">            </span>
<span id="cb5-13">            <span class="co" style="color: #5E5E5E;"># Call the original method as a bound method</span></span>
<span id="cb5-14">            <span class="co" style="color: #5E5E5E;"># This ensures 'self_attn' is correctly passed as 'self'</span></span>
<span id="cb5-15">            <span class="cf" style="color: #003B4F;">return</span> orig_forward.<span class="fu" style="color: #4758AB;">__get__</span>(self_attn, <span class="bu" style="color: null;">type</span>(self_attn))(<span class="op" style="color: #5E5E5E;">**</span>kwargs)</span>
<span id="cb5-16">        </span>
<span id="cb5-17">        <span class="cf" style="color: #003B4F;">return</span> patched_forward</span>
<span id="cb5-18"></span>
<span id="cb5-19">    <span class="co" style="color: #5E5E5E;"># Replace the forward method</span></span>
<span id="cb5-20">    layer.self_attn.forward <span class="op" style="color: #5E5E5E;">=</span> make_patched_forward(layer_idx, original_forward).<span class="fu" style="color: #4758AB;">__get__</span>(layer.self_attn, <span class="bu" style="color: null;">type</span>(layer.self_attn))</span></code></pre></div>
<p><code>patched_forward</code> receives positional arguments <code>*args</code> (of which there are none) and keyword arguments <code>**kwargs</code> (all of the arguments to the self-attention forward) and logs the data types of the inputs to self-attention (<code>hidden_states</code>) as <code>self_attn_input</code> before returning the outputs of the original forward pass.</p>
<p>A key line is <code>orig_forward.__get__(self_attn, type(self_attn))(**kwargs)</code>. As Claude’s comment mentions, this is to avoid using <code>orig_forward(self_attn, **kwargs)</code> which was causing the following error because the first argument, <code>self_attn</code>, was being interpreted as <code>hidden_states</code> whereas it was intended to represent <code>self</code>:</p>
<pre><code>TypeError: LlamaFlashAttention2.forward() got multiple values for argument 'hidden_states'</code></pre>
<p>In short, when you call <code>__get__(obj, type)</code> on a function it will bind that function as a method to the given object, thus no longer requiring you to pass in <code>self</code> as an argument. This is critical because <code>self_attn.forward</code> <em>has no positional arguments</em>. We can then pass in the keyword arguments to the bound method <code>orig_forward.__get__(self_attn, type(self_attn))(**kwargs)</code>, and let the model continue using self-attention correctly. See the <a href="https://docs.python.org/3/howto/descriptor.html#functions-and-methods:~:text=To%20recap%2C%20functions%20have%20a%20__get__()%20method%20so%20that%20they%20can%20be%20converted%20to%20a%20method%20when%20accessed%20as%20attributes.%20The%20non%2Ddata%20descriptor%20transforms%20an%20obj.f(*args)%20call%20into%20f(obj%2C%20*args).%20Calling%20cls.f(*args)%20becomes%20f(*args).">Descriptor Guide in the Python docs</a> for more information.</p>
</section>
<section id="helper-functions" class="level2">
<h2 class="anchored" data-anchor-id="helper-functions">Helper Functions</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;">import</span> re</span>
<span id="cb7-2"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb7-3"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb7-4"><span class="im" style="color: #00769E;">import</span> requests</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;">def</span> parse_index(string):</span>
<span id="cb8-2">    <span class="co" style="color: #5E5E5E;">"""Extract structured information from parameter names"""</span></span>
<span id="cb8-3">    info <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb8-4">        <span class="st" style="color: #20794D;">'layer_number'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-5">        <span class="st" style="color: #20794D;">'module'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-6">        <span class="st" style="color: #20794D;">'layer_name'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-7">        <span class="st" style="color: #20794D;">'lora_layer'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-8">        <span class="st" style="color: #20794D;">'training_step'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-9">        <span class="st" style="color: #20794D;">'entity'</span>: <span class="va" style="color: #111111;">None</span></span>
<span id="cb8-10">    }</span>
<span id="cb8-11"></span>
<span id="cb8-12">    <span class="co" style="color: #5E5E5E;"># layer = string.split(":")[1]</span></span>
<span id="cb8-13">    <span class="co" style="color: #5E5E5E;"># info["layer"] = layer</span></span>
<span id="cb8-14"></span>
<span id="cb8-15">    layer_number_match <span class="op" style="color: #5E5E5E;">=</span> re.search(<span class="vs" style="color: #20794D;">r'layers\.(\d+)'</span>, string)</span>
<span id="cb8-16">    <span class="cf" style="color: #003B4F;">if</span> layer_number_match: info[<span class="st" style="color: #20794D;">'layer_number'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(layer_number_match.group(<span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb8-17"></span>
<span id="cb8-18">    modules <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb8-19">        <span class="st" style="color: #20794D;">"embed_tokens"</span>,</span>
<span id="cb8-20">        <span class="st" style="color: #20794D;">"input_layernorm"</span>,</span>
<span id="cb8-21">        <span class="st" style="color: #20794D;">"self_attn"</span>,</span>
<span id="cb8-22">        <span class="st" style="color: #20794D;">"post_attention_layernorm"</span>,</span>
<span id="cb8-23">        <span class="st" style="color: #20794D;">"mlp"</span>,</span>
<span id="cb8-24">        <span class="st" style="color: #20794D;">"norm"</span>,</span>
<span id="cb8-25">        <span class="st" style="color: #20794D;">"lm_head"</span></span>
<span id="cb8-26">    ]</span>
<span id="cb8-27"></span>
<span id="cb8-28">    module_match <span class="op" style="color: #5E5E5E;">=</span> re.search(<span class="vs" style="color: #20794D;">r'(mlp|self_attn|input_layernorm|post_attention_layernorm|embed_tokens|norm|lm_head)'</span>, string)</span>
<span id="cb8-29">    <span class="cf" style="color: #003B4F;">if</span> module_match: info[<span class="st" style="color: #20794D;">'module'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(modules.index(module_match.group(<span class="dv" style="color: #AD0000;">1</span>))).zfill(<span class="dv" style="color: #AD0000;">2</span>) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'_'</span> <span class="op" style="color: #5E5E5E;">+</span> module_match.group(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb8-30"></span>
<span id="cb8-31">    layer_name_match <span class="op" style="color: #5E5E5E;">=</span> re.search(<span class="vs" style="color: #20794D;">r'(q_proj|k_proj|v_proj|o_proj|gate_proj|up_proj|down_proj)'</span>, string)</span>
<span id="cb8-32">    <span class="cf" style="color: #003B4F;">if</span> layer_name_match: info[<span class="st" style="color: #20794D;">'layer_name'</span>] <span class="op" style="color: #5E5E5E;">=</span> layer_name_match.group(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb8-33"></span>
<span id="cb8-34">    lora_match <span class="op" style="color: #5E5E5E;">=</span> re.search(<span class="vs" style="color: #20794D;">r'(base_layer|lora_A|lora_B)'</span>, string)</span>
<span id="cb8-35">    <span class="cf" style="color: #003B4F;">if</span> lora_match: info[<span class="st" style="color: #20794D;">'lora_layer'</span>] <span class="op" style="color: #5E5E5E;">=</span> lora_match.group(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb8-36">    <span class="cf" style="color: #003B4F;">else</span>: info[<span class="st" style="color: #20794D;">'lora_layer'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Not a LoRA Layer"</span></span>
<span id="cb8-37"></span>
<span id="cb8-38">    training_steps <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb8-39">        <span class="st" style="color: #20794D;">"fit_start"</span>,</span>
<span id="cb8-40">        <span class="st" style="color: #20794D;">"epoch_start"</span>,</span>
<span id="cb8-41">        <span class="st" style="color: #20794D;">"before_dataloader"</span>,</span>
<span id="cb8-42">        <span class="st" style="color: #20794D;">"after_dataloader"</span>,</span>
<span id="cb8-43">        <span class="st" style="color: #20794D;">"batch_start"</span>,</span>
<span id="cb8-44">        <span class="st" style="color: #20794D;">"before_forward"</span>,</span>
<span id="cb8-45">        <span class="st" style="color: #20794D;">"forward"</span>,</span>
<span id="cb8-46">        <span class="st" style="color: #20794D;">"after_forward"</span>,</span>
<span id="cb8-47">        <span class="st" style="color: #20794D;">"before_loss"</span>,</span>
<span id="cb8-48">        <span class="st" style="color: #20794D;">"after_loss"</span>,</span>
<span id="cb8-49">        <span class="st" style="color: #20794D;">"before_backward"</span>,</span>
<span id="cb8-50">        <span class="st" style="color: #20794D;">"after_backward"</span>,</span>
<span id="cb8-51">        <span class="st" style="color: #20794D;">"before_optim_step"</span>,</span>
<span id="cb8-52">        <span class="st" style="color: #20794D;">"optimizer_step"</span>,</span>
<span id="cb8-53">        <span class="st" style="color: #20794D;">"after_optim_step"</span></span>
<span id="cb8-54">        ]</span>
<span id="cb8-55"></span>
<span id="cb8-56">    training_step <span class="op" style="color: #5E5E5E;">=</span> string.split(<span class="st" style="color: #20794D;">":"</span>)[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb8-57">    info[<span class="st" style="color: #20794D;">'training_step'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(training_steps.index(training_step)).zfill(<span class="dv" style="color: #AD0000;">2</span>) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'_'</span> <span class="op" style="color: #5E5E5E;">+</span> training_step</span>
<span id="cb8-58"></span>
<span id="cb8-59">    info[<span class="st" style="color: #20794D;">'entity'</span>] <span class="op" style="color: #5E5E5E;">=</span> string.split(<span class="st" style="color: #20794D;">":"</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb8-60"></span>
<span id="cb8-61"></span>
<span id="cb8-62">    <span class="cf" style="color: #003B4F;">return</span> info</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;">def</span> _df(url):</span>
<span id="cb9-2">    dtype_data <span class="op" style="color: #5E5E5E;">=</span> json.loads(requests.get(url).text)</span>
<span id="cb9-3"></span>
<span id="cb9-4">    df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(dtype_data).reset_index()</span>
<span id="cb9-5">    df <span class="op" style="color: #5E5E5E;">=</span> df.rename(columns<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">"index"</span>: <span class="st" style="color: #20794D;">"index"</span>, <span class="st" style="color: #20794D;">"log"</span>: <span class="st" style="color: #20794D;">"dtype"</span>})</span>
<span id="cb9-6"></span>
<span id="cb9-7">    parsed_info <span class="op" style="color: #5E5E5E;">=</span> df[<span class="st" style="color: #20794D;">'index'</span>].<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: parse_index(x))</span>
<span id="cb9-8"></span>
<span id="cb9-9">    df[<span class="st" style="color: #20794D;">'layer_number'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'layer_number'</span>])</span>
<span id="cb9-10">    df[<span class="st" style="color: #20794D;">'module'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'module'</span>])</span>
<span id="cb9-11">    df[<span class="st" style="color: #20794D;">'layer_name'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'layer_name'</span>])</span>
<span id="cb9-12">    df[<span class="st" style="color: #20794D;">'lora_layer'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'lora_layer'</span>])</span>
<span id="cb9-13">    df[<span class="st" style="color: #20794D;">'training_step'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'training_step'</span>])</span>
<span id="cb9-14">    df[<span class="st" style="color: #20794D;">'entity'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'entity'</span>])</span>
<span id="cb9-15"></span>
<span id="cb9-16">    <span class="cf" style="color: #003B4F;">return</span> df</span></code></pre></div>
</div>
</section>
<section id="model-in-fp32-master_weights_dtypenone" class="level2">
<h2 class="anchored" data-anchor-id="model-in-fp32-master_weights_dtypenone">Model in fp32 (<code>master_weights_dtype==None</code>)</h2>
<p>In this case, <code>master_weights_dtype</code> is not provided in the training YAML file.</p>
<div class="cell" data-outputid="73fb1c7d-f091-413b-90af-cf9fb0c6eb51" data-execution_count="5">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">url <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"https://gist.githubusercontent.com/vishalbakshi/9ade8d501629d4c30e8aecfa1c6f67cf/raw/0c162e2305002fbe57fd2570ade302c3659140a1/dtypes_logs_1ba_fp32.json"</span></span>
<span id="cb10-2">df <span class="op" style="color: #5E5E5E;">=</span> _df(url)</span>
<span id="cb10-3">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">


  <div id="df-f6bb70e8-9110-47f0-85d1-46d907c311a6" class="colab-df-container">
    <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>index</th>
      <th>dtype</th>
      <th>layer_number</th>
      <th>module</th>
      <th>layer_name</th>
      <th>lora_layer</th>
      <th>training_step</th>
      <th>entity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>fit_start:embed_tokens.weight:weights</td>
      <td>torch.float32</td>
      <td>NaN</td>
      <td>00_embed_tokens</td>
      <td>None</td>
      <td>Not a LoRA Layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fit_start:layers.0.self_attn.q_proj.base_layer...</td>
      <td>torch.float32</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>base_layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fit_start:layers.0.self_attn.q_proj.lora_A.def...</td>
      <td>torch.float32</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>lora_A</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fit_start:layers.0.self_attn.q_proj.lora_B.def...</td>
      <td>torch.float32</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>lora_B</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>4</th>
      <td>fit_start:layers.0.self_attn.k_proj.base_layer...</td>
      <td>torch.float32</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>k_proj</td>
      <td>base_layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-f6bb70e8-9110-47f0-85d1-46d907c311a6')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-f6bb70e8-9110-47f0-85d1-46d907c311a6 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-f6bb70e8-9110-47f0-85d1-46d907c311a6');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-b878e7a4-6a3d-484e-8565-4873e2d61a8a">
  <button class="colab-df-quickchart" onclick="quickchart('df-b878e7a4-6a3d-484e-8565-4873e2d61a8a')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-b878e7a4-6a3d-484e-8565-4873e2d61a8a button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<section id="data-types-by-lora_layer" class="level3">
<h3 class="anchored" data-anchor-id="data-types-by-lora_layer">Data Types by <code>lora_layer</code></h3>
<p>All LoRA layer entities are in fp32.</p>
<div class="cell" data-outputid="d3494bca-3fbd-4a42-ae1b-5087d3ef6618" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">df.groupby([<span class="st" style="color: #20794D;">'lora_layer'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>lora_layer</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="4" valign="top">Not a LoRA Layer</th>
      <th>None</th>
      <td>62</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>331</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>2339</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">base_layer</th>
      <th>None</th>
      <td>210</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>2520</td>
    </tr>
    <tr>
      <th>lora_A</th>
      <th>torch.float32</th>
      <td>2730</td>
    </tr>
    <tr>
      <th>lora_B</th>
      <th>torch.float32</th>
      <td>2730</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
<section id="data-types-by-entity-activations-gradients-loss-optimizer-states-and-weights" class="level3">
<h3 class="anchored" data-anchor-id="data-types-by-entity-activations-gradients-loss-optimizer-states-and-weights">Data Types by <code>entity</code> (Activations, Gradients, Loss, Optimizer States and Weights)</h3>
<p>Every entity except activations are in fp32. Some parameters don’t have gradients because we are training with LoRA.</p>
<div class="cell" data-outputid="78343b50-69b7-4e1e-f2eb-58f2a3fbc781" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">df.groupby([<span class="st" style="color: #20794D;">'entity'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>entity</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">activation_input</th>
      <th>torch.bfloat16</th>
      <td>60</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">activation_output</th>
      <th>torch.bfloat16</th>
      <td>271</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>62</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">gradients</th>
      <th>None</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>420</td>
    </tr>
    <tr>
      <th>loss</th>
      <th>torch.float32</th>
      <td>1</td>
    </tr>
    <tr>
      <th>optimizer_states</th>
      <th>torch.float32</th>
      <td>1260</td>
    </tr>
    <tr>
      <th>weights</th>
      <th>torch.float32</th>
      <td>8304</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
<section id="data-types-by-composer-training-step" class="level3">
<h3 class="anchored" data-anchor-id="data-types-by-composer-training-step">Data Types by Composer Training Step</h3>
<div class="cell" data-outputid="98def9cf-d2c3-4003-a11c-1293b9879460" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">df.groupby([<span class="st" style="color: #20794D;">'training_step'</span>, <span class="st" style="color: #20794D;">'entity'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>training_step</th>
      <th>entity</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>00_fit_start</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>01_epoch_start</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>02_before_dataloader</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>03_after_dataloader</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>04_batch_start</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>05_before_forward</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">06_forward</th>
      <th rowspan="3" valign="top">activation_input</th>
      <th>torch.bfloat16</th>
      <td>60</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">activation_output</th>
      <th>torch.bfloat16</th>
      <td>271</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>62</td>
    </tr>
    <tr>
      <th>07_after_forward</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>08_before_loss</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">09_after_loss</th>
      <th>loss</th>
      <th>torch.float32</th>
      <td>1</td>
    </tr>
    <tr>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>10_before_backward</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">11_after_backward</th>
      <th rowspan="2" valign="top">gradients</th>
      <th>None</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>420</td>
    </tr>
    <tr>
      <th>12_before_optim_step</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>13_optimizer_step</th>
      <th>optimizer_states</th>
      <th>torch.float32</th>
      <td>1260</td>
    </tr>
    <tr>
      <th>14_after_optim_step</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
</section>
<section id="model-in-bf16-master_weights_dtypebfloat16" class="level2">
<h2 class="anchored" data-anchor-id="model-in-bf16-master_weights_dtypebfloat16">Model in bf16 (<code>master_weights_dtype==bfloat16</code>)</h2>
<p>I also logged data types after setting <code>master_weights_dtype</code> in the training YAML to <code>bfloat16</code>.</p>
<div class="cell" data-outputid="5b638922-40c0-42a9-9c0e-8b907d105abd" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">url <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"https://gist.githubusercontent.com/vishalbakshi/ec91a59754633611fd8eb33b59031243/raw/5b83a7ebd5759cf6bd2db2369edf1c73e1fb67cf/dtypes_logs_1ba_bf16.json"</span></span>
<span id="cb14-2">df <span class="op" style="color: #5E5E5E;">=</span> _df(url)</span>
<span id="cb14-3">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">


  <div id="df-6f3e8532-20df-451d-8e93-caa52d279f3f" class="colab-df-container">
    <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>index</th>
      <th>dtype</th>
      <th>layer_number</th>
      <th>module</th>
      <th>layer_name</th>
      <th>lora_layer</th>
      <th>training_step</th>
      <th>entity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>fit_start:embed_tokens.weight:weights</td>
      <td>torch.bfloat16</td>
      <td>NaN</td>
      <td>00_embed_tokens</td>
      <td>None</td>
      <td>Not a LoRA Layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fit_start:layers.0.self_attn.q_proj.base_layer...</td>
      <td>torch.bfloat16</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>base_layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fit_start:layers.0.self_attn.q_proj.lora_A.def...</td>
      <td>torch.bfloat16</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>lora_A</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fit_start:layers.0.self_attn.q_proj.lora_B.def...</td>
      <td>torch.bfloat16</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>lora_B</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>4</th>
      <td>fit_start:layers.0.self_attn.k_proj.base_layer...</td>
      <td>torch.bfloat16</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>k_proj</td>
      <td>base_layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-6f3e8532-20df-451d-8e93-caa52d279f3f')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-6f3e8532-20df-451d-8e93-caa52d279f3f button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-6f3e8532-20df-451d-8e93-caa52d279f3f');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-159646a6-3c88-49de-8770-5f4464ad1b49">
  <button class="colab-df-quickchart" onclick="quickchart('df-159646a6-3c88-49de-8770-5f4464ad1b49')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-159646a6-3c88-49de-8770-5f4464ad1b49 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<section id="data-type-by-lora_layer" class="level3">
<h3 class="anchored" data-anchor-id="data-type-by-lora_layer">Data Type by <code>lora_layer</code></h3>
<p>Interestingly, setting <code>master_weights_dtype</code> makes all LoRA layers bfloat16 but some non-LoRA layers’ entities are still in fp32.</p>
<div class="cell" data-outputid="b18ff791-dbf5-40a8-fcfe-402ed510d645" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">df.groupby([<span class="st" style="color: #20794D;">'lora_layer'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>lora_layer</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="4" valign="top">Not a LoRA Layer</th>
      <th>None</th>
      <td>62</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>2249</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>421</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">base_layer</th>
      <th>None</th>
      <td>210</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>2520</td>
    </tr>
    <tr>
      <th>lora_A</th>
      <th>torch.bfloat16</th>
      <td>2730</td>
    </tr>
    <tr>
      <th>lora_B</th>
      <th>torch.bfloat16</th>
      <td>2730</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
<section id="data-types-by-entity-activations-gradients-loss-optimizer-states-and-weights-1" class="level3">
<h3 class="anchored" data-anchor-id="data-types-by-entity-activations-gradients-loss-optimizer-states-and-weights-1">Data Types by <code>entity</code> (Activations, Gradients, Loss, Optimizer States and Weights)</h3>
<p>All floating point values are in bfloat16 except for the loss and some of the optimizer states. I’m not sure why some optimizer states are in bf16, even though it says in the <a href="https://docs.mosaicml.com/projects/composer/en/latest/notes/numerics.html#automatic-mixed-precision-amp-training">Composer docs</a>:</p>
<blockquote class="blockquote">
<p>Store the weights and perform the optimizer step in single precision, enabling the weight update to be done more precisely.</p>
</blockquote>
<div class="cell" data-outputid="17283b63-7034-448d-f2a6-b51857b9d320" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">df.groupby([<span class="st" style="color: #20794D;">'entity'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>entity</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">activation_input</th>
      <th>torch.bfloat16</th>
      <td>332</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th>activation_output</th>
      <th>torch.bfloat16</th>
      <td>333</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">gradients</th>
      <th>None</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>420</td>
    </tr>
    <tr>
      <th>loss</th>
      <th>torch.float32</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">optimizer_states</th>
      <th>torch.bfloat16</th>
      <td>840</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>420</td>
    </tr>
    <tr>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>8304</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
<section id="data-type-by-composer-training-step" class="level3">
<h3 class="anchored" data-anchor-id="data-type-by-composer-training-step">Data Type by Composer Training Step</h3>
<div class="cell" data-outputid="168d15bc-1303-40c0-cc01-7a529ed5cb5d" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">df.groupby([<span class="st" style="color: #20794D;">'training_step'</span>, <span class="st" style="color: #20794D;">'entity'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>training_step</th>
      <th>entity</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>00_fit_start</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>01_epoch_start</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>02_before_dataloader</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>03_after_dataloader</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>04_batch_start</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>05_before_forward</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">06_forward</th>
      <th rowspan="2" valign="top">activation_input</th>
      <th>torch.bfloat16</th>
      <td>332</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th>activation_output</th>
      <th>torch.bfloat16</th>
      <td>333</td>
    </tr>
    <tr>
      <th>07_after_forward</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>08_before_loss</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">09_after_loss</th>
      <th>loss</th>
      <th>torch.float32</th>
      <td>1</td>
    </tr>
    <tr>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>10_before_backward</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">11_after_backward</th>
      <th rowspan="2" valign="top">gradients</th>
      <th>None</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>420</td>
    </tr>
    <tr>
      <th>12_before_optim_step</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">13_optimizer_step</th>
      <th rowspan="2" valign="top">optimizer_states</th>
      <th>torch.bfloat16</th>
      <td>840</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>420</td>
    </tr>
    <tr>
      <th>14_after_optim_step</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>I absolutely loved this exercise. I learned a ton about callbacks, data types during mixed precision training, and Python fundamentals. Working with LLM-Foundry has opened up a whole universe of learning opportunities as I try to better understand what’s going on under the hood. It’s a gift that keeps giving!</p>
<p>I’m trying to grow <a href="https://www.youtube.com/@vishal_learner">my YouTube channel</a> so please give it a visit and subscribe if you want to stay in the loop.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-02-Composer-Callback-Logging-dtypes/index.html</guid>
  <pubDate>Wed, 02 Apr 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Understanding Python Descriptors</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-01-Python-Descriptor/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>When monkey-patching the Llama self-attention forward pass (to log its inputs’ data type) I was vibe coding with Claude and it generated the following line to pass the necessary arguments to the original forward pass of the module:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">orig_forward.<span class="fu" style="color: #4758AB;">__get__</span>(self_attn, <span class="bu" style="color: null;">type</span>(self_attn))(<span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
<p>In a prior iteration, I was using the following line suggested by Claude, with the intention of passing <code>self_attn</code> as <code>self</code>:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">orig_forward(self_attn, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
<p>This was essentially doing the following:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">orig_forward(self_attn, hidden_states<span class="op" style="color: #5E5E5E;">=</span>hidden_states, attention_mask<span class="op" style="color: #5E5E5E;">=</span>attention_mask, ...)</span></code></pre></div>
<p>Which caused the following error:</p>
<pre><code>TypeError: LlamaFlashAttention2.forward() got multiple values for argument 'hidden_states'</code></pre>
<p><code>self_attn</code> was being passed as the argument to the <code>hidden_states</code> parameter, and then <code>hidden_states=hidden_states</code> was again assigning an argument to the <code>hidden_states</code> parameter. So how do we pass <code>self_attn</code> as <code>self</code>? This is where the <code>__get__</code> method comes in which is part of the Python <a href="https://docs.python.org/3/glossary.html#term-descriptor">Descriptor</a>. Descriptors are:</p>
<blockquote class="blockquote">
<p>Any object which defines the methods <code>__get__()</code>, <code>__set__()</code>, or <code>__delete__()</code>. When a class attribute is a descriptor, its special binding behavior is triggered upon attribute lookup. Normally, using <em>a.b</em> to get, set or delete an attribute looks up the object named <em>b</em> in the class dictionary for <em>a</em>, but if <em>b</em> is a descriptor, the respective descriptor method gets called. Understanding descriptors is a key to a deep understanding of Python because they are the basis for many features including functions, methods, properties, class methods, static methods, and reference to super classes.</p>
</blockquote>
<p>After reading that a few times I still didn’t understand it! Though I think the key is:</p>
<blockquote class="blockquote">
<p>When a class attribute is a descriptor, its special binding behavior is triggered upon attribute lookup.</p>
</blockquote>
<p>Claude explained it this way:</p>
<blockquote class="blockquote">
<p><code>__get__</code> is a special method that converts a function into a bound method. It’s like saying “make this function a method of this object.”</p>
</blockquote>
<p>Translating that to my use case: <code>__get__</code> makes <code>orig_forward</code> a method of <code>self_attn</code>, no longer requiring us to pass <code>self_attn</code> as it now is <code>self</code>.</p>
<p>That certainly makes sense (i.e.&nbsp;I understand those words) but I don’t really understand why or how. That led me to the Python documentation’s <a href="https://docs.python.org/3/howto/descriptor.html#id1">Descriptor Guide</a> which I’ll walk through here.</p>
<p>(There was also this interesting <a href="https://discuss.python.org/t/changing-the-name-of-get-to-bind/14243">discussion</a> about changing the name to <code>__bind__</code> when calling it on a function as it binds the function as a method of the given object, which we’ll see later on).</p>
</section>
<section id="primer" class="level2">
<h2 class="anchored" data-anchor-id="primer">Primer</h2>
<section id="simple-example-a-descriptor-that-returns-a-constant" class="level3">
<h3 class="anchored" data-anchor-id="simple-example-a-descriptor-that-returns-a-constant">Simple example: A descriptor that returns a constant</h3>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;">class</span> Ten:</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb5-3">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">10</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="eeac4968-a49d-4411-c5f6-3231b2ff396c" data-execution_count="18">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">t <span class="op" style="color: #5E5E5E;">=</span> Ten()</span>
<span id="cb6-2">t</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>&lt;__main__.Ten at 0x78b2fd072c50&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="3c8c18b5-e974-4c71-90cd-bed54365c3f9" data-execution_count="19">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="bu" style="color: null;">type</span>(t)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>__main__.Ten</code></pre>
</div>
</div>
<div class="cell" data-outputid="6af99ff9-5bb6-4561-b5df-af18e218253f" data-execution_count="20">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">t.<span class="fu" style="color: #4758AB;">__get__</span>(<span class="dv" style="color: #AD0000;">4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>10</code></pre>
</div>
</div>
<p>I think the only reason <code>Ten</code> is a descriptor is because it “defines the methods <code>__get__()</code>, <code>__set__()</code>, or <code>__delete__()</code>”.</p>
<blockquote class="blockquote">
<p>To use the descriptor, it must be stored as a class variable in another class:</p>
</blockquote>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="kw" style="color: #003B4F;">class</span> A:</span>
<span id="cb12-2">    x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span>                       <span class="co" style="color: #5E5E5E;"># Regular class attribute</span></span>
<span id="cb12-3">    y <span class="op" style="color: #5E5E5E;">=</span> Ten()                   <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="fe3fcdb4-845c-4e7e-d4aa-83f23603d858" data-execution_count="22">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">a <span class="op" style="color: #5E5E5E;">=</span> A()                     <span class="co" style="color: #5E5E5E;"># Make an instance of class A</span></span>
<span id="cb13-2">a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>&lt;__main__.A at 0x78b2fd0707d0&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="93f0602a-05b0-4a09-b674-aa00ee892704" data-execution_count="23">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">a.x                         <span class="co" style="color: #5E5E5E;"># Normal attribute lookup</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>5</code></pre>
</div>
</div>
<div class="cell" data-outputid="52372c3e-1077-4f9a-b2f8-71b3394c8b1b" data-execution_count="24">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">a.y                         <span class="co" style="color: #5E5E5E;"># Descriptor lookup</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>10</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note that the value 10 is not stored in either the class dictionary or the instance dictionary. Instead, the value 10 is computed on demand.</p>
</blockquote>
<div class="cell" data-outputid="afb4e225-ef85-4202-eb56-db22b5269554" data-execution_count="25">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">A.__dict__</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>mappingproxy({'__module__': '__main__',
              'x': 5,
              'y': &lt;__main__.Ten at 0x78b2fd0722d0&gt;,
              '__dict__': &lt;attribute '__dict__' of 'A' objects&gt;,
              '__weakref__': &lt;attribute '__weakref__' of 'A' objects&gt;,
              '__doc__': None})</code></pre>
</div>
</div>
<p>Modifying <code>Ten</code> a bit to visualize this:</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;">class</span> Ten2:</span>
<span id="cb21-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb21-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__get__ called with obj=</span><span class="sc" style="color: #5E5E5E;">{</span>obj<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, objtype=</span><span class="sc" style="color: #5E5E5E;">{</span>objtype<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb21-4">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb21-5"></span>
<span id="cb21-6"><span class="kw" style="color: #003B4F;">class</span> A2:</span>
<span id="cb21-7">    x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb21-8">    y <span class="op" style="color: #5E5E5E;">=</span> Ten2()  <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">a2 <span class="op" style="color: #5E5E5E;">=</span> A2()</span></code></pre></div>
</div>
<div class="cell" data-outputid="e528db12-faa4-463b-b3ba-71897fc0b887" data-execution_count="28">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">a2.y</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2fd089710&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>10</code></pre>
</div>
</div>
<p>Cool!</p>
</section>
<section id="dynamic-lookups" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-lookups">Dynamic Lookups</h3>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb26-2"></span>
<span id="cb26-3"><span class="kw" style="color: #003B4F;">class</span> DirectorySize:</span>
<span id="cb26-4"></span>
<span id="cb26-5">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb26-6">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">len</span>(os.listdir(obj.dirname))</span>
<span id="cb26-7"></span>
<span id="cb26-8"><span class="kw" style="color: #003B4F;">class</span> Directory:</span>
<span id="cb26-9"></span>
<span id="cb26-10">    size <span class="op" style="color: #5E5E5E;">=</span> DirectorySize()              <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span>
<span id="cb26-11"></span>
<span id="cb26-12">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, dirname):</span>
<span id="cb26-13">        <span class="va" style="color: #111111;">self</span>.dirname <span class="op" style="color: #5E5E5E;">=</span> dirname          <span class="co" style="color: #5E5E5E;"># Regular instance attribute</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">s <span class="op" style="color: #5E5E5E;">=</span> Directory(<span class="st" style="color: #20794D;">'songs'</span>)</span>
<span id="cb27-2">g <span class="op" style="color: #5E5E5E;">=</span> Directory(<span class="st" style="color: #20794D;">'games'</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="09aa2729-6427-4da8-e619-fb6ce2abd29e" data-execution_count="54">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">s.size</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>4</code></pre>
</div>
</div>
<div class="cell" data-outputid="5f1ace26-b65a-4747-dccf-150ae2da1111" data-execution_count="48">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">g.size</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>2</code></pre>
</div>
</div>
<p>Removing a file then calling the descriptor’s <code>__get__</code> dynamically calculates the new value:</p>
<div class="cell" data-outputid="0e7788d5-e734-40fc-df0c-07077782244a" data-execution_count="49">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">os.remove(<span class="st" style="color: #20794D;">'games/game1.txt'</span>)            <span class="co" style="color: #5E5E5E;"># Delete a game</span></span>
<span id="cb32-2">g.size</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>1</code></pre>
</div>
</div>
</section>
<section id="managed-attributes" class="level3">
<h3 class="anchored" data-anchor-id="managed-attributes">Managed attributes</h3>
<blockquote class="blockquote">
<p>The descriptor is assigned to a public attribute in the class dictionary while the actual data is stored as a private attribute in the instance dictionary.</p>
</blockquote>
<p>Note that I wasn’t able to see the logging output in this notebook so I’m using print statements instead.</p>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="kw" style="color: #003B4F;">class</span> LoggedAgeAccess:</span>
<span id="cb34-2"></span>
<span id="cb34-3">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb34-4">        value <span class="op" style="color: #5E5E5E;">=</span> obj._age</span>
<span id="cb34-5">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Accessing age giving </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb34-6">        <span class="cf" style="color: #003B4F;">return</span> value</span>
<span id="cb34-7"></span>
<span id="cb34-8">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__set__</span>(<span class="va" style="color: #111111;">self</span>, obj, value):</span>
<span id="cb34-9">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Updating age to </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb34-10">        obj._age <span class="op" style="color: #5E5E5E;">=</span> value</span>
<span id="cb34-11"></span>
<span id="cb34-12"><span class="kw" style="color: #003B4F;">class</span> Person:</span>
<span id="cb34-13"></span>
<span id="cb34-14">    age <span class="op" style="color: #5E5E5E;">=</span> LoggedAgeAccess()             <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span>
<span id="cb34-15"></span>
<span id="cb34-16">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, name, age):</span>
<span id="cb34-17">        <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name                <span class="co" style="color: #5E5E5E;"># Regular instance attribute</span></span>
<span id="cb34-18">        <span class="va" style="color: #111111;">self</span>.age <span class="op" style="color: #5E5E5E;">=</span> age                  <span class="co" style="color: #5E5E5E;"># Calls __set__()</span></span>
<span id="cb34-19"></span>
<span id="cb34-20">    <span class="kw" style="color: #003B4F;">def</span> birthday(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb34-21">        <span class="va" style="color: #111111;">self</span>.age <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span>                   <span class="co" style="color: #5E5E5E;"># Calls both __get__() and __set__()</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="8b75d44a-d3d3-4a0f-8b6a-b1526c61850c" data-execution_count="82">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">mary <span class="op" style="color: #5E5E5E;">=</span> Person(<span class="st" style="color: #20794D;">'Mary M'</span>, <span class="dv" style="color: #AD0000;">30</span>)         <span class="co" style="color: #5E5E5E;"># The initial age update is logged</span></span>
<span id="cb35-2">dave <span class="op" style="color: #5E5E5E;">=</span> Person(<span class="st" style="color: #20794D;">'David D'</span>, <span class="dv" style="color: #AD0000;">40</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Updating age to 30
Updating age to 40</code></pre>
</div>
</div>
<div class="cell" data-outputid="6bfbbf95-7e19-4375-e7d0-3ea569224486" data-execution_count="83">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="bu" style="color: null;">vars</span>(mary), <span class="bu" style="color: null;">vars</span>(dave)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>({'name': 'Mary M', '_age': 30}, {'name': 'David D', '_age': 40})</code></pre>
</div>
</div>
<div class="cell" data-outputid="b498be42-317d-4880-e5cd-0ec735143778" data-execution_count="84">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">mary.age</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accessing age giving 30</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>30</code></pre>
</div>
</div>
<div class="cell" data-outputid="c30f9e43-22cb-4d26-b75b-75d9c486f9b9" data-execution_count="85">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">mary.birthday()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accessing age giving 30
Updating age to 31</code></pre>
</div>
</div>
<div class="cell" data-outputid="317f28b0-1e3a-49ed-ef6b-fa6904e9c636" data-execution_count="86">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">mary.age</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accessing age giving 31</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>31</code></pre>
</div>
</div>
<div class="cell" data-outputid="805635b0-8485-4fdb-b066-60314f8ff50c" data-execution_count="87">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">dave.name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>'David D'</code></pre>
</div>
</div>
<div class="cell" data-outputid="a14b4606-f0e2-4654-956e-0b937a8bc394" data-execution_count="88">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">dave.age</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accessing age giving 40</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>40</code></pre>
</div>
</div>
</section>
<section id="customized-names" class="level3">
<h3 class="anchored" data-anchor-id="customized-names">Customized names</h3>
<blockquote class="blockquote">
<p>When a class uses descriptors, it can inform each descriptor about which variable name was used.</p>
</blockquote>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="kw" style="color: #003B4F;">class</span> LoggedAccess:</span>
<span id="cb52-2"></span>
<span id="cb52-3">    <span class="kw" style="color: #003B4F;">def</span> __set_name__(<span class="va" style="color: #111111;">self</span>, owner, name):</span>
<span id="cb52-4">        <span class="va" style="color: #111111;">self</span>.public_name <span class="op" style="color: #5E5E5E;">=</span> name</span>
<span id="cb52-5">        <span class="va" style="color: #111111;">self</span>.private_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'_'</span> <span class="op" style="color: #5E5E5E;">+</span> name</span>
<span id="cb52-6"></span>
<span id="cb52-7">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb52-8">        value <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">getattr</span>(obj, <span class="va" style="color: #111111;">self</span>.private_name)</span>
<span id="cb52-9">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Accessing </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>public_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> giving </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb52-10">        <span class="cf" style="color: #003B4F;">return</span> value</span>
<span id="cb52-11"></span>
<span id="cb52-12">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__set__</span>(<span class="va" style="color: #111111;">self</span>, obj, value):</span>
<span id="cb52-13">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Updating </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>public_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> to </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb52-14">        <span class="bu" style="color: null;">setattr</span>(obj, <span class="va" style="color: #111111;">self</span>.private_name, value)</span>
<span id="cb52-15"></span>
<span id="cb52-16"><span class="kw" style="color: #003B4F;">class</span> Person:</span>
<span id="cb52-17"></span>
<span id="cb52-18">    name <span class="op" style="color: #5E5E5E;">=</span> LoggedAccess()                <span class="co" style="color: #5E5E5E;"># First descriptor instance</span></span>
<span id="cb52-19">    age <span class="op" style="color: #5E5E5E;">=</span> LoggedAccess()                 <span class="co" style="color: #5E5E5E;"># Second descriptor instance</span></span>
<span id="cb52-20"></span>
<span id="cb52-21">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, name, age):</span>
<span id="cb52-22">        <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name                 <span class="co" style="color: #5E5E5E;"># Calls the first descriptor</span></span>
<span id="cb52-23">        <span class="va" style="color: #111111;">self</span>.age <span class="op" style="color: #5E5E5E;">=</span> age                   <span class="co" style="color: #5E5E5E;"># Calls the second descriptor</span></span>
<span id="cb52-24"></span>
<span id="cb52-25">    <span class="kw" style="color: #003B4F;">def</span> birthday(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb52-26">        <span class="va" style="color: #111111;">self</span>.age <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="84700369-3ad4-4565-f86b-10eb90e39f15" data-execution_count="97">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="bu" style="color: null;">vars</span>(Person)[<span class="st" style="color: #20794D;">'name'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>&lt;__main__.LoggedAccess at 0x78b2edeb8950&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="7cac51e2-e623-48fd-8fb0-5a24e8eb9ec0" data-execution_count="98">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="bu" style="color: null;">vars</span>(<span class="bu" style="color: null;">vars</span>(Person)[<span class="st" style="color: #20794D;">'name'</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>{'public_name': 'name', 'private_name': '_name'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="92758304-fcce-4f59-b09d-4b5e8bd02aae" data-execution_count="91">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><span class="bu" style="color: null;">vars</span>(<span class="bu" style="color: null;">vars</span>(Person)[<span class="st" style="color: #20794D;">'age'</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>{'public_name': 'age', 'private_name': '_age'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="1eaab803-e055-4a57-c28e-be9a86a91e4e" data-execution_count="92">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">pete <span class="op" style="color: #5E5E5E;">=</span> Person(<span class="st" style="color: #20794D;">'Peter P'</span>, <span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Updating name to Peter P
Updating age to 10</code></pre>
</div>
</div>
<div class="cell" data-outputid="90fbd1f4-dd19-4e81-ddc0-fa6fc51f8cca" data-execution_count="93">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1">kate <span class="op" style="color: #5E5E5E;">=</span> Person(<span class="st" style="color: #20794D;">'Catherine C'</span>, <span class="dv" style="color: #AD0000;">20</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Updating name to Catherine C
Updating age to 20</code></pre>
</div>
</div>
<div class="cell" data-outputid="aa93dc1b-bbef-4bba-ec4f-adea7923f972" data-execution_count="94">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><span class="bu" style="color: null;">vars</span>(pete)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>{'_name': 'Peter P', '_age': 10}</code></pre>
</div>
</div>
<div class="cell" data-outputid="b45e31dc-98a5-4fca-c3ab-f0f18e80416f" data-execution_count="95">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="bu" style="color: null;">vars</span>(kate)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="95">
<pre><code>{'_name': 'Catherine C', '_age': 20}</code></pre>
</div>
</div>
<p>I think the main takeaway here is that we didn’t specify the name of the field so we could use the same descriptor for both <code>name</code> and <code>age</code>.</p>
</section>
<section id="closing-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="closing-thoughts">Closing thoughts</h3>
<p>Looking at how <code>__set_name__</code> behaves (the example in the <a href="https://docs.python.org/3/reference/datamodel.html#object.__set_name__">docs</a>):</p>
<div class="cell" data-outputid="0db303bd-1e64-4471-940d-7dd8c37833e8" data-execution_count="103">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="kw" style="color: #003B4F;">class</span> C:</span>
<span id="cb67-2">    <span class="kw" style="color: #003B4F;">def</span> __set_name__(<span class="va" style="color: #111111;">self</span>, owner, name):</span>
<span id="cb67-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__set_name__ called with owner=</span><span class="sc" style="color: #5E5E5E;">{</span>owner<span class="sc" style="color: #5E5E5E;">.</span><span class="va" style="color: #111111;">__name__</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, name='</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'"</span>)</span>
<span id="cb67-4">        <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name</span>
<span id="cb67-5"></span>
<span id="cb67-6"><span class="kw" style="color: #003B4F;">class</span> A:</span>
<span id="cb67-7">    x <span class="op" style="color: #5E5E5E;">=</span> C()  <span class="co" style="color: #5E5E5E;"># This will trigger __set_name__</span></span>
<span id="cb67-8">    y <span class="op" style="color: #5E5E5E;">=</span> C()  <span class="co" style="color: #5E5E5E;"># This will trigger it again with a different name</span></span>
<span id="cb67-9">    bananas <span class="op" style="color: #5E5E5E;">=</span> C()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set_name__ called with owner=A, name='x'
__set_name__ called with owner=A, name='y'
__set_name__ called with owner=A, name='bananas'</code></pre>
</div>
</div>
<div class="cell" data-outputid="940a7982-0418-4c1f-aa86-adf2fecace1f" data-execution_count="104">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1">a <span class="op" style="color: #5E5E5E;">=</span> A()</span>
<span id="cb69-2">a.x, a.y, a.x.name, a.y.name, a.bananas.name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<pre><code>(&lt;__main__.C at 0x78b331674190&gt;,
 &lt;__main__.C at 0x78b2df52ccd0&gt;,
 'x',
 'y',
 'bananas')</code></pre>
</div>
</div>
<p>The part of particular interest to me is:</p>
<blockquote class="blockquote">
<p>Descriptors are used throughout the language. It is how functions turn into bound methods.</p>
</blockquote>
</section>
</section>
<section id="complete-practical-example" class="level2">
<h2 class="anchored" data-anchor-id="complete-practical-example">Complete practical example</h2>
<section id="validator-class" class="level3">
<h3 class="anchored" data-anchor-id="validator-class">Validator class</h3>
<blockquote class="blockquote">
<p>A validator is a descriptor for managed attribute access. Prior to storing any data, it verifies that the new value meets various type and range restrictions. If those restrictions aren’t met, it raises an exception to prevent data corruption at its source.</p>
</blockquote>
<div class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><span class="im" style="color: #00769E;">from</span> abc <span class="im" style="color: #00769E;">import</span> ABC, abstractmethod</span>
<span id="cb71-2"></span>
<span id="cb71-3"><span class="kw" style="color: #003B4F;">class</span> Validator(ABC):</span>
<span id="cb71-4"></span>
<span id="cb71-5">    <span class="kw" style="color: #003B4F;">def</span> __set_name__(<span class="va" style="color: #111111;">self</span>, owner, name):</span>
<span id="cb71-6">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__set_name__ is called"</span>)</span>
<span id="cb71-7">        <span class="va" style="color: #111111;">self</span>.private_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'_'</span> <span class="op" style="color: #5E5E5E;">+</span> name</span>
<span id="cb71-8"></span>
<span id="cb71-9">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb71-10">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__get__ is called"</span>)</span>
<span id="cb71-11">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">getattr</span>(obj, <span class="va" style="color: #111111;">self</span>.private_name)</span>
<span id="cb71-12"></span>
<span id="cb71-13">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__set__</span>(<span class="va" style="color: #111111;">self</span>, obj, value):</span>
<span id="cb71-14">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__set__ is called"</span>)</span>
<span id="cb71-15">        <span class="va" style="color: #111111;">self</span>.validate(value)</span>
<span id="cb71-16">        <span class="bu" style="color: null;">setattr</span>(obj, <span class="va" style="color: #111111;">self</span>.private_name, value)</span>
<span id="cb71-17"></span>
<span id="cb71-18">    <span class="at" style="color: #657422;">@abstractmethod</span></span>
<span id="cb71-19">    <span class="kw" style="color: #003B4F;">def</span> validate(<span class="va" style="color: #111111;">self</span>, value):</span>
<span id="cb71-20">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"validate is called"</span>)</span>
<span id="cb71-21">        <span class="cf" style="color: #003B4F;">pass</span></span></code></pre></div>
</div>
</section>
<section id="custom-validators" class="level3">
<h3 class="anchored" data-anchor-id="custom-validators">Custom validators</h3>
<blockquote class="blockquote">
<p>Here are three practical data validation utilities:</p>
<ol type="1">
<li><p><code>OneOf</code> verifies that a value is one of a restricted set of options.</p></li>
<li><p><code>Number</code> verifies that a value is either an int or float. Optionally, it verifies that a value is between a given minimum or maximum.</p></li>
<li><p><code>String</code> verifies that a value is a str. Optionally, it validates a given minimum or maximum length. It can validate a user-defined predicate as well.</p></li>
</ol>
</blockquote>
<div class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><span class="kw" style="color: #003B4F;">class</span> OneOf(Validator):</span>
<span id="cb72-2"></span>
<span id="cb72-3">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, <span class="op" style="color: #5E5E5E;">*</span>options):</span>
<span id="cb72-4">        <span class="va" style="color: #111111;">self</span>.options <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">set</span>(options)</span>
<span id="cb72-5"></span>
<span id="cb72-6">    <span class="kw" style="color: #003B4F;">def</span> validate(<span class="va" style="color: #111111;">self</span>, value):</span>
<span id="cb72-7">        <span class="cf" style="color: #003B4F;">if</span> value <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.options:</span>
<span id="cb72-8">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-9">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be one of </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>options<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-10">            )</span>
<span id="cb72-11"></span>
<span id="cb72-12"><span class="kw" style="color: #003B4F;">class</span> Number(Validator):</span>
<span id="cb72-13"></span>
<span id="cb72-14">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, minvalue<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, maxvalue<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb72-15">        <span class="va" style="color: #111111;">self</span>.minvalue <span class="op" style="color: #5E5E5E;">=</span> minvalue</span>
<span id="cb72-16">        <span class="va" style="color: #111111;">self</span>.maxvalue <span class="op" style="color: #5E5E5E;">=</span> maxvalue</span>
<span id="cb72-17"></span>
<span id="cb72-18">    <span class="kw" style="color: #003B4F;">def</span> validate(<span class="va" style="color: #111111;">self</span>, value):</span>
<span id="cb72-19">        <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="bu" style="color: null;">isinstance</span>(value, (<span class="bu" style="color: null;">int</span>, <span class="bu" style="color: null;">float</span>)):</span>
<span id="cb72-20">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">TypeError</span>(<span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be an int or float'</span>)</span>
<span id="cb72-21">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.minvalue <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> value <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="va" style="color: #111111;">self</span>.minvalue:</span>
<span id="cb72-22">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-23">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be at least </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>minvalue<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-24">            )</span>
<span id="cb72-25">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.maxvalue <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> value <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="va" style="color: #111111;">self</span>.maxvalue:</span>
<span id="cb72-26">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-27">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be no more than </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>maxvalue<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-28">            )</span>
<span id="cb72-29"></span>
<span id="cb72-30"><span class="kw" style="color: #003B4F;">class</span> String(Validator):</span>
<span id="cb72-31"></span>
<span id="cb72-32">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, minsize<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, maxsize<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, predicate<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb72-33">        <span class="va" style="color: #111111;">self</span>.minsize <span class="op" style="color: #5E5E5E;">=</span> minsize</span>
<span id="cb72-34">        <span class="va" style="color: #111111;">self</span>.maxsize <span class="op" style="color: #5E5E5E;">=</span> maxsize</span>
<span id="cb72-35">        <span class="va" style="color: #111111;">self</span>.predicate <span class="op" style="color: #5E5E5E;">=</span> predicate</span>
<span id="cb72-36"></span>
<span id="cb72-37">    <span class="kw" style="color: #003B4F;">def</span> validate(<span class="va" style="color: #111111;">self</span>, value):</span>
<span id="cb72-38">        <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="bu" style="color: null;">isinstance</span>(value, <span class="bu" style="color: null;">str</span>):</span>
<span id="cb72-39">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">TypeError</span>(<span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be an str'</span>)</span>
<span id="cb72-40">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.minsize <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(value) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="va" style="color: #111111;">self</span>.minsize:</span>
<span id="cb72-41">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-42">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be no smaller than </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>minsize<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-43">            )</span>
<span id="cb72-44">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.maxsize <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(value) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="va" style="color: #111111;">self</span>.maxsize:</span>
<span id="cb72-45">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-46">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be no bigger than </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>maxsize<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-47">            )</span>
<span id="cb72-48">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.predicate <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">self</span>.predicate(value):</span>
<span id="cb72-49">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-50">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>predicate<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> to be true for </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-51">            )</span></code></pre></div>
</div>
</section>
<section id="practical-application" class="level3">
<h3 class="anchored" data-anchor-id="practical-application">Practical application</h3>
<div class="cell" data-outputid="a291dd22-396d-4771-ef6d-f9ccf1dd7aa8" data-execution_count="119">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><span class="kw" style="color: #003B4F;">class</span> Component:</span>
<span id="cb73-2"></span>
<span id="cb73-3">    name <span class="op" style="color: #5E5E5E;">=</span> String(minsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, maxsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>, predicate<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span>.isupper)</span>
<span id="cb73-4">    kind <span class="op" style="color: #5E5E5E;">=</span> OneOf(<span class="st" style="color: #20794D;">'wood'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="st" style="color: #20794D;">'plastic'</span>)</span>
<span id="cb73-5">    quantity <span class="op" style="color: #5E5E5E;">=</span> Number(minvalue<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb73-6"></span>
<span id="cb73-7">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, name, kind, quantity):</span>
<span id="cb73-8">        <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name</span>
<span id="cb73-9">        <span class="va" style="color: #111111;">self</span>.kind <span class="op" style="color: #5E5E5E;">=</span> kind</span>
<span id="cb73-10">        <span class="va" style="color: #111111;">self</span>.quantity <span class="op" style="color: #5E5E5E;">=</span> quantity</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set_name__ is called
__set_name__ is called
__set_name__ is called</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>The descriptors prevent invalid instances from being created:</p>
</blockquote>
<div class="cell" data-outputid="3b846377-b1de-40cd-dc38-47f088d7bda6" data-execution_count="120">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1">Component(<span class="st" style="color: #20794D;">'Widget'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="dv" style="color: #AD0000;">5</span>)      <span class="co" style="color: #5E5E5E;"># Blocked: 'Widget' is not all uppercase</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>ValueError: Expected &lt;method 'isupper' of 'str' objects&gt; to be true for 'Widget'</code></pre>
</div>
</div>
<div class="cell" data-outputid="a1ff6411-3569-4dca-91df-dc09c8cfe544" data-execution_count="121">
<div class="sourceCode cell-code" id="cb78" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1">Component(<span class="st" style="color: #20794D;">'WIDGET'</span>, <span class="st" style="color: #20794D;">'metle'</span>, <span class="dv" style="color: #AD0000;">5</span>)      <span class="co" style="color: #5E5E5E;"># Blocked: 'metle' is misspelled</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called
__set__ is called</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>ValueError: Expected 'metle' to be one of {'metal', 'plastic', 'wood'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="8b1180ca-b0c2-4911-a392-e358c0b51258" data-execution_count="122">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">Component(<span class="st" style="color: #20794D;">'WIDGET'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">5</span>)     <span class="co" style="color: #5E5E5E;"># Blocked: -5 is negative</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called
__set__ is called
__set__ is called</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>ValueError: Expected -5 to be at least 0</code></pre>
</div>
</div>
<div class="cell" data-outputid="f79c42d5-1ba2-48b0-a112-012fbf3be47b" data-execution_count="123">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1">Component(<span class="st" style="color: #20794D;">'WIDGET'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="st" style="color: #20794D;">'V'</span>)    <span class="co" style="color: #5E5E5E;"># Blocked: 'V' isn't a number</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called
__set__ is called
__set__ is called</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>TypeError: Expected 'V' to be an int or float</code></pre>
</div>
</div>
<div class="cell" data-outputid="b0422385-73be-45e5-b490-fe4632f4fe19" data-execution_count="124">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1">c <span class="op" style="color: #5E5E5E;">=</span> Component(<span class="st" style="color: #20794D;">'WIDGET'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="dv" style="color: #AD0000;">5</span>)  <span class="co" style="color: #5E5E5E;"># Allowed:  The inputs are valid</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called
__set__ is called
__set__ is called</code></pre>
</div>
</div>
<div class="cell" data-outputid="bdccab04-b422-445b-dd67-18994ae02b77" data-execution_count="125">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1">c.name</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ is called</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="125">
<pre><code>'WIDGET'</code></pre>
</div>
</div>
</section>
</section>
<section id="technical-tutorial" class="level2">
<h2 class="anchored" data-anchor-id="technical-tutorial">Technical tutorial</h2>
<p>After the reading the introduction of this guide I assumed I would skip the technical tutorial, expecting it to be too technical, but after skimming it I’ve decided to go through it as it might clear some things up for me and the following line was attractive:</p>
<blockquote class="blockquote">
<p>Learning about descriptors not only provides access to a larger toolset, it creates a deeper understanding of how Python works.</p>
</blockquote>
<section id="definition-and-introduction" class="level3">
<h3 class="anchored" data-anchor-id="definition-and-introduction">Definition and introduction</h3>
<p>Reiterating the important definition that a descriptor is anything that has one of the methods in the descriptor protocol:</p>
<blockquote class="blockquote">
<p>In general, a descriptor is an attribute value that has one of the methods in the descriptor protocol. Those methods are <code>__get__()</code>, <code>__set__()</code>, and <code>__delete__()</code>. If any of those methods are defined for an attribute, it is said to be a descriptor.</p>
</blockquote>
<p>And the main goal of descriptors:</p>
<blockquote class="blockquote">
<p>The default behavior for attribute access is to get, set, or delete the attribute from an object’s dictionary.</p>
</blockquote>
</section>
<section id="descriptor-protocol" class="level3">
<h3 class="anchored" data-anchor-id="descriptor-protocol">Descriptor protocol</h3>
<p>I don’t have any comments for this section other than reiterating the following points:</p>
<blockquote class="blockquote">
<p><code>descr.__get__(self, obj, type=None)</code></p>
<p><code>descr.__set__(self, obj, value)</code></p>
<p><code>descr.__delete__(self, obj)</code></p>
<p>That is all there is to it. Define any of these methods and an object is considered a descriptor and can override default behavior upon being looked up as an attribute.</p>
</blockquote>
<blockquote class="blockquote">
<p>If an object defines <code>__set__()</code> or <code>__delete__()</code>, it is considered a data descriptor. Descriptors that only define <code>__get__()</code> are called non-data descriptors (they are often used for methods but other uses are possible).</p>
</blockquote>
</section>
<section id="overview-of-descriptor-invocation" class="level3">
<h3 class="anchored" data-anchor-id="overview-of-descriptor-invocation">Overview of descriptor invocation</h3>
<blockquote class="blockquote">
<p>A descriptor can be called directly with <code>desc.__get__(obj)</code> or <code>desc.__get__(None, cls)</code>.</p>
</blockquote>
<blockquote class="blockquote">
<p>But it is more common for a descriptor to be invoked automatically from attribute access.</p>
</blockquote>
<p>We saw this earlier, but putting that example here again:</p>
<div class="cell" data-outputid="4b62a4a6-552d-4080-eb17-deeba13a03de" data-execution_count="127">
<div class="sourceCode cell-code" id="cb92" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><span class="kw" style="color: #003B4F;">class</span> Ten2:</span>
<span id="cb92-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb92-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__get__ called with obj=</span><span class="sc" style="color: #5E5E5E;">{</span>obj<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, objtype=</span><span class="sc" style="color: #5E5E5E;">{</span>objtype<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb92-4">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb92-5"></span>
<span id="cb92-6"><span class="kw" style="color: #003B4F;">class</span> A2:</span>
<span id="cb92-7">    x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb92-8">    y <span class="op" style="color: #5E5E5E;">=</span> Ten2()  <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span>
<span id="cb92-9"></span>
<span id="cb92-10">a2 <span class="op" style="color: #5E5E5E;">=</span> A2()</span>
<span id="cb92-11">a2.y</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2ded96890&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="127">
<pre><code>10</code></pre>
</div>
</div>
</section>
<section id="invocation-from-an-instance" class="level3">
<h3 class="anchored" data-anchor-id="invocation-from-an-instance">Invocation from an instance</h3>
<blockquote class="blockquote">
<p>Instance lookup scans through a chain of namespaces giving data descriptors the highest priority, followed by instance variables, then non-data descriptors, then class variables, and lastly <code>__getattr__()</code> if it is provided.</p>
</blockquote>
<p>I’ve added some print statements in their example code to show which option is triggered:</p>
<div class="cell" data-execution_count="138">
<div class="sourceCode cell-code" id="cb95" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><span class="kw" style="color: #003B4F;">def</span> find_name_in_mro(cls, name, default):</span>
<span id="cb95-2">    <span class="co" style="color: #5E5E5E;">"Emulate _PyType_Lookup() in Objects/typeobject.c"</span></span>
<span id="cb95-3">    <span class="cf" style="color: #003B4F;">for</span> base <span class="kw" style="color: #003B4F;">in</span> cls.__mro__:</span>
<span id="cb95-4">        <span class="cf" style="color: #003B4F;">if</span> name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">vars</span>(base):</span>
<span id="cb95-5">            <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">vars</span>(base)[name]</span>
<span id="cb95-6">    <span class="cf" style="color: #003B4F;">return</span> default</span>
<span id="cb95-7"></span>
<span id="cb95-8"><span class="kw" style="color: #003B4F;">def</span> object_getattribute(obj, name):</span>
<span id="cb95-9">    <span class="co" style="color: #5E5E5E;">"Emulate PyObject_GenericGetAttr() in Objects/object.c"</span></span>
<span id="cb95-10">    null <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">object</span>()</span>
<span id="cb95-11">    objtype <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">type</span>(obj)</span>
<span id="cb95-12">    cls_var <span class="op" style="color: #5E5E5E;">=</span> find_name_in_mro(objtype, name, null)</span>
<span id="cb95-13">    descr_get <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">getattr</span>(<span class="bu" style="color: null;">type</span>(cls_var), <span class="st" style="color: #20794D;">'__get__'</span>, null)</span>
<span id="cb95-14">    <span class="cf" style="color: #003B4F;">if</span> descr_get <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> null:</span>
<span id="cb95-15">        <span class="cf" style="color: #003B4F;">if</span> (<span class="bu" style="color: null;">hasattr</span>(<span class="bu" style="color: null;">type</span>(cls_var), <span class="st" style="color: #20794D;">'__set__'</span>)</span>
<span id="cb95-16">            <span class="kw" style="color: #003B4F;">or</span> <span class="bu" style="color: null;">hasattr</span>(<span class="bu" style="color: null;">type</span>(cls_var), <span class="st" style="color: #20794D;">'__delete__'</span>)):</span>
<span id="cb95-17">            <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"returning data descriptor set/delete"</span>)</span>
<span id="cb95-18">            <span class="cf" style="color: #003B4F;">return</span> descr_get(cls_var, obj, objtype)     <span class="co" style="color: #5E5E5E;"># data descriptor</span></span>
<span id="cb95-19">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(obj, <span class="st" style="color: #20794D;">'__dict__'</span>) <span class="kw" style="color: #003B4F;">and</span> name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">vars</span>(obj):</span>
<span id="cb95-20">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"returning instance variable"</span>)</span>
<span id="cb95-21">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">vars</span>(obj)[name]                          <span class="co" style="color: #5E5E5E;"># instance variable</span></span>
<span id="cb95-22">    <span class="cf" style="color: #003B4F;">if</span> descr_get <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> null:</span>
<span id="cb95-23">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"returning descr_get"</span>)</span>
<span id="cb95-24">        <span class="cf" style="color: #003B4F;">return</span> descr_get(cls_var, obj, objtype)         <span class="co" style="color: #5E5E5E;"># non-data descriptor</span></span>
<span id="cb95-25">    <span class="cf" style="color: #003B4F;">if</span> cls_var <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> null:</span>
<span id="cb95-26">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"returning class variable"</span>)</span>
<span id="cb95-27">        <span class="cf" style="color: #003B4F;">return</span> cls_var                                  <span class="co" style="color: #5E5E5E;"># class variable</span></span>
<span id="cb95-28">    <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">AttributeError</span>(name)</span></code></pre></div>
</div>
<div class="cell" data-outputid="7624e6f8-8312-40d2-9c43-178a8e8a5655" data-execution_count="139">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">object_getattribute(a2, <span class="st" style="color: #20794D;">'y'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>returning descr_get
__get__ called with obj=&lt;__main__.A2 object at 0x78b2ded96890&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="139">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="588ae176-621c-4ae7-b37c-c7a616007844" data-execution_count="140">
<div class="sourceCode cell-code" id="cb99" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1">object_getattribute(a2, <span class="st" style="color: #20794D;">'x'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>returning class variable</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="140">
<pre><code>5</code></pre>
</div>
</div>
<div class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb102" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><span class="kw" style="color: #003B4F;">def</span> getattr_hook(obj, name):</span>
<span id="cb102-2">    <span class="co" style="color: #5E5E5E;">"Emulate slot_tp_getattr_hook() in Objects/typeobject.c"</span></span>
<span id="cb102-3">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb102-4">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__getattribute__"</span>)</span>
<span id="cb102-5">        <span class="cf" style="color: #003B4F;">return</span> obj.<span class="fu" style="color: #4758AB;">__getattribute__</span>(name)</span>
<span id="cb102-6">    <span class="cf" style="color: #003B4F;">except</span> <span class="pp" style="color: #AD0000;">AttributeError</span>:</span>
<span id="cb102-7">        <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="bu" style="color: null;">hasattr</span>(<span class="bu" style="color: null;">type</span>(obj), <span class="st" style="color: #20794D;">'__getattr__'</span>):</span>
<span id="cb102-8">            <span class="cf" style="color: #003B4F;">raise</span></span>
<span id="cb102-9">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__getattr__"</span>)</span>
<span id="cb102-10">    <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">type</span>(obj).<span class="fu" style="color: #4758AB;">__getattr__</span>(obj, name)</span></code></pre></div>
</div>
<div class="cell" data-outputid="0aabb2c0-7a6d-416b-893c-47b6c94dd29e" data-execution_count="146">
<div class="sourceCode cell-code" id="cb103" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1">getattr_hook(a2, <span class="st" style="color: #20794D;">'y'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__getattribute__
__get__ called with obj=&lt;__main__.A2 object at 0x78b2ded96890&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="146">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="f95a8401-3380-4234-b372-e43d61463745" data-execution_count="147">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1">getattr_hook(a2, <span class="st" style="color: #20794D;">'x'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__getattribute__</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="147">
<pre><code>5</code></pre>
</div>
</div>
</section>
<section id="invocation-from-a-class" class="level3">
<h3 class="anchored" data-anchor-id="invocation-from-a-class">Invocation from a class</h3>
<blockquote class="blockquote">
<p>The logic for a dotted lookup such as <code>A.x</code> is in <code>type.__getattribute__()</code>.</p>
</blockquote>
<div class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb109" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1">A2.<span class="fu" style="color: #4758AB;">__getattribute__</span>??</span></code></pre></div>
</div>
<pre><code>Signature:   A2.__getattribute__(*args, **kwargs)
Type:        wrapper_descriptor
String form: &lt;slot wrapper '__getattribute__' of 'object' objects&gt;
Docstring:   Return getattr(self, name).</code></pre>
<div class="cell" data-outputid="a7e35d14-2e01-4cb6-f616-cc491f83a923" data-execution_count="152">
<div class="sourceCode cell-code" id="cb111" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1">A2.<span class="fu" style="color: #4758AB;">__getattribute__</span>(A2, <span class="st" style="color: #20794D;">'y'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="152">
<pre><code>&lt;__main__.Ten2 at 0x78b2dee79310&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="da9fcb9a-e92a-4040-eaee-008bfaff133b" data-execution_count="153">
<div class="sourceCode cell-code" id="cb113" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1">A2.<span class="fu" style="color: #4758AB;">__getattribute__</span>(A2, <span class="st" style="color: #20794D;">'x'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="153">
<pre><code>5</code></pre>
</div>
</div>
</section>
<section id="invocation-from-super" class="level3">
<h3 class="anchored" data-anchor-id="invocation-from-super">Invocation from super</h3>
<blockquote class="blockquote">
<p>A dotted lookup such as <code>super(A, obj).m</code> searches <code>obj.__class__.__mro__</code> for the base class <code>B</code> immediately following <code>A</code> and then returns <code>B.__dict__['m'].__get__(obj, A)</code>. If not a descriptor, <code>m</code> is returned unchanged.</p>
</blockquote>
<div class="cell" data-execution_count="175">
<div class="sourceCode cell-code" id="cb115" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><span class="kw" style="color: #003B4F;">class</span> Base:</span>
<span id="cb115-2">    z <span class="op" style="color: #5E5E5E;">=</span> Ten2()  <span class="co" style="color: #5E5E5E;"># Descriptor in the base class</span></span>
<span id="cb115-3"></span>
<span id="cb115-4"><span class="kw" style="color: #003B4F;">class</span> A2(Base):</span>
<span id="cb115-5">    x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb115-6">    y <span class="op" style="color: #5E5E5E;">=</span> Ten2()  <span class="co" style="color: #5E5E5E;"># Descriptor instance in A2</span></span>
<span id="cb115-7"></span>
<span id="cb115-8">    <span class="kw" style="color: #003B4F;">def</span> show_super_lookup(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb115-9">        <span class="co" style="color: #5E5E5E;"># This will trigger the descriptor lookup through super()</span></span>
<span id="cb115-10">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">super</span>().z</span></code></pre></div>
</div>
<div class="cell" data-outputid="31c162b5-50cb-4d2f-aeab-40bc3a875242" data-execution_count="176">
<div class="sourceCode cell-code" id="cb116" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1">a <span class="op" style="color: #5E5E5E;">=</span> A2()</span>
<span id="cb116-2">a.y</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2dededa90&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="176">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="506d9028-2db4-425b-e3e3-2dadd34ff683" data-execution_count="177">
<div class="sourceCode cell-code" id="cb119" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><span class="bu" style="color: null;">super</span>(A2, a).z</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2dededa90&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="177">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="f4e57871-b58e-4058-ca54-b2d696eca82e" data-execution_count="178">
<div class="sourceCode cell-code" id="cb122" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1">Base.__dict__[<span class="st" style="color: #20794D;">'z'</span>].<span class="fu" style="color: #4758AB;">__get__</span>(a, A2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2dededa90&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="178">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="b2270d8e-31ea-4f77-d03f-f9679b1e541e" data-execution_count="179">
<div class="sourceCode cell-code" id="cb125" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1">a.__class__.__mro__</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="179">
<pre><code>(__main__.A2, __main__.Base, object)</code></pre>
</div>
</div>
</section>
<section id="summary-of-invocation-logic" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-invocation-logic">Summary of invocation logic</h3>
<p>Showing examples of some of the bullet points in the summary:</p>
<ul>
<li>Descriptors are invoked by the <code>__getattribute__()</code> method.</li>
</ul>
<div class="cell" data-outputid="ea38ba47-a928-4128-a1fb-cbc231fa3a35" data-execution_count="180">
<div class="sourceCode cell-code" id="cb127" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1">a.<span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="st" style="color: #20794D;">'y'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2dededa90&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="180">
<pre><code>10</code></pre>
</div>
</div>
<ul>
<li>Overriding <code>__getattribute__()</code> prevents automatic descriptor calls because all the descriptor logic is in that method.</li>
</ul>
<div class="cell" data-outputid="68ac78c2-2ec1-4ee6-f840-32491435634e" data-execution_count="195">
<div class="sourceCode cell-code" id="cb130" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><span class="kw" style="color: #003B4F;">class</span> MyDescriptor:</span>
<span id="cb130-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb130-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Descriptor __get__ called!"</span>)</span>
<span id="cb130-4">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">42</span></span>
<span id="cb130-5"></span>
<span id="cb130-6"><span class="kw" style="color: #003B4F;">class</span> Normal:</span>
<span id="cb130-7">    x <span class="op" style="color: #5E5E5E;">=</span> MyDescriptor()</span>
<span id="cb130-8"></span>
<span id="cb130-9">n <span class="op" style="color: #5E5E5E;">=</span> Normal()</span>
<span id="cb130-10">n.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Descriptor __get__ called!</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="195">
<pre><code>42</code></pre>
</div>
</div>
<div class="cell" data-outputid="4c3bfd01-d824-4254-9e21-daf3ab13b60b" data-execution_count="196">
<div class="sourceCode cell-code" id="cb133" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><span class="kw" style="color: #003B4F;">class</span> OverrideGetattribute:</span>
<span id="cb133-2">    x <span class="op" style="color: #5E5E5E;">=</span> MyDescriptor()</span>
<span id="cb133-3">    y <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb133-4"></span>
<span id="cb133-5">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="va" style="color: #111111;">self</span>, name):</span>
<span id="cb133-6">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Custom __getattribute__ called for </span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb133-7">        <span class="cf" style="color: #003B4F;">if</span> name <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'x'</span>:</span>
<span id="cb133-8">            <span class="cf" style="color: #003B4F;">return</span> <span class="st" style="color: #20794D;">"Bypassed descriptor"</span></span>
<span id="cb133-9">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">object</span>.<span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="va" style="color: #111111;">self</span>, name)</span>
<span id="cb133-10"></span>
<span id="cb133-11">o <span class="op" style="color: #5E5E5E;">=</span> OverrideGetattribute()</span>
<span id="cb133-12">o.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Custom __getattribute__ called for x</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="196">
<pre><code>'Bypassed descriptor'</code></pre>
</div>
</div>
<div class="cell" data-outputid="db10e098-648b-42ca-8ca4-51a062eb62c8" data-execution_count="197">
<div class="sourceCode cell-code" id="cb136" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1">o.y</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Custom __getattribute__ called for y</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="197">
<pre><code>5</code></pre>
</div>
</div>
<ul>
<li><code>object.__getattribute__()</code> and <code>type.__getattribute__()</code> make different calls to <code>__get__()</code>. The first includes the instance and may include the class. The second puts in <code>None</code> for the instance and always includes the class.</li>
</ul>
<div class="cell" data-execution_count="208">
<div class="sourceCode cell-code" id="cb139" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><span class="kw" style="color: #003B4F;">class</span> DetailedDescriptor:</span>
<span id="cb139-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb139-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__get__ called with obj=</span><span class="sc" style="color: #5E5E5E;">{</span>obj<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, objtype=</span><span class="sc" style="color: #5E5E5E;">{</span>objtype<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb139-4">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">42</span></span>
<span id="cb139-5"></span>
<span id="cb139-6"><span class="kw" style="color: #003B4F;">class</span> Normal:</span>
<span id="cb139-7">    x <span class="op" style="color: #5E5E5E;">=</span> DetailedDescriptor()</span>
<span id="cb139-8"></span>
<span id="cb139-9">n <span class="op" style="color: #5E5E5E;">=</span> Normal()</span></code></pre></div>
</div>
<div class="cell" data-outputid="0d60c5f0-9623-4c6f-ccb4-fbcddfa7a428" data-execution_count="209">
<div class="sourceCode cell-code" id="cb140" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1">n.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.Normal object at 0x78b2dedf0750&gt;, objtype=&lt;class '__main__.Normal'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="209">
<pre><code>42</code></pre>
</div>
</div>
<div class="cell" data-outputid="cc7f4537-465e-48e7-c91d-0060eac405d9" data-execution_count="210">
<div class="sourceCode cell-code" id="cb143" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1">Normal.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=None, objtype=&lt;class '__main__.Normal'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="210">
<pre><code>42</code></pre>
</div>
</div>
<ul>
<li>Data descriptors always override instance dictionaries.</li>
</ul>
<div class="cell" data-execution_count="211">
<div class="sourceCode cell-code" id="cb146" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><span class="kw" style="color: #003B4F;">class</span> DataDescriptor:</span>
<span id="cb146-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, initial_value<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb146-3">        <span class="va" style="color: #111111;">self</span>.value <span class="op" style="color: #5E5E5E;">=</span> initial_value</span>
<span id="cb146-4"></span>
<span id="cb146-5">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb146-6">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"DataDescriptor.__get__ called"</span>)</span>
<span id="cb146-7">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.value</span>
<span id="cb146-8"></span>
<span id="cb146-9">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__set__</span>(<span class="va" style="color: #111111;">self</span>, obj, value):</span>
<span id="cb146-10">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"DataDescriptor.__set__ called with value: </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb146-11">        <span class="va" style="color: #111111;">self</span>.value <span class="op" style="color: #5E5E5E;">=</span> value</span>
<span id="cb146-12"></span>
<span id="cb146-13"><span class="kw" style="color: #003B4F;">class</span> Example:</span>
<span id="cb146-14">    x <span class="op" style="color: #5E5E5E;">=</span> DataDescriptor(<span class="dv" style="color: #AD0000;">42</span>)  <span class="co" style="color: #5E5E5E;"># Data descriptor defined in class</span></span>
<span id="cb146-15"></span>
<span id="cb146-16">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb146-17">        <span class="co" style="color: #5E5E5E;"># Try to override with instance attribute</span></span>
<span id="cb146-18">        <span class="va" style="color: #111111;">self</span>.__dict__[<span class="st" style="color: #20794D;">'x'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Instance value"</span></span>
<span id="cb146-19"></span>
<span id="cb146-20"></span>
<span id="cb146-21">example <span class="op" style="color: #5E5E5E;">=</span> Example()</span></code></pre></div>
</div>
<div class="cell" data-outputid="1733a8ce-6f53-4e41-9649-7fa4ddd997f3" data-execution_count="212">
<div class="sourceCode cell-code" id="cb147" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1">example.__dict__</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="212">
<pre><code>{'x': 'Instance value'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="1d03bcd6-c2b8-4c63-cbfc-cc7c91dbe214" data-execution_count="213">
<div class="sourceCode cell-code" id="cb149" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1">example.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DataDescriptor.__get__ called</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="213">
<pre><code>42</code></pre>
</div>
</div>
<div class="cell" data-outputid="11962f2b-4023-4831-cbb2-cff4a1d85fa1" data-execution_count="215">
<div class="sourceCode cell-code" id="cb152" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1">example.x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">100</span></span>
<span id="cb152-2">example.__dict__[<span class="st" style="color: #20794D;">'x'</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DataDescriptor.__set__ called with value: 100</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="215">
<pre><code>'Instance value'</code></pre>
</div>
</div>
<div class="cell" data-outputid="b74e3010-a30c-4e4e-b9e3-6d8ddee5a1e8" data-execution_count="216">
<div class="sourceCode cell-code" id="cb155" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1">example.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DataDescriptor.__get__ called</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="216">
<pre><code>100</code></pre>
</div>
</div>
<ul>
<li>Non-data descriptors may be overridden by instance dictionaries.</li>
</ul>
<div class="cell" data-execution_count="217">
<div class="sourceCode cell-code" id="cb158" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><span class="kw" style="color: #003B4F;">class</span> NonDataDescriptor:</span>
<span id="cb158-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, initial_value<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb158-3">        <span class="va" style="color: #111111;">self</span>.value <span class="op" style="color: #5E5E5E;">=</span> initial_value</span>
<span id="cb158-4"></span>
<span id="cb158-5">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb158-6">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"DataDescriptor.__get__ called"</span>)</span>
<span id="cb158-7">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.value</span>
<span id="cb158-8"></span>
<span id="cb158-9"><span class="kw" style="color: #003B4F;">class</span> Example:</span>
<span id="cb158-10">    x <span class="op" style="color: #5E5E5E;">=</span> NonDataDescriptor(<span class="dv" style="color: #AD0000;">42</span>)  <span class="co" style="color: #5E5E5E;"># Data descriptor defined in class</span></span>
<span id="cb158-11"></span>
<span id="cb158-12">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb158-13">        <span class="co" style="color: #5E5E5E;"># Try to override with instance attribute</span></span>
<span id="cb158-14">        <span class="va" style="color: #111111;">self</span>.__dict__[<span class="st" style="color: #20794D;">'x'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Instance value"</span></span>
<span id="cb158-15"></span>
<span id="cb158-16"></span>
<span id="cb158-17">example <span class="op" style="color: #5E5E5E;">=</span> Example()</span></code></pre></div>
</div>
<div class="cell" data-outputid="2e68841b-5462-42ae-d551-9bda604be404" data-execution_count="218">
<div class="sourceCode cell-code" id="cb159" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1">example.__dict__</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="218">
<pre><code>{'x': 'Instance value'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="01acab7f-edb3-4c11-e650-0fa57a156ceb" data-execution_count="219">
<div class="sourceCode cell-code" id="cb161" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb161-1">example.x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="219">
<pre><code>'Instance value'</code></pre>
</div>
</div>
</section>
<section id="automatic-name-notification" class="level3">
<h3 class="anchored" data-anchor-id="automatic-name-notification">Automatic name notification</h3>
<blockquote class="blockquote">
<p>Sometimes it is desirable for a descriptor to know what class variable name it was assigned to. When a new class is created, the <code>type</code> metaclass scans the dictionary of the new class. If any of the entries are descriptors and if they define <code>__set_name__()</code>, that method is called with two arguments. The owner is the class where the descriptor is used, and the name is the class variable the descriptor was assigned to.</p>
</blockquote>
<div class="cell" data-execution_count="227">
<div class="sourceCode cell-code" id="cb163" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><span class="kw" style="color: #003B4F;">class</span> NameTracker:</span>
<span id="cb163-2">   <span class="kw" style="color: #003B4F;">def</span> __set_name__(<span class="va" style="color: #111111;">self</span>, owner, name): <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name</span></code></pre></div>
</div>
<div class="cell" data-execution_count="228">
<div class="sourceCode cell-code" id="cb164" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1">class_dict <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb164-2">        <span class="st" style="color: #20794D;">'x'</span>: NameTracker(),</span>
<span id="cb164-3">        <span class="st" style="color: #20794D;">'y'</span>: NameTracker(),</span>
<span id="cb164-4">        <span class="st" style="color: #20794D;">'z'</span>: <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb164-5">    }</span></code></pre></div>
</div>
<div class="cell" data-execution_count="229">
<div class="sourceCode cell-code" id="cb165" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1">Demo <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">type</span>(<span class="st" style="color: #20794D;">'Demo'</span>, (), class_dict)</span></code></pre></div>
</div>
<div class="cell" data-outputid="c1ee1f3c-ddbe-4e35-bced-a11f96ae3cc4" data-execution_count="231">
<div class="sourceCode cell-code" id="cb166" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb166-1">Demo.x.name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="231">
<pre><code>'x'</code></pre>
</div>
</div>
<div class="cell" data-outputid="b3867517-a51b-4675-b24b-70b33ce13579" data-execution_count="232">
<div class="sourceCode cell-code" id="cb168" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1">Demo.y.name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="232">
<pre><code>'y'</code></pre>
</div>
</div>
<p>I’m skipping the ORM example since I don’t have access to the example database.</p>
</section>
</section>
<section id="pure-python-equivalents" class="level2">
<h2 class="anchored" data-anchor-id="pure-python-equivalents">Pure Python Equivalents</h2>
<p>Finally! The section I’m most interested in.</p>
<blockquote class="blockquote">
<p>Properties, bound methods, static methods, class methods, and <code>__slots__</code> are all based on the descriptor protocol.</p>
</blockquote>
<p>I’m going to focus on the functions and methods section.</p>
<section id="functions-and-methods" class="level3">
<h3 class="anchored" data-anchor-id="functions-and-methods">Functions and methods</h3>
<blockquote class="blockquote">
<p>Functions stored in class dictionaries get turned into methods when invoked. Methods only differ from regular functions in that the object instance is prepended to the other arguments. By convention, the instance is called self but could be called this or any other variable name.</p>
</blockquote>
<blockquote class="blockquote">
<p>Methods can be created manually with types.MethodType which is roughly equivalent to:</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb170" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><span class="kw" style="color: #003B4F;">class</span> MethodType:</span>
<span id="cb170-2">    <span class="co" style="color: #5E5E5E;">"Emulate PyMethod_Type in Objects/classobject.c"</span></span>
<span id="cb170-3"></span>
<span id="cb170-4">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, func, obj):</span>
<span id="cb170-5">        <span class="va" style="color: #111111;">self</span>.__func__ <span class="op" style="color: #5E5E5E;">=</span> func</span>
<span id="cb170-6">        <span class="va" style="color: #111111;">self</span>.__self__ <span class="op" style="color: #5E5E5E;">=</span> obj</span>
<span id="cb170-7"></span>
<span id="cb170-8">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__call__</span>(<span class="va" style="color: #111111;">self</span>, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb170-9">        func <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.__func__</span>
<span id="cb170-10">        obj <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.__self__</span>
<span id="cb170-11">        <span class="cf" style="color: #003B4F;">return</span> func(obj, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span>
<span id="cb170-12"></span>
<span id="cb170-13">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="va" style="color: #111111;">self</span>, name):</span>
<span id="cb170-14">        <span class="co" style="color: #5E5E5E;">"Emulate method_getset() in Objects/classobject.c"</span></span>
<span id="cb170-15">        <span class="cf" style="color: #003B4F;">if</span> name <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'__doc__'</span>:</span>
<span id="cb170-16">            <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.__func__.__doc__</span>
<span id="cb170-17">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">object</span>.<span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="va" style="color: #111111;">self</span>, name)</span>
<span id="cb170-18"></span>
<span id="cb170-19">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__getattr__</span>(<span class="va" style="color: #111111;">self</span>, name):</span>
<span id="cb170-20">        <span class="co" style="color: #5E5E5E;">"Emulate method_getattro() in Objects/classobject.c"</span></span>
<span id="cb170-21">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">getattr</span>(<span class="va" style="color: #111111;">self</span>.__func__, name)</span>
<span id="cb170-22"></span>
<span id="cb170-23">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb170-24">        <span class="co" style="color: #5E5E5E;">"Emulate method_descr_get() in Objects/classobject.c"</span></span>
<span id="cb170-25">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span></span></code></pre></div>
</div>
<p>The key dunder method of interest is <code>__call</code>__:</p>
<div class="sourceCode" id="cb171" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb171-1"><span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__call__</span>(<span class="va" style="color: #111111;">self</span>, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb171-2">    func <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.__func__</span>
<span id="cb171-3">    obj <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.__self__</span>
<span id="cb171-4">    <span class="cf" style="color: #003B4F;">return</span> func(obj, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
<p>In the example of the self attention module, it has no positional arguments <code>*args</code> and so when I passed <code>self_attn</code> to the <code>obj</code> parameter in <code>func(obj, *args, **kwargs)</code> it understood it to be the first keyword argument.</p>
<blockquote class="blockquote">
<p>The interesting behavior occurs during dotted access from an instance. The dotted lookup calls <strong>get</strong>() which returns a bound method object:</p>
</blockquote>
<div class="cell" data-execution_count="236">
<div class="sourceCode cell-code" id="cb172" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><span class="kw" style="color: #003B4F;">class</span> D:</span>
<span id="cb172-2">    <span class="kw" style="color: #003B4F;">def</span> f(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb172-3">         <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="d7863453-4518-4486-909a-226a3a4b8b2c" data-execution_count="238">
<div class="sourceCode cell-code" id="cb173" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1">d <span class="op" style="color: #5E5E5E;">=</span> D()</span>
<span id="cb173-2"><span class="bu" style="color: null;">print</span>(d.f)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;bound method D.f of &lt;__main__.D object at 0x78b2dec54790&gt;&gt;</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Internally, the bound method stores the underlying function and the bound instance:</p>
</blockquote>
<div class="cell" data-outputid="e01f04f2-79f4-4fb7-df6d-734f9a3490e7" data-execution_count="240">
<div class="sourceCode cell-code" id="cb175" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><span class="bu" style="color: null;">print</span>(d.f.__func__)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;function D.f at 0x78b2dedd3ba0&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="be868138-560a-4319-d92a-2572e6d78318" data-execution_count="241">
<div class="sourceCode cell-code" id="cb177" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><span class="bu" style="color: null;">print</span>(d.f.__self__)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;__main__.D object at 0x78b2dec54790&gt;</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>If you have ever wondered where <code>self</code> comes from in regular methods or where <code>cls</code> comes from in class methods, this is it!</p>
</blockquote>
</section>
<section id="kinds-of-methods" class="level3">
<h3 class="anchored" data-anchor-id="kinds-of-methods">Kinds of methods</h3>
<p>Here’s the crux of what I was looking for:</p>
<blockquote class="blockquote">
<p>To recap, functions have a <code>__get__()</code> method so that they can be converted to a method when accessed as attributes. The non-data descriptor transforms an <code>obj.f(*args</code>) call into <code>f(obj, *args)</code>. Calling <code>cls.f(*args)</code> becomes <code>f(*args)</code>.</p>
</blockquote>
<p>If I call <code>__get__(d)</code> on <code>d.f</code> it creates a bound method which passes in the object as <code>self</code>, the first argument of a bound method.</p>
<div class="cell" data-outputid="881f67c4-ba12-49a2-f010-d585a5594103" data-execution_count="243">
<div class="sourceCode cell-code" id="cb179" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb179-1"><span class="bu" style="color: null;">print</span>(d.f.<span class="fu" style="color: #4758AB;">__get__</span>(d))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;bound method D.f of &lt;__main__.D object at 0x78b2dec54790&gt;&gt;</code></pre>
</div>
</div>
<p>Now when I call <code>d.f.__get__(d)()</code> I don’t need to explicitly pass in the object:</p>
<div class="cell" data-outputid="b9d99ad4-baa0-4101-b3bc-a8de2a759be3" data-execution_count="244">
<div class="sourceCode cell-code" id="cb181" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1">d.f.<span class="fu" style="color: #4758AB;">__get__</span>(d)()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="244">
<pre><code>&lt;__main__.D at 0x78b2dec54790&gt;</code></pre>
</div>
</div>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>Thanks to vibe coding, Claude introduced me to Python behavior I was unfamiliar with, and thanks to the excellent Python documentation, I understood it at a much deeper level than I was planning to.</p>
<p>I think something that still confuses me, and where I feel empathy for <a href="https://discuss.python.org/t/changing-the-name-of-get-to-bind/14243">this poster</a>, is how <code>__get__</code> has special behavior for functions where it binds it to the given object.</p>
<p>In the Primer, initial examples of <code>__get__</code> all, well, get a value:</p>
<div class="sourceCode" id="cb183" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1"><span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb183-2">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__get__ called with obj=</span><span class="sc" style="color: #5E5E5E;">{</span>obj<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, objtype=</span><span class="sc" style="color: #5E5E5E;">{</span>objtype<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb183-3">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb183-4"></span>
<span id="cb183-5"></span>
<span id="cb183-6"><span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb183-7">    <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">len</span>(os.listdir(obj.dirname))</span>
<span id="cb183-8"></span>
<span id="cb183-9"></span>
<span id="cb183-10"><span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb183-11">    value <span class="op" style="color: #5E5E5E;">=</span> obj._age</span>
<span id="cb183-12">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Accessing age giving </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb183-13">    <span class="cf" style="color: #003B4F;">return</span> value</span></code></pre></div>
<p>How that behavior is related to binding a function to an object is beyond my current understanding.</p>
<p>This poster’s response does make sense:</p>
<blockquote class="blockquote">
<p>If descriptors were only callables that bind as methods when accessed as an attribute, then perhaps <code>__bind__()</code> would be a reasonable name for the method. But the descriptor protocol (i.e.&nbsp;<code>__get__</code>, <code>__set__</code>, and <code>__delete__</code>) is a means of implementing a computed attribute in general, which is not necessarily about binding a callable to the instance or type. For example, the <code>__get__()</code> method of a property named <code>x</code> might return the instance attribute <code>_x</code>.</p>
</blockquote>
<p>So perhaps of a computed attributed is generalizable whether your using <code>__get__</code> on a callable descriptor or otherwise. For a function, the “computation” of the attribute is binding it to the object.</p>
<p>I hope you enjoyed this blog post! I’m trying to <a href="https://www.youtube.com/@vishal_learner">grow my YouTube channel</a> so please give that a look/subscribe.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-01-Python-Descriptor/index.html</guid>
  <pubDate>Tue, 01 Apr 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TIL: Creating a Custom Composer Callback</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-03-30-Composer-Callback/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I’m learning to use LLM-Foundry to finetune SLMs. To better understand what’s going on in the training loop when using Flash Attention 2 (for SmolLM2-135M), I decided to ask Claude to write me a custom callback. Here is my <a href="https://claude.ai/share/9bb6c135-2ffb-42be-91bc-b4e4a6356173">full Claude conversation</a>.</p>
</section>
<section id="initial-plan" class="level2">
<h2 class="anchored" data-anchor-id="initial-plan">Initial Plan</h2>
<p>At first, I was planning to fork Composer (which I did), create a new branch for edits (print statements of datatypes in the <code>Trainer</code> code), and install that repo/branch for training. However, as I was chatting with Claude, it offered an option to write a callback instead. Being that <a href="https://docs.mosaicml.com/projects/composer/en/stable/getting_started/welcome_tour.html#:~:text=This%20is%20based%20on%20the%20two%2Dway%20callback%20system%20from%20(Howard%20et%20al%2C%202020)">this is a core philosophy of how Composer is built</a>, it was a no brainer for me to pursue.</p>
</section>
<section id="first-callback" class="level2">
<h2 class="anchored" data-anchor-id="first-callback">First Callback</h2>
<p>The first callback Claude wrote (I guided it a little bit by feeding it Composer’s <code>trainer.py</code> and giving it their callback example from the docs) was as follows:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;">class</span> WeightDtypeMonitor(Callback):</span>
<span id="cb1-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, backward_log_interval<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb1-3">        <span class="va" style="color: #111111;">self</span>.backward_log_interval <span class="op" style="color: #5E5E5E;">=</span> backward_log_interval</span>
<span id="cb1-4">    </span>
<span id="cb1-5">    <span class="kw" style="color: #003B4F;">def</span> fit_start(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-6">        <span class="va" style="color: #111111;">self</span>._log_dtypes(state, logger, <span class="st" style="color: #20794D;">"fit_start"</span>)</span>
<span id="cb1-7">    </span>
<span id="cb1-8">    <span class="kw" style="color: #003B4F;">def</span> after_backward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-9">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.backward_log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb1-10">            <span class="va" style="color: #111111;">self</span>._log_dtypes(state, logger, <span class="ss" style="color: #20794D;">f"backward_</span><span class="sc" style="color: #5E5E5E;">{</span>state<span class="sc" style="color: #5E5E5E;">.</span>timestamp<span class="sc" style="color: #5E5E5E;">.</span>batch<span class="sc" style="color: #5E5E5E;">.</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-11">    </span>
<span id="cb1-12">    <span class="kw" style="color: #003B4F;">def</span> epoch_end(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-13">        <span class="va" style="color: #111111;">self</span>._log_dtypes(state, logger, <span class="ss" style="color: #20794D;">f"epoch_</span><span class="sc" style="color: #5E5E5E;">{</span>state<span class="sc" style="color: #5E5E5E;">.</span>timestamp<span class="sc" style="color: #5E5E5E;">.</span>epoch<span class="sc" style="color: #5E5E5E;">.</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-14">    </span>
<span id="cb1-15">    <span class="kw" style="color: #003B4F;">def</span> _log_dtypes(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger, prefix: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-16">        model <span class="op" style="color: #5E5E5E;">=</span> state.model</span>
<span id="cb1-17">        logger.log_metrics({</span>
<span id="cb1-18">            <span class="ss" style="color: #20794D;">f"dtype/</span><span class="sc" style="color: #5E5E5E;">{</span>prefix<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/lm_head"</span>: <span class="bu" style="color: null;">str</span>(model.model.base_model.model.lm_head.weight.dtype),</span>
<span id="cb1-19">            <span class="ss" style="color: #20794D;">f"dtype/</span><span class="sc" style="color: #5E5E5E;">{</span>prefix<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/q_proj_base"</span>: <span class="bu" style="color: null;">str</span>(model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.q_proj.base_layer.weight.dtype),</span>
<span id="cb1-20">            <span class="ss" style="color: #20794D;">f"dtype/</span><span class="sc" style="color: #5E5E5E;">{</span>prefix<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/q_proj_lora_A"</span>: <span class="bu" style="color: null;">str</span>(model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.q_proj.lora_A.default.weight.dtype),</span>
<span id="cb1-21">            <span class="ss" style="color: #20794D;">f"dtype/</span><span class="sc" style="color: #5E5E5E;">{</span>prefix<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/q_proj_lora_B"</span>: <span class="bu" style="color: null;">str</span>(model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.q_proj.lora_B.default.weight.dtype)</span>
<span id="cb1-22">        })</span></code></pre></div>
<p>For reference, here is the list of events available in Composer during the training loop:</p>
<pre><code># &lt;INIT&gt;
# &lt;BEFORE_LOAD&gt;
# &lt;AFTER_LOAD&gt;
# &lt;FIT_START&gt;
for epoch in range(NUM_EPOCHS):
    # &lt;EPOCH_START&gt;
    while True:
        # &lt;BEFORE_DATALOADER&gt;
        batch = next(dataloader)
        if batch is None:
            break
        inputs, targets = batch
        # &lt;AFTER_DATALOADER&gt;

        # &lt;BATCH_START&gt;

        # &lt;BEFORE_FORWARD&gt;
        outputs = model.forward(inputs)
        # &lt;AFTER_FORWARD&gt;

        # &lt;BEFORE_LOSS&gt;
        loss = model.loss(outputs, targets)
        # &lt;AFTER_LOSS&gt;

        # &lt;BEFORE_BACKWARD&gt;
        loss.backward()
        # &lt;AFTER_BACKWARD&gt;

        optimizer.step()
        optimizer.zero_grad()

        # &lt;BATCH_END&gt;
    # &lt;EPOCH_END&gt;</code></pre>
<p>For each event I wanted to log data types for, the callback passes <code>state</code> (where the <code>model</code> is stored), <code>logger</code> (to do the logging) and a <code>prefix</code> (to denote what’s being logged). Only every <code>backward_log_interval</code>-th batch’s backward pass is logged, to avoid clutter.</p>
<p>Here is example output:</p>
<pre><code># fit_start
Train dtype/fit_start/lm_head: "torch.float32"
Train dtype/fit_start/q_proj_base: "torch.float32"
Train dtype/fit_start/q_proj_lora_A: "torch.float32" 
Train dtype/fit_start/q_proj_lora_B: "torch.float32"

# after_backward
Train dtype/backward_0/lm_head: "torch.float32"
Train dtype/backward_0/q_proj_base: "torch.float32"
Train dtype/backward_0/q_proj_lora_A: "torch.float32"
Train dtype/backward_0/q_proj_lora_B: "torch.float32"</code></pre>
<p>I was surprised to see that everything was in float32, I thought Flash Attention 2 (FA2) used mixed precision? Note that I haven’t read the FA2 paper.</p>
</section>
<section id="second-callback" class="level2">
<h2 class="anchored" data-anchor-id="second-callback">Second Callback</h2>
<p>Now that I understood a basic logging callback, I asked Claude to generate a callback that would help me see where mixed precision came into play. This one was a bit more involved:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;">class</span> DtypeMonitor(Callback):</span>
<span id="cb4-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, log_interval<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">100</span>):</span>
<span id="cb4-3">        <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">=</span> log_interval</span>
<span id="cb4-4">        <span class="va" style="color: #111111;">self</span>.hooks <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-5">    </span>
<span id="cb4-6">    <span class="kw" style="color: #003B4F;">def</span> fit_start(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-7">        <span class="va" style="color: #111111;">self</span>._log_weight_dtypes(state, logger, <span class="st" style="color: #20794D;">"fit_start"</span>)</span>
<span id="cb4-8">    </span>
<span id="cb4-9">    <span class="kw" style="color: #003B4F;">def</span> before_forward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-10">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb4-11">            <span class="co" style="color: #5E5E5E;"># Log input tensor dtypes</span></span>
<span id="cb4-12">            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(state.batch, <span class="bu" style="color: null;">dict</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="st" style="color: #20794D;">'input_ids'</span> <span class="kw" style="color: #003B4F;">in</span> state.batch:</span>
<span id="cb4-13">                logger.log_metrics({</span>
<span id="cb4-14">                    <span class="st" style="color: #20794D;">"dtype/input/input_ids"</span>: <span class="bu" style="color: null;">str</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>].dtype)</span>
<span id="cb4-15">                })</span>
<span id="cb4-16">            </span>
<span id="cb4-17">            <span class="co" style="color: #5E5E5E;"># Register hooks to capture activation dtypes</span></span>
<span id="cb4-18">            layer <span class="op" style="color: #5E5E5E;">=</span> state.model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn</span>
<span id="cb4-19">            </span>
<span id="cb4-20">            <span class="kw" style="color: #003B4F;">def</span> hook_fn(name):</span>
<span id="cb4-21">                <span class="kw" style="color: #003B4F;">def</span> _hook(module, inputs, outputs):</span>
<span id="cb4-22">                    <span class="co" style="color: #5E5E5E;"># Log input activation dtype</span></span>
<span id="cb4-23">                    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(inputs, <span class="bu" style="color: null;">tuple</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(inputs) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb4-24">                        logger.log_metrics({<span class="ss" style="color: #20794D;">f"dtype/activation/</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_input"</span>: <span class="bu" style="color: null;">str</span>(inputs[<span class="dv" style="color: #AD0000;">0</span>].dtype)})</span>
<span id="cb4-25">                    </span>
<span id="cb4-26">                    <span class="co" style="color: #5E5E5E;"># Log output activation dtype</span></span>
<span id="cb4-27">                    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(outputs, torch.Tensor):</span>
<span id="cb4-28">                        logger.log_metrics({<span class="ss" style="color: #20794D;">f"dtype/activation/</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_output"</span>: <span class="bu" style="color: null;">str</span>(outputs.dtype)})</span>
<span id="cb4-29">                    <span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">isinstance</span>(outputs, <span class="bu" style="color: null;">tuple</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(outputs) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb4-30">                        logger.log_metrics({<span class="ss" style="color: #20794D;">f"dtype/activation/</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_output"</span>: <span class="bu" style="color: null;">str</span>(outputs[<span class="dv" style="color: #AD0000;">0</span>].dtype)})</span>
<span id="cb4-31">                <span class="cf" style="color: #003B4F;">return</span> _hook</span>
<span id="cb4-32">            </span>
<span id="cb4-33">            <span class="co" style="color: #5E5E5E;"># Clear old hooks</span></span>
<span id="cb4-34">            <span class="cf" style="color: #003B4F;">for</span> hook <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.hooks:</span>
<span id="cb4-35">                hook.remove()</span>
<span id="cb4-36">            <span class="va" style="color: #111111;">self</span>.hooks <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-37">            </span>
<span id="cb4-38">            <span class="co" style="color: #5E5E5E;"># Register new hooks</span></span>
<span id="cb4-39">            <span class="va" style="color: #111111;">self</span>.hooks.append(layer.q_proj.register_forward_hook(hook_fn(<span class="st" style="color: #20794D;">"q_proj"</span>)))</span>
<span id="cb4-40">            <span class="va" style="color: #111111;">self</span>.hooks.append(layer.register_forward_hook(hook_fn(<span class="st" style="color: #20794D;">"self_attn"</span>)))</span>
<span id="cb4-41">    </span>
<span id="cb4-42">    <span class="kw" style="color: #003B4F;">def</span> after_forward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-43">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb4-44">            <span class="co" style="color: #5E5E5E;"># Log model output dtype</span></span>
<span id="cb4-45">            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(state.outputs, torch.Tensor):</span>
<span id="cb4-46">                logger.log_metrics({</span>
<span id="cb4-47">                    <span class="st" style="color: #20794D;">"dtype/computation/output"</span>: <span class="bu" style="color: null;">str</span>(state.outputs.dtype)</span>
<span id="cb4-48">                })</span>
<span id="cb4-49">    </span>
<span id="cb4-50">    <span class="kw" style="color: #003B4F;">def</span> after_loss(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-51">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb4-52">            <span class="co" style="color: #5E5E5E;"># Log loss dtype</span></span>
<span id="cb4-53">            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(state.loss, torch.Tensor):</span>
<span id="cb4-54">                logger.log_metrics({</span>
<span id="cb4-55">                    <span class="st" style="color: #20794D;">"dtype/computation/loss"</span>: <span class="bu" style="color: null;">str</span>(state.loss.dtype)</span>
<span id="cb4-56">                })</span>
<span id="cb4-57">            <span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">isinstance</span>(state.loss, <span class="bu" style="color: null;">dict</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="st" style="color: #20794D;">'total'</span> <span class="kw" style="color: #003B4F;">in</span> state.loss:</span>
<span id="cb4-58">                logger.log_metrics({</span>
<span id="cb4-59">                    <span class="st" style="color: #20794D;">"dtype/computation/loss"</span>: <span class="bu" style="color: null;">str</span>(state.loss[<span class="st" style="color: #20794D;">'total'</span>].dtype)</span>
<span id="cb4-60">                })</span>
<span id="cb4-61">    </span>
<span id="cb4-62">    <span class="kw" style="color: #003B4F;">def</span> after_backward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-63">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb4-64">            <span class="va" style="color: #111111;">self</span>._log_weight_dtypes(state, logger, <span class="ss" style="color: #20794D;">f"backward_</span><span class="sc" style="color: #5E5E5E;">{</span>state<span class="sc" style="color: #5E5E5E;">.</span>timestamp<span class="sc" style="color: #5E5E5E;">.</span>batch<span class="sc" style="color: #5E5E5E;">.</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb4-65">            </span>
<span id="cb4-66">            <span class="co" style="color: #5E5E5E;"># Check gradient dtypes</span></span>
<span id="cb4-67">            model <span class="op" style="color: #5E5E5E;">=</span> state.model</span>
<span id="cb4-68">            lora_A <span class="op" style="color: #5E5E5E;">=</span> model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.q_proj.lora_A.default</span>
<span id="cb4-69">            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(lora_A, <span class="st" style="color: #20794D;">'weight'</span>) <span class="kw" style="color: #003B4F;">and</span> lora_A.weight.grad <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-70">                logger.log_metrics({</span>
<span id="cb4-71">                    <span class="st" style="color: #20794D;">"dtype/gradient/q_proj_lora_A"</span>: <span class="bu" style="color: null;">str</span>(lora_A.weight.grad.dtype)</span>
<span id="cb4-72">                })</span>
<span id="cb4-73">    </span>
<span id="cb4-74">    <span class="kw" style="color: #003B4F;">def</span> epoch_end(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-75">        <span class="va" style="color: #111111;">self</span>._log_weight_dtypes(state, logger, <span class="ss" style="color: #20794D;">f"epoch_</span><span class="sc" style="color: #5E5E5E;">{</span>state<span class="sc" style="color: #5E5E5E;">.</span>timestamp<span class="sc" style="color: #5E5E5E;">.</span>epoch<span class="sc" style="color: #5E5E5E;">.</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb4-76">        <span class="co" style="color: #5E5E5E;"># Remove any remaining hooks</span></span>
<span id="cb4-77">        <span class="cf" style="color: #003B4F;">for</span> hook <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.hooks:</span>
<span id="cb4-78">            hook.remove()</span>
<span id="cb4-79">        <span class="va" style="color: #111111;">self</span>.hooks <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-80">    </span>
<span id="cb4-81">    <span class="kw" style="color: #003B4F;">def</span> _log_weight_dtypes(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger, prefix: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-82">        model <span class="op" style="color: #5E5E5E;">=</span> state.model</span>
<span id="cb4-83">        logger.log_metrics({</span>
<span id="cb4-84">            <span class="ss" style="color: #20794D;">f"dtype/</span><span class="sc" style="color: #5E5E5E;">{</span>prefix<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/lm_head"</span>: <span class="bu" style="color: null;">str</span>(model.model.base_model.model.lm_head.weight.dtype),</span>
<span id="cb4-85">            <span class="ss" style="color: #20794D;">f"dtype/</span><span class="sc" style="color: #5E5E5E;">{</span>prefix<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/q_proj_base"</span>: <span class="bu" style="color: null;">str</span>(model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.q_proj.base_layer.weight.dtype),</span>
<span id="cb4-86">            <span class="ss" style="color: #20794D;">f"dtype/</span><span class="sc" style="color: #5E5E5E;">{</span>prefix<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/q_proj_lora_A"</span>: <span class="bu" style="color: null;">str</span>(model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.q_proj.lora_A.default.weight.dtype),</span>
<span id="cb4-87">            <span class="ss" style="color: #20794D;">f"dtype/</span><span class="sc" style="color: #5E5E5E;">{</span>prefix<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/q_proj_lora_B"</span>: <span class="bu" style="color: null;">str</span>(model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.q_proj.lora_B.default.weight.dtype)</span>
<span id="cb4-88">        })</span></code></pre></div>
<p>Fortunately, I had just recently learned about <code>register_forward_hook</code> and created a short TIL video about it:</p>
<div class="quarto-video ratio ratio-16x9"><iframe src="https://www.youtube.com/embed/Y6qgWxU3oO4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>In short, <code>register_forward_hook</code> exposes the forward pass inputs and outputs. You can manipulate both but you have access to inputs/outputs <em>after</em> the forward pass so you can’t change the inputs before they go into the forward pass. Thankfully that restriction doesn’t matter in my case, as I only want to log data types.</p>
<p>Running the training loop with this callback generated the following logs:</p>
<pre><code> Train dtype/input/input_ids: "torch.int64"
 Train dtype/activation/q_proj_input: "torch.float32"
 Train dtype/activation/q_proj_output: "torch.bfloat16"
 Train dtype/activation/self_attn_output: "torch.bfloat16"
 Train dtype/computation/loss: "torch.float32"
 Train dtype/backward_0/lm_head: "torch.float32"
 Train dtype/backward_0/q_proj_base: "torch.float32"
 Train dtype/backward_0/q_proj_lora_A: "torch.float32"
 Train dtype/backward_0/q_proj_lora_B: "torch.float32"
 Train dtype/gradient/q_proj_lora_A: "torch.float32"</code></pre>
<p>This shed some more light into what’s going on! The inputs to <code>q_proj</code> is float32 but the outputs are bfloat16. The loss and gradients are both in float32.</p>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>This exercise has blown up the possibilities available to me for better understanding what goes on during training! I have only gotten a cursory glimpse at the internal mechanism of mixed precision training, but it’s relatively simple for me take this a step further by analyzing more data types during all training events for all model components. That’ll be a future blog post or video this week.</p>
<p>Thanks for reading! Lots more content on my <a href="https://www.youtube.com/@vishal_learner">YouTube channel</a> that I’m working on growing this year so please subscribe to stay in the loop.</p>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-03-30-Composer-Callback/index.html</guid>
  <pubDate>Sun, 30 Mar 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>RAGatouille/ColBERT Indexing Deep Dive</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-03-12-RAGatouille-ColBERT-Indexing-Deep-Dive/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post I dive deeply into the internals of the RAGatouille and ColBERT libraries to understand the intermediate steps taken when building an index for a collection of documents.</p>
<ul>
<li>RAGatouille
<ul>
<li>ragatouille/RAGPretrainedModel.py
<ul>
<li><a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/RAGPretrainedModel.py#L129"><code>_process_corpus</code></a></li>
<li><a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/RAGPretrainedModel.py#L171"><code>index</code></a></li>
</ul></li>
<li>ragatouille/models/colbert.py
<ul>
<li><a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/colbert.py#L294"><code>index</code></a></li>
</ul></li>
<li>ragatouille/models/index.py
<ul>
<li><a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L460"><code>ModelIndexFactory.construct</code></a></li>
<li><a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L132"><code>PLAIDModelIndex.construct</code></a></li>
<li><a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L156"><code>PLAIDModelIndex.build</code></a></li>
<li><a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L212"><code>indexer.index</code></a></li>
</ul></li>
</ul></li>
<li>ColBERT
<ul>
<li>colbert/indexer.py
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexer.py#L85"><code>Launcher(encode)</code></a></li>
</ul></li>
<li>colbert/indexing/collection_indexer.py
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L31"><code>encode</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L51"><code>Collection.cast</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L61"><code>CollectionIndexer.run</code></a>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L80"><code>CollectionIndexer.setup</code></a>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L114"><code>CollectionIndexer._sample_pids</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L133"><code>CollectionIndexer._sample_embeddings</code></a>
<ul>
<li>colbert/indexing/collection_encoder.py: <a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_encoder.py#L13"><code>CollectionEncoder.encode_passages</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/modeling/checkpoint.py#L122"><code>Checkpoint.docFromText</code></a>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/modeling/colbert.py#L95"><code>ColBERT.doc</code></a></li>
</ul></li>
</ul></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L210"><code>CollectionIndexer._save_plan</code></a></li>
</ul></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L226"><code>CollectionIndexer.train</code></a>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L500"><code>compute_faiss_kmeans</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L314"><code>CollectionIndexer._compute_avg_residual</code></a>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/codecs/residual.py#L204"><code>ResidualCodec.compress_into_codes</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/codecs/residual.py#L222"><code>ResidualCodec.lookup_centroids</code></a></li>
</ul></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/index_saver.py#L17"><code>IndexSaver.save_codec</code></a></li>
</ul></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L346"><code>CollectionIndexer.index</code></a>
<ul>
<li>colbert/indexing/collection_encoder.py: <a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_encoder.py#L13"><code>CollectionEncoder.encode_passages</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/index_saver.py#L70"><code>IndexSaver.save_chunk</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/codecs/residual.py#L167"><code>ResidualCodec.compress</code></a>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/codecs/residual.py#L186"><code>ResidualCodec.binarize</code></a></li>
</ul></li>
</ul></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L378"><code>CollectionIndexer.finalize</code></a>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L438"><code>CollectionIndexer._build_ivf</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/utils.py#L8"><code>optimize_ivf</code></a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/collection_indexer.py#L484"><code>CollectionIndexer._update_metadata</code></a></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;">!</span>pip install datasets ragatouille <span class="op" style="color: #5E5E5E;">-</span>qq</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb2-2"><span class="im" style="color: #00769E;">from</span> ragatouille <span class="im" style="color: #00769E;">import</span> RAGPretrainedModel</span>
<span id="cb2-3"><span class="im" style="color: #00769E;">from</span> fastcore.utils <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb2-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb2-5"><span class="im" style="color: #00769E;">import</span> srsly</span>
<span id="cb2-6"><span class="im" style="color: #00769E;">import</span> uuid</span>
<span id="cb2-7"><span class="im" style="color: #00769E;">from</span> ragatouille.data <span class="im" style="color: #00769E;">import</span> CorpusProcessor</span>
<span id="cb2-8"><span class="im" style="color: #00769E;">from</span> llama_index.core.text_splitter <span class="im" style="color: #00769E;">import</span> SentenceSplitter</span>
<span id="cb2-9"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb2-10"><span class="im" style="color: #00769E;">from</span> ragatouille.models.index <span class="im" style="color: #00769E;">import</span> PLAIDModelIndex</span>
<span id="cb2-11"><span class="im" style="color: #00769E;">from</span> colbert.infra <span class="im" style="color: #00769E;">import</span> ColBERTConfig, RunConfig</span>
<span id="cb2-12"><span class="im" style="color: #00769E;">from</span> colbert.data.collection <span class="im" style="color: #00769E;">import</span> Collection</span>
<span id="cb2-13"><span class="im" style="color: #00769E;">from</span> colbert.modeling.checkpoint <span class="im" style="color: #00769E;">import</span> Checkpoint</span>
<span id="cb2-14"><span class="im" style="color: #00769E;">from</span> colbert.indexing.collection_encoder <span class="im" style="color: #00769E;">import</span> CollectionEncoder</span>
<span id="cb2-15"><span class="im" style="color: #00769E;">from</span> colbert.indexing.collection_indexer <span class="im" style="color: #00769E;">import</span> CollectionIndexer</span>
<span id="cb2-16"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb2-17"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb2-18"><span class="im" style="color: #00769E;">from</span> colbert.indexing.collection_indexer <span class="im" style="color: #00769E;">import</span> compute_faiss_kmeans</span>
<span id="cb2-19"><span class="im" style="color: #00769E;">from</span> sklearn.decomposition <span class="im" style="color: #00769E;">import</span> PCA</span>
<span id="cb2-20"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb2-21"><span class="im" style="color: #00769E;">from</span> colbert.indexing.codecs.residual <span class="im" style="color: #00769E;">import</span> ResidualCodec</span>
<span id="cb2-22"><span class="im" style="color: #00769E;">from</span> colbert.utils.utils <span class="im" style="color: #00769E;">import</span> flatten</span>
<span id="cb2-23"><span class="im" style="color: #00769E;">import</span> tqdm</span></code></pre></div>
</div>
<div class="cell" data-outputid="48a0a8b7-2a76-40ef-f24a-3d0c8f01860b" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">def</span> set_all_seeds(seed<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">123</span>):</span>
<span id="cb3-2">    <span class="co" style="color: #5E5E5E;">"""Set seeds for all random number generators"""</span></span>
<span id="cb3-3">    <span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb3-4">    <span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb3-5">    <span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb3-6">    <span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb3-7"></span>
<span id="cb3-8">    <span class="co" style="color: #5E5E5E;"># Python's random module</span></span>
<span id="cb3-9">    random.seed(seed)</span>
<span id="cb3-10"></span>
<span id="cb3-11">    <span class="co" style="color: #5E5E5E;"># NumPy</span></span>
<span id="cb3-12">    np.random.seed(seed)</span>
<span id="cb3-13"></span>
<span id="cb3-14">    <span class="co" style="color: #5E5E5E;"># PyTorch</span></span>
<span id="cb3-15">    torch.manual_seed(seed)</span>
<span id="cb3-16">    <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available():</span>
<span id="cb3-17">        torch.cuda.manual_seed(seed)</span>
<span id="cb3-18">        torch.cuda.manual_seed_all(seed)  <span class="co" style="color: #5E5E5E;"># For multi-GPU</span></span>
<span id="cb3-19"></span>
<span id="cb3-20">    <span class="co" style="color: #5E5E5E;"># Set PYTHONHASHSEED for reproducibility across runs</span></span>
<span id="cb3-21">    os.environ[<span class="st" style="color: #20794D;">'PYTHONHASHSEED'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(seed)</span>
<span id="cb3-22"></span>
<span id="cb3-23">    <span class="co" style="color: #5E5E5E;"># Set deterministic algorithms for PyTorch</span></span>
<span id="cb3-24">    torch.backends.cudnn.deterministic <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb3-25">    torch.backends.cudnn.benchmark <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb3-26"></span>
<span id="cb3-27">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"All seeds set to </span><span class="sc" style="color: #5E5E5E;">{</span>seed<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb3-28"></span>
<span id="cb3-29"><span class="co" style="color: #5E5E5E;"># Call this at the beginning of your script</span></span>
<span id="cb3-30">set_all_seeds(<span class="dv" style="color: #AD0000;">123</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>All seeds set to 123</code></pre>
</div>
</div>
</section>
<section id="ragatouille-rag.index" class="level2">
<h2 class="anchored" data-anchor-id="ragatouille-rag.index">RAGatouille <code>RAG.index</code></h2>
<p>Everything in this notebook will be compared to what’s generated with <code>RAG.index</code>.</p>
<p>For this exercise, I’ll use 1000 passages from the UKPLab/DAPR ConditionalQA dataset.</p>
<div class="cell" data-outputid="7e33ac84-a51a-4f14-bd44-d14716248acd" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">passages <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"ConditionalQA-corpus"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test[:1000]"</span>)</span>
<span id="cb5-2">passages</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: 
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a0c3f7d9bbee4b7db19b8050f440b0ab","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c39bb21b350347678bee62cb857f9e99","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"caae6430636d4781a9d42a33bb39b203","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Dataset({
    features: ['_id', 'text', 'title', 'doc_id', 'paragraph_no', 'total_paragraphs', 'is_candidate'],
    num_rows: 1000
})</code></pre>
</div>
</div>
<div class="cell" data-outputid="f796ba22-e08b-459f-a2de-80af227ab588" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">passages[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'text'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>'Overview'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">model_nm <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="3b8db5f6-6d4e-4e74-b628-ab197b09d564" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">RAG <span class="op" style="color: #5E5E5E;">=</span> RAGPretrainedModel.from_pretrained(model_nm)</span>
<span id="cb11-2">index_path <span class="op" style="color: #5E5E5E;">=</span> RAG.index(index_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"cqa_index"</span>, collection<span class="op" style="color: #5E5E5E;">=</span>passages[<span class="st" style="color: #20794D;">'text'</span>])</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"84a8a4d001ab4ddc9cc43766750856cb","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3d8bdabc4fb24e89829a523480a4bff0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"88424e552e604d548a38219144b45b13","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e607d9321eb047b5aeac1e38a4da9e35","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fd3556a3f0e942db8ccfb750453de036","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fb94def1a1c341108f6aad992b5cd66f","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"566b3397334148e5a490173a285cf92d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6613c12c3da94caf9a022f77525b9918","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler()</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>---- WARNING! You are using PLAID with an experimental replacement for FAISS for greater compatibility ----
This is a behaviour change from RAGatouille 0.8.0 onwards.
This works fine for most users and smallish datasets, but can be considerably slower than FAISS and could cause worse results in some situations.
If you're confident with FAISS working on your machine, pass use_faiss=True to revert to the FAISS-using behaviour.
--------------------


[Mar 13, 01:15:09] #&gt; Creating directory .ragatouille/colbert/indexes/cqa_index 


[Mar 13, 01:15:11] [0]       #&gt; Encoding 1000 passages..</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast() if self.activated else NullContextManager()</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Mar 13, 01:15:14] [0]       avg_doclen_est = 15.197999954223633     len(local_sample) = 1,000
[Mar 13, 01:15:14] [0]       Creating 1,024 partitions.
[Mar 13, 01:15:14] [0]       *Estimated* 15,197 embeddings.
[Mar 13, 01:15:14] [0]       #&gt; Saving the indexing plan to .ragatouille/colbert/indexes/cqa_index/plan.json ..</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/indexing/collection_indexer.py:256: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  sub_sample = torch.load(sub_sample_path)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>used 20 iterations (0.5189s) to cluster 14439 items into 1024 clusters
[Mar 13, 01:15:14] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Mar 13, 01:16:51] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.015, 0.016, 0.015, 0.015, 0.013, 0.016, 0.015, 0.016, 0.017, 0.014, 0.013, 0.015, 0.017, 0.014, 0.015, 0.017, 0.014, 0.015, 0.015, 0.014, 0.015, 0.016, 0.015, 0.015, 0.014, 0.014, 0.015, 0.015, 0.015, 0.015, 0.014, 0.014, 0.015, 0.014, 0.015, 0.015, 0.014, 0.015, 0.016, 0.015, 0.014, 0.015, 0.015, 0.014, 0.014, 0.017, 0.016, 0.017, 0.014, 0.015, 0.016, 0.015, 0.016, 0.016, 0.012, 0.015, 0.016, 0.015, 0.016, 0.016, 0.015, 0.015, 0.016, 0.014, 0.015, 0.017, 0.016, 0.015, 0.014, 0.015, 0.015, 0.015, 0.014, 0.016, 0.016, 0.016, 0.014, 0.015, 0.015, 0.014, 0.014, 0.014, 0.016, 0.015, 0.016, 0.015, 0.014, 0.014, 0.014, 0.015, 0.016, 0.014, 0.014, 0.016, 0.014, 0.015]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/indexing/codecs/residual.py:141: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  centroids = torch.load(centroids_path, map_location='cpu')
/usr/local/lib/python3.11/dist-packages/colbert/indexing/codecs/residual.py:142: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  avg_residual = torch.load(avgresidual_path, map_location='cpu')
/usr/local/lib/python3.11/dist-packages/colbert/indexing/codecs/residual.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  bucket_cutoffs, bucket_weights = torch.load(buckets_path, map_location='cpu')
0it [00:00, ?it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Mar 13, 01:18:16] [0]       #&gt; Encoding 1000 passages..</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast() if self.activated else NullContextManager()
1it [00:00,  1.39it/s]
  0%|          | 0/1 [00:00&lt;?, ?it/s]/usr/local/lib/python3.11/dist-packages/colbert/indexing/codecs/residual_embeddings.py:86: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  return torch.load(codes_path, map_location='cpu')
100%|██████████| 1/1 [00:00&lt;00:00, 787.81it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Mar 13, 01:18:16] #&gt; Optimizing IVF to store map from centroids to list of pids..
[Mar 13, 01:18:16] #&gt; Building the emb2pid mapping..
[Mar 13, 01:18:16] len(emb2pid) = 15198</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
100%|██████████| 1024/1024 [00:00&lt;00:00, 61154.86it/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[Mar 13, 01:18:16] #&gt; Saved optimized IVF to .ragatouille/colbert/indexes/cqa_index/ivf.pid.pt
Done indexing!</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<div class="cell" data-outputid="43f5fe3b-967d-4ee9-c806-a6cf68612e98" data-execution_count="8">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">index_path <span class="op" style="color: #5E5E5E;">=</span> Path(index_path)</span>
<span id="cb29-2">index_path</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Path('.ragatouille/colbert/indexes/cqa_index')</code></pre>
</div>
</div>
<div class="cell" data-outputid="cf51663d-a6b5-46a1-c3e4-64054d65c53a" data-execution_count="9">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> index_path.ls(): <span class="bu" style="color: null;">print</span>(o)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>.ragatouille/colbert/indexes/cqa_index/buckets.pt
.ragatouille/colbert/indexes/cqa_index/collection.json
.ragatouille/colbert/indexes/cqa_index/metadata.json
.ragatouille/colbert/indexes/cqa_index/ivf.pid.pt
.ragatouille/colbert/indexes/cqa_index/doclens.0.json
.ragatouille/colbert/indexes/cqa_index/0.residuals.pt
.ragatouille/colbert/indexes/cqa_index/centroids.pt
.ragatouille/colbert/indexes/cqa_index/0.metadata.json
.ragatouille/colbert/indexes/cqa_index/plan.json
.ragatouille/colbert/indexes/cqa_index/0.codes.pt
.ragatouille/colbert/indexes/cqa_index/avg_residual.pt
.ragatouille/colbert/indexes/cqa_index/pid_docid_map.json</code></pre>
</div>
</div>
<p>While it’s a bit tedious to do so (since I’m chomping at the bit to get to the deep dive!) I think it’s worth analyzing the contents of each of these files, as we’ll be recreating them in this notebook.</p>
<section id="buckets.pt" class="level3">
<h3 class="anchored" data-anchor-id="buckets.pt">buckets.pt</h3>
<p>Looking at <a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/codecs/residual.py#L160">Line 160</a> of the ColBERT repo’s <code>residual.py</code>, buckets.py stores bucket_cutoffs and bucket_weights. We’ll go into detail into what these exactly are later on.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">_bucket_cutoffs, _bucket_weights <span class="op" style="color: #5E5E5E;">=</span> torch.load(index_path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'buckets.pt'</span>, weights_only<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="21050d94-0825-497b-80a5-cc4123b93ac0" data-execution_count="11">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">_bucket_cutoffs.shape, _bucket_weights.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(torch.Size([15]), torch.Size([16]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="9bc408df-7960-4f11-a4bf-21989452487c" data-execution_count="12">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">_bucket_cutoffs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor([-0.0307, -0.0205, -0.0146, -0.0099, -0.0064, -0.0037, -0.0016,  0.0000,
         0.0017,  0.0038,  0.0066,  0.0102,  0.0150,  0.0211,  0.0313],
       device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="4368b89d-459e-4270-a55e-c200fad278c5" data-execution_count="13">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">_bucket_weights</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([-0.0411, -0.0247, -0.0173, -0.0121, -0.0081, -0.0050, -0.0026, -0.0007,
         0.0007,  0.0027,  0.0052,  0.0083,  0.0124,  0.0178,  0.0253,  0.0421],
       device='cuda:0', dtype=torch.float16)</code></pre>
</div>
</div>
</section>
<section id="residuals.pt" class="level3">
<h3 class="anchored" data-anchor-id="residuals.pt">0.residuals.pt</h3>
<p>IIUC, there are 15198 tokens in our collection, each with a 48-dimension vector representation, and each integer value represents two 4-bit codes that each correspond to a quantized value. So there are actually 96 values in each vector.</p>
<div class="cell" data-outputid="f41f7dd3-b478-4bb8-a3be-9fa16b012687" data-execution_count="14">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">_residuals <span class="op" style="color: #5E5E5E;">=</span> torch.load(index_path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'0.residuals.pt'</span>, weights_only<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb40-2">_residuals</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([[ 30, 225, 225,  ..., 238, 238,  30],
        [230,  22, 158,  ..., 233, 106, 170],
        [238, 238, 238,  ..., 238, 238, 238],
        ...,
        [ 43,  22,  23,  ..., 104,  31, 208],
        [222, 254,  91,  ..., 128,   8, 189],
        [229,  82,  22,  ..., 170,  94, 154]], dtype=torch.uint8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="00b115a3-0966-477c-b933-a9ce207a0e22" data-execution_count="15">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">_residuals.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>torch.Size([15198, 48])</code></pre>
</div>
</div>
<div class="cell" data-outputid="bdd729b1-6b9b-48bd-ac9b-753df5045ba7" data-execution_count="16">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="dv" style="color: #AD0000;">48</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">4</span><span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>96.0</code></pre>
</div>
</div>
</section>
<section id="ivf.pid.pt" class="level3">
<h3 class="anchored" data-anchor-id="ivf.pid.pt">ivf.pid.pt</h3>
<p>IIRC, <code>ivf</code> contains a flattened sequence of passage IDs corresponding to each centroid. There are 1024 centroids and the first 8 passage IDs in <code>ivf</code> correspond to the 0-th centroid.</p>
<div class="cell" data-outputid="c5627cea-ba7c-411f-9d79-67d80cfa25d8" data-execution_count="17">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">_ivf, _ivf_lengths <span class="op" style="color: #5E5E5E;">=</span> torch.load(index_path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'ivf.pid.pt'</span>, weights_only<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb46-2">_ivf.shape, _ivf_lengths.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>(torch.Size([11759]), torch.Size([1024]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="ed2b73e1-c8b7-4f2b-bed0-c2eca6183261" data-execution_count="18">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1">_ivf[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor([895, 896, 902, 904, 909], dtype=torch.int32)</code></pre>
</div>
</div>
<div class="cell" data-outputid="792c0d0f-a376-451e-8395-d05a7ecb44e3" data-execution_count="19">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">_ivf_lengths[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor(8)</code></pre>
</div>
</div>
</section>
<section id="metadata.json" class="level3">
<h3 class="anchored" data-anchor-id="metadata.json">0.metadata.json</h3>
<p>There are 1000 passages totaling 15198 tokens.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="kw" style="color: #003B4F;">def</span> load_json(path, filename): <span class="cf" style="color: #003B4F;">return</span> srsly.read_json(<span class="bu" style="color: null;">str</span>(Path(path) <span class="op" style="color: #5E5E5E;">/</span> filename))</span></code></pre></div>
</div>
<div class="cell" data-outputid="5271803e-f8e9-4608-8c89-ffe2bf71f511" data-execution_count="21">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">load_json(index_path, <span class="st" style="color: #20794D;">"0.metadata.json"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>{'passage_offset': 0,
 'num_passages': 1000,
 'num_embeddings': 15198,
 'embedding_offset': 0}</code></pre>
</div>
</div>
</section>
<section id="collection.json" class="level3">
<h3 class="anchored" data-anchor-id="collection.json">collection.json</h3>
<p>This JSON contains, as a list, the strings of the 1000 passages in our collection.</p>
<div class="cell" data-outputid="f9f4876a-5fc7-446c-8477-c4e6846aeb73" data-execution_count="22">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">_collection <span class="op" style="color: #5E5E5E;">=</span> load_json(index_path, <span class="st" style="color: #20794D;">"collection.json"</span>)</span>
<span id="cb55-2"><span class="bu" style="color: null;">len</span>(_collection), _collection[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>(1000, 'Overview')</code></pre>
</div>
</div>
</section>
<section id="avg_residual.pt" class="level3">
<h3 class="anchored" data-anchor-id="avg_residual.pt">avg_residual.pt</h3>
<p>I believe this is the average residual across the 15198 tokens (i.e.&nbsp;the average distance in vector-space between the tokens and their closest centroids).</p>
<div class="cell" data-outputid="ddcc0531-f023-458e-99cf-e1042dd6cec7" data-execution_count="23">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">_avg_residual <span class="op" style="color: #5E5E5E;">=</span> torch.load(index_path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'avg_residual.pt'</span>, weights_only<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb57-2">_avg_residual</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor(0.0150, device='cuda:0', dtype=torch.float16)</code></pre>
</div>
</div>
</section>
<section id="doclens.0.json" class="level3">
<h3 class="anchored" data-anchor-id="doclens.0.json">doclens.0.json</h3>
<p>This contains a mapping (list) between passages IDs (indices) and the number of tokens in the document (values).</p>
<div class="cell" data-outputid="a9af0411-007e-440f-d78d-16219ef8cdd0" data-execution_count="24">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">_doclens <span class="op" style="color: #5E5E5E;">=</span> load_json(index_path, <span class="st" style="color: #20794D;">"doclens.0.json"</span>)</span>
<span id="cb59-2"><span class="bu" style="color: null;">len</span>(_doclens), _doclens[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>(1000, [4, 20, 18, 23, 8])</code></pre>
</div>
</div>
<div class="cell" data-outputid="64fb7278-8964-4a4a-fa37-d2f490e5f7bf" data-execution_count="142">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><span class="bu" style="color: null;">sum</span>(doclens)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="142">
<pre><code>15198</code></pre>
</div>
</div>
</section>
<section id="metadata.json-1" class="level3">
<h3 class="anchored" data-anchor-id="metadata.json-1">metadata.json</h3>
<p>Lots of information in here, will highlight the number of centroids and the number of token embeddings in the collection:</p>
<pre><code>'num_partitions': 1024,
'num_embeddings': 15198</code></pre>
<div class="cell" data-outputid="05ffedca-2da2-4a9b-f4b1-4e9325ecac06" data-execution_count="25">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">load_json(index_path, <span class="st" style="color: #20794D;">"metadata.json"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>{'config': {'query_token_id': '[unused0]',
  'doc_token_id': '[unused1]',
  'query_token': '[Q]',
  'doc_token': '[D]',
  'ncells': None,
  'centroid_score_threshold': None,
  'ndocs': None,
  'load_index_with_mmap': False,
  'index_path': None,
  'index_bsize': 32,
  'nbits': 4,
  'kmeans_niters': 20,
  'resume': False,
  'pool_factor': 1,
  'clustering_mode': 'hierarchical',
  'protected_tokens': 0,
  'similarity': 'cosine',
  'bsize': 64,
  'accumsteps': 1,
  'lr': 1e-05,
  'maxsteps': 15626,
  'save_every': None,
  'warmup': 781,
  'warmup_bert': None,
  'relu': False,
  'nway': 32,
  'use_ib_negatives': False,
  'reranker': False,
  'distillation_alpha': 1.0,
  'ignore_scores': False,
  'model_name': 'answerdotai/AnswerAI-ColBERTv2.5-small',
  'query_maxlen': 32,
  'attend_to_mask_tokens': False,
  'interaction': 'colbert',
  'dim': 96,
  'doc_maxlen': 256,
  'mask_punctuation': True,
  'checkpoint': 'answerdotai/answerai-colbert-small-v1',
  'triples': '/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl',
  'collection': ['list with 1000 elements starting with...',
   ['Overview',
    'You can only make a claim for Child Tax Credit if you already get Working Tax Credit.',
    'If you cannot apply for Child Tax Credit, you can apply for Universal Credit instead.']],
  'queries': '/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv',
  'index_name': 'cqa_index',
  'overwrite': False,
  'root': '.ragatouille/',
  'experiment': 'colbert',
  'index_root': None,
  'name': '2025-03/13/01.14.35',
  'rank': 0,
  'nranks': 1,
  'amp': True,
  'gpus': 1,
  'avoid_fork_if_possible': False},
 'num_chunks': 1,
 'num_partitions': 1024,
 'num_embeddings': 15198,
 'avg_doclen': 15.198,
 'RAGatouille': {'index_config': {'index_type': 'PLAID',
   'index_name': 'cqa_index'}}}</code></pre>
</div>
</div>
</section>
<section id="centroids.pt" class="level3">
<h3 class="anchored" data-anchor-id="centroids.pt">centroids.pt</h3>
<p>There are 1024 96-dimension centroid vectors stored.</p>
<div class="cell" data-outputid="56aaee76-7ad0-4269-f01b-aaeafc824b29" data-execution_count="26">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1">_centroids <span class="op" style="color: #5E5E5E;">=</span> torch.load(index_path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'centroids.pt'</span>, weights_only<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb66-2">_centroids.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>torch.Size([1024, 96])</code></pre>
</div>
</div>
<p>They store the full uncompressed values for the centroids.</p>
<div class="cell" data-outputid="0ade9405-521f-46f7-c241-fa63dadfb05c" data-execution_count="27">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1">_centroids[<span class="dv" style="color: #AD0000;">0</span>][:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([-0.0649,  0.1193, -0.0551,  0.0561, -0.0826], device='cuda:0',
       dtype=torch.float16)</code></pre>
</div>
</div>
</section>
<section id="codes.pt" class="level3">
<h3 class="anchored" data-anchor-id="codes.pt">0.codes.pt</h3>
<p>I believe this is a mapping (list) between tokens (indices) and centroid IDs (values).</p>
<div class="cell" data-outputid="7128258c-5e5b-4b15-f877-f157d71d2bd4" data-execution_count="28">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1">_codes <span class="op" style="color: #5E5E5E;">=</span> torch.load(index_path<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'0.codes.pt'</span>, weights_only<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb70-2">_codes.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>torch.Size([15198])</code></pre>
</div>
</div>
<div class="cell" data-outputid="62d80166-6b60-45db-8305-fab765339cbb" data-execution_count="29">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1">_codes[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor([138, 843, 273, 138, 561], dtype=torch.int32)</code></pre>
</div>
</div>
</section>
<section id="pid_docid_map.json" class="level3">
<h3 class="anchored" data-anchor-id="pid_docid_map.json">pid_docid_map.json</h3>
<p>A mapping between passage ID (0-999) and document ID (UUID).</p>
<div class="cell" data-outputid="e16d0b3d-96c4-4a25-b2b0-b61aa712aa97" data-execution_count="30">
<div class="sourceCode cell-code" id="cb74" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1">_pid_docid_map <span class="op" style="color: #5E5E5E;">=</span> load_json(index_path, <span class="st" style="color: #20794D;">"pid_docid_map.json"</span>)</span>
<span id="cb74-2">_pid_docid_map[<span class="st" style="color: #20794D;">'999'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>'2be086c6-04cc-4d73-b372-08236f76cbe6'</code></pre>
</div>
</div>
</section>
<section id="plan.json" class="level3">
<h3 class="anchored" data-anchor-id="plan.json">plan.json</h3>
<p>This seems to contain the same information as metadata.json.</p>
<div class="cell" data-outputid="4a7d667f-74ca-4a32-8a34-43d295ef9d52" data-execution_count="31">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1">_plan <span class="op" style="color: #5E5E5E;">=</span> load_json(index_path, <span class="st" style="color: #20794D;">"plan.json"</span>)</span>
<span id="cb76-2">_plan</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>{'config': {'query_token_id': '[unused0]',
  'doc_token_id': '[unused1]',
  'query_token': '[Q]',
  'doc_token': '[D]',
  'ncells': None,
  'centroid_score_threshold': None,
  'ndocs': None,
  'load_index_with_mmap': False,
  'index_path': None,
  'index_bsize': 32,
  'nbits': 4,
  'kmeans_niters': 20,
  'resume': False,
  'pool_factor': 1,
  'clustering_mode': 'hierarchical',
  'protected_tokens': 0,
  'similarity': 'cosine',
  'bsize': 64,
  'accumsteps': 1,
  'lr': 1e-05,
  'maxsteps': 15626,
  'save_every': None,
  'warmup': 781,
  'warmup_bert': None,
  'relu': False,
  'nway': 32,
  'use_ib_negatives': False,
  'reranker': False,
  'distillation_alpha': 1.0,
  'ignore_scores': False,
  'model_name': 'answerdotai/AnswerAI-ColBERTv2.5-small',
  'query_maxlen': 32,
  'attend_to_mask_tokens': False,
  'interaction': 'colbert',
  'dim': 96,
  'doc_maxlen': 256,
  'mask_punctuation': True,
  'checkpoint': 'answerdotai/answerai-colbert-small-v1',
  'triples': '/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl',
  'collection': ['list with 1000 elements starting with...',
   ['Overview',
    'You can only make a claim for Child Tax Credit if you already get Working Tax Credit.',
    'If you cannot apply for Child Tax Credit, you can apply for Universal Credit instead.']],
  'queries': '/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv',
  'index_name': 'cqa_index',
  'overwrite': False,
  'root': '.ragatouille/',
  'experiment': 'colbert',
  'index_root': None,
  'name': '2025-03/13/01.14.35',
  'rank': 0,
  'nranks': 1,
  'amp': True,
  'gpus': 1,
  'avoid_fork_if_possible': False},
 'num_chunks': 1,
 'num_partitions': 1024,
 'num_embeddings_est': 15197.999954223633,
 'avg_doclen_est': 15.197999954223633}</code></pre>
</div>
</div>
<p>In the following sections, I’ll try to recreate each of these <code>index_path</code> elements.</p>
</section>
</section>
<section id="process_corpus" class="level2">
<h2 class="anchored" data-anchor-id="process_corpus">_process_corpus</h2>
<p>Inside <code>RAG.index</code>, <code>_process_corpus</code> is called on the documents and document IDs.</p>
<div class="cell" data-outputid="91ca6abf-bd88-4652-efd4-a4b2b77907c2" data-execution_count="32">
<div class="sourceCode cell-code" id="cb78" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1">passage_ids <span class="op" style="color: #5E5E5E;">=</span> [<span class="bu" style="color: null;">str</span>(uuid.uuid4()) <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(passages))]</span>
<span id="cb78-2">passage_ids[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>'d4cdfec5-a949-43e0-94b3-feb24caeac5e'</code></pre>
</div>
</div>
<p>Use the corpus processor to convert the passages into <code>{'document_id': '...', 'content': '...'}</code> dictionaries with 256-token max length.</p>
<div class="cell" data-outputid="40335ff4-def8-4944-8c0b-157d7823934b" data-execution_count="33">
<div class="sourceCode cell-code" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1">cp <span class="op" style="color: #5E5E5E;">=</span> CorpusProcessor()</span>
<span id="cb80-2">cp</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>&lt;ragatouille.data.corpus_processor.CorpusProcessor at 0x794fa0323690&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="dd183218-3093-4c9b-e4f5-7f31c5b9517b" data-execution_count="34">
<div class="sourceCode cell-code" id="cb82" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1">collection_with_ids <span class="op" style="color: #5E5E5E;">=</span> cp.process_corpus(passages[<span class="st" style="color: #20794D;">'text'</span>], passage_ids, chunk_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>)</span>
<span id="cb82-2"><span class="bu" style="color: null;">len</span>(collection_with_ids), collection_with_ids[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>(1000,
 {'document_id': 'd4cdfec5-a949-43e0-94b3-feb24caeac5e',
  'content': 'Overview'})</code></pre>
</div>
</div>
<p>As a brief aside, I’ll take a look at the maximum token length of the passages.</p>
<div class="cell" data-outputid="8bba83eb-1120-4e91-819c-c2d0e5315a93" data-execution_count="35">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1">node_parser <span class="op" style="color: #5E5E5E;">=</span> SentenceSplitter(chunk_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>)</span>
<span id="cb84-2">node_parser._token_size</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<div style="max-width:800px; border: 1px solid var(--colab-border-color);"><style>
      pre.function-repr-contents {
        overflow-x: auto;
        padding: 8px 12px;
        max-height: 500px;
      }

      pre.function-repr-contents.function-repr-contents-collapsed {
        cursor: pointer;
        max-height: 100px;
      }
    </style>
    <pre style="white-space: initial; background:
         var(--colab-secondary-surface-color); padding: 8px 12px;
         border-bottom: 1px solid var(--colab-border-color);"><b>llama_index.core.node_parser.text.sentence.SentenceSplitter._token_size</b><br>def _token_size(text: str) -&gt; int</pre><pre class="function-repr-contents function-repr-contents-collapsed" style="">/usr/local/lib/python3.11/dist-packages/llama_index/core/node_parser/text/sentence.py&lt;no docstring&gt;</pre>
      <script>
      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {
        for (const element of document.querySelectorAll('.filepath')) {
          element.style.display = 'block'
          element.onclick = (event) => {
            event.preventDefault();
            event.stopPropagation();
            google.colab.files.view(element.textContent, 307);
          };
        }
      }
      for (const element of document.querySelectorAll('.function-repr-contents')) {
        element.onclick = (event) => {
          event.preventDefault();
          event.stopPropagation();
          element.classList.toggle('function-repr-contents-collapsed');
        };
      }
      </script>
      </div>
</div>
</div>
<div class="cell" data-outputid="e76d0bf8-1cb0-4106-bbfc-a3afaf329571" data-execution_count="36">
<div class="sourceCode cell-code" id="cb85" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1">tk_szs <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb85-2"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> passages[<span class="st" style="color: #20794D;">'text'</span>]: tk_szs.append(node_parser._token_size(p))</span>
<span id="cb85-3">pd.Series(tk_szs).describe()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>13.217000</td>
    </tr>
    <tr>
      <th>std</th>
      <td>10.192635</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>10.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>19.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>65.000000</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> float64</label>
</div>
</div>
<p>This collection of passages has relatively short passages (a max of 65 tokens).</p>
<p><code>_process_corpus</code> then creates</p>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1">pid_docid_map <span class="op" style="color: #5E5E5E;">=</span> {index: item[<span class="st" style="color: #20794D;">"document_id"</span>] <span class="cf" style="color: #003B4F;">for</span> index, item <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(collection_with_ids)}</span></code></pre></div>
</div>
<div class="cell" data-outputid="d0e99497-9dca-4320-f03f-32432c30bd0a" data-execution_count="38">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1">pid_docid_map[<span class="dv" style="color: #AD0000;">999</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>'096e054e-3041-4881-ac48-b20f1804f650'</code></pre>
</div>
</div>
<p>This matches the content of <code>pid_docid_map.json</code>.</p>
<p><code>_process_corpus</code> also defines a list of strings, <code>collection</code>:</p>
<div class="cell" data-outputid="a8fec22c-5857-42c9-a9fd-a1d68382bff2" data-execution_count="39">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1">collection <span class="op" style="color: #5E5E5E;">=</span> [x[<span class="st" style="color: #20794D;">"content"</span>] <span class="cf" style="color: #003B4F;">for</span> x <span class="kw" style="color: #003B4F;">in</span> collection_with_ids]</span>
<span id="cb89-2">collection[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>'Overview'</code></pre>
</div>
</div>
<p><code>_process_corpus</code> also calls <code>_process_metadata</code> which defines <code>docid_metadata_map</code> as <code>None</code> when <code>document_metadatas</code> is <code>None</code> (which it is in our case).</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb91" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1">docid_metadata_map <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span></code></pre></div>
</div>
</section>
<section id="rag.index-internals" class="level2">
<h2 class="anchored" data-anchor-id="rag.index-internals"><code>RAG.index</code> Internals</h2>
<p>After calling <code>_process_corpus</code>, <code>RAG.index</code> calls <code>model.index</code>, where <code>model</code> is:</p>
<div class="sourceCode" id="cb92" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1">instance.model <span class="op" style="color: #5E5E5E;">=</span> ColBERT(</span>
<span id="cb92-2">            pretrained_model_name_or_path, n_gpu, index_root<span class="op" style="color: #5E5E5E;">=</span>index_root, verbose<span class="op" style="color: #5E5E5E;">=</span>verbose</span>
<span id="cb92-3">        )</span></code></pre></div>
<p><code>ColBERT.index</code> in turn calls:</p>
<div class="sourceCode" id="cb93" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1">ModelIndexFactory.construct</span></code></pre></div>
<p>By default the type of index is PLAID, so the following is called:</p>
<div class="sourceCode" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1">PLAIDModelIndex(config).build(</span>
<span id="cb94-2">            checkpoint, collection, index_name, overwrite, verbose, <span class="op" style="color: #5E5E5E;">**</span>kwargs</span>
<span id="cb94-3">        )</span></code></pre></div>
<section id="plaidmodelindex.build" class="level3">
<h3 class="anchored" data-anchor-id="plaidmodelindex.build">PLAIDModelIndex.build</h3>
<p>A couple of key configuration values are set in this method, starting with the bsize (which I think is batch size?) defaulting to 32.</p>
<div class="cell" data-outputid="713f95b3-a2dd-4045-8a63-2831279ab052" data-execution_count="41">
<div class="sourceCode cell-code" id="cb95" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1">PLAIDModelIndex._DEFAULT_INDEX_BSIZE</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>32</code></pre>
</div>
</div>
<div class="cell" data-outputid="509c34cf-aaab-43ae-98e3-1236b1783297" data-execution_count="42">
<div class="sourceCode cell-code" id="cb97" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1">bsize <span class="op" style="color: #5E5E5E;">=</span> PLAIDModelIndex._DEFAULT_INDEX_BSIZE</span>
<span id="cb97-2">bsize</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>32</code></pre>
</div>
</div>
<p>The size of compressed residual embedding values is determined based on the size of the collection.</p>
<div class="cell" data-outputid="fcd4d4e2-a40c-4bb1-e23c-38198b4d9f3b" data-execution_count="43">
<div class="sourceCode cell-code" id="cb99" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(collection) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">10000</span>: nbits <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb99-2">nbits</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>4</code></pre>
</div>
</div>
<p>It then defines a <code>ColBERTConfig</code> object, which I believe is instantiated as follows when the <code>ColBERT</code> checkpoint is instantiated:</p>
<div class="cell" data-outputid="45f559af-99fc-449e-a652-ac3a4b9e433a" data-execution_count="44">
<div class="sourceCode cell-code" id="cb101" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1">ckpt_config <span class="op" style="color: #5E5E5E;">=</span> ColBERTConfig.load_from_checkpoint(<span class="bu" style="color: null;">str</span>(model_nm))</span>
<span id="cb101-2">ckpt_config</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>ColBERTConfig(query_token_id='[unused0]', doc_token_id='[unused1]', query_token='[Q]', doc_token='[D]', ncells=None, centroid_score_threshold=None, ndocs=None, load_index_with_mmap=False, index_path=None, index_bsize=64, nbits=1, kmeans_niters=4, resume=False, pool_factor=1, clustering_mode='hierarchical', protected_tokens=0, similarity='cosine', bsize=32, accumsteps=1, lr=1e-05, maxsteps=15626, save_every=None, warmup=781, warmup_bert=None, relu=False, nway=32, use_ib_negatives=False, reranker=False, distillation_alpha=1.0, ignore_scores=False, model_name='answerdotai/AnswerAI-ColBERTv2.5-small', query_maxlen=32, attend_to_mask_tokens=False, interaction='colbert', dim=96, doc_maxlen=300, mask_punctuation=True, checkpoint='/root/.cache/huggingface/hub/models--answerdotai--answerai-colbert-small-v1/snapshots/be1703c55532145a844da800eea4c9a692d7e267/', triples='/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl', collection='/home/bclavie/colbertv2.5_en/data/msmarco/collection.tsv', queries='/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv', index_name=None, overwrite=False, root='/home/bclavie/colbertv2.5_en/experiments', experiment='minicolbertv2.5', index_root=None, name='2024-08/07/08.16.20', rank=0, nranks=4, amp=True, gpus=4, avoid_fork_if_possible=False)</code></pre>
</div>
</div>
<div class="cell" data-outputid="6030245b-21ac-43ab-bc51-a9702c22a661" data-execution_count="45">
<div class="sourceCode cell-code" id="cb103" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1">config <span class="op" style="color: #5E5E5E;">=</span> ColBERTConfig.from_existing(ckpt_config)</span>
<span id="cb103-2">config</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>ColBERTConfig(query_token_id='[unused0]', doc_token_id='[unused1]', query_token='[Q]', doc_token='[D]', ncells=None, centroid_score_threshold=None, ndocs=None, load_index_with_mmap=False, index_path=None, index_bsize=64, nbits=1, kmeans_niters=4, resume=False, pool_factor=1, clustering_mode='hierarchical', protected_tokens=0, similarity='cosine', bsize=32, accumsteps=1, lr=1e-05, maxsteps=15626, save_every=None, warmup=781, warmup_bert=None, relu=False, nway=32, use_ib_negatives=False, reranker=False, distillation_alpha=1.0, ignore_scores=False, model_name='answerdotai/AnswerAI-ColBERTv2.5-small', query_maxlen=32, attend_to_mask_tokens=False, interaction='colbert', dim=96, doc_maxlen=300, mask_punctuation=True, checkpoint='/root/.cache/huggingface/hub/models--answerdotai--answerai-colbert-small-v1/snapshots/be1703c55532145a844da800eea4c9a692d7e267/', triples='/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl', collection='/home/bclavie/colbertv2.5_en/data/msmarco/collection.tsv', queries='/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv', index_name=None, overwrite=False, root='/home/bclavie/colbertv2.5_en/experiments', experiment='minicolbertv2.5', index_root=None, name='2024-08/07/08.16.20', rank=0, nranks=4, amp=True, gpus=4, avoid_fork_if_possible=False)</code></pre>
</div>
</div>
<p>We also need to create a <code>RunConfig</code> object:</p>
<div class="cell" data-outputid="36d6fd1b-c4b7-4f84-a1a9-ceb78c9accb1" data-execution_count="46">
<div class="sourceCode cell-code" id="cb105" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1">run_config <span class="op" style="color: #5E5E5E;">=</span> RunConfig(nranks<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>, experiment<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"colbert"</span>, root<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">".ragatouille/"</span>)</span>
<span id="cb105-2">run_config</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>RunConfig(overwrite=False, root='.ragatouille/', experiment='colbert', index_root=None, name='2025-03/13/01.14.35', rank=0, nranks=-1, amp=True, gpus=1, avoid_fork_if_possible=False)</code></pre>
</div>
</div>
<p>A couple more config values are set:</p>
<div class="cell" data-outputid="d74d250c-86e3-43d0-ed8b-2420290082d6" data-execution_count="47">
<div class="sourceCode cell-code" id="cb107" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1">config.avoid_fork_if_possible <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb107-2"></span>
<span id="cb107-3"><span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(collection) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">100000</span>:</span>
<span id="cb107-4">    config.kmeans_niters <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb107-5"><span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">len</span>(collection) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">50000</span>:</span>
<span id="cb107-6">    config.kmeans_niters <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb107-7"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb107-8">    config.kmeans_niters <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">20</span></span>
<span id="cb107-9">config.avoid_fork_if_possible, config.kmeans_niters</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>(True, 20)</code></pre>
</div>
</div>
<p>After determining whether the PyTorch or FAISS k-means implementation will be used, <code>Indexer.index</code> is called.</p>
</section>
</section>
<section id="indexer.index" class="level2">
<h2 class="anchored" data-anchor-id="indexer.index">Indexer.index</h2>
<p>The <code>Indexer</code> comes from the ColBERT repo, so this is essentially the connection point between the RAGatouille and ColBERT libraries.</p>
<section id="launcher" class="level3">
<h3 class="anchored" data-anchor-id="launcher">Launcher</h3>
<p>Inside <code>Indexer.index</code>, <code>__launch</code> is called, from within which a <code>Launcher</code> instance is created with the <code>encode</code> function.</p>
<p>I’m a bit fuzzy on the next part but I’ll give it a shot:</p>
<p>when <code>Launcher.launch</code> is called, the following two lines are called (where <code>callee</code> is the <code>encode</code> function):</p>
<div class="sourceCode" id="cb109" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1">args_ <span class="op" style="color: #5E5E5E;">=</span> (<span class="va" style="color: #111111;">self</span>.callee, port, return_value_queue, new_config, <span class="op" style="color: #5E5E5E;">*</span>args)</span>
<span id="cb109-2">all_procs.append(mp.Process(target<span class="op" style="color: #5E5E5E;">=</span>setup_new_process, args<span class="op" style="color: #5E5E5E;">=</span>args_))</span></code></pre></div>
<p><code>setup_new_process</code> contains the following lines:</p>
<div class="sourceCode" id="cb110" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><span class="cf" style="color: #003B4F;">with</span> Run().context(config, inherit_config<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb110-2">    return_val <span class="op" style="color: #5E5E5E;">=</span> callee(config, <span class="op" style="color: #5E5E5E;">*</span>args)</span></code></pre></div>
<p>With <code>callee</code> being called, let’s look at the function that <code>callee</code> is : <code>encode</code>, which is part of the collection_indexer.py file.</p>
</section>
</section>
<section id="encode" class="level2">
<h2 class="anchored" data-anchor-id="encode">encode</h2>
<div class="sourceCode" id="cb111" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><span class="kw" style="color: #003B4F;">def</span> encode(config, collection, shared_lists, shared_queues, verbose: <span class="bu" style="color: null;">int</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">3</span>):</span>
<span id="cb111-2">    encoder <span class="op" style="color: #5E5E5E;">=</span> CollectionIndexer(config<span class="op" style="color: #5E5E5E;">=</span>config, collection<span class="op" style="color: #5E5E5E;">=</span>collection, verbose<span class="op" style="color: #5E5E5E;">=</span>verbose)</span>
<span id="cb111-3">    encoder.run(shared_lists)</span></code></pre></div>
<p>This leads us to <code>encoder.run</code> which is <code>CollectionIndexer.run</code>. But before that, we need to look at how the collection is transformed when <code>CollectionIndexer</code> is instantiated.</p>
</section>
<section id="collectionindexer.__init__" class="level2">
<h2 class="anchored" data-anchor-id="collectionindexer.__init__">CollectionIndexer.__init__</h2>
<p>There are two important objects created when the <code>CollectionIndexer</code> is instantiated. First is the <code>Collection</code> object, which turns our list <code>collection</code>:</p>
<div class="cell" data-outputid="7e5b183f-41a1-4a6b-d0a0-526ed5504b0e" data-execution_count="48">
<div class="sourceCode cell-code" id="cb112" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><span class="bu" style="color: null;">type</span>(collection)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>list</code></pre>
</div>
</div>
<p>into a <code>Collection</code> object:</p>
<div class="cell" data-outputid="4542f1a3-6850-4403-ec5d-229a6867ac95" data-execution_count="49">
<div class="sourceCode cell-code" id="cb114" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1">collection <span class="op" style="color: #5E5E5E;">=</span> Collection.cast(collection)</span>
<span id="cb114-2">collection</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>&lt;colbert.data.collection.Collection at 0x794fa037e410&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="1b3747d7-93d9-4b39-c5bb-d9a6cd236a16" data-execution_count="50">
<div class="sourceCode cell-code" id="cb116" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><span class="bu" style="color: null;">type</span>(collection)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<div style="max-width:800px; border: 1px solid var(--colab-border-color);"><style>
      pre.function-repr-contents {
        overflow-x: auto;
        padding: 8px 12px;
        max-height: 500px;
      }

      pre.function-repr-contents.function-repr-contents-collapsed {
        cursor: pointer;
        max-height: 100px;
      }
    </style>
    <pre style="white-space: initial; background:
         var(--colab-secondary-surface-color); padding: 8px 12px;
         border-bottom: 1px solid var(--colab-border-color);"><b>colbert.data.collection.Collection</b><br>def __init__(path=None, data=None)</pre><pre class="function-repr-contents function-repr-contents-collapsed" style="">/usr/local/lib/python3.11/dist-packages/colbert/data/collection.py&lt;no docstring&gt;</pre>
      <script>
      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {
        for (const element of document.querySelectorAll('.filepath')) {
          element.style.display = 'block'
          element.onclick = (event) => {
            event.preventDefault();
            event.stopPropagation();
            google.colab.files.view(element.textContent, 14);
          };
        }
      }
      for (const element of document.querySelectorAll('.function-repr-contents')) {
        element.onclick = (event) => {
          event.preventDefault();
          event.stopPropagation();
          element.classList.toggle('function-repr-contents-collapsed');
        };
      }
      </script>
      </div>
</div>
</div>
<p>Next, it creates a <code>CollectionEncoder</code> object:</p>
<div class="cell" data-outputid="287c057a-b53b-4e29-b8e2-3fa7945b558c" data-execution_count="51">
<div class="sourceCode cell-code" id="cb117" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1">checkpoint <span class="op" style="color: #5E5E5E;">=</span> Checkpoint(config.checkpoint, colbert_config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb117-2">encoder <span class="op" style="color: #5E5E5E;">=</span> CollectionEncoder(config, checkpoint)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/utils/amp.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler()</code></pre>
</div>
</div>
<p><code>checkpoint</code> is our model:</p>
<div class="cell" data-outputid="d4e3ee56-c931-4512-c4e5-4e3b94ffeaa4" data-execution_count="52">
<div class="sourceCode cell-code" id="cb119" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1">checkpoint</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>Checkpoint(
  (model): HF_ColBERT(
    (linear): Linear(in_features=384, out_features=96, bias=False)
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 384, padding_idx=0)
        (position_embeddings): Embedding(512, 384)
        (token_type_embeddings): Embedding(2, 384)
        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0-11): 12 x BertLayer(
            (attention): BertAttention(
              (self): BertSdpaSelfAttention(
                (query): Linear(in_features=384, out_features=384, bias=True)
                (key): Linear(in_features=384, out_features=384, bias=True)
                (value): Linear(in_features=384, out_features=384, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=384, out_features=384, bias=True)
                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=384, out_features=1536, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=1536, out_features=384, bias=True)
              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=384, out_features=384, bias=True)
        (activation): Tanh()
      )
    )
  )
)</code></pre>
</div>
</div>
<p>The <code>CollectionEncoder</code> will be used later on to encode the passages.</p>
<div class="cell" data-outputid="4a91eac1-1fcd-4304-9aa7-c9116e131bc4" data-execution_count="53">
<div class="sourceCode cell-code" id="cb121" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1">encoder</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>&lt;colbert.indexing.collection_encoder.CollectionEncoder at 0x794fa0683dd0&gt;</code></pre>
</div>
</div>
<p>Next we’ll dive into <code>CollectionIndexer.run</code> within which all of the indexing operations that I’m most interested in take place, starting with <code>setup</code>.</p>
</section>
<section id="collectionindexer.run" class="level2">
<h2 class="anchored" data-anchor-id="collectionindexer.run">CollectionIndexer.run</h2>
<section id="collectionindexer.setup" class="level3">
<h3 class="anchored" data-anchor-id="collectionindexer.setup">CollectionIndexer.setup</h3>
<pre><code>'''
Calculates and saves plan.json for the whole collection.

plan.json { config, num_chunks, num_partitions, num_embeddings_est, avg_doclen_est}
num_partitions is the number of centroids to be generated.
'''</code></pre>
<p>We’ll see where <code>num_chunks</code> is used, but for now I’ll just define it:</p>
<div class="cell" data-outputid="4608be3d-b02a-4824-9af6-5179e47e4662" data-execution_count="54">
<div class="sourceCode cell-code" id="cb124" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1">num_chunks <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(np.ceil(<span class="bu" style="color: null;">len</span>(collection) <span class="op" style="color: #5E5E5E;">/</span> collection.get_chunksize()))</span>
<span id="cb124-2"><span class="bu" style="color: null;">len</span>(collection), collection.get_chunksize(), num_chunks</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>(1000, 1001, 1)</code></pre>
</div>
</div>
<p>Next we look at <code>_sample_pids</code> and <code>_sample_embeddings</code> which are later clustered to get our centroids.</p>
<section id="sample_pids" class="level4">
<h4 class="anchored" data-anchor-id="sample_pids">_sample_pids</h4>
<div class="cell" data-outputid="bf8f7646-fe8c-48d8-a32a-bb2183c3d9aa" data-execution_count="55">
<div class="sourceCode cell-code" id="cb126" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1">num_passages <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(collection)</span>
<span id="cb126-2">num_passages</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>1000</code></pre>
</div>
</div>
<p>It’s awesome to see one of the heuristics mentioned in the <a href="https://arxiv.org/abs/2112.01488">ColBERTv2 paper</a>:</p>
<blockquote class="blockquote">
<p>To reduce memory consumption, we apply k-means clustering to the embeddings produced by invoking our BERT encoder over only a sample of all passages, proportional to the square root of the collection size, an approach we found to perform well in practice.</p>
</blockquote>
<div class="cell" data-outputid="3dc9f49f-7fe1-42c1-a2b3-8e7780d9d1ee" data-execution_count="56">
<div class="sourceCode cell-code" id="cb128" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1">typical_doclen <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">120</span></span>
<span id="cb128-2">sampled_pids <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">16</span> <span class="op" style="color: #5E5E5E;">*</span> np.sqrt(typical_doclen <span class="op" style="color: #5E5E5E;">*</span> num_passages)</span>
<span id="cb128-3">sampled_pids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>5542.562584220407</code></pre>
</div>
</div>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb130" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1">sampled_pids <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">min</span>(<span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">int</span>(sampled_pids), num_passages)</span></code></pre></div>
</div>
<p>In this case because my toy collection is so small (1000 passages) we will use all of them for centroid clustering.</p>
<div class="cell" data-outputid="d9d310be-a543-4cac-aadd-94fe8439164f" data-execution_count="58">
<div class="sourceCode cell-code" id="cb131" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1">sampled_pids <span class="op" style="color: #5E5E5E;">=</span> random.sample(<span class="bu" style="color: null;">range</span>(num_passages), sampled_pids)</span>
<span id="cb131-2">sampled_pids <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">set</span>(sampled_pids)</span>
<span id="cb131-3"><span class="bu" style="color: null;">len</span>(sampled_pids), <span class="bu" style="color: null;">min</span>(sampled_pids), <span class="bu" style="color: null;">max</span>(sampled_pids)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>(1000, 0, 999)</code></pre>
</div>
</div>
</section>
<section id="sample_embeddings" class="level4">
<h4 class="anchored" data-anchor-id="sample_embeddings">_sample_embeddings</h4>
<div class="cell" data-outputid="695c7b09-bd48-4085-ddcb-78113cbe4cbf" data-execution_count="59">
<div class="sourceCode cell-code" id="cb133" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1">local_pids <span class="op" style="color: #5E5E5E;">=</span> collection.<span class="bu" style="color: null;">enumerate</span>(rank<span class="op" style="color: #5E5E5E;">=</span>config.rank)</span>
<span id="cb133-2">local_pids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>&lt;generator object Collection.enumerate at 0x794fa067dc40&gt;</code></pre>
</div>
</div>
<p><code>sampled_pids</code> contains all of our passages</p>
<div class="cell" data-outputid="131ba5cd-16c8-42ae-c811-fe0eaecfb591" data-execution_count="60">
<div class="sourceCode cell-code" id="cb135" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1">local_sample <span class="op" style="color: #5E5E5E;">=</span> [passage <span class="cf" style="color: #003B4F;">for</span> pid, passage <span class="kw" style="color: #003B4F;">in</span> local_pids <span class="cf" style="color: #003B4F;">if</span> pid <span class="kw" style="color: #003B4F;">in</span> sampled_pids]</span>
<span id="cb135-2"><span class="bu" style="color: null;">len</span>(local_sample)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>1000</code></pre>
</div>
</div>
<p>Next come another critical process—encoding our passages!</p>
</section>
<section id="collectionencoder.encode_passages" class="level4">
<h4 class="anchored" data-anchor-id="collectionencoder.encode_passages">CollectionEncoder.encode_passages</h4>
<p>Inside <code>encode_passages</code> we call <code>checkpoint.docFromText</code>.</p>
</section>
<section id="checkpoint.docfromtext" class="level4">
<h4 class="anchored" data-anchor-id="checkpoint.docfromtext">checkpoint.docFromText</h4>
<p>And inside <code>checkpoint.docFromText</code> we call <code>checkpoint.doc</code></p>
</section>
<section id="checkpoint.doc" class="level4">
<h4 class="anchored" data-anchor-id="checkpoint.doc">checkpoint.doc</h4>
<p>Inside <code>ColBERT.doc</code> we finally call the lowest-level method in this chain:</p>
<div class="sourceCode" id="cb137" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1">D <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.bert(input_ids, attention_mask<span class="op" style="color: #5E5E5E;">=</span>attention_mask)[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<p>One key point to visualize is that the BERT output is normalized:</p>
<div class="sourceCode" id="cb138" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"> D <span class="op" style="color: #5E5E5E;">=</span> torch.nn.functional.normalize(D, p<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<p>I’ll zoom out again and call <code>encode_passages</code>.</p>
<div class="cell" data-outputid="baf86309-4cd0-415d-d2c2-239648f21835" data-execution_count="61">
<div class="sourceCode cell-code" id="cb139" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1">local_sample_embs, doclens <span class="op" style="color: #5E5E5E;">=</span> encoder.encode_passages(local_sample)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Mar 13, 01:18:18] [0]       #&gt; Encoding 1000 passages..</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast() if self.activated else NullContextManager()</code></pre>
</div>
</div>
<div class="cell" data-outputid="5368e56a-dc60-4b05-e281-6bc83260149d" data-execution_count="62">
<div class="sourceCode cell-code" id="cb142" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1">local_sample_embs.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>torch.Size([15198, 96])</code></pre>
</div>
</div>
<p>Note that the token embeddings are a unit vector:</p>
<div class="cell" data-outputid="7535c91f-acbc-4310-fe2c-eceaa0aac05e" data-execution_count="63">
<div class="sourceCode cell-code" id="cb144" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1">local_sample_embs[<span class="dv" style="color: #AD0000;">0</span>].norm()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>tensor(1., dtype=torch.float16)</code></pre>
</div>
</div>
<div class="cell" data-outputid="51a948d6-7cc9-424f-f0fd-aec96603de60" data-execution_count="64">
<div class="sourceCode cell-code" id="cb146" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><span class="bu" style="color: null;">len</span>(doclens), doclens[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>(1000, [4, 20, 18, 23, 8])</code></pre>
</div>
</div>
<p>We have 15198 token embeddings (embedded into answerai-colbert-small-v1’s 96-dimension space) and a mapping (list) of passage ID (indices) to number of tokens (values).</p>
<div class="cell" data-outputid="58d443ae-bb70-432c-fa22-e4d6508ee855" data-execution_count="65">
<div class="sourceCode cell-code" id="cb148" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1">avg_doclen_est <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(doclens) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(doclens) <span class="cf" style="color: #003B4F;">if</span> doclens <span class="cf" style="color: #003B4F;">else</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb148-2">avg_doclen_est</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>15.198</code></pre>
</div>
</div>
<p>On average, each passage (document) is 15 tokens long.</p>
<p>Zooming back out to CollectionIndexer.setup we have a few more steps before our planning is complete:</p>
<div class="cell" data-outputid="204bfd18-33ef-4bdb-c0f9-08f6fb4a4261" data-execution_count="66">
<div class="sourceCode cell-code" id="cb150" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1">num_passages <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(collection)</span>
<span id="cb150-2">num_embeddings_est <span class="op" style="color: #5E5E5E;">=</span> num_passages <span class="op" style="color: #5E5E5E;">*</span> avg_doclen_est</span>
<span id="cb150-3">num_partitions <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(<span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">**</span> np.floor(np.log2(<span class="dv" style="color: #AD0000;">16</span> <span class="op" style="color: #5E5E5E;">*</span> np.sqrt(num_embeddings_est))))</span>
<span id="cb150-4">num_passages, num_embeddings_est, num_partitions</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>(1000, 15198.0, 1024)</code></pre>
</div>
</div>
<p><code>num_partitions</code> is the number of clusters we will cluster our 15198 token embeddings into.</p>
<p>This is the information that was in plan.json in <code>index_path</code> (in addition to the other ColBERTConfig information).</p>
</section>
</section>
</section>
<section id="collectionindexer.train" class="level2">
<h2 class="anchored" data-anchor-id="collectionindexer.train">CollectionIndexer.train</h2>
<p>After <code>setup</code> is complete, the next method called in <code>run</code> is <code>train</code>.</p>
<p>The first step in <code>train</code> is to split our <code>local_sample_embs</code> into <code>sample</code> and <code>sample_heldout</code>.</p>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb152" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1">local_sample_embs <span class="op" style="color: #5E5E5E;">=</span> local_sample_embs[torch.randperm(local_sample_embs.size(<span class="dv" style="color: #AD0000;">0</span>))]</span></code></pre></div>
</div>
<div class="cell" data-outputid="ec7757d2-ca75-477d-84f3-f81c3517883a" data-execution_count="68">
<div class="sourceCode cell-code" id="cb153" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1">heldout_fraction <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.05</span></span>
<span id="cb153-2">heldout_size <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(<span class="bu" style="color: null;">min</span>(heldout_fraction <span class="op" style="color: #5E5E5E;">*</span> local_sample_embs.size(<span class="dv" style="color: #AD0000;">0</span>), <span class="dv" style="color: #AD0000;">50_000</span>))</span>
<span id="cb153-3">heldout_size</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>759</code></pre>
</div>
</div>
<div class="cell" data-outputid="6f55866f-73fe-4764-8f4b-75357ff74422" data-execution_count="69">
<div class="sourceCode cell-code" id="cb155" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1">sample, sample_heldout <span class="op" style="color: #5E5E5E;">=</span> local_sample_embs.split([local_sample_embs.size(<span class="dv" style="color: #AD0000;">0</span>) <span class="op" style="color: #5E5E5E;">-</span> heldout_size, heldout_size], dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb155-2">sample.shape, sample_heldout.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>(torch.Size([14439, 96]), torch.Size([759, 96]))</code></pre>
</div>
</div>
<section id="compute_faiss_kmeans" class="level3">
<h3 class="anchored" data-anchor-id="compute_faiss_kmeans">compute_faiss_kmeans</h3>
<p>Next we get the centroids using <code>compute_faiss_kmeans</code></p>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb157" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1">args_ <span class="op" style="color: #5E5E5E;">=</span> [config.dim, num_partitions, config.kmeans_niters, [[sample]]]</span></code></pre></div>
</div>
<div class="cell" data-outputid="054f14d5-c959-471a-8b5e-ed27aa85b2a3" data-execution_count="71">
<div class="sourceCode cell-code" id="cb158" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1">centroids <span class="op" style="color: #5E5E5E;">=</span> compute_faiss_kmeans(<span class="op" style="color: #5E5E5E;">*</span>args_)</span>
<span id="cb158-2">centroids.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>torch.Size([1024, 96])</code></pre>
</div>
</div>
<p>We then normalize the centroids</p>
<div class="cell" data-outputid="cf1bbf89-4877-4093-fe5c-81dc240a6794" data-execution_count="72">
<div class="sourceCode cell-code" id="cb160" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1">centroids <span class="op" style="color: #5E5E5E;">=</span> torch.nn.functional.normalize(centroids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb160-2">centroids.shape, centroids[<span class="dv" style="color: #AD0000;">0</span>].norm()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>(torch.Size([1024, 96]), tensor(1.))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb162" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb162-1">centroids <span class="op" style="color: #5E5E5E;">=</span> centroids.half()</span></code></pre></div>
</div>
<p>I was hoping to get the same values as <code>RAG.index</code> centroids by setting seeds at the start of this notebook, but I am not getting the same result.</p>
<div class="cell" data-outputid="9f560916-f170-474e-f865-9a7313707a5c" data-execution_count="74">
<div class="sourceCode cell-code" id="cb163" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1">_centroids[<span class="dv" style="color: #AD0000;">0</span>][:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>tensor([-0.0649,  0.1193, -0.0551,  0.0561, -0.0826], device='cuda:0',
       dtype=torch.float16)</code></pre>
</div>
</div>
<div class="cell" data-outputid="d9d7ff01-dce7-403d-fa02-f04cb7ac8318" data-execution_count="75">
<div class="sourceCode cell-code" id="cb165" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1">centroids[<span class="dv" style="color: #AD0000;">0</span>][:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>tensor([-0.0587,  0.0379, -0.0847, -0.0224, -0.0636], dtype=torch.float16)</code></pre>
</div>
</div>
<p>I’ll use PCA to compare the two sets of centroids:</p>
<div class="cell" data-outputid="364dc72a-4316-4c4b-c262-4ce9c136f239" data-execution_count="76">
<div class="sourceCode cell-code" id="cb167" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb167-1"><span class="co" style="color: #5E5E5E;"># Project to 2D</span></span>
<span id="cb167-2">pca <span class="op" style="color: #5E5E5E;">=</span> PCA(n_components<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb167-3">prev_2d <span class="op" style="color: #5E5E5E;">=</span> pca.fit_transform(_centroids.cpu().numpy())</span>
<span id="cb167-4">new_2d <span class="op" style="color: #5E5E5E;">=</span> pca.transform(centroids.cpu().numpy())</span>
<span id="cb167-5"></span>
<span id="cb167-6"><span class="co" style="color: #5E5E5E;"># Plot</span></span>
<span id="cb167-7">plt.figure(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">10</span>, <span class="dv" style="color: #AD0000;">8</span>))</span>
<span id="cb167-8">plt.scatter(prev_2d[:, <span class="dv" style="color: #AD0000;">0</span>], prev_2d[:, <span class="dv" style="color: #AD0000;">1</span>], alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Previous'</span>)</span>
<span id="cb167-9">plt.scatter(new_2d[:, <span class="dv" style="color: #AD0000;">0</span>], new_2d[:, <span class="dv" style="color: #AD0000;">1</span>], alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'New'</span>)</span>
<span id="cb167-10">plt.legend()</span>
<span id="cb167-11">plt.title(<span class="st" style="color: #20794D;">'PCA projection of centroids'</span>)</span>
<span id="cb167-12">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-78-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-03-12-RAGatouille-ColBERT-Indexing-Deep-Dive/index_files/figure-html/cell-78-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>I’m not super familiar with interpreting PCA plots, so I asked Claude what it thought about this result:</p>
<blockquote class="blockquote">
<p>I would describe this as showing “good structural similarity but with expected local variations.” The centroids aren’t identical (which would show perfect overlap), but they capture similar patterns in the embedding space. This suggests that while individual centroid positions differ, the overall index structure should perform similarly for retrieval tasks.</p>
</blockquote>
<p>For now, I’ll consider this part of indexing completing, as we have generated similar contents to what’s in centroids.pt.</p>
</section>
<section id="compute_avg_residual" class="level3">
<h3 class="anchored" data-anchor-id="compute_avg_residual">_compute_avg_residual</h3>
<p>This next section was quite eye opening for me, as it was the first time I understood how quantization is implemented.</p>
<p>The <code>ResidualCodec</code> does all of the compression/binarization/decompress of residuals.</p>
<div class="cell" data-outputid="63e544fc-d70a-4ec4-c20d-f662dcd573dd" data-execution_count="77">
<div class="sourceCode cell-code" id="cb168" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1">compressor <span class="op" style="color: #5E5E5E;">=</span> ResidualCodec(config<span class="op" style="color: #5E5E5E;">=</span>config, centroids<span class="op" style="color: #5E5E5E;">=</span>centroids, avg_residual<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>)</span>
<span id="cb168-2">compressor</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>&lt;colbert.indexing.codecs.residual.ResidualCodec at 0x794f9aacfdd0&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="91dd3f8e-f5d4-4011-b8b6-8f07d856f678" data-execution_count="78">
<div class="sourceCode cell-code" id="cb170" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1">heldout_reconstruct <span class="op" style="color: #5E5E5E;">=</span> compressor.compress_into_codes(sample_heldout, out_device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cuda'</span> )</span>
<span id="cb170-2">heldout_reconstruct.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>torch.Size([759])</code></pre>
</div>
</div>
<p><code>compress_into_codes</code> finds the nearest centroid IDs to the token embeddings. It does so using cosine similarity:</p>
<div class="sourceCode" id="cb172" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1">indices <span class="op" style="color: #5E5E5E;">=</span> (<span class="va" style="color: #111111;">self</span>.centroids <span class="op" style="color: #5E5E5E;">@</span> batch.T.cuda().half()).<span class="bu" style="color: null;">max</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>).indices.to(device<span class="op" style="color: #5E5E5E;">=</span>out_device)</span></code></pre></div>
<div class="cell" data-outputid="7d386c67-5697-4b06-bc60-3016a5268171" data-execution_count="79">
<div class="sourceCode cell-code" id="cb173" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1">heldout_reconstruct[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>tensor([633, 667, 738, 641, 443], device='cuda:0')</code></pre>
</div>
</div>
<p><code>lookup_centroids</code> gets the full vectors related to the centroid IDs in <code>heldout_reconstruct</code></p>
<div class="cell" data-outputid="1828d155-c7d2-49d6-ee0b-bf28088fed2f" data-execution_count="80">
<div class="sourceCode cell-code" id="cb175" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1">heldout_reconstruct <span class="op" style="color: #5E5E5E;">=</span> compressor.lookup_centroids(heldout_reconstruct, out_device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cuda'</span>)</span>
<span id="cb175-2">heldout_reconstruct.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>torch.Size([759, 96])</code></pre>
</div>
</div>
<p>The residual between the heldout token embeddings and the closest centroids is then calculated:</p>
<div class="cell" data-outputid="fa4c97ef-1b38-47cb-e495-71769187250b" data-execution_count="81">
<div class="sourceCode cell-code" id="cb177" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1">heldout_avg_residual <span class="op" style="color: #5E5E5E;">=</span> sample_heldout.cuda() <span class="op" style="color: #5E5E5E;">-</span> heldout_reconstruct</span>
<span id="cb177-2">heldout_avg_residual.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>torch.Size([759, 96])</code></pre>
</div>
</div>
<p>We then calculate the average residual vector (96 dimensions):</p>
<div class="cell" data-outputid="1abb38ee-908f-4466-ee55-18874f0cf623" data-execution_count="82">
<div class="sourceCode cell-code" id="cb179" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb179-1">avg_residual <span class="op" style="color: #5E5E5E;">=</span> torch.<span class="bu" style="color: null;">abs</span>(heldout_avg_residual).mean(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>).cpu()</span>
<span id="cb179-2">avg_residual.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<pre><code>torch.Size([96])</code></pre>
</div>
</div>
<p>The average residual is somewhat similar to the stored value in avg_residual.pt.</p>
<div class="cell" data-outputid="9851ccd2-9b46-4391-ca49-60e73eb9143b" data-execution_count="83">
<div class="sourceCode cell-code" id="cb181" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1">_avg_residual, avg_residual.mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>(tensor(0.0150, device='cuda:0', dtype=torch.float16),
 tensor(0.0158, dtype=torch.float16))</code></pre>
</div>
</div>
<p>To match the <code>RAG.index</code> defaults, I’m going to set <code>nbits</code> to 4.</p>
<div class="cell" data-outputid="d40f05df-3a4a-49ea-d2d3-c95a13fe8f05" data-execution_count="84">
<div class="sourceCode cell-code" id="cb183" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1">config.nbits</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>1</code></pre>
</div>
</div>
<div class="cell" data-outputid="b221b665-e69d-4f60-d7bf-e103bc4f07ea" data-execution_count="85">
<div class="sourceCode cell-code" id="cb185" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb185-1">config.nbits <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb185-2">config.nbits</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>4</code></pre>
</div>
</div>
<div class="cell" data-outputid="caa9c096-c212-4d1d-c2fc-5dc98b08f134" data-execution_count="86">
<div class="sourceCode cell-code" id="cb187" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb187-1">num_options <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">**</span> config.nbits</span>
<span id="cb187-2">config.nbits, num_options</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>(4, 16)</code></pre>
</div>
</div>
<p>A 4-bit value has four 0 or 1 values and there are 16 possible combinations:</p>
<table class="table">
<thead>
<tr class="header">
<th>Binary</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0000</td>
</tr>
<tr class="even">
<td>0001</td>
</tr>
<tr class="odd">
<td>0010</td>
</tr>
<tr class="even">
<td>0011</td>
</tr>
<tr class="odd">
<td>0100</td>
</tr>
<tr class="even">
<td>0101</td>
</tr>
<tr class="odd">
<td>0110</td>
</tr>
<tr class="even">
<td>0111</td>
</tr>
<tr class="odd">
<td>1000</td>
</tr>
<tr class="even">
<td>1001</td>
</tr>
<tr class="odd">
<td>1010</td>
</tr>
<tr class="even">
<td>1011</td>
</tr>
<tr class="odd">
<td>1100</td>
</tr>
<tr class="even">
<td>1101</td>
</tr>
<tr class="odd">
<td>1110</td>
</tr>
<tr class="even">
<td>1111</td>
</tr>
</tbody>
</table>
<p>We split 0-to-1 into 16 equal parts:</p>
<div class="cell" data-outputid="d7e5088e-a9a2-4bf2-ef43-6cd89420cbbb" data-execution_count="87">
<div class="sourceCode cell-code" id="cb189" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb189-1">quantiles <span class="op" style="color: #5E5E5E;">=</span> torch.arange(<span class="dv" style="color: #AD0000;">0</span>, num_options, device<span class="op" style="color: #5E5E5E;">=</span>heldout_avg_residual.device) <span class="op" style="color: #5E5E5E;">*</span> (<span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">/</span> num_options)</span>
<span id="cb189-2">quantiles.shape, quantiles</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>(torch.Size([16]),
 tensor([0.0000, 0.0625, 0.1250, 0.1875, 0.2500, 0.3125, 0.3750, 0.4375, 0.5000,
         0.5625, 0.6250, 0.6875, 0.7500, 0.8125, 0.8750, 0.9375],
        device='cuda:0'))</code></pre>
</div>
</div>
<div class="cell" data-outputid="aad0ff4d-d8f5-490c-8ab5-ea569284ecb7" data-execution_count="88">
<div class="sourceCode cell-code" id="cb191" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb191-1">bucket_cutoffs_quantiles, bucket_weights_quantiles <span class="op" style="color: #5E5E5E;">=</span> quantiles[<span class="dv" style="color: #AD0000;">1</span>:], quantiles <span class="op" style="color: #5E5E5E;">+</span> (<span class="fl" style="color: #AD0000;">0.5</span> <span class="op" style="color: #5E5E5E;">/</span> num_options)</span>
<span id="cb191-2">bucket_cutoffs_quantiles, bucket_weights_quantiles</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>(tensor([0.0625, 0.1250, 0.1875, 0.2500, 0.3125, 0.3750, 0.4375, 0.5000, 0.5625,
         0.6250, 0.6875, 0.7500, 0.8125, 0.8750, 0.9375], device='cuda:0'),
 tensor([0.0312, 0.0938, 0.1562, 0.2188, 0.2812, 0.3438, 0.4062, 0.4688, 0.5312,
         0.5938, 0.6562, 0.7188, 0.7812, 0.8438, 0.9062, 0.9688],
        device='cuda:0'))</code></pre>
</div>
</div>
<p>IIUC, the weights’ quantiles are the midpoints between adjacent cutoffs’ quantiles.</p>
<div class="cell" data-outputid="91a23e13-086b-4777-aa6f-a9f5b246825f" data-execution_count="89">
<div class="sourceCode cell-code" id="cb193" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb193-1">(bucket_cutoffs_quantiles[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">+</span> bucket_cutoffs_quantiles[<span class="dv" style="color: #AD0000;">2</span>])<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>tensor(0.1562, device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="e84a2eef-9e00-4ba8-c455-645783076de1" data-execution_count="90">
<div class="sourceCode cell-code" id="cb195" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb195-1">(bucket_cutoffs_quantiles[<span class="dv" style="color: #AD0000;">3</span>] <span class="op" style="color: #5E5E5E;">+</span> bucket_cutoffs_quantiles[<span class="dv" style="color: #AD0000;">4</span>])<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>tensor(0.2812, device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="770906cf-1692-4c8a-c273-26905182aeac" data-execution_count="91">
<div class="sourceCode cell-code" id="cb197" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb197-1">(bucket_cutoffs_quantiles[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>] <span class="op" style="color: #5E5E5E;">+</span> bucket_cutoffs_quantiles[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>tensor(0.9062, device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb199" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb199-1">bucket_cutoffs <span class="op" style="color: #5E5E5E;">=</span> heldout_avg_residual.<span class="bu" style="color: null;">float</span>().quantile(bucket_cutoffs_quantiles)</span>
<span id="cb199-2">bucket_weights <span class="op" style="color: #5E5E5E;">=</span> heldout_avg_residual.<span class="bu" style="color: null;">float</span>().quantile(bucket_weights_quantiles)</span></code></pre></div>
</div>
<p>IIUC, <code>bucket_cutoffs</code> are the values with which we can group our (flattened) <code>heldout_avg_residual</code>s into 16 equal groups. Visualized here by setting the bins to <code>bucket_cutoffs</code>.</p>
<div class="cell" data-outputid="a25d3724-e9fe-4ba8-f0e4-07621a74e7c3" data-execution_count="93">
<div class="sourceCode cell-code" id="cb200" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb200-1">pd.Series(heldout_avg_residual.flatten().cpu()).hist(bins<span class="op" style="color: #5E5E5E;">=</span>bucket_cutoffs.cpu())</span>
<span id="cb200-2">plt.xlim([<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.035</span>, <span class="fl" style="color: #AD0000;">0.035</span>])</span>
<span id="cb200-3">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-95-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-03-12-RAGatouille-ColBERT-Indexing-Deep-Dive/index_files/figure-html/cell-95-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>Perhaps due to randomness during the sample split, my manually calculated cutoffs are not quite the same as the <code>RAG.index</code> values.</p>
<div class="cell" data-outputid="51ca7346-ac8f-43dd-aad1-4cd0e1d4885e" data-execution_count="94">
<div class="sourceCode cell-code" id="cb201" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb201-1">bucket_cutoffs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>tensor([-0.0322, -0.0219, -0.0156, -0.0108, -0.0070, -0.0040, -0.0017,  0.0000,
         0.0019,  0.0042,  0.0071,  0.0108,  0.0155,  0.0220,  0.0327],
       device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="ff1b5563-7c6b-48d7-8d25-c2742fca0614" data-execution_count="95">
<div class="sourceCode cell-code" id="cb203" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb203-1">_bucket_cutoffs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="95">
<pre><code>tensor([-0.0307, -0.0205, -0.0146, -0.0099, -0.0064, -0.0037, -0.0016,  0.0000,
         0.0017,  0.0038,  0.0066,  0.0102,  0.0150,  0.0211,  0.0313],
       device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="0bbd9adb-7d24-49d1-ae17-80ea28e16e61" data-execution_count="96">
<div class="sourceCode cell-code" id="cb205" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb205-1">bucket_weights</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="96">
<pre><code>tensor([-0.0434, -0.0261, -0.0185, -0.0131, -0.0088, -0.0054, -0.0028, -0.0009,
         0.0009,  0.0029,  0.0055,  0.0088,  0.0130,  0.0184,  0.0262,  0.0441],
       device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="8eed6fed-a09a-4a78-d340-2deaeb08189b" data-execution_count="97">
<div class="sourceCode cell-code" id="cb207" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb207-1">_bucket_weights</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>tensor([-0.0411, -0.0247, -0.0173, -0.0121, -0.0081, -0.0050, -0.0026, -0.0007,
         0.0007,  0.0027,  0.0052,  0.0083,  0.0124,  0.0178,  0.0253,  0.0421],
       device='cuda:0', dtype=torch.float16)</code></pre>
</div>
</div>
<p>There seems to be some rounding differences (or perhaps it depends on the distribution?) but the weights again seem to be the midpoints-ish between the cutoffs.</p>
<div class="cell" data-outputid="fae360c9-59e9-4c91-84b1-5282a62c4dd8" data-execution_count="98">
<div class="sourceCode cell-code" id="cb209" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb209-1">(bucket_cutoffs[<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">+</span> bucket_cutoffs[<span class="dv" style="color: #AD0000;">1</span>])<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>tensor(-0.0270, device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="0ce69033-621e-4ed5-ebee-c03c57bf4ee1" data-execution_count="99">
<div class="sourceCode cell-code" id="cb211" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb211-1">(bucket_cutoffs[<span class="dv" style="color: #AD0000;">3</span>] <span class="op" style="color: #5E5E5E;">+</span> bucket_cutoffs[<span class="dv" style="color: #AD0000;">4</span>])<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="99">
<pre><code>tensor(-0.0089, device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="228f1503-ef60-4224-fb95-34e25c4540f0" data-execution_count="100">
<div class="sourceCode cell-code" id="cb213" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb213-1">(bucket_cutoffs[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>] <span class="op" style="color: #5E5E5E;">+</span> bucket_cutoffs[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>tensor(0.0273, device='cuda:0')</code></pre>
</div>
</div>
</section>
</section>
<section id="collectionindexer.index" class="level2">
<h2 class="anchored" data-anchor-id="collectionindexer.index">CollectionIndexer.index</h2>
<p>Thus far we have found centroids from a sample of our token embeddings (5%, or 759) and calculated bucket cutoffs and bucket weights for quantization. We also know what the average residual mean value is.</p>
<p>Now we find the closest centroids and residuals for all passages’ token embeddings, starting first by encoding all 15198 tokens with our model:</p>
<div class="cell" data-outputid="dbfd1e50-465c-4ec6-85f8-d9e4cc6050c9" data-execution_count="101">
<div class="sourceCode cell-code" id="cb215" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb215-1">embs, doclens <span class="op" style="color: #5E5E5E;">=</span> encoder.encode_passages(collection)</span>
<span id="cb215-2">embs.shape, <span class="bu" style="color: null;">len</span>(doclens), doclens[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[Mar 13, 01:18:21] [0]       #&gt; Encoding 1000 passages..</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast() if self.activated else NullContextManager()</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>(torch.Size([15198, 96]), 1000, [4, 20, 18, 23, 8])</code></pre>
</div>
</div>
<p>Then we call <code>save_chunk</code> which is inside the <a href="https://github.com/stanford-futuredata/ColBERT/blob/7067ef598b5011edaa1f4a731a2c269dbac864e4/colbert/indexing/index_saver.py#L70"><code>IndexSaver</code></a> within which some interesting things take place:</p>
<div class="sourceCode" id="cb219" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb219-1"><span class="kw" style="color: #003B4F;">def</span> save_chunk(<span class="va" style="color: #111111;">self</span>, chunk_idx, offset, embs, doclens):</span>
<span id="cb219-2">        compressed_embs <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.codec.compress(embs)</span></code></pre></div>
<p>Looking into <code>ResidualCodec.compress</code>:</p>
<div class="sourceCode" id="cb220" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb220-1"><span class="kw" style="color: #003B4F;">def</span> compress(<span class="va" style="color: #111111;">self</span>, embs):</span>
<span id="cb220-2">        codes, residuals <span class="op" style="color: #5E5E5E;">=</span> [], []</span>
<span id="cb220-3"></span>
<span id="cb220-4">        <span class="cf" style="color: #003B4F;">for</span> batch <span class="kw" style="color: #003B4F;">in</span> embs.split(<span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">&lt;&lt;</span> <span class="dv" style="color: #AD0000;">18</span>):</span>
<span id="cb220-5">            <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.use_gpu:</span>
<span id="cb220-6">                batch <span class="op" style="color: #5E5E5E;">=</span> batch.cuda().half()</span>
<span id="cb220-7">            codes_ <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.compress_into_codes(batch, out_device<span class="op" style="color: #5E5E5E;">=</span>batch.device)</span>
<span id="cb220-8">            centroids_ <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.lookup_centroids(codes_, out_device<span class="op" style="color: #5E5E5E;">=</span>batch.device)</span>
<span id="cb220-9"></span>
<span id="cb220-10">            residuals_ <span class="op" style="color: #5E5E5E;">=</span> (batch <span class="op" style="color: #5E5E5E;">-</span> centroids_)</span>
<span id="cb220-11"></span>
<span id="cb220-12">            codes.append(codes_.cpu())</span>
<span id="cb220-13">            residuals.append(<span class="va" style="color: #111111;">self</span>.binarize(residuals_).cpu())</span>
<span id="cb220-14"></span>
<span id="cb220-15">        codes <span class="op" style="color: #5E5E5E;">=</span> torch.cat(codes)</span>
<span id="cb220-16">        residuals <span class="op" style="color: #5E5E5E;">=</span> torch.cat(residuals)</span>
<span id="cb220-17"></span>
<span id="cb220-18">        <span class="cf" style="color: #003B4F;">return</span> ResidualCodec.Embeddings(codes, residuals)</span></code></pre></div>
<p>We’ve seen <code>compress_into_codes</code> and <code>lookup_centroids</code> before:</p>
<div class="cell" data-outputid="82757a39-cced-4d5c-c8c3-f758c840585d" data-execution_count="102">
<div class="sourceCode cell-code" id="cb221" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb221-1">codes_ <span class="op" style="color: #5E5E5E;">=</span> compressor.compress_into_codes(embs, out_device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cuda'</span>)</span>
<span id="cb221-2">codes_.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>torch.Size([15198])</code></pre>
</div>
</div>
<p>These codes are the centroids ID closest to each token embeddings.</p>
<div class="cell" data-outputid="63da570e-358e-43bd-88c2-f0b1a74b801c" data-execution_count="103">
<div class="sourceCode cell-code" id="cb223" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb223-1">codes_[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="103">
<pre><code>tensor([654, 843, 401, 654, 926], device='cuda:0')</code></pre>
</div>
</div>
<p>We then get those 15198 centroid vectors:</p>
<div class="cell" data-outputid="fda18ac7-ee33-4d4f-ec04-9528e2453ce3" data-execution_count="104">
<div class="sourceCode cell-code" id="cb225" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb225-1">centroids_ <span class="op" style="color: #5E5E5E;">=</span> compressor.lookup_centroids(codes_, out_device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cuda'</span>)</span>
<span id="cb225-2">centroids_.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<pre><code>torch.Size([15198, 96])</code></pre>
</div>
</div>
<p>A reminder that our centroids and our token embeddings are unit vectors:</p>
<div class="cell" data-outputid="b1543905-9715-4783-b3be-e13eb3094026" data-execution_count="105">
<div class="sourceCode cell-code" id="cb227" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb227-1">centroids_[<span class="dv" style="color: #AD0000;">0</span>].norm(), embs[<span class="dv" style="color: #AD0000;">0</span>].norm()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="105">
<pre><code>(tensor(1., device='cuda:0', dtype=torch.float16),
 tensor(1., dtype=torch.float16))</code></pre>
</div>
</div>
<p>We then find the residuals between token embeddings and centroids:</p>
<div class="cell" data-outputid="a5dda6a8-5743-4fd3-9b0d-36917f21a02e" data-execution_count="106">
<div class="sourceCode cell-code" id="cb229" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb229-1">residuals_ <span class="op" style="color: #5E5E5E;">=</span> (embs.cpu() <span class="op" style="color: #5E5E5E;">-</span> centroids_.cpu())</span>
<span id="cb229-2">residuals_.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="106">
<pre><code>torch.Size([15198, 96])</code></pre>
</div>
</div>
<p>The next piece is <em>super cool</em>. We <code>binarize</code> the residuals, starting by using <code>bucketize</code>:</p>
<div class="cell" data-outputid="e860a0ef-35b7-4d10-8336-2a3ea3e6bd72" data-execution_count="107">
<div class="sourceCode cell-code" id="cb231" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb231-1">residuals <span class="op" style="color: #5E5E5E;">=</span> torch.bucketize(residuals_.<span class="bu" style="color: null;">float</span>().cpu(), bucket_cutoffs.cpu()).to(dtype<span class="op" style="color: #5E5E5E;">=</span>torch.uint8)</span>
<span id="cb231-2">residuals.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="107">
<pre><code>torch.Size([15198, 96])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e7f706cd-4b35-4663-9d89-d7de3d093130" data-execution_count="108">
<div class="sourceCode cell-code" id="cb233" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb233-1">residuals[<span class="dv" style="color: #AD0000;">0</span>][:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>tensor([8, 7, 7, 8, 7], dtype=torch.uint8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="dd9263e6-caaf-48ac-a88f-19c118c8e13b" data-execution_count="109">
<div class="sourceCode cell-code" id="cb235" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb235-1">residuals_[<span class="dv" style="color: #AD0000;">0</span>][:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="109">
<pre><code>tensor([6.1035e-05, 0.0000e+00, 0.0000e+00, 1.9073e-06, 0.0000e+00],
       dtype=torch.float16)</code></pre>
</div>
</div>
<div class="cell" data-outputid="a952ad43-2fc7-4847-c66d-998ff667af2e" data-execution_count="144">
<div class="sourceCode cell-code" id="cb237" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb237-1">residuals_[<span class="dv" style="color: #AD0000;">1</span>][<span class="dv" style="color: #AD0000;">10</span>:<span class="dv" style="color: #AD0000;">20</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="144">
<pre><code>tensor([ 0.0234, -0.0100,  0.0046, -0.0078, -0.0111,  0.0249, -0.0081, -0.0048,
         0.0270,  0.0037], dtype=torch.float16)</code></pre>
</div>
</div>
<div class="cell" data-outputid="5bbaf19f-fb73-4ba3-98a8-2f0869a7cad8" data-execution_count="110">
<div class="sourceCode cell-code" id="cb239" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb239-1">bucket_cutoffs[<span class="dv" style="color: #AD0000;">6</span>:<span class="dv" style="color: #AD0000;">10</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>tensor([-0.0017,  0.0000,  0.0019,  0.0042], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="6e97f8aa-771d-4d69-df7a-50648e37149f" data-execution_count="111">
<div class="sourceCode cell-code" id="cb241" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb241-1">residuals.<span class="bu" style="color: null;">min</span>(), residuals.<span class="bu" style="color: null;">max</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="111">
<pre><code>(tensor(0, dtype=torch.uint8), tensor(15, dtype=torch.uint8))</code></pre>
</div>
</div>
<p>The values of <code>residuals</code> are now the ID (indices) of the buckets that the residual values fall into!</p>
<div class="cell" data-outputid="f379c67e-3051-4a0e-9d35-33c033a39828" data-execution_count="112">
<div class="sourceCode cell-code" id="cb243" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb243-1">residuals <span class="op" style="color: #5E5E5E;">=</span> residuals.unsqueeze(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>).expand(<span class="op" style="color: #5E5E5E;">*</span>residuals.size(), config.nbits)</span>
<span id="cb243-2">residuals.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="112">
<pre><code>torch.Size([15198, 96, 4])</code></pre>
</div>
</div>
<p>We add a space for 4-bits per residual.</p>
<div class="cell" data-outputid="ebcfa0f0-782f-46d9-b050-0215c1833fb6" data-execution_count="113">
<div class="sourceCode cell-code" id="cb245" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb245-1">arange_bits <span class="op" style="color: #5E5E5E;">=</span> torch.arange(<span class="dv" style="color: #AD0000;">0</span>, config.nbits, device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cuda'</span>, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.uint8)</span>
<span id="cb245-2">arange_bits</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>tensor([0, 1, 2, 3], device='cuda:0', dtype=torch.uint8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="a9d88007-2fc8-4d6f-847a-0b6635666954" data-execution_count="114">
<div class="sourceCode cell-code" id="cb247" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb247-1">residuals <span class="op" style="color: #5E5E5E;">=</span> residuals.cpu() <span class="op" style="color: #5E5E5E;">&gt;&gt;</span> arange_bits.cpu()</span>
<span id="cb247-2">residuals.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="114">
<pre><code>torch.Size([15198, 96, 4])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ef3c7ef7-9a30-462a-90ae-a617cf11e584" data-execution_count="115">
<div class="sourceCode cell-code" id="cb249" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb249-1">residuals[<span class="dv" style="color: #AD0000;">0</span>][:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="115">
<pre><code>tensor([[8, 4, 2, 1],
        [7, 3, 1, 0],
        [7, 3, 1, 0],
        [8, 4, 2, 1],
        [7, 3, 1, 0]], dtype=torch.uint8)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb251" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb251-1">residuals <span class="op" style="color: #5E5E5E;">=</span> residuals <span class="op" style="color: #5E5E5E;">&amp;</span> <span class="dv" style="color: #AD0000;">1</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="49ffdff1-767f-4e6d-e76c-7d224a302255" data-execution_count="117">
<div class="sourceCode cell-code" id="cb252" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb252-1">residuals[<span class="dv" style="color: #AD0000;">0</span>][:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="117">
<pre><code>tensor([[0, 0, 0, 1],
        [1, 1, 1, 0],
        [1, 1, 1, 0],
        [0, 0, 0, 1],
        [1, 1, 1, 0]], dtype=torch.uint8)</code></pre>
</div>
</div>
<p>We have now converted the bucket ID into the actual 4-bit binary value it represents.</p>
<div class="cell" data-outputid="3570c048-cb9b-4262-87e9-07ee6275be44" data-execution_count="118">
<div class="sourceCode cell-code" id="cb254" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb254-1">residuals_packed <span class="op" style="color: #5E5E5E;">=</span> np.packbits(np.asarray(residuals.contiguous().flatten()))</span>
<span id="cb254-2">residuals_packed <span class="op" style="color: #5E5E5E;">=</span> torch.as_tensor(residuals_packed, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.uint8)</span>
<span id="cb254-3">residuals_packed <span class="op" style="color: #5E5E5E;">=</span> residuals_packed.reshape(residuals.size(<span class="dv" style="color: #AD0000;">0</span>), config.dim <span class="op" style="color: #5E5E5E;">//</span> <span class="dv" style="color: #AD0000;">8</span> <span class="op" style="color: #5E5E5E;">*</span> config.nbits)</span>
<span id="cb254-4">residuals_packed.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>torch.Size([15198, 48])</code></pre>
</div>
</div>
<div class="cell" data-outputid="a627b3f7-5234-458e-cef0-c483e854316a" data-execution_count="119">
<div class="sourceCode cell-code" id="cb256" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb256-1">residuals_packed[<span class="dv" style="color: #AD0000;">0</span>][:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="119">
<pre><code>tensor([ 30, 225, 225, 238, 238], dtype=torch.uint8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="68dcabcf-bddb-4463-b81e-8168b29a1fba" data-execution_count="120">
<div class="sourceCode cell-code" id="cb258" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb258-1"><span class="ss" style="color: #20794D;">f"30 in binary: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">bin</span>(<span class="dv" style="color: #AD0000;">30</span>)[<span class="dv" style="color: #AD0000;">2</span>:]<span class="sc" style="color: #5E5E5E;">.</span>zfill(<span class="dv" style="color: #AD0000;">8</span>)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="120">
<pre><code>'30 in binary: 00011110'</code></pre>
</div>
</div>
<p>For each residual vector with 96 values, each value is represented with 4-bits (e.g.&nbsp;0, 0, 0, 1). Every 8 bits are stored into an integer (e.g.&nbsp;0001 and 1110 concatenate to become the integer 30) so we have cut the number of values in half (from 96 to 48).</p>
<p>These residuals would be stored in 0.residuals.pt.</p>
<section id="build_ivf" class="level3">
<h3 class="anchored" data-anchor-id="build_ivf">_build_ivf</h3>
<p>This is a critical piece—the mapping between passages and centroids!</p>
<div class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb260" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb260-1">codes <span class="op" style="color: #5E5E5E;">=</span> codes_.sort()</span>
<span id="cb260-2">ivf, values <span class="op" style="color: #5E5E5E;">=</span> codes.indices, codes.values</span></code></pre></div>
</div>
<p>Token embeddings IDs:</p>
<div class="cell" data-outputid="0a8941c2-e96a-453a-ad35-687d6b05d7fa" data-execution_count="122">
<div class="sourceCode cell-code" id="cb261" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb261-1">ivf</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="122">
<pre><code>tensor([  936,  1171,  2363,  ..., 12051, 12147, 12161], device='cuda:0')</code></pre>
</div>
</div>
<p>Centroid IDs:</p>
<div class="cell" data-outputid="9c575499-74e7-437c-a7ec-3f6224bdace3" data-execution_count="123">
<div class="sourceCode cell-code" id="cb263" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb263-1">values</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="123">
<pre><code>tensor([   0,    0,    0,  ..., 1023, 1023, 1023], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="2625c9fd-341c-43fa-cc67-8cd42aab05b0" data-execution_count="124">
<div class="sourceCode cell-code" id="cb265" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb265-1">ivf.shape, values.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="124">
<pre><code>(torch.Size([15198]), torch.Size([15198]))</code></pre>
</div>
</div>
<p><code>ivf</code> contains the token embedding ID (the indices of <code>codes_</code>) and <code>values</code> contains the centroid ID (the values of <code>codes_</code>).</p>
<p>We then get the number of tokens per centroid ID:</p>
<div class="cell" data-outputid="c9f64c61-1c04-4218-fbe1-7ee963268021" data-execution_count="125">
<div class="sourceCode cell-code" id="cb267" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb267-1">ivf_lengths <span class="op" style="color: #5E5E5E;">=</span> torch.bincount(values, minlength<span class="op" style="color: #5E5E5E;">=</span>num_partitions)</span>
<span id="cb267-2">ivf_lengths</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="125">
<pre><code>tensor([10, 11, 17,  ..., 17,  9, 29], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="cb4967d4-6fa5-46dc-9a60-1e2fce30a0a5" data-execution_count="126">
<div class="sourceCode cell-code" id="cb269" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb269-1">ivf_lengths.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="126">
<pre><code>torch.Size([1024])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ab06f90b-3457-4c00-97f5-e332b495a3a7" data-execution_count="127">
<div class="sourceCode cell-code" id="cb271" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb271-1">ivf_lengths.<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="127">
<pre><code>tensor(15198, device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="colbertindexingutils.py-optimize_ivf" class="level3">
<h3 class="anchored" data-anchor-id="colbertindexingutils.py-optimize_ivf">colbert/indexing/utils.py: optimize_ivf</h3>
<p>We have 1000 documents containing a total of 15198 tokens.</p>
<div class="cell" data-outputid="36918e33-d687-4eb3-f114-0b0dfbc6ca7e" data-execution_count="128">
<div class="sourceCode cell-code" id="cb273" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb273-1">total_num_embeddings <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(doclens)</span>
<span id="cb273-2"><span class="bu" style="color: null;">len</span>(doclens), total_num_embeddings</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="128">
<pre><code>(1000, 15198)</code></pre>
</div>
</div>
<p>Instantiating an empty mapping between token embeddings IDs and passage IDs</p>
<div class="cell" data-outputid="349ec960-7935-41db-ead6-9b1e4d4f4175" data-execution_count="129">
<div class="sourceCode cell-code" id="cb275" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb275-1">emb2pid <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(total_num_embeddings, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.<span class="bu" style="color: null;">int</span>)</span>
<span id="cb275-2">emb2pid.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="129">
<pre><code>torch.Size([15198])</code></pre>
</div>
</div>
<p>The indices of <code>doclens</code> are passage IDs <code>pid</code>. The values are the number of tokens in the document <code>dlength</code>.</p>
<div class="cell" data-execution_count="130">
<div class="sourceCode cell-code" id="cb277" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb277-1">offset_doclens <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb277-2"><span class="cf" style="color: #003B4F;">for</span> pid, dlength <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(doclens):</span>
<span id="cb277-3">    emb2pid[offset_doclens: offset_doclens <span class="op" style="color: #5E5E5E;">+</span> dlength] <span class="op" style="color: #5E5E5E;">=</span> pid</span>
<span id="cb277-4">    offset_doclens <span class="op" style="color: #5E5E5E;">+=</span> dlength</span></code></pre></div>
</div>
<div class="cell" data-outputid="abd41ab8-b033-4cab-f477-0020bca35b9b" data-execution_count="131">
<div class="sourceCode cell-code" id="cb278" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb278-1">emb2pid.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="131">
<pre><code>torch.Size([15198])</code></pre>
</div>
</div>
<p>The first 4 token embeddings correspond to the first passage, the next 20 token embeddings to the second passage, and so on.</p>
<div class="cell" data-outputid="185d9dde-73dd-4676-972d-110d141244dd" data-execution_count="132">
<div class="sourceCode cell-code" id="cb280" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb280-1">emb2pid[:<span class="dv" style="color: #AD0000;">50</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="132">
<pre><code>tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,
        3, 3], dtype=torch.int32)</code></pre>
</div>
</div>
<p>Recall that <code>ivf</code> contained as values the token embeddings IDs which are the indices of <code>emb2pid</code>. The values of <code>emb2pid</code> are passage IDs. Indexing into <code>emb2pid</code> with <code>ivf</code> pulls out the passage IDs corresponding to tokens. Note that <code>ivf</code> is sorted by centroid ID.</p>
<div class="cell" data-outputid="9a5ff539-5781-4b8a-909d-d71e67b45e4f" data-execution_count="133">
<div class="sourceCode cell-code" id="cb282" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb282-1">ivf</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="133">
<pre><code>tensor([  936,  1171,  2363,  ..., 12051, 12147, 12161], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="2d3478d4-a6db-435d-84c3-26586af708e8" data-execution_count="134">
<div class="sourceCode cell-code" id="cb284" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb284-1">values</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="134">
<pre><code>tensor([   0,    0,    0,  ..., 1023, 1023, 1023], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="c8de26e5-55cc-47fa-9211-ec2d3137c285" data-execution_count="135">
<div class="sourceCode cell-code" id="cb286" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb286-1">new_ivf <span class="op" style="color: #5E5E5E;">=</span> emb2pid[ivf.cpu()]</span>
<span id="cb286-2">new_ivf.shape, new_ivf[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="135">
<pre><code>(torch.Size([15198]), tensor([ 55,  69, 143, 416, 471], dtype=torch.int32))</code></pre>
</div>
</div>
<div class="cell" data-outputid="8b3ce2a7-0e4c-4f41-fc9f-c2c0a711cf76" data-execution_count="136">
<div class="sourceCode cell-code" id="cb288" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb288-1">new_ivf</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="136">
<pre><code>tensor([ 55,  69, 143,  ..., 795, 800, 800], dtype=torch.int32)</code></pre>
</div>
</div>
<p>The first token embedding corresponding to centroid ID of 0 corresponds to passage ID 55.</p>
<div class="cell" data-outputid="3422eb75-44e7-4bf3-e2c9-393a22fbb47f" data-execution_count="137">
<div class="sourceCode cell-code" id="cb290" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb290-1">emb2pid[<span class="dv" style="color: #AD0000;">936</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="137">
<pre><code>tensor(55, dtype=torch.int32)</code></pre>
</div>
</div>
<p><code>new_ivf</code> is a mapping from its indices (token embeddings) to values (passage IDs) which is now aligned to the <code>ivf_lengths</code> tensor which contains number of tokens per centroid ID (which came from <code>values</code>).</p>
<p>Next, we iterate through <code>ivf_lengths</code>, which contains the number of tokens per centroid ID. For each <code>length</code> we get the unique passages IDs from <code>new_ivf</code>, and append that to <code>unique_pids_per_centroid</code>. The number of unique pids for that centroid is added to <code>new_ivf_lengths</code>.</p>
<div class="cell" data-outputid="e0a2e628-3973-4569-d3fe-0fd919828152" data-execution_count="138">
<div class="sourceCode cell-code" id="cb292" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb292-1">unique_pids_per_centroid <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb292-2">new_ivf_lengths <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb292-3"></span>
<span id="cb292-4">offset <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb292-5"><span class="cf" style="color: #003B4F;">for</span> length <span class="kw" style="color: #003B4F;">in</span> tqdm.tqdm(ivf_lengths.tolist()):</span>
<span id="cb292-6">    pids <span class="op" style="color: #5E5E5E;">=</span> torch.unique(new_ivf[offset:offset<span class="op" style="color: #5E5E5E;">+</span>length])</span>
<span id="cb292-7">    unique_pids_per_centroid.append(pids)</span>
<span id="cb292-8">    new_ivf_lengths.append(pids.shape[<span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb292-9">    offset <span class="op" style="color: #5E5E5E;">+=</span> length</span>
<span id="cb292-10">ivf <span class="op" style="color: #5E5E5E;">=</span> torch.cat(unique_pids_per_centroid)</span>
<span id="cb292-11">new_ivf_lengths <span class="op" style="color: #5E5E5E;">=</span> torch.tensor(new_ivf_lengths)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 1024/1024 [00:00&lt;00:00, 35975.77it/s]
&lt;ipython-input-138-6c68981e98f9&gt;:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  new_ivf_lengths = torch.tensor(ivf_lengths)</code></pre>
</div>
</div>
<div class="cell" data-outputid="037fa496-6036-491b-ee1b-8ccbd2686e75" data-execution_count="139">
<div class="sourceCode cell-code" id="cb294" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb294-1">ivf.shape, new_ivf_lengths.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="139">
<pre><code>(torch.Size([11593]), torch.Size([1024]))</code></pre>
</div>
</div>
<p>Note that there are now fewer values in <code>ivf</code> than 15198 since we are only capturing the unique pids per centroid.</p>
<div class="cell" data-outputid="c0dd2e47-ad6c-4298-e895-dcfd39ff4898" data-execution_count="140">
<div class="sourceCode cell-code" id="cb296" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb296-1">ivf[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="140">
<pre><code>tensor([ 55,  69, 143, 416, 471], dtype=torch.int32)</code></pre>
</div>
</div>
<div class="cell" data-outputid="1b6b71a0-fe95-40a4-ad3e-8dd8c089d87d" data-execution_count="141">
<div class="sourceCode cell-code" id="cb298" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb298-1">new_ivf_lengths[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="141">
<pre><code>tensor([10, 11, 17,  1, 34], device='cuda:0')</code></pre>
</div>
</div>
<p><code>new_ivf_lengths</code> is the count of unique passage IDs per centroid. So, for example the first 10 pids correspond to centroid ID <code>0</code>.</p>
<p><code>ivf</code> and <code>new_ivf_lengths</code> would be stored in ivf.pid.pt.</p>
<p>After updating metadata, this completes the indexing process in RAGatouille and ColBERT!</p>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>There were of course many details that I didn’t fully explain in this walkthrough, and since I wasn’t able to exactly replicate some of the indexing artifacts there may be some errors in my code, but I think I both covered and understood the main components to creating an index. Getting to this stage involved a <em>lot</em> of discussion with Claude. I used AnswerAI’s toolslm to create context from the RAGatouille and ColBERT repos to provide as Claude project knowledge. I also pored through the codebase for hours, making sure to trace my steps from method-to-method. While I could do more deep dives into the individual components of indexing, I feel satisfied with this walk through for now. I hope you enjoyed this blog post!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>information retrieval</category>
  <category>machine learning</category>
  <category>deep learning</category>
  <category>RAGatouille</category>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-03-12-RAGatouille-ColBERT-Indexing-Deep-Dive/index.html</guid>
  <pubDate>Wed, 12 Mar 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TIL: PeftModel Base Model Behavior</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-03-10-TIL-PeftModel-Behavior/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this TIL blog post I share some unexpected behavior when using <code>PeftModel</code>. In short, when merging LoRA adapter weights with the base model, the base model gets overwritten. While unexpected, in hindsight this makes sense if you want to minimize memory usage.</p>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoModelForCausalLM</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> peft <span class="im" style="color: #00769E;">import</span> PeftModel</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> psutil</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> copy</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> gc</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> google.colab <span class="im" style="color: #00769E;">import</span> userdata</span>
<span id="cb2-2"></span>
<span id="cb2-3">os.environ[<span class="st" style="color: #20794D;">'HUGGING_FACE_HUB_TOKEN'</span>] <span class="op" style="color: #5E5E5E;">=</span> userdata.get(<span class="st" style="color: #20794D;">'HUGGING_FACE_HUB_TOKEN'</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">def</span> _mem(): <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"RAM Usage: </span><span class="sc" style="color: #5E5E5E;">{</span>psutil<span class="sc" style="color: #5E5E5E;">.</span>virtual_memory()<span class="sc" style="color: #5E5E5E;">.</span>percent<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">% (Used: </span><span class="sc" style="color: #5E5E5E;">{</span>psutil<span class="sc" style="color: #5E5E5E;">.</span>virtual_memory()<span class="sc" style="color: #5E5E5E;">.</span>used <span class="op" style="color: #5E5E5E;">/</span> (<span class="dv" style="color: #AD0000;">1024</span><span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span>)<span class="sc" style="color: #5E5E5E;">:.2f}</span><span class="ss" style="color: #20794D;"> GB / Total: </span><span class="sc" style="color: #5E5E5E;">{</span>psutil<span class="sc" style="color: #5E5E5E;">.</span>virtual_memory()<span class="sc" style="color: #5E5E5E;">.</span>total <span class="op" style="color: #5E5E5E;">/</span> (<span class="dv" style="color: #AD0000;">1024</span><span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">3</span>)<span class="sc" style="color: #5E5E5E;">:.2f}</span><span class="ss" style="color: #20794D;"> GB)"</span>)</span></code></pre></div>
</div>
</section>
<section id="merging-lora-adapter-weights" class="level2">
<h2 class="anchored" data-anchor-id="merging-lora-adapter-weights">Merging LoRA Adapter Weights</h2>
<p>Before loading any model, here is the memory usage. I’m using an A100 GPU with Colab Pro.</p>
<div class="cell" data-outputid="b461255e-c263-4bba-c06b-4148a74092f9" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">_mem()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>RAM Usage: 3.5% (Used: 2.10 GB / Total: 83.48 GB)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">base_model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;">"meta-llama/Llama-2-7b-hf"</span>).to(<span class="st" style="color: #20794D;">"cpu"</span>)</span></code></pre></div>
</div>
<p>After loading the base model (Llama2-7B) the memory usage increases to 27GB.</p>
<div class="cell" data-outputid="8bf9d682-b07b-4bc0-c632-3081f1f8dce6" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">_mem()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>RAM Usage: 33.8% (Used: 27.35 GB / Total: 83.48 GB)</code></pre>
</div>
</div>
<p>Loading the LoRA adapter weights increases the memory usage to 28 GB.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">model_to_merge <span class="op" style="color: #5E5E5E;">=</span> PeftModel.from_pretrained(</span>
<span id="cb9-2">    model<span class="op" style="color: #5E5E5E;">=</span>base_model,</span>
<span id="cb9-3">    model_id<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"LoRA-TMLR-2024/magicoder-lora-rank-64-alpha-128"</span></span>
<span id="cb9-4">).to(<span class="st" style="color: #20794D;">"cpu"</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="c5110313-9aa0-4808-dd9f-36ab1d38cb0b" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">_mem()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>RAM Usage: 34.8% (Used: 28.22 GB / Total: 83.48 GB)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">merged_model <span class="op" style="color: #5E5E5E;">=</span> model_to_merge.merge_and_unload()</span></code></pre></div>
</div>
<p>Merging the model essentially keeps the memory usage constant at 28GB.</p>
<div class="cell" data-outputid="53481002-dcec-4742-84c1-ed3e7770493f" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">_mem()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>RAM Usage: 34.9% (Used: 28.28 GB / Total: 83.48 GB)</code></pre>
</div>
</div>
</section>
<section id="comparing-base_model-and-merged_model-weights" class="level2">
<h2 class="anchored" data-anchor-id="comparing-base_model-and-merged_model-weights">Comparing <code>base_model</code> and <code>merged_model</code> Weights</h2>
<p>However, saving memory comes at a cost! You no longer have access to the base model. I’ll first do a visual inspection of one of the weight matrices.</p>
<div class="cell" data-outputid="71d52a31-eed0-4dec-f48c-bf132f221ed5" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">base_model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.q_proj.weight</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>Parameter containing:
tensor([[-0.0020, -0.0156,  0.0023,  ...,  0.0098, -0.0017, -0.0031],
        [ 0.0283, -0.0176,  0.0062,  ..., -0.0076,  0.0004,  0.0087],
        [-0.0230,  0.0225,  0.0001,  ...,  0.0028,  0.0190, -0.0063],
        ...,
        [ 0.0003,  0.0016, -0.0013,  ...,  0.0081, -0.0308,  0.0110],
        [ 0.0259,  0.0203,  0.0045,  ..., -0.0310, -0.0147, -0.0111],
        [-0.0077, -0.0174,  0.0012,  ...,  0.0182,  0.0181, -0.0070]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="9b2f1df8-7c78-4f23-ef3b-77c2b981ff99" data-execution_count="13">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">merged_model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.q_proj.weight</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>Parameter containing:
tensor([[-0.0020, -0.0156,  0.0023,  ...,  0.0098, -0.0017, -0.0031],
        [ 0.0283, -0.0176,  0.0062,  ..., -0.0076,  0.0004,  0.0087],
        [-0.0230,  0.0225,  0.0001,  ...,  0.0028,  0.0190, -0.0063],
        ...,
        [ 0.0003,  0.0016, -0.0013,  ...,  0.0081, -0.0308,  0.0110],
        [ 0.0259,  0.0203,  0.0045,  ..., -0.0310, -0.0147, -0.0111],
        [-0.0077, -0.0174,  0.0012,  ...,  0.0182,  0.0181, -0.0070]])</code></pre>
</div>
</div>
<p>Both matrices are equal. Analyzing weight matrix differences more systematically:</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;">def</span> _diffs(model1, model2):</span>
<span id="cb19-2">    n_diff <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb19-3">    <span class="cf" style="color: #003B4F;">for</span> layer_idx <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">32</span>):</span>
<span id="cb19-4">        <span class="cf" style="color: #003B4F;">for</span> component <span class="kw" style="color: #003B4F;">in</span> [<span class="st" style="color: #20794D;">"q_proj"</span>, <span class="st" style="color: #20794D;">"k_proj"</span>, <span class="st" style="color: #20794D;">"o_proj"</span>, <span class="st" style="color: #20794D;">"v_proj"</span>]:</span>
<span id="cb19-5">            W1 <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">getattr</span>(model1.model.layers[layer_idx].self_attn, component).weight</span>
<span id="cb19-6">            W2<span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">getattr</span>(model2.model.layers[layer_idx].self_attn, component).weight</span>
<span id="cb19-7">            <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> torch.allclose(W1, W2, rtol<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1e-5</span>, atol<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1e-8</span>): n_diff <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb19-8">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Different Self-Attention Matrices: </span><span class="sc" style="color: #5E5E5E;">{</span>n_diff<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb19-9">    n_diff <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb19-10">    <span class="cf" style="color: #003B4F;">for</span> layer_idx <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">32</span>):</span>
<span id="cb19-11">        <span class="cf" style="color: #003B4F;">for</span> component <span class="kw" style="color: #003B4F;">in</span> [<span class="st" style="color: #20794D;">"up_proj"</span>, <span class="st" style="color: #20794D;">"down_proj"</span>, <span class="st" style="color: #20794D;">"gate_proj"</span>]:</span>
<span id="cb19-12">            W1 <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">getattr</span>(model1.model.layers[layer_idx].mlp, component).weight</span>
<span id="cb19-13">            W2 <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">getattr</span>(model2.model.layers[layer_idx].mlp, component).weight</span>
<span id="cb19-14">            <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> torch.allclose(W1, W2, rtol<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1e-5</span>, atol<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1e-8</span>): n_diff <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb19-15">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Different MLP Weight Matrices: </span><span class="sc" style="color: #5E5E5E;">{</span>n_diff<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="3725270e-f6e2-494a-ea46-28c2fa835116" data-execution_count="21">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">_diffs(base_model, merged_model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Different Self-Attention Matrices: 0
Different MLP Weight Matrices: 0</code></pre>
</div>
</div>
<p>For both self-attention and MLP modules, all weight matrices between the <code>base_model</code> and the <code>merged_model</code> are the same. Using the <code>is</code> operator we can see that they reference the same object in memory (which is where the memory savings come from):</p>
<div class="cell" data-outputid="f6d7747c-a8d9-4c32-8172-0b6ba59831ed" data-execution_count="23">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">base_model <span class="kw" style="color: #003B4F;">is</span> merged_model</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>True</code></pre>
</div>
</div>
</section>
<section id="copying-the-base-model-for-comparison" class="level2">
<h2 class="anchored" data-anchor-id="copying-the-base-model-for-comparison">Copying the Base Model for Comparison</h2>
<p>I’ll now load the base model again to compare with the merged model weights.</p>
<div class="cell" data-outputid="7cefff4e-025f-4b4c-bff5-09676d8af019" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">_mem()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>RAM Usage: 35.4% (Used: 28.68 GB / Total: 83.48 GB)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="kw" style="color: #003B4F;">del</span> base_model</span></code></pre></div>
</div>
<div class="cell" data-outputid="213ac2ca-846f-4460-cce6-4b4bed5ad05f" data-execution_count="27">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">gc.collect()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>483</code></pre>
</div>
</div>
<div class="cell" data-outputid="8a10f443-157a-456a-cb0a-34e11771d03b" data-execution_count="54">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">_mem()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>RAM Usage: 35.5% (Used: 28.78 GB / Total: 83.48 GB)</code></pre>
</div>
</div>
<p>Note that deleting the base model did not change the memory usage.</p>
<div class="cell" data-outputid="74341ad5-ee28-474b-d505-0a5f04e140e5" data-execution_count="55">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">base_model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;">"meta-llama/Llama-2-7b-hf"</span>).to(<span class="st" style="color: #20794D;">"cpu"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ee5aafe00d32446f95ab002be2ec8fcc","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-outputid="faa5c925-2fdc-45b9-b943-07f8baf2e19c" data-execution_count="56">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">_mem()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>RAM Usage: 65.7% (Used: 53.94 GB / Total: 83.48 GB)</code></pre>
</div>
</div>
<p>With a new base model loaded, the memory usage jumps up to 54 GB.</p>
<div class="cell" data-outputid="83d16db7-457a-4ca2-c6a9-f24e099d27c6" data-execution_count="57">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">_diffs(base_model, merged_model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Different Self-Attention Matrices: 128
Different MLP Weight Matrices: 96</code></pre>
</div>
</div>
<p>There are 32 layers in this Llama model, and each model’s self-attention module has 4 weight matrices we are comparing, resulting in 128 matrices in total. The MLP module has 3 weight matrices we are comparing, resulting in 96 total across the model. The base model and merged model are fully different models (in terms of weight matrix values).</p>
</section>
<section id="using-.get_base_model" class="level2">
<h2 class="anchored" data-anchor-id="using-.get_base_model">Using <code>.get_base_model</code></h2>
<p>Looking at the <code>PeftModel</code> documentation, I noted the method <code>get_base_model</code> which seems relevant to this exercise. However, using that method results in the same weights as the merged model:</p>
<div class="cell" data-outputid="6ba3da16-ba96-4c24-9b8b-d0abcff91230" data-execution_count="59">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">model_to_merge.get_base_model</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<div style="max-width:800px; border: 1px solid var(--colab-border-color);"><style>
      pre.function-repr-contents {
        overflow-x: auto;
        padding: 8px 12px;
        max-height: 500px;
      }

      pre.function-repr-contents.function-repr-contents-collapsed {
        cursor: pointer;
        max-height: 100px;
      }
    </style>
    <pre style="white-space: initial; background:
         var(--colab-secondary-surface-color); padding: 8px 12px;
         border-bottom: 1px solid var(--colab-border-color);"><b>peft.peft_model.PeftModel.get_base_model</b><br>def get_base_model() -&gt; torch.nn.Module</pre><pre class="function-repr-contents function-repr-contents-collapsed" style="">/usr/local/lib/python3.11/dist-packages/peft/peft_model.pyReturns the base model.</pre>
      <script>
      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {
        for (const element of document.querySelectorAll('.filepath')) {
          element.style.display = 'block'
          element.onclick = (event) => {
            event.preventDefault();
            event.stopPropagation();
            google.colab.files.view(element.textContent, 912);
          };
        }
      }
      for (const element of document.querySelectorAll('.function-repr-contents')) {
        element.onclick = (event) => {
          event.preventDefault();
          event.stopPropagation();
          element.classList.toggle('function-repr-contents-collapsed');
        };
      }
      </script>
      </div>
</div>
</div>
<div class="cell" data-outputid="28cc252a-570d-41b6-cecd-2a7dbbab953d" data-execution_count="60">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">_diffs(merged_model, model_to_merge.get_base_model())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Different Self-Attention Matrices: 0
Different MLP Weight Matrices: 0</code></pre>
</div>
</div>
<hr>
<p>I am planning to do more of these short TIL blog posts this year! It helps me solidify concepts as I come across them. I hope you enjoyed this blog post!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>machine learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-03-10-TIL-PeftModel-Behavior/index.html</guid>
  <pubDate>Mon, 10 Mar 2025 07:00:00 GMT</pubDate>
</item>
</channel>
</rss>
