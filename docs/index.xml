<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Vishal Bakshi&#39;s Blog</title>
<link>https://vishalbakshi.github.io/blog/</link>
<atom:link href="https://vishalbakshi.github.io/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Machine Learning blog by Vishal Bakshi</description>
<generator>quarto-1.7.32</generator>
<lastBuildDate>Sun, 14 Sep 2025 07:00:00 GMT</lastBuildDate>
<item>
  <title>Debugging ColBERT Index Differences Between PyTorch 2.7.1 and 2.8.0</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-09-14-colbert-maintenance/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I’ve been redoing my <code>colbert-ai</code> index comparisons between PyTorch versions using <a href="https://github.com/bitsandbytes-foundation/bitsandbytes/blob/39dd8471c1c0677001d0d20ba2218b14bf18fd00/tests/test_optim.py#L189-L194">bitsandbytes’ <code>torch.allclose</code> tolerances</a>. There are three PyTorch version changes that cause index artifact changes: 2.0.1 to 2.1.0 (<a href="https://vishalbakshi.github.io/blog/posts/2025-09-13-colbert-maintenance/"><code>BertModel</code> forward pass outputs diverge for all inputs</a>), 2.4.1 to 2.5.0 (<a href="https://vishalbakshi.github.io/blog/posts/2025-09-11-colbert-maintenance/">certain batch sizes cause <code>BertModel</code> output divergence</a>), and 2.7.1 to 2.8.0 (detailed in this blog post).</p>
</section>
<section id="difference-between-pytorch-versions-residuals.pt" class="level2">
<h2 class="anchored" data-anchor-id="difference-between-pytorch-versions-residuals.pt">Difference Between PyTorch Versions: <code>residuals.pt</code></h2>
<p>When using the bitsandbytes’ <code>torch.allclose</code> tolerances, all final index artifacts pass <code>torch.allclose</code> except <code>residuals.pt</code>. Residuals are a key component in the indexing pipeline, they are the distance between document token embeddings and centroids. From <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/codecs/residual.py#L167">residual.py’s <code>ResidualCodec.compress</code></a>:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> compress(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, embs, chunk_idx): <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># chunk_idx ADDED BY VISHAL</span></span>
<span id="cb1-2">    codes, residuals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [], []</span>
<span id="cb1-3"></span>
<span id="cb1-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> batch <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> embs.split(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>):</span>
<span id="cb1-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.use_gpu:</span>
<span id="cb1-6">            batch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> batch.cuda().half()</span>
<span id="cb1-7">        codes_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.compress_into_codes(batch, out_device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch.device)</span>
<span id="cb1-8">        centroids_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.lookup_centroids(codes_, out_device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch.device)</span>
<span id="cb1-9"></span>
<span id="cb1-10">        residuals_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (batch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> centroids_)</span>
<span id="cb1-11">        torch.save(residuals_, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/residuals__</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>chunk_idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb1-12">        torch.save(codes_, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/codes__</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>chunk_idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb1-13">        torch.save(batch, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/batch_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>chunk_idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb1-14">        torch.save(centroids_, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/centroids__</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>chunk_idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb1-15">        codes.append(codes_.cpu())</span>
<span id="cb1-16">        residuals.append(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.binarize(residuals_).cpu())</span>
<span id="cb1-17"></span>
<span id="cb1-18">    codes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat(codes)</span>
<span id="cb1-19">    torch.save(codes, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/compress_codes_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>chunk_idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pt"</span>)</span>
<span id="cb1-20">    residuals <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat(residuals)</span>
<span id="cb1-21"></span>
<span id="cb1-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> ResidualCodec.Embeddings(codes, residuals)</span></code></pre></div>
<p>The key line is:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">residuals_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (batch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> centroids_)</span></code></pre></div>
<p>As you can see above, I have added <code>torch.save</code> calls to compare those intermediate index artifacts between PyTorch versions.</p>
<p>I figured that since <code>residuals_</code> do not pass <code>torch.allclose</code> between torch versions, <code>batch</code> and <code>centroids_</code> must not as well. I was wrong! <code>batch</code> does not only pass <code>torch.allclose</code> but also passes <code>torch.equal</code> between torch versions. <code>centroids_</code> passes <code>torch.allclose</code> but not <code>torch.equal</code>. Even though <code>centroids_</code> values are within floating-point tolerance (<code>torch.allclose</code> passes), the small differences get amplified during the subtraction operation that creates <code>residuals_</code>. This amplification pushes the final result outside the tolerance bounds, causing <code>residuals_</code> to fail <code>torch.allclose</code>.</p>
</section>
<section id="difference-between-pytorch-versions-centroids.pt" class="level2">
<h2 class="anchored" data-anchor-id="difference-between-pytorch-versions-centroids.pt">Difference Between PyTorch Versions: <code>centroids.pt</code></h2>
<p>This begs the question: why are <code>centroids_</code> between PyTorch versions not exactly equal? In other words, why don’t <code>centroids_</code> pass <code>torch.equal</code> like <code>batch</code> does? To figure this out, I added <code>torch.save</code> calls to <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/collection_indexer.py#L280"><code>_train_kmeans</code></a> where the centroids are created:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _train_kmeans(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, sample, shared_lists):</span>
<span id="cb3-2">        centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> compute_faiss_kmeans(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args_)</span>
<span id="cb3-3">    torch.save(centroids, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/prenorm_centroids.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb3-4">    centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.functional.normalize(centroids, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> POSTNORM_CENTROIDS_SWAP <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"True"</span>: centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>POSTNORM_CENTROIDS_SWAP_ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/postnorm_centroids.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb3-6">    torch.save(centroids, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/postnorm_centroids.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb3-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.use_gpu:</span>
<span id="cb3-8">        centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> centroids.half()</span>
<span id="cb3-9">        torch.save(centroids, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/half_centroids.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb3-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb3-11">        centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> centroids.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>()</span>
<span id="cb3-12"></span>
<span id="cb3-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> centroids</span></code></pre></div>
<p>There are three versions of centroids I save: <code>prenorm_centroids.pt</code> (the output of <code>compute_faiss_kmeans</code>), <code>postnorm_centroids.pt</code> (the output of <code>torch.nn.functional.normalize(centroids, dim=-1)</code>) and <code>half_centroids.pt</code> (the output of <code>centroids.half()</code>).</p>
<p>I compare each tensor (created with <code>torch==2.7.1</code> and <code>torch==2.8.0</code>) with both <code>torch.allclose</code> and <code>torch.equal</code>:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Tensor</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
<th style="text-align: center;"><code>torch.equal</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">prenorm_centroids.pt</td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;">postnorm_centroids.pt</td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;">half_centroids.pt</td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
</tbody>
</table>
<p>The pre-norm centroids are <em>exactly the same</em> between PyTorch versions, but the post-norm centroids are not. To confirm that the divergence between PyTorch versions is the normalization operation, I replace the 2.8.0 <code>postnorm_centroids.pt</code> with the 2.7.1 ones (the <code>if POSTNORM_CENTROIDS_SWAP == "True"</code> line in the code above) and all final and intermediate index artifacts (including <code>residuals.pt</code>) pass <code>torch.allclose</code> between PyTorch versions.</p>
<p>To confirm that there exists a difference in normalization between PyTorch versions 2.7.1 and 2.8.0 I generate the following tensors with each install:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>)</span>
<span id="cb4-2">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.empty(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>).uniform_(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>)</span>
<span id="cb4-3">torch.save(t, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/t.pt"</span>)</span>
<span id="cb4-4">torch.save(t.half(), <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/half_t.pt"</span>)</span>
<span id="cb4-5"></span>
<span id="cb4-6">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.functional.normalize(t, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-7">torch.save(t, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/norm.pt"</span>)</span>
<span id="cb4-8">torch.save(t.half(), <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/half_norm.pt"</span>)</span></code></pre></div>
<p>Comparing the four tensors (<code>t.pt</code>, <code>half_t.pt</code>, <code>norm.pt</code> and <code>half_norm.pt</code>) between PyTorch versions:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Tensor</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
<th style="text-align: center;"><code>torch.equal</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">t.pt</td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;">half_t.pt</td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;">norm.pt</td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="even">
<td style="text-align: center;">half_norm.pt</td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
</tbody>
</table>
<p>While all tensors pass <code>torch.allclose</code> (bnb tolerances) the normalized tensors (full precision and half precision) fail <code>torch.equal</code> between PyTorch versions. When used in further operations (as <code>centroids_</code> are when calculating <code>residuals_ = batch - centroids_</code>) this inequality compounds and amplifies floating point differences enough to fail <code>torch.allclose</code> for the residuals.</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>When working with floating point values, it’s easy to dismiss minor differences. The recent <a href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">Thinking Machines’ blog post</a> communicated this sentiment:</p>
<blockquote class="blockquote">
<p>What’s wrong with bumping up the atol/rtol on the failing unit test?</p>
</blockquote>
<p>As I’ve been exploring <code>colbert-ai</code> index artifact differences across PyTorch versions, it’s been tempting to consider that “fix”. However, by caring about failed <code>torch.allclose</code> or <code>torch.equal</code> I’ve learned a lot about how small differences impact index artifacts downstream, and have gained a better understanding of how changes in PyTorch can impact <code>colbert-ai</code>. While I may not cover all such impacts, I’m hoping that documenting them here will help some engineer somewhere who is debugging why their RAG pipeline has subtle changes after bumping up PyTorch versions.</p>


</section>

 ]]></description>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-09-14-colbert-maintenance/</guid>
  <pubDate>Sun, 14 Sep 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Comparing colbert-ai Artifacts Between PyTorch Versions 2.0.1 and 2.1.0</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-09-13-colbert-maintenance/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I’ve been redoing my <code>colbert-ai</code> index comparisons between PyTorch versions using <a href="https://github.com/bitsandbytes-foundation/bitsandbytes/blob/39dd8471c1c0677001d0d20ba2218b14bf18fd00/tests/test_optim.py#L189-L194">bitsandbytes’ <code>torch.allclose</code> tolerances</a>. In this blog post I explore <code>colbert-ai</code> index artifact differences between PyTorch versions 2.0.1 and 2.1.0.</p>
</section>
<section id="comparing-intermediate-and-final-index-artifacts" class="level2">
<h2 class="anchored" data-anchor-id="comparing-intermediate-and-final-index-artifacts">Comparing Intermediate and Final Index Artifacts</h2>
<section id="final-index-artifacts" class="level3">
<h3 class="anchored" data-anchor-id="final-index-artifacts">Final Index Artifacts</h3>
<p>Using the more lenient bitsandbytes tolerances, <mark><code>avg_residual.pt</code> and <code>bucket_weights.pt</code> pass <code>torch.allclose</code></mark> while <code>bucket_cutoffs</code> and <code>centroids</code> do not.</p>
<section id="integer-tensors" class="level4">
<h4 class="anchored" data-anchor-id="integer-tensors">Integer Tensors</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">dtype</th>
<th style="text-align: center;"><code>torch.equal</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>codes.pt</code></td>
<td style="text-align: center;">centroid id mapped to doc token embeddings</td>
<td style="text-align: center;"><code>torch.int32</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>residuals.pt</code></td>
<td style="text-align: center;">difference b/w centroid and doc token embeddings</td>
<td style="text-align: center;"><code>torch.uint8</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>ivf.pid.pt</code> (ivf)</td>
<td style="text-align: center;">unique pids per centroid id</td>
<td style="text-align: center;"><code>torch.int32</code></td>
<td style="text-align: center;"><mark>shape mismatch<mark></mark></mark></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>ivf.pid.pt</code> (ivf_lengths)</td>
<td style="text-align: center;">number of pids per centroid id</td>
<td style="text-align: center;"><code>torch.int64</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
</tbody>
</table>
</section>
<section id="float-tensors" class="level4">
<h4 class="anchored" data-anchor-id="float-tensors">Float Tensors</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">dtype</th>
<th style="text-align: center;">Default</th>
<th style="text-align: center;">bnb</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>avg_residual.pt</code></td>
<td style="text-align: center;">Average difference b/w centroids and doc token embeddings</td>
<td style="text-align: center;"><code>torch.float16</code></td>
<td style="text-align: center;"><code>False</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>buckets.pt</code> (<code>bucket_cutoffs</code>)</td>
<td style="text-align: center;">The quantization bins</td>
<td style="text-align: center;"><code>torch.float32</code></td>
<td style="text-align: center;"><code>False</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>buckets.pt</code> (<code>bucket_weights</code>)</td>
<td style="text-align: center;">The quantization values for each bin</td>
<td style="text-align: center;"><code>torch.float16</code></td>
<td style="text-align: center;"><code>False</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>centroids.pt</code></td>
<td style="text-align: center;">Centroids of clustered sample doc token embeddings</td>
<td style="text-align: center;"><code>torch.float16</code></td>
<td style="text-align: center;"><code>False</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="intermediate-index-artifacts" class="level3">
<h3 class="anchored" data-anchor-id="intermediate-index-artifacts">Intermediate Index Artifacts</h3>
<p>“Intermediate” artifacts are tensors saved in the middle of the indexing pipeline by adding <code>torch.save</code> calls in <code>/colbert/indexing/collection_indexer.py</code> and <code>/colbert/modeling/checkpoint.py</code>.</p>
<section id="integer-tensors-1" class="level4">
<h4 class="anchored" data-anchor-id="integer-tensors-1">Integer Tensors</h4>
<p>Some of the intermediate artifacts are not tensors so the equality column I’m titling “Equal” instead of <code>torch.equal</code>.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">dtype</th>
<th style="text-align: center;">Equal</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>sample_pids.pt</code></td>
<td style="text-align: center;">A sample of passage ids used to calculate centroids</td>
<td style="text-align: center;"><code>int</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>num_passages.pt</code></td>
<td style="text-align: center;">Number of sampled passages</td>
<td style="text-align: center;"><code>int</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>doclens.pt</code></td>
<td style="text-align: center;">List of number of tokens per document</td>
<td style="text-align: center;"><code>int</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
</tbody>
</table>
</section>
<section id="float-tensors-1" class="level4">
<h4 class="anchored" data-anchor-id="float-tensors-1">Float Tensors</h4>
<p>Using the more lenient bitsandbytes tolerances, none of the <code>torch.allclose</code> calls pass.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;">Description</th>
<th style="text-align: center;">dtype</th>
<th style="text-align: center;">Default</th>
<th style="text-align: center;">bnb</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>local_sample_embs.pt</code></td>
<td style="text-align: center;">Embeddings of sample document passages used to calculate centroids</td>
<td style="text-align: center;"><code>torch.float16</code></td>
<td style="text-align: center;"><code>False</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>sample.pt</code></td>
<td style="text-align: center;">95% of the values from <code>local_sample_embs.half()</code></td>
<td style="text-align: center;"><code>torch.float16</code></td>
<td style="text-align: center;"><code>False</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>sample_heldout.pt</code></td>
<td style="text-align: center;">5% of the values from <code>local_sample_embs.half()</code></td>
<td style="text-align: center;"><code>torch.float16</code></td>
<td style="text-align: center;"><code>False</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>batches.pt</code></td>
<td style="text-align: center;">1 batch of encoded passages</td>
<td style="text-align: center;"><code>torch.float16</code></td>
<td style="text-align: center;"><code>False</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>D.pt</code></td>
<td style="text-align: center;">sorted and reshaped <code>batches</code></td>
<td style="text-align: center;"><code>torch.float16</code></td>
<td style="text-align: center;"><code>False</code></td>
<td style="text-align: center;"><code>False</code></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="root-cause-of-divergence-bertmodel-forward-pass" class="level2">
<h2 class="anchored" data-anchor-id="root-cause-of-divergence-bertmodel-forward-pass">Root Cause of Divergence: <code>BertModel</code> Forward Pass</h2>
<p><code>local_sample_embs</code> are a critical tensor in the ColBERT indexing process: this is the sample of document token embeddings used to calculate centroids. These centroids are later mapped (<code>ivf.pid.pt</code>) to document token IDs, allowing a smaller footprint (instead of storing full document token embeddings, we only have to store integer centroid IDs and low-bit residual vectors–the difference between centroids and document token embeddings), and more efficient search (we only consider those documents that are close to centroids that are close to the query tokens). <code>local_sample_embs</code> fails <code>torch.allclose</code> between PyTorch versions 2.0.1 and 2.1.0. This divergence then results in different <code>centroids.pt</code> and eventually different final indexes (<code>ivf.pid.pt</code>) between torch versions. To prove this, I injected 2.0.1’s <code>local_sample_embs</code> into 2.1.0 and the resulting intermediate and final artifacts were identical.</p>
<p><code>local_sample_embs</code> are created by passing the sample passages through the <code>CollectionEncoder.encode_passages</code> method which eventually passes them through the <code>Checkpoint.bert</code> model. Given the same inputs (the sample passage) the BERT model produces different outputs between PyTorch versions. I found that regardless of what the input tokens are, the <code>BertModel</code> outputs fail <code>torch.allclose</code>.</p>
<p>Here’s the code I used to capture model layer outputs:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">docs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a"</span>]</span>
<span id="cb1-2">kpoint.doc_tokenizer.tensorize(docs, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config.index_bsize)</span>
<span id="cb1-3">input_ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] </span>
<span id="cb1-4">attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] </span>
<span id="cb1-5"></span>
<span id="cb1-6">outputs_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> capture_output(name):</span>
<span id="cb1-8">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>, output):</span>
<span id="cb1-9">        outputs_dict[name] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach()</span>
<span id="cb1-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.cuda.amp.autocast():</span>
<span id="cb1-13">    hooks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb1-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>): hooks.append(checkpoint.bert.encoder.layer[i].register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span>
<span id="cb1-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad(): D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.bert(input_ids, attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb1-16">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> hooks: h.remove()</span>
<span id="cb1-17">    torch.save(outputs_dict, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/amp_outputs_dict.pt"</span>)</span>
<span id="cb1-18">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"amp_outputs_dict saved!"</span>)</span></code></pre></div>
<p>For <code>docs</code> I tried a single letter (<code>"a"</code>), a test sentence (<code>["test input"]</code>) and different batches from the UKPLab/DAPR/ConditionalQA document collection. In all cases, the model layer outputs between PyTorch versions failed <code>torch.allclose</code>.</p>
<p>As an aside, I also discovered that even after swapping <code>local_sample_embs</code> and obtaining final <code>ivf.pid.pt</code> tensors that passed <code>torch.allclose</code>, the intermediate <code>codes</code> (centroid IDs) were sorted differently between PyTorch versions. I have detailed that observation <a href="https://vishalbakshi.github.io/blog/posts/2025-09-09-colbert-maintenance/">in another blog post</a> in which I also go on to show that even differently sorted <code>codes</code>, as long as they contain the right IDs, can result in the correct final <code>ivf</code> (unique passage IDs per centroid) and <code>ivf_lengths</code> (number of passage IDs per centroid).</p>


</section>

 ]]></description>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-09-13-colbert-maintenance/</guid>
  <pubDate>Sat, 13 Sep 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Batch Size Causes BertModel Forward Pass Divergence Between torch==2.4.1 and torch==2.5.0 for colbert-ai.</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-09-11-colbert-maintenance/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I’ve recently been documenting how PyTorch version changes impact stanford-futuredata/ColBERT (<code>colbert-ai</code> on PyPI) intermediate and final index artifacts. The index artifact I’ll focus on in this blog post is the very important <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/collection_indexer.py#L137"><code>local_sample_embs</code></a> tensor. This is the sample of token embeddings used to calculate the centroids, which are later on used during search. Instead of loading and comparing full document token embeddings, ColBERT’s PLAID index compares centroid IDs (integers) and compressed residuals (low bit vectors) in the first three stages of the search pipeline, only decompressing residuals in the final stage. This reduces storage footprint and search latency.</p>
<p>When comparing <code>local_sample_embs</code> (<code>torch.float16</code>) between <code>torch==2.4.1</code> and <code>torch==2.5.0</code>, using atol=1e-4 and rtol=1e-3 in <code>torch.allclose</code>:</p>
<pre><code>torch.allclose: False
Mean Acc:       0.7978946566581726      
MAD:            1.2740434613078833e-05  
Max Abs Diff:   0.00115966796875 </code></pre>
</section>
<section id="whats-the-diff" class="level2">
<h2 class="anchored" data-anchor-id="whats-the-diff">Whats the Diff?</h2>
<p>What’s causing the <code>local_sample_embs</code> to be different across PyTorch versions? Here’s how I explored it:</p>
<p><code>colbert-ai</code> encodes passages in batches (1600 at a time in my case, for a total of 29 batches across 46107 passages) so I compared model layer outputs for each batch between PyTorch versions using the following script:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">checkpoint <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Checkpoint(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answerdotai/answerai-colbert-small-v1"</span>, colbert_config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config)</span>
<span id="cb2-2">sample_pids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/sample_pids.pt"</span>)</span>
<span id="cb2-3"></span>
<span id="cb2-4">idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb2-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29</span>):</span>
<span id="cb2-6">    docs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> passages[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'text'</span>][<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(sample_pids)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1600</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>idx:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1600</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)]]</span>
<span id="cb2-7">    text_batches, reverse_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.doc_tokenizer.tensorize(docs, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config.index_bsize)</span>
<span id="cb2-8">    input_ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] </span>
<span id="cb2-9">    attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] </span>
<span id="cb2-10"></span>
<span id="cb2-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.cuda.amp.autocast():</span>
<span id="cb2-12">        outputs_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb2-13">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> capture_output(name):</span>
<span id="cb2-14">            <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>, output):</span>
<span id="cb2-15">                outputs_dict[name] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach()</span>
<span id="cb2-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb2-17"></span>
<span id="cb2-18">        hooks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb2-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>): hooks.append(checkpoint.bert.encoder.layer[i].register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span>
<span id="cb2-20">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad(): D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.bert(input_ids, attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb2-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> hooks: h.remove()</span>
<span id="cb2-22"></span>
<span id="cb2-23">        torch.save(outputs_dict, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/lse_outputs_dict_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pt"</span>)</span>
<span id="cb2-24">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"lse_outputs_dict_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> saved!"</span>)</span></code></pre></div>
<p>Batch idx <code>2</code>, <code>3</code>, <code>4</code>, <code>5</code>, <code>12</code>, <code>15</code>, <code>18</code>, <code>19</code>, <code>20</code>, and <code>26</code> fail the <code>torch.allclose</code> comparison between <code>BertModel</code> layer outputs. Why is that the case?</p>
<p>Here are the tensor shapes for each batch of <code>input_ids</code>:</p>
<pre><code>0 torch.Size([32, 71])
1 torch.Size([32, 72])
2 torch.Size([32, 79])   # fails
3 torch.Size([32, 78])   # fails
4 torch.Size([32, 77])   # fails
5 torch.Size([32, 194])  # fails
6 torch.Size([32, 70])
7 torch.Size([32, 73])
8 torch.Size([32, 71])
9 torch.Size([32, 68])
10 torch.Size([32, 66])
11 torch.Size([32, 115])
12 torch.Size([32, 82])  # fails
13 torch.Size([32, 115])
14 torch.Size([32, 115])
15 torch.Size([32, 80])  # fails
16 torch.Size([32, 72])
17 torch.Size([32, 64])
18 torch.Size([32, 90])  # fails
19 torch.Size([32, 82])  # fails
20 torch.Size([32, 86])  # fails
21 torch.Size([32, 63])
22 torch.Size([32, 71])
23 torch.Size([32, 62])
24 torch.Size([32, 61])
25 torch.Size([32, 67])
26 torch.Size([32, 83])  # fails
27 torch.Size([32, 69])
28 torch.Size([32, 72])</code></pre>
<p>The batches that diverge have a second dimension of: <code>79</code>, <code>78</code>, <code>77</code>, <code>194</code>, <code>82</code>, <code>80</code>, <code>90</code>, <code>86</code>, and <code>83</code>.</p>
<p>The batches that do not diverge have a second dimension of: <code>71</code>, <code>72</code>, <code>70</code>, <code>73</code>, <code>68</code>, <code>66</code>, <code>115</code>, <code>64</code>, <code>63</code>, <code>62</code>, <code>61</code>, <code>67</code>, <code>69</code>.</p>
<p>It is interesting to note that these sets do not intersect. To test if batch size is the root cause, I index into the first 70 items of the diverging batches and run the layer output comparison again:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">batch_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span></span>
<span id="cb4-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">18</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">19</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">26</span>]:</span>
<span id="cb4-3">    docs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> passages[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'text'</span>][<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(sample_pids)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1600</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>idx:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1600</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>(idx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)]]</span>
<span id="cb4-4">    text_batches, reverse_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.doc_tokenizer.tensorize(docs, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config.index_bsize)</span>
<span id="cb4-5">    input_ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:, :batch_idx]</span>
<span id="cb4-6">    attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][:, :batch_idx]</span>
<span id="cb4-7"></span>
<span id="cb4-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.cuda.amp.autocast():</span>
<span id="cb4-9">        outputs_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb4-10">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> capture_output(name):</span>
<span id="cb4-11">            <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>, output):</span>
<span id="cb4-12">                outputs_dict[name] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach()</span>
<span id="cb4-13">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb4-14"></span>
<span id="cb4-15">        hooks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb4-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">12</span>): hooks.append(checkpoint.bert.encoder.layer[i].register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span>
<span id="cb4-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad(): D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.bert(input_ids, attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-18">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> hooks: h.remove()</span>
<span id="cb4-19"></span>
<span id="cb4-20">        torch.save(outputs_dict, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/lse_outputs_dict_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pt"</span>)</span>
<span id="cb4-21">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"lse_outputs_dict_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> saved!"</span>)</span></code></pre></div>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29</span>):</span>
<span id="cb5-2">    a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>root_a<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/lse_outputs_dict_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pt"</span>)</span>
<span id="cb5-3">    b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>root_b<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/lse_outputs_dict_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pt"</span>)</span>
<span id="cb5-4"></span>
<span id="cb5-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(a.keys())):</span>
<span id="cb5-6">        a_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb5-7">        b_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb5-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> _close(a_, b_)</span></code></pre></div>
<p>Where <code>_close</code> is defined as:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _close(a, b, default<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb6-2">    gtype <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.dtype</span>
<span id="cb6-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> gtype <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [torch.uint8, torch.int32, torch.int64]:</span>
<span id="cb6-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> a.shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> b.shape: <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.equal(a,b)</span>
<span id="cb6-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb6-6"></span>
<span id="cb6-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> default:</span>
<span id="cb6-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> gtype <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> torch.float32:</span>
<span id="cb6-9">            atol, rtol <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span></span>
<span id="cb6-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> gtype <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> torch.bfloat16:</span>
<span id="cb6-11">            atol, rtol <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-2</span></span>
<span id="cb6-12">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-13">            atol, rtol <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span></span>
<span id="cb6-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-15">        atol, rtol <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-8</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span></span>
<span id="cb6-16">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.allclose(a, b, rtol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>rtol, atol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>atol)</span></code></pre></div>
<p>All model layer outputs match between PyTorch versions! Just to be sure, I tried <code>batch_idx</code> of <code>61</code>, <code>64</code> and <code>68</code>, and all model layer outputs match.</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Earlier today I read the <a href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">Thinking Machines blog post on why LLM inference is non-deterministic</a>. The main cause for non-determinism is that not all tensor ops are <em>batch size invariant</em>:</p>
<blockquote class="blockquote">
<p>As it turns out, our request’s output does depend on the parallel user requests. Not because we’re somehow leaking information across batches — instead, it’s because our forward pass lacks “batch invariance”, causing our request’s output to depend on the batch size of our forward pass.</p>
</blockquote>
<blockquote class="blockquote">
<p>To explain batch invariance, let’s simplify the system and look solely at matmuls. You can assume that all matmul implementations are “run-to-run deterministic.”This is not totally true, but most common matmul implementations do have this property. However, they are not “batch-invariant.” In other words, when the batch size changes, each element in the batch can get different results.</p>
</blockquote>
<p>While I’m not going to (can’t?) dig into PyTorch to understand what is causing batch size variance between <code>2.4.1</code> and <code>2.5.0</code>, I think there is enough evidence to show that something in PyTorch is causing it. If you disagree with that conclusion, <a href="https://x.com/vishal_learner">please @ me on Twitter</a>!</p>


</section>

 ]]></description>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-09-11-colbert-maintenance/</guid>
  <pubDate>Thu, 11 Sep 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>PyTorch .sort Behavior Changes from Version 2.0.1 to 2.1.0</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-09-09-colbert-maintenance/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this notebook I’m going to explore how (and hopefully why) you can start with different <code>codes.indices</code> but end up with the same <code>ivf</code> and <code>ivf_lengths</code> when indexing a document collection using <code>colbert-ai</code>.</p>
<p>I came across this behavior by accident. I was comparing final and intermediate <code>colbert-ai</code> index artifacts between installs using <code>torch==2.0.1</code> and <code>torch==2.1.0</code> and found that even after swapping <code>local_sample_embs.pt</code> (the document token embeddings clustered to find centroids) and <code>embs_{chunk_idx}.pt</code> (the full set of document token embeddings) from 2.0.1 to 2.1.0, the intermediate <code>codes.indices</code> (centroid ID for each document token embedding) did not pass <code>torch.equal</code> <mark>but the final <code>ivf.pid.pt</code> tensors did</mark>. How could that be possible? How can you start with different intermediate centroid-to-document token mappings and end up with the same final centroid-to-document token mappings? Furthermore, how can you end up with different <code>codes.indices</code> when your processing the same <code>embs</code>?</p>
<p>First a bit of review of where <code>codes</code> comes from. The highest-level abstraction we start with is the <code>Indexer</code>:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>nranks)):</span>
<span id="cb1-2">    config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ColBERTConfig(...)</span>
<span id="cb1-3">    indexer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Indexer(checkpoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answerdotai/answerai-colbert-small-v1"</span>, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config)</span>
<span id="cb1-4">    _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> indexer.index(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"..."</span>, collection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>collection)</span></code></pre></div>
<p>Inside <code>Indexer</code>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexer.py#L80"><code>encode</code> is called</a> within which <code>CollectionIndexer</code> is instantiated:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> encode(config, collection, shared_lists, shared_queues, verbose: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>):</span>
<span id="cb2-2">    encoder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CollectionIndexer(config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config, collection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>collection, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>verbose)</span>
<span id="cb2-3">    encoder.run(shared_lists)</span></code></pre></div>
<p>Inside <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/collection_indexer.py#L346"><code>CollectionIndexer.index</code></a> the following line saves (i.e.&nbsp;compresses and stores the residuals of) document token embeddings (the input <code>embs</code> are manually forced to be identical b/w PyTorch version <code>colbert-ai</code> installs):</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.saver.save_chunk(chunk_idx, offset, embs, doclens) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># offset = first passage index in chunk</span></span></code></pre></div>
<p>Once saved, the embeddings are deleted, which is why <code>colbert-ai</code> is so memory efficient! It’s also why indexing and embedding are tied together with the same model.</p>
<p><a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/index_saver.py#L70"><code>IndexSaver.save_chunk</code></a> is defined as:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> save_chunk(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, chunk_idx, offset, embs, doclens):</span>
<span id="cb4-2">    compressed_embs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.codec.compress(embs)</span>
<span id="cb4-3">    </span>
<span id="cb4-4">    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.saver_queue.put((chunk_idx, offset, compressed_embs, doclens))</span></code></pre></div>
<p>The <code>codec</code> is a <code>ResidualCodec</code> object and <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/codecs/residual.py#L167">its <code>compress</code> method</a> contains the following line:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">codes_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.compress_into_codes(batch, out_device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>batch.device)</span></code></pre></div>
<p>We’re almost there! <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/codecs/residual.py#L204"><code>compress_into_codes</code></a> is defined as:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> compress_into_codes(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, embs, out_device):</span>
<span id="cb6-2">    codes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb6-3"></span>
<span id="cb6-4">    bsize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">29</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">//</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.centroids.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb6-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> batch <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> embs.split(bsize):</span>
<span id="cb6-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.use_gpu:</span>
<span id="cb6-7">            indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> batch.T.cuda().half()).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).indices.to(device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>out_device)</span>
<span id="cb6-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-9">            indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> batch.T.cpu().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>()).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).indices.to(device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>out_device)</span>
<span id="cb6-10">        codes.append(indices)</span>
<span id="cb6-11"></span>
<span id="cb6-12">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.cat(codes)</span></code></pre></div>
<p>So, <code>codes</code> are the indices (i.e “IDs”) of the centroids with the maximum cosine similarity with the document token embeddings.</p>
<p>Let’s say our <code>centroids</code> have shape <code>(1024, 96)</code> and the <code>batch</code> contains thirty-two 96-dimensional embeddings (shape <code>(32, 96)</code>), each corresponding to a different document token embedding. The transpose of <code>batch</code> has shape <code>(96, 32)</code> and the matrix multiplication <code>centroids @ batch.T</code> has shape <code>(1024, 32)</code> where the rows represent centroid indices and the columns represent token indices. Taking <code>.max(dim=0).indices</code> returns the row indices corresponding to the maximum value in each of the 32 columns. In other words, the 32 centroid IDs that are closest to the document token embeddings. Note that since <code>centroids</code> <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/collection_indexer.py#L306">are normalized</a> as are <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/modeling/colbert.py#L104">document token embeddings</a>, the matrix multiplication <em>is</em> the cosine similarity between the two sets of vectors.</p>
<p>Which goes back to my question: how can different <code>codes</code> yield the same final <code>ivf</code> and <code>ivf_lengths</code>? And why are <code>codes</code> different to begin with?</p>
<p>To set the stage, let’s look at how <code>ivf</code> and <code>ivf_lengths</code> are created, starting with <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/collection_indexer.py#L438"><code>CollectionIndexer._build_ivf</code></a>, the trimmed down version which is:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _build_ivf(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>):</span>
<span id="cb7-2">    codes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> codes.sort()</span>
<span id="cb7-3">    ivf, values <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> codes.indices, codes.values</span>
<span id="cb7-4">    ivf_lengths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.bincount(values, minlength<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.num_partitions)</span>
<span id="cb7-5"></span>
<span id="cb7-6">    _, _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> optimize_ivf(ivf, ivf_lengths, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config.index_path_)</span></code></pre></div>
<p>The <code>codes</code> are first sorted. The sorted indices (the document token IDs) are assigned as <code>ivf</code> and the values (the centroid IDs) after being <code>bincount</code>-ed (i.e.&nbsp;the frequency of each centroid ID—the number of tokens associated with each centroid ID) are assigned as <code>ivf_lengths</code>. These are the first iteration of <code>ivf</code> and <code>ivf_lengths</code> and will change later on in <code>optimize_ivf</code>, the trimmed down version of which is:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> optimize_ivf(orig_ivf, orig_ivf_lengths, index_path, verbose:<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>):</span>
<span id="cb8-2">    all_doclens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_doclens(index_path, flatten<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb8-3">    all_doclens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flatten(all_doclens)</span>
<span id="cb8-4">    total_num_embeddings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(all_doclens)</span>
<span id="cb8-5"></span>
<span id="cb8-6">    emb2pid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(total_num_embeddings, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>)</span>
<span id="cb8-7"></span>
<span id="cb8-8">    offset_doclens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb8-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> pid, dlength <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(all_doclens):</span>
<span id="cb8-10">        emb2pid[offset_doclens: offset_doclens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> dlength] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pid</span>
<span id="cb8-11">        offset_doclens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> dlength</span>
<span id="cb8-12"></span>
<span id="cb8-13">    ivf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> emb2pid[orig_ivf]</span>
<span id="cb8-14">    unique_pids_per_centroid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb8-15">    ivf_lengths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb8-16"></span>
<span id="cb8-17">    offset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb8-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> length <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm.tqdm(orig_ivf_lengths.tolist()):</span>
<span id="cb8-19">        pids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.unique(ivf[offset:offset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>length])</span>
<span id="cb8-20">        unique_pids_per_centroid.append(pids)</span>
<span id="cb8-21">        ivf_lengths.append(pids.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb8-22">        offset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> length</span>
<span id="cb8-23">    ivf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat(unique_pids_per_centroid)</span>
<span id="cb8-24">    ivf_lengths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(ivf_lengths)</span>
<span id="cb8-25">    </span>
<span id="cb8-26">    original_ivf_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.path.join(index_path, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ivf.pt'</span>)</span>
<span id="cb8-27">    optimized_ivf_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.path.join(index_path, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ivf.pid.pt'</span>)</span>
<span id="cb8-28">    torch.save((ivf, ivf_lengths), optimized_ivf_path)</span>
<span id="cb8-29"></span>
<span id="cb8-30">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> ivf, ivf_lengths</span></code></pre></div>
<p>We’ll actually start from the bottom:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">ivf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat(unique_pids_per_centroid)</span>
<span id="cb9-2">ivf_lengths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(ivf_lengths)</span></code></pre></div>
<p><code>ivf</code> is a flattened tensor of pids (unique passage IDs per centroid). Looking at the loop right above this:</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">offset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb10-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> length <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm.tqdm(orig_ivf_lengths.tolist()):</span>
<span id="cb10-3">    pids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.unique(ivf[offset:offset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>length])</span>
<span id="cb10-4">    unique_pids_per_centroid.append(pids)</span>
<span id="cb10-5">    ivf_lengths.append(pids.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb10-6">    offset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> length</span></code></pre></div>
<p><code>ivf_lengths</code> is the flattened tensor of the <em>number</em> of pids per centroid.</p>
<p>So again: how can we start with different <code>codes</code> (a list of centroid IDs, where the indices are the document token embedding IDs) and end up with the same <code>ivf</code> (unique pids corresponding to centroids) and <code>ivf_lengths</code> (number of pids per centroid)?</p>
<p>I fed this background section to Sonnet 4 (with the stanford-futuredata/ColBERT repo attached as Project Knowledge) to fact check me and it said:</p>
<blockquote class="blockquote">
<p>The key insight is that the final IVF only cares about which passages are associated with each centroid, not which specific token embeddings within those passages. If the different codes still result in the same set of passages being associated with each centroid (even if individual token assignments differ), the final ivf and ivf_lengths would be identical</p>
</blockquote>
<p>TBD if that’s correct, certainly seems plausible!</p>
</section>
<section id="inspecting-codes" class="level2">
<h2 class="anchored" data-anchor-id="inspecting-codes">Inspecting <code>codes</code></h2>
<p>First, I’ll show that <code>codes.indices</code> (document token IDs) are not equal between my <code>torch==2.0.1</code> install and the <code>torch==2.1.0</code> install where I <em>swapped</em> its <code>local_sample_embs.pt</code> and <code>embs_{chunk_idx}.pt</code> with 2.0.1’s tensors. In other words, I “forced” the <code>2.1.0</code> install to cluster the same sample of document token embeddings when calculating centroids and then forced it to use the same document token embeddings to compress as residuals and centroid IDs.</p>
<div id="e6c32453-b312-4bcd-aa85-d856041f6223" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.indexing.loaders <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_doclens</span>
<span id="cb11-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.utils.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> print_message, flatten</span></code></pre></div>
</div>
<div id="b16b8160-9d0d-4797-907b-e20d3816cd4e" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">codes_indices_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20250909-0.2.22.main.torch.2.0.1-1/ivf.pt"</span>)</span>
<span id="cb12-2">codes_indices_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20250909-0.2.22.main.torch.2.1.0-swap-1/ivf.pt"</span>)</span>
<span id="cb12-3">codes_values_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20250909-0.2.22.main.torch.2.0.1-1/values.pt"</span>)</span>
<span id="cb12-4">codes_values_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20250909-0.2.22.main.torch.2.1.0-swap-1/values.pt"</span>)</span>
<span id="cb12-5">torch.equal(codes_indices_a, codes_indices_b), torch.equal(codes_values_a, codes_values_b)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>(False, True)</code></pre>
</div>
</div>
<div id="457ebf9c-d62f-4794-a952-a99fa693a42b" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">codes_values_a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>tensor([    0,     0,     0,  ..., 16383, 16383, 16383])</code></pre>
</div>
</div>
<div id="6ca62459-2e06-481c-a5c4-3e06630fb1fb" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">codes_values_b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>tensor([    0,     0,     0,  ..., 16383, 16383, 16383])</code></pre>
</div>
</div>
<p>Note that <code>codes.values</code> (the centroid IDs) are identical. So <em>which</em> centroid IDs are closest to the document token embeddings stays consistent across versions, but which document token IDs they correspond to does not.</p>
<div id="3bebf034-54ad-470a-8ad9-7b24d3a85866" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">ivf_a, ivf_lengths_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20250909-0.2.22.main.torch.2.0.1-1/indexing/ConditionalQA/ivf.pid.pt"</span>)</span>
<span id="cb18-2">ivf_b, ivf_lengths_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20250909-0.2.22.main.torch.2.1.0-swap-1/indexing/ConditionalQA/ivf.pid.pt"</span>)</span>
<span id="cb18-3">torch.equal(ivf_a, ivf_b), torch.equal(ivf_lengths_a, ivf_lengths_b)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(True, True)</code></pre>
</div>
</div>
<p>Furthermore, the final unique passage IDs for each centroid (<code>ivf</code>) and the number of passage IDs per centroid ID (<code>ivf_lengths</code>) are equal across versions. What this tells me (re: Sonnet’s hypothesis) is that the document token IDs, while dissimilar across versions, come from the same passages!</p>
</section>
<section id="recreating-optimize_ivf" class="level2">
<h2 class="anchored" data-anchor-id="recreating-optimize_ivf">Recreating <code>optimize_ivf</code></h2>
<p>To explore the relationship between document token IDs and passage IDs, I’ll use the code in <code>optimize_ivf</code>, where initially, <code>ivf</code> means <code>codes.indices</code> and <code>ivf_lengths</code> mean <code>torch.bincount(codes.values)</code>.</p>
<div id="5129ecad-90a2-47dc-b90d-8bf7d6ed590e" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">codes_values_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.bincount(codes_values_a, minlength<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16384</span>)</span>
<span id="cb20-2">codes_values_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.bincount(codes_values_b, minlength<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16384</span>)</span></code></pre></div>
</div>
<div id="fc5fe7b6-ceb4-4b47-9310-e1efebdb0ac2" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">codes_values_a, codes_values_b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>(tensor([1110,   36,  173,  ...,  104,   95,   25]),
 tensor([1110,   36,  173,  ...,  104,   95,   25]))</code></pre>
</div>
</div>
<p>I’ll start by loading the mapping between passages and tokens: <code>doclens</code>.</p>
<div id="b5b24e79-31bf-417e-a4ec-c51a073244c0" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">all_doclens_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_doclens(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20250909-0.2.22.main.torch.2.0.1-1/indexing/ConditionalQA/"</span>, flatten<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb23-2">all_doclens_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flatten(all_doclens_a)</span>
<span id="cb23-3">total_num_embeddings_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(all_doclens_a)</span>
<span id="cb23-4"></span>
<span id="cb23-5">all_doclens_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_doclens(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20250909-0.2.22.main.torch.2.1.0-swap-1/indexing/ConditionalQA"</span>, flatten<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb23-6">all_doclens_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flatten(all_doclens_b)</span>
<span id="cb23-7">total_num_embeddings_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(all_doclens_b)</span></code></pre></div>
</div>
<div id="cb42376a-e264-4c03-abfd-822843cd070d" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">all_doclens_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> all_doclens_b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>True</code></pre>
</div>
</div>
<div id="6ca17167-53cb-462c-a5d9-405eb319e16b" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">total_num_embeddings_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> total_num_embeddings_b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>True</code></pre>
</div>
</div>
<div id="8ca9301c-bc51-4c99-a087-45c8c990078a" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">total_num_embeddings_b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>1146937</code></pre>
</div>
</div>
<p>Next we create <code>emb2pid</code> which is a tensor that has 1146937 indices (one for each token across the collection) and values (passage IDs).</p>
<div id="11a4ccd5-c96d-4c3e-a72c-6490aec768cf" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _emb2pid(total_num_embeddings, all_doclens):</span>
<span id="cb30-2">    emb2pid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(total_num_embeddings, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>)</span>
<span id="cb30-3">    offset_doclens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb30-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> pid, dlength <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(all_doclens):</span>
<span id="cb30-5">        emb2pid[offset_doclens: offset_doclens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> dlength] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pid</span>
<span id="cb30-6">        offset_doclens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> dlength</span>
<span id="cb30-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> emb2pid</span></code></pre></div>
</div>
<div id="5757b1c8-3a06-4981-af67-92cfe3dd049f" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">emb2pid_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _emb2pid(total_num_embeddings_a, all_doclens_a)</span>
<span id="cb31-2">emb2pid_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _emb2pid(total_num_embeddings_b, all_doclens_b)</span></code></pre></div>
</div>
<div id="4111b48e-e67f-4246-80ed-a8b57eb80337" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">emb2pid_a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([    0,     0,     0,  ..., 69198, 69198, 69198], dtype=torch.int32)</code></pre>
</div>
</div>
<div id="b4412d37-1159-4438-80b7-ce79ffd7e1c7" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">emb2pid_b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([    0,     0,     0,  ..., 69198, 69198, 69198], dtype=torch.int32)</code></pre>
</div>
</div>
<div id="90e5a257-3567-4259-b530-cdcf266b6e8b" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">torch.equal(emb2pid_a, emb2pid_b)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>True</code></pre>
</div>
</div>
<p>The first three tokens we see correspond to passage ID <code>0</code>, and the last three tokens to passage ID <code>69198</code>.</p>
<p>Let’s now see if the tokens in the two <code>codes_indices</code> come from the same passages.</p>
<div id="e6e78240-66c7-4cbf-a025-b118e70e4ca2" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">codes_indices_a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor([377624, 285309, 285322,  ..., 117986, 118780, 128088])</code></pre>
</div>
</div>
<div id="14eacdad-a983-45f9-9c2a-e2e9445277eb" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">codes_indices_b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([  2776,   2808,   5974,  ..., 309906, 579450, 884128])</code></pre>
</div>
</div>
<div id="be00bed9-6268-424d-a64c-424191dfd8e6" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">pids_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> emb2pid_a[codes_indices_a]</span>
<span id="cb42-2">pids_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> emb2pid_b[codes_indices_b]</span></code></pre></div>
</div>
<div id="0ba56de0-58d2-4d93-961a-f9e589d5f0ea" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">pids_a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([23120, 17145, 17145,  ...,  7128,  7172,  7691], dtype=torch.int32)</code></pre>
</div>
</div>
<div id="27f3a838-3ba3-4cf1-9838-f59d92e21d3c" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">pids_b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([  170,   170,   377,  ..., 18739, 35561, 53527], dtype=torch.int32)</code></pre>
</div>
</div>
<p>Looking at the resulting passage IDs: the first two tokens of <code>pids_a</code> (<code>torch==2.0.1</code>) come from passages <code>23120</code> and <code>17145</code>, respectively. The first two tokens of <code>pids_b</code> (<code>torch==2.0.1</code> <em>swapped</em>) come from passage <code>170</code>.</p>
<p>If we count the number of times each passage ID occurs in each tensor (<code>pids_a</code> or <code>pids_b</code>) they are identical! This is the first hint of Sonnet’s hypothesis.</p>
<div id="af8ab632-932c-4a0f-8a6e-1d967b8b3f17" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">torch.equal(torch.bincount(pids_a), torch.bincount(pids_b))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>True</code></pre>
</div>
</div>
<p>Let’s keep moving along in recreating <code>optimize_ivf</code>:</p>
<div class="sourceCode" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">ivf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> emb2pid[orig_ivf]</span>
<span id="cb49-2">unique_pids_per_centroid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb49-3">ivf_lengths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb49-4"></span>
<span id="cb49-5">offset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb49-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> length <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm.tqdm(orig_ivf_lengths.tolist()):</span>
<span id="cb49-7">    pids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.unique(ivf[offset:offset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>length])</span>
<span id="cb49-8">    unique_pids_per_centroid.append(pids)</span>
<span id="cb49-9">    ivf_lengths.append(pids.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb49-10">    offset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> length</span>
<span id="cb49-11">ivf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat(unique_pids_per_centroid)</span>
<span id="cb49-12">ivf_lengths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(ivf_lengths)</span></code></pre></div>
<p>Instead of:</p>
<div class="sourceCode" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">ivf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> emb2pid[orig_ivf]</span></code></pre></div>
<p>I did:</p>
<div class="sourceCode" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">pids_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> emb2pid_a[codes_indices_a]</span></code></pre></div>
<p>I’ll move onto the for loop:</p>
<div id="79136fe2-c17f-4d3f-9d82-5726af13387f" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _loop(orig_ivf_lengths, ivf):</span>
<span id="cb52-2">    unique_pids_per_centroid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb52-3">    ivf_lengths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb52-4">    offset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb52-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> length <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> orig_ivf_lengths.tolist():</span>
<span id="cb52-6">        pids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.unique(ivf[offset:offset<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>length])</span>
<span id="cb52-7">        unique_pids_per_centroid.append(pids)</span>
<span id="cb52-8">        ivf_lengths.append(pids.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb52-9">        offset <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> length</span>
<span id="cb52-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> unique_pids_per_centroid, ivf_lengths</span></code></pre></div>
</div>
<div id="cd34f1d4-35f5-4d57-8c84-4691a9499fa7" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">unique_pids_per_centroid_a, _ivf_lengths_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _loop(orig_ivf_lengths<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>codes_values_a, ivf<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>codes_indices_a)</span>
<span id="cb53-2">unique_pids_per_centroid_b, _ivf_lengths_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _loop(orig_ivf_lengths<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>codes_values_b, ivf<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>codes_indices_b)</span></code></pre></div>
</div>
<div id="f0205892-4e54-45f3-b292-10a0a1ac89ec" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, item <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(unique_pids_per_centroid_a): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> torch.equal(item, unique_pids_per_centroid_b[idx])</span></code></pre></div>
</div>
<p>And there we see it! While the order of the passage IDs is different, both <code>codes.indices</code> tensors contain the same unique passage IDs per centroid. The key reason for this is that in the for-loop, we use <code>torch.unique</code> which sorts the values in ascending order. So as long as the set of <code>ivf[offset:offset_length]</code> passages IDs are identical across PyTorch versions, even if sorted differently will have the same order after being sorted by <code>torch.unique</code>.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Let’s revisit Sonnet 4’s hypothesis:</p>
<blockquote class="blockquote">
<p>The key insight is that the final IVF only cares about which passages are associated with each centroid, not which specific token embeddings within those passages</p>
</blockquote>
<p>While true, the reality was a bit different—the specific token IDs are identical across torch versions, it’s just that they are sorted differently! However, this begs the question: why are the token IDs sorted differently across torch versions? I’ll explore that in the Appendix section below.</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<p>To understand how the max cosine similarity calculation deviates between <code>torch==2.0.1</code> and <code>torch==2.1.0</code> (using <code>2.0.1</code>’s <code>local_sample_embs.pt</code>) I’ll start by comparing the <code>embs</code> that I <code>torch.save</code>-d right before they were compressed. This is more of a sanity check as these were explicitly swapped from <code>torch==2.0.1</code>.</p>
<div id="58706b53-428f-4263-b423-2ff53868f8c0" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> f <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"embs_0.pt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"embs_1.pt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"embs_2.pt"</span>]:</span>
<span id="cb55-2">    a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.0.1-1/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>f<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb55-3">    b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.1.0-swap-1/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>f<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb55-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> torch.allclose(a, b, atol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>, rtol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>)</span></code></pre></div>
</div>
<p>They are all close enough! Next, I’ll compare the single batch and centroids that I saved in the <code>ResidualCodec.compress_into_codes</code> method.</p>
<div id="e60a6aa0-787a-41c1-9332-e814223512ec" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1">batch_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.0.1-1/compress_batch.pt"</span>)</span>
<span id="cb56-2">batch_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.1.0-swap-1/compress_batch.pt"</span>)</span>
<span id="cb56-3">torch.allclose(batch_a, batch_b, atol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>, rtol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>True</code></pre>
</div>
</div>
<div id="b1f55e3a-a2bb-4599-a24f-a8234495ee6f" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">centroids_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.0.1-1/compress_centroids.pt"</span>)</span>
<span id="cb58-2">centroids_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.1.0-swap-1/compress_centroids.pt"</span>)</span>
<span id="cb58-3">torch.allclose(centroids_a, centroids_b, atol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>, rtol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>True</code></pre>
</div>
</div>
<p>Both the token embeddings and the centroids are close enough (both are float16). Next I’ll compare a batch of <code>codes</code> (<code>indices</code>) saved inside <code>compress_into_codes</code>:</p>
<div id="c34fc6d6-9f4e-4f7d-ac38-ee6245bbc2a5" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1">indices_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.0.1-1/compress_indices.pt"</span>)</span>
<span id="cb60-2">indices_b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.1.0-swap-1/compress_indices.pt"</span>)</span>
<span id="cb60-3">torch.equal(indices_a, indices_b)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>True</code></pre>
</div>
</div>
<p>Interestingly, they are equal across the PyTorch versions. Next I’ll compare the <code>codes</code> for each batch of <code>embs</code> in <code>compress</code>:</p>
<div id="37189c07-f016-48b8-b3c4-87d8559af709" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> f <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compress_codes_0.pt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compress_codes_1.pt"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"compress_codes_2.pt"</span>]:</span>
<span id="cb62-2">    a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.0.1-1/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>f<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb62-3">    b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.1.0-swap-1/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>f<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb62-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> torch.equal(a, b)</span></code></pre></div>
</div>
<p>They are all equal as well!</p>
<p>At this point it was clear to me that the cosine similarity calculation was not the root cause of the <code>codes.indices</code> diverging between PyTorch versions. The next place to look: the sorting of codes! I added a line in <code>CollectionIndexer._build_ivf</code> which saved the pre-sorted <code>codes</code>.</p>
<p>Surprisingly: the <code>codes</code> <em>before being sorted</em> are identical between PyTorch versions.</p>
<div id="f1dff886-85ae-4539-9cd2-754802ab3e5e" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.0.1-1/presort_codes.pt"</span>)</span>
<span id="cb63-2">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.1.0-swap-1/presort_codes.pt"</span>)</span></code></pre></div>
</div>
<div id="834bba2b-15fe-4dde-a4de-eb333ec29320" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor([ 1269,   582, 10939,  ...,  5013,  4582,   431])</code></pre>
</div>
</div>
<div id="d84268d3-d374-4e6e-954a-0a70ee7d1433" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1">b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([ 1269,   582, 10939,  ...,  5013,  4582,   431])</code></pre>
</div>
</div>
<div id="11423d8d-09d1-423f-b6c2-81aac1668ad7" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1">torch.equal(a,b)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>True</code></pre>
</div>
</div>
<p>However, <em>after being sorted</em> the <code>codes.indices</code> diverge:</p>
<div id="1a9b7b4d-adeb-4581-8c4f-6a7c6455e95e" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1">a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.0.1-1/codes.pt"</span>)</span>
<span id="cb70-2">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"20250909-0.2.22.main.torch.2.1.0-swap-1/codes.pt"</span>)</span></code></pre></div>
</div>
<div id="f862aead-56af-44e9-b6ae-57e861337323" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1">a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>torch.return_types.sort(
values=tensor([    0,     0,     0,  ..., 16383, 16383, 16383]),
indices=tensor([377624, 285309, 285322,  ..., 117986, 118780, 128088]))</code></pre>
</div>
</div>
<div id="00005e6b-fa99-4c7e-ba3a-41c9fbddcb29" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1">b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>torch.return_types.sort(
values=tensor([    0,     0,     0,  ..., 16383, 16383, 16383]),
indices=tensor([  2776,   2808,   5974,  ..., 309906, 579450, 884128]))</code></pre>
</div>
</div>
<div id="b59723db-6e47-4223-8938-17a231a1a71d" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1">torch.equal(a.indices, b.indices)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>False</code></pre>
</div>
</div>
<p>There was the source of discrepancy! The order of indices <em>after</em> being sorted!</p>
<p>Is this the case for all <code>sort</code> calls between these PyTorch versions? To test this, I ran the following code with each PyTorch install (<code>torch==2.0.1</code> and <code>torch==2.1.0</code>) and saved <code>t</code> before and after <code>.sort</code> was called:</p>
<div class="sourceCode" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb77-2">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb77-3">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randint(low<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, high<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16383</span>, size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1146937</span>,))</span>
<span id="cb77-4">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> t.sort()</span></code></pre></div>
<p>For both PyTorch versions, <code>t.indices</code> was not equal (i.e.&nbsp;<code>torch.equal</code> was <code>False</code>). This is evidence that <code>sort</code>’s behavior changes from 2.0.1 to 2.1.0. After keyword searching the release notes, I couldn’t find a PR that could be the culprit.</p>
<p>Thankfully, <code>colbert-ai</code> is robust to such changes! Since we only care about the unique passage IDs (and number of passage IDs) for <code>ivf</code> and <code>ivf_lengths</code>, respectively, and <em>not</em> the order of token IDs, this PyTorch change does not break the indexing pipeline.</p>


</section>

 ]]></description>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-09-09-colbert-maintenance/</guid>
  <pubDate>Tue, 09 Sep 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>My Top-5 Blog Posts I’ve Written this Year</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-09-03-top-5-own-blog-posts/</link>
  <description><![CDATA[ 




<p>I recently surpassed my goal of publishing 50 machine learning blog posts in 2025. I shared that on Twitter and got this interesting question from Skylar Payne:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Do you have one that is your favorite or one you are most proud of?
</p>
— Skylar Payne (<span class="citation" data-cites="skylar_b_payne">@skylar_b_payne</span>) <a href="https://twitter.com/skylar_b_payne/status/1963262456811205081?ref_src=twsrc%5Etfw">September 3, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I browsed through the blog posts I’ve published this year, and I found it really hard to pick just one because each blog post either taught me something new (I learn through writing) or gave me an opportunity to try something new (writing style, blog post topic or technical project) that I was scared to do in public. They all served a purpose!</p>
<p>So instead I am picking my top 5 in no particular order.</p>
<ol type="1">
<li><a href="https://vishalbakshi.github.io/blog/posts/2025-03-12-RAGatouille-ColBERT-Indexing-Deep-Dive/">RAGatouille/ColBERT Indexing Deep Dive</a>: This was a critical deep dive in my understanding of the ColBERT Library, and is the main reason why I am able to navigate the codebase today as a maintainer.</li>
<li><a href="https://vishalbakshi.github.io/blog/posts/2025-02-14-RAGatouille-ColBERT-Memory-Profiling/">Memory Profiling raw ColBERT and RAGatouille</a>: This was the first time I had done non-trivial memory profiling, and it also served as a great mechanism to better understand the ColBERT and RAGatouille codebases.</li>
<li><a href="https://vishalbakshi.github.io/blog/posts/2025-06-09-fireside-chat/">Proof, Pricing, and Passion: Finding My Path in Machine Learning</a>: This was the first career-focused blog post I had published, which was a big step for me in sharing thoughts from a point of vulnerability publicly.</li>
<li><a href="https://vishalbakshi.github.io/blog/posts/2025-06-18-imagenette/">An Analysis of Batch Size vs.&nbsp;Learning Rate on Imagenette</a>: This was an important exploration as it built my fundamental intuition around the relationship between batch size, learning rate, and downstream performance (accuracy).</li>
<li><a href="https://vishalbakshi.github.io/blog/posts/2025-06-26-portfolio-llm/">Introducing portfolio-llm: A Professional Portfolio You Can Chat With</a>: I don’t consider myself an innovative applied AI thinker so this project was a breakthrough for me because I feel like it’s the first interesting applied AI idea I’ve had.</li>
</ol>
<p>This was a fun exercise, and definitely something I’ll do again at the end of the year and routinely moving forward. It gave me a moment to reflect and appreciate the progress that I’ve made in my ML journey.</p>



 ]]></description>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-09-03-top-5-own-blog-posts/</guid>
  <pubDate>Wed, 03 Sep 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>PyTorch Version Impact on ColBERT Index Artifacts: 2.7.1 –&gt; 2.8.0</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-09-02-colbert-maintenance/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In a <a href="https://vishalbakshi.github.io/blog/posts/2025-08-18-colbert-maintenance/">previous blog post</a> I showed how I traced index artifact differences between <code>colbert-ai</code> installs using <code>torch==1.13.1</code> (the current pinned version) and <code>torch==2.1.0</code> (the first version which produces different index artifacts) to a difference in floating point differences in the forward pass of the underlying <code>BertModel</code>.</p>
<p>In a <a href="https://vishalbakshi.github.io/blog/posts/2025-08-26-colbert-maintenance/">subsequent blog post</a> I showed how the index artifact differences between <code>colbert-ai</code> installs using <code>torch==2.4.1</code> and <code>torch==2.5.0</code> (the next two versions with differences) was due to floating point divergence in BERT’s intermediate linear layer under mixed precision with small batch sizes.</p>
<p>In this blog post, I’ll show how the index artifacts differencces between <code>torch==2.7.1</code> and <code>torch==2.8.0</code> is due to floating point differences between half precision normalized centroid tensors.</p>
</section>
<section id="index-artifact-comparison" class="level2">
<h2 class="anchored" data-anchor-id="index-artifact-comparison">Index Artifact Comparison</h2>
<p>There are two index artifacts that are different between <code>colbert-ai</code> installs using <code>torch==2.7.1</code> and <code>torch==2.8.0</code>: centroids.pt and the related residuals.pt (the difference between document token embeddings and centroids). This divergence does <mark>NOT</mark> result in a divergence in the critical <code>ivf.pt</code> (document token IDs) and <code>values</code> (centroid IDs) tensors. In other words, the most important mapping from document token IDs to centroid IDs does not change even though centroids floating point values change enough to fail <code>torch.allclose</code>.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>sampled_pids</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>num_passages</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>local_sample_embs</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>centroids</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>bucket_cutoffs</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>bucket_weights</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>avg_residual</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>residuals</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>sample</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>sample_heldout</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>embs</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>doclens</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>codes</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>ivf</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>values</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>tensorize_output</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>batches</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>D</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
</tbody>
</table>
</section>
<section id="inspecting-centroids.pt" class="level2">
<h2 class="anchored" data-anchor-id="inspecting-centroids.pt">Inspecting <code>centroids.pt</code></h2>
<p>I added the following <code>torch.save</code> calls inside <a href="https://github.com/stanford-futuredata/ColBERT/blob/501c29d9e0b7f7b393e36c4177ec2b141a253114/colbert/indexing/collection_indexer.py#L280"><code>CollectionIndexer._train_kmeans</code></a>:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> do_fork_for_faiss:</span>
<span id="cb1-2">    ...</span>
<span id="cb1-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-4">    args_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> args_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> [[[sample]]]</span>
<span id="cb1-5">    centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> compute_faiss_kmeans(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args_)</span>
<span id="cb1-6">    torch.save(centroids, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/prenorm_centroids.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb1-7">    centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.functional.normalize(centroids, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb1-8">    torch.save(centroids, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/postnorm_centroids.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.use_gpu:</span>
<span id="cb1-11">    centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> centroids.half()</span>
<span id="cb1-12">    torch.save(centroids, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>ROOT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/half_centroids.pt"</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># ADDED BY VISHAL</span></span>
<span id="cb1-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb1-14">    centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> centroids.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>()</span></code></pre></div>
<p>I then compared <code>prenorm_centroids.pt</code>, <code>postnorm_centroids.pt</code> and <code>half_centroids.pt</code> between both <code>colbert-ai</code> installs using <code>torch.allclose</code>:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">prenorm_centroids.pt torch.allclose:    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb2-2">prenorm_centroids.pt MAD: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>   <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb2-3"></span>
<span id="cb2-4">postnorm_centroids.pt torch.allclose:   <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb2-5">postnorm_centroids.pt MAD: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.014875902378037e-10</span>        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb2-6"></span>
<span id="cb2-7">half_centroids.pt torch.allclose:       <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb2-8">half_centroids.pt MAD: <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.313225746154785e-10</span>    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span></code></pre></div>
<p>The pre-normalization and post-normalization centroids are identical across torch versions, but the <mark>half precision normalized centroids</mark> diverge.</p>
</section>
<section id="inspecting-.half-behavior" class="level2">
<h2 class="anchored" data-anchor-id="inspecting-.half-behavior">Inspecting <code>.half</code> Behavior</h2>
<p>Are all half precision tensors different across torch versions? No.&nbsp;There are a number of index artifacts that are converted to half precision during indexing and are identical between torch versions: <code>avg_residual.pt</code>, <code>D.pt</code>, <code>bucket_weights.pt</code>, and <code>embs.pt</code>.</p>
<p>Furthermore, I created a random tensor, its half precision version, and its normalized version (full and half precision)…</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>)</span>
<span id="cb3-2">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.empty(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>).uniform_(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>)</span>
<span id="cb3-3">torch.save(t, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"t.pt"</span>)</span>
<span id="cb3-4">torch.save(t.half(), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"half_t.pt"</span>)</span>
<span id="cb3-5"></span>
<span id="cb3-6">t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.functional.normalize(t, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-7">torch.save(t, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"norm.pt"</span>)</span>
<span id="cb3-8">torch.save(t.half(), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"half_norm.pt"</span>)</span></code></pre></div>
<p>…and compared it between torch versions:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>t.pt</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>half_t.pt</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>norm.pt</code></td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>half_norm.pt</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
</tr>
</tbody>
</table>
<p>The half precision random tensors (before normalization) are identical between torch versions but the half precision normalized tensors are not. <mark>It was not apparent from a cursory review of the <a href="https://github.com/pytorch/pytorch/releases/tag/v2.8.0">PyTorch Release 2.8.0 Release Notes</a> what caused this behavior.</mark> Sonnet 4 is confident it’s due to PyTorch PR <a href="https://github.com/pytorch/pytorch/pull/153888">#153888</a> (upgrade cuDNN frontend submodule to 1.12) but that could just be a shot in the dark and I can’t verify it.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>I have now identified what causes index artifacts to diverge between the three pairs of PyTorch versions in question (1.13.1 –&gt; 2.1.0, 2.4.1 –&gt; 2.5.0, and 2.7.1 –&gt; 2.8.0). Next I will inspect search related artifacts and understand where there are differences and why. Once that’s complete, I’ll look into training artifacts. Finally, I’ll test index, search and training for different Python versions (3.9, 3.10, 3.11, 3.12, and 3.13). Unless something else emerges in my analysis, after Python version testing is complete, I’ll be able to push the next release of <code>colbert-ai</code> with the dependency change from <code>"torch==1.13.1"</code> to (most likely) <code>"torch&gt;=1.13.1,&lt;=2.8.0"</code>.</p>


</section>

 ]]></description>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-09-02-colbert-maintenance/</guid>
  <pubDate>Tue, 02 Sep 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>A Summary of and My Thoughts on the DocWrangler Paper</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-09-01-DocWrangler/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I’ll summarize the main points from the <a href="https://arxiv.org/abs/2504.14764">“Steering Semantic Data Processing with DocWrangler” paper by Shreya Shankar et al</a> and share my commentary (<a href="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/">something I’ve been doing more of lately</a>).</p>
<p>This work is inspiring and fascinating. Shreya previewed DocWrangler during the AI Evals course, but reading the paper—especially the user study section—helped me grasp its magnitude. While I lack formal data visualization training, what I’ve read (like <a href="https://vishalbakshi.github.io/blog/posts/2023-05-20-visualization-analysis-and-design/">Visualization Analysis &amp; Design by Tamara Munzner</a>) taught me about the fundamental building blocks of data, UI, analysis goals, and their relationships. For example:</p>
<blockquote class="blockquote">
<p>Search can be classified according to whether the identity and location of targets are known or not</p>
<ul>
<li>both are known with <em>lookup</em></li>
<li>the target is known but its location is not for <em>locate</em></li>
<li>the location is known but the target is not for <em>browse</em></li>
<li>neither the target nor the location are known for <em>explore</em></li>
</ul>
</blockquote>
<p>or:</p>
<blockquote class="blockquote">
<p>The intent of the user is to generate new material.</p>
<p>There are three kinds of produce goals:</p>
<ul>
<li>annotate (adds a new attribute to the data)</li>
<li>record (saves visualization artifacts as persistent artifacts)</li>
<li>derive (produce new data elements based on existing data elements)</li>
</ul>
</blockquote>
<p>Reading the DocWrangler paper felt similar—like discovering building blocks of a fundamentally new paradigm. LLMs enabling large-scale data analysis is already paradigm-shifting, so our analysis methods should match that novelty. Exciting time to work with data!</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Paper Quotes Will be Collapsible
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>I’m trying out collapsible sections for paper quotes so that it shortens the blog post.</p>
</div>
</div>
</div>
</section>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The LLM Paradox
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>…building effective semantic data processing pipelines presents a departure from traditional data pipelines: <mark>users need to understand their data to write effective pipelines, yet they need to construct pipelines to extract the data necessary for that understanding</mark>…</p>
</div>
</div>
</div>
<p>With structured data, you have deterministic algorithms (groupby, aggregate, filter) available through stable APIs like Pandas. With unstructured data and LLMs, no stable API exists. Anthropic doesn’t have a reference page for semantic data processing—just <a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview">guidelines on structuring prompts</a>. These guidelines may or may not work depending on your model, task, and data. Success requires iteration: prompt → inspect results → improve prompt. Each pipeline step affects the next, accumulating ambiguity throughout.</p>
<p>Large collections of unstructured text (emails, documents, reports, transcripts) contain variations of similar data. An email thread about a project might refer to tasks using different words and phrases. Company reports express sentiment differently across documents. Compare this to a 5-point Likert scale from a survey. Before identifying characteristics in unstructured data, you must interpret how different variations of the same characteristic are expressed. This requires processing lots of information—where LLMs excel. But determining which concrete steps, in which order, with which prompts requires going back and forth between understanding your data and constructing/improving your pipeline.</p>
<p>Fellow fast.ai students will recognize this philosophy: you often need a quick and dirty model to view actual vs.&nbsp;predicted results before identifying what needs data cleaning.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
DocWrangler is an IDE
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>…[DocWrangler is] a mixed-initiative integrated development environment (IDE) for semantic data processing…</p>
</div>
</div>
</div>
<p>It’s important to highlight the difference between DocWrangler and DocETL. DocWrangler is the graphical user interface where Shreya and her team have designed intentionally a specific set of interaction components to construct semantic data processing pipelines. It is an opinionated frontend with specific goals. DocETL is the back-end which runs the pipeline as <a href="https://ucbepic.github.io/docetl/tutorial/#creating-the-pipeline:~:text=Create%20a%20file%20named%20pipeline.yaml%20with%20the%20following%20structure%3A">defined by a YAML file</a>. In theory, you can write whatever front-end you want on top of DocETL.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Semantic Data Processing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>semantic data processing: a paradigm where users can instruct LLMs to manipulate data through familiar data processing operators like map, reduce, filter, and groupby.</p>
</div>
</div>
</div>
<p>Even though LLMs don’t have a deterministic, stable API to perform common algorithms, we can still use them for that end. Say we have a collection of 10,000 documents, we can use a semantic <code>map</code> “to extract mentions of medications and reported side effects, followed by a semantic reduce to summarize effects per medication.”</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The Three Gulfs
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><mark>gulf of comprehension</mark>: Documents contain too much information for humans to fully process [and for LLMs to accurately process].</p>
<p><mark>gulf of specification</mark>: users must first discover their true intent—often only possible after exploring sufficient data to understand what questions the data can reasonably answer.</p>
<p><mark>gulf of generalization</mark>: even with clear, unambiguous prompts, LLMs may fail to generalize correctly to the user’s actual data</p>
</div>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="The Three Gulfs Framework"><img src="https://vishalbakshi.github.io/blog/posts/2025-09-01-DocWrangler/1.png" class="img-fluid figure-img" alt="The Three Gulfs Framework"></a></p>
<figcaption>The Three Gulfs Framework</figcaption>
</figure>
</div>
<p>The Three Gulfs Framework drives DocWrangler’s design philosophy. The comprehension gulf motivates using LLMs, but LLMs aren’t a silver bullet. The specification gulf connects to the LLM paradox—deciding whether to apply semantic map or reduce requires knowing your data’s contents. In medical notes, some contain brand names, others generic names, others medication classes. You need to run map operations and examine samples to identify these patterns before crafting your final prompt and pipeline. The generalization gulf highlights LLMs’ fundamental limitation: they struggle with out-of-domain data.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
DocWrangler Features Address the Three Gulfs
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The <mark><strong>in-situ user notes</strong></mark> feature tackles the comprehension gulf by enabling users to annotate observations directly on both documents and outputs. The <mark><strong>LLM-assisted prompt refinement</strong></mark> feature addresses the specification gulf through an interactive interface where an LLM analyzes the pipeline, documents, outputs, and user notes to suggest more effective prompts. The <mark><strong>LLM-assisted operation decomposition</strong></mark> feature targets the generalization gulf by identifying when the pipeline is inadequate for the documents, using an LLM-as-judge that runs in the background.</p>
</div>
</div>
</div>
<p>In-situ user notes attach as text attributes to specific data items, providing context when the LLM helps refine prompts or suggest task decomposition. I think the quality of in-situ user notes drives the entire effort to bridge the three gulfs.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
How Users Intuitively Resolve the LLM Paradox
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Users also employed intentionally vague prompts in map operations to learn more about their data, reminiscent of epistemic actions, i.e., actions taken not to directly achieve a goal but to gather information that reveals new possibilities.</p>
</div>
</div>
</div>
<p>I want to highlight this because 1) this behavior stems from DocWrangler’s design, and 2) it demonstrates good problem-solving skills. I often run intermediate code while trying to understand relationships between high-level abstractions and low-level functionality in a codebase. Intentionally vague prompts expose the LLM’s and data’s “tells”—what does the LLM naturally parse from the data? What data characteristics work best with LLM processing? A common theme: the study users are smart, and DocWrangler facilitates smart decisions.</p>
</section>
<section id="related-work" class="level2">
<h2 class="anchored" data-anchor-id="related-work">Related Work</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The LLM Stability-Capability Tradeoff
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>In semantic data processing, LLMs aren’t just writing scripts in a traditional data processing language, they provide entirely new black-box capabilities for unstructured data transformations.</p>
</div>
</div>
</div>
<p>Returning to my point about stable APIs for structured data: LLMs offer a unique trade-off. No stable API, but functionality well-suited for unstructured data—summarization, theme extraction, sentiment analysis. My imagination around LLM capabilities is limited by my traditional data analysis background. Reading this paper, especially the user study, improved my understanding of how to interact with LLMs and leverage their semantic data processing capabilities.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
How Users Intuitively Resolve the LLM Paradox
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>However, we lack general-purpose interfaces for semantic data processing across diverse document and operator types. Designing such interfaces is not straightforward, as users encounter the “gulf of envisioning”—<mark>the cognitive gap between having a goal and translating it into effective LLM instructions—while also understanding how to evaluate whether the output meets their original intentions</mark>.</p>
</div>
</div>
</div>
<p>I’m tired of the generic chatbot interface—the same blank screen with a narrow text box, buttons for tools/thinking/conciseness, and uniform static messages. Occasionally Claude generates an artifact. As someone without UI design expertise, I’ve wondered why we see this same interface everywhere, even for domain-specific tasks. This excerpt answers that question: it’s hard to design interactive LLM interfaces that alternate between user goals and LLM-generated outputs.</p>
</section>
<section id="docetl-background-and-example" class="level2">
<h2 class="anchored" data-anchor-id="docetl-background-and-example">DocETL Background and Example</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What’s in a DocETL LLM Operation?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Each LLM-powered operator is defined through two components: a natural language prompt that specifies what the operation should do, and an output schema that determines the structure of data the LLM should generate.</p>
</div>
</div>
</div>
<p>Every experience I’ve had with structured data responses has been positive. I discovered this concept through FastHTML’s <code>__ft__</code> method for dataclasses, then later through Anthropic’s XML response format documentation. Having an output schema makes you think about your needs—what data and data types fulfill them, and what format works for post-processing. In DocETL pipelines, the output schema determines the input schema for the next operation.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The <code>resolve</code> Operator
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><code>resolve</code> (performs entity resolution and canonicalization across documents).</p>
</div>
</div>
</div>
<p>Highlighting this operator because I was not familiar with the terms ‘entity resolution’ (figuring out when different text references actually refer to the same real-world thing) and ‘canonicalization’ (converting these different variations into one standard, consistent form). One example could be resolving different medication names, generic or brand name.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Data Presentation Facilitates Different Analyses
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>showing aggregates first helps users identify patterns, while enabling drill-down into specific examples supports verification</p>
</div>
</div>
</div>
<p>Quick aside: I generally dislike dashboards because they facilitate bloated data presentation. I’ve repeatedly seen people equate visualization quantity with quality—like showing you have data is itself a feat. Sometimes it is, especially when organizations try to change their data culture. But after seven years as a data analyst, I think 90% of data presentation only requires (and is most effective with) simple tables or bar plots. Start with high-level aggregate tables or bar plots, then drill down to lower-level categories as you scroll. <em>chef’s kiss</em>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Five DocWrangler Design Goals
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>D1. <strong>Scaffold Pipeline Initialization</strong>: Help users create and configure <mark>operations</mark> with minimal friction, with built-in guidance and quick experimentation.</li>
<li>D2. <strong>Facilitate Efficient Data Inspection and Notetaking</strong>: Enable users to <mark>validate</mark> inputs and outputs individually and in aggregate, while supporting note-taking to capture insights and patterns.</li>
<li>D3. <strong>Guide Pipeline Improvement</strong>: Offer assistance for translating user feedback into effective <mark>pipeline modifications</mark>, both at the individual operation level (e.g., prompt improvements) and pipeline level (e.g., operation decomposition).</li>
<li>D4. <strong>Maintain End-to-End Observability</strong>: Ensure <mark>transparency</mark> into transformation logic at each pipeline step (e.g., inputs, outputs, LLM prompts).</li>
<li>D5. <strong>Minimize Context Switching</strong>: Integrate all essential analytical capabilities within a <mark>unified interface</mark>, minimizing the need for external tools (e.g., spreadsheets, custom scripts, AI assistants like ChatGPT).</li>
</ul>
</div>
</div>
</div>
<p>Combining the highlighted terms into a single phrase: the goal of Doc Wrangler is to operationalize semantic data processing with built-in data validation and annotation, LLM-assisted pipeline modification, and full pipeline transparency in a unified interface.</p>
</section>
<section id="docwrangler-system" class="level2">
<h2 class="anchored" data-anchor-id="docwrangler-system">DocWrangler System</h2>
<p>I’m planning on doing a video demo of DocWrangler so I won’t go into details about the interface from the paper. Instead, I will highlight a couple of aspects of operation decomposition which I think is the most interesting part of the system. Mainly because task decomposition is something that I’ve been thinking a lot about recently. On that note, <a href="https://x.com/sh_reya/status/1957499705321210106">here’s a tweet from Shreya</a> that gives the best explanation and motivation for task decomposition that I’ve come across yet:</p>
<blockquote class="blockquote">
<p>What struck us was that these weren’t prompt-engineering problems. They were structural decomposition problems. Every serious task required breaking down into sub-task, where, crucially, each sub-task is something that an LLM can reliably do. But even expert engineers couldn’t predict the right decomposition without long cycles of trial and error. This is what makes LLM pipelines different from SQL.</p>
<p>In a database, users declare what they want, and the optimizer finds a good plan. We can assume the query itself is correct. For LLMs, we can’t even write a pipeline that works “as is” on state-of-the-art models. So the optimizer must generate and test different pipelines on the user’s behalf. Optimizers need to test many different logical rewrites of the initial pipeline to see what will work best.</p>
</blockquote>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Operation Decomposition Feature
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>While they are inspecting symptom outputs, DocWrangler notifies the user (Fig. 6A) that the operation may be too complex (D3). Clicking on the notification triggers the the Operation Decomposition feature. A dialog appears, showing examples of incorrect LLM results when handling both discomfort assessment and symptom extraction simultaneously (Fig. 6B). The analyst clicks “Automatically Decompose” (Fig. 6C), and the system transparently streams its accuracy optimization process (Fig. 6D), evaluating different candidate plans with LLM-as-judge evaluators [105] (D4).</p>
</div>
</div>
</div>
<p>I like how data validation is built into the operation decomposition feature. The LLM presents evidence for why it thinks the task should be decomposed. The accuracy optimization process involves different candidate paths evaluated by an LLM judge, which is a really interesting way to use LLMs for pipeline optimization.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Managing Context Windows for AI-Assisted Features
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For each document, we remove text from the middle while preserving beginnings and endings, replacing the removed content with an ellipsis. Essentially, as the conversation history grows, documents progressively lose more middle content to accommodate new messages within the context window. We specifically preserve document beginnings and endings because introductions typically contain key metadata and conclusions often summarize content, both important for maintaining document context for the LLM.</p>
</div>
</div>
</div>
<p>This made me think about human document design. From elementary school, we learn to structure papers with introduction, thesis, body paragraphs (one per supporting point), and conclusion. We’ve collectively standardized information structure, even in unstructured formats. This enables clever removal of likely low-importance content to fit context windows.</p>
</section>
<section id="user-study-findings" class="level2">
<h2 class="anchored" data-anchor-id="user-study-findings">User Study Findings</h2>
<p>This is my favorite section of the paper, and I’m excited to share what I found particularly informative and interesting.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
How many users do you need?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>even five participants can uncover valuable usability insights</p>
</div>
</div>
</div>
<p>I didn’t know research showed you only need 5 participants for valuable usability insights. Makes sense though—in my 3-5 person teams, getting their feedback on reports or data products significantly improves the output. This 5-person threshold makes UX research accessible for bootstrapped teams.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prompting goals beyond raw outputs
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>To better understand LLM behavior at a glance, participants often adjusted operation outputs for interpretability…these added attributes (e.g., rationales, summaries, indicators) were not used as final task outputs. Instead, they served to help participants verify whether the LLM had correctly interpreted their intent—bridging the specification gulf.</p>
</div>
</div>
</div>
<p>Returning to the LLM paradox: users cleverly augmented LLM outputs with interpretability clues to better understand how the LLM handles tasks, enabling better decisions about improving prompts or decomposing operations. This interpretability output also informs the LLM during prompt refinement or operation decomposition assistance. This exemplifies the stability-capability tradeoff I mentioned—sure, it takes fuzzy, squishy data processing to understand LLM behavior, but that fuzziness provides information richness you can’t get with structured data.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Binary Classification + Likert Scale Use!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>when analyzing doctor-patient trust, P1 initially used a free-form <code>trust_summary</code> attribute, but added a boolean trust attribute to validate results more easily via a histogram. As shown in Fig. 8, the LLM labeled all examples as “true,” so P1 switched to a 5-point Likert scale for more granularity</p>
</div>
</div>
</div>
<p>I’m always interested in effective Likert scale use (usually find them ineffective) and examples of binary classification (easier for LLMs). This excerpt highlights both. The <code>trust_summary</code> became a boolean <code>trust</code> attribute, which when all labeled “true” led to a 5-point Likert scale revealing proper trust distribution. Another example where structured data from a survey’s true/false trust question couldn’t tease out the nuance you get by transforming unstructured trust summaries into Likert scales with an LLM.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Let the Results Guide You
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Unlike typical data science workflows where users begin with exploratory data analysis [57], all participants skipped manual document review and jumped straight into writing map operations. As they inspected outputs, they frequently revised their pipelines in response to what they saw—what we call opportunistic realignment.</p>
</div>
</div>
</div>
<p>This reminds me of fast.ai’s approach. When confronting a problem, train models first and examine results—baseline heuristic, then traditional ML, then neural nets. Some upfront cleaning and quick viz helps, but much data intuition comes from training models and examining results. As Jeremy Howard shows in his <a href="https://vishalbakshi.github.io/blog/index.html#category=paddy%20doctor">Paddy Doctor Kaggle series</a>, get through your entire pipeline first, then change one thing at a time following intuition rather than running hyperparameter sweeps. You need fast, tight feedback loops—manual document review prohibits this. Makes sense users jump straight to operations. I’ll remember this when using DocWrangler.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Using Operation Decomposition to Write Better Prompts
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>even though the Operation Decomposition feature was designed to help address the generalization gulf, users sometimes adopted it as a way to improve specification too—using suggestions to rethink how they framed their tasks or restructure their prompts.</p>
</div>
</div>
</div>
<p>When tackling LLM-assisted problems, you may not know what tasks are involved or their order. Makes sense that complex task decomposition informs users’ overall approach. Another example of how “The LLM Paradox” creates new problem-solving opportunities.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-21-contents" aria-controls="callout-21" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
LLMs Uncover Serendipitous Opportunities for Analysis
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-21" class="callout-21-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Some users shifted direction after spotting surprising or useful patterns in the LLM’s outputs. These “serendipitous” findings weren’t requested explicitly, but appeared occasionally, revealing new opportunities for analysis.</p>
</div>
</div>
</div>
<p>This resembles exploring structured data through different groupbys and aggregations—unexpected insights surface in visualizations. But there’s a fundamental difference. With structured data, you can list all columns and explore methodically. With unstructured data at scale, you may not know what information is buried in documents. These “new opportunities” involve LLMs discovering previously unknown data attributes.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prompt Rubber Ducking
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>“prompt rubber ducking”: how interacting with LLMs helped them figure out what questions to ask about their data. In this way, semantic data processing pipelines don’t just answer predefined questions, they also help shape users’ understanding of what questions are worth asking—perhaps similar to the “berry picking” model of information seeking, where users iteratively refine their search as they gain new insights</p>
</div>
</div>
</div>
<p>The “berry picking” model definition:</p>
<blockquote class="blockquote">
<p>Bates, 1989 proposed the berry-picking model of information seeking, which has two main points. The first is that, in the process of reading and learning from the information encountered throughout the search process, the searchers’ information needs, and consequently their queries, continually shift (see Figure 3.3). Information encountered at one point in a search may lead in a new, unanticipated direction. The original goal may become partly fulfilled, thus lowering the priority of one goal in favor of another. The second point is that searchers’ information needs are not satisfied by a single, final retrieved set of documents, but rather by a series of selections and bits of information found along the way. This is in contrast to the assumption that the main goal of the search process is to hone down the set of retrieved documents into a perfect match of the original information need. (<a href="https://searchuserinterfaces.com/book/sui_ch3_models_of_information_seeking.html#section_3.3">source</a>)</p>
</blockquote>
<p>This model matches anyone’s Google or Wikipedia journey—you start with one page, encounter new terms, look those up, find related concepts, look those up, step back, move forward. Non-linear information seeking. This matches the earlier user behavior where users skip manual document review and jump straight into map operations to discover patterns. Semantic data processing is like LLMs going on their own Google/Wikipedia journey.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-23-contents" aria-controls="callout-23" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Thinking Fast and Slow
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-23" class="callout-23-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>system responsiveness allowed rapid iteration…output schemas acted as “speed breaks”, slowing exploration just enough for meaningful reflection</p>
</div>
</div>
</div>
<p>This testifies to DocWrangler’s UI design. One reason vibe coding fails is that chatbot interfaces lack user interaction elements that switch between rapid iteration and meaningful reflection. Problem-solving (<a href="https://math.libretexts.org/Courses/Coalinga_College/Math_for_Educators_(MATH_010A_and_010B_CID120)/05%3A_Problem_Solving/5.02%3A_George_Polya's_Strategy">Polya’s method</a>) involves: understanding the problem, breaking it into steps, generating a plan, and working iteratively in small chunks. While users could follow this method themselves, having a UI that conduces this organically is impressive.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-24-contents" aria-controls="callout-24" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
LLM Take the Wheel!
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-24" class="callout-24-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A key factor in whether participants accepted [LLM] suggestions was their confidence in implementing the changes on their own.</p>
</div>
</div>
</div>
<p>LLM users relate to situations where LLMs suggest commands or functions outside their understanding. I’ll often trust the LLM if the code works—especially for bash commands. But if suggested code is fundamental to my script and in Python, I’ll understand each line and likely implement from scratch.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-25-contents" aria-controls="callout-25" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
LLMs Blur Traditional Data Analysis Phases
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-25" class="callout-25-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>LLM pipelines blur the boundary between data cleaning and analysis, unlike traditional workflows where these phases are less intertwined</p>
</div>
</div>
</div>
<p>Users requested LLM error tracing features. In one example, a user wanted to identify where dosage was incorrectly listed as 200 grams instead of 200 milligrams. The LLM faithfully reproduced this error without understanding 200 grams is incorrect. This emphasizes the need for domain experts reviewing LLM inputs/outputs and the importance of citations now common in frontier model interfaces—though citations don’t guarantee correct LLM interpretation.</p>
</section>
<section id="real-world-deployment-and-usage" class="level2">
<h2 class="anchored" data-anchor-id="real-world-deployment-and-usage">Real-World Deployment and Usage</h2>
<p>In addition to their 10 Think-A-Loud interview sessions with participants in the user study, the authors also deployed DocWrangler online and collected telemetry data for about 1500 interactions (pipelines). This section details some of the interesting findings.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-26-contents" aria-controls="callout-26" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prompt Refinement Addresses Skill Issue
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-26" class="callout-26-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>users often struggle with formulating effective prompts from the outset.</p>
</div>
</div>
</div>
<p>There was evidence that users needed the prompt confinement LLM assistance to improve their initial prompts, which were often ineffective. This highlights the importance of prompt engineering as a skill but also provides evidence that the DocWrangler interface was designed correctly.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-27-contents" aria-controls="callout-27" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pipeline Development Trends
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-27" class="callout-27-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>53% of pipelines grew more complex by adding operations or upgrading models; 18% actually became simpler through operation consolidation or reduced sample sizes; and 29% maintained the same operations while only changing prompts or output schemas</p>
</div>
</div>
</div>
<p>I’d like to understand which tasks led to complexity growth versus simplification. Did complexity grow because humans better understood workflows by breaking tasks into sub-tasks, or because they had to adjust to LLM limitations? I’m confused why “upgrading models” counts as complexity growth.</p>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-28-contents" aria-controls="callout-28" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Creativity Support Tool Epistemic Artifacts
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-28" class="callout-28-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We observed users creating what creativity support tool (CST) research calls epistemic artifacts [89]—exploratory objects that help users discover possibilities…any system addressing ambiguous tasks may benefit from CST design principles; e.g., supporting exploration without predefined goals and allowing movement between different levels of abstraction</p>
</div>
</div>
</div>
<p>I love epistemic artifacts—one reason I love notebooks. Notebooks let you quickly probe variables and data structures, visualizing them, wrapping them in functions, adjusting code on-the-fly in a unified interface. It’s why chatbot interfaces resemble notebooks and why AnswerAI’s SolveIt platform works (combining LLM interaction with editable notebooks).</p>
<p>“Addressing ambiguous tasks” is core to problem-solving. Makes sense that DocWrangler’s interface—allowing data “exploration without predefined goals” and movement “between different levels of abstraction”—is such an effective problem-solving tool for study users.</p>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>Few papers light up different parts of my brain—connecting past experiences with unconsidered opportunities, intertwining with my interests while providing chances to build new skills. The ColBERT papers, TinyStories, and Small-scale Proxies are examples. DocWrangler fits this mold. I feel introduced to a fundamental interaction pattern beyond generic chatbot interfaces. I’m excited to try DocWrangler with familiar data and record findings in future blog posts or videos. Thanks for sticking around until the end!</p>


</section>

 ]]></description>
  <category>LLM</category>
  <category>DocWrangler</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-09-01-DocWrangler/</guid>
  <pubDate>Mon, 01 Sep 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>The Term “Non-Deterministic” and LLMs</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-30-non-deterministic/</link>
  <description><![CDATA[ 




<p>I have recently found myself using the term “non-deterministic” to describe LLM behavior. However, something feels off about using that term and I’m nearly convinced that not only is it (sometimes) incorrect, it is imprecise, as it leaves unexplained a critical charactericistic of LLM behavior that makes LLMs different from deterministic functions.</p>
<p>First, defining “deterministic algorithm” (Wikipedia):</p>
<blockquote class="blockquote">
<p>In computer science, a deterministic algorithm is an algorithm that, given a particular input, will always produce the same output, with the underlying machine always passing through the same sequence of states.</p>
</blockquote>
<p>LLMs can be deterministic (i.e.&nbsp;temperature = 0, <code>do_sample=False</code>). For example running the following code passes all 100 assertions:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb1-2"></span>
<span id="cb1-3">model_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFaceTB/SmolLM2-135M"</span></span>
<span id="cb1-4">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(model_id)</span>
<span id="cb1-5">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(model_id)</span>
<span id="cb1-6"></span>
<span id="cb1-7">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The best thing about artificial intelligence is "</span></span>
<span id="cb1-8">inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(prompt, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>)</span>
<span id="cb1-9">attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> inputs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"attention_mask"</span>]</span>
<span id="cb1-10"></span>
<span id="cb1-11">texts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb1-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>):</span>
<span id="cb1-13">    outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate(</span>
<span id="cb1-14">        inputs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>],</span>
<span id="cb1-15">        attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask,</span>
<span id="cb1-16">        pad_token_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer.eos_token_id</span>
<span id="cb1-17">    )</span>
<span id="cb1-18"></span>
<span id="cb1-19">    text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer.decode(outputs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], skip_special_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-20">    texts.append(text)</span>
<span id="cb1-21"></span>
<span id="cb1-22"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> text <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> texts: <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The best thing about artificial intelligence is &nbsp;that it can be used to solve problems that would otherwise be impossible to solve.</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">For"</span></span></code></pre></div>
<p>What I think people mean by saying “LLMs are non-deterministic” is something like the following from the <a href="https://arxiv.org/abs/2504.14764">Steering Semantic Data Processing With DocWrangler</a> paper by Shreya Shankar, et al:</p>
<blockquote class="blockquote">
<p>users need to understand their data to write effective pipelines, yet they need to construct pipelines to extract the data necessary for that understanding</p>
</blockquote>
<p>Thinking on that a bit more, what I think people mean by saying “LLMs are non-deterministic” is: what inputs to give LLMs for a desired output is ambiguous. Prompt engineering being a thing is a great example of this. I don’t know enough mathematics to know if there’s a term for this. “Input ambiguous”? “Non-deterministic on both ends”? The best Sonnet 4 came up with was “non-invertible” (other option was “non-transparent”). GPT-5 Thinking came up with a more sophisticated response “Prompting LLMs is an ill-posed inverse problem.”</p>
<blockquote class="blockquote">
<ul>
<li>Inverse problem: you start from a desired output and try to find an input (prompt) that yields it.</li>
<li>Ill-posed (Hadamard): the inverse fails one or more of
<ul>
<li>existence (your target may be unreachable),</li>
<li>uniqueness (many prompts produce similar outputs → non-injective),</li>
<li>stability (tiny prompt tweaks swing the output a lot).</li>
</ul></li>
</ul>
<p>Separately, decoding can be stochastic (temperature/top-p), which is where “non-deterministic” actually applies. With temperature=0 and deterministic kernels, the model is deterministic—but the inverse remains ill-posed.</p>
</blockquote>
<p>A well-posed problem (Wiki):</p>
<blockquote class="blockquote">
<p>In mathematics, a well-posed problem is one for which the following properties hold:</p>
<ol type="1">
<li>The problem has a solution</li>
<li>The solution is unique</li>
<li>The solution’s behavior changes continuously with the initial conditions.</li>
</ol>
</blockquote>
<p>Problems we try to solve with LLMs often fail all three properties, but again, I don’t know enough about mathematics to know if this truly applies to LLMs.</p>
<p>Most of my interactions with LLMs are through Claude Projects for coding assistance, and I make sure I understand the code (and that it works) before using it, so input ambiguity is acceptable. As I learn to use LLMs to build pipelines the input ambiguity problem sharpens and quickly makes my pipeline brittle. Over the next couple weeks, I plan on learning more about DocWrangler and DSPy to better understand how to temper my pipeline.</p>



 ]]></description>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-30-non-deterministic/</guid>
  <pubDate>Sat, 30 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>PyTorch Version Impact on ColBERT Index Artifacts: 2.4.1 –&gt; 2.5.0</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-26-colbert-maintenance/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In a previous blog post I outlined two things:</p>
<ol type="1">
<li>Which two subsequent PyTorch versions caused a divergence in stanford-futuredata/ColBERT index <code>.pt</code> artifacts (ConditionalQA document collection):</li>
</ol>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Version A</th>
<th style="text-align: center;">Version B</th>
<th style="text-align: center;">All <code>.pt</code> Shapes Match? (Matches)</th>
<th style="text-align: center;">All <code>.pt</code> Values Match? (Matches)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1.13.1</td>
<td style="text-align: center;">2.0.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.0.0</td>
<td style="text-align: center;">2.0.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark>2.0.1</mark></td>
<td style="text-align: center;"><mark>2.1.0</mark></td>
<td style="text-align: center;"><mark>No (9/10)</mark></td>
<td style="text-align: center;"><mark>No (0/10)</mark></td>
</tr>
<tr class="even">
<td style="text-align: center;">2.1.0</td>
<td style="text-align: center;">2.1.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.1.1</td>
<td style="text-align: center;">2.1.2</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.1.2</td>
<td style="text-align: center;">2.2.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.2.0</td>
<td style="text-align: center;">2.2.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.2.1</td>
<td style="text-align: center;">2.2.2</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.2.2</td>
<td style="text-align: center;">2.3.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.3.0</td>
<td style="text-align: center;">2.3.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.3.1</td>
<td style="text-align: center;">2.4.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.4.0</td>
<td style="text-align: center;">2.4.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark>2.4.1</mark></td>
<td style="text-align: center;"><mark>2.5.0</mark></td>
<td style="text-align: center;"><mark>No (9/10)</mark></td>
<td style="text-align: center;"><mark>No (0/10)</mark></td>
</tr>
<tr class="even">
<td style="text-align: center;">2.5.0</td>
<td style="text-align: center;">2.5.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.5.1</td>
<td style="text-align: center;">2.6.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.6.0</td>
<td style="text-align: center;">2.7.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.7.0</td>
<td style="text-align: center;">2.7.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark>2.7.1</mark></td>
<td style="text-align: center;"><mark>2.8.0</mark></td>
<td style="text-align: center;"><mark>Yes (10/10)</mark></td>
<td style="text-align: center;"><mark>No (6/10)</mark></td>
</tr>
</tbody>
</table>
<ol start="2" type="1">
<li>That the difference in ColBERT index artifacts between <code>torch==1.13.1</code> and <code>torch==2.1.0</code> was a result of floating point precision divergence during the forward pass of the underlying <code>BertModel</code>‘s 10 encoder layers, maximum absolute difference between each PyTorch version’s layers’ outputs:</li>
</ol>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.5763e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb1-2"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.7684e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb1-3"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.9605e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb1-4"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.9605e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb1-5"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.1526e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb1-6"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.1526e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb1-7"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.1526e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb1-8"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.5367e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb1-9"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.5367e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb1-10"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.1921e-06</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span></code></pre></div>
<p>In this blog post I’m going to show that the difference in ColBERT indexes between <code>torch==2.4.1</code> and <code>torch==2.5.0</code> is due to <mark>mixed precision forward pass divergence in the <code>BertModel</code> for small batch sizes</mark>.</p>
</section>
<section id="torch2.4.1-vs-torch2.5.0-index-artifact-comparison" class="level2">
<h2 class="anchored" data-anchor-id="torch2.4.1-vs-torch2.5.0-index-artifact-comparison"><code>torch==2.4.1</code> vs <code>torch==2.5.0</code> Index Artifact Comparison</h2>
<p>Similar to the difference between <code>torch==1.13.1</code> and <code>torch==2.1.0</code>, most artifacts don’t match between 2.4.1 and 2.5.0:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>sampled_pids</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>num_passages</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>local_sample_embs</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>centroids</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>bucket_cutoffs</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>bucket_weights</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>avg_residual</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>sample</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>sample_heldout</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>embs</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>doclens</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>codes</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>ivf</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>values</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>tensorize_output</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>batches</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>D</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Also similar to 1.13.1 vs 2.1.0, swapping <code>local_sample_embs</code> resolves all intermediate artifact differences:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>centroids</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>bucket_cutoffs</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>bucket_weights</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>avg_residual</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>sample</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>sample_heldout</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>embs</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>doclens</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>codes</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>ivf</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>values</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</section>
<section id="inspecting-batches" class="level2">
<h2 class="anchored" data-anchor-id="inspecting-batches">Inspecting <code>batches</code></h2>
<p>In 1.13.1 vs 2.1.0, all embeddings in generated when encoding documents were different between versions, this was explained by the divergence in <code>BertModel</code> per-layer outputs. For 2.4.1 vs 2.5.0, only the <em>last batch of embeddings</em> were different between versions. The first 31 batches of embeddings had shape <code>[32, 71, 96]</code> (batch size x max seq len x emb dim), the last batch had shape <code>[8, 71, 96]</code>. This was the first “smell” about where the problem was. These embeddings, <code>batches</code>, are generated with the following code in <code>colbert/modeling/checkpoint.py</code>:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">batches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb2-2">    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.doc(input_ids, attention_mask, keep_dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>keep_dims_, to_cpu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>to_cpu)</span>
<span id="cb2-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> input_ids, attention_mask <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> tqdm(</span>
<span id="cb2-4">        text_batches, disable<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> showprogress</span>
<span id="cb2-5">    )</span>
<span id="cb2-6">]</span></code></pre></div>
<p><code>checkpoint.doc</code> was the method of interest:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> doc(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, to_cpu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kw_args):</span>
<span id="cb3-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb3-3">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.amp_manager.context():</span>
<span id="cb3-4">            D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">super</span>().doc(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kw_args)</span>
<span id="cb3-5"></span>
<span id="cb3-6">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> to_cpu:</span>
<span id="cb3-7">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (D[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].cpu(), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>D[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:]) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(D, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> D.cpu()</span>
<span id="cb3-8"></span>
<span id="cb3-9">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> D</span></code></pre></div>
<p>Here’s the super class’ <code>.doc</code> method, <code>ColBERT.doc</code>:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> doc(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, input_ids, attention_mask, keep_dims<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>):</span>
<span id="cb4-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> keep_dims <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'return_mask'</span>]</span>
<span id="cb4-3"></span>
<span id="cb4-4">    input_ids, attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> input_ids.to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device), attention_mask.to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device)</span>
<span id="cb4-5">    D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bert(input_ids, attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-6">    D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.linear(D)</span>
<span id="cb4-7">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mask(input_ids, skiplist<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.skiplist), device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>()</span>
<span id="cb4-8">    D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> mask</span>
<span id="cb4-9"></span>
<span id="cb4-10">    D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.functional.normalize(D, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb4-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.use_gpu:</span>
<span id="cb4-12">        D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D.half()</span>
<span id="cb4-13"></span>
<span id="cb4-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> keep_dims <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>:</span>
<span id="cb4-15">        D, mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D.cpu(), mask.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>().cpu().squeeze(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb4-16">        D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [d[mask[idx]] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, d <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(D)]</span>
<span id="cb4-17"></span>
<span id="cb4-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> keep_dims <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'return_mask'</span>:</span>
<span id="cb4-19">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> D, mask.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>()</span>
<span id="cb4-20"></span>
<span id="cb4-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> D</span></code></pre></div>
</section>
<section id="mixed-precision-bertmodel-forward-pass-divergence" class="level2">
<h2 class="anchored" data-anchor-id="mixed-precision-bertmodel-forward-pass-divergence">Mixed Precision <code>BertModel</code> Forward Pass Divergence</h2>
<p>I found that the similarity of intermediate artifacts generated in <code>checkpoint.doc</code> between PyTorch versions depended on floating point precision.</p>
<p>Here’s a table showing the different artifacts of different precision types I compared between <code>torch==2.4.1</code> and <code>torch.2.5.0</code>:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Batch Size</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Per-Layer <code>BertModel</code> Outputs</td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>checkpoint.bert(input_ids, attention_mask=attention_mask)[0]</code></td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>checkpoint.linear(D)</code></td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>torch.nn.functional.normalize(D, p=2, dim=2)</code></td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Per-Layer <code>BertModel</code> Outputs</td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>checkpoint.bert(input_ids, attention_mask=attention_mask)[0]</code></td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>checkpoint.linear(D)</code></td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>torch.nn.functional.normalize(D, p=2, dim=2)</code></td>
<td style="text-align: center;">Full</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Per-Layer <code>BertModel</code> Outputs</td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>checkpoint.bert(input_ids, attention_mask=attention_mask)[0]</code></td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>checkpoint.linear(D)</code></td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>torch.nn.functional.normalize(D, p=2, dim=2)</code></td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Per-Layer <code>BertModel</code> Outputs</td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>checkpoint.bert(input_ids, attention_mask=attention_mask)[0]</code></td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>checkpoint.linear(D)</code></td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>False</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>torch.nn.functional.normalize(D, p=2, dim=2)</code></td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>False</code></td>
</tr>
</tbody>
</table>
<p>Mixed precision (<code>with torch.cuda.amp.autocast():</code>) alone was not sufficient to cause divergence. When combining mixed precision with a batch size of 8, the floating point values diverge. Why? The intermediate linear layer (384 –&gt; 1536) appears to be the source of divergence for the batch-size of 8 + mixed precision divergence across PyTorch versions. Note that it didn’t matter which 8-items were selected (from the first or last batch, or in between), this divergence took place between PyTorch versions.</p>
<p>To isolate what in <code>checkpoint.bert</code> was causing this divergence, I replaced different <code>checkpoint.bert</code> modules with <code>Identity</code>, defined as:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Identity(torch.nn.Module):</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, x):</span>
<span id="cb5-3">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> x</span></code></pre></div>
<p>Ultimately I landed on the following code, replacing two of the dense layers with <code>Identity</code>:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> layer <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> checkpoint.bert.encoder.layer:</span>
<span id="cb6-2">    layer.intermediate.dense <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Identity()</span>
<span id="cb6-3">    layer.output.dense <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Identity()</span></code></pre></div>
<p>After running the scripts with this model modification, mixed precision 8-item batches yielded identical results across PyTorch versions!</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Batch Size</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Per-Layer <code>BertModel</code> Outputs</td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>checkpoint.bert(input_ids, attention_mask=attention_mask)[0]</code></td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>checkpoint.linear(D)</code></td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>torch.nn.functional.normalize(D, p=2, dim=2)</code></td>
<td style="text-align: center;">Mixed</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><code>True</code></td>
</tr>
</tbody>
</table>
<p>Here are the two modules in question: (<code>layer.intermediate.dense</code> and <code>layer.output.dense</code>)</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">(intermediate): BertIntermediate(</span>
<span id="cb7-2">    (dense): Linear(in_features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span>, out_features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1536</span>, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-3">    (intermediate_act_fn): GELUActivation()</span>
<span id="cb7-4">)</span>
<span id="cb7-5">(output): BertOutput(</span>
<span id="cb7-6">    (dense): Linear(in_features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1536</span>, out_features<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span>, bias<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-7">    (LayerNorm): LayerNorm((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span>,), eps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-12</span>, elementwise_affine<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb7-8">    (dropout): Dropout(p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1</span>, inplace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb7-9">)</span></code></pre></div>
<p>Running the following small reproduction of the two linear layers:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.bert.encoder.layer[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb8-2">x32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">71</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span>).cuda()</span>
<span id="cb8-3">x8 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x32[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>]</span>
<span id="cb8-4"></span>
<span id="cb8-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.cuda.amp.autocast():</span>
<span id="cb8-6">    out32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> layer.intermediate.dense(x32) </span>
<span id="cb8-7">    out8 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> layer.intermediate.dense(x8)</span>
<span id="cb8-8"></span>
<span id="cb8-9"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Intermediate Linear match: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>torch<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>allclose(out32[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>], out8)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb8-10"></span>
<span id="cb8-11">x32_wide <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">71</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1536</span>).cuda()</span>
<span id="cb8-12">x8_wide <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x32_wide[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>]</span>
<span id="cb8-13"></span>
<span id="cb8-14"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.cuda.amp.autocast():</span>
<span id="cb8-15">    out32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> layer.output.dense(x32_wide)</span>
<span id="cb8-16">    out8 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> layer.output.dense(x8_wide)</span>
<span id="cb8-17"></span>
<span id="cb8-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Output Linear match: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>torch<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>allclose(out32[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>], out8)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<p>Prints out the following:</p>
<pre><code>Intermediate Linear match: False
Output Linear match: True</code></pre>
<p>The intermediate layer (projecting from 384 to 1536 dimensions) causes the divergence in floating point values between the first 8 items of a batch of 32 and all items in the batch of 8 for the same PyTorch version (<code>2.4.1</code>). It’s interesting that the largest matrix multiplication is causing this divergence.</p>
<p>Additionally, this divergence between intermediate dense layer outputs of the first n-items of a batch size of 32 and a smaller batch size of n exists for n = 8, 9 and 10, as checked by the following code:</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.bert.encoder.layer[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb10-2">x32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">71</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">384</span>).cuda()</span>
<span id="cb10-3"></span>
<span id="cb10-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>):</span>
<span id="cb10-5">    xs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x32[:i]</span>
<span id="cb10-6">    </span>
<span id="cb10-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.cuda.amp.autocast():</span>
<span id="cb10-8">        out32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> layer.intermediate.dense(x32) </span>
<span id="cb10-9">        outs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> layer.intermediate.dense(xs)</span>
<span id="cb10-10">    </span>
<span id="cb10-11">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> Intermediate Linear match: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>torch<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>allclose(out32[:i], outs)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<pre><code>...
5 Intermediate Linear match: True
6 Intermediate Linear match: True
7 Intermediate Linear match: True
8 Intermediate Linear match: False
9 Intermediate Linear match: False
10 Intermediate Linear match: False
11 Intermediate Linear match: True
12 Intermediate Linear match: True
...</code></pre>
</section>
<section id="appendix-code" class="level2">
<h2 class="anchored" data-anchor-id="appendix-code">Appendix: Code</h2>
<p>Here’s the core functionality that I used to generate and save full precision <code>BertModel</code> (and related) artifacts:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">text_batches, reverse_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/tensorize_output.pt'</span>)</span>
<span id="cb12-2">input_ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>]</span>
<span id="cb12-3">attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>]</span>
<span id="cb12-4"></span>
<span id="cb12-5">outputs_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb12-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> capture_output(name):</span>
<span id="cb12-7">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>, output):</span>
<span id="cb12-8">        outputs_dict[name] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach()</span>
<span id="cb12-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb12-10"></span>
<span id="cb12-11">hooks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb12-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>): hooks.append(checkpoint.bert.encoder.layer[i].register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span>
<span id="cb12-13"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad(): D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.bert(input_ids, attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb12-14"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> hooks: h.remove()</span>
<span id="cb12-15"></span>
<span id="cb12-16">D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.bert(input_ids, attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb12-17">D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.linear(D)</span>
<span id="cb12-18">mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(checkpoint.mask(input_ids, skiplist<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>checkpoint.skiplist), device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>checkpoint.device).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>()</span>
<span id="cb12-19">D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> mask</span>
<span id="cb12-20">D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.nn.functional.normalize(D, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<p>For mixed precision I indented everything after a <code>with torch.cuda.amp.autocast():</code> line.</p>
<p>My code to compare two versions’ artifacts generally looked like this:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb13-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> rich.console <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Console</span>
<span id="cb13-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> rich.panel <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Panel</span>
<span id="cb13-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> rich.text <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Text</span>
<span id="cb13-5">console <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Console(force_terminal<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb13-6"></span>
<span id="cb13-7">a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>root_a<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/outputs_dict.pt"</span>)</span>
<span id="cb13-8">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>root_b<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/outputs_dict.pt"</span>)</span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb13-11">    a_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb13-12">    b_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb13-13">    console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Layer </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, torch.allclose(a_, b_))</span>
<span id="cb13-14"></span>
<span id="cb13-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _print(string, flag, print_flag<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"[</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> flag <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>string<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\t</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>flag <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> print_flag <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">''</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'/green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> flag <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'/red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]"</span></span>
<span id="cb13-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _compare(fn):</span>
<span id="cb13-17">    a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>root_a<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fn<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb13-18">    b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>root_b<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fn<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb13-19">    console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(_print(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fn<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> torch.allclose:"</span>, torch.allclose(a, b), <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>))</span>
<span id="cb13-20"></span>
<span id="cb13-21">_compare(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"D_bert.pt"</span>)</span>
<span id="cb13-22">_compare(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"D_linear.pt"</span>)</span>
<span id="cb13-23">_compare(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"D_mask.pt"</span>)</span>
<span id="cb13-24">_compare(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"D_norm.pt"</span>)</span></code></pre></div>


</section>

 ]]></description>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-26-colbert-maintenance/</guid>
  <pubDate>Tue, 26 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>PyTorch Version Impact on ColBERT Index Artifacts</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-18-colbert-maintenance/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I recently released <code>colbert-ai==0.2.22</code> which removed the deprecated <code>transformers.AdamW</code> import <a href="https://github.com/stanford-futuredata/ColBERT/releases/tag/v0.2.22">among other changes</a>. I’m now turning my attention to upgrading the PyTorch dependency to 2.x, which will not only introduce compatibility with modern version installations of <code>torch</code> but will also allow the integration of the <a href="https://github.com/AnswerDotAI/fastkmeans">AnswerAI <code>fastkmeans</code> library</a> as a replacement for the <code>faiss-gpu</code> and <code>faiss-cpu</code> libraries (which are no longer officially maintained on PyPI).</p>
<p>I started this PyTorch 2.x upgrade effort by analyzing the impact of <code>torch==2.0.0</code> on <code>colbert-ai</code> as this was the first upgrade from the existing <code>torch==1.13.1</code> dependency. I approached this analysis by reviewing and documenting whether the 500+ PRs involved in <code>torch==2.0.0</code> would impact <code>colbert-ai</code>. The resulting <a href="https://docs.google.com/spreadsheets/d/1sUEN7xo5-hLVoxF9NL_ibGxPaKlPzxmnMU46zf3wd-U/edit?usp=sharing">spreadsheet</a> and <a href="https://vishalbakshi.github.io/blog/posts/2025-07-27-torch-colbert/">blog post</a> detail my findings. In short, I estimated that 28 PRs potentially impacted <code>colbert-ai</code>.</p>
<p>In this blog post I’m detailing a different approach, from the “other end” so to speak: what changes in <code>colbert-ai</code> index artifacts when changing PyTorch versions?</p>
</section>
<section id="indexing-conditionalqa-with-19-pytorch-versions" class="level2">
<h2 class="anchored" data-anchor-id="indexing-conditionalqa-with-19-pytorch-versions">Indexing ConditionalQA with 19 PyTorch Versions</h2>
<p>I started by indexing the <a href="https://huggingface.co/datasets/UKPLab/dapr">UKPLab/DAPR/ConditionalQA</a> document collection with 19 different <code>colbert-ai</code> installs (one for each version of PyTorch from <code>1.13.1</code> to <code>2.8.0</code>), using Modal. Each Dockerfile looks something like this:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode dockerfile code-with-copy"><code class="sourceCode dockerfile"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> mambaorg/micromamba:latest</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">USER</span> root</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">RUN</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">apt-get</span> update <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">apt-get</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span> git nano curl wget build-essential <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">apt-get</span> clean <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-rf</span> /var/lib/apt/lists/<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">RUN</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> clone https://github.com/stanford-futuredata/ColBERT.git /ColBERT <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-8">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> /ColBERT <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-9">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">micromamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-n</span> colbert python=3.11 cuda <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> nvidia/label/11.7.1 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> conda-forge <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-10">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">micromamba</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-n</span> colbert faiss-gpu <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> pytorch <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> conda-forge <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-11">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">micromamba</span> run <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-n</span> colbert pip install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-e</span> . <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-12">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">micromamba</span> run <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-n</span> colbert pip install torch==2.2.0 transformers==4.38.2 pandas</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">ENV</span> CONDA_DEFAULT_ENV=colbert</span>
<span id="cb1-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">ENV</span> PATH=/opt/conda/envs/colbert/bin:$PATH</span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WORKDIR</span> /ColBERT</span>
<span id="cb1-18"></span>
<span id="cb1-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">RUN</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"eval </span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\"\$</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">(micromamba shell hook --shell bash)</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\"</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;</span> ~/.bashrc <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-20">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"micromamba activate colbert"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;</span> ~/.bashrc</span>
<span id="cb1-21"></span>
<span id="cb1-22"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">CMD</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/bin/bash"</span>]</span></code></pre></div>
<p>I decided to <code>git clone</code> and <code>pip install -e .</code> the <code>main</code> branch of <a href="https://github.com/stanford-futuredata/colbert">stanford-futuredata/ColBERT</a> since I wanted to modify the files down the road to save/inject intermediate index artifacts (as we’ll see later on in this blog post).</p>
<p>My indexing function looks like:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@app.function</span>(gpu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>GPU, image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image, timeout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3600</span>,</span>
<span id="cb2-2">              volumes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{MOUNT: VOLUME},</span>
<span id="cb2-3">              max_containers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb2-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _index(source, project, date, nranks, ndocs, root):</span>
<span id="cb2-5">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb2-6">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> subprocess</span>
<span id="cb2-7">    subprocess.run([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pwd'</span>], text<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, shell<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-8">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Indexer</span>
<span id="cb2-9">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.infra <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RunConfig, ColBERTConfig</span>
<span id="cb2-10">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.infra.run <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Run</span>
<span id="cb2-11">    <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dataset</span>
<span id="cb2-12"></span>
<span id="cb2-13">    os.environ[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ROOT"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> root</span>
<span id="cb2-14"></span>
<span id="cb2-15">    dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ConditionalQA"</span></span>
<span id="cb2-16">    passages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-corpus"</span>, split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test"</span>)</span>
<span id="cb2-17">    queries <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-queries"</span>, split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test"</span>)</span>
<span id="cb2-18">    qrels_rows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-qrels"</span>, split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test"</span>)</span>
<span id="cb2-19"></span>
<span id="cb2-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>nranks)):</span>
<span id="cb2-21">        config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ColBERTConfig(</span>
<span id="cb2-22">            doc_maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>,      </span>
<span id="cb2-23">            nbits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,             </span>
<span id="cb2-24">            dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>,             </span>
<span id="cb2-25">            kmeans_niters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>,</span>
<span id="cb2-26">            index_bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>,</span>
<span id="cb2-27">            bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>,</span>
<span id="cb2-28">            checkpoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answerdotai/answerai-colbert-small-v1"</span></span>
<span id="cb2-29">        )</span>
<span id="cb2-30">        </span>
<span id="cb2-31">        indexer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Indexer(checkpoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answerdotai/answerai-colbert-small-v1"</span>, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config)</span>
<span id="cb2-32">        _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> indexer.index(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>MOUNT<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>project<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>date<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>source<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>nranks<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/indexing/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, collection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>passages[:ndocs][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>], overwrite<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-33"></span>
<span id="cb2-34">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Index created!"</span>)</span></code></pre></div>
<p>I would run the indexing function (in my <code>main.py</code> file) using a terminal command like so:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">SOURCE</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.2.22.main.torch.1.13.1"</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">DATE</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"20250818"</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">PROJECT</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"torch2.x"</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">NRANKS</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>1 <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">GPU</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"L4"</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">modal</span> run main.py</span></code></pre></div>
</section>
<section id="comparing-index-artifacts-across-pytorch-versions" class="level2">
<h2 class="anchored" data-anchor-id="comparing-index-artifacts-across-pytorch-versions">Comparing Index Artifacts Across PyTorch Versions</h2>
<p>Once indexed, I ran my comparison script which starts by comparing index file names:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">[bold blue]INDEX FILE NAME COMPARISON[/bold blue]"</span>)</span>
<span id="cb4-2">a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.listdir(a_path)</span>
<span id="cb4-3">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.listdir(b_path)</span>
<span id="cb4-4"></span>
<span id="cb4-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb4-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, f <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(a): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> f <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> b[i]</span>
<span id="cb4-7">    console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"[green]✓ All </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(a)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> files match[/green]"</span>)</span>
<span id="cb4-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span>:</span>
<span id="cb4-9">    console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"[red]✗ File names don't match[/red]"</span>)</span></code></pre></div>
<p>Then index tensor shapes:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, f <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(a_pts):</span>
<span id="cb5-2">    console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[bold]</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>f<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[/bold]"</span>)</span>
<span id="cb5-3">    a_pt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(a_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> f)</span>
<span id="cb5-4">    b_pt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(b_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> f)</span>
<span id="cb5-5">    </span>
<span id="cb5-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(a_pt, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>):</span>
<span id="cb5-7">        match1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> b_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape</span>
<span id="cb5-8">        match2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> b_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].shape</span>
<span id="cb5-9">        console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  Tensor[0]: [</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match1 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>a_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> vs </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>b_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match1 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]"</span>)</span>
<span id="cb5-10">        console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  Tensor[1]: [</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match2 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>a_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> vs </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>b_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match2 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]"</span>)</span>
<span id="cb5-11">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> (match1 <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> match2):</span>
<span id="cb5-12">            shape_mismatches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb5-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb5-14">        match <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a_pt.shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> b_pt.shape</span>
<span id="cb5-15">        console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  Shape: [</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>a_pt<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> vs </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>b_pt<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]"</span>)</span>
<span id="cb5-16">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> match:</span>
<span id="cb5-17">            shape_mismatches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<p>and finally compare tensor values between indexes:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, f <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(a_pts):</span>
<span id="cb6-2">    console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[bold]</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>f<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[/bold]"</span>)</span>
<span id="cb6-3">    a_pt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(a_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> f)</span>
<span id="cb6-4">    b_pt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(b_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> f)</span>
<span id="cb6-5">    </span>
<span id="cb6-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(a_pt, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>):</span>
<span id="cb6-7">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> a_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> b_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape:</span>
<span id="cb6-8">            match1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.allclose(a_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], b_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb6-9">            console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  [</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match1 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'✓'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match1 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'✗'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> Tensor[0] values </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'match'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match1 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'differ'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match1 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]"</span>)</span>
<span id="cb6-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-11">            console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"  [red]✗ Tensor[0] shape mismatch[/red]"</span>)</span>
<span id="cb6-12">            match1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb6-13">            </span>
<span id="cb6-14">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> a_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> b_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].shape:</span>
<span id="cb6-15">            match2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.allclose(a_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], b_pt[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb6-16">            console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  [</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match2 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'✓'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match2 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'✗'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> Tensor[1] values </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'match'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match2 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'differ'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match2 <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]"</span>)</span>
<span id="cb6-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-18">            console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"  [red]✗ Tensor[1] shape mismatch[/red]"</span>)</span>
<span id="cb6-19">            match2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb6-20">            </span>
<span id="cb6-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> (match1 <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> match2):</span>
<span id="cb6-22">            value_mismatches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb6-23">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-24">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> a_pt.shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> b_pt.shape:</span>
<span id="cb6-25">            match <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.allclose(a_pt, b_pt)</span>
<span id="cb6-26">            console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  [</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'✓'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'✗'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> Values </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'match'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'differ'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">[/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'green'</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> match <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">]"</span>)</span>
<span id="cb6-27">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-28">            console.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"  [red]✗ Shape mismatch[/red]"</span>)</span>
<span id="cb6-29">            match <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span></span>
<span id="cb6-30">            </span>
<span id="cb6-31">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> match:</span>
<span id="cb6-32">            value_mismatches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<p>I compared consecutive pairs of PyTorch version <code>colbert-ai</code> installs to understand between which versions the index artifacts change. Here are my results:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Version A</th>
<th style="text-align: center;">Version B</th>
<th style="text-align: center;">All <code>.pt</code> Shapes Match? (Matches)</th>
<th style="text-align: center;">All <code>.pt</code> Values Match? (Matches)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1.13.1</td>
<td style="text-align: center;">2.0.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.0.0</td>
<td style="text-align: center;">2.0.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark>2.0.1</mark></td>
<td style="text-align: center;"><mark>2.1.0</mark></td>
<td style="text-align: center;"><mark>No (9/10)</mark></td>
<td style="text-align: center;"><mark>No (0/10)</mark></td>
</tr>
<tr class="even">
<td style="text-align: center;">2.1.0</td>
<td style="text-align: center;">2.1.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.1.1</td>
<td style="text-align: center;">2.1.2</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.1.2</td>
<td style="text-align: center;">2.2.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.2.0</td>
<td style="text-align: center;">2.2.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.2.1</td>
<td style="text-align: center;">2.2.2</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.2.2</td>
<td style="text-align: center;">2.3.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.3.0</td>
<td style="text-align: center;">2.3.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.3.1</td>
<td style="text-align: center;">2.4.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.4.0</td>
<td style="text-align: center;">2.4.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark>2.4.1</mark></td>
<td style="text-align: center;"><mark>2.5.0</mark></td>
<td style="text-align: center;"><mark>No (9/10)</mark></td>
<td style="text-align: center;"><mark>No (0/10)</mark></td>
</tr>
<tr class="even">
<td style="text-align: center;">2.5.0</td>
<td style="text-align: center;">2.5.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.5.1</td>
<td style="text-align: center;">2.6.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.6.0</td>
<td style="text-align: center;">2.7.0</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.7.0</td>
<td style="text-align: center;">2.7.1</td>
<td style="text-align: center;">Yes (10/10)</td>
<td style="text-align: center;">Yes (10/10)</td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark>2.7.1</mark></td>
<td style="text-align: center;"><mark>2.8.0</mark></td>
<td style="text-align: center;"><mark>Yes (10/10)</mark></td>
<td style="text-align: center;"><mark>No (6/10)</mark></td>
</tr>
</tbody>
</table>
<p>There are three PyTorch upgrades that cause a change in index artifacts: 2.0.1 –&gt; 2.1.0, 2.4.1 –&gt; 2.5.0, and 2.7.1 –&gt; 2.8.0.</p>
</section>
<section id="comparing-intermediate-index-artifacts" class="level2">
<h2 class="anchored" data-anchor-id="comparing-intermediate-index-artifacts">Comparing Intermediate Index Artifacts</h2>
<p>To better understand exactly where the index artifacts changed when upgrading PyTorch, I created my own copies of two stanford-futuredata/ColBERT files and added <code>torch.save</code> lines to save the intermediate artifacts listed below:</p>
<ul>
<li>colbert/indexing/collection_indexer.py
<ul>
<li><code>sampled_pids</code> (a set of integers corresponding to sampled passage IDs)</li>
<li><code>num_passages</code> (a single integers, the number of total passages in the collection)</li>
<li><code>local_sample_embs</code> (BERT encodings of the sample pids, created by <code>Checkpoint.docFromText</code>)</li>
<li><code>centroids</code> (from <code>_train_kmeans</code>)</li>
<li><code>bucket_cutoffs</code> (the bin “boundaries” used for quantization from <code>_compute_avg_residual</code>)</li>
<li><code>bucket_weights</code> (the quantized values, from <code>_compute_avg_residual</code>)</li>
<li><code>avg_residual</code> (a single float, from <code>_compute_avg_residual</code>)</li>
<li><code>sample</code> (95% of the values from <code>local_sample_embs.half()</code>)</li>
<li><code>sample_heldout</code> (5% of the values from <code>local_sample_embs.half()</code>)</li>
<li><code>embs</code> (encoded passages)</li>
<li><code>doclens</code> (number of tokens in each passage)</li>
<li><code>codes</code> (centroid IDs (values) and document token IDs (indices))</li>
<li><code>ivf</code> (document token IDs)</li>
<li><code>values</code> (centroid IDs)</li>
</ul></li>
<li>colbert/modeling/checkpoint.py
<ul>
<li><code>tensorize_output</code> (tuple (<code>text_batches</code>, <code>reverse_indices</code>) output from <code>DocTokenizer.tensorize</code>)</li>
<li><code>batches</code> (BERT encodings, output from <code>Checkpoint.doc</code>)</li>
<li><code>D</code> (sorted and reshaped <code>batches</code>)</li>
</ul></li>
</ul>
<p>I then replaced the corresponding files in the <code>/ColBERT</code> directory (which is why I used <code>git clone</code> and <code>pip install e .</code>) with the following lines for Modal:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.add_local_file(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"collection_indexer.py"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/ColBERT/colbert/indexing/collection_indexer.py"</span>)</span>
<span id="cb7-2">image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.add_local_file(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"checkpoint.py"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/ColBERT/colbert/modeling/checkpoint.py"</span>)</span></code></pre></div>
<p>Here are the results when comparing these artifacts between <code>colbert-ai</code> installs using <code>torch==1.13.1</code> and <code>torch==2.1.0</code>:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>sampled_pids</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>num_passages</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>local_sample_embs</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>centroids</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>bucket_cutoffs</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>bucket_weights</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>avg_residual</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>sample</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>sample_heldout</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>embs</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>doclens</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>codes</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>ivf</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>values</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>tensorize_output</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>batches</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>D</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>After reviewing these comparisons, my hypothesis was that the first difference (in <code>local_sample_embs</code>) affected all subsequent artifacts. The difference in <code>local_sample_embs</code> can be traced down to the difference in <code>batches</code> and <code>D</code>. To test this hypothesis, I “injected” the <code>local_sample_embs</code> from the <code>torch==1.13.1</code> install into the <code>collection_indexer.py</code> when indexing with <code>torch==2.1.0</code>:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">local_sample_embs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/colbert-maintenance/torch2.x/20250818-0.2.22.main.torch.1.13.1-1k-1/local_sample_embs.pt"</span>)</span></code></pre></div>
<p>I then re-compared the artifacts, and my hypothesis was correct!</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Artifact</th>
<th style="text-align: center;"><code>torch.allclose</code></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>centroids</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>bucket_cutoffs</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>bucket_weights</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>avg_residual</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>sample</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>sample_heldout</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>embs</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>doclens</code></td>
<td style="text-align: center;"><code>True</code></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>codes</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;"><mark><code>ivf</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><mark><code>values</code></mark></td>
<td style="text-align: center;"><mark><code>False</code></mark></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</section>
<section id="comparing-the-bertmodels" class="level2">
<h2 class="anchored" data-anchor-id="comparing-the-bertmodels">Comparing the <code>BertModel</code>s</h2>
<p>Where do <code>local_sample_embs</code> come from? The highest-level method is <code>CollectionEncoder.encode_passages</code>. Inside <code>CollectionEncoder.encode_passages</code> the collection of texts, <code>passages</code> is fed to <code>Checkpoint.docFromText</code>. Inside there, the tokenized text is passed to <code>Checkpoint.doc</code>, which passes them to <code>ColBERT.doc</code>, which finally passes the <code>input_ids</code> and <code>attention_mask</code> to <code>ColBERT.bert</code>. Since there was a divergence in <code>local_sample_embs</code>, I figured there would be a divergence in either the weights and/or the logits of <code>ColBERT.bert</code> between both PyTorch version installs.</p>
<p>I installed each image of <code>colbert-ai</code> and separately saved the <code>BertModel</code> weights as well as a dictionary with outputs from each of the 10 <code>BertEncoder</code> layers. These outputs were accessed using a forward hook:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">outputs_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> capture_output(name):</span>
<span id="cb9-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>, output):</span>
<span id="cb9-5">        outputs_dict[name] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach()</span>
<span id="cb9-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb9-7"></span>
<span id="cb9-8">hooks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb9-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb9-10">    hooks.append(checkpoint.bert.encoder.layer[i].register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"1.13.1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span>
<span id="cb9-11"></span>
<span id="cb9-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb9-13">    D <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.bert(input_ids, attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb9-14"></span>
<span id="cb9-15"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> hooks: h.remove()</span></code></pre></div>
<p>Both <code>colbert-ai</code> installs (<code>torch==1.13.1</code> and <code>torch==2.1.0</code>) had equal <code>BertModel</code> weights. However, both of them have diverging <code>BertEncoder</code> outputs.</p>
<p>Here are the mean absolute differences between corresponding <code>BertEncoder</code> layer outputs between <code>torch==1.13.1</code> and <code>torch==2.1.0</code>:</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb10-2">    a_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"1.13.1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb10-3">    b_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> b[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"2.1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb10-4">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(i, torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(a_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> b_).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>().mean())</span></code></pre></div>
<pre><code>0 tensor(2.8141e-08, device='cuda:0')
1 tensor(5.9652e-08, device='cuda:0')
2 tensor(8.0172e-08, device='cuda:0')
3 tensor(7.8228e-08, device='cuda:0')
4 tensor(7.9968e-08, device='cuda:0')
5 tensor(8.3589e-08, device='cuda:0')
6 tensor(8.7348e-08, device='cuda:0')
7 tensor(8.5140e-08, device='cuda:0')
8 tensor(8.5651e-08, device='cuda:0')
9 tensor(8.1636e-08, device='cuda:0')</code></pre>
<p>The difference increases about 2x as we go deeper through the model.</p>
<p>Here are the max absolute differences, which increases 2x by the final layer:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">3.5763e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb12-2"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.7684e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb12-3"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.9605e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb12-4"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.9605e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb12-5"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.1526e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb12-6"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.1526e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb12-7"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">7.1526e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb12-8"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.5367e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb12-9"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.5367e-07</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span>
<span id="cb12-10"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9</span> tensor(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.1921e-06</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cuda:0'</span>)</span></code></pre></div>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>From this analysis, I can conclude that the difference in index artifacts generated by <code>colbert-ai</code> using different <code>torch==1.13.1</code> vs.&nbsp;<code>torch==2.1.0</code> is due to floating point differences in the forward pass of the <code>BertModel</code> used to generate token-level embeddings from text passages. I have not yet analyzed the <code>torch==2.1.0</code> release notes to make an educated guess on why these differences occur. But given that it’s during the forward pass of the model, I would wager there was some update to the underlying C++ code for the <code>torch.nn</code> module.</p>
<p>I will move forward with comparing intermediate artifacts between each subsequent versions where the final index artifacts are different 2.4.1 –&gt; 2.5.0, and 2.7.1 –&gt; 2.8.0. Once that’s complete, I’ll dive into the PyTorch release notes and see if I can reasonably point to a few PRs behind this change. Once I have a reasonable handle on understanding <code>colbert-ai</code> indexing behavior with different versions of PyTorch 2.x, I’ll perform a similar analysis with <code>colbert-ai</code> training and document my findings.</p>
<p>Thanks for reading until the end! I’ll be posting more blog post and/or video updates around ColBERT maintenance as soon as I have something more to share.</p>


</section>

 ]]></description>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-18-colbert-maintenance/</guid>
  <pubDate>Tue, 19 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TIL: Launching Jupyter with a Custom Modal Image and Volume</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-17-modal-jupyter/</link>
  <description><![CDATA[ 




<p>Yesterday I learned of the Modal docs example showing how to start <a href="https://github.com/modal-labs/modal-examples/blob/main/11_notebooks/jupyter_inside_modal.py">a jupyter server via a Modal tunnel</a>. I was elated to see this because it solved my problem of not being able to specify a custom image when using <code>modal launch jupyter</code>.</p>
<p>I have a Dockerfile which installs <code>colbert-ai</code> from the <code>main</code> branch of the stanford-futuredata/ColBERT repo with a specific PyTorch and Transformers version:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode dockerfile code-with-copy"><code class="sourceCode dockerfile"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">FROM</span> mambaorg/micromamba:latest</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">USER</span> root</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">RUN</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">apt-get</span> update <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">apt-get</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span> git nano curl wget build-essential <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">apt-get</span> clean <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rm</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-rf</span> /var/lib/apt/lists/<span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">RUN</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">git</span> clone https://github.com/stanford-futuredata/ColBERT.git /ColBERT <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-8">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">cd</span> /ColBERT <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-9">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">micromamba</span> create <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-n</span> colbert python=3.11 cuda <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> nvidia/label/11.7.1 <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> conda-forge <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-10">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">micromamba</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-n</span> colbert faiss-gpu <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> pytorch <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-c</span> conda-forge <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-11">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">micromamba</span> run <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-n</span> colbert pip install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-e</span> . <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-12">    <span class="ex" style="color: null;
background-color: null;
font-style: inherit;">micromamba</span> run <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-n</span> colbert pip install torch==1.13.1 transformers==4.38.2 pandas</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">ENV</span> CONDA_DEFAULT_ENV=colbert</span>
<span id="cb1-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">ENV</span> PATH=/opt/conda/envs/colbert/bin:$PATH</span>
<span id="cb1-16"></span>
<span id="cb1-17"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">WORKDIR</span> /</span>
<span id="cb1-18"></span>
<span id="cb1-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">RUN</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"eval </span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\"\$</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">(micromamba shell hook --shell bash)</span><span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\"</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;</span> ~/.bashrc <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">&amp;&amp;</span> <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb1-20">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">echo</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"micromamba activate colbert"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;&gt;</span> ~/.bashrc</span>
<span id="cb1-21"></span>
<span id="cb1-22"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">CMD</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/bin/bash"</span>]</span></code></pre></div>
<p>I then modified the Modal documentation example as follows (<code>jupyter_inside_modal.py</code>) to use my Dockerfile to create an image and use an existing Modal Volume:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> subprocess</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> modal</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> modal <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image, App, Secret, Volume</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> datetime</span>
<span id="cb2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb2-7"></span>
<span id="cb2-8">SOURCE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.environ.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"SOURCE"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>)</span>
<span id="cb2-9">VOLUME <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Volume.from_name(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"colbert-maintenance"</span>, create_if_missing<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-10">MOUNT <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/colbert-maintenance"</span></span>
<span id="cb2-11">image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Image.from_dockerfile(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Dockerfile.</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>SOURCE<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, gpu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"L4"</span>)</span>
<span id="cb2-12"></span>
<span id="cb2-13">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> App(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"jupyter-tunnel"</span>, image<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>image.pip_install(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"jupyter"</span>))</span>
<span id="cb2-14">JUPYTER_TOKEN <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># some list of characters you'll enter when accessing the Modal tunnel</span></span>
<span id="cb2-15"></span>
<span id="cb2-16"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@app.function</span>(max_containers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, volumes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{MOUNT: VOLUME}, timeout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10_000</span>, gpu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"L4"</span>)</span>
<span id="cb2-17"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> run_jupyter(timeout: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>):</span>
<span id="cb2-18">    jupyter_port <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8888</span></span>
<span id="cb2-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> modal.forward(jupyter_port) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> tunnel:</span>
<span id="cb2-20">        jupyter_process <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> subprocess.Popen(</span>
<span id="cb2-21">            [</span>
<span id="cb2-22">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"jupyter"</span>,</span>
<span id="cb2-23">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"notebook"</span>,</span>
<span id="cb2-24">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--no-browser"</span>,</span>
<span id="cb2-25">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--allow-root"</span>,</span>
<span id="cb2-26">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--ip=0.0.0.0"</span>,</span>
<span id="cb2-27">                <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"--port=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>jupyter_port<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb2-28">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--NotebookApp.allow_origin='*'"</span>,</span>
<span id="cb2-29">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"--NotebookApp.allow_remote_access=1"</span>,</span>
<span id="cb2-30">            ],</span>
<span id="cb2-31">            env<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>os.environ, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"JUPYTER_TOKEN"</span>: JUPYTER_TOKEN},</span>
<span id="cb2-32">        )</span>
<span id="cb2-33"></span>
<span id="cb2-34">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Jupyter available at =&gt; </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tunnel<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>url<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb2-35"></span>
<span id="cb2-36">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb2-37">            end_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> timeout</span>
<span id="cb2-38">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> time.time() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> end_time:</span>
<span id="cb2-39">                time.sleep(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb2-40">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Reached end of </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>timeout<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> second timeout period. Exiting..."</span>)</span>
<span id="cb2-41">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">KeyboardInterrupt</span>:</span>
<span id="cb2-42">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Exiting..."</span>)</span>
<span id="cb2-43">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">finally</span>:</span>
<span id="cb2-44">            jupyter_process.kill()</span>
<span id="cb2-45"></span>
<span id="cb2-46"></span>
<span id="cb2-47"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@app.local_entrypoint</span>()</span>
<span id="cb2-48"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> main(timeout: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10_000</span>):</span>
<span id="cb2-49">    run_jupyter.remote(timeout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>timeout)</span></code></pre></div>
<p>I then run the following locally form my terminal:</p>
<pre><code>SOURCE="0.2.22.main.torch.1.13.1" modal run jupyter_inside_modal.py</code></pre>
<p>Where my Dockerfile is in the same folder as <code>jupyter_inside_modal.py</code> and titled <code>Dockerfile.0.2.22.main.torch.1.13.1</code>. I can then access the cloned repo as well as my mounted volume and use a Jupyter Notebook to explore data, iterate on function definitions, compare model weights, add hooks to ColBERT models, and so on. This unlocks a ton of productivity and iteration velocity that I was scratching my head on how to obtain without the use of notebooks.</p>



 ]]></description>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-17-modal-jupyter/</guid>
  <pubDate>Sun, 17 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Reflections After Completing the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-17-ai-evals/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>This blog post is part journal, part reflection, and part planning around the topics of AI engineering, AI evals, applied AI, and my career path into machine learning. When I decided to take <a href="https://t.co/Zrmp6LRd9c">Hamel and Shreya’s AI evals course</a>, I had recently watched a very short talk on LLM reliability by Featherless AI CEO Eugene Cheah. I had also learned about the <a href="https://www.realevals.xyz/">realevals.xyz benchmark</a>, which shows just how bad LLMs are at reliably completing “boring” tasks that are necessary in commerce. I had also watched and <a href="https://youtu.be/9s88C8XBBiQ">deeply reflected</a> on a discussion between Jason Liu, Andy Walters, and Vignesh Mohankumar about the different routes into AI industry work. I had also reflected on my own fear of applied AI: the risk of automating tasks for which failures would have real, concrete consequences. The amalgamation of these experiences led me to adopt the “narrow fence/long leash” framework as discussed in the AnswerAI launch blog post, an idea that came from the old GE research and development lab. In this framework, the manager would provide the researchers a “long leash” to explore whatever problems they wanted to, at whatever depth they needed to, as long as they tied back to an applied AI project; as long as they stayed within the bounds of this “narrow fence” of an applied AI project.</p>
<p>A couple of weeks before the AI evals course started, I was chosen to be a maintainer of the stanford_futuredata/ColBERT (<code>colbert-ai</code> on PyPI) library. I had “suddenly” gone from “hobby ML researcher” to maintainer of a foundational library in the information retrieval ML space. I say “suddenly” because while everything I had done up to that point led to me landing that role, I hadn’t done everything with the goal of landing it. I had done what I did because it was fun, it was exciting, it was challenging, and I was learning a lot. Suddenly my priorities shifted. I put ColBERT maintenance (gratefully) at #1, and everything else I was working on (both long Leashes and narrow fences) became a distant #2. I had a number of goals of what I wanted to prepare before the AI evals course started, but I was not able to bring that energy and bring that preparation as I planned. Like anything, you get out what you put in. While I wasn’t able to put in my maximum in the AI Evals course, I was able to adapt to my circumstances and put in and get out something extremely valuable. I hope to distill those experiences in this blog post.</p>
</section>
<section id="applied-ai-is-different" class="level2">
<h2 class="anchored" data-anchor-id="applied-ai-is-different">Applied AI is Different</h2>
<p>Taking the AI Evals course was a humbling experience. I thought that because of how much time I had spent learning about deep learning through the fast.ai course, reading research papers, and diving into research codebases would give me some kind of running start for the course. I was completely wrong. Of course, there are transferable skills between any data-related fields, but successful applied AI folks are just built different: I can think of no better example than <a href="https://www.youtube.com/watch?v=N-qAOv_PNPc">the talk by Teresa Torres</a>.</p>
<p>Now, Teresa has a very impressive background. She studied <a href="https://symsys.stanford.edu/">symbolic systems at Stanford</a>, which was a cross-functional, interdisciplinary approach to what seems like human-software interaction and related systems. She also had experience as a technical product manager. However, her background does not make it any less impressive what she was able to accomplish in the given time frame: in a couple of weeks she created an Applied AI product that was set to be integrated with existing software in beta with robust evals. She applied data science skills because it just made sense to, because she needed to, because she had to, because she was terrified of creating a product that was not validated and tested. She was terrified of using AI-generated code that she didn’t understand, so she had to learn Python. She wanted to cleanly and quickly inspect data, so she learned data visualization. She wanted to be cost-effective when using AI, so she recreated the MapReduce methodology for LLMs from first principles. And she did all this in a few weeks. While her velocity and problem-solving abilities are likely unique to her, I don’t think her overall behavior is unique to folks in Applied AI. After my sense of awe and feeling inspired settled down, I couldn’t help but think that people like her just operate differently than I do. I’m a believer that almost anything can be learned, but there’s just something about applied AI that seems mutually exclusive from AI research, data science or data analysis. I can’t quite put my finger on it because I do believe I’m on the outside of that world looking in. But I felt it when I watched Teresa’s talk.</p>
<p>I also felt it when I was listening to other students ask questions and talk about their projects during office hours. I won’t go into specifics because office hours are meant to be private, but student after student had specific, applied, real-production-level questions and problems that they were trying to solve. I think what I was inspired by the most was that they didn’t wait to take the course to solve these problems. They were already figuring things out with whatever tools and skills they currently had, and were taking this course because they (correctly) bet it was going to provide them a system they needed to get the results they desired. You can also see this “production-ready” nature of the cohorts based on <a href="https://x.com/sh_reya/status/1957139727322411291">the hundreds of testimonials of the course</a>.</p>
<p>I also felt the unique nature of applied AI by a consistent theme taught in the course: the quality of error analysis and the quality of your AI evals depend on your product sense and knowledge. “Looking at data” is just as much of a data science skill as it is a product skill. Data science teaches you how, but product sense teaches you why (and where to look). I think it’s why someone like Teresa, who seems to have fantastic product sense, is able to pick up necessary data science skills to execute on her ability “follow the smell” of failure modes.</p>
<p>I think there certainly are unicorns where ML researchers or data scientists also have good product sense. The <a href="https://www.youtube.com/watch?v=DgPr3HVp0eg">folks at AnswerAI</a> certainly seem to fit this description as was evident in the SolveIt walkthrough during the course. Another example is Omar Khattab, who gave a guest talk on DSPy during the course, who seems to see problems and solutions (and systems) differently (and earlier) than the industry at-large. As a fast.ai student/community member and late interaction enjoyer, I am of course biased.</p>
</section>
<section id="the-value-of-mundane-tasks" class="level2">
<h2 class="anchored" data-anchor-id="the-value-of-mundane-tasks">The Value of Mundane Tasks</h2>
<p>A topic that I’ve been meaning to write about but haven’t yet found the time or right opportunity to do so is the skill of looking at data. I think many different paths in data science and ML (and elsewhere) provide opportunities to build this skill. Personally I built this skill by working in low-tech or even no-tech data environments. I think when you’re a lowly analyst cleaning data entry errors or doing manual data entry yourself, you learn viscerally about the pain points in data collection and how those pain points can find their way to inaccuracies in downstream analyses. When you’re going through binders of handwritten notes and printed PDF tables, cross-referencing aggregate numbers with poorly formatted Excel workbooks containing missing data, you build the resilience and patience necessary to thoroughly “look at data” going in and out of LLMs. I think something that has kept me from becoming a better programmer is I’m not lazy and I enjoy a moderate dose (and see the value) of mundane tasks (such as reading hundreds or thousands of LLM outputs). I think those are two characteristics that have helped me become a better data and LLM wrangler. I think it’s also what will help me become a good maintainer.</p>
<p>A more abstract “skill” is the urge to figure out: why are two things that are supposed to be equal, not equal? And then stubbornly resolving that discrepancy, encountering all sorts of roadblocks (and learning opportunities along the way). Prioritizing this urge has accounted for most of my professional development in ML.</p>
</section>
<section id="my-approach-to-the-course" class="level2">
<h2 class="anchored" data-anchor-id="my-approach-to-the-course">My Approach to the Course</h2>
<p>I somewhat organically found my rhythm in this course. I held myself to the following non-negotiable standard:</p>
<ol type="1">
<li>I would attend every lecture live.</li>
<li>I would attend every office hours live.</li>
<li>I would write a blog post with standout ideas <a href="https://vishalbakshi.github.io/blog/index.html#category=AI%20Evals">from each lesson and corresponding course reader chapter</a>.</li>
</ol>
<p>I didn’t do most of the homeworks, I didn’t apply what I learned to the (personal) projects I was working on (that were now back burner projects).</p>
</section>
<section id="applying-applied-ai-skills" class="level2">
<h2 class="anchored" data-anchor-id="applying-applied-ai-skills">Applying Applied AI Skills</h2>
<p>While I can’t commit to a daily or weekly allotment of hours that I’ll spend applying the learnings from this course, there are two concrete tasks that I can commit to finishing before the end of the year:</p>
<ol type="1">
<li>Perform error analysis on each pipeline step in my <a href="https://youtu.be/NwPKy1rqXT8">AgentFasbook project</a> for one chapter of fastbook.</li>
<li>Perform error analysis (and LLM Judge prompt error estimation “in production”) for my <a href="https://youtu.be/FXOXoaGjntc">TinyScaleLab project</a> for one training run.</li>
</ol>
<p>My AgentFastbook project involves expanding my manually curated fastbook-benchmark IR dataset using an LLM pipeline (decomposing a gold answer into atomic facts –&gt; retrieving chapter passages relevant to those facts –&gt; extracting only relevant text from those passages). I learned from Q+A in the course discord that I should perform error analysis on each step first and then on the full “trace” from end-to-end (because the quality of retrieval can for example effect the quality of relevant text extraction).</p>
<p>My TinyScaleLab project aims to train tiny models to 1) generate coherent english (as shown in <a href="https://arxiv.org/abs/2305.07759">the TinyStories paper</a>) and 2) perform small tasks (like gold answer decomposition or text extraction) reliably after multi-stage finetuning.</p>
</section>
<section id="closing-thoughtstestimonial" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughtstestimonial">Closing Thoughts/Testimonial</h2>
<p>I still have a lingering feeling that I didn’t maximize what I put into the course. I think that’s totally on me. The best I can do now is use that as motivation to apply what I’ve learned to my projects.</p>
<p>One unexpected benefit from this course is that my mind is more open to AI applications. Watching the examples in the course, listening to problems that students are solving in real life, really made me question my relationship with LLMs. I don’t think I fully see the potential and myriad of the problems LLMs can solve. I’m not even sure I see the “shapes” of those problems and solutions. I think the only way to bridge the gap between my understanding of applied AI and the understanding of so many people in the course that I witnessed first-hand is to actually engage in that work. Jeremy Howard and Jonathan Whitaker’s SolveIt talk, even though I was a student in their first cohort, made me question my relationship with problem-solving. Teresa’s talk made me question if I am moving with enough courage in this space. Omar’s talk made me question whether I’m investing enough time in systems thinking.</p>
<p>Engaging in this course with a lot of things going on in my life was a grounding and stabilizing experience. Shreya and Hamel, as knowledgeable and brilliant as they are, are equally welcoming and inclusive. I learned a lot about how to hold space for people to ask challenging or vulnerable questions and what it means to actively encourage community and belonging in a distributed, semi-asynchronous, remote setting. There was a very strong resonance amongst everyone in the cohort. You could tell that everyone was on the same frequency, thinking about the same problems, trying to figure out similar solutions. Everyone had a different angle, background, or story to share, whether it was the guest speakers or the students participating in the office hours. I strongly recommend that everyone using LLMs or building LLM applications take this course.</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-17-ai-evals/</guid>
  <pubDate>Sun, 17 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Logit Divergence Between Models Differently Converted to torch.bfloat16</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-17-hf-torch-dtype/</link>
  <description><![CDATA[ 




<div id="cell-1" class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post I’ll illustrate a recent head-scratcher I came across—how to convert a model to <code>torch.bfloat16</code> changes the intermediate and final outputs. I don’t know why this happens and not sure of a path to figure that out.</p>
<p>In <code>model1</code> I specify <code>torch_dtype</code> in <code>AutoModelForCausalLM.from_pretrained</code>. In <code>model2</code>, I don’t, and instead use <code>to(torch.bfloat16)</code> after the model is loaded.</p>
<div id="cell-5" class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">checkpoint <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFaceTB/SmolLM2-135M"</span></span>
<span id="cb2-2">device <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span></span>
<span id="cb2-3">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(checkpoint)</span>
<span id="cb2-4">model1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.bfloat16).to(device)</span>
<span id="cb2-5">model2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(checkpoint).to(device).to(torch.bfloat16)</span></code></pre></div>
</div>
</section>
<section id="comparing-logits" class="level2">
<h2 class="anchored" data-anchor-id="comparing-logits">Comparing Logits</h2>
<p>Given a set of input tokens, the output logits of the two models are not identical.</p>
<div id="cell-8" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="80502c56-d418-4fba-dde2-a134dcd209db">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer.encode(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gravity is"</span>, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>).to(device)</span>
<span id="cb3-2">inputs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>tensor([[22007,  6463,   314]], device='cuda:0')</code></pre>
</div>
</div>
<div id="cell-9" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="782d67bf-c79b-45cc-fb92-9981b1528788">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">model1.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb5-2">logits1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model1(inputs).logits</span>
<span id="cb5-3">logits1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>tensor([[[18.0000, 14.5625, 14.6875,  ..., 16.2500, 16.2500, 22.1250],
         [15.6875, -0.4180, -0.3477,  ...,  8.2500, 12.1250,  7.3438],
         [12.1875, -2.2812, -2.2031,  ...,  7.3750, 10.6875,  8.1875]]],
       device='cuda:0', dtype=torch.bfloat16, grad_fn=&lt;UnsafeViewBackward0&gt;)</code></pre>
</div>
</div>
<div id="cell-10" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="cf487415-91c9-4464-c064-a506c4a090cb">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">model2.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb7-2">logits2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model2(inputs).logits</span>
<span id="cb7-3">logits2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor([[[18.0000, 14.5625, 14.6875,  ..., 16.2500, 16.2500, 22.1250],
         [15.7500, -0.2715, -0.2002,  ...,  8.4375, 12.2500,  7.5000],
         [12.3125, -2.2188, -2.1406,  ...,  7.5000, 10.6875,  8.3125]]],
       device='cuda:0', dtype=torch.bfloat16, grad_fn=&lt;UnsafeViewBackward0&gt;)</code></pre>
</div>
</div>
<div id="cell-11" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9c6a1f1e-6ce9-4a20-ee2d-ef92a3a9f82e">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">torch.allclose(logits1, logits2)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>False</code></pre>
</div>
</div>
<div id="cell-12" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1377752c-96df-4195-9d6f-052bbbe3cf7d">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">(logits1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> logits2).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor(0.3457, device='cuda:0')</code></pre>
</div>
</div>
<div id="cell-13" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="41d1e426-3945-40e1-c97b-f2e20debb62e">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(logits1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> logits2).mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor(0.0762, device='cuda:0', dtype=torch.bfloat16, grad_fn=&lt;MeanBackward0&gt;)</code></pre>
</div>
</div>
</section>
<section id="comparing-weights" class="level2">
<h2 class="anchored" data-anchor-id="comparing-weights">Comparing Weights</h2>
<p>A helper function to inspect a particular submodule in a particular layer.</p>
<div id="cell-16" class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _print(model1, model2, module, submodule, layer_idx):</span>
<span id="cb15-2">    w1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(model1.model.layers[layer_idx], module), submodule).weight</span>
<span id="cb15-3">    w2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(model2.model.layers[layer_idx], module), submodule).weight</span>
<span id="cb15-4">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>submodule<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> torch.allclose: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>torch<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>allclose(w1, w2)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
</div>
<div id="cell-17" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2c8feb33-9f2e-4511-9518-0d313209b7d1">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">_print(model1, model2, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"self_attn"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"q_proj"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>self_attn.q_proj torch.allclose: True</code></pre>
</div>
</div>
<p>Looping through all weight matrices in state dicts, they are all identical—why are output logits not identical then? I would assume that something in the matrix ops is causing the divergence.</p>
<div id="cell-19" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="6f87344e-7033-4bee-e12c-ff02b8bb7a89">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb18-2">d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb18-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> model1.state_dict().keys():</span>
<span id="cb18-4">    w1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model1.state_dict()[k]</span>
<span id="cb18-5">    w2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model2.state_dict()[k]</span>
<span id="cb18-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> torch.allclose(w1, w2): n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb18-7">    d <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb18-8">n, d, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>d</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(273, 273, 1.0)</code></pre>
</div>
</div>
</section>
<section id="forward-hooks" class="level2">
<h2 class="anchored" data-anchor-id="forward-hooks">Forward Hooks</h2>
<p>Hooking the two models to track intermediate layer outputs.</p>
<div id="cell-22" class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">model1.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb20-2">model2.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">eval</span>()</span>
<span id="cb20-3">outputs_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span></code></pre></div>
</div>
<div id="cell-23" class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> capture_output(name):</span>
<span id="cb21-2">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span>, output):</span>
<span id="cb21-3">        outputs_dict[name] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> output[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].detach()</span>
<span id="cb21-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span></code></pre></div>
</div>
<div id="cell-24" class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">hooks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb22-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>):</span>
<span id="cb22-3">    hooks.append(model1.model.layers[i].register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span>
<span id="cb22-4">    hooks.append(model2.model.layers[i].register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model2_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span></code></pre></div>
</div>
<div id="cell-25" class="cell">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb23-2">    model1(inputs)</span>
<span id="cb23-3">    model2(inputs)</span></code></pre></div>
</div>
<div id="cell-26" class="cell">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> hooks: h.remove()</span></code></pre></div>
</div>
<p>The difference in intermediate outputs diverges as you pass through the model. That smells of typical floating point precision error.</p>
<div id="cell-28" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="6c7066d4-d24a-4f37-da3c-c396f78e69e0">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">metric <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean"</span></span>
<span id="cb25-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>):</span>
<span id="cb25-3">    o1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outputs_dict[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb25-4">    o2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outputs_dict[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model2_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb25-5"></span>
<span id="cb25-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> torch.allclose(o1, o2):</span>
<span id="cb25-7">        max_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (o1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>o2).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>().item()</span>
<span id="cb25-8">        mean_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (o1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>o2).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>().mean().item()</span>
<span id="cb25-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> metric <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Layer </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: max diff = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>max_diff<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb25-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> metric <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Layer </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: mean diff = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mean_diff<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Layer 0: mean diff = 0.0017547607421875
Layer 1: mean diff = 0.005035400390625
Layer 2: mean diff = 0.00830078125
Layer 3: mean diff = 0.010986328125
Layer 4: mean diff = 0.011962890625
Layer 5: mean diff = 0.01251220703125
Layer 6: mean diff = 0.01312255859375
Layer 7: mean diff = 0.0137939453125
Layer 8: mean diff = 0.015380859375
Layer 9: mean diff = 0.0172119140625
Layer 10: mean diff = 0.0189208984375
Layer 11: mean diff = 0.0185546875
Layer 12: mean diff = 0.01953125
Layer 13: mean diff = 0.020751953125
Layer 14: mean diff = 0.021728515625
Layer 15: mean diff = 0.0234375
Layer 16: mean diff = 0.026123046875
Layer 17: mean diff = 0.0263671875
Layer 18: mean diff = 0.0269775390625
Layer 19: mean diff = 0.0301513671875
Layer 20: mean diff = 0.03271484375
Layer 21: mean diff = 0.036376953125
Layer 22: mean diff = 0.044921875
Layer 23: mean diff = 0.05322265625
Layer 24: mean diff = 0.05810546875
Layer 25: mean diff = 0.06689453125
Layer 26: mean diff = 0.0771484375
Layer 27: mean diff = 0.091796875
Layer 28: mean diff = 0.1005859375
Layer 29: mean diff = 0.1484375</code></pre>
</div>
</div>
<p>The max difference in outputs reaches <code>6.0</code> by the 30th layer!</p>
<div id="cell-30" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d9b03a21-de97-48f9-919c-9c252f976f5c">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">metric <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max"</span></span>
<span id="cb27-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>):</span>
<span id="cb27-3">    o1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outputs_dict[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb27-4">    o2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outputs_dict[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model2_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb27-5"></span>
<span id="cb27-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> torch.allclose(o1, o2):</span>
<span id="cb27-7">        max_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (o1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>o2).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>().<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>().item()</span>
<span id="cb27-8">        mean_diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (o1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>o2).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>().mean().item()</span>
<span id="cb27-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> metric <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Layer </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: max diff = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>max_diff<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb27-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> metric <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mean"</span>: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Layer </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: mean diff = </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>mean_diff<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Layer 0: max diff = 0.0625
Layer 1: max diff = 0.25
Layer 2: max diff = 0.25
Layer 3: max diff = 0.25
Layer 4: max diff = 0.25
Layer 5: max diff = 0.25
Layer 6: max diff = 0.25
Layer 7: max diff = 0.5
Layer 8: max diff = 0.5
Layer 9: max diff = 0.5
Layer 10: max diff = 1.0
Layer 11: max diff = 1.0
Layer 12: max diff = 1.0
Layer 13: max diff = 0.5
Layer 14: max diff = 0.5
Layer 15: max diff = 0.5
Layer 16: max diff = 0.5
Layer 17: max diff = 0.5
Layer 18: max diff = 0.5
Layer 19: max diff = 0.75
Layer 20: max diff = 0.5
Layer 21: max diff = 0.5
Layer 22: max diff = 0.5
Layer 23: max diff = 0.75
Layer 24: max diff = 1.0
Layer 25: max diff = 2.0
Layer 26: max diff = 2.0
Layer 27: max diff = 2.0
Layer 28: max diff = 1.0
Layer 29: max diff = 6.0</code></pre>
</div>
</div>
<p>Reloading the models and inspecting the outputs of intermediate modules like <code>self_attn</code> and <code>mlp</code>.</p>
<div id="cell-32" class="cell">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">model1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.bfloat16).to(device)</span>
<span id="cb29-2">model2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(checkpoint).to(device).to(torch.bfloat16)</span></code></pre></div>
</div>
<div id="cell-33" class="cell">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">modules <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb30-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"self_attn"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"q_proj"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"k_proj"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"v_proj"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"o_proj"</span>],</span>
<span id="cb30-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mlp"</span>: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gate_proj"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"up_proj"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"down_proj"</span>],</span>
<span id="cb30-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input_layernorm"</span>: [],</span>
<span id="cb30-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"post_attention_layernorm"</span>: []</span>
<span id="cb30-6">    }</span></code></pre></div>
</div>
<div id="cell-34" class="cell">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">outputs_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span></code></pre></div>
</div>
<div id="cell-35" class="cell">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> module <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> modules.keys():</span>
<span id="cb32-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input_layernorm"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"post_attention_layernorm"</span>:</span>
<span id="cb32-3">        hooks.append(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(model1.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], module).register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span>
<span id="cb32-4">        hooks.append(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(model2.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], module).register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model2_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span>
<span id="cb32-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb32-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> submodule <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> modules[module]:</span>
<span id="cb32-7">            hooks.append(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(model1.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], module), submodule).register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>submodule<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span>
<span id="cb32-8">            hooks.append(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">getattr</span>(model2.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], module), submodule).register_forward_hook(capture_output(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model2_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>submodule<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)))</span></code></pre></div>
</div>
<div id="cell-36" class="cell">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> torch.no_grad():</span>
<span id="cb33-2">    model1(inputs)</span>
<span id="cb33-3">    model2(inputs)</span></code></pre></div>
</div>
<div id="cell-37" class="cell">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> h <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> hooks: h.remove()</span></code></pre></div>
</div>
<p>Interestingly, the intermediate attention outputs are identical but there’s divergence in the outputs of the attention mechanism as it passes through <code>o_proj</code>.</p>
<div id="cell-39" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ce0830e3-31bc-4554-ce6e-ba3d91c133fb">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> module <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> modules.keys():</span>
<span id="cb35-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input_layernorm"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> module <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"post_attention_layernorm"</span>:</span>
<span id="cb35-3">        o1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outputs_dict[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb35-4">        o2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outputs_dict[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model2_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb35-5">        diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (o1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>o2).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>().mean().item()</span>
<span id="cb35-6">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>diff<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb35-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb35-8">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> submodule <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> modules[module]:</span>
<span id="cb35-9">            o1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outputs_dict[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model1_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>submodule<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb35-10">            o2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outputs_dict[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model2_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>submodule<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb35-11">            diff <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (o1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>o2).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>().mean().item()</span>
<span id="cb35-12">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>module<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>submodule<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>diff<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>self_attn.q_proj: 0.0
self_attn.k_proj: 0.0
self_attn.v_proj: 0.0
self_attn.o_proj: 2.1457672119140625e-05
mlp.gate_proj: 0.000476837158203125
mlp.up_proj: 0.0003833770751953125
mlp.down_proj: 0.00177764892578125
input_layernorm: 0.0
post_attention_layernorm: 1.8715858459472656e-05</code></pre>
</div>
</div>
<p>Again I haven’t dug into why these differences exist, but wanted to document that they do.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-17-hf-torch-dtype/</guid>
  <pubDate>Sun, 17 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Standout Ideas from Lesson 8 of the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-14-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-8-course-review-and-live-coding-an-annotation-app" class="level2">
<h2 class="anchored" data-anchor-id="lesson-8-course-review-and-live-coding-an-annotation-app">Lesson 8: Course Review and Live Coding an Annotation App</h2>
<p><strong>Idea 1: You should have AI-in-the-loop,</strong> as opposed to being the “human-in-the-loop”. You should drive the AI. You should understand every step of the AI pipeline (as is learned through the process of doing error analysis). As we’ve seen throughout the course, there are strategic opportunities to use LLMs to <em>supplement</em> your analysis, potentially evolving to full automation with routine human validation (e.g.&nbsp;production LLM Judge outputs sampled and reviewed every week).</p>
<p><strong>Idea 2: Provide a detailed prompt when vibe coding an annotation app.</strong> Shreya provided the direct path to the trace CSV, an explanation of the CSV and message column structures (content/roles), and the goals/key characteristics of the app and its UI/UX (such as open coding, a progress bar, navigation buttons and a dropdown of previously used annotations). Shreya asks the LLM to create a <code>plan.md</code> when coding something for the first time and reviews/provides feedback before finalizing it. You can always follow up with more requirements as you review the plan before executing on it.</p>
<p><strong>Idea 3: Implement heuristics for where the user’s attention should go.</strong> One example is semantic and/or keyword highlighting in the displayed trace based on previous annotations. This will help the user more easily identify common failure modes (which supports the core goal: reduce friction! Ease cognitive load!).</p>
<p><strong>Idea 4: Common preferred annotation app UI characteristics</strong> <mark>(note: these are just examples, you should think about your own app requirements when building it)</mark>: expanding/collapse the system prompt, “keywords from user query” at the top which are highlighted in the messages listed below it, annotation should always be visible (shouldn’t require scrolling to view it), highlight domain-specific details (like dates/times for scheduling requests), visually flagged duplicate assistant messages, cleanly render raw JSON messages/tool calls.</p>
<p><strong>Idea 5: Think step by step.</strong> That means you too, not just the LLM! To improve accuracy, start with low hanging fruit (disambiguate your prompt/instructions), then tackle more involved tasks (decomposing the task into smaller subtasks that are easier for the LLM to handle), and finally approach advanced strategies (e.g.&nbsp;fine-tuning, prompt optimization, human review loops to generate more labeled examples).</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-14-ai-evals/</guid>
  <pubDate>Thu, 14 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Standout Ideas from Lesson 7 of the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-12-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-7-interfaces-for-human-review" class="level2">
<h2 class="anchored" data-anchor-id="lesson-7-interfaces-for-human-review">Lesson 7: Interfaces for Human Review</h2>
<p><strong>Idea 1: Custom UIs = 10x review throughput</strong> compared to reviewing in a spreadsheet. This because custom UIs allow a domain-aware view (emails structured like your inbox instead of a string of text) and hotkeys for navigation or one-click tags, <em>and</em> takes only 1 hr to prototype nowadays. A middle-ground between spreadsheets and custom UIs: jupyter notebook (a pseudo-interface) especially with the <a href="https://ipython.readthedocs.io/en/stable/config/integrating.html#rich-display:~:text=_repr_html_%20should%20return%20HTML%20as%20a%20str"><code>_repr_html_</code> method</a>.</p>
<p><strong>Idea 2: HCI Principles for UIs (Nielsen, 1994).</strong> Visibility of status (let your user know where they are), recognition over recall (assign tags instead of free-form text in second round of error analysis and beyond), match the real world (native end user display form; results in catching errors only apparent in this form), user control (pass/fail 1-key press, undo, tag select w/number keys, “defer” for uncertainty, goal: <em>get the user into a flow state</em>), minimalist first (expand on demand). Add a progress bar whenever you’re making a user wait for something. Overall principle: <mark>reduce friction</mark>.</p>
<p><strong>Idea 3: Nerd-snipe your features.</strong> Shreya implemented a highlight feature where on the backend their app looks for semantic or keyword similarities with previous failed samples and highlights those words in the current example display to flag common issues for easier user identification. Super cool. Another similar example: batch-label similar traces after clustering to wipeout repeat bugs. I never considered integrating machine intelligence into error analysis before this!</p>
<p><strong>Idea 4: Criteria drift happens!</strong> Reviewers’ definitions change over time so keep rubrics and labels editable. What you think was acceptable/unacceptable changes as you review real traces. Additionally, humans’ understanding of LLM capabilities also evolves over time (i.e.&nbsp;humans align with LLMs as LLMs align with humans).</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-12-ai-evals/</guid>
  <pubDate>Tue, 12 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Standout Ideas from Lessons 5 + 6 and Chapter 7 from the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-07-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-5-architecture-specific-evaluation-strategies" class="level2">
<h2 class="anchored" data-anchor-id="lesson-5-architecture-specific-evaluation-strategies">Lesson 5: Architecture-Specific Evaluation Strategies</h2>
<p><strong>Idea 1: Include edge cases in few shot examples</strong>. Show the LLM examples that you might struggle with, give it a lot of information in each example. I imagine that you will gain a better understanding of what truly contributes to Pass or Fail judgments as you curate difficult few shot examples. Don’t just randomly pick examples, cherry pick them based on how well they complement the rest of your prompt. Give examples that are the most instructive.</p>
<p><strong>Idea 2: Use automation strategically</strong>. We don’t want to not look at our data, but we also want to use the reasoning power of LLMs. Shreya fed an LLM their open codes, axial codes and traces and asked it to label true/false (if LLM responses in trace are substantiated with tool outputs) for each trace and provide a rationale. Shreya trusted the LLM’s true/false labels because they provided it with open codes.</p>
<p><strong>Idea 3: Don’t provide open/axial codes in LLM Judge Prompt few shot examples.</strong> We’re using this judge in production on unlabeled traces which will not have open/axial codes so we don’t want the LLM Judge to learn/expect these codes to be present.</p>
<p><strong>Idea 4: Aim for 80-85% LLM Judge TNR and TPR.</strong> 50% is random chance, 100% probably means something’s wrong in your judge prompt.</p>
<p><strong>Idea 5: The fastest way for you to fail in an AI project is for people to lose trust in what you’re doing.</strong> There’s a human bias that people have in trusting what a computer says. Don’t take the judge at face value. Run some tests to evaluate the confidence interval of the Judge, unbiasing its success rate (bias = Judge labels “Pass” more than “Fail” by default or vice vesa). The eval should align with the product experience.</p>
</section>
<section id="lesson-6-rag-cicd" class="level2">
<h2 class="anchored" data-anchor-id="lesson-6-rag-cicd">Lesson 6: RAG, CI/CD</h2>
<p><strong>Idea 1 Do error analysis on the whole system, but do evals on retrieval and LLM generation separately.</strong> Make sure your retriever’s Recall@k is 80%+, then perform error analysis, otherwise you’re evaluating generation errors based on flawed context. Don’t use popular metrics to evaluate generation—measure what’s relevant to your product, which you will uncover during your analysis.</p>
<p><strong>Idea 2 Bring domain knowledge to chunk size.</strong> Is there a natural breaking point in your document? What is a meaningful chunk in the context of your domain? The chunks ultimately represent the document during search. It’s okay to have variable chunk sizes.</p>
<p><strong>Idea 3 Likert scales have a use!</strong> Shreya asks an LLM to score synthetic queries (when creating an evaluation dataset) on a Likert scale and filters out queries with scores of 1 or 2 (out of 5). These scores are discarded after this filtering use.</p>
<p><strong>Idea 4 Ground synthetic queries in realism:</strong> User queries are often confusing to interpret, incomplete, and contain typos/grammatical errors. The queries in your evaluation dataset should reflect such nuances to provide meaningful use cases for retrieval.</p>
<p><strong>Idea 5 Optimize for Recall@k first.</strong> Shreya has rarely seen utility in optimizing for Precision@k first (how many of the top-k retrieved chunks are relevant?) because the consumer of these chunks in a RAG pipeline is an LLM, which cares more about how many of the total relevant chunks are present in the top-k retrieved chunks (Recall@k) to generate a relevant response. LLMs are getting better at reasoning over the retrieved chunks to determine relevance. Use MRR@k (how high up in the ranking is the first relevant chunk?) after optimizing for Recall@k as MRR@k measures how quickly the LLM finds <em>an</em> answer.</p>
<p><strong>Idea 6: Focus on process, not tools.</strong> Which goes against how most people think about building AI systems. If something’s not working, your first instinct should be to actually understand what is going wrong, not to plug-in a different tool in hopes for improvement, or sweep different hyperparameters. Additionally, don’t get lost in the vector DB sauce—start with basic BM25 keyword search first.</p>
</section>
<section id="lesson-7-evaluating-retrieval-augmented-generation-rag" class="level2">
<h2 class="anchored" data-anchor-id="lesson-7-evaluating-retrieval-augmented-generation-rag">Lesson 7: Evaluating Retrieval-Augmented Generation (RAG)</h2>
<p><strong>Idea 1: Multi-stage retrieval and the Recall/Precision trade-off</strong>. LLMs can handle many passages so we want to make sure it’s provided as many relevant passages as possible, this means increasing the number of passages provided. However, long contexts cost more and are limited by the LLM’s context window. We use a cheaper retriever to do a first pass on retrieving relevant passages (Recall@k) and a more powerful retriever to then re-rank them (Precision@k, MRR or NDCG@k). We take the top-k (where k is smaller than the first pass retrieved passages) and pass that to the LLM.</p>
<blockquote class="blockquote">
<p>Modern LLM attend more strongly to salient tokens, so they can often ignore irrelevant content if the key information is present. But if that information is missing altogether–low recall–then the generator has no way to produce a correct answer.</p>
</blockquote>
<p><strong>Idea 2: The ARES framework complements error analysis.</strong> Precisely evaluating “Answer Faithfulness” (failures include hallucinations, omissions and misinterpretations) and “Answer Relevance” (failure = factually correct based on context but irrelevant to the query) requires error analysis to identify where and how specific failure modes occur in our product.</p>
<p><strong>Idea 3: Be wary of synthentically generated queries</strong> as they often are not representative of the messy queries encountered in production. Regularly validate these queries, referncing real queries from logs or human-curated examples.</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-07-ai-evals/</guid>
  <pubDate>Thu, 07 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Standout Ideas from Lesson 4 and Chapter 5 of the Course Reader from the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-03-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-4-automated-evaluators" class="level2">
<h2 class="anchored" data-anchor-id="lesson-4-automated-evaluators">Lesson 4: Automated Evaluators</h2>
<p><strong>Idea 1: You can’t measure what you don’t ask for.</strong> If your prompt didn’t include an instruction on providing links to X, and the LLM doesn’t provide those links, that’s a specification failure (fix the prompt!). If the prompt did include it but the LLM failed to apply the instruction, that’s a generalization failure and should be tracked by an automated evaluator.</p>
<p><strong>Idea 2: Use code-based evaluators if you can,</strong> as they are deterministic. They take as input the trace and a failure mode and return <code>True</code> or <code>False</code> or some score for objective rule-based checks (e.g.&nbsp;parsing structure, regex/string matching for keywords, structural constraints, tool execution errors).</p>
<p><strong>Idea 3: Just because you can ask an LLM Judge anything you want, doesn’t mean you should.</strong> Use LLM Judges to do specific, well-defined, binary failure mode classification (Pass/Fail) tasks. A Pass/Fail LLM Judge score is easier to assess and leads to easy-to-interpret Judge accuracy. Also, don’t pack multiple criteria into one prompt, create a prompt for each criterion.</p>
<p><strong>Idea 4: Don’t leak test instances into your process of building an LLM Judge</strong> Use 10-20% of labeled axial coding data to curate Judge prompt few shot examples (training set), ~40% to iteratively improve the prompt (dev set), and ~40% for final unbiased Judge evalation after prompt tuning is done (test set). The last thing you want in your prompt is a few shot example that’s in the test set. <mark>Low dev set performance (TPR and TNR) tell us that the few shot examples from the train set do not generalize.</mark></p>
<p><strong>Idea 5: Don’t show your LLM Judge what it’s already good at.</strong> Your few shot examples should show difficult/tricky situations for evaluation. To do this, manually iterate the examples. I would imagine that like open coding, you would build a more nuanced intuition about your data (and your product!) through this process. Other tips: write your examples like you are explaining it to a human; try to include the best example of a pass or fail; your examples can also contain reasoning to provide richer “grounding” to your LLM.</p>
</section>
<section id="chapter-5-implementing-automated-evaluators" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5-implementing-automated-evaluators">Chapter 5: Implementing Automated Evaluators</h2>
<p><strong>Idea A: Reference-based and reference-free metrics serve different purposes.</strong> A “reference” here means “reference LLM output”. Reference-based metrics allow iterative development with holistic checks (whether the LLM output match the golden reference). Reference-free metrics better adapt at scale on new, unlabeled data (as they measure intrinsic properties or rules related to failure modes). Reference-based metric: LLM output matches a “golden” trace with a specific sequence of tool calls. Reference-free metric: LLM output contains valid tool call names.</p>
<p><strong>Idea B: Test your judge on unlabeled data.</strong> Even the test set is biased as it represents a portion of our labeled data, which may not be representative of broader out-of-domain situations your Judge will inevitably encounter. We use the Judge’s “raw success rate” (number of Pass labels/number of unlabeled traces) and a series of calculations on random test set samples to estimate within a confidence interval the Judge’s “true success rate.”</p>
<p><strong>Idea C: Judges don’t come pretrained on a product’s values—we have to teach them.</strong> This is why we validate the judge’s response and calculate metrics around alignment (like TNR and TPR). This is also why we provide few shot examples so the Judge can evaluate on the specific desired characteristics of our product (especially for vibe-y dimensions like tone).</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-03-ai-evals/</guid>
  <pubDate>Sun, 03 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TIL: How LLM-Foundry Ignores Prompt Tokens in labels for Instruction Finetuning.</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-31-llm-foundry/</link>
  <description><![CDATA[ 




<p>I recently realized (after a conversation with a colleague) that I didn’t know how LLM-Foundry replaces prompt tokens with <code>-100</code> to exclude them from the loss calculation. I fed Claude project knowledge the LLM-Foundry GitHub repo and asked it to walk me through this process line-by-line. Since “Chat using integrations can’t be shared” I’m pasting Claude’s walkthrough here (with a couple of my notes). All the referenced functions are inside <a href="https://github.com/mosaicml/llm-foundry/blob/main/llmfoundry/data/finetuning/collator.py"><code>llmfoundry/data/finetuning/collator.py</code></a></p>
<section id="setup-input-example" class="level2">
<h2 class="anchored" data-anchor-id="setup-input-example">Setup: Input Example</h2>
<p>Let’s say we have this raw training example:</p>
<pre><code>{
    'prompt': 'What is photosynthesis?',
    'response': 'Photosynthesis is the process by which plants convert sunlight into energy.'
}</code></pre>
<p>After tokenization, this becomes:</p>
<pre><code>example = {
    'turns': [
        {
            'input_ids': [1127, 318, 2825, 43943, 30],      # "What is photosynthesis?"
            'labels': [21197, 43943, 318, 262, 1429, 416, 543, 6134, 10385, 4252, 1657, 656, 2568, 13]  # "Photosynthesis is the process..."
        }
    ]
}</code></pre>
</section>
<section id="line-by-line-processing" class="level2">
<h2 class="anchored" data-anchor-id="line-by-line-processing">Line-by-Line Processing</h2>
<section id="collator-entry-point-seq2seqfinetuningcollator.__call__" class="level3">
<h3 class="anchored" data-anchor-id="collator-entry-point-seq2seqfinetuningcollator.__call__">Collator Entry Point (<code>Seq2SeqFinetuningCollator.__call__</code>)</h3>
<pre><code>def __call__(self, examples: list[TokenizedExample]) -&gt; dict[str, torch.Tensor]:
    # examples is a list of TokenizedExample objects (batch)
    
    if self.decoder_only_format:
        batch = self._process_and_batch_decoder_only(examples)  # Most common path</code></pre>
</section>
<section id="batch-processing-_process_and_batch_decoder_only" class="level3">
<h3 class="anchored" data-anchor-id="batch-processing-_process_and_batch_decoder_only">Batch Processing (<code>_process_and_batch_decoder_only</code>)</h3>
<pre><code>def _process_and_batch_decoder_only(self, examples: list[TokenizedExample]):
    processed_examples = []
    
    # Step 1: Process each example in the batch through stitch_turns_decoder_only
    input_ids_and_labels = [
        stitch_turns_decoder_only(
            example_turns=example['turns'],           # The prompt/response turns
            target_prompts=self.target_prompts,      # 'none' 
            target_responses=self.target_responses,   # 'last'
            eos_token_id=self.tokenizer.eos_token_id,
        ) for example in examples
    ]</code></pre>
</section>
<section id="core-processing-stitch_turns_decoder_only" class="level3">
<h3 class="anchored" data-anchor-id="core-processing-stitch_turns_decoder_only">Core Processing (<code>stitch_turns_decoder_only</code>)</h3>
<p>This is where the magic happens:</p>
<pre><code>def stitch_turns_decoder_only(example_turns, target_prompts, target_responses, eos_token_id):
    target_prompts = target_prompts.lower()  # 'none'
    target_responses = target_responses.lower()  # 'last'
    
    # Line 1: Look up the target policy functions
    prompt_to_target = _TARGET_POLICY_LOOKUP[target_prompts]  # Gets _sequence_to_labels_none
    response_to_target = _TARGET_POLICY_LOOKUP[target_responses]  # Gets _sequence_to_labels_last
    
    # Line 2: Initialize output sequences
    input_ids = []
    labels = []
    
    # Line 3: Process each turn in the conversation
    for idx, turn in enumerate(example_turns):
        is_last_turn = idx + 1 == len(example_turns)  # True for our single-turn example
        
        # Line 4: Extract the prompt and response token sequences
        context = ensure_list(turn['input_ids'])   # [1127, 318, 2825, 43943, 30] - "What is photosynthesis?"  
        target = ensure_list(turn['labels'])       # [21197, 43943, 318, ...] - "Photosynthesis is..."
        
        # Line 5: Add EOS token to final response if needed
        if is_last_turn and eos_token_id is not None:
            if target[-1] != eos_token_id:
                target = target + [eos_token_id]   # Append &lt;|endoftext|&gt; token
        
        # Line 6: Build the concatenated input_ids sequence
        input_ids += context  # Add prompt tokens: [1127, 318, 2825, 43943, 30]
        input_ids += target   # Add response tokens: [1127, 318, 2825, 43943, 30, 21197, 43943, 318, ...]
        
        # Line 7: Build the labels sequence using target policies
        labels += prompt_to_target(context, is_last_turn, prompt_cutoff)  # Calls _sequence_to_labels_none
        labels += response_to_target(target, is_last_turn)                # Calls _sequence_to_labels_last</code></pre>
<blockquote class="blockquote">
<p>Vishal note: in Line 7, <code>labels</code> starts out as an empty list <code>[]</code> so the prompt is added first (via <code>+= prompt_to_target(...)</code>), after which the response is added (via <code>+= response_to_target</code>).</p>
</blockquote>
</section>
<section id="target-policy-functions" class="level3">
<h3 class="anchored" data-anchor-id="target-policy-functions">Target Policy Functions</h3>
<pre><code>def _sequence_to_labels_none(sequence, is_last_turn, cutoff):
    # Line 1: Convert ALL prompt tokens to -100 (ignore during loss)
    return [CROSS_ENTROPY_IGNORE_INDEX] * len(sequence)  # [-100, -100, -100, -100, -100]

def _sequence_to_labels_last(sequence, is_last_turn, cutoff):  
    # Line 1: Check if this is the final turn
    if is_last_turn:  # True in our case
        return sequence  # Keep actual token IDs: [21197, 43943, 318, ...]
    else:
        return [CROSS_ENTROPY_IGNORE_INDEX] * len(sequence)  # Would be [-100, -100, ...] for non-final turns</code></pre>
</section>
<section id="result-after-stitch_turns_decoder_only" class="level3">
<h3 class="anchored" data-anchor-id="result-after-stitch_turns_decoder_only">Result After <code>stitch_turns_decoder_only</code></h3>
<pre><code># Returned values:
input_ids = [1127, 318, 2825, 43943, 30, 21197, 43943, 318, 262, 1429, 416, 543, 6134, 10385, 4252, 1657, 656, 2568, 13, 50256]
#            |----------prompt----------|  |-------------------response---------------------------|  |EOS|

labels =    [-100, -100, -100, -100, -100, 21197, 43943, 318, 262, 1429, 416, 543, 6134, 10385, 4252, 1657, 656, 2568, 13, 50256]
#            |------ignore prompt-------|  |-------------------keep response--------------------|  |EOS|</code></pre>
<blockquote class="blockquote">
<p>Vishal note: we added <code>prompt_to_target</code> first to the empty <code>labels</code> list so the <code>-100</code>s come first.</p>
</blockquote>
</section>
<section id="back-to-batch-processing-continued" class="level3">
<h3 class="anchored" data-anchor-id="back-to-batch-processing-continued">Back to Batch Processing (continued)</h3>
<pre><code># Step 2: Handle sequence length limits
for input_ids, labels in input_ids_and_labels:
    orig_size = len(input_ids)
    
    # Truncate if too long
    if orig_size &gt; max_seq_len:
        input_ids = input_ids[:max_seq_len]
        labels = labels[:max_seq_len]
    
    # Create attention mask
    attention_mask = [1] * len(input_ids)  # All 1s for actual tokens
    
    # Step 3: Pad sequences to max_seq_len
    n_total = len(input_ids)
    i_pad = [CROSS_ENTROPY_IGNORE_INDEX] * (max_seq_len - n_total)  # Padding with -100
    
    if self.tokenizer.padding_side == 'left':
        labels = i_pad + labels  # Left pad labels with -100
    else:
        labels = labels + i_pad  # Right pad labels with -100 (more common)
    
    processed_example = {
        'input_ids': input_ids,      # Will be padded by tokenizer.pad()
        'labels': labels,            # Already padded with -100
        'attention_mask': attention_mask,  # Will be padded by tokenizer.pad()
    }
    processed_examples.append(processed_example)

# Step 4: Final padding using HuggingFace tokenizer
batch = self.tokenizer.pad(
    processed_examples,
    padding='max_length',
    max_length=max_seq_len,
    return_tensors='pt',
)</code></pre>
</section>
<section id="final-batch-output" class="level3">
<h3 class="anchored" data-anchor-id="final-batch-output">Final Batch Output</h3>
<pre><code>batch = {
    'input_ids': torch.tensor([
        [1127, 318, 2825, 43943, 30, 21197, 43943, 318, ..., 0, 0, 0]  # Padded with pad_token_id (0)
    ]),
    'labels': torch.tensor([
        [-100, -100, -100, -100, -100, 21197, 43943, 318, ..., -100, -100, -100]  # Padded with -100
    ]),
    'attention_mask': torch.tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, ..., 0, 0, 0]  # 1 for real tokens, 0 for padding
    ])
}</code></pre>
</section>
<section id="key-points" class="level3">
<h3 class="anchored" data-anchor-id="key-points">Key Points</h3>
<ol type="1">
<li>Prompt tokens → Labels = -100: The _sequence_to_labels_none function converts all prompt tokens to -100</li>
<li>Response tokens → Labels = actual token IDs: The _sequence_to_labels_last function keeps response tokens as-is</li>
<li>Padding tokens → Labels = -100: All padding positions also get -100</li>
<li>Loss calculation: PyTorch’s CrossEntropyLoss(ignore_index=-100) will only compute loss on response tokens</li>
</ol>
<p>This ensures the model learns to generate responses but never tries to “predict” the input prompt!</p>


</section>
</section>

 ]]></description>
  <category>LLM-Foundry</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-31-llm-foundry/</guid>
  <pubDate>Thu, 31 Jul 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Standout Ideas from Lesson 3 and Chapter 4 of the Course Reader from the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-31-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-3-error-analysis-contd." class="level2">
<h2 class="anchored" data-anchor-id="lesson-3-error-analysis-contd.">Lesson 3: Error Analysis (cont’d.)</h2>
<p><strong>Idea 1: Open code at the trace-level</strong>. Many errors only emerge in the context of the whole trace and mistakes often cascade across turns (i.e.&nbsp;label only the <em>first</em> failure).</p>
<p><strong>Idea 2: Manually classify open codes using AI-generated axial codes.</strong> This verifies whether the AI-generated codes are applicable (accurate and relevant). During the lesson ChatGPT missed “Did not invoke tool” in its initial axial code generation based on open codes. This type of mistake is common and is why we manually apply LLM-generated axial codes.</p>
<p><strong>Idea 3: If possible, reproduce a multi-turn error with a simpler single-turn test case</strong>. For example if a multi-turn conversation fails when the LLM tries to retrieve some information, (e.g.&nbsp;return the correct price for product X), create a new single-turn conversation targeting just that task. This “minimal reproducible error” is analogous to software engineering’s “minimal reproducible bug”. In both cases, you’re cutting through the noise and targeting the single task that fails; this help find the root cause.</p>
</section>
<section id="chapter-4-collaborative-evaluation-practices" class="level2">
<h2 class="anchored" data-anchor-id="chapter-4-collaborative-evaluation-practices">Chapter 4: Collaborative Evaluation Practices</h2>
<p><strong>Idea A: When possible, have only one person make the final judgment call on AI evaluation</strong>. You want a single person making decisions about the success or failure of the AI outputs to reduce noisy cooks in the kitchen. You need that person to have deep domain knowledge or be someone who represents the target users. Hamel and Shreya call this person the Principal Domain Expert.</p>
<p><strong>Idea B: Annotator disagreements inform rubric improvements, not retroactive label updates</strong>. You’re not trying to win an argument. This idea reminds me of being on an interview panel: when you discuss rubric scores with the highest disagreement, the goal is not for panelists to change their scores, the goal is to come to a common understanding of what rubric item was measuring, and if needed, update your understanding to reach concensus for future candidate assessments. If your process is flawed, try to correct it as soon as you can.</p>
<p><strong>Idea C: Battle-test your artifacts manually</strong>. The iteratively improved human annotator rubric and the concensus labeled dataset becomes the gold standard used for automated evaluators. The rubric becomes the specification passed to the LLM-Judge. A recurring theme in this course: don’t build something in the abstract, build it while grounded in real data. Just as we don’t predefine axial codes for failure modes before we look at the data and document open codes, we don’t predefine a rubric for the LLM Judge before we look at the data. There’s a feedback loop between error analysis artifacts (open codes, axial codes, annotator rubrics, annotation scores) and looking at your data. Looking at data builds your intuition which then informs the error analysis artifacts.</p>
<p><strong>Idea D: Even with multiple annotators, there’s an escalation path.</strong> A benevolent dictator may need to intervene and make the final call if the annotators can’t come to concensus. This underscores the importance of identifying a single Principal Domain Expert <em>even during collaborative evaluation</em>.</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-31-ai-evals/</guid>
  <pubDate>Thu, 31 Jul 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Standout Ideas from Lesson 2 of the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-28-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-2-error-analysis" class="level2">
<h2 class="anchored" data-anchor-id="lesson-2-error-analysis">Lesson 2: Error Analysis</h2>
<p><strong>Idea 1: Error analysis is how we close the gulf of comprehension.</strong> The gulf of comprehension is the gap between the information the data contains and your understanding of it. While it’s either impossible or unreasonable to look at every single piece of data collected from your users, Hamel and Shreya recommend looking at at least 100 traces.</p>
<p><strong>Idea 2: You need ~100 diverse traces to get a good representation of failure modes.</strong> A trace is a full record of the pipeline’s interaction (initil user query, all LLM inputs/outs, intermediate reasoning or tool calls, and final user-facing result). The number 100 is not a hard and fast rule, but signifies that 10-15 traces is not going to be enough. You want to look at enough traces such that you reach a theoretical saturation of failure modes. What that means is you’ve seen enough traces that are diverse enough that looking at any more traces will not introduce any new failure modes that you haven’t seen yet.</p>
<p><strong>Idea 3: Open coding is Hamel’s favorite subject in evals.</strong> Open codes are brief, descriptive notes about any observed problems, surprising actions or where behavior feels wrong or unexpected in the trace. As you write open codes, categories of errors will emerge.</p>
<p><strong>Idea 4: During open coding, don’t find the root cause, just observe and note.</strong> As you come across failed traces, it’s tempting to make note of why you think this failure occurred. For example, if you see that the LLM tool call return value did not contain the correct information, it’s tempting to step back and think about why that took place. Maybe the input to the tool was incorrect because your voice agent converted speech to text incorrectly. Maybe there’s something wrong in the database which resulted in leading to missed matches. As you can see, this type of pontification can potentially be endless and is not fruitful for the focused process of identifying failure modes. Just note the failure and move on to the next trace. We’ll think about root causes later.</p>
<p><strong>Idea 5: Pull the main failure mode from each trace. don’t get embroiled in the details.</strong> Relatedly, it’s tempting to zoom in as deep as you can, putting each word of the trace under a microscope. For folks who like analyzing data, this is satisfying. But it introduces noise in identifying high-priority failure modes. These open codes are later going to be clustered by theme (Axial Coding) and higher-level themes will be extracted; too granular of an analysis is a waste of time.</p>
<p><strong>Idea 6: The quality of open coding is going to hinge on your product sense.</strong> Successful open coding depends on your ability to skillfully look at data. This involves two broad skills: 1) you have to know what to look for, 2) you have to be detail-oriented enough to find the failure by looking at a sequence of messages. Knowing what to look for requires a deep understanding of your product from the user’s perspective.</p>
<p><strong>Idea 7: Start with a simple approach to get value fast.</strong> Fatigue from cognitive load is a real thing, especially when you’re looking at a hundred traces, many of which can involve multiple messages between the user and the assistant and multiple tool calls. The success of error analysis is going to depend on how fresh your mind is during the process. To achieve this, keep your open coding and axial coding heuristics simple. You can always do a second, third, and fourth pass through future traces after you fix the most pressing failure modes.</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-28-ai-evals/</guid>
  <pubDate>Mon, 28 Jul 2025 07:00:00 GMT</pubDate>
</item>
</channel>
</rss>
