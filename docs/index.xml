<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Vishal Bakshi&#39;s Blog</title>
<link>https://vishalbakshi.github.io/blog/</link>
<atom:link href="https://vishalbakshi.github.io/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Machine Learning blog by Vishal Bakshi</description>
<generator>quarto-1.7.32</generator>
<lastBuildDate>Thu, 07 Aug 2025 07:00:00 GMT</lastBuildDate>
<item>
  <title>Standout Ideas from Lessons 5 + 6 and Chapter 7 from the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-07-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-5-architecture-specific-evaluation-strategies" class="level2">
<h2 class="anchored" data-anchor-id="lesson-5-architecture-specific-evaluation-strategies">Lesson 5: Architecture-Specific Evaluation Strategies</h2>
<p><strong>Idea 1: Include edge cases in few shot examples</strong>. Show the LLM examples that you might struggle with, give it a lot of information in each example. I imagine that you will gain a better understanding of what truly contributes to Pass or Fail judgments as you curate difficult few shot examples. Don’t just randomly pick examples, cherry pick them based on how well they complement the rest of your prompt. Give examples that are the most instructive.</p>
<p><strong>Idea 2: Use automation strategically</strong>. We don’t want to not look at our data, but we also want to use the reasoning power of LLMs. Shreya fed an LLM their open codes, axial codes and traces and asked it to label true/false (if LLM responses in trace are substantiated with tool outputs) for each trace and provide a rationale. Shreya trusted the LLM’s true/false labels because they provided it with open codes.</p>
<p><strong>Idea 3: Don’t provide open/axial codes in LLM Judge Prompt few shot examples.</strong> We’re using this judge in production on unlabeled traces which will not have open/axial codes so we don’t want the LLM Judge to learn/expect these codes to be present.</p>
<p><strong>Idea 4: Aim for 80-85% LLM Judge TNR and TPR.</strong> 50% is random chance, 100% probably means something’s wrong in your judge prompt.</p>
<p><strong>Idea 5: The fastest way for you to fail in an AI project is for people to lose trust in what you’re doing.</strong> There’s a human bias that people have in trusting what a computer says. Don’t take the judge at face value. Run some tests to evaluate the confidence interval of the Judge, unbiasing its success rate (bias = Judge labels “Pass” more than “Fail” by default or vice vesa). The eval should align with the product experience.</p>
</section>
<section id="lesson-6-rag-cicd" class="level2">
<h2 class="anchored" data-anchor-id="lesson-6-rag-cicd">Lesson 6: RAG, CI/CD</h2>
<p><strong>Idea 1 Do error analysis on the whole system, but do evals on retrieval and LLM generation separately.</strong> Make sure your retriever’s Recall@k is 80%+, then perform error analysis, otherwise you’re evaluating generation errors based on flawed context. Don’t use popular metrics to evaluate generation—measure what’s relevant to your product, which you will uncover during your analysis.</p>
<p><strong>Idea 2 Bring domain knowledge to chunk size.</strong> Is there a natural breaking point in your document? What is a meaningful chunk in the context of your domain? The chunks ultimately represent the document during search. It’s okay to have variable chunk sizes.</p>
<p><strong>Idea 3 Likert scales have a use!</strong> Shreya asks an LLM to score synthetic queries (when creating an evaluation dataset) on a Likert scale and filters out queries with scores of 1 or 2 (out of 5). These scores are discarded after this filtering use.</p>
<p><strong>Idea 4 Ground synthetic queries in realism:</strong> User queries are often confusing to interpret, incomplete, and contain typos/grammatical errors. The queries in your evaluation dataset should reflect such nuances to provide meaningful use cases for retrieval.</p>
<p><strong>Idea 5 Optimize for Recall@k first.</strong> Shreya has rarely seen utility in optimizing for Precision@k first (how many of the top-k retrieved chunks are relevant?) because the consumer of these chunks in a RAG pipeline is an LLM, which cares more about how many of the total relevant chunks are present in the top-k retrieved chunks (Recall@k) to generate a relevant response. LLMs are getting better at reasoning over the retrieved chunks to determine relevance. Use MRR@k (how high up in the ranking is the first relevant chunk?) after optimizing for Recall@k as MRR@k measures how quickly the LLM finds <em>an</em> answer.</p>
<p><strong>Idea 6: Focus on process, not tools.</strong> Which goes against how most people think about building AI systems. If something’s not working, your first instinct should be to actually understand what is going wrong, not to plug-in a different tool in hopes for improvement, or sweep different hyperparameters. Additionally, don’t get lost in the vector DB sauce—start with basic BM25 keyword search first.</p>
</section>
<section id="lesson-7-evaluating-retrieval-augmented-generation-rag" class="level2">
<h2 class="anchored" data-anchor-id="lesson-7-evaluating-retrieval-augmented-generation-rag">Lesson 7: Evaluating Retrieval-Augmented Generation (RAG)</h2>
<p><strong>Idea 1: Multi-stage retrieval and the Recall/Precision trade-off</strong>. LLMs can handle many passages so we want to make sure it’s provided as many relevant passages as possible, this means increasing the number of passages provided. However, long contexts cost more and are limited by the LLM’s context window. We use a cheaper retriever to do a first pass on retrieving relevant passages (Recall@k) and a more powerful retriever to then re-rank them (Precision@k, MRR or NDCG@k). We take the top-k (where k is smaller than the first pass retrieved passages) and pass that to the LLM.</p>
<blockquote class="blockquote">
<p>Modern LLM attend more strongly to salient tokens, so they can often ignore irrelevant content if the key information is present. But if that information is missing altogether–low recall–then the generator has no way to produce a correct answer.</p>
</blockquote>
<p><strong>Idea 2: The ARES framework complements error analysis.</strong> Precisely evaluating “Answer Faithfulness” (failures include hallucinations, omissions and misinterpretations) and “Answer Relevance” (failure = factually correct based on context but irrelevant to the query) requires error analysis to identify where and how specific failure modes occur in our product.</p>
<p><strong>Idea 3: Be wary of synthentically generated queries</strong> as they often are not representative of the messy queries encountered in production. Regularly validate these queries, referncing real queries from logs or human-curated examples.</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-07-ai-evals/</guid>
  <pubDate>Thu, 07 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Standout Ideas from Lesson 4 and Chapter 5 of the Course Reader from the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-08-03-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-4-automated-evaluators" class="level2">
<h2 class="anchored" data-anchor-id="lesson-4-automated-evaluators">Lesson 4: Automated Evaluators</h2>
<p><strong>Idea 1: You can’t measure what you don’t ask for.</strong> If your prompt didn’t include an instruction on providing links to X, and the LLM doesn’t provide those links, that’s a specification failure (fix the prompt!). If the prompt did include it but the LLM failed to apply the instruction, that’s a generalization failure and should be tracked by an automated evaluator.</p>
<p><strong>Idea 2: Use code-based evaluators if you can,</strong> as they are deterministic. They take as input the trace and a failure mode and return <code>True</code> or <code>False</code> or some score for objective rule-based checks (e.g.&nbsp;parsing structure, regex/string matching for keywords, structural constraints, tool execution errors).</p>
<p><strong>Idea 3: Just because you can ask an LLM Judge anything you want, doesn’t mean you should.</strong> Use LLM Judges to do specific, well-defined, binary failure mode classification (Pass/Fail) tasks. A Pass/Fail LLM Judge score is easier to assess and leads to easy-to-interpret Judge accuracy. Also, don’t pack multiple criteria into one prompt, create a prompt for each criterion.</p>
<p><strong>Idea 4: Don’t leak test instances into your process of building an LLM Judge</strong> Use 10-20% of labeled axial coding data to curate Judge prompt few shot examples (training set), ~40% to iteratively improve the prompt (dev set), and ~40% for final unbiased Judge evalation after prompt tuning is done (test set). The last thing you want in your prompt is a few shot example that’s in the test set. <mark>Low dev set performance (TPR and TNR) tell us that the few shot examples from the train set do not generalize.</mark></p>
<p><strong>Idea 5: Don’t show your LLM Judge what it’s already good at.</strong> Your few shot examples should show difficult/tricky situations for evaluation. To do this, manually iterate the examples. I would imagine that like open coding, you would build a more nuanced intuition about your data (and your product!) through this process. Other tips: write your examples like you are explaining it to a human; try to include the best example of a pass or fail; your examples can also contain reasoning to provide richer “grounding” to your LLM.</p>
</section>
<section id="chapter-5-implementing-automated-evaluators" class="level2">
<h2 class="anchored" data-anchor-id="chapter-5-implementing-automated-evaluators">Chapter 5: Implementing Automated Evaluators</h2>
<p><strong>Idea A: Reference-based and reference-free metrics serve different purposes.</strong> A “reference” here means “reference LLM output”. Reference-based metrics allow iterative development with holistic checks (whether the LLM output match the golden reference). Reference-free metrics better adapt at scale on new, unlabeled data (as they measure intrinsic properties or rules related to failure modes). Reference-based metric: LLM output matches a “golden” trace with a specific sequence of tool calls. Reference-free metric: LLM output contains valid tool call names.</p>
<p><strong>Idea B: Test your judge on unlabeled data.</strong> Even the test set is biased as it represents a portion of our labeled data, which may not be representative of broader out-of-domain situations your Judge will inevitably encounter. We use the Judge’s “raw success rate” (number of Pass labels/number of unlabeled traces) and a series of calculations on random test set samples to estimate within a confidence interval the Judge’s “true success rate.”</p>
<p><strong>Idea C: Judges don’t come pretrained on a product’s values—we have to teach them.</strong> This is why we validate the judge’s response and calculate metrics around alignment (like TNR and TPR). This is also why we provide few shot examples so the Judge can evaluate on the specific desired characteristics of our product (especially for vibe-y dimensions like tone).</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-08-03-ai-evals/</guid>
  <pubDate>Sun, 03 Aug 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TIL: How LLM-Foundry Ignores Prompt Tokens in labels for Instruction Finetuning.</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-31-llm-foundry/</link>
  <description><![CDATA[ 




<p>I recently realized (after a conversation with a colleague) that I didn’t know how LLM-Foundry replaces prompt tokens with <code>-100</code> to exclude them from the loss calculation. I fed Claude project knowledge the LLM-Foundry GitHub repo and asked it to walk me through this process line-by-line. Since “Chat using integrations can’t be shared” I’m pasting Claude’s walkthrough here (with a couple of my notes). All the referenced functions are inside <a href="https://github.com/mosaicml/llm-foundry/blob/main/llmfoundry/data/finetuning/collator.py"><code>llmfoundry/data/finetuning/collator.py</code></a></p>
<section id="setup-input-example" class="level2">
<h2 class="anchored" data-anchor-id="setup-input-example">Setup: Input Example</h2>
<p>Let’s say we have this raw training example:</p>
<pre><code>{
    'prompt': 'What is photosynthesis?',
    'response': 'Photosynthesis is the process by which plants convert sunlight into energy.'
}</code></pre>
<p>After tokenization, this becomes:</p>
<pre><code>example = {
    'turns': [
        {
            'input_ids': [1127, 318, 2825, 43943, 30],      # "What is photosynthesis?"
            'labels': [21197, 43943, 318, 262, 1429, 416, 543, 6134, 10385, 4252, 1657, 656, 2568, 13]  # "Photosynthesis is the process..."
        }
    ]
}</code></pre>
</section>
<section id="line-by-line-processing" class="level2">
<h2 class="anchored" data-anchor-id="line-by-line-processing">Line-by-Line Processing</h2>
<section id="collator-entry-point-seq2seqfinetuningcollator.__call__" class="level3">
<h3 class="anchored" data-anchor-id="collator-entry-point-seq2seqfinetuningcollator.__call__">Collator Entry Point (<code>Seq2SeqFinetuningCollator.__call__</code>)</h3>
<pre><code>def __call__(self, examples: list[TokenizedExample]) -&gt; dict[str, torch.Tensor]:
    # examples is a list of TokenizedExample objects (batch)
    
    if self.decoder_only_format:
        batch = self._process_and_batch_decoder_only(examples)  # Most common path</code></pre>
</section>
<section id="batch-processing-_process_and_batch_decoder_only" class="level3">
<h3 class="anchored" data-anchor-id="batch-processing-_process_and_batch_decoder_only">Batch Processing (<code>_process_and_batch_decoder_only</code>)</h3>
<pre><code>def _process_and_batch_decoder_only(self, examples: list[TokenizedExample]):
    processed_examples = []
    
    # Step 1: Process each example in the batch through stitch_turns_decoder_only
    input_ids_and_labels = [
        stitch_turns_decoder_only(
            example_turns=example['turns'],           # The prompt/response turns
            target_prompts=self.target_prompts,      # 'none' 
            target_responses=self.target_responses,   # 'last'
            eos_token_id=self.tokenizer.eos_token_id,
        ) for example in examples
    ]</code></pre>
</section>
<section id="core-processing-stitch_turns_decoder_only" class="level3">
<h3 class="anchored" data-anchor-id="core-processing-stitch_turns_decoder_only">Core Processing (<code>stitch_turns_decoder_only</code>)</h3>
<p>This is where the magic happens:</p>
<pre><code>def stitch_turns_decoder_only(example_turns, target_prompts, target_responses, eos_token_id):
    target_prompts = target_prompts.lower()  # 'none'
    target_responses = target_responses.lower()  # 'last'
    
    # Line 1: Look up the target policy functions
    prompt_to_target = _TARGET_POLICY_LOOKUP[target_prompts]  # Gets _sequence_to_labels_none
    response_to_target = _TARGET_POLICY_LOOKUP[target_responses]  # Gets _sequence_to_labels_last
    
    # Line 2: Initialize output sequences
    input_ids = []
    labels = []
    
    # Line 3: Process each turn in the conversation
    for idx, turn in enumerate(example_turns):
        is_last_turn = idx + 1 == len(example_turns)  # True for our single-turn example
        
        # Line 4: Extract the prompt and response token sequences
        context = ensure_list(turn['input_ids'])   # [1127, 318, 2825, 43943, 30] - "What is photosynthesis?"  
        target = ensure_list(turn['labels'])       # [21197, 43943, 318, ...] - "Photosynthesis is..."
        
        # Line 5: Add EOS token to final response if needed
        if is_last_turn and eos_token_id is not None:
            if target[-1] != eos_token_id:
                target = target + [eos_token_id]   # Append &lt;|endoftext|&gt; token
        
        # Line 6: Build the concatenated input_ids sequence
        input_ids += context  # Add prompt tokens: [1127, 318, 2825, 43943, 30]
        input_ids += target   # Add response tokens: [1127, 318, 2825, 43943, 30, 21197, 43943, 318, ...]
        
        # Line 7: Build the labels sequence using target policies
        labels += prompt_to_target(context, is_last_turn, prompt_cutoff)  # Calls _sequence_to_labels_none
        labels += response_to_target(target, is_last_turn)                # Calls _sequence_to_labels_last</code></pre>
<blockquote class="blockquote">
<p>Vishal note: in Line 7, <code>labels</code> starts out as an empty list <code>[]</code> so the prompt is added first (via <code>+= prompt_to_target(...)</code>), after which the response is added (via <code>+= response_to_target</code>).</p>
</blockquote>
</section>
<section id="target-policy-functions" class="level3">
<h3 class="anchored" data-anchor-id="target-policy-functions">Target Policy Functions</h3>
<pre><code>def _sequence_to_labels_none(sequence, is_last_turn, cutoff):
    # Line 1: Convert ALL prompt tokens to -100 (ignore during loss)
    return [CROSS_ENTROPY_IGNORE_INDEX] * len(sequence)  # [-100, -100, -100, -100, -100]

def _sequence_to_labels_last(sequence, is_last_turn, cutoff):  
    # Line 1: Check if this is the final turn
    if is_last_turn:  # True in our case
        return sequence  # Keep actual token IDs: [21197, 43943, 318, ...]
    else:
        return [CROSS_ENTROPY_IGNORE_INDEX] * len(sequence)  # Would be [-100, -100, ...] for non-final turns</code></pre>
</section>
<section id="result-after-stitch_turns_decoder_only" class="level3">
<h3 class="anchored" data-anchor-id="result-after-stitch_turns_decoder_only">Result After <code>stitch_turns_decoder_only</code></h3>
<pre><code># Returned values:
input_ids = [1127, 318, 2825, 43943, 30, 21197, 43943, 318, 262, 1429, 416, 543, 6134, 10385, 4252, 1657, 656, 2568, 13, 50256]
#            |----------prompt----------|  |-------------------response---------------------------|  |EOS|

labels =    [-100, -100, -100, -100, -100, 21197, 43943, 318, 262, 1429, 416, 543, 6134, 10385, 4252, 1657, 656, 2568, 13, 50256]
#            |------ignore prompt-------|  |-------------------keep response--------------------|  |EOS|</code></pre>
<blockquote class="blockquote">
<p>Vishal note: we added <code>prompt_to_target</code> first to the empty <code>labels</code> list so the <code>-100</code>s come first.</p>
</blockquote>
</section>
<section id="back-to-batch-processing-continued" class="level3">
<h3 class="anchored" data-anchor-id="back-to-batch-processing-continued">Back to Batch Processing (continued)</h3>
<pre><code># Step 2: Handle sequence length limits
for input_ids, labels in input_ids_and_labels:
    orig_size = len(input_ids)
    
    # Truncate if too long
    if orig_size &gt; max_seq_len:
        input_ids = input_ids[:max_seq_len]
        labels = labels[:max_seq_len]
    
    # Create attention mask
    attention_mask = [1] * len(input_ids)  # All 1s for actual tokens
    
    # Step 3: Pad sequences to max_seq_len
    n_total = len(input_ids)
    i_pad = [CROSS_ENTROPY_IGNORE_INDEX] * (max_seq_len - n_total)  # Padding with -100
    
    if self.tokenizer.padding_side == 'left':
        labels = i_pad + labels  # Left pad labels with -100
    else:
        labels = labels + i_pad  # Right pad labels with -100 (more common)
    
    processed_example = {
        'input_ids': input_ids,      # Will be padded by tokenizer.pad()
        'labels': labels,            # Already padded with -100
        'attention_mask': attention_mask,  # Will be padded by tokenizer.pad()
    }
    processed_examples.append(processed_example)

# Step 4: Final padding using HuggingFace tokenizer
batch = self.tokenizer.pad(
    processed_examples,
    padding='max_length',
    max_length=max_seq_len,
    return_tensors='pt',
)</code></pre>
</section>
<section id="final-batch-output" class="level3">
<h3 class="anchored" data-anchor-id="final-batch-output">Final Batch Output</h3>
<pre><code>batch = {
    'input_ids': torch.tensor([
        [1127, 318, 2825, 43943, 30, 21197, 43943, 318, ..., 0, 0, 0]  # Padded with pad_token_id (0)
    ]),
    'labels': torch.tensor([
        [-100, -100, -100, -100, -100, 21197, 43943, 318, ..., -100, -100, -100]  # Padded with -100
    ]),
    'attention_mask': torch.tensor([
        [1, 1, 1, 1, 1, 1, 1, 1, ..., 0, 0, 0]  # 1 for real tokens, 0 for padding
    ])
}</code></pre>
</section>
<section id="key-points" class="level3">
<h3 class="anchored" data-anchor-id="key-points">Key Points</h3>
<ol type="1">
<li>Prompt tokens → Labels = -100: The _sequence_to_labels_none function converts all prompt tokens to -100</li>
<li>Response tokens → Labels = actual token IDs: The _sequence_to_labels_last function keeps response tokens as-is</li>
<li>Padding tokens → Labels = -100: All padding positions also get -100</li>
<li>Loss calculation: PyTorch’s CrossEntropyLoss(ignore_index=-100) will only compute loss on response tokens</li>
</ol>
<p>This ensures the model learns to generate responses but never tries to “predict” the input prompt!</p>


</section>
</section>

 ]]></description>
  <category>LLM-Foundry</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-31-llm-foundry/</guid>
  <pubDate>Thu, 31 Jul 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Standout Ideas from Lesson 3 and Chapter 4 of the Course Reader from the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-31-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-3-error-analysis-contd." class="level2">
<h2 class="anchored" data-anchor-id="lesson-3-error-analysis-contd.">Lesson 3: Error Analysis (cont’d.)</h2>
<p><strong>Idea 1: Open code at the trace-level</strong>. Many errors only emerge in the context of the whole trace and mistakes often cascade across turns (i.e.&nbsp;label only the <em>first</em> failure).</p>
<p><strong>Idea 2: Manually classify open codes using AI-generated axial codes.</strong> This verifies whether the AI-generated codes are applicable (accurate and relevant). During the lesson ChatGPT missed “Did not invoke tool” in its initial axial code generation based on open codes. This type of mistake is common and is why we manually apply LLM-generated axial codes.</p>
<p><strong>Idea 3: If possible, reproduce a multi-turn error with a simpler single-turn test case</strong>. For example if a multi-turn conversation fails when the LLM tries to retrieve some information, (e.g.&nbsp;return the correct price for product X), create a new single-turn conversation targeting just that task. This “minimal reproducible error” is analogous to software engineering’s “minimal reproducible bug”. In both cases, you’re cutting through the noise and targeting the single task that fails; this help find the root cause.</p>
</section>
<section id="chapter-4-collaborative-evaluation-practices" class="level2">
<h2 class="anchored" data-anchor-id="chapter-4-collaborative-evaluation-practices">Chapter 4: Collaborative Evaluation Practices</h2>
<p><strong>Idea A: When possible, have only one person make the final judgment call on AI evaluation</strong>. You want a single person making decisions about the success or failure of the AI outputs to reduce noisy cooks in the kitchen. You need that person to have deep domain knowledge or be someone who represents the target users. Hamel and Shreya call this person the Principal Domain Expert.</p>
<p><strong>Idea B: Annotator disagreements inform rubric improvements, not retroactive label updates</strong>. You’re not trying to win an argument. This idea reminds me of being on an interview panel: when you discuss rubric scores with the highest disagreement, the goal is not for panelists to change their scores, the goal is to come to a common understanding of what rubric item was measuring, and if needed, update your understanding to reach concensus for future candidate assessments. If your process is flawed, try to correct it as soon as you can.</p>
<p><strong>Idea C: Battle-test your artifacts manually</strong>. The iteratively improved human annotator rubric and the concensus labeled dataset becomes the gold standard used for automated evaluators. The rubric becomes the specification passed to the LLM-Judge. A recurring theme in this course: don’t build something in the abstract, build it while grounded in real data. Just as we don’t predefine axial codes for failure modes before we look at the data and document open codes, we don’t predefine a rubric for the LLM Judge before we look at the data. There’s a feedback loop between error analysis artifacts (open codes, axial codes, annotator rubrics, annotation scores) and looking at your data. Looking at data builds your intuition which then informs the error analysis artifacts.</p>
<p><strong>Idea D: Even with multiple annotators, there’s an escalation path.</strong> A benevolent dictator may need to intervene and make the final call if the annotators can’t come to concensus. This underscores the importance of identifying a single Principal Domain Expert <em>even during collaborative evaluation</em>.</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-31-ai-evals/</guid>
  <pubDate>Thu, 31 Jul 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Standout Ideas from Lesson 2 of the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-28-ai-evals/</link>
  <description><![CDATA[ 




<section id="lesson-2-error-analysis" class="level2">
<h2 class="anchored" data-anchor-id="lesson-2-error-analysis">Lesson 2: Error Analysis</h2>
<p><strong>Idea 1: Error analysis is how we close the gulf of comprehension.</strong> The gulf of comprehension is the gap between the information the data contains and your understanding of it. While it’s either impossible or unreasonable to look at every single piece of data collected from your users, Hamel and Shreya recommend looking at at least 100 traces.</p>
<p><strong>Idea 2: You need ~100 diverse traces to get a good representation of failure modes.</strong> A trace is a full record of the pipeline’s interaction (initil user query, all LLM inputs/outs, intermediate reasoning or tool calls, and final user-facing result). The number 100 is not a hard and fast rule, but signifies that 10-15 traces is not going to be enough. You want to look at enough traces such that you reach a theoretical saturation of failure modes. What that means is you’ve seen enough traces that are diverse enough that looking at any more traces will not introduce any new failure modes that you haven’t seen yet.</p>
<p><strong>Idea 3: Open coding is Hamel’s favorite subject in evals.</strong> Open codes are brief, descriptive notes about any observed problems, surprising actions or where behavior feels wrong or unexpected in the trace. As you write open codes, categories of errors will emerge.</p>
<p><strong>Idea 4: During open coding, don’t find the root cause, just observe and note.</strong> As you come across failed traces, it’s tempting to make note of why you think this failure occurred. For example, if you see that the LLM tool call return value did not contain the correct information, it’s tempting to step back and think about why that took place. Maybe the input to the tool was incorrect because your voice agent converted speech to text incorrectly. Maybe there’s something wrong in the database which resulted in leading to missed matches. As you can see, this type of pontification can potentially be endless and is not fruitful for the focused process of identifying failure modes. Just note the failure and move on to the next trace. We’ll think about root causes later.</p>
<p><strong>Idea 5: Pull the main failure mode from each trace. don’t get embroiled in the details.</strong> Relatedly, it’s tempting to zoom in as deep as you can, putting each word of the trace under a microscope. For folks who like analyzing data, this is satisfying. But it introduces noise in identifying high-priority failure modes. These open codes are later going to be clustered by theme (Axial Coding) and higher-level themes will be extracted; too granular of an analysis is a waste of time.</p>
<p><strong>Idea 6: The quality of open coding is going to hinge on your product sense.</strong> Successful open coding depends on your ability to skillfully look at data. This involves two broad skills: 1) you have to know what to look for, 2) you have to be detail-oriented enough to find the failure by looking at a sequence of messages. Knowing what to look for requires a deep understanding of your product from the user’s perspective.</p>
<p><strong>Idea 7: Start with a simple approach to get value fast.</strong> Fatigue from cognitive load is a real thing, especially when you’re looking at a hundred traces, many of which can involve multiple messages between the user and the assistant and multiple tool calls. The success of error analysis is going to depend on how fresh your mind is during the process. To achieve this, keep your open coding and axial coding heuristics simple. You can always do a second, third, and fourth pass through future traces after you fix the most pressing failure modes.</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-28-ai-evals/</guid>
  <pubDate>Mon, 28 Jul 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Analyzing PyTorch 2.0 Release Notes for ColBERT Dependency Impact</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-27-torch-colbert/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post, I walk through the <a href="https://github.com/pytorch/pytorch/releases/tag/v2.0.0">PyTorch 2.0 Release Note</a> PRs where I’m estimating there will be some kind of impact to ColBERT as I update the torch dependency to 2.0 (ColBERT is currently dependent on torch==1.13.1). The level of detail in my analysis of a PyTorch PR is not necessarily signifying its importance. In some cases, I am using this analysis as an opportunity to get more familiar with details about the ColBERT codebase (such as the number of instances where <code>torch.cat</code> is used).</p>
</section>
<section id="full-release-notes-analysis" class="level2">
<h2 class="anchored" data-anchor-id="full-release-notes-analysis">Full Release Notes Analysis</h2>
<p>You can find my item-by-item PyTorch 2.0 release notes analysis for ColBERT in <a href="https://docs.google.com/spreadsheets/d/1sUEN7xo5-hLVoxF9NL_ibGxPaKlPzxmnMU46zf3wd-U/edit?usp=sharing">this Google Sheet</a>.</p>
<p>Overall, across 508 PyTorch PRs, I have estimated that 455 of them are not applicable to ColBERT and 42 (8.7%) have a potential impact. I was unclear if or how 11 of the PyTorch 2.0 PRs would affect ColBERT (2.6%).</p>
<p>There are 5 sections in the PyTorch 2.0 Release Notes, here’s a break down of PRs by section that will have a potential (or unclear) impact on ColBERT:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Section</th>
<th style="text-align: center;"># of PRs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Improvements</td>
<td style="text-align: center;">22</td>
</tr>
<tr class="even">
<td style="text-align: center;">Bug Fixes</td>
<td style="text-align: center;">21</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Performance</td>
<td style="text-align: center;">6</td>
</tr>
<tr class="even">
<td style="text-align: center;">Backwards Incompatible Changes</td>
<td style="text-align: center;">3</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Deprecations</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>In my estimation, the improvements and bug fixes PRs in PyTorch 2.0 will only improve the performance of ColBERT. That being said, there still may be noticeable differences in indexing, search, and training artifacts which may break tests I write for before/after comparisons.</p>
<p>Fortunately, only two backward-compatible changes may affect ColBERT.</p>
<p>There are 11 subsections in the PyTorch 2.0 Release Notes, here’s a break down of PRs that will have a potential (or unclear) impact on ColBERT:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Subsection</th>
<th style="text-align: center;"># of PRs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">MPS</td>
<td style="text-align: center;">12</td>
</tr>
<tr class="even">
<td style="text-align: center;">Python API</td>
<td style="text-align: center;">8</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Cuda</td>
<td style="text-align: center;">8</td>
</tr>
<tr class="even">
<td style="text-align: center;">Releng</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Distributed</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;">Build</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ONNX</td>
<td style="text-align: center;">3</td>
</tr>
<tr class="even">
<td style="text-align: center;">Cpu</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Cpp API</td>
<td style="text-align: center;">2</td>
</tr>
<tr class="even">
<td style="text-align: center;">torch.nn API</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>I am including MPS-related PRs in this analysis just in case we consider making ColBERT compatible with MPS in the future.</p>
<p>I’ll start by analyzing breaking changes, which are likely going to be the most impactful.</p>
</section>
<section id="backwards-incompatible-changes" class="level2">
<h2 class="anchored" data-anchor-id="backwards-incompatible-changes">Backwards Incompatible Changes</h2>
<section id="pr-92731" class="level3">
<h3 class="anchored" data-anchor-id="pr-92731">PR <a href="https://github.com/pytorch/pytorch/pull/92731">#92731</a></h3>
<blockquote class="blockquote">
<p>Gradients are now set to None instead of zeros by default in <code>torch.optim.*.zero_grad()</code> and <code>torch.nn.Module.zero_grad()</code> (#92731)</p>
</blockquote>
<p>There are two lines in ColBERT where<code>zero_grad</code> is called: in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/amp.py#L37">colbert/utils/amp.py</a> and in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/training/training.py#L61">colbert/training/training.py</a>. I’m not sure how this change would affect ColBERT behavior, but flagging it as something to keep in mind.</p>
</section>
<section id="pr-92306" class="level3">
<h3 class="anchored" data-anchor-id="pr-92306">PR <a href="https://github.com/pytorch/pytorch/pull/92306">#92306</a></h3>
<blockquote class="blockquote">
<p>Algorithms <code>{Adadelta, Adagrad, Adam, Adamax, AdamW, ASGD, NAdam, RAdam, RMSProp, RProp, SGD}</code> default to faster <code>foreach</code> implementation when on CUDA + differentiable=<code>False</code></p>
</blockquote>
<p>This PR adds the following lines to <code>AdamW</code>, which is used in ColBERT’s <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/training/training.py#L60">`training.py</a>:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> foreach <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb1-2">    foreach <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _default_to_foreach(</span>
<span id="cb1-3">        [params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps],</span>
<span id="cb1-4">        differentiable<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>differentiable)</span></code></pre></div>
<p><code>foreach</code> is <code>None</code> in ColBERT, as it’s not specified and that’s what it defaults to (<code>foreach: Optional[bool] = None</code>):</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">optimizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AdamW(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">filter</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> p: p.requires_grad, colbert.parameters()), lr<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config.lr, eps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-8</span>)</span></code></pre></div>
<p>Since this is described as a “faster implementation”, I would expect the training time to decrease. <mark>I’ll be on the lookout for this when comparing training time benchmarks before/after upgrading to PyTorch 2.0</mark>.</p>
</section>
<section id="pr-88913" class="level3">
<h3 class="anchored" data-anchor-id="pr-88913">PR <a href="https://github.com/pytorch/pytorch/pull/88913">#88913</a></h3>
<blockquote class="blockquote">
<p>Update <code>torch.tensor</code> and <code>nn.Parameter</code> to serialize all their attributes (#88913)</p>
</blockquote>
<p><mark>It’s unclear what this PR is doing but since it’s touching the <code>nn.Parameter</code> definition, I’m flagging it.</mark></p>
</section>
</section>
<section id="bug-fixes" class="level2">
<h2 class="anchored" data-anchor-id="bug-fixes">Bug Fixes</h2>
<p>I would expect PyTorch PRs that introduce bug fixes to only positively affect ColBERT. That being said, a positive effect is still a change and can potentially impact concrete artifacts during indexing, search and training. I am planning on curating a baseline set of these artifacts before I test the upgrade to PyTorch 2.0.</p>
<section id="pr-92810" class="level3">
<h3 class="anchored" data-anchor-id="pr-92810">PR <a href="https://github.com/pytorch/pytorch/pull/92810">#92810</a></h3>
<blockquote class="blockquote">
<p>Fix SIGSEGV on a big-endian machine when reading pickle data (#92810)</p>
</blockquote>
<p>The PR states:</p>
<blockquote class="blockquote">
<p>This PR fixes SIGSEGV on a big-endian machine when reading pickle data.</p>
</blockquote>
<p>I’m not familiar with the term “big-endian” so had to look it up:</p>
<blockquote class="blockquote">
<p>A big-endian system stores the most significant byte of a word at the smallest memory address and the least significant byte at the largest. A little-endian system, in contrast, stores the least-significant byte at the smallest address. (<a href="https://en.wikipedia.org/wiki/Endianness">source</a>)</p>
</blockquote>
<p>Claude’s understanding of the cpp method affected by this PR is that it affects the <code>torch.load</code> method. There are a number of ColBERT files that use <code>torch.load</code>:</p>
<ul>
<li>colbert/utils/coalesce.py uses it to <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/coalesce.py#L47">load <code>codes.pt</code></a> (centroid id for each embedding in chunk) and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/coalesce.py#L66">load <code>residuals.pt</code></a> (16-bits residual for each embedding in chunk).</li>
<li>colbert/search/index_loader.py uses it to <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_loader.py#L33">load <code>ivf.pid.pt</code></a> or <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_loader.py#L36"><code>ivf.pt</code></a>.</li>
<li>colbert/utils/utils.py uses it <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/utils.py#L44">in <code>torch_load_dnn</code></a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/utils.py#L91"><code>load_checkpoint_raw</code></a> and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/utils.py#L205"><code>load_ranking</code></a>.</li>
<li>colbert/indexing/index_manager.py uses it in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/index_manager.py#L20"><code>load_index_part</code></a>.</li>
<li>colbert/indexing/codecs/residual_embeddings.py uses it in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual_embeddings.py#L86"><code>load_codes</code></a> and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual_embeddings.py#L93"><code>load_residuals</code></a>.</li>
<li>colbert/indexing/codecs/residual.py uses it in <code>load</code> to load <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L141">centroids</a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L142"><code>avg_residual</code></a>, and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L143"><code>bucket_cutoffs, bucket_weights</code></a>.</li>
<li>colbert/indexing/collection_indexer.py uses it in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/collection_indexer.py#L256"><code>_concatenate_and_split_sample</code></a>.</li>
<li>colbert/index_updater.py uses it in <code>_load_disk_ivf</code> to load <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L281"><code>ivf.pid.pt</code></a> or <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L286"><code>ivf.pt</code></a>, in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L312"><code>load_chunk_codes</code></a>, and in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L316"><code>_load_chunk_residuals</code></a>.</li>
<li>colbert/tests/index_coalesce_test.py uses it to load <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/tests/index_coalesce_test.py#L57">multi-file <code>codes.pt</code></a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/tests/index_coalesce_test.py#L66">single-file <code>codes.pt</code></a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/tests/index_coalesce_test.py#L83">multi-file <code>residuals.pt</code></a> and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/tests/index_coalesce_test.py#L92">single-file <code>residuals.pt</code></a>.</li>
</ul>
</section>
<section id="pr-92315" class="level3">
<h3 class="anchored" data-anchor-id="pr-92315">PR <a href="https://github.com/pytorch/pytorch/pull/92315">#92315</a></h3>
<blockquote class="blockquote">
<p>Fix NVML visible device parsing (#92315)</p>
</blockquote>
<blockquote class="blockquote">
<p>CUDA_VISIBLE_DEVICES can contain either ordinals or UUIDs Extend the logic to be able to parse it by UUID</p>
</blockquote>
<p><mark>I don’t think this would affect any artifacts created during indexing/searching/training but would make it easier for PyTorch to identify GPUs.</mark></p>
</section>
<section id="pr-93095" class="level3">
<h3 class="anchored" data-anchor-id="pr-93095">PR <a href="https://github.com/pytorch/pytorch/pull/93095">#93095</a></h3>
<p>This PR fixes an error in <a href="https://github.com/pytorch/pytorch/issues/93006">#93006</a> when using <code>topk</code>, which is used in the following places in ColBERT:</p>
<ul>
<li><code>get_cells</code> in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/candidate_generation.py#L17">colbert/search/candidate_generation.py</a></li>
<li><code>score_pids</code> in colbert/search/index_storage.py to <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L127">filter centroids by the threshold</a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L152">filter <code>pids</code> using pruned centroid scores</a> and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L161">filter <code>pids</code> using full centroid scores</a></li>
<li>filter scores in <code>colbert_score_reduce</code> for the <code>"flipr"</code> interaction method: <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L146">link1</a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L150">link 2</a></li>
</ul>
<p>Claude recommended also consider uses of <code>max</code> and <code>argmax</code> to be potentially impacted:</p>
<ul>
<li><code>get_cells</code> if <code>ncells==1</code> in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/candidate_generation.py#L15">colbert/search/candidate_generation.py</a></li>
<li>colbert/modeling/colbert.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L121"><code>ColBERT.score</code></a></li>
<li>colbert/modeling/colbert.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L135"><code>colbert_score_reduce</code></a></li>
<li>colbert/indexing/codecs/residual.py in <code>ResidualCodec.compress_into_codes</code> on <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L215">GPU</a> and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L217">CPU</a></li>
<li>colbert/search/strided_tensor.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor.py#L74">`StridedTensor.lookup</a></li>
<li>colbert/search/strided_tensor_core.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor_core.py#L27"><code>StridedTensorCore.__init__</code></a></li>
<li>colbert/modeling/checkpoint.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L215">`Checkpoint.score</a></li>
<li>colbert/indexing/utils.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/utils.py#L48"><code>optimize_ivf</code></a></li>
</ul>
<p><mark>I would assume that the only impact this PR would have on PyTorch is avoiding any errors during the use of <code>topk</code> (no such errors have been reported on in the open issues).</mark></p>
</section>
<section id="pr-85596" class="level3">
<h3 class="anchored" data-anchor-id="pr-85596">PR <a href="https://github.com/pytorch/pytorch/pull/85596">#85596</a></h3>
<blockquote class="blockquote">
<p>Fix: half reduction with multiple sub-iterators (#85596)</p>
</blockquote>
<p>Fixes <a href="https://github.com/pytorch/pytorch/issues/74438">cuda low-precision reductions on large tensors produce wrong results #74438</a>:</p>
<blockquote class="blockquote">
<p>Reductions with low precision inputs (half, bfloat16) that need sub-iterators accumulate directly in output and thus truncate intermediate results</p>
</blockquote>
<p>This would fix any issues related to the use of <code>half</code> in the following ColBERT files:</p>
<ul>
<li>in <code>ResidualCodec</code> for <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L27"><code>centroids</code></a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L35"><code>avg_residual</code></a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L40"><code>bucket_weights</code></a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L159">saving <code>centroids</code></a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L172">compressing token embeddings</a>, calculating cosine similarity between token embeddings and centroids <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L215">on GPU</a>.</li>
<li>colbert/search/candidate_generation.py in <code>CandidateGeneration.generate_candidates</code> for queries when <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/candidate_generation.py#L52">using the GPU</a>.</li>
<li>colbert/indexing/collection_indexer.py in <code>CollectionIndexer._sample_embeddings</code> when <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/collection_indexer.py#L181">saving <code>local_sample_embs</code></a>, in <code>CollectionIndexer.train_kmeans</code> for <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/collection_indexer.py#L308">centroids on the GPU</a>, and in <code>CollectionIndexer.index</code> when <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/collection_indexer.py#L370">saving token embeddings</a>.</li>
<li>colbert/modeling/colbert.py in <code>ColBERT.doc</code> for <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L106">document token embeddings on the GPU</a></li>
</ul>
<p><mark>If this PR fix is relevant to the use of <code>half</code> in the above files I would expect there to be numeric differences in indexing/search artifacts</mark>.</p>
</section>
<section id="pr-86492" class="level3">
<h3 class="anchored" data-anchor-id="pr-86492">PR <a href="https://github.com/pytorch/pytorch/pull/86492">#86492</a></h3>
<blockquote class="blockquote">
<p>Fixes a memory leak by making autocast cache global instead of thread-local (#86492)</p>
</blockquote>
<p>This PR adds a PyTorch test which:</p>
<blockquote class="blockquote">
<p>Verifies that the autocast cache is global. This is done by mocking out cache clearing at the end of the forward pass, running forward+backward with an explicit call to autocast in the backward, and verifying that the weight only get cast to float16 once.</p>
</blockquote>
<p>Claude’s analysis:</p>
<blockquote class="blockquote">
<p>This PyTorch enhancement directly benefits ColBERT. By making the autocast cache global, this PR provides a performance improvement when training ColBERT with mixed precision. It reduces redundant computations during the backward pass, leading to faster and more efficient training without changing the model’s functionality.</p>
</blockquote>
<p>ColBERT uses <code>torch.cuda.amp.autocast</code> in the following files:</p>
<ul>
<li>colbert/utils/amp.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/amp.py#L15"><code>MixedPrecisionManager.context</code></a> which is used in colbert/training/training.py during <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/training/training.py#L96"><code>train</code></a>, and in colbert/modeling/checkpoint.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L87"><code>Checkpoint.query</code></a> and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L93"><code>Checkpoint.doc</code></a> to calculate query and document token embeddings, respectively.</li>
<li>colbert/distillation/scorer in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/distillation/scorer.py#L48"><code>Scorer._score_pairs</code></a>.</li>
</ul>
</section>
<section id="pr-88898" class="level3">
<h3 class="anchored" data-anchor-id="pr-88898">PR <a href="https://github.com/pytorch/pytorch/pull/88898">#88898</a></h3>
<p>Fixes PyTorch <a href="https://github.com/pytorch/pytorch/issues/88873">#88873</a>:</p>
<blockquote class="blockquote">
<p>torch_extension.py should be fixed or ninja compile will fail.</p>
</blockquote>
<p>Gemini’s analysis: Because ColBERT uses the very feature this PR is fixing (torch.utils.cpp_extension.py), the change is directly relevant. This bug fix is important for any developer or user who needs to compile and run ColBERT on a Windows machine. It ensures that ColBERT’s performance-critical custom CUDA code can be built correctly, preventing potential compilation errors.</p>
<p>ColBERT uses <code>torch.utils.cpp_extension</code> in the following files:</p>
<ul>
<li>colbert/modeling/colbert.py in <code>ColBERT.try_load_torch_extensions</code> to <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L12">load <code>segmented_lookup.cpp</code></a> on CPU.</li>
<li>colbert/search/index_storage.py in <code>IndexScorer.try_load_torch_extensions</code> to load <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L38">filter_pids.cpp</a> and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L51">decompress_residuals.cpp</a>.</li>
<li>colbert/search/strided_tensor.py in <code>StridedTensor.try_load_torch_extensions</code> to <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor.py#L26">load <code>segmented_lookup.cpp</code></a> on CPU.</li>
<li>colbert/indexing/codecs/residual.py in <code>ResidualCode.try_load_torch_extensions</code> to load <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L103">decompress_residuals.cpp</a></li>
</ul>
<p><mark>This might be related to ColBERT <a href="https://github.com/stanford-futuredata/ColBERT/issues/371">#317</a></mark></p>
</section>
<section id="pr-90149" class="level3">
<h3 class="anchored" data-anchor-id="pr-90149">PR <a href="https://github.com/pytorch/pytorch/pull/90149">#90149</a></h3>
<blockquote class="blockquote">
<p>Fix a static initialization order fiasco in c10d (#90149)</p>
</blockquote>
<p>Gemini’s analysis: Because ColBERT’s multi-GPU functionality is built directly on the PyTorch library that this PR is fixing, this change is highly relevant. This is a crucial stability improvement that makes ColBERT’s distributed training and inference more reliable by preventing potential crashes at startup.</p>
<p><mark>If Gemini’s analysis is correct, this will make ColBERT’s multi-GPU functionality more reliable and might address related open issues.</mark></p>
</section>
<section id="prs-86956-86958" class="level3">
<h3 class="anchored" data-anchor-id="prs-86956-86958">PRs <a href="https://github.com/pytorch/pytorch/pull/86956">#86956</a>, <a href="https://github.com/pytorch/pytorch/pull/86958">#86958</a></h3>
<blockquote class="blockquote">
<p>Fix issues with non-contiguous Tensor handling (#86956, #86958)</p>
</blockquote>
<p><mark>These are both MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS</mark></p>
</section>
<section id="prs-94119-86240-91520-94442-94386" class="level3">
<h3 class="anchored" data-anchor-id="prs-94119-86240-91520-94442-94386">PRs <a href="https://github.com/pytorch/pytorch/pull/94119">#94119</a>, <a href="https://github.com/pytorch/pytorch/pull/86240">#86240</a>, <a href="https://github.com/pytorch/pytorch/pull/91520">#91520</a>, <a href="https://github.com/pytorch/pytorch/pull/94442">#94442</a>, <a href="https://github.com/pytorch/pytorch/pull/94386">#94386</a></h3>
<blockquote class="blockquote">
<p>Fix issues with ops implementation torch.median (#90326, #88807), torch.{std,var} correction argument (#91203), torch.index_select (#94117, #91064), torch.cumsum (#94119), torch.where (#86240), torch.nn.Embedding (#82809), torch.nn.Softplus (#88555), torch.nn.functional.pad (#89864), torch.max (#91520), padding functions (#91522), torch.nn.functional.upsample (#91669), pooling functions (#91519, #94348), torch.nn.{NLLLoss,SmoothL1Loss} (#94226), torch.nn.SoftPlus (#94256), torch.masked_fill (#94263), torch.fill_ (#94479), torch.median (#94489), torch.nonzero (#94442), torch.nn.BatchNorm (#94351), torch.{min,max} (#94386), torch.nn.GELU (#94529), torch.nn.LSTM (#94889), #95137),torch.nn.Conv2d(#95078),torch.nn.functional.bilinear(#94892),torch.copy_ (#95272),torch.max_pool2d(#94963),torch.div (#95769)</p>
</blockquote>
<p>ColBERT uses topk in the following files:</p>
<ul>
<li><code>get_cells</code> in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/candidate_generation.py#L17">colbert/search/candidate_generation.py</a></li>
<li><code>score_pids</code> in colbert/search/index_storage.py to <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L127">filter centroids by the threshold</a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L152">filter <code>pids</code> using pruned centroid scores</a> and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L161">filter <code>pids</code> using full centroid scores</a></li>
<li>filter scores in <code>colbert_score_reduce</code> for the <code>"flipr"</code> interaction method: <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L146">link1</a>, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L150">link 2</a></li>
</ul>
<p>ColBERT uses max/argmax in the following files:</p>
<ul>
<li><code>get_cells</code> if <code>ncells==1</code> in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/candidate_generation.py#L15">colbert/search/candidate_generation.py</a></li>
<li>colbert/modeling/colbert.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L121"><code>ColBERT.score</code></a></li>
<li>colbert/modeling/colbert.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L135"><code>colbert_score_reduce</code></a></li>
<li>colbert/indexing/codecs/residual.py in <code>ResidualCodec.compress_into_codes</code> on <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L215">GPU</a> and <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L217">CPU</a></li>
<li>colbert/search/strided_tensor.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor.py#L74">`StridedTensor.lookup</a></li>
<li>colbert/search/strided_tensor_core.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor_core.py#L27"><code>StridedTensorCore.__init__</code></a></li>
<li>colbert/modeling/checkpoint.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L215">`Checkpoint.score</a></li>
<li>colbert/indexing/utils.py in <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/utils.py#L48"><code>optimize_ivf</code></a></li>
</ul>
<p>ColBERT uses <code>torch.cumsum</code> in the following files to calculate <code>offsets</code>.:</p>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/utils.py#L50">colbert/indexing/utils.py</a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor_core.py#L31">colbert/search/strided_tensor_core.py</a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor.py#L48">colbert/search/strided_tensor.py</a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L68">colbert/search/index_storage.py</a></li>
</ul>
<p>ColBERT uses <code>torch.where</code> in the following files:</p>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L49">colbert/modeling/checkpoint.py</a> to pool embeddings within each cluster.</li>
</ul>
<p>ColBERT uses <code>torch.nonzero</code> in the following files:</p>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L351">colbert/index_updater.py</a> to construct mask of where pids to be removed appear in ivf.</li>
</ul>
<p><mark>These are all MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="prs-91120-94464" class="level3">
<h3 class="anchored" data-anchor-id="prs-91120-94464">PRs <a href="https://github.com/pytorch/pytorch/pull/91120">#91120</a>, <a href="https://github.com/pytorch/pytorch/pull/94464">#94464</a></h3>
<blockquote class="blockquote">
<p>Fix issues with torch.bool for Unary ops (#91120), scatter ops (#94464)</p>
</blockquote>
<p>Claude’s analysis: Claude: The PR fixes compatibility issues where boolean tensors needed to be cast to int8 on older macOS versions, then cast back. This would be important for ColBERT’s masking operations which rely heavily on boolean tensors for attention and padding masks.</p>
<p><mark>These are MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="pr-94484" class="level3">
<h3 class="anchored" data-anchor-id="pr-94484">PR <a href="https://github.com/pytorch/pytorch/pull/94484">#94484</a></h3>
<blockquote class="blockquote">
<p>Properly cast torch.int64 to torch.int32 for reduction ops and raise warning. (#94484)</p>
</blockquote>
<p>Claude’s analysiss: The PR changes TORCH_CHECK (which throws an error) to TORCH_WARN_ONCE (which just warns) and automatically casts int64 to int32 for min/max operations. This would allow ColBERT to run on MPS with int64 tensors instead of failing, though with potential precision loss.</p>
<p><mark>MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="prs-91120-94464-1" class="level3">
<h3 class="anchored" data-anchor-id="prs-91120-94464-1">PRs <a href="https://github.com/pytorch/pytorch/pull/91197">#91120</a>, <a href="https://github.com/pytorch/pytorch/pull/91514">#94464</a></h3>
<blockquote class="blockquote">
<p>Fix handling of ops taking multiple dtypes as input (#91197, #91514)</p>
</blockquote>
<p>Claude’s analysis: The PR fixes MPS scatter to handle type mismatches between source and destination tensors automatically.</p>
<p><mark>MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="prs-91786-94662" class="level3">
<h3 class="anchored" data-anchor-id="prs-91786-94662">PRs <a href="https://github.com/pytorch/pytorch/pull/91786">#91786</a>, <a href="https://github.com/pytorch/pytorch/pull/94662">#94662</a></h3>
<blockquote class="blockquote">
<p>Fix handling of channels last for torch.cat (#91786, #94662), torch.Conv2d (#91822, #94384), torch.nn.{ELU,ReLU,Hardswish} (#94664), torch.nn.BatchNorm (#94760), torch.nn.MaxPool2d (#94877)</p>
</blockquote>
<p>ColBERT uses <code>.cat</code> in the following files:</p>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/utils.py#L45">colbert/indexing/utils.py</a> to concatenate a list of tensors (<code>unique_pids_per_centroid</code>) into a single tensor (<code>ivf</code>).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/index_manager.py#L23">colbert/indexing/index_manager.py</a> to concatenate multiple path names.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor_core.py#L31"></a> to calculate <code>offsets</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor_core.py#L39"></a> to add padding to a tensor.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/distillation/scorer.py#L60"></a> to concatenate <code>scores</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/collection_encoder.py#L38"></a> to concatenate document token embeddings.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L181"></a> to concatenate <code>codes</code> (centroid IDs).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L182"></a> to concatenate <code>residuals</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L220"></a> to concatenate <code>codes</code> (centroid IDs).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L237"></a> to concatenate <code>centroids</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L276"></a> to concatenate document token embeddings.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor.py#L51"></a> to concatenate <code>packed_tensor</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor.py#L152"></a> to concatenate <code>all_orders</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/strided_tensor.py#L155"></a> to concatenate <code>all_lengths</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L101"></a> to concatenate <code>compressed_embs.codes</code> (centroid IDs corresponding to document token embeddings).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L108"></a> to concatenate <code>compressed_embs.residuals</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L117"></a> to concatenate <code>doclens</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L431"></a> to concatenate <code>codes</code> (centroid IDs).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L434"></a> to concatenate <code>residuals</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L506"></a> to concatenate <code>codes</code> (centroid IDs).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/index_updater.py#L507"></a> to concatenate <code>residuals</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L115"></a> to concatenate <code>batches</code> (of queries).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L168"></a> to concatenate document token embeddings (in order).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L169"></a> to concatenate <code>mask</code> for document token embeddings (in order).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/coalesce.py#L48"></a> to concatenate <code>code</code> chunks.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L69"></a> to concatenate <code>offsets</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L149"></a> to concatenate <code>approx_scores</code>.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/tokenization/query_tokenization.py#L88"></a> to concatenate <code>ids</code> (for query tokens).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/tokenization/query_tokenization.py#L89"></a> to concatenate <code>masks</code> (for query tokens).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/tokenization/utils.py#L72"></a> to concatenate prefix token.</li>
</ul>
<p><mark>MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="prs-94259-94278-95145-95762-95905" class="level3">
<h3 class="anchored" data-anchor-id="prs-94259-94278-95145-95762-95905">PRs <a href="https://github.com/pytorch/pytorch/pull/94259">#94259</a>, <a href="https://github.com/pytorch/pytorch/pull/94278">#94278</a>, <a href="https://github.com/pytorch/pytorch/pull/95145">#95145</a>, <a href="https://github.com/pytorch/pytorch/pull/95762">#95762</a>, <a href="https://github.com/pytorch/pytorch/pull/95905">#95905</a></h3>
<blockquote class="blockquote">
<p>Fix view operations handling (#94259, #94278,#95145, #95762, #95905)</p>
</blockquote>
<p>Claude’s analysis: This PR fixes crashes in view operations when slicing with incorrect lengths, which ColBERT uses for tensor reshaping and indexing operations.</p>
<p><mark>MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="pr-87853" class="level3">
<h3 class="anchored" data-anchor-id="pr-87853">PR <a href="87853">#87853</a></h3>
<blockquote class="blockquote">
<p>Move incorrectly placed closing curly brace of extern “C” block (#87853)</p>
</blockquote>
<p>Gemini’s analysis: This pull request is a foundational C++ correctness fix for the PyTorch framework. Because ColBERT compiles its own C++ extensions that depend on these core headers, this change is directly beneficial. It ensures the stability and reliability of ColBERT’s own build process, preventing potential compilation failures.</p>
<p>ColBERT’s C++ extensions:</p>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/main/colbert/modeling/segmented_maxsim.cpp">segmented_maxsim.cpp</a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/main/colbert/search/filter_pids.cpp">filter_pids.cpp</a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/main/colbert/search/decompress_residuals.cpp">decompress_residuals.cpp</a></li>
</ul>
<p><mark>Unsure how to measure the impact but if it’s about reliability perhaps it will address some open issues. TBD.</mark></p>
</section>
<section id="pr-93322" class="level3">
<h3 class="anchored" data-anchor-id="pr-93322">PR <a href="https://github.com/pytorch/pytorch/pull/93322">#93322</a></h3>
<blockquote class="blockquote">
<p>Fix MSVC compiler error in basic_ops.h (#93322)</p>
</blockquote>
<p>Gemini’s take: This pull request is a crucial build-system and correctness fix. It directly impacts ColBERT by ensuring that its custom C++ code can be compiled successfully on Windows machines that use the affected MSVC compiler. Without this fix, users in that environment would be unable to run ColBERT. This change makes ColBERT’s build process more robust and widens its platform compatibility.</p>
<p><mark>TBD if this addressed open issues related to Windows machines.</mark></p>
</section>
<section id="pr-89310" class="level3">
<h3 class="anchored" data-anchor-id="pr-89310">PR <a href="https://github.com/pytorch/pytorch/pull/89310">#89310</a></h3>
<blockquote class="blockquote">
<p>Fix a bug that redefines __STDC_FORMAT_MACROS (#89310)</p>
</blockquote>
<p>Gemini’s take: This pull request provides a stability and correctness fix to the underlying PyTorch framework. Because ColBERT compiles its own C++ code that depends on these core PyTorch headers, this change is directly beneficial. It makes ColBERT’s own compilation process more reliable and prevents a potential class of build failures.</p>
<p><mark>Unsure how to measure the impact but if it’s about reliability perhaps it will address some open issues. TBD.</mark></p>
</section>
<section id="pr-90411" class="level3">
<h3 class="anchored" data-anchor-id="pr-90411">PR <a href="https://github.com/pytorch/pytorch/pull/90411">#90411</a></h3>
<blockquote class="blockquote">
<p>Add manual cuda deps search logic (#90411)</p>
</blockquote>
<p>Gemini’s take: This PyTorch pull request adds a new mechanism to help PyTorch find its essential CUDA libraries (cuBLAS and cuDNN) on Linux systems.</p>
<p><mark>Unsure how to measure the impact but if it’s about reliability perhaps it will address some open issues. TBD.</mark></p>
</section>
<section id="pr-89759" class="level3">
<h3 class="anchored" data-anchor-id="pr-89759">PR <a href="https://github.com/pytorch/pytorch/pull/89759">#89759</a></h3>
<blockquote class="blockquote">
<p>Workaround for NumPy builds that ship with a broken Dlpack deleter (#89759)</p>
</blockquote>
<p><mark>TBD if this improves reliability as ColBERT uses NumPy</mark>/.</p>
</section>
<section id="pr-86288" class="level3">
<h3 class="anchored" data-anchor-id="pr-86288">PR <a href="https://github.com/pytorch/pytorch/pull/86288">#86288</a></h3>
<blockquote class="blockquote">
<p>Workaround MSVC ICE due to constexpr char* template argument (#86288)</p>
</blockquote>
<p>Gemini’s take: It directly impacts ColBERT by ensuring that its custom C++ code can be compiled successfully on Windows machines that use an affected MSVC compiler.</p>
<p><mark>TBD if this addressed open issues related to Windows machines.</mark></p>
</section>
<section id="pr-85408" class="level3">
<h3 class="anchored" data-anchor-id="pr-85408">PR <a href="https://github.com/pytorch/pytorch/pull/85408">#85408</a></h3>
<blockquote class="blockquote">
<p>Add define to fix issue with compatibility with latest Windows SDK (#85408)</p>
</blockquote>
<p>Gemini’s take: It directly impacts ColBERT by ensuring that the underlying PyTorch framework can be successfully built on modern Windows environments.</p>
<p><mark>TBD if this addressed open issues related to Windows machines.</mark></p>
</section>
</section>
<section id="improvements" class="level2">
<h2 class="anchored" data-anchor-id="improvements">Improvements</h2>
<p>These PyTorch PRs are related to improvements, which could affect ColBERT by speeding things up (and therefore seeing a speed up in indexing/search/training time) or changing baseline indexing/search/training artifacts if improvements impact numeric precision.</p>
<section id="pr-56398" class="level3">
<h3 class="anchored" data-anchor-id="pr-56398">PR <a href="https://github.com/pytorch/pytorch/pull/56398">#56398</a></h3>
<blockquote class="blockquote">
<p>Set std/var correction overloads default value to None (#56398)</p>
</blockquote>
<p><mark>Unclear if and how this affects ColBERT but highlighting it since it changes code in PyTorch’s aten/src/ATen/native.</mark></p>
</section>
<section id="pr-86309" class="level3">
<h3 class="anchored" data-anchor-id="pr-86309">PR <a href="https://github.com/pytorch/pytorch/pull/86309">#86309</a></h3>
<blockquote class="blockquote">
<p>Add support for int32 indices in index/index_put ops (#86309)</p>
</blockquote>
<p><mark>I think this PR is related to <a href="https://github.com/stanford-futuredata/ColBERT/pull/180">this ColBERT PR</a> which I think is related to <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L163">this line of code in <code>IndexScorer</code></a></mark>.</p>
</section>
<section id="pr-87022" class="level3">
<h3 class="anchored" data-anchor-id="pr-87022">PR <a href="https://github.com/pytorch/pytorch/pull/87022">#87022</a></h3>
<blockquote class="blockquote">
<p>Enable where to have cpu scalar args (#87022)</p>
</blockquote>
<p>ColBERT uses <code>torch.where</code> in the following files:</p>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L49">colbert/modeling/checkpoint.py</a> to pool embeddings within each cluster.</li>
</ul>
<p><mark>Unclear if this will affect ColBERT but there are currently no open issues related to <code>torch.where</code></mark>.</p>
</section>
<section id="pr-90914" class="level3">
<h3 class="anchored" data-anchor-id="pr-90914">PR <a href="https://github.com/pytorch/pytorch/pull/90914">#90914</a></h3>
<blockquote class="blockquote">
<p>Add support for NumPy scalars to torch.tensor.asarray (#90914)</p>
</blockquote>
<p><mark>Found <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L198">1 use of <code>asarray</code></a> but it doesn’t deal with a scalar so probably won’t be affected</mark>.</p>
</section>
<section id="pr-85926" class="level3">
<h3 class="anchored" data-anchor-id="pr-85926">PR <a href="https://github.com/pytorch/pytorch/pull/85926">#85926</a></h3>
<blockquote class="blockquote">
<p>Enable out variant of torch.max(#85926)</p>
</blockquote>
<p><mark>Unclear what this PR does but highlighting it since ColBERT uses <code>torch.max</code></mark>.</p>
</section>
<section id="pr-91846" class="level3">
<h3 class="anchored" data-anchor-id="pr-91846">PR <a href="https://github.com/pytorch/pytorch/pull/91846">#91846</a></h3>
<blockquote class="blockquote">
<p>Implement faster gradient clipping using foreach function (#91846)</p>
</blockquote>
<p>ColBERT uses <code>torch.nn.utils.clip_grad_norm_</code> in two lines:</p>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/amp.py#L26">colbert/utils/amp.py#L26</a></li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/amp.py#L31">colbert/utils/amp.py#L31</a></li>
</ul>
<p><mark>IIUC this won’t affect ColBERT since it doesn’t set <code>foreach</code> in <code>torch.nn.utils.clip_grad_norm_</code>.</mark></p>
</section>
<section id="pr-92334" class="level3">
<h3 class="anchored" data-anchor-id="pr-92334">PR <a href="https://github.com/pytorch/pytorch/pull/92334">#92334</a></h3>
<blockquote class="blockquote">
<p>Enable DDP to handle custom dataclass forward outputs (#92334)</p>
</blockquote>
<p><mark>ColBERT does use DistributedDataParallel (<a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/training/training.py#L56">in <code>train</code></a>) butit’s not being passed a custom dataclass, it’s being passed a <code>colbert</code> model so I don’t think this PR applies.</mark></p>
</section>
<section id="pr-89137" class="level3">
<h3 class="anchored" data-anchor-id="pr-89137">PR <a href="https://github.com/pytorch/pytorch/pull/89137">#89137</a></h3>
<blockquote class="blockquote">
<p>Skip collective communications for NO_SHARD in clip_grad_norm_ (#89137)</p>
</blockquote>
<p><mark>ColBERT doesn’t use FullyShardedDataParallel but it <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/amp.py#L26">does use <code>torch.nn.utils.clip_grad_norm</code></a> so not sure if this PyTorch PR affects it</mark>.</p>
</section>
<section id="pr-90028" class="level3">
<h3 class="anchored" data-anchor-id="pr-90028">PR <a href="https://github.com/pytorch/pytorch/pull/90028">#90028</a></h3>
<blockquote class="blockquote">
<p>Apply the “largest” dtype across all parameters/gradients as defined by PyTorch’s type promotion semantics for the total norm returned in clip_grad_norm_ for low prec grads (#90028)</p>
</blockquote>
<p><mark>ColBERT doesn’t use FullyShardedDataParallel but it <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/utils/amp.py#L26">does use <code>torch.nn.utils.clip_grad_norm</code></a> so not sure if this PyTorch PR affects it</mark>.</p>
</section>
<section id="pr-85692" class="level3">
<h3 class="anchored" data-anchor-id="pr-85692">PR <a href="https://github.com/pytorch/pytorch/pull/85692">#85692</a></h3>
<blockquote class="blockquote">
<p>Set CUDA_MODULE_LOADING to LAZY when not set by the user (#85692)</p>
</blockquote>
<p><mark>Unclear exactly what this does but it relates to the CUDA_MODULE_LOADING env var which is not set in ColBERT</mark></p>
</section>
<section id="pr-89172" class="level3">
<h3 class="anchored" data-anchor-id="pr-89172">PR <a href="https://github.com/pytorch/pytorch/pull/89172">#89172</a></h3>
<blockquote class="blockquote">
<p>Add an option to disable reduced precision reductions for BF16 GEMM (#89172)</p>
</blockquote>
<p><mark>Unclear exactly what this does, but in the PR they mentioned it improves H100 usage, so I’ll keep that in mind.</mark></p>
</section>
<section id="pr-91436" class="level3">
<h3 class="anchored" data-anchor-id="pr-91436">PR <a href="https://github.com/pytorch/pytorch/pull/91436">#91436</a></h3>
<blockquote class="blockquote">
<p>Add an env variable to disable addmm_cuda_lt kernel (#91436)</p>
</blockquote>
<p><mark>Unclear what this does, but it’s adding a variable, so it’s a new feature.</mark></p>
</section>
<section id="pr-86041-93022" class="level3">
<h3 class="anchored" data-anchor-id="pr-86041-93022">PR <a href="https://github.com/pytorch/pytorch/pull/86041">#86041</a>, <a href="https://github.com/pytorch/pytorch/pull/93022">#93022</a></h3>
<blockquote class="blockquote">
<p>Clean up flatbuffer lib dependency and fixed its test to match pkl models (#86041, #93022)</p>
</blockquote>
<p><mark>I am not sure what these PRs are doing. The title refers “pkl models” which ColBERT doesn’t use to my knowledge.</mark></p>
</section>
<section id="pr-93898" class="level3">
<h3 class="anchored" data-anchor-id="pr-93898">PR <a href="https://github.com/pytorch/pytorch/pull/93898">#93898</a></h3>
<blockquote class="blockquote">
<p>Type corrections to avoid unnecessary static_casts (#93898)</p>
</blockquote>
<p><mark>Unclear what this PR does but it touches a lot of what seem to be core files so I’m flagging it</mark>.</p>
</section>
<section id="pr-87245" class="level3">
<h3 class="anchored" data-anchor-id="pr-87245">PR <a href="https://github.com/pytorch/pytorch/pull/87245">#87245</a></h3>
<blockquote class="blockquote">
<p>Integrate all ONNX operators with a new JitScalarType API (#87245)</p>
</blockquote>
<p><mark>It’s onnx related, which ColBERT doesn’t use, but it also says: “this PR addresses not only the issue above, but the entire family of issues related to torch._C.Value.type() parsing when scalarType() or dtype() is not available.”</mark></p>
</section>
<section id="pr-87343" class="level3">
<h3 class="anchored" data-anchor-id="pr-87343">PR <a href="https://github.com/pytorch/pytorch/pull/87343">#87343</a></h3>
<blockquote class="blockquote">
<p>Add share_from_this to torch::jit::Graph (#87343)</p>
</blockquote>
<p><mark>Is ONNX related, but unclear if it affects anything else?</mark></p>
</section>
<section id="pr-84789" class="level3">
<h3 class="anchored" data-anchor-id="pr-84789">PR <a href="https://github.com/pytorch/pytorch/pull/84789">#84789</a></h3>
<blockquote class="blockquote">
<p>Use optional op to keep None in results for ONNX internal tests (#84789)</p>
</blockquote>
<p><mark>Is ONNX related, but unclear if it affects anything else?</mark></p>
</section>
<section id="pr-86218" class="level3">
<h3 class="anchored" data-anchor-id="pr-86218">PR <a href="https://github.com/pytorch/pytorch/pull/86218">#86218</a></h3>
<blockquote class="blockquote">
<p>Add fp16 support for torch.nn.Linear (#89774), torch.nn.GELU (#86218)</p>
</blockquote>
<p><mark>MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="pr-91884" class="level3">
<h3 class="anchored" data-anchor-id="pr-91884">PR <a href="https://github.com/pytorch/pytorch/pull/91884">#91884</a></h3>
<blockquote class="blockquote">
<p>Add support for empty Tensors in torch.bitwise_not (#87286), torch.nn.LayerNorm (#94212), many backward functions (#94343), torch.nn.functional.hardswish (#94342), torch.topk (#91884), torch.arange (#94485), torch.linal.inv (#94551),</p>
</blockquote>
<p><mark>MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="pr-91734" class="level3">
<h3 class="anchored" data-anchor-id="pr-91734">PR <a href="https://github.com/pytorch/pytorch/pull/91734">#91734</a></h3>
<blockquote class="blockquote">
<p>Add support for reduction ops on multiple axis at a time (#91734)</p>
</blockquote>
<p><mark>MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="pr-94639" class="level3">
<h3 class="anchored" data-anchor-id="pr-94639">PR <a href="https://github.com/pytorch/pytorch/pull/94639">#94639</a></h3>
<blockquote class="blockquote">
<p>Add support for k greater than 16 for torch.topk (#94639)</p>
</blockquote>
<p><mark>MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
<section id="pr-91576" class="level3">
<h3 class="anchored" data-anchor-id="pr-91576">PR <a href="https://github.com/pytorch/pytorch/pull/91576">#91576</a></h3>
<blockquote class="blockquote">
<p>Simplify OpenMP detection in CMake (#91576)</p>
</blockquote>
<p>Claude’s take: While ColBERT should continue working, there could be subtle performance or compilation differences depending on how PyTorch’s simplified OpenMP detection affects the runtime compilation of ColBERT’s C++ extensions, particularly in multi-threaded scenarios.</p>
<p><mark>Unclear what this PR is doing but flagging it as it might improve performance as Claude states.</mark></p>
</section>
</section>
<section id="deprecations" class="level2">
<h2 class="anchored" data-anchor-id="deprecations">Deprecations</h2>
<p>These are PRs I would think would have a significant impact if applicable.</p>
<section id="pr-92143" class="level3">
<h3 class="anchored" data-anchor-id="pr-92143">PR <a href="https://github.com/pytorch/pytorch/pull/92143">#92143</a></h3>
<blockquote class="blockquote">
<p>Deprecate tensor.mT,tensor.T,tensor.mH,tensor.H on 0D-tensors (#92143)</p>
</blockquote>
<p><mark>There are five instances where .T is used, but pretty sure none of these are 0-D tensors, will confirm</mark>:</p>
<ul>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/candidate_generation.py#L13">colbert/search/candidate_generation.py#L13</a>: cosine similarity between centroids and query token embeddings.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/candidate_generation.py#L43">colbert/search/candidate_generation.py#L43</a>: used in <code>generate_candidate_scores</code> which uses <code>lookup_eids</code> which I can’t find anywhere else in the codebase.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/colbert.py#L195">colbert/modeling/colbert.py#L195</a>: Cosine similarity between query and document token embeddings.</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L215">colbert/indexing/codecs/residual.py#L215</a>: Cosine similarity between centroids and document token embeddings (GPU).</li>
<li><a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/codecs/residual.py#L217">colbert/indexing/codecs/residual.py#L217</a>: Cosine similarity between centroids and document token embeddings (CPU).</li>
</ul>
</section>
</section>
<section id="performance" class="level2">
<h2 class="anchored" data-anchor-id="performance">Performance</h2>
<p>Similar to improvements, I would only expect this set of PRs to improve ColBERT performance, keeping an eye on how different artifacts changed because of that.</p>
<section id="pr-93234" class="level3">
<h3 class="anchored" data-anchor-id="pr-93234">PR <a href="https://github.com/pytorch/pytorch/pull/93234">#93234</a></h3>
<blockquote class="blockquote">
<p>Improve performance for functional.multi_head_attention_forward() (#93234, #89847)</p>
</blockquote>
<p><mark>ColBERT uses BERT, which has its own attention implementation, so this likely wouldn’t impact it unless the BERT model specifically uses <code>torch.nn.functional.multi_head_attention_forward</code> or <code>torch.nn.MultiheadAttention</code>.</mark></p>
</section>
<section id="pr-84981" class="level3">
<h3 class="anchored" data-anchor-id="pr-84981">PR <a href="https://github.com/pytorch/pytorch/pull/84981">#84981</a></h3>
<blockquote class="blockquote">
<p>Use atomicAdd for bfloat16 in Ampere and above (#84981)</p>
</blockquote>
<p>Gemini’s take: This pull request directly accelerates a fundamental operation used during the training of ColBERT. By replacing a slow, emulated function with a fast, hardware-native instruction, this change leads to a noticeable increase in training speed for anyone training ColBERT with bfloat16 mixed precision on an Ampere or newer GPU.</p>
<p><mark>If Gemini is correct, then I will see a speedup in training.</mark></p>
</section>
<section id="pr-94034" class="level3">
<h3 class="anchored" data-anchor-id="pr-94034">PR <a href="https://github.com/pytorch/pytorch/pull/94034">#94034</a></h3>
<blockquote class="blockquote">
<p>Add various performance fixes to c++ STL usage (#94034)</p>
</blockquote>
<p>Gemini’s take: The changes in this PR touch several core PyTorch components that are critical to ColBERT’s operation:</p>
<ul>
<li>Autograd Engine (function.h): Every gradient calculation during training will benefit from these optimizations.</li>
<li>CUDA Communication (comm.cpp): The code that handles broadcasting and gathering tensors across GPUs for multi-GPU training and inference is made more efficient.</li>
<li>Mixed Precision (autocast_mode.h): The logic for automatic mixed precision, which is key for training ColBERT efficiently, is also slightly optimized.</li>
</ul>
<p><mark>If Gemini is correct, then I will see a speed up in all aspects of ColBERT. </mark></p>
</section>
<section id="pr-86568" class="level3">
<h3 class="anchored" data-anchor-id="pr-86568">PR <a href="https://github.com/pytorch/pytorch/pull/86568">#86568</a></h3>
<blockquote class="blockquote">
<p>Add fmsub to vectorization primitives (#86568)</p>
</blockquote>
<p>Gemini’s take: This pull request is a CPU-specific performance optimization. It adds support for the fmsub (fused multiply-subtract) instruction to PyTorch’s CPU vectorization library. This allows PyTorch to perform the operation (a * b) - c in a single, faster instruction on modern CPUs that support it (e.g., via AVX or NEON).</p>
<p><mark>I’m pretty sure ColBERT doesn’t use multiply-subtract, but keeping it in here just in case it comes up. </mark></p>
</section>
<section id="pr-92300" class="level3">
<h3 class="anchored" data-anchor-id="pr-92300">PR <a href="https://github.com/pytorch/pytorch/pull/92300">#92300</a></h3>
<blockquote class="blockquote">
<p>Fix biasadd OMP perf issue for the packed MKL SGEMM (#92300)</p>
</blockquote>
<p>Gemini’s take: This pull request is a CPU-specific performance optimization. It fixes a parallelization issue within the Intel MKL (Math Kernel Library) backend for linear layers. This change improves the efficiency of adding a bias term to the output of a matrix multiplication when running on a CPU.</p>
<p><mark>If Gemini is correct, I would expect a speedup on CPU. </mark></p>
</section>
<section id="pr-91114" class="level3">
<h3 class="anchored" data-anchor-id="pr-91114">PR <a href="https://github.com/pytorch/pytorch/pull/91114">#91114</a></h3>
<blockquote class="blockquote">
<p>Increase performance of torch.add{cmul,cdiv,mm}(#94214, #94534)torch.multinomial (#86342), faster op launch time (#86437), torch.linear (#91114), view handling (#91743, #94218), convolutions(#94661), scatter/gather (#94663)</p>
</blockquote>
<p>Gemini’s take: While the Adam optimizer used by ColBERT does use the addcdiv operation, this is executed on the GPU via CUDA, not MPS. This pull request is a performance optimization for the torch.nn.Linear layer, but it is exclusively for the MPS (Metal Performance Shaders) backend.</p>
<p><mark>MPS-related and will only affect ColBERT if we in the future choose to make it compatible with MPS.</mark></p>
</section>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Based on my analysis, I’m optimistic about upgrading ColBERT from torch==1.13.1 to 2.0. The upgrade should deliver concrete benefits with reasonable testing overhead. Performance-wise, I’ll be watching for training time improvements from the faster <code>foreach</code> optimizer implementations and expect speedups across all aspects of ColBERT from C++ optimizations and CUDA improvements. For validation, I’ll need to check for numeric differences in indexing/search artifacts from half-precision bug fixes and benchmark retrieval quality metrics after reindexing to avoid regressions. The reliability improvements should make ColBERT’s multi-GPU functionality more reliable and might address related open issues. Plus there are fixes for operations like <code>topk</code> and <code>torch.load</code> that ColBERT uses extensively. Most MPS-related changes will only affect ColBERT if we choose future compatibility, so they’re not immediate concerns but good to have.</p>
<p>My next step will be to establish training time benchmarks and indexing/retrieval/training baseline artifacts so that I can concretely monitor even subtle performance/behavior changes when using <code>torch==2.0</code> in my development branch.</p>


</section>

 ]]></description>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-27-torch-colbert/</guid>
  <pubDate>Sun, 27 Jul 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TIL: Custom Composer Callback to Push Checkpoints to HuggingFace Hub During Training.</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-26-push-to-hub/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this short TIL blog post, I’m going to share the code I wrote with Claude’s help for a custom Composer callback which pushes the model to Hugging Face Hub every specified number of steps. The purpose of doing so is so that you can run evaluation after training so it doesn’t slow down training.</p>
</section>
<section id="custom-composer-callback" class="level2">
<h2 class="anchored" data-anchor-id="custom-composer-callback">Custom Composer Callback</h2>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> HFPushCallback(Callback):</span>
<span id="cb1-2">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__init__</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, repo_id: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, push_every_n_steps: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb1-3">      <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.repo_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> repo_id</span>
<span id="cb1-4">      <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.push_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> push_every_n_steps</span>
<span id="cb1-5">      <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.token <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.getenv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HF_TOKEN"</span>)</span>
<span id="cb1-6">      <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.hf_api <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> HfApi(token<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.token)</span>
<span id="cb1-7">  </span>
<span id="cb1-8">      create_repo(</span>
<span id="cb1-9">          repo_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.repo_id,</span>
<span id="cb1-10">          token<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.token,</span>
<span id="cb1-11">          private<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb1-12">          exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb1-13">      )</span>
<span id="cb1-14">  </span>
<span id="cb1-15">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> batch_end(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:            </span>
<span id="cb1-16">      <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.push_every_n_steps <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb1-17">          <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._push_model(state)</span>
<span id="cb1-18">  </span>
<span id="cb1-19">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _push_model(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, state: State):</span>
<span id="cb1-20">      <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> tempfile.TemporaryDirectory() <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> temp_dir:</span>
<span id="cb1-21">          state.model.model.save_pretrained(temp_dir)</span>
<span id="cb1-22">          </span>
<span id="cb1-23">          <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.hf_api.upload_folder(</span>
<span id="cb1-24">              folder_path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>temp_dir,</span>
<span id="cb1-25">              repo_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.repo_id,</span>
<span id="cb1-26">              commit_message<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Step </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>state<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>timestamp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>batch<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>value<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb1-27">          )</span></code></pre></div>
<p>Important to note, <code>state.model</code> is the <code>ComposerHFCausalLM</code> wrapper around the HuggingFace model, so you have to access <code>state.model.model</code> to use the attribute <code>save_pretrained</code>.</p>
</section>
<section id="running-inference" class="level2">
<h2 class="anchored" data-anchor-id="running-inference">Running Inference</h2>
<p>You can use the following code to run inference on the model, just as you would any set of PEFT adapters from Hugging Face Hub.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> peft <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> PeftModel</span>
<span id="cb2-3"></span>
<span id="cb2-4"></span>
<span id="cb2-5">model_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFaceTB/SmolLM2-135M"</span></span>
<span id="cb2-6">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(model_id)</span>
<span id="cb2-7">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(model_id)</span>
<span id="cb2-8"></span>
<span id="cb2-9">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> PeftModel.from_pretrained(</span>
<span id="cb2-10">    model,</span>
<span id="cb2-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"&lt;repo_id&gt;"</span>,</span>
<span id="cb2-12">    revision <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"&lt;revision&gt;"</span></span>
<span id="cb2-13">)</span>
<span id="cb2-14"></span>
<span id="cb2-15">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The best thing about artificial intelligence is "</span></span>
<span id="cb2-16">inputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(prompt, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>)</span>
<span id="cb2-17">attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> inputs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"attention_mask"</span>]</span>
<span id="cb2-18"></span>
<span id="cb2-19">outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate(</span>
<span id="cb2-20">  inputs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>],</span>
<span id="cb2-21">  attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask,</span>
<span id="cb2-22">  pad_token_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer.eos_token_id</span>
<span id="cb2-23">)</span>
<span id="cb2-24"></span>
<span id="cb2-25"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(tokenizer.decode(outputs[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], skip_special_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>))      </span></code></pre></div>
<p>The <code>revision</code> parameter is the commit ID in your Hugging Face repo. In this way, if you, say, push your model every 100 steps, then you can use the <code>revision</code> argument for each of those checkpoints and run your evaluations. Then you can log those evaluations to your W&amp;B project so that your evaluation log is comparable with other training logs.</p>


</section>

 ]]></description>
  <category>LLM</category>
  <category>Custom Composer Callback</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-26-push-to-hub/</guid>
  <pubDate>Sat, 26 Jul 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Takeaways from Lesson 1 of the AI Evals Course</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-22-evals-course/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post, I’m going highlight ideas that stood out to me from the first lesson and first three chapters of the course reader from the AI evals course by Hamel Husain and Shreya Shankar.</p>
</section>
<section id="ideas-that-stood-out-from-the-first-three-chapters-of-the-course-reader" class="level2">
<h2 class="anchored" data-anchor-id="ideas-that-stood-out-from-the-first-three-chapters-of-the-course-reader">Ideas that Stood Out from the First Three Chapters of the Course Reader</h2>
<p><strong>Idea 1: LLMs used for intermediate tasks still need evals.</strong> I think this is an important reminder because I often think of LLM tasks as complex or mission-critical or user-facing. However, there are smaller subtasks that happen “behind the scenes”, assisting the rest of the pipeline. These tasks can be overlooked. For example you could have an LLM-assisted task of curating few-shot examples that are used for a larger prompt downstream. This task needs evals.</p>
<p><strong>Idea 2: looking at data, whether it’s curating few-shot examples manually or reviewing LLM traces to classify failures, deepens our understanding of what the user wants and how the LLM fails to deliver.</strong> What makes a good example? We have to think about objectives, content, format, tone, instruction, and output. What type of failure are we witnessing in a trace? We have to think about those dimensions, and identify specifically what the LLM failed to do and categorize it precisely.</p>
<p><strong>Idea 3: We allow ourselves to adjust annotations or revise failure mode definitions as needed as we organize our thoughts and observations on LLM traces.</strong> It’s normal for annotation schemas to evolve after reviewing more data. I fully agree and relate to this idea. <a href="https://youtu.be/FXOXoaGjntc">After evaluating 1350 LLM judge scores (for LM-generated tiny stories)</a> I improved my understanding of what makes a high quality story (in terms of creativity, grammar, context-tracking, plot, factual knowledge, and reasoning) and modified the criteria I used to evaluate those dimensions.</p>
<p><strong>Idea 4: Forcing binary decisions about whether a failure mode occurs or not produces more reproducible annotations than the Likert scale.</strong> As someone who has advised, designed and administered a dozen or more surveys, I plead the case for binary decisions and groan at the sight of a Likert scale. What’s the difference between “Good” and “Very Good”? What about “Mostly Satisfied” and “Somewhat Satisfied”? If you’re asking someone to evaluate even 10s of LLM traces using a Likert scale, the cognitive load quickly fatigues the evaluator. It’s much simpler to answer “Did the LLM fail to use an appropriate tone?” (Yes/No) than “How well did the LLM use an appropriate tone?” (Exceptionally Well, Very Well, Somewhat Well, Not Well at All).</p>
<p>Note: Allen Downey has an excellent blog post, <a href="https://www.allendowney.com/blog/2024/05/03/the-mean-of-a-likert-scale/"><em>The Mean of a Likert Scale</em></a> which tackles the challenges of summarizing Likert scale data.</p>
</section>
<section id="ideas-from-lesson-1" class="level2">
<h2 class="anchored" data-anchor-id="ideas-from-lesson-1">Ideas from Lesson 1</h2>
<p><strong>Idea A: LLM Evaluation is the systematic measurement of LLM pipeline quality.</strong> This is the first (and best) concise definition of evals I’ve come across. We want to create a system (that’s reproducible and reliable) to measure the quality of an LLM pipeline. What to measure in the pipeline and how to define quality is what this course will teach us.</p>
<p><strong>Idea B: Pay attention to your prompt.</strong> Many folks don’t read the prompt they’re sending to the LLM! Think about the prompt first before writing an AI-assisted prompt. Specifying your problem involves writing your prompts with care. Use an LLM where it makes sense to be used (e.g.&nbsp;to improve the clarity of your already specific prompt).</p>
<p><strong>Idea C: You have to wear all these hats.</strong> To cross the gulf of comprehension (i.e.&nbsp;what is my data and what stories does it tell?) you must wear your “data scientist” hat. For specification, your “product” hat, and for generalization your “engineer” hat. Shreya and Hamel encourage us to move slowly as we navigate these gulfs. As Kawhi Leonard says: <a href="https://x.com/patbev21/status/1884687382412132558">slow is pro</a>.</p>
<p><strong>Idea D: Collecting representative samples and analyzing failure modes is the most important step in AI evals.</strong> This is where you learn the most, is what most people skip, what has the least guidance out there in the industry. Shreya spends 75-80% of her time on error analysis. Asking the question “what would make a user unhappy?” uncovers your failure modes.</p>
<p><strong>Idea E: The process of writing a good prompt sets the foundation for your evaluation success.</strong> If your prompt fails to specify, in no uncertain terms, what the LLM should and shouldn’t do, how can you expect to evaluate the LLM’s output? “The LLM didn’t structure its response as JSON”—did you ask it to? “The LLM didn’t provide measurements for the recipe”—did you ask it to?</p>
<p><strong>Idea F: The process of removing errors from the LLM pipeline is a process of improving your communication to the LLM,</strong> and this requires empathy! You have to put yourself in the user’s shoes and ask: what do I want from this interaction? What will make me happy? What will make me frustrated? And then you have to relay those user needs to the LLM via the prompt. And finally you have to evaluate whether the desired experience was delivered by the LLM. This dance between playing data scientist/product manager/user/engineer/communicator makes applied AI such a fascinating field.</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>I’m swimming in tasks right now (including a new puppy!) so it’s important for me to move slowly and deliberately. Taking this course at this juncture in my life is itself a process of evaluation: what do I focus my time on? How deep do I go into which assignments? What questions should I ask during office hours? The excellent structure and resources that Hamel and Shreya provided us will help ease my cognitive load, allowing me to focus on high value tasks. I don’t know if I’ll be able to write a blog post or make a video for each lesson, but I’ll try to publish at least once a week (on average). Our HW is to write a system prompt for a recipe chatbot, so expect some of my musings on that soon!</p>


</section>

 ]]></description>
  <category>AI Evals</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-22-evals-course/</guid>
  <pubDate>Tue, 22 Jul 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Revisiting ColBERTv1 : A Return to First Principles</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/</link>
  <description><![CDATA[ 




<div id="cell-1" class="cell">
<details class="code-fold">
<summary>pip installs</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span>pip install transformers<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.49.0</span></span>
<span id="cb1-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span>pip install ragatouille</span></code></pre></div>
</details>
</div>
<div id="cell-2" class="cell">
<details class="code-fold">
<summary>imports</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.indexing.collection_encoder <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> CollectionEncoder</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.infra <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ColBERTConfig</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.modeling.checkpoint <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Checkpoint</span>
<span id="cb2-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.modeling.tokenization.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> _split_into_batches, _sort_by_length, _insert_prefix_token</span>
<span id="cb2-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> random</span>
<span id="cb2-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb2-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> getsource</span>
<span id="cb2-8"></span>
<span id="cb2-9">checkpoint <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Checkpoint(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answerdotai/answerai-colbert-small-v1"</span>, ColBERTConfig())</span>
<span id="cb2-10">ce <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CollectionEncoder(config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ColBERTConfig(), checkpoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>checkpoint)</span></code></pre></div>
</details>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<ul>
<li>Main takeaways (Omar’s thread)</li>
<li>Abstract</li>
<li>Background: Neural Rankers</li>
<li>How does ColBERT compare to previous architectures?</li>
<li>The ColBERT architecture</li>
<li>Encoding Queries and Documents</li>
<li>MaxSim</li>
<li>Offline Indexing</li>
<li>Experimental Evaluation</li>
<li>Results</li>
<li>Ablation Studies</li>
<li>Indexing Throughput &amp; Footprint</li>
<li>Conclusion</li>
</ul>
</section>
<section id="main-takeaways-omars-thread" class="level2">
<h2 class="anchored" data-anchor-id="main-takeaways-omars-thread">Main Takeaways (Omar’s Thread)</h2>
<p>Instead of coming up with my own takeaways, I’m going to do something different this time, where I’m going to walk through Omar’s thread from 2023, where he himself summarizes the main takeaways from the ColBERT v1 paper.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Progress on dense retrievers is saturating.<br><br>The best retrievers in 2024 will apply new forms of late interaction, i.e.&nbsp;scalable attention-like scoring for multi-vector embeddings.<br><br>A🧵on late interaction, how it works efficiently, and why/where it's been shown to improve quality <a href="https://t.co/2XG33TtM9R">pic.twitter.com/2XG33TtM9R</a>
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804963760976092?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I think it’s important to highlight that he talks about new forms of late interaction as “scalable attention-like scoring for multi-vector embeddings”. From my understanding of ColBERT, the attention-like scoring mechanism refers to the BERT contextualization of meaning of tokens. As the query or the document goes through BERT, it passes through the attention mechanism, and tokens attend to each other. So no single query token or document token is isolated; it exists in the context of the entire query or the entire document that it’s in, respectively. The “multi-vector embeddings” part of his tweet is referring to this idea: we don’t compress an entire document or an entire query into a single vector, but instead have more than one vector representing different dimensions of meaning of the text.</p>
<p><mark><strong>Update</strong>: Omar clarified on Twitter that by “attention-like scoring mechanism” he was actually referring specifically to MaxSim as fast attention-like scoring, rather than the BERT contextualization during encoding that I initially described above. Which in hindsight makes sense—emphasis on “attention-like <strong>scoring mechanism</strong>”</mark>.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
Say you have 1M documents. With infinite GPUs, what would your retriever look like?<br><br>Maybe a cross-encoder? Finetune a large LM to take &lt;query,doc&gt; pairs. Run it 1M times to get a score for all docs.<br><br>Expressive! Given a query, the LM can pay attention to every detail in the doc! <a href="https://t.co/P4t7bYe9dT">pic.twitter.com/P4t7bYe9dT</a>
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804965942013978?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Something I want to highlight is that you still have to fine-tune a language model to become a retriever because the language model itself has this general knowledge about language and the relationship between words but it doesn’t have explicitly the capability of accurately producing a score that measures the relevancy of one body of text to another. So fine-tuning brings out that implicit skill that is in the latent space of the model into an actionable task. If we had infinite GPUs, we would want to get the relationship of every query token to every document token encoded. We would want to do this during training and we would want to do this during inference. That’s why he says “expressive” - this is the ultimate expressiveness or maximum expressiveness that you can achieve between query and document tokens. Your query tokens are no longer just contextualized within the query; they are contextualized within the query and every single document. That’s a really powerful expressive way of capturing meaning between two bodies of text to determine if they are related to each other to some level.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
But cross-encoders are expensive: must re-run each doc thru the LM <em>for every new query</em>.<br><br>Most retrievers are <em>single-vector</em> encoders: Cram each doc into a vector in advance; match queries/docs with a dot-product.<br><br>Scalable! We can apply dot-product search at the billion scale! <a href="https://t.co/lvLp6vSd8K">pic.twitter.com/lvLp6vSd8K</a>
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804967942697408?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>On the other side of the spectrum, we have the least expressive encoding but it is also more scalable: single vector encoders. You’re cramming each document into a vector and then you’re matching the queries and documents with a dot product.</p>
<p>You’re getting limited contextualization because of the limited expressiveness of what the tokens mean because everything is expressed by a single vector. But this is the most scalable.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
A huge burden on these bi-encoders: They must create <em>one</em> vector that captures <em>every</em> question you may ask about <em>any</em> content in the doc<br><br>Repeatedly been shown to be really fragile (especially OOD) and data-inefficient.<br><br>Can we build far more effective, yet scalable, encoders?
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804970144710981?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I think the key here is that the motivation is not just to build more effective encoders but effective <em>and</em> scalable encoders.</p>
<p>A brief aside on the limitations of single vector representations.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="The 9:30 mark of the Late Interaction Beats Single Vectors for RAG Introduction to PyLate video"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/1.png" class="img-fluid figure-img" alt="The 9:30 mark of the Late Interaction Beats Single Vectors for RAG Introduction to PyLate video"></a></p>
<figcaption>The 9:30 mark of the Late Interaction Beats Single Vectors for RAG Introduction to PyLate video</figcaption>
</figure>
</div>
<p>There is a great talk by Antoine Chaffin published recently called <a href="https://youtu.be/1x3k0V2IITo?feature=shared">“Late Interaction Beats Single Vectors for RAG Introduction to PyLate”</a> which is part of Hamel Husain’s AI Evals course. He talks about how pooling is the intrinsic flaw of dense models: the pooling operation compresses <code>n</code> tokens into a single one, because of this selective behavior is learned during training through data, it gets more extreme with longer context because you have to compress more, and the compressed representation learns one notion of similarity. This is what Omar means by the “huge burden” on the bi-encoders. They have to compress a lot of information into a single representation.</p>
<p>If you think about it, during training, which Antoine is talking about here (and he also had a good thread on Twitter, which I can’t find because Twitter’s search is horrible) is that as you’re training a single vector representation, small changes in the query will result in wholesale changes of the single vector that represents the entire document.</p>
<p>So for example if you have a query about actors the document embedding will be trained on expressing that one notion of movies. If you have a separate query about the plot now the document encoding has to represent that different notion of similarity with one vector.</p>
<p>Antoine says in his thread that because of this you get a very noisy training experience for the document encodings because they’re constantly being tossed around left and right to match different notions of similarity with each query in the training step. They can’t match all of the notions because they are a single vector representation or compression of multiple tokens.</p>
<p>Contrast this with the late interaction setup where you have one representation for each token. Now, when you are training, the token embedding in the document that corresponds to the query about the actors gets modified and adjusted to result in a better relevance score. Later on in training, a query about the plot is going to activate the token in the document about the plot, and the query about the visual effects will activate the visual effect tokens in the document, and so on. So, you get this fine-grained, nuanced representation aligning with fine-grained, nuanced meaning in queries during training. The benefit of this is that n each step of training you can have a new, nuanced gradient update to the weights that produce these granular representations.</p>
<p>Back to Omar’s thread.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
Late interaction (ColBERT) is simple.<br><br>Let's <em>not</em> cram docs into a vector. Instead, let's make the attention (interaction) scalable.<br><br>How? Build a <em>late</em> interaction fn.<br><br>(1) Applied after, not during, encoding.<br>(2) Pruning-capable, i.e.&nbsp;scales better than linear. This is key! <a href="https://t.co/m7fS15SdIE">pic.twitter.com/m7fS15SdIE</a>
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804972455768167?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>If we want efficiency, we can’t get the full effect of attention. We can’t get all query tokens and all document tokens attending to each other. And we can get an interaction between query token embeddings and document token embeddings that is done efficiently if it is applied after, not during, encoding. The “late” in “late interaction” is what allows the pruning capability, which we’ll talk about later in the presentation.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
Is there a function like this that preserves the retrieval precision of BERT attention?<br><br>Oddly, yes and it's incredibly simple: just aggregate (sum) the MaxSim from query tokens to doc tokens.<br><br>Basically, softly locate each query vector in the doc (w dot product), and aggregate.
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804974485811685?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>The key aspect of MaxSim is it takes the maximum similarity. Unlike something like average similarity, it doesn’t care about all tokens; it cares about the document token that has the maximum similarity with the given query token. This eliminates all but one document token from final consideration, which is what allows pruning capability to unlock. Because the interaction between query and document token embeddings happens after they’re encoded, you can encode queries and documents separately.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
It was a last-ditch run on a Sunday night (3 Nov'19) after complex scoring failed.<br><br>I spent weeks looking for a "bug". ColBERT w cheap scoring rivaled BERT-large cross-encoders with 10,000x more FLOPs?!<br><br>Called it ColBERT as a pun: late show / late interaction<br><br>log scale latency: <a href="https://t.co/4MGmzAYHYG">pic.twitter.com/4MGmzAYHYG</a>
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804976406802703?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Incredible that events like these happen, and I think happen quite frequently.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
There's a little-known trick that was essential for ColBERT's results: Query Augmentation.<br><br>ColBERT appends [MASK] tokens to the query encoder to allow BERT to create more query vectors that aren't there!<br><br>Is it the earliest form of a scratchpad / chain of thought? From Nov 2019! <a href="https://t.co/2rIoMn1jxP">pic.twitter.com/2rIoMn1jxP</a>
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804978667434048?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This is a super interesting concept that we’ll look at in detail later on.</p>
<p>As another aside—one of the reasons I was motivated to re-read the ColBERT V1 paper was this thread below by Antoine.</p>
<blockquote class="twitter-tweet blockquote" data-theme="dark">
<p lang="en" dir="ltr">
I am starting to be more and more convinced that MaxSim generalize very well to long documents but struggles on longer query, most probably due to the asymmetry<br>Larger documents are bound by the number of query tokens, but larger queries might get noisy<br>Either it is a query…
</p>
— Antoine Chaffin (<span class="citation" data-cites="antoine_chaffin">@antoine_chaffin</span>) <a href="https://twitter.com/antoine_chaffin/status/1942909502723883381?ref_src=twsrc%5Etfw">July 9, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>If you have a document with 1k tokens and a query with 32 tokens, at most 32 document tokens will pass the maximum similarity threshold, hence “larger documents are bound by the number of query tokens.” As your query gets larger the meaning of tokens becomes diverse, this may create noise in the meaning expressed in the query. Query tokens with vastly different meanings will have maximum similarity with document tokens that are vastly different in meaning as well.</p>
<p>The conversation continues with:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Yes, that is also why it was not a big issue with query expansion because all the queries had the same number of tokens<br>but with longer queries and no query exp, meh
</p>
— Antoine Chaffin (<span class="citation" data-cites="antoine_chaffin">@antoine_chaffin</span>) <a href="https://twitter.com/antoine_chaffin/status/1943002350274179544?ref_src=twsrc%5Etfw">July 9, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>slm tokens makes a really interesting point. Let’s assume that for each of the 32 query tokens, you find a document token that has a cosine similarity of 1. You add them up, and the maximum similarity is 32, the length of the query. That’s what they’re saying by the maximum MaxSim is the length of the query. Assuming that as your query gets longer, the meaning of the tokens starts to vary, and potentially the maximum similarity between the query and document tokens starts to vary.</p>
<p>You can imagine that you could have a very long query where one or more tokens are kind of obscure and may be on the fringes of the intent and meaning of the whole query, and potentially dissimilar to any document in the collection. These will potentially have a very small maximum similarity with some document token. In this situation, you can imagine that you have a very high variance because some query tokens will have high maximum similarities, some will have low, and you get this kind of noisy distribution of similarities across the query.</p>
<p>They go on to say that normalization can’t be something like the mean over query tokens, but has to be related to the distribution. Why does Antoine say that there is no query expansion? We’ll see that in the next tweet.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
btw let's rule out query expansion because I am training models using flash attention and so there isn't any query expansion (I keep forgetting ffs 😭)
</p>
— Antoine Chaffin (<span class="citation" data-cites="antoine_chaffin">@antoine_chaffin</span>) <a href="https://twitter.com/antoine_chaffin/status/1942969244183834786?ref_src=twsrc%5Etfw">July 9, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This will make more sense after we look at query expansion/augmentation later in this blog post. Basically, query expansion relies on masked tokens containing semantic meaning, but, IIUC, Flash Attention negates masked tokens, so it nullifies the interaction between masked tokens and other tokens.</p>
<p>Here’s a tweet from Antoine 9 months ago that explains this:</p>
<blockquote class="twitter-tweet blockquote" data-theme="dark">
<p lang="en" dir="ltr">
</p><p>Funny insight:<br><br>ColBERT query expansion works by adding tokens that are not attended but attend to the others <br><br>This works in the OG attention implementation with attention mask (as the attention values are computed for these tokens, their contributions are just masked out for the other tokens, but their representations are computed w.r.t the unmasked tokens)</p>
<p>However, with Flash Attention, masked tokens embeddings are just zeros, meaning the contribution to MaxSim is always zeros and these tokens are not used, as if there was no query expansion at all</p>
This might explain Jina-ColBERT results of attending vs not attending to those (which seems contrary to our results): if they activated FA during the tests, the comparaison is actually no query expansion vs query expansion with attending, not not attending vs attending
<p></p>
— Antoine Chaffin (<span class="citation" data-cites="antoine_chaffin">@antoine_chaffin</span>) <a href="https://twitter.com/antoine_chaffin/status/1862059400271389138?ref_src=twsrc%5Etfw">November 28, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Here is a slide from a previous video that I made titled <a href="https://youtu.be/u_v6HHyv4No?feature=shared">“Understanding Eager Bidirectional Attention via the Attention Mask”</a>. In this case, we have 16 tokens, including four masked tokens. The large 16x16 tensor at the bottom is the attention scores tensor. The masked tokens are correctly not being attended to, but they do attend to other tokens. The last four columns are set to negative infinity because they are masked tokens, so their attention scores will be zero. But the last four rows do contain some 1s. The attention scores will not be zero for those rows and columns where we have 1s. Masked tokens are not being attended to, but they do attend to other tokens, and therefore they do have an attention score, and therefore they will have hidden states in the embedding space.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="16x16 attention mask"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/2.png" class="img-fluid figure-img" alt="16x16 attention mask"></a></p>
<figcaption>16x16 attention mask</figcaption>
</figure>
</div>
<p>Back to Omar’s thread.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
OK, but how can ColBERT search 100M docs in ~100 milliseconds?<br><br>Late interaction is pruning-capable: it only needs to "touch" &lt; 0.1% of the documents to find the top-K.<br><br>This is by design: it's composed of monotonic functions (Max/Sum), which enable some neat algorithmic tricks.
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804980840182079?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-theme="dark">
<p lang="en" dir="ltr">
We can decompose late interaction into dozens of tiny nearest-neighbor searches, at the token level.<br><br>We'll only fetch &amp; score docs in which at least one token in close to (at least one token in) the query.<br><br>Otherwise, we can prove the score will be too small, and we can skip it! <a href="https://t.co/6vBZp1U0Ku">pic.twitter.com/6vBZp1U0Ku</a>
</p>
— Omar Khattab (<span class="citation" data-cites="lateinteraction">@lateinteraction</span>) <a href="https://twitter.com/lateinteraction/status/1736804982949917032?ref_src=twsrc%5Etfw">December 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>As shown in the diagram, we have clusters of document token embeddings, clustered by some vector-similarity indexing process. For each query token embedding, we find the closest few clusters to it. We perform our MaxSim operation between the query tokens and all those clustered documents’ tokens. With this initial clustering step, we’re filtering out low-relevance documents using nearest neighbor search from the start.</p>
<p>With these main takeaways under our belt, in the following sections we’ll walk through each part of the ColBERTv1 paper in detail. I’ll provide excerpts from the paper in block quotes (highlighted emphasis mine) and then my thoughts after that.</p>
</section>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<blockquote class="blockquote">
<p>To tackle this, we present ColBERT, a novel ranking model that adapts deep LMs (in particular, BERT) for efficient retrieval. ColBERT introduces a <mark>late interaction architecture that independently encodes the query and the document using BERT</mark> and then employs a <mark>cheap yet powerful interaction step that models their fine-grained similarity.</mark> By delaying and yet retaining this fine-granular interaction, ColBERT can leverage the expressiveness of deep LMs while simultaneously gaining the ability to <mark>pre-compute document representations offine</mark>, considerably speeding up query processing. Beyond reducing the cost of re-ranking the documents retrieved by a traditional model, ColBERT’s <mark>pruning-friendly interaction mechanism</mark> enables leveraging vector-similarity indexes for end-to-end retrieval directly from a large document collection. We extensively evaluate ColBERT using two recent passage search datasets. Results show that ColBERT’s effectiveness is competitive with existing BERT-based models (and outperforms every non-BERT baseline), while executing <mark>two orders-of-magnitude faster and requiring four orders-of-magnitude fewer FLOPs per query</mark>.</p>
</blockquote>
<p>The key part about late interaction is that the architecture independently encodes the query and document. This allows you to index document representations offline which allows you to delay the query-document interaction until the end of the architecture.</p>
<p>What took me some unpacking is the line: &gt; ColBERT’s pruning-friendly interaction mechanism enables leveraging vector-similarity indexes for end-to-end retrieval directly from a large document collection.</p>
<p>IIUC, the pruning-friendliness of ColBERT is unlocked by the fact that the interaction mechanism uses <strong>maximum</strong> similarity, and because of the nature of maximum (i.e.&nbsp;only 1 token can satisfy maximum) you can ignore low-similarity documents. Vector similarity indexes group together documents by similarity, so if a cluster of documents is not close to the query token embedding in question, it can be ignored completely.</p>
</section>
<section id="background-neural-rankers" class="level2">
<h2 class="anchored" data-anchor-id="background-neural-rankers">Background: Neural Rankers</h2>
<p>On the terms “ranker” vs.&nbsp;“retriever” and what that brings up or me:</p>
<p>The terms Ranker and Retriever give me different mental images.</p>
<p>When I think of Ranker, I think of you already having some passages that are deemed relevant and you’re ranking them, bringing the best ones to the top.</p>
<p>When I think of Retriever, the mental image I have is that you have this collection of data documents, a corpus of text where you have irrelevant and relevant passages all mixed together. The retriever then goes in, sifts through this text, and finds the relevant passages.</p>
<p>It’s been a bit of an adjustment for me using these two as synonyms. So that’s something I just want to keep in mind as I’m reading literature is that Ranker and Retriever should give me the same mental image, but they don’t.</p>
<blockquote class="blockquote">
<p><mark>By computing deeply-contextualized semantic representations of query-document pairs, these LMs help bridge the pervasive vocabulary mismatch [21, 42] between documents and queries [30].</mark></p>
</blockquote>
<p>I wanted to highlight this sentence from the background section because I thought it was getting to the core of something about BERT that I didn’t really know. We’ll see in a bit. But first–</p>
<p>The following excerpt is from the paper Modeling and Solving Term Mismatch for Full-Text Retrieval Which is reference [42], written in 2012:</p>
<blockquote class="blockquote">
<p>Even though modern retrieval systems typically use a multitude of features to rank documents, the backbone for search ranking is usually the standard tf.idf retrieval models.</p>
<p>This thesis addresses a limitation of the fundamental retrieval models, the term mismatch problem, which happens when query terms fail to appear in the documents that are relevant to the query. The term mismatch problem is a long standing problem in information retrieval.</p>
</blockquote>
<p>I haven’t read the full thesis, but it does make sense that for keyword-based search, the query term failing to appear in the document that is relevant to the query would be a major problem as it’s frequency in the document would be 0.</p>
<p>Another paper referenced on this vocabulary mismatch problem is “Understanding the Behaviors of BERT and Ranking” where they say:</p>
<blockquote class="blockquote">
<p>The observations suggest that, BERT’s pre-training on surrounding contexts favors text sequence pairs that are closer in their semantic meaning.</p>
</blockquote>
<p>So, it seems like even in the embedding space, the term mismatch problem is present. Another excerpt from the same paper:</p>
<blockquote class="blockquote">
<p>[BERT] prefers semantic matches between paraphrase tokens</p>
</blockquote>
<p>Here’s Figure 2 from the same paper where each point on the chart corresponds to one query-passage pair with a random regular term removed from the passage:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Figure 2 from “Understanding the Behaviors of BERT and Ranking”"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/3.png" class="img-fluid figure-img" alt="Figure 2 from “Understanding the Behaviors of BERT and Ranking”"></a></p>
<figcaption>Figure 2 from “Understanding the Behaviors of BERT and Ranking”</figcaption>
</figure>
</div>
<p>The x-axis is the original ranking score, and the y-axis is the score after the term is removed. One takeaway they had in the paper is that BERT in general has extreme scores. It either scores 1 or 0. But that’s not the main take away here when it comes to the concept of query-document-term mismatch. In the bottom right corner of the BERT chart, we can see that there are query-passage pairs with a high orginal ranking score and a low score after a term is removed. The original ranking of 1.0 drops to a ranking of 0.0. This is evidence that the query document term mismatch problem occurs in semantic space as well. If you remove a term that’s semantically similar in the query to the document, then BERT will not recognize the similarity between the two and will give the pair a low ranking score.</p>
<p>Let’s continue a little bit more into the background of neural rankers, but now in the context of how does ColBERT compare to these previous neural architectures?</p>
</section>
<section id="how-does-colbert-compare-to-previous-architectures" class="level2">
<h2 class="anchored" data-anchor-id="how-does-colbert-compare-to-previous-architectures">How does ColBERT compare to previous architectures?</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Figure 2 from ColBERTv1 paper"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/4.png" class="img-fluid figure-img" alt="Figure 2 from ColBERTv1 paper"></a></p>
<figcaption>Figure 2 from ColBERTv1 paper</figcaption>
</figure>
</div>
<p>The small rectangles in this graphic represent words, subwords or tokens. The wider rectangle represent large dimension vectors or representations.</p>
<p>Representation-based Similarity (figure 2a) calculates a single cosine similarity score between a single query embedding and a single document embedding. Query-Document interaction (2b) feeds an interaction matrix with similarity scores between every pair of query-document tokens to a neural net which produces a single final similarity score. BERT (2c), all-to-all interaction, attends each token in the query to all other tokens in the query, and each token in the document to all other tokens in the document, contextualizing each token with all other query/document tokens. From the <a href="https://arxiv.org/pdf/1901.04085">Passage Re-Ranking with BERT paper</a>:</p>
<blockquote class="blockquote">
<p>We use a BERT_LARGE model as a binary classification model, that is, we use the [CLS] vector as input to a single layer neural network to obtain the probability of the passage being relevant</p>
</blockquote>
<p>Late interaction (2d), ColBERT, combines the best of both worlds: the offline computation of representation-based similarity and the richness/granularity of interaction-based similarity. Query tokens attend to each other during encoding, document tokens attend to each other during (offline) encoding; during interaction, each query token interacts with all document tokens and the document token with the maximum similarity is selected; these maximum similarities are summed across all query tokens, giving you one score per document. Not all documents in the collection need to be considered; vector similarity indexes naturally group relevant documents together. Searching for document token embeddings in clusters close to the query token embeddings reduces the number of candidates considered.</p>
<p>These architectural differences of ColBERT give it a ton of advantages:</p>
<blockquote class="blockquote">
<p>As Figure 1 illustrates, ColBERT can serve queries in tens or few hundreds of milliseconds. For instance, when used for reranking as in “ColBERT (re-rank)”, it delivers over 170× speedup (and requires 14,000× fewer FLOPs) relative to existing BERT-based models, while being more effective than every non-BERT baseline (§4.2 &amp; 4.3). ColBERT’s indexing—the only time it needs to feed documents through BERT—is also practical: it can index the MS MARCO collection of 9M passages in about 3 hours using a single server with four GPUs (§4.5), retaining its effectiveness with a space footprint of as little as few tens of GiBs.</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="5.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure 1 from the ColBERTv1 paper"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/5.png" class="img-fluid figure-img" alt="Figure 1 from the ColBERTv1 paper"></a></p>
<figcaption>Figure 1 from the ColBERTv1 paper</figcaption>
</figure>
</div>
<p>Figure 1 shows that ColBERT has comparable performance to BERT Large and BERT Base but a 100x faster query latency. This is not an insignificant difference, as they say that “raising query response times by as little as 100ms is known to impact user experience and even measurably diminish revenue”. So, it follows that a decrease from 10,000 milliseconds to 100s of milliseconds is going to measurably increase revenue.</p>
<p>One related paper I briefly want to focus on is this 2018 paper by Zamani et al, which introduces SNRM (emphasis mine):</p>
<blockquote class="blockquote">
<p>In 2018, Zamani et al.&nbsp;[41] introduced SNRM, a representationfocused IR model that encodes each query and each document as a single, sparse high-dimensional vector of “latent terms”. By producing a <mark>sparse-vector representation for each document</mark>, SNRM is able to use a traditional IR inverted index for representing documents, allowing fast end-to-end retrieval. Despite highly promising results and insights, SNRM’s effectiveness is substantially outperformed by the state of the art on the datasets with which it was evaluated (e.g., see [18, 38]). <mark>While SNRM employs sparsity to allow using inverted indexes</mark>, we relax this assumption and compare a (dense) BERT-based representation-focused model against our late-interaction ColBERT in our ablation experiments</p>
</blockquote>
<p>I fed the SNRM paper to Claude Sonnet 4 and asked it to give me an example of sparsity allows the use of an inverted file index:</p>
<blockquote class="blockquote">
<p><strong>Simple SNRM example:</strong></p>
<p><strong>Training produces latent terms like:</strong> - Latent term 47: “sports concepts” - Latent term 203: “technology concepts”</p>
<p><strong>Document representations:</strong> - Doc A (about basketball): [0, 0, …, 0.8, 0, …, 0, 0, …] (high weight at position 47) - Doc B (about AI): [0, 0, …, 0, 0, …, 0.9, 0, …] (high weight at position 203)</p>
<p><strong>Inverted index:</strong> - Latent term 47 → [Doc A: 0.8, Doc C: 0.3] - Latent term 203 → [Doc B: 0.9, Doc D: 0.5]</p>
<p><strong>Query time:</strong> Sports query activates latent term 47 → quickly finds Doc A and C without checking every document.</p>
</blockquote>
<p>Let’s say we have two document representations: document A which is about basketball and document B which is about AI. SNRM generates sparse representations, so a number of values are zero. Let’s say that we have a latent term 47 that’s about sports concepts and a latent term 203 that’s about technology concepts. The inverted index for latent term 47 is going to store the value of that term in doc A (which is 0.8) and in doc D (let’s say that’s 0.3). For the latent term 203 (which is technology concepts), the inverted index will store 0.9 for doc B (which is the highest position value) and 0.5 for doc D (which would be some relatively low position). At query time, a sports query activates the latent term for 47, and because that’s efficiently stored in the inverted index, it’s a quick lookup and you don’t have to check every document.</p>
<p>So now that we have a sense of where the ColBERT architecture falls in the context of previous work, we can now dive into the ColBERT architecture itself.</p>
</section>
<section id="the-colbert-architecture" class="level2">
<h2 class="anchored" data-anchor-id="the-colbert-architecture">The ColBERT Architecture</h2>
<blockquote class="blockquote">
<p>delaying the query–document interaction can facilitate cheap neural re-ranking (i.e., through pre-computation) and even support practical end-to-end neural retrieval (i.e., through pruning via vector-similarity search)</p>
</blockquote>
<p>ColBERT balances neural retrieval quality and cost, benefiting both re-ranking and end-to-end retrieval. The delayed query-document interaction enables offline document indexing. At query time, you only encode the query and run MaxSim operations. For end-to-end retrieval, this same offline indexing allows vector similarity clustering—instead of searching all documents, you query the closest clusters, dramatically reducing candidates.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="6.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Figure 3 from the ColBERTv1 paper: the general architecture of ColBERT given a query q and a document d"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/6.png" class="img-fluid figure-img" alt="Figure 3 from the ColBERTv1 paper: the general architecture of ColBERT given a query q and a document d"></a></p>
<figcaption>Figure 3 from the ColBERTv1 paper: the general architecture of ColBERT given a query q and a document d</figcaption>
</figure>
</div>
<p>The general architecture of ColBERT, comprises of: a query encoder fQ (shown in green), a document encoder fD (shown in blue), and the late interaction mechanism S(shown in gray). Given a query q and document d, fQ encodes q into a bag of embeddings Eq while fD encodes d into another bag Ed. Each embeddings in Eq and Ed is contextualized based on the other terms in q or d, respectively.</p>
<p>Before we look at the Late Interaction Mechanism, let’s look closer at what is involved during the encoding of queries and documents.</p>
</section>
<section id="encoding-queries-and-documents" class="level2">
<h2 class="anchored" data-anchor-id="encoding-queries-and-documents">Encoding Queries and Documents</h2>
<blockquote class="blockquote">
<p>We share a single BERT model among our query and document encoders but distinguish input sequences that correspond to queries and documents by prepending a special token [Q] to queries and another token [D] to documents.</p>
</blockquote>
<blockquote class="blockquote">
<p>Given BERT’s representation of each token, our encoder passes the contextualized output representations through a linear layer with no activations. This layer serves to control the dimension of ColBERT’s embeddings, producing m-dimensional embeddings for the layer’s output size m. As we discuss later in more detail, we typically x m to be much smaller than BERT’s xed hidden dimension.</p>
</blockquote>
<blockquote class="blockquote">
<p>While ColBERT’s embedding dimension has limited impact on the efficiency of query encoding, this step is crucial for controlling the space footprint of documents</p>
</blockquote>
<p>A quick note about embedding dimension: there are models such as <a href="https://huggingface.co/answerdotai/answerai-colbert-small-v1">answerai-colbert-small-v1</a> where the embedding dimension is as small as 96.</p>
<p>Here’s the desription of the query encoder:</p>
<blockquote class="blockquote">
<p><strong>Query Encoder.</strong> Given a textual query q, we tokenize it into its BERT-based WordPiece [35] tokens q1, q2…ql . We prepend the token [Q] to the query. We place this token right after BERT’s sequence-start token [CLS]. If the query has fewer than a pre-defined number of tokens Nq , <mark>we pad it with BERT’s special [mask] tokens up to length Nq</mark> (otherwise, we truncate it to the first Nq tokens). This padded sequence of input tokens is then passed into BERT’s deep transformer architecture, which computes a contextualized representation of each token.</p>
</blockquote>
<p>Here is a key contribution of this paper, that I am going to do a dive into next:</p>
<blockquote class="blockquote">
<p>We denote the padding with masked tokens as <strong>query augmentation</strong>, a step that allows BERT to produce query-based embeddings at the positions corresponding to these masks. Query augmentation is intended to serve as a <mark>soft, differentiable mechanism for learning to expand queries with new terms or to re-weigh existing terms based on their importance for matching the query</mark>. As we show in §4.4, this operation is essential for ColBERT’s effectiveness.</p>
</blockquote>
<section id="query-augmentation" class="level3">
<h3 class="anchored" data-anchor-id="query-augmentation">Query Augmentation</h3>
<p>Query augmentation is the idea that mask tokens carry semantic meaning, so padding short queries up to some fixed length expands the queries with these new semantically relevant terms, adding more nuance to help match similar terms in documents. In this side quest, I want to understand just how semantically similar these mask token embeddings are to the non-mask query tokens. I’ll start by digging into the code in the repo which takes text and converts it to embeddings.</p>
<p>Here’s how the <code>Searcher</code> encodes the query, where it uses <code>queryFromText</code></p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> encode(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, text: TextQueries, full_length_search<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb3-2">    queries <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> text <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(text) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> [text]</span>
<span id="cb3-3">    bsize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(queries) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb3-4"></span>
<span id="cb3-5">    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.checkpoint.query_tokenizer.query_maxlen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config.query_maxlen</span>
<span id="cb3-6">    Q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.checkpoint.queryFromText(queries, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>bsize, to_cpu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, full_length_search<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>full_length_search)</span>
<span id="cb3-7"></span>
<span id="cb3-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Q</span></code></pre></div>
<div id="cell-88" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="37d9aab6-94cb-4de6-fcf1-f5a8e2827de4" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">checkpoint.query_tokenizer.query_maxlen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span></span>
<span id="cb4-2">Q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.queryFromText([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"this is a short query"</span>], bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, to_cpu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, full_length_search<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast() if self.activated else NullContextManager()</code></pre>
</div>
</div>
<div id="cell-89" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f66d2856-acc2-454d-911b-3f3b98324759" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">Q.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>torch.Size([1, 32, 96])</code></pre>
</div>
</div>
<p>Note that even though there are less than 32 tokens in <code>"this is a short query"</code>, the norm of all <code>Q</code> embeddings is <code>1.0</code>. This is because ColBERT adds <code>[MASK]</code> tokens to pad the query to a 32-token length, which we’ll see next.</p>
<div id="cell-91" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b21a9f43-389e-4837-bb58-ef047821bddb" data-execution_count="199">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">Q.norm(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="199">
<pre><code>tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,
         1.0000, 1.0000, 1.0000, 1.0000, 1.0000]])</code></pre>
</div>
</div>
<p><code>checkpoint.queryFromText</code> uses <code>QueryTokenizer.tokenizer</code> which does the following:</p>
<p>It first tokenizes the text</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># tokenize with max_length - 1 to add the marker id afterwards</span></span>
<span id="cb10-2">obj <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tok(batch_text, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_length'</span>, truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb10-3">                return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pt'</span>, max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(max_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)).to(DEVICE)</span>
<span id="cb10-4"></span>
<span id="cb10-5">ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.Q_marker_token_id)</span>
<span id="cb10-6">mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<p>And then replaces the padding token with the mask token.</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># postprocess for the [MASK] augmentation</span></span>
<span id="cb11-2">ids[ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.pad_token_id] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mask_token_id</span></code></pre></div>
<p>Looking at that concretely:</p>
<div id="cell-94" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">obj <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.query_tokenizer.tok([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"this is a short query"</span>], padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'max_length'</span>, truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb12-2">                return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pt'</span>, max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb12-3"></span>
<span id="cb12-4">ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>], checkpoint.query_tokenizer.Q_marker_token_id)</span>
<span id="cb12-5">mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
</div>
<div id="cell-95" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="6d429500-8377-4845-c844-08099e97adcc" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">ids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([[  101,     1,  2023,  2003,  1037,  2460, 23032,   102,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,
             0,     0]])</code></pre>
</div>
</div>
<div id="cell-96" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="14e03a64-ea80-4a01-db59-1d2dc156355a" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">ids[ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> checkpoint.query_tokenizer.pad_token_id] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> checkpoint.query_tokenizer.mask_token_id</span>
<span id="cb15-2">ids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([[  101,     1,  2023,  2003,  1037,  2460, 23032,   102,   103,   103,
           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
           103,   103]])</code></pre>
</div>
</div>
<div id="cell-97" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:35}}" data-outputid="7d24afd2-b0ea-4f04-a1bf-ad826c24ce00" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">checkpoint.query_tokenizer.tok.decode([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">103</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>'[MASK]'</code></pre>
</div>
</div>
<div id="cell-98" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:71}}" data-outputid="900df54d-3ce7-428a-d888-c7cd3023214d" data-execution_count="19">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">checkpoint.query_tokenizer.tok.decode(ids[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>'[CLS] [unused0] this is a short query [SEP] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]'</code></pre>
</div>
</div>
<p>This replacement of pad tokens with mask tokens is critical because <code>queryFromText</code> calls <code>query</code> which is defined as:</p>
<div class="sourceCode" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> query(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, input_ids, attention_mask):</span>
<span id="cb21-2">    input_ids, attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> input_ids.to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device), attention_mask.to(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device)</span>
<span id="cb21-3">    Q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.bert(input_ids, attention_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>attention_mask)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb21-4">    Q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.linear(Q)</span>
<span id="cb21-5"></span>
<span id="cb21-6">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.mask(input_ids, skiplist<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[]), device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.device).unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>()</span>
<span id="cb21-7">    Q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> mask</span>
<span id="cb21-8"></span>
<span id="cb21-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.nn.functional.normalize(Q, p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<p>It actually creates its own <code>mask</code> to multiply <code>Q</code> by—it doesn’t use <code>attention_mask</code>.</p>
<p>Looking at <code>mask</code>:</p>
<div id="cell-102" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f57d4111-5908-4afa-8094-80164a8f80af" data-execution_count="20">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(getsource(checkpoint.mask))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    def mask(self, input_ids, skiplist):
        mask = [[(x not in skiplist) and (x != self.pad_token) for x in d] for d in input_ids.cpu().tolist()]
        return mask
</code></pre>
</div>
</div>
<p>If the token is <code>not in skiplist</code> and <code>!= self.pad_token</code> it gets a <code>1</code> in the <code>mask</code>. Since we swapped pad tokens with MASK tokens, they get a <code>1</code>.</p>
<div id="cell-104" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c8d1cd3a-ee95-43f9-f43f-0ceffc6c2aaa" data-execution_count="21">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">ids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor([[  101,     1,  2023,  2003,  1037,  2460, 23032,   102,   103,   103,
           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
           103,   103]])</code></pre>
</div>
</div>
<div id="cell-105" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="99bb7805-01f9-43be-f484-4bfd3e7a088c" data-execution_count="24">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">torch.tensor(checkpoint.mask(ids, skiplist<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[])).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])</code></pre>
</div>
</div>
<p>As we can see, the <code>mask</code> is all <code>1</code>s, so <code>Q</code> remains unchanged.</p>
<p>As an aside, I’ve been thinking about how RAGatouille sets the maximum query length based on the full query length (instead of fixing to 32):</p>
<div class="sourceCode" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(query, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>):</span>
<span id="cb28-2">    query_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(query.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" "</span>)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.35</span>)</span>
<span id="cb28-3">    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._upgrade_searcher_maxlen(query_length, base_model_max_tokens)</span>
<span id="cb28-4">    results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._search(query, k, pids)]</span>
<span id="cb28-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb28-6">    longest_query_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>([<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(x.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" "</span>)) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.35</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> query])</span>
<span id="cb28-7">    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._upgrade_searcher_maxlen(longest_query_length, base_model_max_tokens)</span>
<span id="cb28-8">    results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._batch_search(query, k)</span></code></pre></div>
<p>I think the following note about <code>full_length_search</code> in the ColBERT repo is related but I’m not currently sure:</p>
<div class="sourceCode" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Full length search is only available for single inference (for now)</span></span>
<span id="cb29-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Batched full length search requires far deeper changes to the code base</span></span>
<span id="cb29-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span>(full_length_search <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> (<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(batch_text) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(batch_text) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb29-4"></span>
<span id="cb29-5"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> full_length_search:</span>
<span id="cb29-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Tokenize each string in the batch</span></span>
<span id="cb29-7">    un_truncated_ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tok(batch_text, add_special_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>).to(DEVICE)[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>]</span>
<span id="cb29-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the longest length in the batch</span></span>
<span id="cb29-9">    max_length_in_batch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(x) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> un_truncated_ids)</span>
<span id="cb29-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the max length</span></span>
<span id="cb29-11">    max_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.max_len(max_length_in_batch)</span>
<span id="cb29-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb29-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Max length is the default max length from the config</span></span>
<span id="cb29-14">    max_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.query_maxlen</span></code></pre></div>
</section>
<section id="mask-token-embeddings-are-not-meaningless" class="level3">
<h3 class="anchored" data-anchor-id="mask-token-embeddings-are-not-meaningless"><code>MASK</code> token embeddings are not meaningless</h3>
<p>So what meaning is embedded for the MASK token in the semantic space? To (lightly) explore this, I’ll calculate the cosine similarity between the non-MASK and MASK tokens.</p>
<div id="cell-110" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1d97c78d-80f4-426d-9feb-7aaa3f8dcd15" data-execution_count="25">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">ids[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([  101,     1,  2023,  2003,  1037,  2460, 23032])</code></pre>
</div>
</div>
<div id="cell-111" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:35}}" data-outputid="55585a26-af0a-4b64-8453-102cc78da962" data-execution_count="26">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">checkpoint.query_tokenizer.tok.decode(ids[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>'[CLS] [unused0] this is a short query'</code></pre>
</div>
</div>
<div id="cell-112" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:35}}" data-outputid="9e6e1ed8-eca4-4a74-b2da-f98270723158" data-execution_count="32">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">checkpoint.query_tokenizer.tok.decode([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2460</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">23032</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>'short query'</code></pre>
</div>
</div>
<div id="cell-113" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="620147a3-0f6b-4a41-cd88-120864057e16" data-execution_count="27">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">ids[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>:]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103,
        103, 103, 103, 103, 103, 103, 103, 103, 103, 103])</code></pre>
</div>
</div>
<div id="cell-114" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:53}}" data-outputid="91f261b2-0a15-4150-cf9d-58c6933c3069" data-execution_count="28">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">checkpoint.query_tokenizer.tok.decode(ids[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>:])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>'[MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK]'</code></pre>
</div>
</div>
<p>Gathering the 96-dimensional embeddings for my non-MASK tokens.</p>
<div id="cell-116" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="249a17b0-4f81-4171-84a9-dc10719f7f0a" data-execution_count="29">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">Qnm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Q[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>]</span>
<span id="cb40-2">Qnm.shape, Qnm.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>(torch.Size([7, 96]), torch.Size([1, 7, 96]))</code></pre>
</div>
</div>
<p>Gathering the 96-dimensional embeddings for my MASK tokens.</p>
<div id="cell-118" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f68d9c1b-3b29-4da5-e522-dcd4e2a19cee" data-execution_count="30">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">Qm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Q[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">7</span>:]</span>
<span id="cb42-2">Qm.shape, Qm.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>(torch.Size([25, 96]), torch.Size([25, 1, 96]))</code></pre>
</div>
</div>
<p>Taking the cosine similarity between the non-MASK and MASK tokens, we see that the MASK tokens (rows) are considerably similar in meaning (and in one case exactly the same) to the non-MASK tokens (columns)!</p>
<div id="cell-120" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="fbf9c790-8b74-49db-e9a9-248b313bf574" data-execution_count="31">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">torch.nn.functional.cosine_similarity(Qnm.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>), Qm.unsqueeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>), dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor([[1.0000, 0.9709, 0.9150, 0.9461, 0.9672, 0.7417, 0.6532],
        [0.9793, 0.9566, 0.9038, 0.9301, 0.9495, 0.7177, 0.6400],
        [0.9804, 0.9585, 0.9053, 0.9320, 0.9517, 0.7195, 0.6380],
        [0.9814, 0.9604, 0.9059, 0.9340, 0.9534, 0.7198, 0.6394],
        [0.9812, 0.9598, 0.9065, 0.9342, 0.9533, 0.7220, 0.6390],
        [0.9814, 0.9601, 0.9073, 0.9355, 0.9537, 0.7223, 0.6341],
        [0.9816, 0.9612, 0.9068, 0.9367, 0.9549, 0.7222, 0.6354],
        [0.9809, 0.9604, 0.9050, 0.9357, 0.9535, 0.7212, 0.6333],
        [0.9823, 0.9623, 0.9064, 0.9385, 0.9562, 0.7228, 0.6365],
        [0.9826, 0.9629, 0.9070, 0.9389, 0.9567, 0.7249, 0.6373],
        [0.9818, 0.9614, 0.9062, 0.9387, 0.9554, 0.7248, 0.6390],
        [0.9819, 0.9608, 0.9044, 0.9387, 0.9550, 0.7241, 0.6388],
        [0.9821, 0.9620, 0.9032, 0.9394, 0.9561, 0.7252, 0.6372],
        [0.9830, 0.9655, 0.9048, 0.9428, 0.9601, 0.7278, 0.6390],
        [0.9836, 0.9690, 0.9081, 0.9459, 0.9632, 0.7273, 0.6392],
        [0.9860, 0.9761, 0.9165, 0.9517, 0.9717, 0.7343, 0.6475],
        [0.9850, 0.9848, 0.9299, 0.9542, 0.9805, 0.7550, 0.6576],
        [0.9805, 0.9872, 0.9360, 0.9545, 0.9827, 0.7667, 0.6658],
        [0.9780, 0.9878, 0.9385, 0.9544, 0.9833, 0.7705, 0.6693],
        [0.9774, 0.9879, 0.9389, 0.9543, 0.9832, 0.7701, 0.6699],
        [0.9764, 0.9887, 0.9397, 0.9549, 0.9839, 0.7709, 0.6731],
        [0.9762, 0.9887, 0.9394, 0.9548, 0.9838, 0.7714, 0.6736],
        [0.9763, 0.9885, 0.9396, 0.9548, 0.9837, 0.7715, 0.6738],
        [0.9776, 0.9881, 0.9392, 0.9551, 0.9837, 0.7709, 0.6713],
        [0.9772, 0.9887, 0.9400, 0.9555, 0.9840, 0.7714, 0.6736]])</code></pre>
</div>
</div>
<p>It’s interesting to note that the first MASK token (first row) has a cosine similarity of 1 with the first non-MASK token (the <code>[CLS]</code> tokens, first column). Other interesting observations:</p>
<ul>
<li>the second non-MASK token (<code>[unused0]</code>, second column) is more similar to the last MASK token than most of the other MASK tokens.</li>
<li>In general, the MASK tokens are much less similar to the last two non-MASK token (<code>short query</code>, 6th and 7th columns) than they are to the first five non-MASK tokens.</li>
</ul>
<p>I think this is enough evidence to show that the MASK tokens carry semantic meaning important to the query.</p>
<p>Returning to the paper, let’s see what they have to say about the document encoder:</p>
<blockquote class="blockquote">
<p><strong>Document Encoder</strong>. Our document encoder has a very similar architecture. We first segment a document d into its constituent tokens d1, d2…dm, to which we prepend BERT’s start token [CLS] followed by our special token [D] that indicates a document sequence. <mark>Unlike queries, we do not append [mask] tokens to documents</mark>. After passing this input sequence through BERT and the subsequent linear layer, the document encoder filters out the embeddings corresponding to punctuation symbols, determined via a pre-defined list. This filtering is meant to reduce the number of embeddings per document, as we hypothesize that (even contextualized) embeddings of punctuation are unnecessary for effectiveness. In summary, given q = q0, q1…ql and d = d0, d1…dn , we compute the bags of embeddings Eq and Ed in the following manner, where # refers to the [mask] tokens:</p>
<p>Eq := Normalize( CNN( BERT(“[Q]q0q1…ql ##…#”) ) ) (1)</p>
<p>Ed := Filter( Normalize( CNN( BERT(“[D]d0d1…dn”) ) ) ) (2)</p>
</blockquote>
<p>I want to highlight something they say about how they encode their documents:</p>
<blockquote class="blockquote">
<p>When batching, <mark>we pad all documents to the maximum length of a document within the batch</mark>. To make capping the sequence length on a per-batch basis more effective, our indexer proceeds through documents in groups of B (e.g., B = 100,000) documents. <mark>It sorts these documents by length</mark> and then feeds batches of b (e.g., b = 128) <mark>documents of comparable length</mark> through our encoder.</p>
</blockquote>
<p>So let’s look at some of the code. In the <code>CollectionEncoder</code> class, which is what’s used to encode documents and queries, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/indexing/collection_encoder.py#L26">they call <code>docFromText</code></a> and they pass to it the passages which are currently strings:</p>
<div class="sourceCode" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> passages_batch <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> batch(passages, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config.index_bsize <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>):</span>
<span id="cb46-2">    embs_, doclens_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.checkpoint.docFromText(</span>
<span id="cb46-3">        passages_batch,</span>
<span id="cb46-4">        ...)</span></code></pre></div>
<p>Inside <code>docFromText</code>, the document tokenizer’s <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/checkpoint.py#L138"><code>tensorize</code> method is called</a>, and you pass to it the documents which are still strings:</p>
<div class="sourceCode" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> bsize:</span>
<span id="cb47-2">    text_batches, reverse_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.doc_tokenizer.tensorize(</span>
<span id="cb47-3">        docs, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>bsize</span>
<span id="cb47-4">    )</span></code></pre></div>
<p>And then <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/tokenization/doc_tokenization.py#L48">inside <code>DocTokenizer.tensorize</code></a>, you first convert the text into tokens. And then you pass those tokens into the <code>_sort_by_length</code> helper method:</p>
<div class="sourceCode" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> tensorize(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, batch_text, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb48-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(batch_text) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">tuple</span>], (<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(batch_text))</span>
<span id="cb48-3"></span>
<span id="cb48-4">    obj <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.tok(batch_text, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'longest'</span>, truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'longest_first'</span>,</span>
<span id="cb48-5">                    return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pt'</span>, max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.doc_maxlen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)).to(DEVICE)</span>
<span id="cb48-6"></span>
<span id="cb48-7">    ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.D_marker_token_id)</span>
<span id="cb48-8">    mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb48-9"></span>
<span id="cb48-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> bsize:</span>
<span id="cb48-11">        ids, mask, reverse_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _sort_by_length(ids, mask, bsize)</span>
<span id="cb48-12">        batches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _split_into_batches(ids, mask, bsize)</span>
<span id="cb48-13">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> batches, reverse_indices</span>
<span id="cb48-14"></span>
<span id="cb48-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> ids, mask</span></code></pre></div>
<p>And finally, <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/modeling/tokenization/utils.py#L40">inside the <code>_sort_by_length</code> method</a>, it sums the mask in the last dimension, which is the sequence length dimension. Then it sorts it, grabs those indices, and returns the tokens of the passages in order. Using those indices:</p>
<div class="sourceCode" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _sort_by_length(ids, mask, bsize):</span>
<span id="cb49-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> ids.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> bsize:</span>
<span id="cb49-3">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> ids, mask, torch.arange(ids.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>))</span>
<span id="cb49-4"></span>
<span id="cb49-5">    indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mask.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).sort().indices</span>
<span id="cb49-6">    reverse_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> indices.sort().indices</span>
<span id="cb49-7"></span>
<span id="cb49-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> ids[indices], mask[indices], reverse_indices</span></code></pre></div>
<p>They’re summing the mask across the sequence length dimension (<code>mask.sum(-1)</code>). The mask contains 1s where you have non-padding tokens and 0s where you have padding tokens. So the sum of the mask across a sequence is the number of non-padding tokens in it. Sorting by this sum sorts the sequences by non-padding token length in ascending order.</p>
<p>Let’s look at this concretely through code.</p>
</section>
<section id="sorting-documents-by-length-for-batching" class="level3">
<h3 class="anchored" data-anchor-id="sorting-documents-by-length-for-batching">Sorting Documents by Length for Batching</h3>
<p>To better understand how ColBERT sorts documents by length for batching, I’m going to walk through a toy example using the internal methods provided in the repo.</p>
<p>I’ll start by intentionally creating a list of passages of four different lengths: 40, 60, 80, and 100</p>
<div id="cell-133" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">passages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb50-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>):</span>
<span id="cb50-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>: passages.append(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb50-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>: passages.append(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>)</span>
<span id="cb50-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>: passages.append(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>)</span>
<span id="cb50-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>: passages.append(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>)</span></code></pre></div>
</div>
<p>I now pass the passages with a bat size of 32 into the Checkpoints.DocFromText method, and as a result, I get encoded documents where the bat size is 128, the maximum document length is 103, and the embedding dimension is 96 because I’m using answerai-colbert-small-v1.</p>
<div id="cell-135" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="68ad41b5-0de8-47c5-a676-37ecdf8bc6db" data-execution_count="5">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ce.checkpoint.docFromText(docs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>passages, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.11/dist-packages/colbert/utils/amp.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast() if self.activated else NullContextManager()</code></pre>
</div>
</div>
<div id="cell-136" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1414b4c2-4f36-407c-b617-2b1e08a96169" data-execution_count="6">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">res[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>torch.Size([128, 103, 96])</code></pre>
</div>
</div>
<p>If we look one level deeper, inside docfromtext it calls the docTokenizer’s tensorize method which converts the string of text into tokens</p>
<div id="cell-138" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">text_batches, reverse_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ce.checkpoint.doc_tokenizer.tensorize(passages, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>)</span></code></pre></div>
</div>
<div id="cell-139" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1880f14a-a499-48af-a232-1866041700f1" data-execution_count="8">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1">text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>torch.Size([32, 103])</code></pre>
</div>
</div>
<div id="cell-140" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="eb4ab00f-7d27-4e08-f589-29937da66e0c" data-execution_count="10">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">text_batches[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor([ 101,    2, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037,
        1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037,
        1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037, 1037,
        1037, 1037, 1037, 1037, 1037, 1037,  102,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0], device='cuda:0')</code></pre>
</div>
</div>
<p>Taking a look at the number of tokens in each of the batch items.</p>
<div id="cell-142" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1c30db69-0973-428c-8334-db7e12190cce" data-execution_count="11">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>]:</span>
<span id="cb60-2">    obj <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ce.checkpoint.doc_tokenizer.tok(passages[i], padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'longest'</span>, truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'longest_first'</span>,</span>
<span id="cb60-3">                       return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pt'</span>, max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(ce.checkpoint.doc_tokenizer.doc_maxlen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb60-4">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>].shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 102])
torch.Size([1, 82])
torch.Size([1, 62])
torch.Size([1, 42])</code></pre>
</div>
</div>
<p><code>tensorize</code> adds the <code>[Q]</code> or <code>[D]</code> token, so that’s why the first batch item only has 102 tokens, whereas after Tensorize, it has 103 tokens.</p>
<p>Before I run the rest of the sorting code, I’m going to shuffle the passages so that we can see if sorting actually takes place.</p>
<div id="cell-145" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1">random.shuffle(passages)</span></code></pre></div>
</div>
<div id="cell-146" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1d2981e8-e3eb-4cf4-9e2d-477bc4d8b4f4" data-execution_count="14">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> o <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> passages[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>]: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(o))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>80
120
80
80
160
80
160
160
120
200</code></pre>
</div>
</div>
<p>When passing all of the passages to the <code>.tok</code> method, the tokenized batch has a number of tokens equal to the largest, longest passage. All 128 passages are tokenized up to a length of 102.</p>
<div id="cell-148" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="91d5a4ed-20e5-4e49-c275-63186d596371" data-execution_count="15">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1">obj <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ce.checkpoint.doc_tokenizer.tok(passages, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'longest'</span>, truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'longest_first'</span>,</span>
<span id="cb65-2">                       return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pt'</span>, max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(ce.checkpoint.doc_tokenizer.doc_maxlen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb65-3">obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>torch.Size([128, 102])</code></pre>
</div>
</div>
<p>Here’s the step where we add the prefixed tokens for the documents, which is <code>[D]</code>.</p>
<div id="cell-150" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1">ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>], ce.checkpoint.doc_tokenizer.D_marker_token_id)</span>
<span id="cb67-2">mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
</div>
<div id="cell-151" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e9702bae-2d9f-4243-d67e-6493a571f295" data-execution_count="17">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1">ids.shape, mask.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>(torch.Size([128, 103]), torch.Size([128, 103]))</code></pre>
</div>
</div>
<p>Looking at the number of non-zero tokens in the batch (i.e., the non-padding tokens), we can see that our batch is still currently unsorted</p>
<div id="cell-153" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="fbe6f4d0-b7ee-4ccb-a64a-91cba295e447" data-execution_count="18">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb70-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(torch.count_nonzero(ids[i]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(43)
tensor(63)
tensor(43)
tensor(43)
tensor(83)
tensor(43)
tensor(83)
tensor(83)
tensor(63)
tensor(103)</code></pre>
</div>
</div>
<p>Looking at the sum of the masks, we can see that the sum of masks is equal to the number of non-padding tokens in the batch item.</p>
<div id="cell-155" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="51eeac0c-0838-41fa-8d40-413f43fc1f82" data-execution_count="19">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>): <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(mask[i]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(43)
tensor(63)
tensor(43)
tensor(43)
tensor(83)
tensor(43)
tensor(83)
tensor(83)
tensor(63)
tensor(103)</code></pre>
</div>
</div>
<p>Alright, here’s the main part where it sorts by length the batches.</p>
<div id="cell-157" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="54ca1995-bd89-4a39-955d-bc69bdc07331" data-execution_count="20">
<div class="sourceCode cell-code" id="cb74" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1">ids, mask, reverse_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _sort_by_length(ids, mask, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>)</span>
<span id="cb74-2">ids.shape, mask.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>(torch.Size([128, 103]), torch.Size([128, 103]))</code></pre>
</div>
</div>
<p>Looking at the lengths of non-zero values in ids and mask. The items are now sorted by token length in increasing order.</p>
<div id="cell-159" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="942cc8ed-af36-4b59-838a-ccf99c63b13f" data-execution_count="21">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb76-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(torch.count_nonzero(ids[i]), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(mask[i]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)</code></pre>
</div>
</div>
<p>It then splits it into batches of 32. Note that all batches are padded up to the maximum document length.</p>
<div id="cell-161" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb78" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1">batches <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _split_into_batches(ids, mask, bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>)</span></code></pre></div>
</div>
<div id="cell-162" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="5388ec21-f3f5-4c15-c667-582abdd8b2f1" data-execution_count="23">
<div class="sourceCode cell-code" id="cb79" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>): <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(batches[i][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([32, 103])
torch.Size([32, 103])
torch.Size([32, 103])
torch.Size([32, 103])</code></pre>
</div>
</div>
<p>Looking at the lengths of non-zero values in each batch we can see that the batches are now sorted by length of passage.</p>
<div id="cell-164" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1424fa48-3507-4b53-8f82-52ccbd0ad231" data-execution_count="24">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>):</span>
<span id="cb81-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"------ Batch </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>i<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb81-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb81-4">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(torch.count_nonzero(batches[i][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][j]), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(batches[i][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>][j]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>------ Batch 0
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
tensor(43) tensor(43)
------ Batch 1
tensor(63) tensor(63)
tensor(63) tensor(63)
tensor(63) tensor(63)
tensor(63) tensor(63)
tensor(63) tensor(63)
tensor(63) tensor(63)
tensor(63) tensor(63)
tensor(63) tensor(63)
tensor(63) tensor(63)
tensor(63) tensor(63)
------ Batch 2
tensor(83) tensor(83)
tensor(83) tensor(83)
tensor(83) tensor(83)
tensor(83) tensor(83)
tensor(83) tensor(83)
tensor(83) tensor(83)
tensor(83) tensor(83)
tensor(83) tensor(83)
tensor(83) tensor(83)
tensor(83) tensor(83)
------ Batch 3
tensor(103) tensor(103)
tensor(103) tensor(103)
tensor(103) tensor(103)
tensor(103) tensor(103)
tensor(103) tensor(103)
tensor(103) tensor(103)
tensor(103) tensor(103)
tensor(103) tensor(103)
tensor(103) tensor(103)
tensor(103) tensor(103)</code></pre>
</div>
</div>
<p>Now let’s go a layer deeper and look at <code>_sort_by_length</code> to see how the sorting actually happens. I’ll reinstantiate the passages and shuffle them to make sure the sorting actually happens.</p>
<div id="cell-166" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1">passages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb83-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>):</span>
<span id="cb83-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>: passages.append(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb83-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>: passages.append(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80</span>)</span>
<span id="cb83-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>: passages.append(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">60</span>)</span>
<span id="cb83-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>: passages.append(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"a "</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">40</span>)</span></code></pre></div>
</div>
<div id="cell-167" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1">random.shuffle(passages)</span></code></pre></div>
</div>
<p>I’ll also tokenize the passages and insert the prefix tokens.</p>
<div id="cell-169" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b456ac02-a0ec-4535-e5c3-35adcb8a43e7" data-execution_count="27">
<div class="sourceCode cell-code" id="cb85" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1">obj <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ce.checkpoint.doc_tokenizer.tok(passages, padding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'longest'</span>, truncation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'longest_first'</span>,</span>
<span id="cb85-2">                       return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'pt'</span>, max_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(ce.checkpoint.doc_tokenizer.doc_maxlen <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb85-3">obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>torch.Size([128, 102])</code></pre>
</div>
</div>
<div id="cell-170" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1">ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>], ce.checkpoint.doc_tokenizer.D_marker_token_id)</span>
<span id="cb87-2">mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _insert_prefix_token(obj[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>], <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
</div>
<div id="cell-171" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d8ef3186-088e-46b3-c0fe-2fb711f56713" data-execution_count="29">
<div class="sourceCode cell-code" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1">ids.shape, mask.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>(torch.Size([128, 103]), torch.Size([128, 103]))</code></pre>
</div>
</div>
<p>Checking to make sure that my batch is shuffled</p>
<div id="cell-173" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9d2b5d99-f4b1-40a3-f4f4-6610581b7912" data-execution_count="30">
<div class="sourceCode cell-code" id="cb90" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>):</span>
<span id="cb90-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(torch.count_nonzero(ids[i]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(103)
tensor(103)
tensor(43)
tensor(83)
tensor(83)
tensor(103)
tensor(63)
tensor(83)
tensor(43)
tensor(43)</code></pre>
</div>
</div>
<p>To sort the batch items by length of non-padding tokens, they sum the mask across the last dimension, which is the number of tokens.</p>
<div id="cell-175" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="351136c3-ea11-4339-ddd8-297058bc2d4d" data-execution_count="31">
<div class="sourceCode cell-code" id="cb92" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1">mask.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>torch.Size([128, 103])</code></pre>
</div>
</div>
<p>So, what you get here is basically the number of non-padding tokens in each of the 128 items.</p>
<div id="cell-177" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9b928051-0462-461c-907c-d1f39e828bd9" data-execution_count="32">
<div class="sourceCode cell-code" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1">mask.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([103, 103,  43,  83,  83, 103,  63,  83,  43,  43, 103,  83,  43,  83,
         63,  83,  43, 103,  43,  63, 103, 103,  43,  43, 103,  63,  83, 103,
        103, 103, 103,  63,  43,  83,  63,  83,  63, 103,  43,  43,  63,  63,
        103,  43, 103,  43,  63, 103,  43,  43,  63,  63,  83,  63, 103, 103,
         83,  63, 103,  83,  43, 103, 103,  63,  83,  43, 103,  83,  83, 103,
        103,  63,  63,  83,  43,  83,  83,  43,  83,  43, 103,  83, 103,  43,
         83,  83,  43,  63,  63,  63, 103,  63,  43, 103,  83,  63,  63,  43,
         63, 103,  83,  83,  83, 103,  63,  63,  63,  83,  83,  43,  43,  63,
        103,  83,  63,  83,  43,  83,  63,  63,  43,  43,  43,  63, 103,  43,
         83,  43])</code></pre>
</div>
</div>
<p>Then they sort it and get the indices.</p>
<div id="cell-179" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c32564d4-1263-41dd-fa9e-a2e6326b6039" data-execution_count="33">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> mask.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).sort().indices</span>
<span id="cb96-2">indices</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor([ 49,  22,  23, 110, 109,  32,  38,  43,  45,  48,  39,  97,  60,  92,
         65,  86,  83,  74,  79,  77, 121, 127,   2, 125, 122,   8,   9, 116,
        120,  12,  18,  16,  63,  51,  53,  98,  96,  57,  95,  25, 114,  91,
         31,  89,   6,  88,  87, 123,  71,  72,  19, 119,  34, 106,  36, 105,
         14,  50,  40,  41, 104, 118,  46, 111,  64, 107, 126,  81, 108, 115,
         84,  85,  94, 102, 101, 113, 117, 100,  15,  33,  35,  26,  52,  56,
         59,  13,  11,   7,  67,  76,  78,  75,   3,  73,   4,  68,  17,   1,
         20,  21,  24, 124, 112,  27,  28,  29,  10,   5,  93,  80,  82,  70,
         69,  66,   0,  90,  62,  61,  30,  58,  55,  54,  99,  47,  44, 103,
         42,  37])</code></pre>
</div>
</div>
<div id="cell-180" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="110c7559-8e92-4cda-b255-2b6360b377d5" data-execution_count="37">
<div class="sourceCode cell-code" id="cb98" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1">mask[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">49</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(), mask[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">37</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>(tensor(43), tensor(103))</code></pre>
</div>
</div>
<p>If we look at the first index, the corresponding mask sum is 43, which is the smallest non-padding token length. And if we look at the last index, the sum of the mask is 103, which is the largest.</p>
<p>And then they sort these indices and then get the indices of that sort</p>
<div id="cell-183" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4d611ab4-29ea-4cbd-e22a-4833bcd1c8b5" data-execution_count="38">
<div class="sourceCode cell-code" id="cb100" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1">reverse_indices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> indices.sort().indices</span>
<span id="cb100-2">reverse_indices</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([114,  97,  22,  92,  94, 107,  44,  87,  25,  26, 106,  86,  29,  85,
         56,  78,  31,  96,  30,  50,  98,  99,   1,   2, 100,  39,  81, 103,
        104, 105, 118,  42,   5,  79,  52,  80,  54, 127,   6,  10,  58,  59,
        126,   7, 124,   8,  62, 123,   9,   0,  57,  33,  82,  34, 121, 120,
         83,  37, 119,  84,  12, 117, 116,  32,  64,  14, 113,  88,  95, 112,
        111,  48,  49,  93,  17,  91,  89,  19,  90,  18, 109,  67, 110,  16,
         70,  71,  15,  46,  45,  43, 115,  41,  13, 108,  72,  38,  36,  11,
         35, 122,  77,  74,  73, 125,  60,  55,  53,  65,  68,   4,   3,  63,
        102,  75,  40,  69,  27,  76,  61,  51,  28,  20,  24,  47, 101,  23,
         66,  21])</code></pre>
</div>
</div>
<div id="cell-184" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8b07ff83-1783-4921-e11e-131109581342" data-execution_count="39">
<div class="sourceCode cell-code" id="cb102" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1">indices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">114</span>], indices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">97</span>], indices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">22</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>(tensor(0), tensor(1), tensor(2))</code></pre>
</div>
</div>
<p>Looking at the first three values of <code>reverse_indices</code>: the reverse indices’ first value corresponds to the original index of 0, the reverse indices’ second value corresponds to the original index of 1, and the reverse indices’ third value corresponds to the original index of 2.</p>
<p>Finally, using <code>indices</code> to index into <code>ids</code></p>
<div id="cell-187" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2208b96c-fa28-4691-82b7-da4f0c41477a" data-execution_count="40">
<div class="sourceCode cell-code" id="cb104" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1">ids[indices]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>tensor([[ 101,    2, 1037,  ...,    0,    0,    0],
        [ 101,    2, 1037,  ...,    0,    0,    0],
        [ 101,    2, 1037,  ...,    0,    0,    0],
        ...,
        [ 101,    2, 1037,  ..., 1037, 1037,  102],
        [ 101,    2, 1037,  ..., 1037, 1037,  102],
        [ 101,    2, 1037,  ..., 1037, 1037,  102]])</code></pre>
</div>
</div>
<p>We can see that <code>ids[indices]</code> is sorted.</p>
<div id="cell-189" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="5f05b8f3-8f3a-4a69-fa8a-0b19dfbf5175" data-execution_count="43">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>):</span>
<span id="cb106-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>):</span>
<span id="cb106-3">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(torch.count_nonzero(ids[indices][i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>j]))</span>
<span id="cb106-4">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(43)
tensor(43)
tensor(43)
tensor(43)
tensor(43)
------------------------------
tensor(63)
tensor(63)
tensor(63)
tensor(63)
tensor(63)
------------------------------
tensor(83)
tensor(83)
tensor(83)
tensor(83)
tensor(83)
------------------------------
tensor(103)
tensor(103)
tensor(103)
tensor(103)
tensor(103)
------------------------------</code></pre>
</div>
</div>
<p>And that is what they mean by “sorting documents by length and feeding the batches with documents of comparable length to the encoder”.</p>
<p>So that’s how queries and documents are encoded. We can now look at the interaction between the two at query time, which is the MaxSim operator.</p>
</section>
</section>
<section id="maxsim" class="level2">
<h2 class="anchored" data-anchor-id="maxsim">MaxSim</h2>
<blockquote class="blockquote">
<p>Using Eq and Ed , ColBERT computes the relevance score between q and d via late interaction, which we define as a summation of maximum similarity (MaxSim) operators. In particular, we find the maximum cosine similarity of each v ∈ Eq with vectors in Ed , and combine the outputs via summation.</p>
</blockquote>
<p><img src="https://latex.codecogs.com/png.latex?S_%7Bq,d%7D%20:=%20%5Csum_%7Bi%20%5Cin%20%5B%5C%7CE_q%5C%7C%5D%7D%20%5Cmax_%7Bj%20%5Cin%20%5B%5C%7CE_d%5C%7C%5D%7D%20E_%7Bqi%7D%20%5Ccdot%20E_%7Bdj%7D%5ET"></p>
<p>Looking at the equation—we iterate through the queries, for each query we iterate through the document tokens and calculate the cosine similarity. we keep the maximum and sum it to S. Note that cosine similarity can be implemented as dot product because the embeddings are normalized. Another way to put it, taken from <a href="https://www.mixedbread.com/blog/maxsim-cpu#:~:text=For%20each%20candidate%20document%2C%20MaxSim%20iterates%20through%20every%20token%20within%20the%20query%2C%20and%20compares%20its%20similarity%20to%20every%20token%20within%20the%20document%2C%20before%20keeping%20the%20maximum%20value%20for%20each%20query%20token%20(hence%20the%20Max)%20and%20summing%20them%20up%20to%20produce%20a%20document%2Dlevel%20score.">Ben Clavie’s recent maxsim-cpu release blog post</a>:</p>
<blockquote class="blockquote">
<p>For each candidate document, MaxSim iterates through every token within the query, and compares its similarity to every token within the document, before keeping the maximum value for each query token (hence the Max) and summing them up to produce a document-level score.</p>
</blockquote>
<p>Beautiful.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="7.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Example of a MaxSim calculation between a query and a document"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/7.png" class="img-fluid figure-img" alt="Example of a MaxSim calculation between a query and a document"></a></p>
<figcaption>Example of a MaxSim calculation between a query and a document</figcaption>
</figure>
</div>
<p>Here is an example of the summation of MaxSim between query and document token embeddings. In this example, we have four query tokens and eight document tokens. For the first query token q1, the highest cosine similarity is with the fifth document token d5. d1 has the maximum cosine similarity for that q2, d2 for q3, and d8 for q4. Adding up these maximum cosine similarities, we get a final relevance score of 3.1. Since there are four tokens, the maximum possible MaxSim value is 4.0.</p>
<blockquote class="blockquote">
<p>this interaction mechanism softly searches for each query term tq —in a manner that reflects its context in the query—against the document’s embeddings, quantifying the strength of the “match” via the largest similarity score between tq and a document term td . Given these term scores, it then estimates the document relevance by summing the matching evidence across all query terms.</p>
</blockquote>
<p>The query tokens have passed through a transformer model and as such have passed through an attention mechanism so that all tokens attend to all other tokens. So the query itself now has interdependent relationships across tokens. When we’re searching for one token and looking to find the closest document, we’re not just looking to find the closest document to that token in isolation, we’re trying to find the closest document to that token within the context of the entire query. Some contextualized query token embeddings will find strong matches in certain documents, but what we’re looking for is the document for which the total maximum similarity for all query tokens is the largest. You can imagine that as a query gets very long, and the words in the query drift farther apart in meaning, the MaxSim values (before summation) for a document will have high variance.</p>
<blockquote class="blockquote">
<p>more sophisticated matching is possible with other choices such as deep convolution and attention layers (i.e., as in typical interaction-focused models),</p>
</blockquote>
<p>This reminds me of the <a href="https://arxiv.org/abs/2502.05364">Hypencoder paper</a> where they use a neural net for each query that takes as input a document embeddings and outputs a scalar relevance score. This is motivated by the fact that inner product (which is what cosine similarity is) is a linear operation and can thus only linearly separate two groups of vectors (such as embeddings). When your embedding dimension is much smaller than the number of vectors that you have, you can’t separate two groups linearly. In our case, our embedding dimension may be 96 and the number of vectors could be in the millions. Mathematically, you cannot linearly separate such a high number of vectors when they’re in a relatively low-dimensional space.</p>
<p>So you need a complex function because a line doesn’t work, and anytime you need a complex function where it’s more squiggly than a line, a neural net is a good choice!</p>
<p>However, the simplicity of MaxSim has two benefits:</p>
<blockquote class="blockquote">
<p>First, it stands out as a particularly cheap interaction mechanism, as we examine its FLOPs in §4.2. Second, and more importantly, it is amenable to highly-efficient pruning for top-k retrieval, as we evaluate in §4.3. This enables using vector-similarity algorithms for skipping documents without materializing the full interaction matrix or even considering each document in isolation. Other cheap choices (e.g., a summation of average similarity scores, instead of maximum) are possible; however, many are less amenable to pruning.</p>
</blockquote>
<p>ColBERT’s MaxSim mechanism enables efficient pruning: document tokens are clustered by similarity in vector indexes. At query time, each query token searches only the nearest clusters, skipping irrelevant documents. The “maximum” aggregation makes this possible—you only need the best matches, not exhaustive comparison across all documents.</p>
<p>We’re going to take a look at this paragraph, and then we’re going to look at the code that corresponds to it. Note that this is for a single query, which is what I’m going to focus on.</p>
<blockquote class="blockquote">
<p>Given a query q, we compute its bag of contextualized embeddings Eq (Equation 1) and, concurrently, gather the document representations into a 3-dimensional tensor D consisting of k document matrices. We pad the k documents to their maximum length to facilitate batched operations, and move the tensor D to the GPU’s memory. On the GPU, <mark>we compute a batch dot-product of Eq and D</mark>, possibly over multiple mini-batches. e output materializes a 3-dimensional tensor that is a collection of cross-match matrices between q and each document. To compute the score of each document, <mark>we reduce its matrix across document terms via a max-pool (i.e., representing an exhaustive implementation of our MaxSim computation) and reduce across query terms via a summation.</mark> Finally, we sort the k documents by their total scores.</p>
</blockquote>
<p>So let’s first look at the higher level class which is the <code>IndexScorer</code>. <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L188C9-L189C75">In <code>score_pids</code></a>, if the query size is 1 (which it is in our case), it’s going to pass the query and the documents to <code>colbert_score_packed</code>.</p>
<div class="sourceCode" id="cb108" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> Q.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:</span>
<span id="cb108-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> colbert_score_packed(Q, D_packed, D_mask, config), pids</span></code></pre></div>
<p>Inside <code>colbert_score_packed</code>, it removes the unit batch axis of the queries, and makes sure that q and d both have two dimensions. Then it performs the dot product between the two, and we can do this instead of explicitly calling cosine similarity because q and d are both normalized embeddings. The dot product results in a <code>scores</code> tensor that has size <code>number of document tokens x number of query tokens</code>. It then passes these scores into the <code>StridedTensor</code> and it gets back <code>scores_padded</code> and <code>scores_mask</code> which are then passed to <code>colbert_score_reduce</code>.</p>
<div class="sourceCode" id="cb109" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> colbert_score_packed(Q, D_packed, D_lengths, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ColBERTConfig()):</span>
<span id="cb109-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb109-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        Works with a single query only.</span></span>
<span id="cb109-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb109-5"></span>
<span id="cb109-6">    use_gpu <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> config.total_visible_gpus <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb109-7"></span>
<span id="cb109-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> use_gpu:</span>
<span id="cb109-9">        Q, D_packed, D_lengths <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Q.cuda(), D_packed.cuda(), D_lengths.cuda()</span>
<span id="cb109-10"></span>
<span id="cb109-11">    Q <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Q.squeeze(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># removes the unit batch axis</span></span>
<span id="cb109-12"></span>
<span id="cb109-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> Q.dim() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, Q.size()                     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># num query tokens x emb dim</span></span>
<span id="cb109-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> D_packed.dim() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, D_packed.size()       <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># num doc tokens   x emb dim</span></span>
<span id="cb109-15"></span>
<span id="cb109-16">    scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> D_packed <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> Q.to(dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>D_packed.dtype).T  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># num doc tokens x num query tokens</span></span>
<span id="cb109-17"></span>
<span id="cb109-18">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> use_gpu <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> config.interaction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"flipr"</span>:</span>
<span id="cb109-19">        scores_padded, scores_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StridedTensor(scores, D_lengths, use_gpu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>use_gpu).as_padded_tensor()</span>
<span id="cb109-20"></span>
<span id="cb109-21">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> colbert_score_reduce(scores_padded, scores_mask, config)</span>
<span id="cb109-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb109-23">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> ColBERT.segmented_maxsim(scores, D_lengths)</span></code></pre></div>
<p><code>scores_padded</code> has shape <code>number of documents x maximum number of tokens in the documents x number of query tokens</code>. So if we have three documents, a maximum of 13 document tokens, and 32 query tokens, <code>scores_padded</code> has shape 3 x 13 x 32.</p>
<p>Finally, <code>colbert_score_reduce</code> is called which takes the maximum of <code>scores_padded</code> across the second dimension (number of document tokens) to leave us with one score for each query token per document.</p>
<div class="sourceCode" id="cb110" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> colbert_score_reduce(scores_padded, D_mask, config: ColBERTConfig):</span>
<span id="cb110-2">    D_padding <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>D_mask.view(scores_padded.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>), scores_padded.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>()</span>
<span id="cb110-3">    scores_padded[D_padding] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">9999</span></span>
<span id="cb110-4">    scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> scores_padded.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).values</span>
<span id="cb110-5"></span>
<span id="cb110-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># flipr code removed for brevity</span></span>
<span id="cb110-7"></span>
<span id="cb110-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> scores.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
<p>Taking <code>scores.sum(-1)</code>, the summation across the query token dimension, leaves us with one score per document, our desired result.</p>
<blockquote class="blockquote">
<p>Relative to existing neural rankers (especially, but not exclusively, BERT-based ones), this computation is very cheap that, in fact, its cost is dominated by the cost of gathering and transferring the pre-computed embeddings. To illustrate, ranking k documents via typical BERT rankers requires feeding BERT k different inputs each of length l = |q| + |di | for query q and documents di , where attention has quadratic cost in the length of the sequence. In contrast, ColBERT feeds BERT only a single, much shorter sequence of length l = |q|. Consequently, ColBERT is not only cheaper, it also scales much better with k as we examine in §4.2.</p>
</blockquote>
<p>So, what is involved in that cost of gathering and transferring the pre-computed embeddings? We will look at what they say about offline indexing next.</p>
</section>
<section id="offline-indexing" class="level2">
<h2 class="anchored" data-anchor-id="offline-indexing">Offline Indexing</h2>
<blockquote class="blockquote">
<p>Instead of applying MaxSim between one of the query embeddings and all of one document’s embeddings, we can use fast vector-similarity data structures to efficiently conduct this search between the query embedding and all document embeddings across the full collection. For this, we employ an off-the-shelf library for large-scale vector-similarity search, namely faiss [15] from Facebook. In particular, at the end of offline indexing (§3.4), we maintain a mapping from each embedding to its document of origin and then index all document embeddings into faiss.</p>
</blockquote>
<p>The current implementation in the repo uses a more efficient indexing system, the PLAID index, as opposed to what is written here (indexing “all document embeddings into faiss” and “mantain a mapping from each embeddings to its document of origin”). Instead, the PLAID index uses residual compression with centroids, maintains an Inverted File (IVF) structure that maps centroids to passage IDs, and stores embeddings as compressed residuals relative to centroids.</p>
<p>There’s a lot to unpack in the following section:</p>
<blockquote class="blockquote">
<p>Subsequently, when serving queries, we use a two-stage procedure to retrieve the top-k documents from the entire collection. Both stages rely on ColBERT’s scoring: the first is an approximate stage aimed at filtering while the second is a refinement stage. For the first stage, we concurrently issue Nq vector-similarity queries (corresponding to each of the embeddings in Eq ) onto our faiss index. This retrieves the top-k’ (e.g., k’ = k/2) matches for that vector over all document embeddings. We map each of those to its document of origin, producing Nq × k’ document IDs, only K ≤ Nq × k’ of which are unique. These K documents likely contain one or more embeddings that are highly similar to the query embeddings. For the second stage, we refine this set by exhaustively re-ranking only those K documents in the usual manner described in §3.5. In our faiss-based implementation, we use an IVFPQ index (“inverted file with product quantization”). This index partitions the embedding space into P (e.g., P = 1000) cells based on k-means clustering and then assigns each document embedding to its nearest cell based on the selected vector-similarity metric. For serving queries, when searching for the top-k’ matches for a single query embedding, only the nearest p (e.g., p = 10) partitions are searched. To improve memory efficiency, every embedding is divided into s (e.g., s = 16) sub-vectors, each represented using one byte. Moreover, the index conducts the similarity computations in this compressed domain, leading to cheaper computations and thus faster search.</p>
</blockquote>
<ul>
<li>There are NQ query token embeddings, and for each one, we find the top K’ document IDs.</li>
<li>NQ x k’ (say 32 x 500) documents will include some duplicates, Meaning that some documents will contain document token embeddings that are close to more than one query token. Removing those duplicates will give us a K number of documents, which is less than the number of query embeddings x k’.</li>
<li>This first stage has greatly reduced the number of documents in consideration. You go from all documents in consideration, which could be tens of millions, down to just NQ x k’ or fewer documents in consideration. This K documents are then re-ranked according to the MaxSim computation across query token embeddings that we saw earlier.</li>
<li>The late interaction architecture allows for pruning, as exhibited by the IVFPQ index. That index starts by partitioning the embedding space into some number of clusters, where that number of clusters is much much less than the number of token embeddings. It assigns each document token embedding to its nearest cluster based on whatever similarity metric is being used. This reduces the number of potential candidates that are close to a query token. When we search for a document similar to a given query, you only search the nearest p partitions, and p is small, say 10. And so think about this: you started out with maybe tens of millions of documents, you’ve narrowed that down to a thousand clusters of documents, and then you’re now narrowing that even further down to only 10 clusters that are considered for a single query token. That we can index these documents offline before the interaction takes place and organize them into clusters is what allows this pruning to take place.</li>
<li>The last thing I’ll say about this section is that the compression that they’re explaining here, where they divide every embedding into sub-vectors each represented using one byte, is now replaced with the PLAID compression where they quantize the residual embeddings into n bits.</li>
</ul>
<p>So with that, we have pretty much covered all of the conceptual foundations of ColBERT. To understand the impact of those foundations, we’ll now look at the experimental evaluation section from the paper.</p>
</section>
<section id="experimental-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="experimental-evaluation">Experimental Evaluation</h2>
<p>And we’ll explore the four research questions that the ColBERT authors have put forth in this section.</p>
<ul>
<li>RQ1: In a typical re-ranking setup, how well can ColBERT bridge the existing gap between highly-efficient and highly-effective neural models?</li>
<li>RQ2: Beyond re-ranking, can ColBERT effectively support end-to-end retrieval directly from a large collection?</li>
<li>RQ3: What does each component of ColBERT (e.g., late interaction, query augmentation) contribute to its quality?</li>
<li>RQ4: What are ColBERT’s indexing-related costs in terms of offline computation and memory overhead?</li>
</ul>
<p>Some training details to prepare the ColBERT retriever: they fine-tune ColBERT models on the MS MARCO and TREC CAR datasets with a learning rate of 3e-6 and a batch size of 32. They fix the number of embeddings per query at 32, meaning that they have 32 tokens per query, and the embedding dimension is 128. The model is trained on a triple of query, positive document and negative document. ColBERT is used to produce a score for each document individually, and is optimized via pairwise softmax cross-entropy loss over the computed scores of the positive and negative document.</p>
<p>Here are two lines from the <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/training/training.py#L74-L119C21"><code>train</code> function</a> where you can see the loss method, which is cross-entropy loss, and that the labels are just zeros because the document that is positive is first in the batch item (the zero-eth index):</p>
<div class="sourceCode" id="cb111" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1">...</span>
<span id="cb111-2"></span>
<span id="cb111-3">labels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(config.bsize, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">long</span>, device<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>DEVICE)</span>
<span id="cb111-4"></span>
<span id="cb111-5">...</span>
<span id="cb111-6"></span>
<span id="cb111-7">loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.CrossEntropyLoss()(scores, labels[:scores.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)])</span></code></pre></div>
<p>We’ll now dig into the results of their evaluation of the ColBERT architecture vs.&nbsp;existing methods to address the four research questions listed.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="8.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="Table 1"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/8.png" class="img-fluid figure-img" alt="Table 1"></a></p>
<figcaption>Table 1</figcaption>
</figure>
</div>
<p>Here are the results for the first type of evaluation where Colbert and other architectures are used to re-rank The top 1000 results produced by BM25, which is full text search. There are three notable takeaways from this table:</p>
<ol type="1">
<li>ColBERT beats non-BERT-based models in terms of retrieval metric MRR@10 and is comparable to BERT models.</li>
<li>ColBERT is three orders of magnitude faster than the more performant BERT models and is comparable in latency to the non-BERT neural rankers.</li>
<li>Except for KNRM, ColBERT requires 11x to 48600x fewer FLOPs per query.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="9.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Figure 4"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/9.png" class="img-fluid figure-img" alt="Figure 4"></a></p>
<figcaption>Figure 4</figcaption>
</figure>
</div>
<p>They also compared ColBERT to BERT-base trained on retrieval. In this comparison, they increased the number of documents considered for re-ranking, calculated the FLOPs required to perform the re-ranking and then calculated the retrieval performance. The purple line at the top shows BERT-base, the green line at the bottom shows ColBERT. ColBERT for each value of k (number of documents reranked) requires fewer FLOPs and is comparable in retrieval performance. Most importantly, ColBERT scales much better than BERT-base as the number of document candidates considered increases from 10 to 2000. ColBERT stays within the same order of magnitude for FLOPs whereas BERT-base FLOPs increase by two orders of magnitude.</p>
<p>Next, we’ll look at their full retrieval results where they retrieve the top 1000 documents from the 8.8 million document MS Marco Corpus.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="10.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Table 2"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/10.png" class="img-fluid figure-img" alt="Table 2"></a></p>
<figcaption>Table 2</figcaption>
</figure>
</div>
<p>What immediately jumps off the page here is the MRR improvement that ColBERT provides, twice that of the Anserini BM25 method, which is an excellent baseline. However, ColBERT has about 5-8 times the latency of these other methods–that could be justifiable given the increased improvement. ColBERT (end-to-end) has the best Recall across all methods.</p>
<p>Next, we’ll look at some of the ablation studies that they performed, which to me are the most exciting results.</p>
</section>
<section id="ablation-studies" class="level2">
<h2 class="anchored" data-anchor-id="ablation-studies">Ablation Studies</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="11.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11" title="Figure 5"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/11.png" class="img-fluid figure-img" alt="Figure 5"></a></p>
<figcaption>Figure 5</figcaption>
</figure>
</div>
<p>This figure is really interesting, and there’s a lot to unpack here. I think it serves as a really comprehensive summary of the main architectural decisions that they’ve made in this work.</p>
<p>Models A through E are used in a re-ranking setting. The first comparison we’ll look at is between model A and model D. Model A is a BERT model, and it takes the CLS token embedding representation for query and document and performs an inner product between them to calculate similarity for re-ranking, which achieves an MRR@10 of about 0.26 which is 6 points fewer than a 5-layer ColBERT model. So, fine grained, token-wise embedding interaction with ColBERT is yielding better results than a single vector interaction with BERT. This is a confirmation of the fundamental concept behind late interaction.</p>
<p>The second comparison is between model B and model D. Model B is using average similarity, and model D is using the MaxSim operator. Model D again has about a 6 point increase in MRR. This validates the second fundamental concept behind late interaction: the MaxSim operator.</p>
<p>The third comparison is between Model C and Model D. In Model C, the query is <strong>not</strong> padded to 32 tokens with <code>[MASK]</code> tokens. Model D uses query augmentation (it pads to 32 with <code>[MASK]</code> tokens) and has a 2 point increase in MRR showing that these <code>[MASK]</code> tokens, which carry semantic meaning in embedding space, improve the model’s ability to find relevant documents given a query.</p>
<p>The final comparison is between Model E and Model F. Model E is ColBERT used as a re-ranker for the top 1000 documents retrieved by full-text search. Model F is ColBERT used for end-to-end retrieval using a vector similarity index to cluster documents before retrieval. Using ColBERT end-to-end gives another boost to performance.</p>
<p>Something to keep in mind is that BERT requires you to pass in the query and document embedding one pair at a time. For one query, you have to do a thousand forward passes if you have a thousand documents that you want to compare it to. Whereas ColBERT, because of late interaction, can utilize vector similarity indexes because documents are indexed offline, and the interaction calculation is much quicker because you are considering fewer candidate documents—the documents that are close to the query token embeddings via the clusters created by the indexing process.</p>
</section>
<section id="indexing-throughpout-footprint" class="level2">
<h2 class="anchored" data-anchor-id="indexing-throughpout-footprint">Indexing Throughpout &amp; Footprint</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="12.png" class="lightbox" data-gallery="quarto-lightbox-gallery-12" title="Figure 6"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/12.png" class="img-fluid figure-img" alt="Figure 6"></a></p>
<figcaption>Figure 6</figcaption>
</figure>
</div>
<p>I’ll start by showing figure 6, where it shows that on top of basic ColBERT indexing, adding these optimizations increases the throughput, which means it increases the number of documents that are processed each minute. The two that I’ll highlight here is that length-based bucketing, which we saw in detail, and per-batch maximum sequence length, where they pad all items in the batch to the maximum document length, both improve the throughput.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="13.png" class="lightbox" data-gallery="quarto-lightbox-gallery-13" title="Table 4"><img src="https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/13.png" class="img-fluid figure-img" alt="Table 4"></a></p>
<figcaption>Table 4</figcaption>
</figure>
</div>
<p>This table shows the space footprint and MRR@10 for different settings, dimensions, and bytes per dimension. The most space-effcient setting, re-ranking with cosine similarity with 24-dimensional vectors stored as 2-byte floats, which takes up 27 GB, is only 1% worse in MRR@10 than the most space-consuming one which takes up 286 GB.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The body of the ColBERTv1 paper is only about 9 pages long, but it is incredibly information dense. What I thought would be a 1-day foray turned into a 6-day deep dive. I found it helpful to interleave twitter conversations with core concepts from the paper, as casual conversations are often more accessible, and equally impressive as formal work.</p>
<p>As a new canonical ColBERT maintainer I wanted to ground myself in the first principles of late interaction. There are three key elements involved:</p>
<ol type="1">
<li>Independent encoding of queries and documents.</li>
<li>Offline document indexing.</li>
<li>the MaxSim operation.</li>
</ol>
<p>Encoding queries and documents separately allows for offline document indexing, and delays the interaction to the end of the architecture. Offline indexing and MaxSim both unlock pruning in their own ways. Vector-similarity indexes, through clustering, eliminate low-relevance documents from consideration before the interaction takes place. MaxSim eliminates low-relevance tokens during the interaction.</p>
<p>MaxSim is further enhanced by query augmentation, as meaningful <code>[MASK]</code> tokens are introduced in the query to improve the chance of matching relevant terms in the document.</p>
<p>That the most space-efficient setting is only 1% less performant than the most space-consuming setting foreshadows the compression opportunities realized in the PLAID paper.</p>
<p>With these foundations reinforced, I’ll revisit the ColBERTv2 and PLAID papers next, and will continue to concretely witness the concepts at play in the repo’s codebase.</p>


</section>

 ]]></description>
  <category>ColBERT</category>
  <category>information retrieval</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-07-16-ColBERTv1/</guid>
  <pubDate>Wed, 16 Jul 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Debugging Flash Attention in LLM-Foundry (and a 20% Slow Down!)</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-30-debug-fa2-llm-foundry/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I’m learning a lot about LLM-Foundry while working on a group research project. In this blog post I’ll walk through how we figured out two things:</p>
<ol type="1">
<li>LLM-Foundry, by default when using a HuggingFace LlamaModel, does not use <code>flash_attn_varlen_func</code> and instead uses <code>flash_attn_func</code>. In other words, it doesn’t unpad the batch by default.</li>
<li>When forcing LLM-Foundry to use <code>flash_attn_varlen_func</code>, it slows down training time.</li>
</ol>
<p>I’ll start by walking through the forward pass of the HuggingFace <code>LlamaModel</code> down to the attention mechanism which uses the <code>_flash_attention_forward</code> utility function which decides which Flash Attention interface is being used.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/BWO5guW7Kl4?si=l30jswKSmduhzd2g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="what-is-the-value-of-the-attention_mask" class="level2">
<h2 class="anchored" data-anchor-id="what-is-the-value-of-the-attention_mask">What is the value of the <code>attention_mask</code>?</h2>
<p>The model we’re using is SmolLM2-135M which uses the now-deprecated <a href="https://github.com/huggingface/transformers/blob/d363e71d0e32f44d7a5b3571d4921371907bd0ee/src/transformers/models/llama/modeling_llama.py#L324"><code>LlamaFlashAttention2</code> module</a>.</p>
<p>Inspecting the <a href="https://github.com/huggingface/transformers/blob/d363e71d0e32f44d7a5b3571d4921371907bd0ee/src/transformers/models/llama/modeling_llama.py#L828"><code>LlamaModel</code> forward pass</a>, the first instance of where the <code>attention_mask</code> is used:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">causal_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._update_causal_mask(</span>
<span id="cb1-2">    attention_mask, inputs_embeds, cache_position, past_key_values, output_attentions</span>
<span id="cb1-3">)</span></code></pre></div>
<p>Looking at <code>_update_causal_mask</code>:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config._attn_implementation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"flash_attention_2"</span>:</span>
<span id="cb2-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> attention_mask <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> attention_mask:</span>
<span id="cb2-3">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> attention_mask</span>
<span id="cb2-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span></code></pre></div>
<p>If <code>0.0 in attention_mask</code> then the <code>attention_mask</code> will be returned, other <code>None</code> is returned.</p>
<p>We’ll come back to this point later on.</p>
</section>
<section id="when-is-flash_attn_varlen_func-called" class="level2">
<h2 class="anchored" data-anchor-id="when-is-flash_attn_varlen_func-called">When is <code>flash_attn_varlen_func</code> called?</h2>
<p>Let’s assume <code>0.0 in attention_mask</code> is <code>True</code>, so the <code>attention_mask</code> is kept as is and is passed onto the <code>LlamaDecoderLayer</code> and eventually the attention mechanism <a href="https://github.com/huggingface/transformers/blob/d363e71d0e32f44d7a5b3571d4921371907bd0ee/src/transformers/models/llama/modeling_llama.py#L414">which calls <code>_flash_attention_forward</code></a>. <code>flash_attention_forward</code> is <a href="https://github.com/huggingface/transformers/blob/ea0ea392e57f8816f9ab8e5f740577a0343a1594/src/transformers/modeling_flash_attention_utils.py#L409">defined in transformers/modeling_flash_utils.py</a>, and triggers the use of <code>flash_attn_varlen_func</code> if one of two conditions are true:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> attention_mask <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span></code></pre></div>
<p>or</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> (</span>
<span id="cb4-2">    position_ids <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb4-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> query_states.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb4-4">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> (max_length_q <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> (query_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> (torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>()))</span>
<span id="cb4-5">)</span></code></pre></div>
<p>The <code>elif</code> condition is <code>True</code> if <code>position_ids is not None</code> and <code>query_states.shape[0] == 1</code> and either <code>max_length_q is not None</code> or <code>(query_length != 1 and not (torch.diff(position_ids, dim=-1) &gt;= 0).all())</code>. The <code>torch.diff</code> expression is <code>False</code> if the difference in consecutive values in <code>position_ids</code> are not greater than <code>0</code>. For example, the following <code>position_ids</code> would yield <code>False</code>:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span></code></pre></div>
<p><code>torch.diff</code> for the 4th and 5th position (<code>3</code> to <code>0</code>) is <code>-3</code>. We would expect such a <code>position_ids</code> sequence when you have packed sequences.</p>
</section>
<section id="how-do-we-check-the-value-of-attention_mask-during-training" class="level2">
<h2 class="anchored" data-anchor-id="how-do-we-check-the-value-of-attention_mask-during-training">How do we check the value of <code>attention_mask</code> during training?</h2>
<p>To do so, I wrote the following Composer callback:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> FlashAttentionDebug(Callback):</span>
<span id="cb6-2">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> before_forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb6-3">      model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state.model</span>
<span id="cb6-4">      <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(model.config._attn_implementation)</span>
<span id="cb6-5">      <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.hooks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb6-6"></span>
<span id="cb6-7">      <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> create_hook_fn(name):</span>
<span id="cb6-8">          <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, args, kwargs, output):</span>
<span id="cb6-9">              <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> kwargs:</span>
<span id="cb6-10">                  <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> FlashAttentionDebug: attention_mask is None:"</span>, kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>] <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb6-11">                  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>] <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb6-12">                      <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> FlashAttentionDebug: attention_mask:"</span>, kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>])</span>
<span id="cb6-13">                      <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> FlashAttentionDebug: 0.0 in attention_mask:"</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>])</span>
<span id="cb6-14">                      <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> FlashAttentionDebug: attention_mask.shape:"</span>, kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>].shape)</span>
<span id="cb6-15">                      <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> FlashAttentionDebug: attention_mask.sum():"</span>, kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"attention_mask"</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>())</span>
<span id="cb6-16">          <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb6-17"></span>
<span id="cb6-18">      attn_layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].self_attn</span>
<span id="cb6-19">      hook_handle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attn_layer.register_forward_hook(create_hook_fn(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"attn_layer"</span>), with_kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb6-20">      <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.hooks.append(hook_handle)</span>
<span id="cb6-21"></span>
<span id="cb6-22">      decoder_layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.model.base_model.model.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb6-23">      <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(decoder_layer))</span>
<span id="cb6-24">      hook_handle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> decoder_layer.register_forward_hook(create_hook_fn(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"decoder_layer"</span>), with_kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb6-25">      <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.hooks.append(hook_handle)</span>
<span id="cb6-26"></span>
<span id="cb6-27">      _model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.model.base_model.model.model</span>
<span id="cb6-28">      <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span>(_model))</span>
<span id="cb6-29">      hook_handle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _model.register_forward_hook(create_hook_fn(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>), with_kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb6-30">      <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.hooks.append(hook_handle)</span>
<span id="cb6-31"></span>
<span id="cb6-32">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> after_forward(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb6-33">      <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> hook <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.hooks:</span>
<span id="cb6-34">          hook.remove()</span>
<span id="cb6-35">      <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.hooks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span></code></pre></div>
<p><code>create_hook_fn</code> is a closure which returns <code>hook_fn</code>. I used this pattern so I could log the name of the module the hook is attached to. Note that when using <code>register_forward_hook</code> you must specify <code>with_kwargs=True</code> to pass kwargs to the hook function.</p>
<p>Here are the outputs when using the default LLM-Foundry pretraining setup:</p>
<pre><code>flash_attention_2
&lt;class 'transformers.models.llama.modeling_llama.LlamaDecoderLayer'&gt;
&lt;class 'transformers.models.llama.modeling_llama.LlamaModel'&gt;
attn_layer FlashAttentionDebug: attention_mask is None: True
decoder_layer FlashAttentionDebug: attention_mask is None: True
model FlashAttentionDebug: attention_mask is None: False
model FlashAttentionDebug: attention_mask: tensor([[1, 1, 1,  ..., 1, 1, 1]], device='cuda:0')
model FlashAttentionDebug: 0.0 in attention_mask: False
model FlashAttentionDebug: attention_mask.shape: torch.Size([1, 2048])
model FlashAttentionDebug: attention_mask.sum(): tensor(2048, device='cuda:0')</code></pre>
<p>Note that in the attention layer, <code>attention_mask</code> is <code>None</code> because as we can see in the <code>model</code> forward output, <code>0.0</code> is not in <code>attention_mask</code> (it’s full of <code>1</code>s).</p>
</section>
<section id="how-do-we-create-an-attention_mask-with-0.0s" class="level2">
<h2 class="anchored" data-anchor-id="how-do-we-create-an-attention_mask-with-0.0s">How do we create an <code>attention_mask</code> with <code>0.0</code>s?</h2>
<p>With the help of Cursor (my first time using it!) I was able to add one simple line to the <code>__call__</code> method of the default pretraining collator <code>ConcatenatedSequenceCollatorWrapper</code>:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">batch[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'attention_mask'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (batch[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'input_ids'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">long</span>()</span></code></pre></div>
<p>Where <code>input_ids</code> are not <code>0</code> (the EOS token id used for padding) <code>attention_mask</code> will be <code>1</code>; it will be <code>0</code> where there are padding tokens.</p>
<p>Since I’m using Modal for training, and since the image brings down our LLM-Foundry fork, and since I need to modify the <code>ConcatenatedSequenceCollatorWrapper.__call__</code> method (which lives in <code>llmfoundry/data/text_data.py</code>) I add the following line after my Modal is built:</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">image <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> image.add_local_file(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text_data.py"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/llm-foundry/llmfoundry/data/text_data.py"</span>)</span></code></pre></div>
<p>Running training with this modified collator the <code>FlashAttentionDebug</code> callback logs the following:</p>
<pre><code>flash_attention_2
&lt;class 'transformers.models.llama.modeling_llama.LlamaDecoderLayer'&gt;
&lt;class 'transformers.models.llama.modeling_llama.LlamaModel'&gt;
attn_layer FlashAttentionDebug: attention_mask is None: False
attn_layer FlashAttentionDebug: attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')
attn_layer FlashAttentionDebug: 0.0 in attention_mask: True
attn_layer FlashAttentionDebug: attention_mask.shape: torch.Size([1, 2048])
attn_layer FlashAttentionDebug: attention_mask.sum(): tensor(201, device='cuda:0')
decoder_layer FlashAttentionDebug: attention_mask is None: False
decoder_layer FlashAttentionDebug: attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')
decoder_layer FlashAttentionDebug: 0.0 in attention_mask: True
decoder_layer FlashAttentionDebug: attention_mask.shape: torch.Size([1, 2048])
decoder_layer FlashAttentionDebug: attention_mask.sum(): tensor(201, device='cuda:0')
model FlashAttentionDebug: attention_mask is None: False
model FlashAttentionDebug: attention_mask: tensor([[1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')
model FlashAttentionDebug: 0.0 in attention_mask: True
model FlashAttentionDebug: attention_mask.shape: torch.Size([1, 2048])
model FlashAttentionDebug: attention_mask.sum(): tensor(201, device='cuda:0')</code></pre>
<p>Now we can see that in the attention layer, the <code>attention_mask</code> is not <code>None</code>. It contains <code>0.0</code> values (note how the <code>sum</code>, 201, is less than the sequence length of 2048) which is why the <code>_update_causal_mask</code> method returned attention_mask as is. We can also visually inspect the <code>attention_mask</code> tensor in the model, decoder layer and attention mechanism forward pass and see both <code>1</code>s and <code>0</code>s.</p>
</section>
<section id="how-do-we-know-if-flash_attn_varlen_func-is-being-used" class="level2">
<h2 class="anchored" data-anchor-id="how-do-we-know-if-flash_attn_varlen_func-is-being-used">How do we know if <code>flash_attn_varlen_func</code> is being used?</h2>
<p>Now that we know that introducing <code>0</code>s in the <code>attention_mask</code> allows it to be passed through the model, including the attention mechanism, we should confirm that <code>flash_attn_varlen_func</code> is called. If you recall, one of the conditions for it being called was that <code>attention_mask is not None</code>. To check this, we can monkey-patch <code>_upad_input</code> which is the method called to unpad the batch if <code>attention_mask is not None</code>:</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> transformers.modeling_flash_attention_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> flash_utils</span>
<span id="cb11-2">original_upad_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flash_utils._upad_input</span>
<span id="cb11-3">original_prepare_fa2_from_position_ids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flash_utils.prepare_fa2_from_position_ids</span>
<span id="cb11-4"></span>
<span id="cb11-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> debug_upad_input(query_states, key_states, value_states, attention_mask, query_length):</span>
<span id="cb11-6">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DEBUG: Using _upad_input"</span>)</span>
<span id="cb11-7">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  query_states: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>query_states<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb11-8">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  key_states: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>key_states<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb11-9">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  value_states: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>value_states<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb11-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  attention_mask: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>attention_mask<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb11-11">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"  query_length: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>query_length<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb11-12">    query_layer, key_layer, value_layer, indices_q, (cu_seqlens_q, cu_seqlens_k),(max_seqlen_in_batch_q, max_seqlen_in_batch_k) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> original_upad_input(query_states, key_states, value_states, attention_mask, query_length)</span>
<span id="cb11-13">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"query_layer.shape: "</span>, query_layer.shape)</span>
<span id="cb11-14">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"key_layer.shape: "</span>, key_layer.shape)</span>
<span id="cb11-15">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"value_layer.shape: "</span>, value_layer.shape)</span>
<span id="cb11-16">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"indices_q.shape: "</span>, indices_q.shape)</span>
<span id="cb11-17">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"cu_seqlens_q.shape: "</span>, cu_seqlens_q.shape)</span>
<span id="cb11-18">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"cu_seqlens_q: "</span>, cu_seqlens_q.tolist())</span>
<span id="cb11-19">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"cu_seqlens_k.shape: "</span>, cu_seqlens_k.shape)</span>
<span id="cb11-20">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"cu_seqlens_k: "</span>, cu_seqlens_k.tolist())</span>
<span id="cb11-21">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"max_seqlen_in_batch_q: "</span>, max_seqlen_in_batch_q)</span>
<span id="cb11-22">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"max_seqlen_in_batch_k: "</span>, max_seqlen_in_batch_k)</span>
<span id="cb11-23">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"indices_q: "</span>, indices_q.tolist())</span>
<span id="cb11-24">    seqlens_in_batch <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attention_mask.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.int32)</span>
<span id="cb11-25">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(seqlens_in_batch.tolist())</span>
<span id="cb11-26">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(attention_mask[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].tolist())</span>
<span id="cb11-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> original_upad_input(query_states, key_states, value_states, attention_mask, query_length)</span>
<span id="cb11-28"></span>
<span id="cb11-29">flash_utils._upad_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> debug_upad_input</span></code></pre></div>
<p>I added a <code>original_upad_input</code> call and stored the output so I could see what gets passed on to <code>flash_attn_varlen_func</code>.</p>
<p>During the training run, with our modified collator, we see the following output (this was for a run with a batch size of 6):</p>
<pre><code>DEBUG: Using _upad_input
  query_states: torch.Size([6, 2048, 9, 64])
  key_states: torch.Size([6, 2048, 3, 64])
  value_states: torch.Size([6, 2048, 3, 64])
  attention_mask: torch.Size([6, 2048])
  query_length: 2048
query_layer.shape:  torch.Size([1395, 9, 64])
key_layer.shape:  torch.Size([1395, 3, 64])
value_layer.shape:  torch.Size([1395, 3, 64])
indices_q.shape:  torch.Size([1395])
cu_seqlens_q.shape:  torch.Size([7])
cu_seqlens_q:  [0, 220, 437, 732, 915, 1045, 1395]
cu_seqlens_k.shape:  torch.Size([7])
cu_seqlens_k:  [0, 220, 437, 732, 915, 1045, 1395]
max_seqlen_in_batch_q:  350
max_seqlen_in_batch_k:  350
</code></pre>
<p>Some key observations:</p>
<p><code>query_states</code> has size 6 (batch size) x 2048 (sequence length) x 9 (num heads) x 64 (head dim).</p>
<p><code>query_layer</code> (one of the <code>_upad_input</code> outputs and <code>flash_attn_varlen_func</code> inputs) has size 1395 (total sequence length) x 9 (num heads) x 64 (head dim).</p>
<p>The <code>cu_seqlens_q</code> that is a critical input to <code>flash_attn_varlen_func</code> show us that there are 6 sequences packed together and the “boundaries” of the sequences are <code>[0, 220, 437, 732, 915, 1045, 1395]</code>. Using my <a href="https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/index.html#datainspector"><code>DataInspector</code> callback</a> I confirmed the number of non-padding tokens in the batch: 220, 217, 295, 183, 130, 350. The sum of these counts is 1395, the total sequence length passed to <code>flash_attn_varlen_func</code>.</p>
</section>
<section id="wait-flash_attn_varlen_func-slows-down-training" class="level2">
<h2 class="anchored" data-anchor-id="wait-flash_attn_varlen_func-slows-down-training">Wait, <code>flash_attn_varlen_func</code> slows down training?</h2>
<p>When using my modified collator, and therefore utilizing <code>flash_attn_varlen_func</code> the training time slows down by <em>over 20%</em>. This was certainly a surprise for me! After discussing this with our research advisor, we learned that this is likely because the HuggingFace implementation of the model unpads and re-pads the batch for each layer.</p>
<p>We can see this <a href="https://github.com/huggingface/transformers/blob/03db2700abf84971351c7374a548a9d4fc156916/src/transformers/modeling_flash_attention_utils.py#L532">in the <code>_flash_attention_forward</code> method, after <code>flash_attn_varlen_func</code> is called</a>:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">attn_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _pad_input(attn_output_unpad, indices_q, batch_size, query_length)</span></code></pre></div>
<p>The solution to mitigating this slow-down is to implement our own custom model where it unpads the batch only once. This will be our next task!</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>The biggest takeaway from this experience, as has been the case for all practical training experiments I’ve run (whether for LMs or vision models) is that there’s a difference between what is theoretically efficient and whether that is practically efficient. In theory, <code>flash_attn_varlen_func</code> should be faster because you are not wasting the quadratic attention compute on padding tokens. In practice, unpadding and re-padding the batch for each layer for each forward pass adds an overhead which not only cancels out that attention computation speedup, but slows down the training compared to a fully-padded forward pass. This is a critical lesson I experience again and again, and it helps me understand the value of choosing the right implementation to actualize theoretical efficiencies.</p>
<p>I’m growing my YouTube channel this year, so if you like this type of content <a href="https://www.youtube.com/@vishal_learner">please subscribe</a>!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM-Foundry</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-30-debug-fa2-llm-foundry/</guid>
  <pubDate>Mon, 30 Jun 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Introducing portfolio-llm: A Professional Portfolio You Can Chat With</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-26-portfolio-llm/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>For my latest project, I wanted to solve a problem I was facing: I have published a large volume of machine learning blog posts and videos, and I was not sure how to unify all of my work.</p>
<p>I’ve also been interested in the <a href="https://llmstxt.org/">llms.txt standard created by Jeremy Howard</a>, so I had an idea: what if I wrote an llms_ctx.txt for my own professional portfolio to make it interactive and queryable?</p>
<p>In this post, I’m going to share the result of that experiment: a professional portfolio you can chat with. I’ll walk through the entire process, from concept and design to the rigorous evaluation framework I built to test the system. I’ll also share my thoughts on how this approach changes the job search paradigm.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Qhax3JerFP0?si=BNFnHmw6cNfW5SlN" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="the-goal-an-interactive-conversation" class="level2">
<h2 class="anchored" data-anchor-id="the-goal-an-interactive-conversation">The Goal: An Interactive Conversation</h2>
<p>You can see a demo of my llms_ctx.txt on Claude.ai in the video embedded above. Here are a couple screenshot examples:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Claude.ai chat screenshot"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-26-portfolio-llm/1.png" class="img-fluid figure-img" alt="Claude.ai chat screenshot"></a></p>
<figcaption>Claude.ai chat screenshot</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="A not very concise response"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-26-portfolio-llm/2.png" class="img-fluid figure-img" alt="A not very concise response"></a></p>
<figcaption>A not very concise response</figcaption>
</figure>
</div>
</section>
<section id="how-it-works-the-llms_ctx.txt-file" class="level2">
<h2 class="anchored" data-anchor-id="how-it-works-the-llms_ctx.txt-file">How It Works: The <code>llms_ctx.txt</code> File</h2>
<p>The <code>llms_ctx.txt</code> file contains 5 sections (following the llms.txt standard):</p>
<ul>
<li>A header: <code># Vishal Bakshi: Building Reliable Systems</code></li>
<li>A blockquote with a high-level summary</li>
</ul>
<blockquote class="blockquote">
<p>Vishal Bakshi has a background in engineering, data analytics, and education, now focusing on Applied AI and ML research. He specializes in building reliable systems, with an emphasis on resource-constrained research, deep evaluation, and a first-principles understanding of machine learning.</p>
</blockquote>
<ul>
<li>A <code>## High-Level Overview &amp; FAQ</code> section with QA pairs.</li>
<li>A <code>## Portfolio Deep Dive Q&amp;A</code> section with QA pairs.</li>
<li>A <code>## Out-of-Scope Questions</code> section with QA pairs.</li>
</ul>
<p>The creation of my <code>llms_ctx.txt</code> file was an iterative process heavily collaborated with Gemini 2.5 Pro.</p>
<p>I first create two txt files: one containing metadata for my videos, and one containing metadata for my blog posts. I chose to keep the metadata simple: the existing title and description. A potential improvement on this could be producing an AI-generated summary of each content piece and adding that as a third field.</p>
<p>I provided Gemini these two files and asked it to generate 5-8 themes across my body of work, and citing which blog posts and videos best represented each theme. It provided by 8 themes. I then iterated on this list manually, adding and removing content pieces and adjusting theme names as needed. You can view the full list of themes and corresponding content pieces <a href="https://github.com/vishalbakshi/portfolio-llm?tab=readme-ov-file#for-a-deeper-dive">on the GitHub repo for this project</a>.</p>
<p>I then asked Gemini to produce three sets of questions:</p>
<ul>
<li>High-Level Overview &amp; FAQ</li>
<li>Portfolio Deep Dive Q&amp;A</li>
<li>Out-of-Scope Questions</li>
</ul>
<p>I then wrote a first draft set of answers for each of the 40 or so questions Gemini created across these three categories. I iterated on my answers with Gemini to make them more readable and effective.</p>
</section>
<section id="evaluation" class="level2">
<h2 class="anchored" data-anchor-id="evaluation">Evaluation</h2>
<p>I wanted to test for three users:</p>
<ul>
<li>First interaction (has not read my list of themes, blog posts or wactched any of my vidoes)</li>
<li>Portfolio deep dive (has read my list of themes, and a few blog posts/videos)</li>
<li>Out of scope (a user who asks unrelated or unspecified questions in my llms_ctx.txt)</li>
</ul>
<p>I wanted to test two types of questions:</p>
<ul>
<li>Unit Test questions (verbatim to the questions in the llms_ctx.txt, tests if the LLM can retrieve answers explicitly listed)</li>
<li>Paraphrased/Follow-Up questions (questions that are similar in meaning but different in phrasing than the questions listed in llms_ctx.txt, or questions that cover multiple QA pairs)</li>
</ul>
<p>For each question, across all users and question types, I created <a href="https://github.com/vishalbakshi/portfolio-llm/blob/main/evals.csv">an evaluation spreadsheet</a> with the following columns:</p>
<ul>
<li>Model</li>
<li>Prompt Type (Unit Test, Paraphrased)</li>
<li>User</li>
<li>Prompt (the question)</li>
<li>Response</li>
<li>Gold Answer (either verbatim from llms_ctx.txt or a bulleted list of content the answer should cover)</li>
<li>Completeness (Full, Partial, None)</li>
<li>Accuracy (Perfect, Minor Error, Major Error)</li>
<li>Conciseness (Concise, Verbose)</li>
<li>Hallucination (None, Speculation, Factual Fabrication)</li>
<li>Format Adherence (Followed, Ignored)</li>
</ul>
<p>I generate an <a href="https://github.com/vishalbakshi/portfolio-llm/blob/main/evals.txt">XML-style version of my evals</a> with <a href="https://github.com/vishalbakshi/portfolio-llm/blob/main/Evals%20XML%20Generation.ipynb">a notebook</a> so I could feed it to an LLM for feedback.</p>
<p>For my first round of evaluation I used only two metrics: Fidelity (High, Medium, Low) and Hallucinations (High, Medium, Low). Upon conversing with Gemini, I learned that I was conflating verbosity with Hallucinations and should decompose Fidelity into Completeness and Accuracy for more clarity in evaluation.</p>
<p>My evaluation results were almost perfect (118/120 “Full” Completeness, 120/120 “Perfect” Accuracy and 120/120 “None” Hallucinations). I’m always wary of such high evaluation results:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
If your eval system says you are achieving 100% w/AI accuracy then your product is actually deeply broken, or you are tracking an irrelevant set of metrics
</p>
— Hamel Husain (<span class="citation" data-cites="HamelHusain">@HamelHusain</span>) <a href="https://twitter.com/HamelHusain/status/1843066772003733783?ref_src=twsrc%5Etfw">October 6, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>However, Claude Sonnet 4 (the model I used via Claude.ai) is highly capable and I provided it well-structured (question-answer pairs) context so it’s a relatively easy Q&amp;A task. I’m essentially providing it 120 few-shot examples of QA pairs which it can also use as a knowledge base.</p>
</section>
<section id="what-i-learned-in-the-process" class="level2">
<h2 class="anchored" data-anchor-id="what-i-learned-in-the-process">What I Learned in the Process</h2>
<ul>
<li>I realized that the style of the response is also dictated by the user prompt which is not in my control. So I’m focused more on the content delivered. It’s up to the user of Claude/Gemini/ChatGPT/etc. to dictate the style (verbose, explanatory, etc.)</li>
<li>I noticed that Claude doesn’t always include the URLs. Not sure how to improve that.</li>
<li>Realizing the benefit of having a chat ui interface as it would allow me to better control the model’s responses by injecting additional instructions or analyzing the response before it’s sent to the reader.</li>
<li>I realized long-term patterns in my work that I don’t see when I’m in the weeds. For example, for fastbook-benchmark, AgentFastbook, and TinyScaleLab I have focused on evals first while I develop other foundational skills.</li>
<li>Evaluating the model responses helped me identify gaps in my answers that I iterate upon.</li>
</ul>
</section>
<section id="what-this-means-for-job-seekers-and-employers" class="level2">
<h2 class="anchored" data-anchor-id="what-this-means-for-job-seekers-and-employers">What this Means for Job Seekers and Employers</h2>
<p>I might just be uninformed, but I think this is a novel approach to sharing a portfolio. I think this llms_ctx.txt approach could benefit both the job seeker and the employer. The job seeker benefits from the creation of the llms_ctx.txt file as they are forced to deeply think about common themes in their work and answer both broad and targeted questions about their projects and experience. The job seeker can also get a “sanity check” on what roles they are well suited for by posing as a hiring manager in a conversation with an LLM they have provided this context to. I also think that this portfolio style could benefit the hiring manager. The hiring manager can have a deep conversation with the LLM to evaluate the candidate across different desired skills/job requirements/experience requirements, especially those that are not explicitly mentioned but need to be inferred from th candidate’s body of work.</p>
<p>There’s also an opportunity to operationalize and systematize my end-to-end process for generating the llms_ctx.txt. You could imagine a UI which guides the user across the pipeline that I followed:</p>
<ul>
<li>Construct metadata around their existing work (blogs, videos, repos, resume, CV)</li>
<li>Generate and iterate on themes underpinning their work.</li>
<li>Generate and iterate on questions and answers related to those themes.</li>
<li>Construct the llms_txt.ctx</li>
<li>Evaluate model responses across 3 dimensions (Completeness, Accuracy, Hallucinations).</li>
</ul>
<p>I believe this end-to-end process could be operationalized into a valuable app, and I’m open-sourcing the methodology in the hopes that others will build upon it.</p>
</section>
<section id="try-it-yourself" class="level2">
<h2 class="anchored" data-anchor-id="try-it-yourself">Try It Yourself</h2>
<p>I’ll end with a call to action: try this for your own work/experience and let me know how it goes! I’m happy to be a test user for your llms_ctx.txt. Just ping me <a href="https://x.com/vishal_learner">on Twitter</a>.</p>
<p>I hope this project unlocks a new universe of opportunities in the job search space. I also hope that this approach allows folks from unconventional or non-traditional backgrounds (like myself) who rely on self-taught and boostrapped methods of experience (taking courses, writing blog posts, publishing YouTube videos) to synthesize their work in a cohesive way. I will continue to iterate on my llms_ctx.txt file, and have conversations with an LLM using it at each step of my professional journey, improving both the file and my professional development along the way.</p>


</section>

 ]]></description>
  <category>Career</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-26-portfolio-llm/</guid>
  <pubDate>Thu, 26 Jun 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Takeaways from Gemini Deep Research Report on Small Batch Training Challenges</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-18-small-batch-report/</link>
  <description><![CDATA[ 




<div id="cell-1" class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> CrossEntropyLoss</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I’ve recently been training models on the fastai <a href="https://github.com/fastai/imagenette?tab=readme-ov-file">Imagenette dataset</a> to gain some intuition on what improves downstream performance (accuracy). <a href="https://vishalbakshi.github.io/blog/posts/2025-06-18-imagenette/">My latest experiment</a> was to train three models on different batch sizes and learning rates (for a fixed 5 epochs) to understand the relationship between the two.</p>
<p>I posted my initial musing (after I had analyzed results for batch sizes 32 to 2048) that lowering the batch size might continue to yield higher accuracy. Jeremy validated this approach:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
That’s a great question! Stable low bs training isn’t easy, but it’s a good plan :)
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1930486029607416069?ref_src=twsrc%5Etfw">June 5, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I also prompted Allen AI’s <a href="https://paperfinder.allen.ai/chat/606ffc67-5539-47a9-8c8a-ec5820666ccc?profile=paper-finder-only">Paper Finder</a> with:</p>
<blockquote class="blockquote">
<p>strategies to make low batch size training more stable and improve accuracy for image recognition</p>
</blockquote>
<p>Imagenette is unlocking an entire new lane of research and experimentation for me, helping me towards my <a href="https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/">TinyScaleLab project goal</a> of training and analyzing high performant tiny language models.</p>
<p>In this blog post, I’ll walk through the Gemini Deep Research and Ai2 Paper Finder findings. The full Deep Research report is in <a href="https://docs.google.com/document/d/1AWoW4sOQ_iR_3pxsTRzYOT0cql60ux0Sjrt4rbLilZM/edit?usp=sharing">this Google Doc</a>.</p>
</section>
<section id="geminis-deep-research-report" class="level2">
<h2 class="anchored" data-anchor-id="geminis-deep-research-report">Gemini’s Deep Research Report</h2>
<p>Here was my initial prompt:</p>
<blockquote class="blockquote">
<p>I recently have been training xresnet18, xresnet34 and xse_resnext50 on the Imagenette dataset by fast.ai (which is a 10k subset of ImageNet with 10 easily classified classes). I have trained on batch sizes from 1 to 2048. Generally speaking, the highest accuracy achieved increases from a batch size of 1 to a batch size of 8, 16 or 32 (depending on the model/learning rate) and then decreases as batch size increases to 2048. This makes me want to explore small batch size training for this project. Jeremy Howard tweeted that “Stable low bs training isn’t easy, but it’s a good plan”. I want you to help me answer two questions in this chat:</p>
<ol type="1">
<li><p>Why is stable low batch size training difficult?</p></li>
<li><p>What techniques are there (either in literature/arxiv, blog posts or forums) to make low batch size training stable? I’m most interested in improving the accuracy of low batch size trainings.</p></li>
</ol>
</blockquote>
<p>I’ll paste the entire executive summary it generated, as its a good one (emphasis mine):</p>
<blockquote class="blockquote">
<p>Training deep learning models with small batch sizes presents a unique set of challenges, primarily stemming from high gradient variance during optimization and the inherent limitations of standard Batch Normalization with few samples. However, this training regime also offers the potential for <mark>improved model generalization</mark>. This report investigates the difficulties associated with stable low batch size training and explores techniques to mitigate these issues, with a particular focus on enhancing model accuracy. For architectures like xresnet, overcoming the instability of Batch Normalization with small batches is a critical first step, often addressed by substituting it with alternatives like <mark>Group Normalization</mark>. Stability and accuracy can be further improved through <mark>careful management of learning rates</mark>, including the use of adaptive schedulers and awareness of optimizer-specific phenomena such as the “surge” in optimal learning rates for Adam-family optimizers. <mark>The choice of optimizer itself</mark>, typically between SGD with momentum and adaptive methods like AdamW, also plays a significant role, alongside appropriate <mark>regularization strategies tailored to the small-batch context</mark>.</p>
</blockquote>
<p>The report starts by outlining why small batch sizes lead to unstable training. Gradient updates using a small batch size “may not accurately reflect the gradient of the true loss function that would be computed over the entire dataset” and “is an estimate derived from a very limited subset of the training data”.</p>
</section>
<section id="small-batch-sizes-the-double-edged-sword" class="level2">
<h2 class="anchored" data-anchor-id="small-batch-sizes-the-double-edged-sword">Small Batch Sizes: The Double Edged Sword</h2>
<p>On one hand, small batch size for a fixed number epochs provide more gradient updates and thus lower the loss. In the plot below (xresnet18) the ideal batch size (16-32) performs better than larger batch sizes. On the other hand, the larger number of updates will take longer and the GPU will be less utilized.</p>
<p><strong>xresnet18</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="lr_acc_18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="xresnet18 batch size vs accuracy for different learning rates"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-18-small-batch-report/lr_acc_18.png" class="img-fluid figure-img" alt="xresnet18 batch size vs accuracy for different learning rates"></a></p>
<figcaption>xresnet18 batch size vs accuracy for different learning rates</figcaption>
</figure>
</div>
<blockquote class="twitter-tweet blockquote" data-dnt="true" align="center" data-conversation="none">
<p lang="en" dir="ltr">
We covered this in some of our earlier courses - lower batch sizes provide more updates, which should give better results for a fixed # epochs.
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1927192030335132090?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Additionally, as the Gemini report goes on to say:</p>
<blockquote class="blockquote">
<p>Small batches can lead to gradients that are “bigger and chaotic” because an incorrect prediction on a single data point within a tiny batch can result in a disproportionately large loss and, subsequently, a large gradient update compared to its effect in a larger batch…high gradient noise, stemming from the limited data used for each estimation, leads to more volatile and less precise parameter updates</p>
</blockquote>
<p>This was a good opportunity to do a quick refresher on cross entropy loss so I worked through <a href="https://github.com/fastai/fastbook/blob/master/05_pet_breeds.ipynb">Chapter 5 of fastbook</a> again and wrote up <a href="https://vishalbakshi.github.io/blog/posts/2025-06-11-CELoss/">a blog post</a> and <a href="https://www.youtube.com/watch?v=swHhoP53jq4">video walkthrough</a> on that.</p>
<p>Suppose we have a batch size of two for a binary classification task:</p>
<div id="cell-17" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="90fce2ca-d659-41a1-9e29-457566223b40" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">acts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tensor([[<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.5</span>], [<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]], requires_grad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb2-2">acts</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>tensor([[0.4000, 9.5000],
        [4.0000, 5.0000]], requires_grad=True)</code></pre>
</div>
</div>
<p>With the following targets—the first batch item target is the first class (index <code>0</code>), which has a very wrong small activation.</p>
<div id="cell-19" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">targ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tensor([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span></code></pre></div>
</div>
<div id="cell-20" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="14e2581f-1023-4b2d-e27b-4abdfd25ab17" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CrossEntropyLoss()(acts, targ)</span>
<span id="cb5-2">loss</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor(4.7067, grad_fn=&lt;NllLossBackward0&gt;)</code></pre>
</div>
</div>
<div id="cell-21" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="a9c7c33f-a43e-49d1-a45b-adb6bf7a6fca" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">loss.backward()</span>
<span id="cb7-2">acts.grad</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor([[-0.4999,  0.4999],
        [ 0.1345, -0.1345]])</code></pre>
</div>
</div>
<p>Now suppose we had the same two items but in a batch size of 8.</p>
<div id="cell-23" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">acts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tensor(</span>
<span id="cb9-2">    [[ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4000</span>,  <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">9.5000</span>], <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># same item as before</span></span>
<span id="cb9-3">     [ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">4.0000</span>,  <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.0000</span>], <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># same item as before</span></span>
<span id="cb9-4">     [ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.3367</span>,  <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1288</span>],</span>
<span id="cb9-5">     [ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2345</span>,  <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2303</span>],</span>
<span id="cb9-6">     [<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.1229</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1863</span>],</span>
<span id="cb9-7">     [ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.2082</span>, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.6380</span>],</span>
<span id="cb9-8">     [ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.4617</span>,  <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2674</span>],</span>
<span id="cb9-9">     [ <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5349</span>,  <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.8094</span>]], requires_grad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
</div>
<p>Adding 6 items to the targets.</p>
<div id="cell-25" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">targ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tensor([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span></code></pre></div>
</div>
<div id="cell-26" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c1f16f85-df02-4d87-f5c2-2ca579425447" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> CrossEntropyLoss()(acts, targ)</span>
<span id="cb11-2">loss</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor(1.5563, grad_fn=&lt;NllLossBackward0&gt;)</code></pre>
</div>
</div>
<p>Note that the loss is smaller.</p>
<div id="cell-28" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="01eb068c-1918-4dad-c0f4-594b01c14ee5" data-execution_count="11">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">loss.backward()</span>
<span id="cb13-2">acts.grad</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([[-0.1250,  0.1250],
        [ 0.0336, -0.0336],
        [-0.0560,  0.0560],
        [ 0.0626, -0.0626],
        [ 0.0352, -0.0352],
        [-0.0069,  0.0069],
        [ 0.0686, -0.0686],
        [ 0.0540, -0.0540]])</code></pre>
</div>
</div>
<p>The loss and gradients are much smaller. The impact of the one confidently wrong prediction has decreased with larger batch size.</p>
<p>There are also two other factors at play, as the Gemini report states:</p>
<blockquote class="blockquote">
<p>On one hand, the noisy gradients can cause the optimization process to oscillate significantly around an optimal solution, making it challenging for the model to settle into a good minimum and potentially slowing down overall convergence</p>
</blockquote>
<blockquote class="blockquote">
<p>On the other hand, this very noise and the resultant exploratory behavior can be beneficial. The stochasticity introduced by small batches can act as a form of implicit regularization, helping the model to escape sharp, narrow local minima in the loss landscape and instead find flatter, broader minima</p>
</blockquote>
<p>The push and pull between the pros (faster updates, implicit regularization) and cons (longer training time, GPU underutilization, oscillating around minima, chaotic gradients/high gradient noise) makes small batch training a fascinating topic. The very characteristics that provide benefit to the training process also damage it.</p>
</section>
<section id="small-batch-size-and-batch-normalization" class="level2">
<h2 class="anchored" data-anchor-id="small-batch-size-and-batch-normalization">Small Batch Size and Batch Normalization</h2>
<p>In addition to making the gradient noisy, small batch sizes make Batch Normalization statistics noisy.</p>
<blockquote class="blockquote">
<p>BN standardizes the activations within a network by calculating mean and variance statistics per batch. When batch sizes are very small (e.g., 1, 2, or 4 samples), these batch-wise statistics become extremely noisy and unreliable estimators of the true population statistics across the entire dataset</p>
</blockquote>
<p>From the <a href="https://arxiv.org/abs/1803.08494">Group Normalization paper</a> (for which I have done a <a href="https://www.youtube.com/watch?v=ZCTcxNEGens">video walkthrough</a>):</p>
<blockquote class="blockquote">
<p>normalizing along the batch dimension introduces problems — BN’s error increases rapidly when the batch size becomes smaller, caused by inaccurate batch statistics estimation.</p>
</blockquote>
<p>The three models I’m using all have a considerable number of Batch Normalization layers.</p>
<div id="cell-37" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fastai.vision.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span></span></code></pre></div>
</div>
<div id="cell-38" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="bbe244fe-90e6-455f-fdb1-f14334b8c350" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">bn_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb16-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> module <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> xresnet18().modules():</span>
<span id="cb16-3">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(module, nn.BatchNorm2d): bn_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb16-4">bn_count</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>22</code></pre>
</div>
</div>
<div id="cell-39" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9b07f053-6422-4605-ea78-61677ea481f9" data-execution_count="14">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">bn_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb18-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> module <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> xresnet34().modules():</span>
<span id="cb18-3">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(module, nn.BatchNorm2d): bn_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb18-4">bn_count</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>38</code></pre>
</div>
</div>
<div id="cell-40" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="176953d5-7ca7-4866-bd9c-695e5105e9a5" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">bn_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb20-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> module <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> xse_resnext50().modules():</span>
<span id="cb20-3">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(module, nn.BatchNorm2d): bn_count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb20-4">bn_count</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>55</code></pre>
</div>
</div>
</section>
<section id="techniques-for-stable-and-accurate-low-batch-size-training" class="level2">
<h2 class="anchored" data-anchor-id="techniques-for-stable-and-accurate-low-batch-size-training">Techniques for Stable and Accurate Low Batch Size Training</h2>
<p>The fascinating complexity of stable small batch training is summarized in the report with the following:</p>
<blockquote class="blockquote">
<p>Addressing the challenges of small batch training requires a multi-pronged approach, focusing on adapting learning rate strategies, rethinking normalization layers, selecting appropriate optimizers, and employing advanced gradient management and regularization techniques.</p>
</blockquote>
<section id="learning-rate" class="level3">
<h3 class="anchored" data-anchor-id="learning-rate">Learning Rate</h3>
<blockquote class="blockquote">
<p>for small batches, the high gradient noise often necessitates smaller learning rates to prevent divergence and ensure stability</p>
</blockquote>
<p>We can see that there’s evidence for that from my <a href="https://vishalbakshi.github.io/blog/posts/2025-06-18-imagenette/">Imagenette experiments</a>. For the xresnet18, xresnet34 and xse_resnext50 models (top to bottom charts, respectively), 1e-3 yields higher accuracy for lower batch sizes than 1e-2.</p>
<p><strong>xresnet18</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="lr_acc_18.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="xresnet18 batch size vs accuracy for different learning rates"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-18-small-batch-report/lr_acc_18.png" class="img-fluid figure-img" alt="xresnet18 batch size vs accuracy for different learning rates"></a></p>
<figcaption>xresnet18 batch size vs accuracy for different learning rates</figcaption>
</figure>
</div>
<p><strong>xresnet34</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="lr_acc_34.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="xresnet34 batch size vs accuracy for different learning rates"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-18-small-batch-report/lr_acc_34.png" class="img-fluid figure-img" alt="xresnet34 batch size vs accuracy for different learning rates"></a></p>
<figcaption>xresnet34 batch size vs accuracy for different learning rates</figcaption>
</figure>
</div>
<p><strong>xse_resnext50</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="lr_acc_50.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="xse_resnext50 batch size vs accuracy for different learning rates"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-18-small-batch-report/lr_acc_50.png" class="img-fluid figure-img" alt="xse_resnext50 batch size vs accuracy for different learning rates"></a></p>
<figcaption>xse_resnext50 batch size vs accuracy for different learning rates</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p>small batch sizes (e.g., 2 to 32) can be more robust to learning rate choices</p>
</blockquote>
<p>I witnessed the second point during my training runs as well. For xresnet34 and a batch size of 8 or 16, the difference in accuracy between learning rates of 1e-4, 1e-3 and 1e-2 was 10%. For a batch size of 1024, the difference in accuracy was 40%. xresnet18 had a similar trend while xse_resnext50 was more robust to changes in learning rates (1e-4, 1e-3, 1e-2) as the accuracy varied about 10-20% across batch sizes of 2 to 1024. In the charts above, this is visualized by the diverging LR curves as batch size increases.</p>
<blockquote class="blockquote">
<p>A learning rate warm-up strategy, where training begins with a very small learning rate that is gradually increased to its target value over a few initial epochs, can significantly stabilize the early phases of training.</p>
</blockquote>
<p>My training runs already did this by default (using fastai’s <code>Learner</code> and <code>vision_learner</code>), though I haven’t experimented with any available parameters related to this (e.g.&nbsp;number of warmup steps).</p>
<blockquote class="blockquote">
<p>The optimal learning rate strategy is non-linear, optimizer-dependent, and may require empirical tuning guided by these more nuanced theoretical understandings.</p>
</blockquote>
</section>
<section id="alternative-forms-of-normalization" class="level3">
<h3 class="anchored" data-anchor-id="alternative-forms-of-normalization">Alternative Forms of Normalization</h3>
<p>Gemini found in its research that alternative forms of normalization (other than Batch Normalization) can improve small batch size performance. Most notably, in the Group Normalization paper they found that Group Normalization resulted in a 10% lower error rate than Batch Normalization for small batch sizes. Group Normalization calculates mean and variance for a group of channels for a single image, thereby being <em>batch independent</em>, so a small batch size doesn’t make the statistics any noisier (as is the case for Batch Normalization where the mean and variance are calculated across all images in the batch). However, there’s two sides to this trade-off. As the paper states:</p>
<blockquote class="blockquote">
<p>BN’s mean and variance computation introduces uncertainty caused by the stochastic batch sampling, which helps regularization. This uncertainty is missing in GN (and LN/IN). But it is possible that GN combined with a suitable regularizer will improve results. This can be a future research topic.</p>
</blockquote>
<p>Gemini also suggests Layer Normalization (calculating mean and variance across all channels for a single image) and Instance Normalization (across a single channel for a single image) as these are both also batch independent. However, the Group Normalization paper finds that these two perform worse than Group Normalization.</p>
</section>
<section id="optimizers-and-regularization" class="level3">
<h3 class="anchored" data-anchor-id="optimizers-and-regularization">Optimizers and Regularization</h3>
<p>Finally, Gemini suggested to try out different optimizers (and tuning their hyperparameters) and regularization techniques (weight decay, data augmentation), both things I wanted to experiment with going into this project.</p>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>Based on Gemini’s research and my reading of the Group Normalization paper I plan on experimenting on the following:</p>
<ul>
<li>Replace Batch Normalization layers with Group Normalization.</li>
<li>Add a regularization method like weight decay.</li>
<li>Try out different optimizers using Benjamin Warner’s <a href="https://optimi.benjaminwarner.dev/">optimi</a> library.</li>
<li>Try out different data augmentation techniques from Benjamin Warner’s <a href="https://fastxtend.benjaminwarner.dev/vision.augment.batch.html">fastxtend</a> library.</li>
</ul>
<p>At each step, I use <code>lr_find</code> and sample three stable LRs, and focus on small batch sizes of {2, 4, 8, 16, 32, 64}. I’m particularly interested in seeing how these experiments affect the three models I’m using (xresnet18, xresnet34, xse_resnext50) as xse_resnext50 was more robust to larger LRs than the other two.</p>
<p>I’ll be documenting my findings in blog posts as well as on my <a href="https://www.youtube.com/@vishal_learner">YouTube channel</a> so please subscribe to follow along!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>fastai</category>
  <category>imagenette</category>
  <category>TinyScaleLab</category>
  <category>deep learning</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-18-small-batch-report/</guid>
  <pubDate>Wed, 18 Jun 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>An Analysis of Batch Size vs. Learning Rate on Imagenette</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-18-imagenette/</link>
  <description><![CDATA[ 




<div id="cell-1" class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fastai.vision.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fastai.callback.wandb <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> WandbCallback</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In <a href="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/">my previous blog post</a> and <a href="https://youtu.be/5xCUEaowcTE">video</a> I worked through my initial imagenette experiments.</p>
<blockquote class="blockquote">
<p>Imagenette is a subset of 10 easily classified classes from Imagenet (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute).</p>
</blockquote>
<p>With a batch size of 64 and three different LRs (1e-4, 1e-3, 1e-2) I achieved the following results using three models (xresnet34, xse_resnext50, xresnet18):</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Model/Learning Rate</th>
<th style="text-align: center;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">xresnet34/1e-2</td>
<td style="text-align: center;">0.7929</td>
</tr>
<tr class="even">
<td style="text-align: center;">xse_resnext50/1e-2</td>
<td style="text-align: center;">0.7926</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet18/1e-2</td>
<td style="text-align: center;">0.7870</td>
</tr>
<tr class="even">
<td style="text-align: center;">xresnet34/1e-3</td>
<td style="text-align: center;">0.7776</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet18/1e-3</td>
<td style="text-align: center;">0.7743</td>
</tr>
<tr class="even">
<td style="text-align: center;">xse_resnext50/1e-3</td>
<td style="text-align: center;">0.7526</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet18/1e-1</td>
<td style="text-align: center;">0.7373</td>
</tr>
<tr class="even">
<td style="text-align: center;">xse_resnext50/1e-4</td>
<td style="text-align: center;">0.6532</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet34/1e-4</td>
<td style="text-align: center;">0.6446</td>
</tr>
<tr class="even">
<td style="text-align: center;">xresnet18/1e-4</td>
<td style="text-align: center;">0.6171</td>
</tr>
</tbody>
</table>
<p>There was a hierarchy of LRs: 1e-2 performed best, followed by 1e-3 and 1e-4.</p>
<p>In this notebook I’m going to expand my training runs to more batch sizes: [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048]. In each case, I’ll use <code>lr_find</code> to determine three stable learning rates.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<div id="cell-7" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb2-3">df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/content/2025-06-04-imagenette-runs.csv"</span>)</span>
<span id="cb2-4">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run"</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x: x.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-"</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>])</span>
<span id="cb2-5">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bs"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run"</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x: x.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-"</span>)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]).astype(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _lr(x):</span>
<span id="cb2-8">    _map <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"05"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-5"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"06"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-6"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"07"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-7"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.0001"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-4"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.001"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-3"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.01"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0.1"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-1"</span>}</span>
<span id="cb2-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> _map[x.split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"-"</span>)[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]]</span>
<span id="cb2-10"></span>
<span id="cb2-11">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run"</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">apply</span>(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x: _lr(x))</span>
<span id="cb2-12">df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Categorical(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>], categories<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-7"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-6"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-5"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-4"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-3"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1e-1"</span>])</span></code></pre></div>
</div>
<p>In total there were 123 training runs.</p>
<div id="cell-9" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8d4136e7-853b-4711-a504-aeb14b3ff108" data-execution_count="10">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">df.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(123, 5)</code></pre>
</div>
</div>
<p>The best training run goes to xresnet34 with a batch size of 16 and a learning rate of 1e-3.</p>
<div id="cell-11" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:81}}" data-outputid="2e30e554-1c1a-495f-9be6-aa7b0fe29193" data-execution_count="11">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">df[df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'acc'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'acc'</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>()]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<div id="df-bd697f8f-dc53-42ec-9e0e-ea34025e8e15" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">run</th>
<th data-quarto-table-cell-role="th">acc</th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">bs</th>
<th data-quarto-table-cell-role="th">lr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">9</td>
<td>imagenette-xresnet34-bs-16-lr-0.001</td>
<td>0.800764</td>
<td>xresnet34</td>
<td>16</td>
<td>1e-3</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-bd697f8f-dc53-42ec-9e0e-ea34025e8e15')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-bd697f8f-dc53-42ec-9e0e-ea34025e8e15 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-bd697f8f-dc53-42ec-9e0e-ea34025e8e15');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    </div>
  </div>
</div>
</div>
<p>The top 10 training runs were for a LR of 1e-3 or 1e-2.</p>
<div id="cell-13" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:363}}" data-outputid="c8fa0fa4-c586-4b1c-c1cd-c541e1b8a267" data-execution_count="12">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">df.sort_values(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>, ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>).head(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<div id="df-77f8aa8d-c052-47a9-9bb5-915ebc8e4364" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">run</th>
<th data-quarto-table-cell-role="th">acc</th>
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th">bs</th>
<th data-quarto-table-cell-role="th">lr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">9</td>
<td>imagenette-xresnet34-bs-16-lr-0.001</td>
<td>0.800764</td>
<td>xresnet34</td>
<td>16</td>
<td>1e-3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">66</td>
<td>imagenette-xresnet18-bs-32-lr-0.01</td>
<td>0.799745</td>
<td>xresnet18</td>
<td>32</td>
<td>1e-2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">75</td>
<td>imagenette-xresnet18-bs-64-lr-0.01</td>
<td>0.797452</td>
<td>xresnet18</td>
<td>64</td>
<td>1e-2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>imagenette-xresnet18-bs-16-lr-0.01</td>
<td>0.796433</td>
<td>xresnet18</td>
<td>16</td>
<td>1e-2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>imagenette-xresnet18-bs-8-lr-0.001</td>
<td>0.795414</td>
<td>xresnet18</td>
<td>8</td>
<td>1e-3</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">25</td>
<td>imagenette-xresnet34-bs-8-lr-0.001</td>
<td>0.795414</td>
<td>xresnet34</td>
<td>8</td>
<td>1e-3</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>imagenette-xresnet34-bs-16-lr-0.01</td>
<td>0.795159</td>
<td>xresnet34</td>
<td>16</td>
<td>1e-2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">84</td>
<td>imagenette-xresnet18-bs-128-lr-0.01</td>
<td>0.791338</td>
<td>xresnet18</td>
<td>128</td>
<td>1e-2</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">76</td>
<td>imagenette-xresnet34-bs-64-lr-0.01</td>
<td>0.790573</td>
<td>xresnet34</td>
<td>64</td>
<td>1e-2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">67</td>
<td>imagenette-xresnet34-bs-32-lr-0.01</td>
<td>0.789554</td>
<td>xresnet34</td>
<td>32</td>
<td>1e-2</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-77f8aa8d-c052-47a9-9bb5-915ebc8e4364')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-77f8aa8d-c052-47a9-9bb5-915ebc8e4364 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-77f8aa8d-c052-47a9-9bb5-915ebc8e4364');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-cea70ab5-c2c5-42c0-a9aa-2d37f96325b0">
      <button class="colab-df-quickchart" onclick="quickchart('df-cea70ab5-c2c5-42c0-a9aa-2d37f96325b0')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-cea70ab5-c2c5-42c0-a9aa-2d37f96325b0 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div>
</div>
<p>All three models achieved a max accuracy within 1.2% of each other.</p>
<div id="cell-15" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:210}}" data-outputid="1bff0dea-551a-4909-d258-99917c965ff5" data-execution_count="14">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">df.groupby([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model"</span>])[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>().sort_values(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">acc</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">xresnet34</td>
<td>0.800764</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">xresnet18</td>
<td>0.799745</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">xse_resnext50</td>
<td>0.788280</td>
</tr>
</tbody>
</table>

</div><br><label><b>dtype:</b> float64</label>
</div>
</div>
<p>A batch size of 16 yielded the highest accuracy, with 8, 32, 64 and 128 within 1%. Accuracy drops significantly for a batch size of 1, 1024 and 2048 showing that too large or too small a batch size is detrimental to training.</p>
<div id="cell-17" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:492}}" data-outputid="aca37107-cb01-462f-d674-f85c9ce8b482" data-execution_count="16">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">df.groupby([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bs"</span>])[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>().sort_values(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">acc</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">bs</th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">16</td>
<td>0.800764</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">32</td>
<td>0.799745</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">64</td>
<td>0.797452</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">8</td>
<td>0.795414</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">128</td>
<td>0.791338</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>0.784968</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">256</td>
<td>0.764841</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">512</td>
<td>0.731975</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.719745</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1024</td>
<td>0.662166</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2048</td>
<td>0.485350</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.452229</td>
</tr>
</tbody>
</table>

</div><br><label><b>dtype:</b> float64</label>
</div>
</div>
<p>As we saw earlier, the highest accuracy was achieved with a learning rate of 1e-3, with 1e-2 right on its tail.</p>
<div id="cell-19" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:304}}" data-outputid="4ed7d42b-5d78-43c1-bade-052f414da0ed" data-execution_count="18">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">df.groupby([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>], observed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>().sort_values(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">acc</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">lr</th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-3</td>
<td>0.800764</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-2</td>
<td>0.799745</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-4</td>
<td>0.715414</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-5</td>
<td>0.526624</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-6</td>
<td>0.304713</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-7</td>
<td>0.150828</td>
</tr>
</tbody>
</table>

</div><br><label><b>dtype:</b> float64</label>
</div>
</div>
<p>Finally, I’ll look at the maximum accuracy achieved for each model/learning rate/batch size combination.</p>
<p>For xresnet18, some interesting patterns:</p>
<ul>
<li>For each learning rate, the maximum accuracy increases up to a point, then decreases, illustrating how batch sizes too small or too large lead to worse performance
<ul>
<li>1e-4: acc increases up to bs=8 then decreases</li>
<li>1e-3: acc increases up to bs=8 then decreases</li>
<li>1e-2: acc increases up to bs=32 then decreases</li>
</ul></li>
</ul>
<div id="cell-22" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:175}}" data-outputid="53e68ba5-db55-4fcf-f64e-2de3b94683f5" data-execution_count="21">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model == 'xresnet18'"</span>)</span>
<span id="cb10-2">pd.crosstab(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>], _df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bs"</span>], values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>], aggfunc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max"</span>).sort_index(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<div id="df-a8a72bd5-679d-4766-8624-a87fadf17809" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">bs</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">8</th>
<th data-quarto-table-cell-role="th">16</th>
<th data-quarto-table-cell-role="th">32</th>
<th data-quarto-table-cell-role="th">64</th>
<th data-quarto-table-cell-role="th">128</th>
<th data-quarto-table-cell-role="th">256</th>
<th data-quarto-table-cell-role="th">512</th>
<th data-quarto-table-cell-role="th">1024</th>
<th data-quarto-table-cell-role="th">2048</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">lr</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-4</td>
<td>0.388535</td>
<td>0.608153</td>
<td>0.693503</td>
<td>0.704968</td>
<td>0.698089</td>
<td>0.665478</td>
<td>0.624713</td>
<td>0.512102</td>
<td>0.400000</td>
<td>0.310318</td>
<td>0.146497</td>
<td>0.000255</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-3</td>
<td>0.452229</td>
<td>0.709809</td>
<td>0.778344</td>
<td>0.795414</td>
<td>0.789299</td>
<td>0.784968</td>
<td>0.769427</td>
<td>0.744713</td>
<td>0.719236</td>
<td>0.647389</td>
<td>0.544459</td>
<td>0.336306</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-2</td>
<td>0.285605</td>
<td>0.649682</td>
<td>0.738089</td>
<td>0.778089</td>
<td>0.796433</td>
<td>0.799745</td>
<td>0.797452</td>
<td>0.791338</td>
<td>0.747006</td>
<td>0.731975</td>
<td>0.661147</td>
<td>0.485350</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-a8a72bd5-679d-4766-8624-a87fadf17809')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-a8a72bd5-679d-4766-8624-a87fadf17809 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-a8a72bd5-679d-4766-8624-a87fadf17809');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-196b94d7-b776-402c-85a0-8001c541b87f">
      <button class="colab-df-quickchart" onclick="quickchart('df-196b94d7-b776-402c-85a0-8001c541b87f')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-196b94d7-b776-402c-85a0-8001c541b87f button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div>
</div>
<p><strong>xresnet18</strong></p>
<div id="cell-24" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:454}}" data-outputid="d3906c9e-8828-4625-b89c-4e4fc9dc3488" data-execution_count="22">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">pd.crosstab(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>], _df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bs"</span>], values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>], aggfunc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max"</span>).sort_index(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>).T.plot(logx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-18-imagenette/index_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We see a similar pattern for xresnet34:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">lr</th>
<th style="text-align: center;">Inflection point (bs)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1e-7</td>
<td style="text-align: center;">–</td>
</tr>
<tr class="even">
<td style="text-align: center;">1e-6</td>
<td style="text-align: center;">–</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1e-5</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;">1e-4</td>
<td style="text-align: center;">16</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1e-3</td>
<td style="text-align: center;">16</td>
</tr>
<tr class="even">
<td style="text-align: center;">1e-2</td>
<td style="text-align: center;">16</td>
</tr>
</tbody>
</table>
<div id="cell-26" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:269}}" data-outputid="69811696-90e6-49a5-f85d-68a2c7fbfcf1" data-execution_count="23">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model == 'xresnet34'"</span>)</span>
<span id="cb12-2">pd.crosstab(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>], _df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bs"</span>], values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>], aggfunc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max"</span>).sort_index(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<div id="df-20fd735d-8058-4aeb-ae6c-3a7dc3eee40d" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">bs</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">8</th>
<th data-quarto-table-cell-role="th">16</th>
<th data-quarto-table-cell-role="th">32</th>
<th data-quarto-table-cell-role="th">64</th>
<th data-quarto-table-cell-role="th">128</th>
<th data-quarto-table-cell-role="th">256</th>
<th data-quarto-table-cell-role="th">512</th>
<th data-quarto-table-cell-role="th">1024</th>
<th data-quarto-table-cell-role="th">2048</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">lr</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-7</td>
<td>NaN</td>
<td>0.109554</td>
<td>0.109045</td>
<td>0.087389</td>
<td>0.100892</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-6</td>
<td>NaN</td>
<td>0.243822</td>
<td>0.180127</td>
<td>0.201274</td>
<td>0.159236</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-5</td>
<td>NaN</td>
<td>0.385478</td>
<td>0.456051</td>
<td>0.446879</td>
<td>0.428535</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-4</td>
<td>0.388535</td>
<td>0.597962</td>
<td>0.704459</td>
<td>0.709809</td>
<td>0.715414</td>
<td>0.680764</td>
<td>0.641529</td>
<td>0.560510</td>
<td>0.489172</td>
<td>0.393376</td>
<td>0.269299</td>
<td>0.212229</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-3</td>
<td>0.403567</td>
<td>0.719745</td>
<td>0.784968</td>
<td>0.795414</td>
<td>0.800764</td>
<td>0.787261</td>
<td>0.765860</td>
<td>0.751592</td>
<td>0.728408</td>
<td>0.667771</td>
<td>0.580127</td>
<td>0.430828</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-2</td>
<td>0.246624</td>
<td>0.638217</td>
<td>0.721019</td>
<td>0.776306</td>
<td>0.795159</td>
<td>0.789554</td>
<td>0.790573</td>
<td>0.787006</td>
<td>0.764841</td>
<td>0.723312</td>
<td>0.662166</td>
<td>0.385732</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-20fd735d-8058-4aeb-ae6c-3a7dc3eee40d')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-20fd735d-8058-4aeb-ae6c-3a7dc3eee40d button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-20fd735d-8058-4aeb-ae6c-3a7dc3eee40d');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-7ffdc5c0-ac7a-4ac5-8e6a-abd0a21467a8">
      <button class="colab-df-quickchart" onclick="quickchart('df-7ffdc5c0-ac7a-4ac5-8e6a-abd0a21467a8')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-7ffdc5c0-ac7a-4ac5-8e6a-abd0a21467a8 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div>
</div>
<p><strong>xresnet34</strong></p>
<div id="cell-28" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:454}}" data-outputid="926c22f9-ed42-4eba-81ef-f61a16f7884e" data-execution_count="24">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">pd.crosstab(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>], _df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bs"</span>], values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>], aggfunc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max"</span>).sort_index(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>).T.plot(logx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-13-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-18-imagenette/index_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>And a similar pattern for xse_resnext50 as well:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">lr</th>
<th style="text-align: center;">Inflection point (bs)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1e-7</td>
<td style="text-align: center;">8</td>
</tr>
<tr class="even">
<td style="text-align: center;">1e-6</td>
<td style="text-align: center;">–</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1e-5</td>
<td style="text-align: center;">–</td>
</tr>
<tr class="even">
<td style="text-align: center;">1e-4</td>
<td style="text-align: center;">8</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1e-3</td>
<td style="text-align: center;">16</td>
</tr>
<tr class="even">
<td style="text-align: center;">1e-2</td>
<td style="text-align: center;">32</td>
</tr>
</tbody>
</table>
<div id="cell-30" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:269}}" data-outputid="bb96c37f-36d4-4ad4-ef06-4ad434436263" data-execution_count="25">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">_df <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> df.query(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model == 'xse_resnext50'"</span>)</span>
<span id="cb14-2">pd.crosstab(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>], _df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bs"</span>], values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>], aggfunc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max"</span>).sort_index(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<div id="df-0c642622-075f-4525-b8d2-f0b575de9eb9" class="colab-df-container">
    <div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">bs</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">8</th>
<th data-quarto-table-cell-role="th">16</th>
<th data-quarto-table-cell-role="th">32</th>
<th data-quarto-table-cell-role="th">64</th>
<th data-quarto-table-cell-role="th">128</th>
<th data-quarto-table-cell-role="th">256</th>
<th data-quarto-table-cell-role="th">512</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">lr</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-7</td>
<td>0.106497</td>
<td>0.127389</td>
<td>0.150828</td>
<td>0.126624</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-6</td>
<td>0.117452</td>
<td>0.234395</td>
<td>0.291465</td>
<td>0.304713</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-5</td>
<td>0.239745</td>
<td>0.420127</td>
<td>0.502675</td>
<td>0.526624</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
<td>NaN</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-4</td>
<td>0.203057</td>
<td>0.568917</td>
<td>0.661147</td>
<td>0.660382</td>
<td>0.652229</td>
<td>0.639236</td>
<td>0.623949</td>
<td>0.601019</td>
<td>0.575541</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">1e-3</td>
<td>0.186752</td>
<td>0.642803</td>
<td>0.766624</td>
<td>0.774267</td>
<td>0.768917</td>
<td>0.743694</td>
<td>0.720510</td>
<td>0.699363</td>
<td>0.671847</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1e-2</td>
<td>0.140637</td>
<td>0.263185</td>
<td>0.564586</td>
<td>0.736306</td>
<td>0.788280</td>
<td>0.770701</td>
<td>0.776306</td>
<td>0.763567</td>
<td>0.725605</td>
</tr>
</tbody>
</table>

</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-0c642622-075f-4525-b8d2-f0b575de9eb9')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-0c642622-075f-4525-b8d2-f0b575de9eb9 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-0c642622-075f-4525-b8d2-f0b575de9eb9');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-713a171e-198c-4f12-b708-12d592f77d1d">
      <button class="colab-df-quickchart" onclick="quickchart('df-713a171e-198c-4f12-b708-12d592f77d1d')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-713a171e-198c-4f12-b708-12d592f77d1d button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div>
</div>
<p><strong>xse_xresnet50</strong></p>
<p>Looking at the accuracy curves for xse_resnext50 we see that it’s more robust to larger batch sizes (the accuracy tapers off slower than xresnet34 and xresnet18 as batch size increases past the inflection point).</p>
<div id="cell-33" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:454}}" data-outputid="dd37f3b1-85fe-45d0-b83e-cb3c9652442b" data-execution_count="26">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">pd.crosstab(df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"lr"</span>], _df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bs"</span>], values<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>_df[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"acc"</span>], aggfunc<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"max"</span>).sort_index(ascending<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>).T.plot(logx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-15-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-18-imagenette/index_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>I posted my initial musing (after I had analyzed results for batch sizes 32 to 2048) that lowering the batch size might continue to yield higher accuracy. Jeremy validated this approach:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
That’s a great question! Stable low bs training isn’t easy, but it’s a good plan :)
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1930486029607416069?ref_src=twsrc%5Etfw">June 5, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I recently started using Gemini Pro 2.5 (preview), and hadn’t yet tried out its Deep Research tool. I thought this would be an excellent opportunity to do so. I prompted Gemini with the following:</p>
<blockquote class="blockquote">
<p>I recently have been training xresnet18, xresnet34 and xse_resnext50 on the Imagenette dataset by fast.ai (which is a 10k subset of ImageNet with 10 easily classified classes). I have trained on batch sizes from 1 to 2048. Generally speaking, the highest accuracy achieved increases from a batch size of 1 to a batch size of 8, 16 or 32 (depending on the model/learning rate) and then decreases as batch size increases to 2048. This makes me want to explore small batch size training for this project. Jeremy Howard tweeted that “Stable low bs training isn’t easy, but it’s a good plan”. I want you to help me answer two questions in this chat:</p>
<ol type="1">
<li><p>Why is stable low batch size training difficult?</p></li>
<li><p>What techniques are there (either in literature/arxiv, blog posts or forums) to make low batch size training stable? I’m most interested in improving the accuracy of low batch size trainings.</p></li>
</ol>
</blockquote>
<p>I also prompted Allen AI’s <a href="https://paperfinder.allen.ai/chat/606ffc67-5539-47a9-8c8a-ec5820666ccc?profile=paper-finder-only">Paper Finder</a> with:</p>
<blockquote class="blockquote">
<p>strategies to make low batch size training more stable and improve accuracy for image recognition</p>
</blockquote>
<p>I have shared the Gemini Deep Research and Ai2 Paper Finder findings in <a href="https://vishalbakshi.github.io/blog/posts/2025-06-18-small-batch-report/">another blog post</a>.</p>
<p>Imagenette will unlock an entire new lane of research and experimentation for me, helping me towards my <a href="https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/">TinyScaleLab project goal</a> of training and analyzing high performant tiny language models.</p>
<p>Lastly, I’m growing my YouTube channel so if you haven’t already, please check it out and <a href="https://www.youtube.com/@vishal_learner">subscribe</a>!</p>
</section>
<section id="appendix-training-code" class="level2">
<h2 class="anchored" data-anchor-id="appendix-training-code">Appendix: Training Code</h2>
<p>Since I’m going to run a significantly larger number of trainings than my initial notebook, I’ll wrap my code into functions/dictionaries for a tighter loop, similar to what Jeremy did in his <a href="https://www.kaggle.com/code/jhoward/scaling-up-road-to-the-top-part-3?scriptVersionId=99313071&amp;cellId=31">Scaling Up: Road to the Top, Part 3</a> notebook.</p>
<p>I ran <code>lr_find</code> for each model/batch size combination and checked that for all combinations, the loss curve was stable for the selected learning rates.</p>
<div id="cell-41" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:37}}" data-outputid="d8684f08-2d75-4679-bf77-4a8360d5a756">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> untar_data(URLs.IMAGENETTE_160)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="99008512" class="" max="99003388" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.01% [99008512/99003388 00:02&lt;00:00]
    </div>
    
</div>
</div>
<div id="cell-42" class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">lbl_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb17-2">    n01440764<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tench'</span>,</span>
<span id="cb17-3">    n02102040<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'English springer'</span>,</span>
<span id="cb17-4">    n02979186<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cassette player'</span>,</span>
<span id="cb17-5">    n03000684<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'chain saw'</span>,</span>
<span id="cb17-6">    n03028079<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'church'</span>,</span>
<span id="cb17-7">    n03394916<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'French horn'</span>,</span>
<span id="cb17-8">    n03417042<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'garbage truck'</span>,</span>
<span id="cb17-9">    n03425413<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gas pump'</span>,</span>
<span id="cb17-10">    n03445777<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'golf ball'</span>,</span>
<span id="cb17-11">    n03888257<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'parachute'</span></span>
<span id="cb17-12">)</span></code></pre></div>
</div>
<div id="cell-43" class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">imagenette <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataBlock(blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (ImageBlock, CategoryBlock),</span>
<span id="cb18-2">                       get_items <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_image_files,</span>
<span id="cb18-3">                       get_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Pipeline([parent_label, lbl_dict.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>]),</span>
<span id="cb18-4">                       splitter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GrandparentSplitter(valid_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'val'</span>),</span>
<span id="cb18-5">                       item_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomResizedCrop(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>, min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.35</span>),</span>
<span id="cb18-6">                       batch_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Normalize.from_stats(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>imagenet_stats))</span></code></pre></div>
</div>
<div id="cell-44" class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _dls(bs): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> imagenette.dataloaders(path, bs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>bs)</span></code></pre></div>
</div>
<div id="cell-45" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="618ee92e-6b22-4fe4-c71c-3c5fab4c5c3e">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">_dls(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>).bs, _dls(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>).bs, _dls(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">256</span>).bs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>(64, 128, 256)</code></pre>
</div>
</div>
<div id="cell-46" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:752}}" data-outputid="785bbfd1-dc53-45c7-ae6b-d7ed244e2e18">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">_dls(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>).show_batch()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-21-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-18-imagenette/index_files/figure-html/cell-21-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="cell-47" class="cell">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">models <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xresnet34'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xse_resnext50'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xresnet18'</span>]</span></code></pre></div>
</div>
<div id="cell-48" class="cell">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#batch_sizes = (32, 64, 128, 256, 512, 1024, 2048)</span></span>
<span id="cb24-2">batch_sizes <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span>)</span>
<span id="cb24-3">lrs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-2</span>)</span></code></pre></div>
</div>
<div id="cell-49" class="cell">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">wandb.login()</span></code></pre></div>
</div>
<div id="cell-50" class="cell">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> bs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> batch_sizes:</span>
<span id="cb26-2">    dls <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _dls(bs)</span>
<span id="cb26-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> dls.bs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> bs</span>
<span id="cb26-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> model <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> models:</span>
<span id="cb26-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xse_resnext50'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> bs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>: <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># avoid Expected more than 1 value per channel when training, got input size torch.Size([1, 4096])</span></span>
<span id="cb26-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> lr <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> lrs:</span>
<span id="cb26-7">            wandb.init(</span>
<span id="cb26-8">                project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb26-9">                name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"imagenette-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-bs-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>bs<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-lr-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb26-10">                tags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"bs=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>bs<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"lr=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb26-11">                )</span>
<span id="cb26-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xse_resnext50'</span>: learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb26-13">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xresnet18'</span>: learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb26-14">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xresnet34'</span>: learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb26-15"></span>
<span id="cb26-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> learn.no_logging() <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> learn.no_mbar(): learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, lr)</span>
<span id="cb26-17">            wandb.finish()</span></code></pre></div>
</div>
<p>Using <code>lr_find</code>, I found that xresnet18 was stable for 1e-4, 1e-3 and 1e-2 LRs but the other two were not. Instead, they were stable for LRs of 1e-7, 1e-6 and 1e-5. So I ran training runs for those two models and LRs for batch sizes of 2, 4, 8 and 16.</p>
<div id="cell-52" class="cell">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> bs <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> batch_sizes:</span>
<span id="cb27-2">    dls <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _dls(bs)</span>
<span id="cb27-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> dls.bs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> bs</span>
<span id="cb27-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> model <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xresnet34'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xse_resnext50'</span>]:</span>
<span id="cb27-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xse_resnext50'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> bs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>: <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># avoid Expected more than 1 value per channel when training, got input size torch.Size([1, 4096])</span></span>
<span id="cb27-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> lr <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-7</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-6</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-5</span>]:</span>
<span id="cb27-7">            wandb.init(</span>
<span id="cb27-8">                project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb27-9">                name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"imagenette-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-bs-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>bs<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-lr-</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb27-10">                tags<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"bs=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>bs<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"model=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"lr=</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>lr<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>]</span>
<span id="cb27-11">                )</span>
<span id="cb27-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xse_resnext50'</span>: learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb27-13">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xresnet18'</span>: learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb27-14">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'xresnet34'</span>: learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb27-15"></span>
<span id="cb27-16">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> learn.no_logging() <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> learn.no_mbar(): learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, lr)</span>
<span id="cb27-17">            wandb.finish()</span></code></pre></div>
</div>


</section>

 ]]></description>
  <category>python</category>
  <category>fastai</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <category>imagenette</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-18-imagenette/</guid>
  <pubDate>Wed, 18 Jun 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Cross Entropy Loss Explained</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-11-CELoss/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>As I’ve been preparing to build <a href="https://vishalbakshi.github.io/blog/index.html#category=TinyScaleLab">highly performant tiny LMs</a>, I realized I needed a refresher on how Cross-Entropy loss works. In this notebook I’m revisiting <a href="https://github.com/fastai/fastbook/blob/master/05_pet_breeds.ipynb">Chapter 5 of fastbook</a> to walk through the code and concepts introduced to build intuition around this loss function.</p>
<p>I was motivated to work on this refresher because I wanted to better visualize with a concrete example how small batch training can lead to noisy gradients.</p>
</section>
<section id="multi-class-classification" class="level2">
<h2 class="anchored" data-anchor-id="multi-class-classification">Multi-Class Classification</h2>
<p>We are going to focus on a single-label, multiple class classification problem using the PETS dataset.</p>
<div id="cell-5" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:37}}" data-outputid="916a6aea-9fc1-4095-a00d-b2d4462f90ed">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fastai.vision.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-2">path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> untar_data(URLs.PETS)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="811712512" class="" max="811706944" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [811712512/811706944 00:14&lt;00:00]
    </div>
    
</div>
</div>
<div id="cell-6" class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">pets <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataBlock(blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (ImageBlock, CategoryBlock),</span>
<span id="cb2-2">                 get_items<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>get_image_files,</span>
<span id="cb2-3">                 splitter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>RandomSplitter(seed<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>),</span>
<span id="cb2-4">                 get_y<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>using_attr(RegexLabeller(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r'</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">(</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">.</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">)</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">\d</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">.</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">jpg</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">$</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>),</span>
<span id="cb2-5">                 item_tfms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>Resize(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">460</span>),</span>
<span id="cb2-6">                 batch_tfms<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>aug_transforms(size<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">224</span>, min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.75</span>))</span>
<span id="cb2-7">dls <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pets.dataloaders(path<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"images"</span>)</span></code></pre></div>
</div>
<div id="cell-7" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:230}}" data-outputid="960ea3d6-91e1-47f4-9ddb-cfa755ef7c81">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vision_learner(dls, resnet34, metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>error_rate)</span>
<span id="cb3-2">learn.fine_tune(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Downloading: "https://download.pytorch.org/models/resnet34-b627a593.pth" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth
100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 138MB/s]</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.499396</td>
<td>0.378620</td>
<td>0.125169</td>
<td>01:07</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.536576</td>
<td>0.329664</td>
<td>0.104871</td>
<td>01:08</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.326150</td>
<td>0.241802</td>
<td>0.078484</td>
<td>01:08</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Inspecting one batch, we see that the inputs are a batch of 64 3-channel 224x224 pixel images, and the targets are integers (between 0 and 36, the number of pet classes in the dataset)</p>
<div id="cell-9" class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">x,y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dls.one_batch()</span></code></pre></div>
</div>
<div id="cell-10" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="33f8f547-092a-488e-a111-dcc96b36d461">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">x.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>torch.Size([64, 3, 224, 224])</code></pre>
</div>
</div>
<div id="cell-11" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3633a063-2f52-47f0-e469-9362a45be99a">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">y</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>TensorCategory([23, 13, 25,  3, 16, 31, 34,  8,  9, 20, 19, 10,  6, 19, 33, 35,
                34, 19, 18, 29, 26, 34, 24, 30, 31,  2,  3, 20, 28, 29,  0, 11,
                22, 31,  3, 36, 15, 16,  0, 18, 32, 17,  3, 18, 16,  6, 16,  2,
                32,  0,  9, 26, 26, 35, 18,  4, 36,  5, 17,  0, 11, 27, 21, 35],
               device='cuda:0')</code></pre>
</div>
</div>
<div id="cell-12" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b4a33fcf-0b37-44c9-b9a3-cc80678a5273">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">y.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>torch.Size([64])</code></pre>
</div>
</div>
<p>Passing this batch to the trained model we get back 37 predictions for each item in the batch.</p>
<div id="cell-14" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:138}}" data-outputid="d002ca06-5bda-43f9-e418-fec34d0b2f52">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">preds,_ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> learn.get_preds(dl<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[(x,y)])</span>
<span id="cb12-2">preds[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor([2.0166e-08, 1.0262e-06, 6.8535e-06, 2.8387e-06, 7.7887e-08, 1.4034e-07,
        4.1744e-07, 9.1272e-06, 1.0166e-05, 1.3550e-07, 5.2067e-08, 3.7820e-06,
        4.2456e-06, 1.2272e-08, 1.2251e-07, 1.4040e-07, 7.0171e-06, 4.2623e-04,
        1.3611e-07, 7.3574e-08, 1.6146e-08, 5.0945e-06, 8.1139e-06, 9.9821e-01,
        4.9108e-05, 3.4051e-06, 7.8016e-09, 2.8509e-07, 1.0994e-03, 1.3271e-06,
        1.4462e-04, 4.8486e-07, 1.3296e-07, 7.4560e-07, 6.1535e-08, 7.6703e-07,
        9.5345e-07])</code></pre>
</div>
</div>
<div id="cell-15" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="6b69e953-00de-43f1-bbd2-3e4379dd465a">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">preds.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>torch.Size([64, 37])</code></pre>
</div>
</div>
<div id="cell-16" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4a8779a2-b7f7-40cf-c5bc-2cdbdecb7913">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">x.shape, y.shape, preds[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(torch.Size([64, 3, 224, 224]), torch.Size([64]), torch.Size([37]))</code></pre>
</div>
</div>
<div id="cell-17" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="73e26c69-068c-4d62-e704-3a365b6fee15">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(preds[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]),preds[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(37, tensor(1.))</code></pre>
</div>
</div>
<p>The predictions for each batch item sum to <code>1.0</code>.</p>
</section>
<section id="building-up-cross-entropy-loss" class="level2">
<h2 class="anchored" data-anchor-id="building-up-cross-entropy-loss">Building Up Cross-Entropy Loss</h2>
<p>We’ll work through a simpler example: binary classification with two classes (and thus two model outputs/activations).</p>
<div id="cell-21" class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">torch.random.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
</div>
<div id="cell-22" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2cf74b04-4eda-4dfe-8af7-475b9c628d44">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">acts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb21-2">acts</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([[ 0.6734,  0.2576],
        [ 0.4689,  0.4607],
        [-2.2457, -0.3727],
        [ 4.4164, -1.2760],
        [ 0.9233,  0.5347],
        [ 1.0698,  1.6187]])</code></pre>
</div>
</div>
<p>We want each row (batch item) to sum to 1.0. In other words, we want to turn these activations into probabilities. Passing each item through sigmoid does not help. While it does constrain the value to 0 and 1 it does so independently across the two classes so they don’t add up to 1.0.</p>
<div id="cell-24" class="cell">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> plot_function(f, tx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, ty<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)):</span>
<span id="cb23-2">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>)</span>
<span id="cb23-3">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.tensor(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>)</span>
<span id="cb23-4">    x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linspace(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>,<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb23-5">    fig,ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>figsize)</span>
<span id="cb23-6">    ax.plot(x,f(x))</span>
<span id="cb23-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tx <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>: ax.set_xlabel(tx)</span>
<span id="cb23-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> ty <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>: ax.set_ylabel(ty)</span>
<span id="cb23-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> title <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>: ax.set_title(title)</span></code></pre></div>
</div>
<div id="cell-25" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:368}}" data-outputid="11a3618a-ebe2-49c2-937f-82be1c97eebb">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">plot_function(f<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.sigmoid, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-16-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-11-CELoss/index_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="cell-26" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3546e7a1-76ee-4404-98de-87468b39dcbb">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">acts.sigmoid()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([[0.6623, 0.5641],
        [0.6151, 0.6132],
        [0.0957, 0.4079],
        [0.9881, 0.2182],
        [0.7157, 0.6306],
        [0.7446, 0.8346]])</code></pre>
</div>
</div>
<div id="cell-27" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2c5c3e3c-892d-4292-cd84-8997dba4b3a0">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">acts[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].sigmoid()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor(0.6623)</code></pre>
</div>
</div>
<p>However, taking the difference <em>between the class activations</em> and then passing that through the sigmoid does give us our desired result: probabilities that sum up to 1.0 across classes for each batch item.</p>
<div id="cell-29" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e9b1877f-f9fb-4dd6-f59e-d79f755693ac">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">(acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]).sigmoid()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor([0.6025, 0.5021, 0.1332, 0.9966, 0.5959, 0.3661])</code></pre>
</div>
</div>
<div id="cell-30" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="a57c5464-916e-4088-809c-c728e94b0b4d">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">(acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]).sigmoid()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([0.3975, 0.4979, 0.8668, 0.0034, 0.4041, 0.6339])</code></pre>
</div>
</div>
<div id="cell-31" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4a8f3e27-8877-42af-eba9-2fa12ffd447c">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">(acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]).sigmoid() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]).sigmoid()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])</code></pre>
</div>
</div>
<p>Why does this work? We can see why mathematically.</p>
<section id="deriving-softmax-from-sigmoid" class="level3">
<h3 class="anchored" data-anchor-id="deriving-softmax-from-sigmoid">Deriving Softmax from Sigmoid</h3>
<p>We start with taking the sigmoid of the difference between the first and second class activations.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bsigmoid%7D(x_1-x_2)%5Ctext%7B%20=%20%7D%5Cfrac%7B1%7D%7B1+e%5E%7B-%7B(x_1-x_2)%7D%7D%7D"></p>
<p>Let’s rewrite the denominator, expanding the exponent term:</p>
<p><img src="https://latex.codecogs.com/png.latex?1+e%5E%7B-%7B(x_1-x_2)%7D%7D%20=%201%20+%20%5Cfrac%7B1%7D%7Be%5E%7B(x_1-x_2)%7D%7D%20=%20%5Cfrac%7B1%7D%7B1%7D+%5Cfrac%7B1%7D%7Be%5E%7B(x_1-x_2)%7D%7D%20=%20%5Cfrac%7Be%5E%7B(x_1-x_2)%7D+1%7D%7Be%5E%7B(x_1-x_2)%7D%7D"></p>
<p>Plugging that back into the original sigmoid fraction and simplifying:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B1+e%5E%7B-%7B(x_1-x_2)%7D%7D%7D%20=%20%5Cfrac%7B1%7D%7B%5Cfrac%7Be%5E%7B(x_1-x_2)%7D+1%7D%7Be%5E%7B(x_1-x_2)%7D%7D%7D%20=%20%5Cfrac%7Be%5E%7B(x_1-x_2)%7D%7D%7Be%5E%7B(x_1-x_2)%7D+1%7D"></p>
<p>Multiplying by a term equivalent to 1 (thanks Gemini):</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Cfrac%7Be%5E%7B(x_1-x_2)%7D%7D%7Be%5E%7B(x_1-x_2)%7D+1%7D%20%5Ctimes%20%5Cfrac%7Be%5E%7Bx_2%7D%7D%7Be%5E%7Bx_2%7D%7D%20=%20%5Cfrac%7Be%5E%7B(x_1-x_2)%7D%5Ctimes%20e%5E%7Bx_2%7D%7D%7B(e%5E%7B(x_1-x_2)%7D+1)%5Ctimes%20e%5E%7Bx_2%7D%7D%20=%20%5Cfrac%7Be%5E%7B(x_1-x_2+x_2)%7D%7D%7Be%5E%7B(x_1-x_2+x_2)%7D+e%5E%7Bx_2%7D%7D=%5Cfrac%7Be%5E%7Bx_1%7D%7D%7Be%5E%7Bx_1%7D+e%5E%7Bx_2%7D%7D"></p>
<p>We are left with the softmax calculation for the first class probability. The chapter goes on to say:</p>
<blockquote class="blockquote">
<p>The second column (the probability of it being a 7) will then just be that value subtracted from 1.</p>
</blockquote>
<p>The sigmoid of the difference between the second and first class probabilities is 1 minus the sigmoid of the difference between the first and second class probabilities.</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bsigmoid%7D(x_2-x_1)%5Ctext%7B%20=%20%7D1%20-%20%5Cfrac%7Be%5E%7Bx_1%7D%7D%7Be%5E%7Bx_1%7D+e%5E%7Bx_2%7D%7D%20=%20%5Cfrac%7Be%5E%7Bx_1%7D+e%5E%7Bx_2%7D%7D%7Be%5E%7Bx_1%7D+e%5E%7Bx_2%7D%7D%20-%20%5Cfrac%7Be%5E%7Bx_1%7D%7D%7Be%5E%7Bx_1%7D+e%5E%7Bx_2%7D%7D%20=%20%5Cfrac%7Be%5E%7Bx_1%7D+e%5E%7Bx_2%7D-e%5E%7Bx_1%7D%7D%7Be%5E%7Bx_1%7D+e%5E%7Bx_2%7D%7D%20=%20%5Cfrac%7Be%5E%7Bx_2%7D%7D%7Be%5E%7Bx_1%7D+e%5E%7Bx_2%7D%7D"></p>
<div id="cell-46" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="197b5713-e23b-405e-d37c-561a6c5b6fd8">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> (acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>acts[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]).sigmoid()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([0.3975, 0.4979, 0.8668, 0.0034, 0.4041, 0.6339])</code></pre>
</div>
</div>
<p>We can also derive the same result with a different approach mathematically, I find this one to be simpler:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bsigmoid%7D(x_1-x_2)%5Ctext%7B%20=%20%7D%5Cfrac%7B1%7D%7B1+e%5E%7B-%7B(x_1-x_2)%7D%7D%7D"></p>
<p>Expanding the exponent term in the denominator:</p>
<p><img src="https://latex.codecogs.com/png.latex?e%5E%7B-(x_1-x_2)%7D%20=%20%5Cfrac%7B1%7D%7Be%5E%7B(x_1-x_2)%7D%7D%20=%20%5Cfrac%7B1%7D%7B%5Cfrac%7Be%5E%7Bx_1%7D%7D%7Be%5E%7Bx_2%7D%7D%7D%20=%20%5Cfrac%7Be%5E%7Bx_2%7D%7D%7Be%5E%7Bx_1%7D%7D"></p>
<p>Plugging that back into the denominator and massaging it:</p>
<p><img src="https://latex.codecogs.com/png.latex?1+%5Cfrac%7Be%5E%7Bx_2%7D%7D%7Be%5E%7Bx_1%7D%7D%20=%20%5Cfrac%7Be%5E%7Bx_1%7D%7D%7Be%5E%7Bx_1%7D%7D%20+%20%5Cfrac%7Be%5E%7Bx_2%7D%7D%7Be%5E%7Bx_1%7D%7D%20=%20%5Cfrac%7Be%5E%7Bx_1%7D%20+%20e%5E%7Bx_2%7D%7D%7Be%5E%7Bx_1%7D%7D"></p>
<p>Plugging that back in to the original sigmoid equation:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bsigmoid%7D(x_1-x_2)%5Ctext%7B%20=%20%7D%5Cfrac%7B1%7D%7B1+e%5E%7B-%7B(x_1-x_2)%7D%7D%7D%20=%20%5Cfrac%7B1%7D%7B%5Cfrac%7Be%5E%7Bx_1%7D%20+%20e%5E%7Bx_2%7D%7D%7Be%5E%7Bx_1%7D%7D%7D%20=%20%5Cfrac%7Be%5E%7Bx_1%7D%7D%7Be%5E%7Bx_2%7D+e%5E%7Bx_1%7D%7D"></p>
<p>Mathematically, with some help from Gemini, that makes sense. But what is the conceptual intuition behind it? Why does taking the sigmoid of <em>the difference between activations</em> equate to softmax?</p>
<p>With loads of help with Gemini, I’ve come to the following conclusions/intuitions:</p>
<ul>
<li>sigmoid is designed for a simple binary outcome: A and not-A, so we can’t use it for more than 2 classes.</li>
<li>the difference in logits is a difference in “learned evidence” between the two classes. The value <code>x_1 - x_2</code> represents the log-odds of class 1 relative to class 2 (i.e., it’s equal to <code>log(P(class 1)/P(class 2))</code>). A difference of <code>0</code> (logits <code>x_1</code> and <code>x_2</code> are equal) passed through sigmoid yields a probability of <code>0.5</code>, meaning both classes are equally probable.</li>
<li>sigmoid is the inverse function of the log-odds (or logit) function. sigmoid(0) = 0.5, and log(0.5/(1-0.5)) = 0.</li>
<li>we call binary classification activations “logits” because we eventually turn them into probabilities using sigmoid.</li>
<li>the softmax function is the general template for all classification problems. For the special case of exactly two classes, this general formula mathematically simplifies to be identical to the sigmoid of the difference between the logits.</li>
<li>For 3+ classes, the model’s final activations are still called logits. However, they no longer have a simple interpretation as the log-odds of a single event. We think of them as some kind of learned “raw” or “uncalibrated” scores that softmax converts into a valid probability distribution.</li>
</ul>
<p>Let’s return back to the process of building up Cross Entropy loss.</p>
</section>
<section id="selecting-the-probabilities-used-and-calculating-their-logarithm" class="level3">
<h3 class="anchored" data-anchor-id="selecting-the-probabilities-used-and-calculating-their-logarithm">Selecting the Probabilities Used and Calculating their Logarithm</h3>
<p>So we have now converted logits into probabilities using softmax.</p>
<blockquote class="blockquote">
<p>Our activations, after softmax, are between 0 and 1, and sum to 1 for each row in the batch of predictions.</p>
</blockquote>
<div id="cell-61" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="659a6f60-3fd6-4033-b6ea-1cd5f18815fe">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">sm_acts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.softmax(acts, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb37-2">sm_acts</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor([[0.6025, 0.3975],
        [0.5021, 0.4979],
        [0.1332, 0.8668],
        [0.9966, 0.0034],
        [0.5959, 0.4041],
        [0.3661, 0.6339]])</code></pre>
</div>
</div>
<p>Okay great, now how do we use these values? We want to penalize the language model’s predictions when they wrong (the target label is not predicted with the highest probability) and especially when they are wrong <em>and</em> confident (the target label is predicted with a very low probability). On the other hand, we want to encourage the model to pick the right class confidently. We achieve this two-pronged behavior by taking the logarithm of the target probability.</p>
<p>Suppose the target classes (<code>0</code> or <code>1</code>) are as follows for the 6-item batch:</p>
<div id="cell-64" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="98ead48f-4666-473d-8ea2-23834f5efd43">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">targ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tensor([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span>
<span id="cb39-2">targ</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([0, 1, 0, 1, 1, 0])</code></pre>
</div>
</div>
<div id="cell-65" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="df800045-6655-4507-da0a-5af91422af66">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">sm_acts</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>tensor([[0.6025, 0.3975],
        [0.5021, 0.4979],
        [0.1332, 0.8668],
        [0.9966, 0.0034],
        [0.5959, 0.4041],
        [0.3661, 0.6339]])</code></pre>
</div>
</div>
<p>We index into our probalities using <code>idx</code> (the batch item index) and <code>targ</code> (the probability column index).</p>
<div id="cell-67" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="aa0d1726-a44c-48eb-ce80-827a2242df46">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)</span>
<span id="cb43-2">sm_acts[idx, targ]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor([0.6025, 0.4979, 0.1332, 0.0034, 0.4041, 0.3661])</code></pre>
</div>
</div>
<div id="cell-68" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:388}}" data-outputid="3560d3c2-3e53-47d3-c2fe-7bc007c5928e">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">plot_function(torch.log, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, ty<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'log(x)'</span>, tx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-27-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-11-CELoss/index_files/figure-html/cell-27-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>The log function is very negative for values close to 0 and less negative for values close to 1. We want our loss function to be very positively large for confidently wrong predictions (i.e.&nbsp;when the target class is predicted with a very low probability) so we want to flip the logarithm’s behavior by multiplying it by -1.</p>
<div id="cell-70" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:410}}" data-outputid="147b1069-226c-4741-e950-8d8808fe8e30">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">plot_function(<span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x: <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>torch.log(x), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">max</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, tx<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'x'</span>, ty<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'- log(x)'</span>, title <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Log Loss when true label = 1'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-28-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-11-CELoss/index_files/figure-html/cell-28-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="cell-71" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="30e9ccac-b0ff-4e76-e05f-2722c489847f">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">sm_acts[idx, targ]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([0.6025, 0.4979, 0.1332, 0.0034, 0.4041, 0.3661])</code></pre>
</div>
</div>
<div id="cell-72" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d72434ec-eca4-48a6-97db-b2cdf9062e9e">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>torch.log(sm_acts)[idx, targ]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor([0.5067, 0.6973, 2.0160, 5.6958, 0.9062, 1.0048])</code></pre>
</div>
</div>
<p>We now have large loss values (2.016, 5.6958) for batch items when the model predicted the target class with a very low probability (0.1332, 0.0034), and we have a relatively smaller loss value (0.5067) when the model predicted the target class with a higher probability than the incorrect class (0.6025).</p>
<p>The PyTorch <code>F.nll_loss</code> function does the indexing and multiplying by negative 1 operations for us, though it expects you to pass it activations after taking the logarithm of them.</p>
<div id="cell-75" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f01c7be6-2b16-48c4-c93e-545c184964ca">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">F.nll_loss(sm_acts, targ, reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661])</code></pre>
</div>
</div>
<div id="cell-76" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="350aacb0-cae9-4606-9f55-849b99d6a93e">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">F.nll_loss(torch.log(sm_acts), targ, reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor([0.5067, 0.6973, 2.0160, 5.6958, 0.9062, 1.0048])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>As long as the activation columns sum to 1 (as they will, if we use softmax), then we’ll have a loss function that shows how well we’re predicting each digit. Therefore, making the activation for the correct label as high as possible must mean we’re also decreasing the activations of the remaining columns.</p>
</blockquote>
<p>We can also directly use <code>CrossEntropyLoss</code></p>
<div id="cell-79" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="103a97e6-a0a6-4ec7-add9-1b887a9226ee">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">nn.CrossEntropyLoss(reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'none'</span>)(acts, targ)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor([0.5067, 0.6973, 2.0160, 5.6958, 0.9062, 1.0048])</code></pre>
</div>
</div>
<div id="cell-80" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="fcf7d116-8fdd-49bd-8f43-9ffefa19e5d5">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">nn.CrossEntropyLoss(reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean'</span>)(acts, targ)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor(1.8045)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Taking the mean of the negative log of our probabilities (taking the mean of the loss column of our table) gives us the negative log likelihood loss, which is another name for cross-entropy loss.</p>
</blockquote>
</section>
</section>
<section id="the-gradient-of-cross-entropy-loss" class="level2">
<h2 class="anchored" data-anchor-id="the-gradient-of-cross-entropy-loss">The Gradient of Cross Entropy Loss</h2>
<p>Let’s recreate with code the following explanation of the cross-entropy loss gradient.</p>
<blockquote class="blockquote">
<p>An interesting feature about cross-entropy loss appears when we consider its gradient. The gradient of cross_entropy(a,b) is just softmax(a)-b. Since softmax(a) is just the final activation of the model, that means that the gradient is proportional to the difference between the prediction and the target. This is the same as mean squared error in regression (assuming there’s no final activation function such as that added by y_range), since the gradient of (a-b)**2 is 2*(a-b). Because the gradient is linear, that means we won’t see sudden jumps or exponential increases in gradients, which should lead to smoother training of models.</p>
</blockquote>
<p>First we’ll calculate the gradients using <code>los.backward()</code>.</p>
<div id="cell-86" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="96b8a5fa-789d-4286-e6b1-cc3a55137dc7">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">acts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> acts.requires_grad_()</span>
<span id="cb59-2">acts</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([[ 0.6734,  0.2576],
        [ 0.4689,  0.4607],
        [-2.2457, -0.3727],
        [ 4.4164, -1.2760],
        [ 0.9233,  0.5347],
        [ 1.0698,  1.6187]], requires_grad=True)</code></pre>
</div>
</div>
<div id="cell-87" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="bbdbb429-a3c1-4688-bb9c-3760d869c144">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1">loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.CrossEntropyLoss(reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'sum'</span>)(acts, targ)</span>
<span id="cb61-2">loss</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>tensor(10.8268, grad_fn=&lt;NllLossBackward0&gt;)</code></pre>
</div>
</div>
<div id="cell-88" class="cell">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">loss.backward()</span></code></pre></div>
</div>
<div id="cell-89" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="411b5c8e-1118-4f02-c551-07a2ed885d7e">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">acts.grad</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>tensor([[-0.3975,  0.3975],
        [ 0.5021, -0.5021],
        [-0.8668,  0.8668],
        [ 0.9966, -0.9966],
        [ 0.5959, -0.5959],
        [-0.6339,  0.6339]])</code></pre>
</div>
</div>
<p>Then, we’ll manually calculate them using <code>softmax(acts) - targ</code>:</p>
<div id="cell-91" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="66f4ee79-5af1-45e0-8e3f-b39d48487049">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1">b <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> F.one_hot(targ, num_classes<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>acts.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>()</span>
<span id="cb66-2">b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>tensor([[1., 0.],
        [0., 1.],
        [1., 0.],
        [0., 1.],
        [0., 1.],
        [1., 0.]])</code></pre>
</div>
</div>
<div id="cell-92" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e656eb87-1b8c-484b-c904-44378d247480">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1">acts.softmax(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> b</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>tensor([[-0.3975,  0.3975],
        [ 0.5021, -0.5021],
        [-0.8668,  0.8668],
        [ 0.9966, -0.9966],
        [ 0.5959, -0.5959],
        [-0.6339,  0.6339]], grad_fn=&lt;SubBackward0&gt;)</code></pre>
</div>
</div>
<p>We see that they are equal! If we want to recreate the gradient when <code>reduction='mean'</code> we can divide <code>softmax(a) - b</code> by the batch size.</p>
<div id="cell-94" class="cell">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1">torch.random.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb70-2">acts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>))<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span></span>
<span id="cb70-3">acts <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> acts.requires_grad_()</span></code></pre></div>
</div>
<div id="cell-95" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="71064327-04a8-4b21-b19c-2ea8391b406e">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1">loss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> nn.CrossEntropyLoss(reduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mean'</span>)(acts, targ)</span>
<span id="cb71-2">loss</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>tensor(1.8045, grad_fn=&lt;NllLossBackward0&gt;)</code></pre>
</div>
</div>
<div id="cell-96" class="cell">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1">loss.backward()</span></code></pre></div>
</div>
<div id="cell-97" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f6b0b28e-6aeb-4217-fbd1-c13f338d78c2">
<div class="sourceCode cell-code" id="cb74" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1">acts.grad</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([[-0.0663,  0.0663],
        [ 0.0837, -0.0837],
        [-0.1445,  0.1445],
        [ 0.1661, -0.1661],
        [ 0.0993, -0.0993],
        [-0.1056,  0.1056]])</code></pre>
</div>
</div>
<div id="cell-98" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1ec7f93f-2050-4bd2-fc8f-6acfe5b0ff6f">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1">(acts.softmax(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> b) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> acts.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([[-0.0663,  0.0663],
        [ 0.0837, -0.0837],
        [-0.1445,  0.1445],
        [ 0.1661, -0.1661],
        [ 0.0993, -0.0993],
        [-0.1056,  0.1056]], grad_fn=&lt;DivBackward0&gt;)</code></pre>
</div>
</div>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Next-token language generation is fundamentally a classification problem. The “classes” are the tokens in the vocabulary. The model predicts the most probable next token, learning to favor target tokens during training using cross-entropy. This refresher on cross-entropy loss helped me solidify my understanding of how this behavior is reinforced.</p>
<p>I’m growing my YouTube channel so if you like this type of content <a href="https://www.youtube.com/@vishal_learner">please subscribe</a>!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>fastai</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-11-CELoss/</guid>
  <pubDate>Wed, 11 Jun 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Proof, Pricing, and Passion: Finding My Path in Machine Learning</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-09-fireside-chat/</link>
  <description><![CDATA[ 




<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Z328Nl6c-8k?si=Ey9ehhiHqoCQfmum" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<p>A recent fireside chat with three successful AI consultants—Jason Liu, Andy Walters, and Vignesh Mohankumar—gave me a much clearer, more realistic perspective on what it takes to build a career in this space. While a previous <a href="https://www.youtube.com/watch?v=nyNQtkiW-ME">paradigm-shifting conversation between Jason Liu and Hamel Husain</a> had inspired me, this conversation answered a critical question I’ve been wrestling with:</p>
<blockquote class="blockquote">
<p>What do you think is the minimum amount of professional experience to have before going full-time consulting?</p>
</blockquote>
<p>I was all ears on this one. Below are the responses from Jason, Vignesh and Andy (emphasis mine)</p>
<blockquote class="blockquote">
<p>Jason: <mark><strong>the thing you want to have is proof.</strong></mark> There are people making a million dollars a year doing Zapier integrations and automations. You can probably just figure that out, just charge very little, do a couple of free jobs, get some proof, maybe if you help a business owner with their automations you can ask if they have anyone they can refer you to, then you get the next job and the next job. I think it depends on what kind of things you’re promising and what kind of solutions you’re promising.</p>
</blockquote>
<blockquote class="blockquote">
<p>Vignesh: I think the fact that I was basically a staff level engineer is really what’s helping me now, but it’s not to say that you don’t need that, I think like you said there’s a lot of things you can do, but <mark><strong>I think for the type of work I’m doing it would be very hard to do if you were less than 5 years of experience, or really, honestly, probably 8</strong></mark>….but it’s about what have you actually done and can you actually prove it.</p>
</blockquote>
<blockquote class="blockquote">
<p>Andy: I started with zero AI knowledge. I was previously a programmer. I never worked at a startup that was successful. I worked at little agencies my whole career. I am where I am today so it’s possible. <mark><strong>It all depends on your skill set. It’s about staffing your weaknesses.</strong></mark> If you want to go big and you’re not good at something if you can partner with somebody who’s good at that thing, now you can move on and go further. It depends on how fast you want to scale, how honest you can be with yourself about your weaknesses and how good you are at acquiring the talent to fill in those weaknesses.</p>
</blockquote>
<p>Jason and Vignesh agreed upon the fact that you can land jobs if you can prove that you can deliver results (at the appropriate scale). For someone like me, who has never worked professionally in ML, getting that proof (at scale, in a setting that emulates a real business) is the tricky part. I would imagine that any proof I can currently collect (research projects, Kaggle competitions, educational content, etc.) will help me get a foot in the door at a company or a lab, which will then unlock my ability to get more proof in a professional setting that could translate to consulting. I could be wrong (tweet at me if I am) but going from 0-to-consulting without any other professional ML experience doesn’t seem likely (or, at least I haven’t seen any examples of this, except for unicorns like Jeremy Howard).</p>
<p>But knowing when to start is only half the battle; understanding the pivotal moments that accelerate a consulting career is just as important, which the speakers addressed next.</p>
</section>
<section id="inflection-points-in-consulting" class="level2">
<h2 class="anchored" data-anchor-id="inflection-points-in-consulting">Inflection points in consulting</h2>
<p>Q: What felt like the inflection point for the way that you were able to bring in revenue or demand higher fees?</p>
<blockquote class="blockquote">
<p>Jason: For me a lot of it was coming down to my writing. At some point it became: “Hey Jason, I’ve seen a couple of your blog posts show up on my Slack, I don’t really know who you are, I finally clicked the website and I realized you were available so can we figure out if it makes sense to work together?” And then I would share another blog post after the call and they would be like “turns out my CTO already read this, what is your availability?”</p>
</blockquote>
<blockquote class="blockquote">
<p>Vignesh: There was one month where I got a project and I finished it in a week or two and it was more money than I had made if I just worked full-time, hourly, for a month and a half. It was a really pressing problem that came up. I realized I’d rather sit there for 29 days a month and find a project-based thing that I could do for one day a month, then work hourly. That’s what shifted it for me.</p>
</blockquote>
<blockquote class="blockquote">
<p>Jason: Going from time-based to project-based pricing, and then getting comfortable understanding the value that your project delivers and increase your fee to reflect the size of the problem.</p>
</blockquote>
<p>In the Hamel/Jason discussion on AI consulting, they talk about how publishing free content is a viable marketing plan. This really resonated with me as a fast.ai community member, encouraged by <a href="https://medium.com/@racheltho/why-you-yes-you-should-blog-7d2544ac1045">Rachel Thomas to blog</a> since “it’s like a resume, only better.” After I watched Jason and Hamel’s discussion, I immediately set a goal to publish 50 ML vidoes and 50 ML blog posts in 2025, and it has been driving me forward ever since. Reading that Jason’s leads often come from people reading his blog further solidified by belief that this is the way. Obviously, what you’re writing about matters, but I think that catches up with quantity over time.</p>
<p>Both of these inflection points are about detaching income from hours and tying it to the value you create. But what’s the upper limit? This led to an interesting exchange about whether AI is removing the ceiling on how much impact a single consultant can have.</p>
</section>
<section id="is-there-a-ceiling-for-one-consultant" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-ceiling-for-one-consultant">Is there a ceiling for one consultant?</h2>
<p>I’ve heard Jason say some iteration of the following in a couple of videos now:</p>
<blockquote class="blockquote">
<p>Jason: I would be surprised if there’s anybody I know that can be like an individual person even doing $10MM a year just feels very difficult whereas if you just have a couple of small operational staff you can probably get pretty far.</p>
</blockquote>
<p>This was the first video (that I’ve watched) where someone pushed back on that.</p>
<blockquote class="blockquote">
<p>Vignesh: If these tools are going to keep getting better, then I don’t know if there is a limit anymore at some point.</p>
</blockquote>
<p>I think this both an inspiring and realistic take. My own self-prescribed limits have continuously been broken with the help of AI. It’s hard for me to quantify how much my growth in ML has accelerated due to AI (as I obviously don’t have a control to compare for that) but anecdotally, every month and every year that I’ve increased my use of AI to augment my learning and implementation skills, I’ve accomplished tasks that I didn’t expect to. You could argue that every project, blog post, and video I’ve published could not have been possible without the support of AI. How this translates to getting paid (and how much I get paid), only time will tell. Going back to the previous topic on when to start consulting, I think the use of AI can help build that proof needed for a 0-to-consulting trajectory. It may require doing a couple free or low-paying jobs, but I think that’s reasonable to expect. This is probably a controversial take, and I’m not condoning or advocating for exploitation, but I do think that when you work for free as a beginner, you are “paying” (with your labor) to get that proof needed to unlock paid work. Working for free can also look like joining a study group/discord server and taking on tasks that need to be done.</p>
<p>While the potential to scale with AI is an exciting thought experiment, financial upside is rarely the sole motivator for taking the risk of going independent. The conversation also explored the fundamental ‘why’ behind this career path, and Vignesh’s reasons resonated deeply with my own.</p>
</section>
<section id="what-attracts-me-to-consulting" class="level2">
<h2 class="anchored" data-anchor-id="what-attracts-me-to-consulting">What attracts me to consulting</h2>
<blockquote class="blockquote">
<p>Q: Why didn’t you join a startup (or starting a company) versus doing your own thing?</p>
</blockquote>
<blockquote class="blockquote">
<p>Vignesh: I just loving working on new problems all of the time, ideally multiple problems at the same time. I think consulting is really interesting because you can price based on the actual value you’re delivering. That keeps me going in some ways—what’s the most valuable things I can be working on? How can I help people the most? The last piece is that I just love owning the brand. Anything I’m writing, anyone I’m meeting is all tied to me…I scale it by finding more valuable projects and more important problems.</p>
</blockquote>
<p>All of these points resonate with me. As a hobby ML researcher, I value the following freedoms:</p>
<ul>
<li>The freedom to start, pause, or stop a project at will.</li>
<li>The freedom of learning and building in public without the constraints of private, proprietary work.</li>
<li>The freedom to choose my focus.</li>
<li>The freedom to control my pace—going slow. Going fast. Going deep. Staying shallow. I choose at all times which of these modes I’m in.</li>
<li>The freedom from an obsession with results, allowing me to instead chase ideas, concepts, and their clear explanation.</li>
</ul>
<p>The cost of these freedoms, currently, is that I do this work for free. Finding a situation where I can continue to have these freedoms is my next challenge.</p>
<p>Vignesh’s drive for autonomy and interesting problems perfectly mirrors the freedoms I value as a hobby researcher. But what I found most encouraging was the discussion that followed, which highlighted that his path isn’t the only one; different personalities and preferences can also lead to fulfilling consulting careers.</p>
</section>
<section id="on-different-paths-to-consulting" class="level2">
<h2 class="anchored" data-anchor-id="on-different-paths-to-consulting">On different paths to consulting</h2>
<p>Vignesh and Andy had diametrically opposed preferences and paths to consulting (emphasis mine):</p>
<blockquote class="blockquote">
<p>Vignesh: I like coding a lot. I love writing code. I love learning things. So it works. It’s like my dream.</p>
</blockquote>
<blockquote class="blockquote">
<p>Andy: I think I’m different than Vignesh in that like I was an okay engineer, but I was never a great engineer, and I really enjoyed the relationship aspect of it, leading people, that kind of stuff, that’s actually more fun to me. I like meetings…I enjoy it. <mark><strong>It’s all about figuring out what you really enjoy and pushing on that a lot.</strong></mark></p>
</blockquote>
<p>I think it was awesome and important for viewers to see these diverse preferences both leading to fulfilling consulting careers. Ultimately, while landing paid work is goal 1B, doing what I enjoy and excites me is 1A and this confirmed that motivation.</p>
<p>The idea that you should build a career around what you genuinely enjoy is a powerful one. And what makes this path so compelling right now is the shared belief among all the speakers that the opportunity is vast enough to accommodate all of these different approaches.</p>
</section>
<section id="the-work-is-literally-falling-off-trucks" class="level2">
<h2 class="anchored" data-anchor-id="the-work-is-literally-falling-off-trucks">The work is literally falling off trucks</h2>
<p>I’ll end with Andy’s closing thoughts:</p>
<blockquote class="blockquote">
<p>Andy: I think the biggest lesson I’ve learned through all of this is it’s all about breaking your context into the next level. There is this cascading series of contexts you have to break yourself into and it’s always uncomfortable and it feels painful and risky…keep pushing, keep growing, and even when it doesn’t work the first time you just keep pulling the thread. It’s surprising how far you can get. We firmly believe that over the next 5 years there’s at least a trillion dollars of integration services on the table for companies to integrate AI into their offerings. The work is literally falling off the trucks. It’s out there to seize, go seize it.</p>
</blockquote>
<p>When you are constantly pushing yourself to grow and take on the next challenging context, you will find yourself working at the edge of your knowledge and capacity. This is an ideal place to be. However, the downside is never truly knowing or feeling how much you have progressed. It’s a constant state of “I am stuck on X which I need to resolve so I can get to Y”. I think documenting your journey (through writing blog posts/tweets and creating videos) helps balance this bleeding-edge approach by concretely and quantitatively showing you what you have learned and how much you have achieved.</p>
<p>Andy’s point that “the work is literally falling off the trucks” should be inspiring to everyone, regardless of whether or not you want to pursue consulting. I think we are still in the very early stages of AI adoption, which means that there is a lot of implementation work that needs to get done. It can seem (falsely) that the field of AI is accelerating at an unsustainable pace, but what is unsustainble in my opinion is that veneer. The fundamentals still matter. Communicating concepts clearly still matters. These are relatively low-hanging fruit.</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing thoughts</h2>
<p>I thoroughly enjoying this fireside chat. I came away from it with more questions and some answers.</p>
<p>To be honest, I don’t know where my ML journey is going to take me. When I’m feeling optimistic, I imagine myself working in an organization or independently with the same joy that I find myself working on my personal projects today. On my worst days, I wonder if I’ll ever leave the purgatory of hobby ML. I think the key to my success is to be consistent regardless of what I’m feeling.</p>
<p>Hearing Andy talk about staffing weaknesses and Vignesh about AI raising the ceiling made me reflect on my own approach. When it comes to using AI, and what capabilities it will unlock for me, I keep waiting for a “choir of angels” (<a href="https://xkcd.com/310/">xkcd</a>) but instead have found a steady plodding forward, task to task. I think Vignesh is right about AI removing the ceiling, and Andy is right about supplementing your weaknesses with others’ strengths. Combining these two ideas, I think my task is to become more aware about 1) what my current ceiling is/what my current weaknesses are and 2) understanding how to augment them with AI. The sycophantic nature of AI makes it difficult to use it for identifying my weaknesses, but I’ve found success by asking Claude to be a “hardass” (and then asking it to critique the hardass), or using Gemini 2.5-Pro for such questions, which I find is more straightforward and informative and less of a coach/cheerleader.</p>
<p>I’ll end by saying that I don’t usually write posts like these, and keep these thoughts to myself, but I’m finding that to strengthen my relationship with my audience I will have to share more of myself in my writing. This is the first of what I hope will be many posts connecting what I’m learning from experts in the field to my own journey.</p>
<p>You can reach me on <a href="https://x.com/vishal_learner">Twitter</a> and find more content on my <a href="https://www.youtube.com/@vishal_learner">YouTube channel</a>.</p>


</section>

 ]]></description>
  <category>Career</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-09-fireside-chat/</guid>
  <pubDate>Mon, 09 Jun 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>HuggingFace’s Default KV Cache and the flash_attn_varlen_func Docstring</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-03-flash_attn_varlen_func-casual-mask/</link>
  <description><![CDATA[ 




<div id="cell-1" class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!</span>pip install <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>qq <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>U flash<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>attn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">--</span>no<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>build<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>isolation</span></code></pre></div>
</div>
<div id="cell-2" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AutoTokenizer, AutoModelForCausalLM, GenerationConfig</span>
<span id="cb2-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch.nn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> nn</span></code></pre></div>
</div>
<div id="cell-3" class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFaceTB/SmolLM2-135M"</span>)</span>
<span id="cb3-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFaceTB/SmolLM2-135M"</span>, attn_implementation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"flash_attention_2"</span>, torch_dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.bfloat16).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I have recently been working on a research project which has required me to <a href="https://vishalbakshi.github.io/blog/posts/2025-05-04-Understanding-Sequence-Packing/">better understand sequence packing and Flash Attention</a>, and <a href="https://youtu.be/u_v6HHyv4No">eager attention as well</a>. However, I’ve found that both in terms of my interest, and for practical understanding, that hasn’t been enough!</p>
<p>Tangentially, I also recently started using Gemini Pro 2.5 (the chat UI) and have been thoroughly enjoying it after using a year of daily use of Claude Pro. This seemed like a great opportunity to test out Gemini’s functionality to learn about a topic that is complex and currently outside of my comfort zone.</p>
<p>I fed Gemini the Flash Attention GitHub repo and explained that I wanted to thoroughly understand <code>flash_attn_varlen_func</code> to the point where I could make a detailed video walkthrough with visuals. It provided me with this condensed timeline:</p>
<ul>
<li><strong>Phase 1: Python Layer &amp; Sequence Packing Concepts</strong>
<ul>
<li>Tasks: Understand <code>flash_attn_varlen_func</code>’s Python call stack, the role of <code>cu_seqlens</code>, <code>max_seqlen</code>, and <code>torch.autograd.Function</code>.</li>
<li>Time: 1-2 Weeks</li>
<li>Hours: Approximately 15-30 hours</li>
</ul></li>
<li><strong>Phase 2: Core CUDA Kernel Deep Dive</strong>
<ul>
<li>Tasks: Study the FlashAttention research paper(s).</li>
<li>Analyze the C++/CUDA dispatcher code (e.g., in <code>csrc/flash_attn/flash_api.cpp</code>).</li>
<li>Dissect the core CUDA kernels for variable length forward and backward passes (e.g., in <code>csrc/flash_attn/src/</code> like <code>flash_fwd_kernel.h</code> and <code>flash_bwd_kernel.h</code>).</li>
<li>Time: 6-12 Weeks</li>
<li>Hours: Approximately 125-240 hours</li>
</ul></li>
<li><strong>Phase 3: Content Creation (Video/Blog)</strong>
<ul>
<li>Tasks: Plan the structure for your content, create visuals, draft explanations, and prepare code snippets.</li>
<li>Time: 2-3 Weeks</li>
<li>Hours: Approximately 30-50 hours</li>
</ul></li>
<li><strong>Total Estimated for CUDA Path</strong>
<ul>
<li>Overall Timeline: Roughly 2.5 - 4.5 months</li>
<li>Total Focused Hours: Approximately 170 - 320 hours</li>
</ul></li>
</ul>
<p>This is obviously an amibitious goal and timeline, especially because of my limited C++/CUDA knowledge and experience. However, I do believe this is a case of aim-for-the-stars-land-on-the-moon, as I’ve already experienced growth and learning in the first steps of Phase 1.</p>
<p>As I was reading through <a href="https://github.com/Dao-AILab/flash-attention/blob/df1847a74ad0f9cee007ed186fab44f83fa03fad/flash_attn/flash_attn_interface.py#L1370"><code>flash_attn_varlen_func</code></a> source code, I got stuck on the following piece of the docstring:</p>
<pre><code>If causal=True, the causal mask is aligned to the bottom right corner of the attention matrix.
For example, if seqlen_q = 2 and seqlen_k = 5, the causal mask (1 = keep, 0 = masked out) is:
    1 1 1 1 0
    1 1 1 1 1
If seqlen_q = 5 and seqlen_k = 2, the causal mask is:
    0 0
    0 0
    0 0
    1 0
    1 1
If the row of the mask is all zero, the output will be zero.</code></pre>
<p>I didn’t have hands-on experience working with this concept, where the query length is different than the key and value length. Gemini helped me realize that this happens in the extremely common case of autoregressive generation—the next token (query length of 1) attends to the previous tokens (key/value length &gt; 1). The concept of KV cache also came up in our conversation.</p>
<p>I don’t tend to understand things until I see them in code, so in this notebook, I’ll inspect the shapes of Q, K and V during the HuggingFace <code>model.generate</code> call. I’ll also peel back a couple layers and understand how HugginFace uses KV cache. After that exploration, I’ll return back to the <code>flash_attn_varlen_func</code> docstring and walk through the logic behind how the causal mask is shaped.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/pZpK5uGr7Lo?si=znCX-qawKdcoX0V9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="understanding-huggingfaces-default-kv-cache" class="level2">
<h2 class="anchored" data-anchor-id="understanding-huggingfaces-default-kv-cache">Understanding HuggingFace’s Default KV Cache</h2>
<p>I’ll start by understanding how HuggingFace uses KV cache (I was surprised to find that it uses it by default!).</p>
<section id="inspecting-model_kwargs-for-caching-method" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-model_kwargs-for-caching-method">Inspecting <code>model_kwargs</code> for Caching Method</h3>
<p>Looking at the <a href="https://github.com/huggingface/transformers/blob/1094dd34f73dae1d9a91a6632635934516612490/src/transformers/generation/utils.py#L2481"><code>generate</code></a> source code, the first method call of interest when it comes to KV cache seems to be <a href="https://github.com/huggingface/transformers/blob/1094dd34f73dae1d9a91a6632635934516612490/src/transformers/generation/utils.py#L1981"><code>_prepare_cache_for_generation</code></a>, which takes the following arguments: <code>generation_config</code>, <code>model_kwargs</code>, <code>assistant_model</code>, <code>batch_size</code>, <code>max_cache_length</code>, <code>device</code>. Going down the different elif statements, <code>_prepare_cache_for_generation</code> sets the following <code>model_kwargs</code> value:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">model_kwargs[cache_name] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb5-2">    DynamicCache()</span>
<span id="cb5-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> requires_cross_attention_cache</span>
<span id="cb5-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> EncoderDecoderCache(DynamicCache(), DynamicCache())</span>
<span id="cb5-5">)</span></code></pre></div>
<p>Where <code>cache_name</code> is defined earlier in that method as:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">cache_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"past_key_values"</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> is_hybrid_cache <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cache_params"</span></span></code></pre></div>
<p>I want to inspect what <code>model_kwargs['past_key_values']</code> is.</p>
<p><a href="https://github.com/huggingface/transformers/blob/1094dd34f73dae1d9a91a6632635934516612490/src/transformers/generation/utils.py#L2369"><code>_prepare_generation_config</code></a> is used in <code>generate</code> to produce <code>generation_config</code> and <code>model_kwargs</code>.</p>
<div id="cell-14" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d4927381-46b1-42f6-aec8-9e94d36c16a8" data-execution_count="50">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">generation_config, model_kwargs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model._prepare_generation_config(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb7-2">generation_config, model_kwargs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>(GenerationConfig {
   "bos_token_id": 0,
   "eos_token_id": 0
 },
 {})</code></pre>
</div>
</div>
<p>I can now pass those on to <code>_prepare_cache_for_generation</code>, which will internally modify <code>model_kwargs</code>.</p>
<div id="cell-16" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">model._prepare_cache_for_generation(generation_config, model_kwargs, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8192</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span></code></pre></div>
</div>
<div id="cell-17" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="533d54c0-fad1-4f4a-9b31-4fe867e16454" data-execution_count="53">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">model_kwargs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>{'past_key_values': &lt;transformers.cache_utils.DynamicCache at 0x78c3b80d9850&gt;}</code></pre>
</div>
</div>
<p>I can see now that <code>model_kwargs</code> has a <code>'past_key_values'</code> key which has a <code>DynamicCache</code> value.</p>
</section>
<section id="how-is-past_key_values-used" class="level3">
<h3 class="anchored" data-anchor-id="how-is-past_key_values-used">How is <code>past_key_values</code> Used?</h3>
<p>I think it makes sense to start by looking at <a href="https://github.com/huggingface/transformers/blob/e8b292e35f331d3c3de85f7e5d3496b0e13d3d6f/src/transformers/models/llama/modeling_llama.py#L223">the forward pass of the LlamaAttention module</a>:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">...</span>
<span id="cb12-2"></span>
<span id="cb12-3">key_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.k_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb12-4">value_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.v_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb12-5"></span>
<span id="cb12-6">...</span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> past_key_value <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb12-9">    key_states, value_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> past_key_value.update(key_states, value_states, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.layer_idx, cache_kwargs)</span></code></pre></div>
<p>The <code>hidden_states</code> pass through <code>k_proj</code> and <code>v_proj</code> to produce <code>key_states</code> and <code>value_states</code>, respectively, which are then passed to <code>past_key_value.update</code> to produce a new set of <code>key_states</code> and <code>value_states</code>. Looking at <a href=""><code>DynamicCache.update</code></a>:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the cache</span></span>
<span id="cb13-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> key_states <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> layer_idx:</span>
<span id="cb13-4">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># There may be skipped layers, fill them with empty lists</span></span>
<span id="cb13-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache), layer_idx):</span>
<span id="cb13-6">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache.append(torch.tensor([]))</span>
<span id="cb13-7">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache.append(torch.tensor([]))</span>
<span id="cb13-8">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache.append(key_states)</span>
<span id="cb13-9">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache.append(value_states)</span>
<span id="cb13-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> (</span>
<span id="cb13-11">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx].numel()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># prefers not t.numel() to len(t) == 0 to export the model</span></span>
<span id="cb13-12">    ):  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fills previously skipped layers; checking for tensor causes errors</span></span>
<span id="cb13-13">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> key_states</span>
<span id="cb13-14">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache[layer_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> value_states</span>
<span id="cb13-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb13-16">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx], key_states], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb13-17">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache[layer_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache[layer_idx], value_states], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb13-18"></span>
<span id="cb13-19"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache[layer_idx]</span></code></pre></div>
<p>Let’s walk through each condition in the if-else block.</p>
<section id="if-lenself.key_cache-layer_idx" class="level4">
<h4 class="anchored" data-anchor-id="if-lenself.key_cache-layer_idx"><code>if len(self.key_cache) &lt;= layer_idx</code></h4>
<p>A full <code>key_cache</code> is has <code>n_layers</code> number of elements. If its number of elements is less than or equal to the <code>layer_idx</code> that means that it does not contain <code>key_states</code> for that <code>layer_idx</code> yet (because python starts count from <code>0</code>). For example suppose <code>layer_idx</code> is <code>0</code>, our first layer. <code>if len(self.key_cache) &lt;= layer_idx</code> is <code>True</code>, that means <code>len(self.key_cache)</code> is <code>0</code> and doesn’t contain <code>key_states</code> for the first layer, as would be the case if you were generating the first token of a response. In this case you simply <code>append</code> the <code>key_states</code> to the cache.</p>
<p>If <code>layer_idx</code> is greater than <code>len(self.key_cache)</code> then it appends an empty tensor for the “skipped” layers. This would be a scenario where you were generating the first token of a response (<code>len(self.key_cache)</code> is <code>0</code>) but starting with <code>layer_idx</code> of <code>2</code>.</p>
</section>
<section id="elif-not-self.key_cachelayer_idx.numel" class="level4">
<h4 class="anchored" data-anchor-id="elif-not-self.key_cachelayer_idx.numel"><code>elif not self.key_cache[layer_idx].numel()</code></h4>
<p>If a layer was skipped and it has an empty tensor as its <code>key_cache</code> then this condition is triggered and it simply assigned <code>key_states</code> to that layer’s <code>key_cache</code>.</p>
</section>
<section id="else" class="level4">
<h4 class="anchored" data-anchor-id="else"><code>else</code></h4>
<p>I think this is the most common case, used for autoregressive next-token generation. The <code>key_cache</code> contains a non-empty value for this layer so it concatenates the current value with the new <code>key_states</code>. In this way, the <code>key_cache</code> for this layer grows over the course of next token generation. Specifically, it’s second to last dimension (sequence length) increases by 1 for each token processed.</p>
</section>
<section id="return-self.key_cachelayer_idx-self.value_cachelayer_idx" class="level4">
<h4 class="anchored" data-anchor-id="return-self.key_cachelayer_idx-self.value_cachelayer_idx"><code>return self.key_cache[layer_idx], self.value_cache[layer_idx]</code></h4>
<p>Finally, the concatenated <code>key_cache</code> and <code>value_cache</code> for the given layer are returned. The <code>update</code> step is complete.</p>
<p><code>key_states</code> and <code>value_states</code> after the <code>past_key_values.update</code> step are passed onto the <code>attention_interface</code> which we’ll look at later in this blog post.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">attn_output, attn_weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attention_interface(</span>
<span id="cb14-2">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,</span>
<span id="cb14-3">            query_states,</span>
<span id="cb14-4">            key_states,</span>
<span id="cb14-5">            value_states,</span>
<span id="cb14-6">            attention_mask,</span>
<span id="cb14-7">            dropout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.training <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.attention_dropout,</span>
<span id="cb14-8">            scaling<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.scaling,</span>
<span id="cb14-9">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs,</span>
<span id="cb14-10">        )</span></code></pre></div>
</section>
</section>
<section id="visualizing-the-dynamiccache.update" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-dynamiccache.update">Visualizing the <code>DynamicCache.update</code></h3>
<p>To see how the cache update takes place during autoregressive language generation, I’ll monkey-patch a <code>debug_update</code> method.</p>
<div id="cell-35" class="cell" data-execution_count="58">
<details class="code-fold">
<summary>Show `debug_update</summary>
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Any, Dict, Iterable, List, Optional, Tuple, Union</span>
<span id="cb15-2"></span>
<span id="cb15-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> debug_update(</span>
<span id="cb15-4">    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,</span>
<span id="cb15-5">    key_states: torch.Tensor,</span>
<span id="cb15-6">    value_states: torch.Tensor,</span>
<span id="cb15-7">    layer_idx: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>,</span>
<span id="cb15-8">    cache_kwargs: Optional[Dict[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, Any]] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb15-9">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Tuple[torch.Tensor, torch.Tensor]:</span>
<span id="cb15-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb15-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Updates the cache with the new `key_states` and `value_states` for the layer `layer_idx`.</span></span>
<span id="cb15-12"></span>
<span id="cb15-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Parameters:</span></span>
<span id="cb15-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        key_states (`torch.Tensor`):</span></span>
<span id="cb15-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            The new key states to cache.</span></span>
<span id="cb15-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        value_states (`torch.Tensor`):</span></span>
<span id="cb15-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            The new value states to cache.</span></span>
<span id="cb15-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        layer_idx (`int`):</span></span>
<span id="cb15-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            The index of the layer to cache the states for.</span></span>
<span id="cb15-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        cache_kwargs (`Dict[str, Any]`, `optional`):</span></span>
<span id="cb15-21"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">            Additional arguments for the cache subclass. No additional arguments are used in `DynamicCache`.</span></span>
<span id="cb15-22"></span>
<span id="cb15-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Return:</span></span>
<span id="cb15-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        A tuple containing the updated key and value states.</span></span>
<span id="cb15-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb15-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the number of seen tokens</span></span>
<span id="cb15-27">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> layer_idx <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>:</span>
<span id="cb15-28">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>._seen_tokens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> key_states.shape[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb15-29"></span>
<span id="cb15-30">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the cache</span></span>
<span id="cb15-31">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> key_states <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb15-32">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> layer_idx:</span>
<span id="cb15-33">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"DEBUG: initializing cache for layer_idx </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb15-34">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache), layer_idx):</span>
<span id="cb15-35">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache.append(torch.tensor([]))</span>
<span id="cb15-36">                <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache.append(torch.tensor([]))</span>
<span id="cb15-37">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache.append(key_states)</span>
<span id="cb15-38">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache.append(value_states)</span>
<span id="cb15-39">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> (</span>
<span id="cb15-40">            <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx].numel()  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># prefers not t.numel() to len(t) == 0 to export the model</span></span>
<span id="cb15-41">        ):  <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># fills previously skipped layers; checking for tensor causes errors</span></span>
<span id="cb15-42">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"DEBUG: filling empty cache for layer_idx </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb15-43">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> key_states</span>
<span id="cb15-44">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache[layer_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> value_states</span>
<span id="cb15-45">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb15-46">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"DEBUG: updating/concatenating cache for layer_idx </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb15-47">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx], key_states], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb15-48">            <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache[layer_idx] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat([<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache[layer_idx], value_states], dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb15-49"></span>
<span id="cb15-50">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.key_cache[layer_idx], <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.value_cache[layer_idx]</span></code></pre></div>
</details>
</div>
<div id="cell-36" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.cache_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> DynamicCache</span>
<span id="cb16-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ORIGINAL_DYNAMIC_CACHE_UPDATE'</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">globals</span>():</span>
<span id="cb16-3">    ORIGINAL_DYNAMIC_CACHE_UPDATE <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DynamicCache.update</span>
<span id="cb16-4">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Stored original DynamicCache.update."</span>)</span>
<span id="cb16-5"></span>
<span id="cb16-6">DynamicCache.update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> debug_update</span></code></pre></div>
</div>
<div id="cell-37" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3bbb53b2-9b89-4361-cb26-e980bb510959" data-execution_count="60">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The quick brown"</span></span>
<span id="cb17-2">input_ids, attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(prompt, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>).values()</span>
<span id="cb17-3">outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DEBUG: initializing cache for layer_idx 0
DEBUG: initializing cache for layer_idx 1
DEBUG: initializing cache for layer_idx 2
DEBUG: initializing cache for layer_idx 3
DEBUG: initializing cache for layer_idx 4
DEBUG: initializing cache for layer_idx 5
DEBUG: initializing cache for layer_idx 6
DEBUG: initializing cache for layer_idx 7
DEBUG: initializing cache for layer_idx 8
DEBUG: initializing cache for layer_idx 9
DEBUG: initializing cache for layer_idx 10
DEBUG: initializing cache for layer_idx 11
DEBUG: initializing cache for layer_idx 12
DEBUG: initializing cache for layer_idx 13
DEBUG: initializing cache for layer_idx 14
DEBUG: initializing cache for layer_idx 15
DEBUG: initializing cache for layer_idx 16
DEBUG: initializing cache for layer_idx 17
DEBUG: initializing cache for layer_idx 18
DEBUG: initializing cache for layer_idx 19
DEBUG: initializing cache for layer_idx 20
DEBUG: initializing cache for layer_idx 21
DEBUG: initializing cache for layer_idx 22
DEBUG: initializing cache for layer_idx 23
DEBUG: initializing cache for layer_idx 24
DEBUG: initializing cache for layer_idx 25
DEBUG: initializing cache for layer_idx 26
DEBUG: initializing cache for layer_idx 27
DEBUG: initializing cache for layer_idx 28
DEBUG: initializing cache for layer_idx 29
DEBUG: updating/concatenating cache for layer_idx 0
DEBUG: updating/concatenating cache for layer_idx 1
DEBUG: updating/concatenating cache for layer_idx 2
DEBUG: updating/concatenating cache for layer_idx 3
DEBUG: updating/concatenating cache for layer_idx 4
DEBUG: updating/concatenating cache for layer_idx 5
DEBUG: updating/concatenating cache for layer_idx 6
DEBUG: updating/concatenating cache for layer_idx 7
DEBUG: updating/concatenating cache for layer_idx 8
DEBUG: updating/concatenating cache for layer_idx 9
DEBUG: updating/concatenating cache for layer_idx 10
DEBUG: updating/concatenating cache for layer_idx 11
DEBUG: updating/concatenating cache for layer_idx 12
DEBUG: updating/concatenating cache for layer_idx 13
DEBUG: updating/concatenating cache for layer_idx 14
DEBUG: updating/concatenating cache for layer_idx 15
DEBUG: updating/concatenating cache for layer_idx 16
DEBUG: updating/concatenating cache for layer_idx 17
DEBUG: updating/concatenating cache for layer_idx 18
DEBUG: updating/concatenating cache for layer_idx 19
DEBUG: updating/concatenating cache for layer_idx 20
DEBUG: updating/concatenating cache for layer_idx 21
DEBUG: updating/concatenating cache for layer_idx 22
DEBUG: updating/concatenating cache for layer_idx 23
DEBUG: updating/concatenating cache for layer_idx 24
DEBUG: updating/concatenating cache for layer_idx 25
DEBUG: updating/concatenating cache for layer_idx 26
DEBUG: updating/concatenating cache for layer_idx 27
DEBUG: updating/concatenating cache for layer_idx 28
DEBUG: updating/concatenating cache for layer_idx 29</code></pre>
</div>
</div>
<p>As we can see by the printed output, for the first generated token <code>update</code> initializes cache with <code>self.key_cache.append(key_states)</code> and <code>self.value_cache.append(value_states)</code>. For the subsequent tokens, it updates the cache with <code>torch.cat</code>.</p>
<p>I’ll re-assign the original <code>update</code> to <code>DynamicCache</code> to avoid cluttering with print outs.</p>
<div id="cell-40" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">DynamicCache.update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ORIGINAL_DYNAMIC_CACHE_UPDATE</span></code></pre></div>
</div>
</section>
</section>
<section id="inspecting-past_key_values-during-model.generate" class="level2">
<h2 class="anchored" data-anchor-id="inspecting-past_key_values-during-model.generate">Inspecting <code>past_key_values</code> During <code>model.generate</code></h2>
<p>With an understanding of how KV cache is updated, I’ll now turn my attention to the key and value cache contents during autoregressive generation.</p>
<div id="cell-43" class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFaceTB/SmolLM2-135M"</span>)</span>
<span id="cb20-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFaceTB/SmolLM2-135M"</span>, attn_implementation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"flash_attention_2"</span>, torch_dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.bfloat16).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span></code></pre></div>
</div>
<div id="cell-44" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:35}}" data-outputid="31e79d9e-72c0-4700-a6eb-7e6f795819b0" data-execution_count="63">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The quick brown"</span></span>
<span id="cb21-2">prompt</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>'The quick brown'</code></pre>
</div>
</div>
<div id="cell-45" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9f2a2d84-afdd-465d-b95e-583cd7a8860a" data-execution_count="64">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">input_ids, attention_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tokenizer(prompt, return_tensors<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"pt"</span>).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>).values()</span>
<span id="cb23-2">input_ids.shape, attention_mask.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>(torch.Size([1, 3]), torch.Size([1, 3]))</code></pre>
</div>
</div>
<p>By setting <code>return_dict_in_generate=True</code> we can retrieve <code>past_key_values</code>.</p>
<div id="cell-47" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8339ed0d-7ce1-45bd-8228-4e3a47f656af" data-execution_count="65">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb25-2">outputs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>GenerateDecoderOnlyOutput(sequences=tensor([[  504,  2365,  6354, 16438, 27003,   690,   260, 23790]],
       device='cuda:0'), scores=None, logits=None, attentions=None, hidden_states=None, past_key_values=&lt;transformers.cache_utils.DynamicCache object at 0x78c4f80c4f50&gt;)</code></pre>
</div>
</div>
<div id="cell-48" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:35}}" data-outputid="df742156-715e-4ca3-f32e-cacc3303d278" data-execution_count="66">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">tokenizer.decode(outputs.sequences[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>'The quick brown fox jumps over the lazy'</code></pre>
</div>
</div>
<p>We have 8 total tokens—3 from the original prompt and 5 new tokens generated.</p>
<div id="cell-50" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4e26edc9-2958-47a7-eee0-7cc23ad3b7cd" data-execution_count="67">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">outputs.sequences.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>torch.Size([1, 8])</code></pre>
</div>
</div>
<p>Inspecting the values in the KV cache: there are 30 items in <code>key_cache</code> and <code>value_cache</code>, corresponding to the 30 layers in the model. For the last generated token (the 8th token) there were <code>7</code> <code>seen_tokens</code>.</p>
<div id="cell-52" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="144271c6-c0d9-443f-b11c-537dd82f3a58" data-execution_count="68">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(outputs.past_key_values.key_cache), <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(outputs.past_key_values.value_cache)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>(30, 30)</code></pre>
</div>
</div>
<div id="cell-53" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d2af89b4-8842-46d2-c6b5-78e8ad4010d7" data-execution_count="69">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">outputs.past_key_values.seen_tokens</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>7</code></pre>
</div>
</div>
<p>The <code>key_cache</code> tensors all have the same shape: batch size, num_heads, seen_tokens, head_dim.</p>
<div id="cell-55" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="df7616f9-08fe-4fa3-f527-615bf9f83a1c" data-execution_count="70">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> outputs.past_key_values.key_cache: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(k.shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<div id="cell-56" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b16b73c8-950b-4443-dcea-4701436d9749" data-execution_count="71">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">model.config.num_attention_heads, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb37-2">model.config.num_hidden_layers, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\</span></span>
<span id="cb37-3">model.config.num_key_value_heads</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>(9, 30, 3)</code></pre>
</div>
</div>
<div id="cell-57" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="41b06ce8-7bfc-4bc6-8ade-8ce7084457ac" data-execution_count="72">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">model.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].self_attn.k_proj.out_features</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>192</code></pre>
</div>
</div>
<div id="cell-58" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="316d31cf-cf8b-49e7-ebc7-1cb061de1468" data-execution_count="73">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>192</code></pre>
</div>
</div>
<p>The <code>value_cache</code> is similarly structured.</p>
<div id="cell-60" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f772dcaa-63fe-4315-e142-0cebb1c9e260" data-execution_count="74">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> v <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> outputs.past_key_values.value_cache: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(v.shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<div id="cell-61" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c4db38cf-43f1-4172-ad94-706d347ecea2" data-execution_count="75">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">init_k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> outputs.past_key_values.key_cache[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb45-2">init_k.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<p>While the shapes of the <code>key_cache</code> tensors across layers are the same, their contents are not. This is because each layer has its own self attention module with its own <code>k_proj</code> and <code>v_proj</code> layers with their own learned weights.</p>
<div id="cell-63" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:141}}" data-outputid="09ec3082-2e2d-44ea-fa9a-1d7517d05b5f" data-execution_count="76">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> outputs.past_key_values.key_cache[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:]: <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> torch.allclose(init_k, k)</span></code></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">AssertionError</span>                            Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-76-f08f1c95a8ee&gt;</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">for</span> k <span class="ansi-green-fg">in</span> outputs<span class="ansi-blue-fg">.</span>past_key_values<span class="ansi-blue-fg">.</span>key_cache<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">assert</span> torch<span class="ansi-blue-fg">.</span>allclose<span class="ansi-blue-fg">(</span>init_k<span class="ansi-blue-fg">,</span> k<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">AssertionError</span>: </pre>
</div>
</div>
</div>
</section>
<section id="inspecting-intermediate-keyvalue-cache-tensors-during-generation" class="level2">
<h2 class="anchored" data-anchor-id="inspecting-intermediate-keyvalue-cache-tensors-during-generation">Inspecting Intermediate Key/Value Cache Tensors During Generation</h2>
<p>Now to understand how KV cache is used during generation: I want to inspect the shape of the key and value cache tensors as the prompt increases by one token at a time.</p>
<p>To achieve this, I’ll add a hook to the first layer’s self attention module’s forward pass using <code>register_forward_hook</code>. I came to an incorrect conclusion in a <a href="https://youtu.be/4OBQkESiL0M?feature=shared&amp;t=965">previous video</a> and <a href="https://vishalbakshi.github.io/blog/posts/2025-04-02-Composer-Callback-Logging-dtypes/#composer-callback-walkthrough:~:text=Self%20attention%20cannot%20utilize%20register_forward_hook%20because%20the%20LlamaDecoderLayer%20does%20not%20call%20self%20attention%20forward%20pass%20with%20any%20positional%20arguments%3A">blog post</a> that you can’t use <code>register_forward_hook</code> for the Llama attention module because it doesn’t capture keyword arguments. What I didn’t realize is that you can capture kwargs with <code>register_forward_hook</code> by setting <code>with_kwargs=True</code>, which I have done below.</p>
<p>I wrapped <code>hook_fn</code> in <code>create_hook_fn</code> because I wanted to print out the <code>count</code> of total generated tokens.</p>
<div id="cell-67" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="222ac421-f62f-444c-d90f-a65a283d8e7b" data-execution_count="77">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> create_hook_fn():</span>
<span id="cb48-2">    count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb48-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, args, kwargs, output):</span>
<span id="cb48-4">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">nonlocal</span> count</span>
<span id="cb48-5">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(count, kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'past_key_value'</span>].key_cache[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape)</span>
<span id="cb48-6">        count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb48-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb48-8"></span>
<span id="cb48-9">_hook_fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> create_hook_fn()</span>
<span id="cb48-10">attn_layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].self_attn</span>
<span id="cb48-11">hook_handle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attn_layer.register_forward_hook(_hook_fn, with_kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb48-12"></span>
<span id="cb48-13">outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb48-14">hook_handle.remove()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1 torch.Size([1, 3, 3, 64])
2 torch.Size([1, 3, 4, 64])
3 torch.Size([1, 3, 5, 64])
4 torch.Size([1, 3, 6, 64])
5 torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<p>Let’s parse this output:</p>
<ul>
<li>The first new token generated sees only the 3 tokens in the prompt. The KV cache subsequently has a third dimension of <code>3</code>.</li>
<li>Each new token generated sees one more new token, so the third dimension (seen tokens) of <code>key_cache</code> and <code>value_cache</code> increases by <code>1</code></li>
</ul>
<p>I’ll slightly modify <code>hook_fn</code> so it prints out the first few shapes of <code>key_cache</code>, allowing us to see what all layers’ cache is storing from the perspective of <code>layer_idx=0</code>.</p>
<div id="cell-70" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="779782e8-dc50-4d92-fc8a-0712826d3cf7" data-execution_count="78">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> create_hook_fn():</span>
<span id="cb50-2">    count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb50-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, args, kwargs, output):</span>
<span id="cb50-4">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">nonlocal</span> count</span>
<span id="cb50-5">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(count)</span>
<span id="cb50-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'past_key_value'</span>].key_cache[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(k.shape)</span>
<span id="cb50-7">        count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb50-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb50-9"></span>
<span id="cb50-10">_hook_fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> create_hook_fn()</span>
<span id="cb50-11">attn_layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].self_attn</span>
<span id="cb50-12">hook_handle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attn_layer.register_forward_hook(_hook_fn, with_kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb50-13"></span>
<span id="cb50-14">outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb50-15">hook_handle.remove()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1
torch.Size([1, 3, 3, 64])
2
torch.Size([1, 3, 4, 64])
torch.Size([1, 3, 3, 64])
torch.Size([1, 3, 3, 64])
torch.Size([1, 3, 3, 64])
torch.Size([1, 3, 3, 64])
3
torch.Size([1, 3, 5, 64])
torch.Size([1, 3, 4, 64])
torch.Size([1, 3, 4, 64])
torch.Size([1, 3, 4, 64])
torch.Size([1, 3, 4, 64])
4
torch.Size([1, 3, 6, 64])
torch.Size([1, 3, 5, 64])
torch.Size([1, 3, 5, 64])
torch.Size([1, 3, 5, 64])
torch.Size([1, 3, 5, 64])
5
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 6, 64])
torch.Size([1, 3, 6, 64])
torch.Size([1, 3, 6, 64])
torch.Size([1, 3, 6, 64])</code></pre>
</div>
</div>
<p>Since we are capturing the <code>key_cache</code> shapes from the first layer (<code>layer_idx=0</code>), the other subsequent layer’s cache tensors are 1 token “behind”, since the new token’s hidden states have not passed through the model yet.</p>
<p>Ultimately, I want to tie this all back to the <code>flash_attn_varlen_func</code>’s dostring’s causal mask example, so I’ll take a look at the <code>query_states</code> shape, copying code from the <a href="https://github.com/huggingface/transformers/blob/78d771c3c21922642fc9546ccb973cc7a182ab34/src/transformers/models/llama/modeling_llama.py#L232-L235"><code>LlamaAttention</code> forward pass</a>. I’ll also inspect the length of the <code>key_cache</code> and its shape, and the shape of <code>value_cache</code>.</p>
<div id="cell-73" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b70a2dd1-b26f-46f9-cf7e-311cccd3d82b" data-execution_count="79">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> create_hook_fn():</span>
<span id="cb52-2">    count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb52-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, args, kwargs, output):</span>
<span id="cb52-4">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">nonlocal</span> count</span>
<span id="cb52-5">        input_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hidden_states'</span>].shape[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb52-6">        hidden_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>input_shape, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, module.head_dim)</span>
<span id="cb52-7">        query_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> module.q_proj(kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hidden_states'</span>]).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb52-8">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(count, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"len(past_key_value): </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'past_key_value'</span>].key_cache)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">,"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"query_states.shape: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>query_states<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">,"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"k.shape: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'past_key_value'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>key_cache[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">,"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"v.shape: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'past_key_value'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>value_cache[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb52-9">        count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb52-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb52-11"></span>
<span id="cb52-12">_hook_fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> create_hook_fn()</span>
<span id="cb52-13">attn_layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].self_attn</span>
<span id="cb52-14">hook_handle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attn_layer.register_forward_hook(_hook_fn, with_kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb52-15"></span>
<span id="cb52-16">outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb52-17">hook_handle.remove()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1 len(past_key_value): 1, query_states.shape: torch.Size([1, 9, 3, 64]), k.shape: torch.Size([1, 3, 3, 64]), v.shape: torch.Size([1, 3, 3, 64])
2 len(past_key_value): 30, query_states.shape: torch.Size([1, 9, 1, 64]), k.shape: torch.Size([1, 3, 4, 64]), v.shape: torch.Size([1, 3, 4, 64])
3 len(past_key_value): 30, query_states.shape: torch.Size([1, 9, 1, 64]), k.shape: torch.Size([1, 3, 5, 64]), v.shape: torch.Size([1, 3, 5, 64])
4 len(past_key_value): 30, query_states.shape: torch.Size([1, 9, 1, 64]), k.shape: torch.Size([1, 3, 6, 64]), v.shape: torch.Size([1, 3, 6, 64])
5 len(past_key_value): 30, query_states.shape: torch.Size([1, 9, 1, 64]), k.shape: torch.Size([1, 3, 7, 64]), v.shape: torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<p>We see that there are 9 query heads, and 3 KV heads. The total hidden dimension for Q, K and V layers is 3 x 64 = 192.</p>
<p>When the first token is being the generated, the length of the <code>key_cache</code> for <code>layer_idx=0</code> is <code>1</code>, because this is the first attention module’s first forward pass. For subsequent tokens (2, 3, 4, 5) the length of the <code>key_cache</code> is <code>30</code>, as the cache has been instantiated for all 30 layers after the first token is generated.</p>
<p>Finally, we see that the <code>key_cache</code> and <code>value_cache</code> shapes are equal, as expected.</p>
</section>
<section id="which-flash-attention-interface-is-used" class="level2">
<h2 class="anchored" data-anchor-id="which-flash-attention-interface-is-used">Which Flash Attention Interface is Used?</h2>
<p>Since this exercise is part of my journey to understand the <code>flash_attn_varlen_func</code>, I was curious to confirm by visual inspection which Flash Attention interface function was being used. To achieve this, I wrote a “debug” version for the following three functions:</p>
<ul>
<li><a href="https://github.com/huggingface/transformers/blob/78d771c3c21922642fc9546ccb973cc7a182ab34/src/transformers/models/llama/modeling_llama.py#L223"><code>LlamaAttention.forward</code></a></li>
<li><a href="https://github.com/huggingface/transformers/blob/78d771c3c21922642fc9546ccb973cc7a182ab34/src/transformers/integrations/flash_attention.py#L14"><code>flash_attention_forward</code></a></li>
<li><a href="https://github.com/huggingface/transformers/blob/78d771c3c21922642fc9546ccb973cc7a182ab34/src/transformers/modeling_flash_attention_utils.py#L284"><code>_flash_attention_forward</code></a></li>
</ul>
<p>How did I know which functions to modify? Well, largely because I <a href="https://vishalbakshi.github.io/blog/posts/2025-05-04-Understanding-Sequence-Packing/">have done this exercise before</a> when I was trying to understand what triggered the use of <code>flash_attn_varlen_func</code>.</p>
<p>More concisely, I first inspected the forward pass of the attention module:</p>
<div id="cell-79" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="fc396455-d320-43da-9491-a9555f6118a5" data-execution_count="80">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> inspect <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> getsource</span>
<span id="cb54-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(getsource(model.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].self_attn.forward))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    def forward(
        self,
        hidden_states: torch.Tensor,
        position_embeddings: Tuple[torch.Tensor, torch.Tensor],
        attention_mask: Optional[torch.Tensor],
        past_key_value: Optional[Cache] = None,
        cache_position: Optional[torch.LongTensor] = None,
        **kwargs: Unpack[FlashAttentionKwargs],
    ) -&gt; Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:
        input_shape = hidden_states.shape[:-1]
        hidden_shape = (*input_shape, -1, self.head_dim)

        query_states = self.q_proj(hidden_states).view(hidden_shape).transpose(1, 2)
        key_states = self.k_proj(hidden_states).view(hidden_shape).transpose(1, 2)
        value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)

        cos, sin = position_embeddings
        query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)

        if past_key_value is not None:
            # sin and cos are specific to RoPE models; cache_position needed for the static cache
            cache_kwargs = {"sin": sin, "cos": cos, "cache_position": cache_position}
            key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)

        attention_interface: Callable = eager_attention_forward

        if self.config._attn_implementation != "eager":
            if self.config._attn_implementation == "sdpa" and kwargs.get("output_attentions", False):
                logger.warning_once(
                    "`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to "
                    'eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.'
                )
            else:
                attention_interface = ALL_ATTENTION_FUNCTIONS[self.config._attn_implementation]

        attn_output, attn_weights = attention_interface(
            self,
            query_states,
            key_states,
            value_states,
            attention_mask,
            dropout=0.0 if not self.training else self.attention_dropout,
            scaling=self.scaling,
            **kwargs,
        )

        attn_output = attn_output.reshape(*input_shape, -1).contiguous()
        attn_output = self.o_proj(attn_output)
        return attn_output, attn_weights
</code></pre>
</div>
</div>
<p>In there I saw the following lines of interest:</p>
<div class="sourceCode" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config._attn_implementation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"eager"</span>:</span>
<span id="cb56-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config._attn_implementation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sdpa"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> kwargs.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_attentions"</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb56-3">        logger.warning_once(</span>
<span id="cb56-4">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to "</span></span>
<span id="cb56-5">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.'</span></span>
<span id="cb56-6">        )</span>
<span id="cb56-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb56-8">        attention_interface <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ALL_ATTENTION_FUNCTIONS[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config._attn_implementation]</span></code></pre></div>
<p>In our case, the <code>else</code> block would trigger and <code>ALL_ATTENTION_FUNCTIONS</code> would be accesssed. Looking at that constant directly we can see that for our model’s <code>_attn_implementation</code> (<code>'flash_attention_2'</code>) the attention interface funtion is <code>flash_attention_forward</code>.</p>
<div id="cell-82" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:35}}" data-outputid="8d40574b-2e73-4ad6-a6b0-7490e87e4108" data-execution_count="81">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">model.config._attn_implementation</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>'flash_attention_2'</code></pre>
</div>
</div>
<div id="cell-83" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:174}}" data-outputid="fc2cd815-84be-44c3-8255-4b6a2f33e5c8" data-execution_count="82">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.modeling_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ALL_ATTENTION_FUNCTIONS</span>
<span id="cb59-2">ALL_ATTENTION_FUNCTIONS[model.config._attn_implementation]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<div style="max-width:800px; border: 1px solid var(--colab-border-color);"><style>
      pre.function-repr-contents {
        overflow-x: auto;
        padding: 8px 12px;
        max-height: 500px;
      }

      pre.function-repr-contents.function-repr-contents-collapsed {
        cursor: pointer;
        max-height: 100px;
      }
    </style>
    <pre style="white-space: initial; background:
         var(--colab-secondary-surface-color); padding: 8px 12px;
         border-bottom: 1px solid var(--colab-border-color);"><b>transformers.integrations.flash_attention.flash_attention_forward</b><br>def flash_attention_forward(module: torch.nn.Module, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, attention_mask: Optional[torch.Tensor], dropout: float=0.0, scaling: Optional[float]=None, sliding_window: Optional[int]=None, softcap: Optional[float]=None, **kwargs) -&gt; Tuple[torch.Tensor, None]</pre><pre class="function-repr-contents function-repr-contents-collapsed" style="">/usr/local/lib/python3.11/dist-packages/transformers/integrations/flash_attention.py&lt;no docstring&gt;</pre>
      <script>
      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {
        for (const element of document.querySelectorAll('.filepath')) {
          element.style.display = 'block'
          element.onclick = (event) => {
            event.preventDefault();
            event.stopPropagation();
            google.colab.files.view(element.textContent, 11);
          };
        }
      }
      for (const element of document.querySelectorAll('.function-repr-contents')) {
        element.onclick = (event) => {
          event.preventDefault();
          event.stopPropagation();
          element.classList.toggle('function-repr-contents-collapsed');
        };
      }
      </script>
      </div>
</div>
</div>
<div id="cell-84" class="cell" data-execution_count="85">
<details class="code-fold">
<summary>Show `_debug_flash_attention_forward</summary>
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Optional, Tuple</span>
<span id="cb60-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> inspect</span>
<span id="cb60-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> flash_attn <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> flash_attn_func, flash_attn_varlen_func</span>
<span id="cb60-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb60-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb60-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.modeling_flash_attention_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> is_flash_attn_greater_or_equal, fa_peft_integration_check, _upad_input, pad_input, prepare_fa2_from_position_ids</span>
<span id="cb60-7"></span>
<span id="cb60-8">_flash_supports_window_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"window_size"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>(inspect.signature(flash_attn_func).parameters)</span>
<span id="cb60-9">flash_241 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> is_flash_attn_greater_or_equal(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"2.4.1"</span>)</span>
<span id="cb60-10">deterministic_g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb60-11"></span>
<span id="cb60-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _debug_flash_attention_forward(</span>
<span id="cb60-13">    query_states: torch.Tensor,</span>
<span id="cb60-14">    key_states: torch.Tensor,</span>
<span id="cb60-15">    value_states: torch.Tensor,</span>
<span id="cb60-16">    attention_mask: Optional[torch.Tensor],</span>
<span id="cb60-17">    query_length: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>,</span>
<span id="cb60-18">    is_causal: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>,</span>
<span id="cb60-19">    dropout: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,</span>
<span id="cb60-20">    position_ids: Optional[torch.Tensor] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-21">    softmax_scale: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-22">    sliding_window: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-23">    use_top_left_mask: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb60-24">    softcap: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-25">    deterministic: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">bool</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-26">    cu_seq_lens_q: Optional[torch.LongTensor] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-27">    cu_seq_lens_k: Optional[torch.LongTensor] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-28">    max_length_q: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-29">    max_length_k: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-30">    target_dtype: Optional[torch.dtype] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb60-31">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs,</span>
<span id="cb60-32">):</span>
<span id="cb60-33"></span>
<span id="cb60-34">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> use_top_left_mask:</span>
<span id="cb60-35">        causal <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> is_causal</span>
<span id="cb60-36">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb60-37">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># </span><span class="al" style="color: #AD0000;
background-color: null;
font-style: inherit;">TODO</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">: Remove the `query_length != 1` check once Flash Attention for RoCm is bumped to 2.1.</span></span>
<span id="cb60-38">        causal <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> is_causal <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> query_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb60-39"></span>
<span id="cb60-40">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Assuming 4D tensors, key_states.shape[1] is the key/value sequence length (source length).</span></span>
<span id="cb60-41">    use_sliding_windows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb60-42">        _flash_supports_window_size <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> sliding_window <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> key_states.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> sliding_window</span>
<span id="cb60-43">    )</span>
<span id="cb60-44">    flash_kwargs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"window_size"</span>: (sliding_window, sliding_window)} <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> use_sliding_windows <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> {}</span>
<span id="cb60-45"></span>
<span id="cb60-46">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> flash_241:</span>
<span id="cb60-47">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> deterministic <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb60-48">            <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">global</span> deterministic_g</span>
<span id="cb60-49">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> deterministic_g <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb60-50">                deterministic_g <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.environ.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"FLASH_ATTENTION_DETERMINISTIC"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"0"</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1"</span></span>
<span id="cb60-51">            deterministic <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deterministic_g</span>
<span id="cb60-52">        flash_kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"deterministic"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> deterministic</span>
<span id="cb60-53"></span>
<span id="cb60-54">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> softcap <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb60-55">        flash_kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"softcap"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> softcap</span>
<span id="cb60-56"></span>
<span id="cb60-57">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># PEFT possibly silently casts tensors to fp32, this potentially reconverts to correct dtype or is a no op</span></span>
<span id="cb60-58">    query_states, key_states, value_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> fa_peft_integration_check(</span>
<span id="cb60-59">        query_states, key_states, value_states, target_dtype</span>
<span id="cb60-60">    )</span>
<span id="cb60-61"></span>
<span id="cb60-62">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Contains at least one padding token in the sequence</span></span>
<span id="cb60-63">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> attention_mask <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb60-64">        batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> query_states.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb60-65">        query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _upad_input(</span>
<span id="cb60-66">            query_states, key_states, value_states, attention_mask, query_length</span>
<span id="cb60-67">        )</span>
<span id="cb60-68">        cu_seqlens_q, cu_seqlens_k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cu_seq_lens</span>
<span id="cb60-69">        max_seqlen_in_batch_q, max_seqlen_in_batch_k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_seq_lens</span>
<span id="cb60-70">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"if attention_mask is not None: flash_attn_varlen_func is being used"</span>)</span>
<span id="cb60-71">        attn_output_unpad <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flash_attn_varlen_func(</span>
<span id="cb60-72">            query_states,</span>
<span id="cb60-73">            key_states,</span>
<span id="cb60-74">            value_states,</span>
<span id="cb60-75">            cu_seqlens_q<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cu_seqlens_q,</span>
<span id="cb60-76">            cu_seqlens_k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cu_seqlens_k,</span>
<span id="cb60-77">            max_seqlen_q<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>max_seqlen_in_batch_q,</span>
<span id="cb60-78">            max_seqlen_k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>max_seqlen_in_batch_k,</span>
<span id="cb60-79">            dropout_p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dropout,</span>
<span id="cb60-80">            softmax_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>softmax_scale,</span>
<span id="cb60-81">            causal<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>causal,</span>
<span id="cb60-82">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>flash_kwargs,</span>
<span id="cb60-83">        )</span>
<span id="cb60-84">        attn_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pad_input(attn_output_unpad, indices_q, batch_size, query_length)</span>
<span id="cb60-85"></span>
<span id="cb60-86">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If position_ids is provided and check all examples do not contain only 1 sequence, If tensor in increasing</span></span>
<span id="cb60-87">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># then we probably have one sequence, otherwise it is packed. Additionally check we are in pre-fill/training stage.</span></span>
<span id="cb60-88">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use `flash_attn_varlen_func` to prevent cross-example attention and also allow padding free approach</span></span>
<span id="cb60-89">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> position_ids <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> (</span>
<span id="cb60-90">        max_length_q <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> (query_length <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> (torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span>())</span>
<span id="cb60-91">    ):</span>
<span id="cb60-92">        batch_size <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> query_states.size(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb60-93"></span>
<span id="cb60-94">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> cu_seq_lens_q <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> cu_seq_lens_k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb60-95">            query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb60-96">                prepare_fa2_from_position_ids(query_states, key_states, value_states, position_ids)</span>
<span id="cb60-97">            )</span>
<span id="cb60-98"></span>
<span id="cb60-99">            cu_seq_lens_q, cu_seq_lens_k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cu_seq_lens</span>
<span id="cb60-100">            max_length_q, max_length_k <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> max_seq_lens</span>
<span id="cb60-101"></span>
<span id="cb60-102">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb60-103">            query_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> query_states.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, query_states.size(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), query_states.size(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb60-104">            key_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> key_states.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, key_states.size(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), key_states.size(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb60-105">            value_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> value_states.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, value_states.size(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), value_states.size(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb60-106"></span>
<span id="cb60-107">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"position_ids is not None: flash_attn_varlen_func is being used"</span>)</span>
<span id="cb60-108">        attn_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flash_attn_varlen_func(</span>
<span id="cb60-109">            query_states,</span>
<span id="cb60-110">            key_states,</span>
<span id="cb60-111">            value_states,</span>
<span id="cb60-112">            cu_seqlens_q<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cu_seq_lens_q,</span>
<span id="cb60-113">            cu_seqlens_k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>cu_seq_lens_k,</span>
<span id="cb60-114">            max_seqlen_q<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>max_length_q,</span>
<span id="cb60-115">            max_seqlen_k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>max_length_k,</span>
<span id="cb60-116">            dropout_p<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dropout,</span>
<span id="cb60-117">            softmax_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>softmax_scale,</span>
<span id="cb60-118">            causal<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>causal,</span>
<span id="cb60-119">            <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>flash_kwargs,</span>
<span id="cb60-120">        )</span>
<span id="cb60-121"></span>
<span id="cb60-122">        attn_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attn_output.view(batch_size, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, attn_output.size(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), attn_output.size(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb60-123"></span>
<span id="cb60-124">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb60-125">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"flash_attn_func is being used"</span>)</span>
<span id="cb60-126">        attn_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flash_attn_func(</span>
<span id="cb60-127">            query_states, key_states, value_states, dropout, softmax_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>softmax_scale, causal<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>causal, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>flash_kwargs</span>
<span id="cb60-128">        )</span>
<span id="cb60-129"></span>
<span id="cb60-130">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> attn_output</span></code></pre></div>
</details>
</div>
<div id="cell-85" class="cell" data-execution_count="86">
<details class="code-fold">
<summary>Show `debug_flash_attention_forward</summary>
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Optional, Tuple</span>
<span id="cb61-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb61-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.modeling_flash_attention_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> _flash_attention_forward, flash_attn_supports_top_left_mask</span>
<span id="cb61-4"></span>
<span id="cb61-5">_use_top_left_mask <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> flash_attn_supports_top_left_mask()</span>
<span id="cb61-6"></span>
<span id="cb61-7"></span>
<span id="cb61-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> debug_flash_attention_forward(</span>
<span id="cb61-9">    module: torch.nn.Module,</span>
<span id="cb61-10">    query: torch.Tensor,</span>
<span id="cb61-11">    key: torch.Tensor,</span>
<span id="cb61-12">    value: torch.Tensor,</span>
<span id="cb61-13">    attention_mask: Optional[torch.Tensor],</span>
<span id="cb61-14">    dropout: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>,</span>
<span id="cb61-15">    scaling: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb61-16">    sliding_window: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb61-17">    softcap: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb61-18">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs,</span>
<span id="cb61-19">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Tuple[torch.Tensor, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]:</span>
<span id="cb61-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> kwargs.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_attentions"</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">or</span> kwargs.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"head_mask"</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>) <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb61-21">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(</span>
<span id="cb61-22">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"`flash_attention_2` does not support `output_attentions=True` or `head_mask`."</span></span>
<span id="cb61-23">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" Please set your attention to `eager` if you want any of these features."</span></span>
<span id="cb61-24">        )</span>
<span id="cb61-25"></span>
<span id="cb61-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This is before the transpose</span></span>
<span id="cb61-27">    seq_len <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> query.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]</span>
<span id="cb61-28"></span>
<span id="cb61-29">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># FA2 uses non-transposed inputs</span></span>
<span id="cb61-30">    query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> query.transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb61-31">    key <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> key.transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb61-32">    value <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> value.transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb61-33"></span>
<span id="cb61-34">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># In PEFT, usually we cast the layer norms in float32 for training stability reasons</span></span>
<span id="cb61-35">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># therefore the input hidden states gets silently casted in float32. Hence, we need</span></span>
<span id="cb61-36">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># cast them back in the correct dtype just to be sure everything works as expected.</span></span>
<span id="cb61-37">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This might slowdown training &amp; inference so it is recommended to not cast the LayerNorms</span></span>
<span id="cb61-38">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># in fp32. (usually our RMSNorm modules handle it correctly)</span></span>
<span id="cb61-39">    target_dtype <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span>
<span id="cb61-40">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> query.dtype <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> torch.float32:</span>
<span id="cb61-41">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> torch.is_autocast_enabled():</span>
<span id="cb61-42">            target_dtype <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.get_autocast_gpu_dtype()</span>
<span id="cb61-43">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Handle the case where the model is quantized</span></span>
<span id="cb61-44">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hasattr</span>(module.config, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_pre_quantization_dtype"</span>):</span>
<span id="cb61-45">            target_dtype <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> module.config._pre_quantization_dtype</span>
<span id="cb61-46">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb61-47">            target_dtype <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">next</span>(layer <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> layer <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> module.modules() <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(layer, torch.nn.Linear)).weight.dtype</span>
<span id="cb61-48"></span>
<span id="cb61-49">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># FA2 always relies on the value set in the module, so remove it if present in kwargs to avoid passing it twice</span></span>
<span id="cb61-50">    kwargs.pop(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"is_causal"</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>)</span>
<span id="cb61-51"></span>
<span id="cb61-52">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"DEBUG: calling _flash_attention_forward"</span>)</span>
<span id="cb61-53">    attn_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> _debug_flash_attention_forward(</span>
<span id="cb61-54">        query,</span>
<span id="cb61-55">        key,</span>
<span id="cb61-56">        value,</span>
<span id="cb61-57">        attention_mask,</span>
<span id="cb61-58">        query_length<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>seq_len,</span>
<span id="cb61-59">        is_causal<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>module.is_causal,</span>
<span id="cb61-60">        dropout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>dropout,</span>
<span id="cb61-61">        softmax_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>scaling,</span>
<span id="cb61-62">        sliding_window<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>sliding_window,</span>
<span id="cb61-63">        softcap<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>softcap,</span>
<span id="cb61-64">        use_top_left_mask<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>_use_top_left_mask,</span>
<span id="cb61-65">        target_dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>target_dtype,</span>
<span id="cb61-66">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs,</span>
<span id="cb61-67">    )</span>
<span id="cb61-68"></span>
<span id="cb61-69">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> attn_output, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span></span></code></pre></div>
</details>
</div>
<div id="cell-86" class="cell" data-execution_count="87">
<details class="code-fold">
<summary>Show `debug_forward</summary>
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Callable, Optional, Tuple, Union</span>
<span id="cb62-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.modeling_flash_attention_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> FlashAttentionKwargs</span>
<span id="cb62-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.cache_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Cache, DynamicCache</span>
<span id="cb62-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.processing_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Unpack</span>
<span id="cb62-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.models.llama.modeling_llama <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> apply_rotary_pos_emb</span>
<span id="cb62-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.models.llama.modeling_llama <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> eager_attention_forward</span>
<span id="cb62-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> transformers.modeling_utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ALL_ATTENTION_FUNCTIONS</span>
<span id="cb62-8"></span>
<span id="cb62-9"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> debug_forward(</span>
<span id="cb62-10">    <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,</span>
<span id="cb62-11">    hidden_states: torch.Tensor,</span>
<span id="cb62-12">    position_embeddings: Tuple[torch.Tensor, torch.Tensor],</span>
<span id="cb62-13">    attention_mask: Optional[torch.Tensor],</span>
<span id="cb62-14">    past_key_value: Optional[Cache] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb62-15">    cache_position: Optional[torch.LongTensor] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>,</span>
<span id="cb62-16">    <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs: Unpack[FlashAttentionKwargs],</span>
<span id="cb62-17">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:</span>
<span id="cb62-18">    input_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> hidden_states.shape[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb62-19">    hidden_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>input_shape, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.head_dim)</span>
<span id="cb62-20"></span>
<span id="cb62-21">    query_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.q_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb62-22">    key_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.k_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb62-23">    value_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.v_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb62-24"></span>
<span id="cb62-25">    cos, sin <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> position_embeddings</span>
<span id="cb62-26">    query_states, key_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> apply_rotary_pos_emb(query_states, key_states, cos, sin)</span>
<span id="cb62-27"></span>
<span id="cb62-28">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> past_key_value <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>:</span>
<span id="cb62-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># sin and cos are specific to RoPE models; cache_position needed for the static cache</span></span>
<span id="cb62-30">        cache_kwargs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sin"</span>: sin, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cos"</span>: cos, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cache_position"</span>: cache_position}</span>
<span id="cb62-31">        key_states, value_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> past_key_value.update(key_states, value_states, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.layer_idx, cache_kwargs)</span>
<span id="cb62-32"></span>
<span id="cb62-33">    attention_interface: Callable <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> eager_attention_forward</span>
<span id="cb62-34"></span>
<span id="cb62-35">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config._attn_implementation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"eager"</span>:</span>
<span id="cb62-36">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.config._attn_implementation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sdpa"</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> kwargs.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"output_attentions"</span>, <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>):</span>
<span id="cb62-37">            <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(</span>
<span id="cb62-38">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to "</span></span>
<span id="cb62-39">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.'</span></span>
<span id="cb62-40">            )</span>
<span id="cb62-41">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb62-42">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#attention_interface = ALL_ATTENTION_FUNCTIONS[self.config._attn_implementation]</span></span>
<span id="cb62-43">            attention_interface <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> debug_flash_attention_forward</span>
<span id="cb62-44"></span>
<span id="cb62-45">    attn_output, attn_weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attention_interface(</span>
<span id="cb62-46">        <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>,</span>
<span id="cb62-47">        query_states,</span>
<span id="cb62-48">        key_states,</span>
<span id="cb62-49">        value_states,</span>
<span id="cb62-50">        attention_mask,</span>
<span id="cb62-51">        dropout<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span> <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.training <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.attention_dropout,</span>
<span id="cb62-52">        scaling<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.scaling,</span>
<span id="cb62-53">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs,</span>
<span id="cb62-54">    )</span>
<span id="cb62-55"></span>
<span id="cb62-56">    attn_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attn_output.reshape(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>input_shape, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).contiguous()</span>
<span id="cb62-57">    attn_output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">self</span>.o_proj(attn_output)</span>
<span id="cb62-58">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> attn_output, attn_weights</span></code></pre></div>
</details>
</div>
<div id="cell-87" class="cell">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">tokenizer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFaceTB/SmolLM2-135M"</span>)</span>
<span id="cb63-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"HuggingFaceTB/SmolLM2-135M"</span>, attn_implementation<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"flash_attention_2"</span>, torch_dtype<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>torch.bfloat16).to(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cuda"</span>)</span></code></pre></div>
</div>
<p><code>types.MethodType</code> binds a function (<code>debug_forward</code>) as a method for a class (<code>attn_layer_instance</code>).</p>
<div id="cell-89" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> types</span>
<span id="cb64-2">types.MethodType??</span></code></pre></div>
</div>
<pre><code>Init signature: types.MethodType(self, /, *args, **kwargs)
Docstring:      Create a bound instance method object.
Type:           type
Subclasses:    </code></pre>
<div id="cell-91" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1">attn_layer_instance <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].self_attn</span>
<span id="cb66-2"></span>
<span id="cb66-3">original_layer_forward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attn_layer_instance.forward</span>
<span id="cb66-4"></span>
<span id="cb66-5">attn_layer_instance.forward <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> types.MethodType(debug_forward, attn_layer_instance)</span></code></pre></div>
</div>
<div id="cell-92" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f9c3e320-4cc7-4467-bd12-727167ceb4b9" data-execution_count="91">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> create_hook_fn():</span>
<span id="cb67-2">    count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb67-3">    <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> hook_fn(module, args, kwargs, output):</span>
<span id="cb67-4">        <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">nonlocal</span> count</span>
<span id="cb67-5">        input_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hidden_states'</span>].shape[:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb67-6">        hidden_shape <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>input_shape, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, module.head_dim)</span>
<span id="cb67-7">        query_states <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> module.q_proj(kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hidden_states'</span>]).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb67-8">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(count, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'past_key_value'</span>].key_cache), <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"query_states.shape: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>query_states<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"k.shape: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>kwargs[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'past_key_value'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>key_cache[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>shape<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb67-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># for k in kwargs['past_key_value'].key_cache: print(k.shape) # do this for v as well</span></span>
<span id="cb67-10">        count <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb67-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> hook_fn</span>
<span id="cb67-12"></span>
<span id="cb67-13">_hook_fn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> create_hook_fn()</span>
<span id="cb67-14">attn_layer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].self_attn</span>
<span id="cb67-15">hook_handle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> attn_layer.register_forward_hook(_hook_fn, with_kwargs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb67-16"></span>
<span id="cb67-17">outputs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb67-18"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(outputs.sequences[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape)</span>
<span id="cb67-19"></span>
<span id="cb67-20">hook_handle.remove()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DEBUG: calling _flash_attention_forward
flash_attn_func is being used
1 1 query_states.shape: torch.Size([1, 9, 3, 64]) k.shape: torch.Size([1, 3, 3, 64])
DEBUG: calling _flash_attention_forward
flash_attn_func is being used
2 30 query_states.shape: torch.Size([1, 9, 1, 64]) k.shape: torch.Size([1, 3, 4, 64])
DEBUG: calling _flash_attention_forward
flash_attn_func is being used
3 30 query_states.shape: torch.Size([1, 9, 1, 64]) k.shape: torch.Size([1, 3, 5, 64])
DEBUG: calling _flash_attention_forward
flash_attn_func is being used
4 30 query_states.shape: torch.Size([1, 9, 1, 64]) k.shape: torch.Size([1, 3, 6, 64])
DEBUG: calling _flash_attention_forward
flash_attn_func is being used
5 30 query_states.shape: torch.Size([1, 9, 1, 64]) k.shape: torch.Size([1, 3, 7, 64])
torch.Size([8])</code></pre>
</div>
</div>
<p>From the print statements in my <code>_debug_flash_attention_forward</code> function, I can see that <code>flash_attn_func</code>, the non-variable-length interface, is being used for this generation. That makes sense because I only have 1 item in the batch.</p>
</section>
<section id="understanding-the-flash_attn_varlen_func-causal-mask-docstring" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-flash_attn_varlen_func-causal-mask-docstring">Understanding the <code>flash_attn_varlen_func</code> Causal Mask Docstring</h2>
<p>A quick recap of what we’ve learned so far:</p>
<ul>
<li>HuggingFace’s <code>model.generate</code> uses KV cache by default (<code>DynamicCache</code>) stored as <code>past_key_values</code>.</li>
<li>For most scenarios, the <code>DynamicCache</code> is updated by concatenating the previous token’s <code>key_cache</code> and <code>value_cache</code> with the <code>key_states</code> and <code>value_states</code> generated for the current new token.</li>
<li>As the next token is generated for a given prompt, <code>query_states</code> has a sequence length of <code>1</code>, whereas <code>key_cache</code> and <code>value_cache</code> tensors’ sequence dimension increases by 1. This is directly relates to the <code>flash_attn_varlen_func</code> causal mask docstring example.</li>
<li><code>model.generate</code> utilized the <code>flash_attn_func</code> interface.</li>
</ul>
<p>Let’s look at the <code>flash_attn_varlen_func</code> docstring snippet again:</p>
<pre><code>If causal=True, the causal mask is aligned to the bottom right corner of the attention matrix.
For example, if seqlen_q = 2 and seqlen_k = 5, the causal mask (1 = keep, 0 = masked out) is:
    1 1 1 1 0
    1 1 1 1 1
If seqlen_q = 5 and seqlen_k = 2, the causal mask is:
    0 0
    0 0
    0 0
    1 0
    1 1
If the row of the mask is all zero, the output will be zero.</code></pre>
<p>I’ll annotate the causal mask examples a bit:</p>
<section id="seqlen_q2-and-seqlen_k5" class="level3">
<h3 class="anchored" data-anchor-id="seqlen_q2-and-seqlen_k5"><code>seqlen_q=2</code> and <code>seqlen_k=5</code></h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">k_0</th>
<th style="text-align: center;">k_1</th>
<th style="text-align: center;">k_2</th>
<th style="text-align: center;">k_3</th>
<th style="text-align: center;">k_4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>q_0</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_1</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>The final query token (<code>q_1</code>) sees all 5 key tokens. The first query token (<code>q_0</code>) only sees the first four key tokens.</p>
</section>
<section id="seqlen_q5-and-seqlen_k2" class="level3">
<h3 class="anchored" data-anchor-id="seqlen_q5-and-seqlen_k2"><code>seqlen_q=5</code> and <code>seqlen_k=2</code></h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">k_0</th>
<th style="text-align: center;">k_1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>q_0</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_1</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>q_2</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_3</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>q_4</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>Again, the final query token (<code>q_4</code>) sees all key tokens. As a consequence, since there are only two key tokens, the first three query tokens do not see any key tokens.</p>
<p>In each example, we are offsetting the shorter sequence so that its last token aligns with the other sequences’s last token. This is what the <code>flash_attn_varlen_func</code> docstring means by</p>
<blockquote class="blockquote">
<p><code>the causal mask is aligned to the bottom right corner of the attention matrix</code></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Annotated casual masks"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-03-flash_attn_varlen_func-casual-mask/1.png" class="img-fluid figure-img" alt="Annotated casual masks"></a></p>
<figcaption>Annotated casual masks</figcaption>
</figure>
</div>
<p>In the first case, the query sequence is shorter so we offset it by 3 positions to align with the last two tokens of the key sequence. The “offset” positions are 1s (this satisfies the rule of causality <code>j &lt;= i</code>, query tokens can look back). In the second case, the key sequence is shorter so we offset it by 3 positions to align with the last two tokens of the query sequence. The offset positions are 0s (again, this satisfies causality, the query tokens have nothing to look back to).</p>
<p>The <code>model.generate</code> examples above are like the first case, where there are more key positions than query positions. The query token (the next-token being predicted) can look back at all key tokens.</p>
</section>
<section id="a-math-y-way-to-think-about-it" class="level3">
<h3 class="anchored" data-anchor-id="a-math-y-way-to-think-about-it">A Math-y Way to think About It</h3>
<p>For those of you who like to think through things with math.</p>
<p>Causality (in language modeling) means that a query token vector at the i-th position can only see its own and previous tokens’ key vectors. Having different sequence lengths for Q and K (5 and 2 or 2 and 5 in the <code>flash_attn_varlen_func</code> docstring example or 1 and 3-7 in my inspections above) requires you to pick <em>how</em> Q and K are aligned. In the case of <code>flash_attn_varlen_func</code> they choose to align Q and K such as <em>the last Q token vector is aligned with the last K token vector</em>. This becomes our “present moment” <code>P</code> with causality allowing access to previous tokens only.</p>
<p>Let’s define <code>i</code> as the position of query tokens and <code>j</code> as the position of key tokens. Causality is defined as token pairs that follow the inequality: <code>j &lt;= i + (seqlen_k - seqlen_q)</code>.</p>
<p>For the first causal mask example:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"><code>j</code></th>
<th style="text-align: center;"><code>i</code></th>
<th style="text-align: center;"><code>j &lt;= i + (seqlen_k - seqlen_q)</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0 &lt;= 0 + 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1 &lt;= 0 + 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2 &lt;= 0 + 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">3 &lt;= 0 + 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">4 &lt;= 0 + 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">4 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
</tbody>
</table>
<p>Where does <code>j &lt;= i + (seqlen_k - seqlen_q)</code> come from?</p>
<p>Let <code>q_i</code> be a query that is <code>seqlen_q - 1 - i</code> steps before the end of the query sequence, and <code>k_j</code> be a key that is <code>seqlen_k - 1 - j</code> steps before the end of the key sequence. More concretely, for the example where <code>seqlen_q = 2</code> and <code>seqlen_k=5</code>:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">q_i</th>
<th style="text-align: center;">Steps before end</th>
<th style="text-align: center;"><code>seqlen_q - 1 - i</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">q_0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2 - 1 - 0</td>
</tr>
<tr class="even">
<td style="text-align: center;">q_1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2 - 1 - 1</td>
</tr>
</tbody>
</table>
<p><br></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">k_j</th>
<th style="text-align: center;">Steps before end</th>
<th style="text-align: center;"><code>seqlen_k - 1 - j</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">k_0</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5 - 1 - 0</td>
</tr>
<tr class="even">
<td style="text-align: center;">k_1</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">5 - 1 - 1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">k_2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5 - 2 - 1</td>
</tr>
<tr class="even">
<td style="text-align: center;">k_3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">5 - 3 - 1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">k_4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">5 - 4 - 1</td>
</tr>
</tbody>
</table>
<p>By picking a “present moment” <code>P</code> (the last token in each sequence) have a unified timeline <code>p</code> such that causality is defined as: <code>p_j &lt;= p_i</code>. <code>k_j</code> has a position on the timeline <code>p_j = P - (seqlen_k - 1 - j)</code> and <code>q_i</code> has a position on the timeline <code>p_i = P - (seqlen_q - 1 - i)</code>. Causality requires that <code>p_j &lt;= p_i</code> on our “unified timeline”. Writing that out:</p>
<p><code>P - (seqlen_k - 1 - j) &lt;= P - (seqlen_q - 1 - i)</code></p>
<p>Cancelling out the <code>P</code>s and distributing the minus sign:</p>
<p><code>-seqlen_k + 1 + j &lt;= -seqlen_q + 1 + i</code></p>
<p>Isolating <code>j</code> on the lefthand side:</p>
<p><code>j &lt;= -seqlen_q + 1 + i + seqlen_k - 1</code></p>
<p>Simplifying + reordering:</p>
<p><code>j &lt;= i + (seqlen_k - seqlen_q)</code></p>
<p>We can think of this <code>(seqlen_k - seqlen_q)</code> to be an “offset” term between the two sequences.</p>
<p>Looking at this concretely for the second causal mask:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">k_0</th>
<th style="text-align: center;">k_1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>q_0</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_1</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>q_2</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_3</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>q_4</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p><br></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;"><code>j</code></th>
<th style="text-align: center;"><code>i</code></th>
<th style="text-align: center;"><code>j &lt;= i + (seqlen_k - seqlen_q)</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0 &lt;= 0 - 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0 &lt;= 1 - 3 (<code>False</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0 &lt;= 2 - 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0 &lt;= 3 - 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0 &lt;= 4 - 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1 &lt;= 0 - 3 (<code>False</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1 &lt;= 1 - 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1 &lt;= 2 - 3 (<code>False</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1 &lt;= 3 - 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1 &lt;= 4 - 3 (<code>True</code>)</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Understanding <code>flash_attn_varlen_func</code> is going to require a sequence (pun intended) of such deep dives. It took me hours to just get through the docstring!! I’m also working on understanding ModernBERT’s sequence packing implementation (to the point of explaining it with visuals) and I expect it to interweave with my Flash Attention study, especially when understanding how ModernBERT prepares and packs sequences and related artifacts in preparation of passing it through the attention mechanism, utilizing <code>flash_attn_varlen_func</code>. It’s an exciting one-two punch for sure! I’m glad I’m working on them together.</p>
<p>I’ll end with listing out again what I’ve learned in this notebook/exercise, with a couple points added about the causal mask:</p>
<ul>
<li>HuggingFace’s <code>model.generate</code> uses KV cache by default (<code>DynamicCache</code>) stored as <code>past_key_values</code>.</li>
<li>For most scenarios, the <code>DynamicCache</code> is updated by concatenating the previous token’s <code>key_cache</code> and <code>value_cache</code> with the <code>key_states</code> and <code>value_states</code> generated for the current new token.</li>
<li>As the next token is generated for a given prompt, <code>query_states</code> has a sequence length of <code>1</code>, whereas <code>key_cache</code> and <code>value_cache</code> tensors’ sequence dimension increases by 1. This is directly relates to the <code>flash_attn_varlen_func</code> causal mask docstring example.</li>
<li><code>model.generate</code> utilized the <code>flash_attn_func</code> interface.</li>
<li>The causal mask is aligned to the bottom-right of the attention matrix (the last tokens of the Q and K sequence are aligned).</li>
<li>Causality, when <img src="https://latex.codecogs.com/png.latex?Q_i"> and <img src="https://latex.codecogs.com/png.latex?K_j"> sequences are of different length, is satisfied by the equation <code>j &lt;= i + (seqlen_k - seqlen_q)</code>.</li>
<li>When there are more query tokens than key tokens, the “offset” (needed to align the last token of each sequence) results in 0s in the mask as there are no key tokens to “look back at”.</li>
<li>When there are more key tokens than query tokens, the “offset” results in 1s as the query tokens can look back at more key tokens.</li>
</ul>
<p>I’m trying to grow my YouTube channel this year so if you enjoyed this blog post, <a href="https://www.youtube.com/@vishal_learner">please subscribe!</a></p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>Flash Attention</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-03-flash_attn_varlen_func-casual-mask/</guid>
  <pubDate>Tue, 03 Jun 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Initial Experiments with Imagenette</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/</link>
  <description><![CDATA[ 




<div id="cell-1" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fastai.vision.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">all</span> <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fastai.callback.wandb <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> WandbCallback</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> wandb</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb1-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post I’m going to share my initial experiments as I try to get on the <a href="https://github.com/fastai/imagenette">imagenette leaderboard</a>.</p>
<blockquote class="blockquote">
<p>Imagenette is a subset of 10 easily classified classes from Imagenet (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute).</p>
</blockquote>
<p>This exercise is a bit of a detour but related to my <a href="https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/">TinyScaleLab project</a> in which I’m trying to analyze the relationship between downstream capabilities and training dynamics for tiny language models (5M-125M) trained on the TinyStories dataset.</p>
<p>I was running some initial rough 1 epoch training runs with my 5M architecture to find the best batch size for training efficiency (memory usage and training speed). I encountered a peculiar result which was counterintuitive to me:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: left;">Metric</th>
<th style="text-align: left;">bs=64</th>
<th style="text-align: left;">256</th>
<th style="text-align: left;">1024</th>
<th style="text-align: left;">2048</th>
<th style="text-align: left;">4096</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Time</td>
<td style="text-align: left;">3hr</td>
<td style="text-align: left;">1hr</td>
<td style="text-align: left;">0.5hr</td>
<td style="text-align: left;">0.5hr</td>
<td style="text-align: left;">OOM</td>
</tr>
<tr class="even">
<td style="text-align: left;">Train loss</td>
<td style="text-align: left;">3.58</td>
<td style="text-align: left;">3.46</td>
<td style="text-align: left;">4.42</td>
<td style="text-align: left;">5.57</td>
<td style="text-align: left;">OOM</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Eval loss</td>
<td style="text-align: left;">3.58</td>
<td style="text-align: left;">3.46</td>
<td style="text-align: left;">4.43</td>
<td style="text-align: left;">5.57</td>
<td style="text-align: left;">OOM</td>
</tr>
</tbody>
</table>
<p>I was expecting that increase the batch size would:</p>
<ol type="1">
<li>speed up training</li>
<li>decrease loss</li>
</ol>
<p>However, increasing batch size from 1024 to 2048 did not speed up training, and increasing batch size from 256 to 2048 did not improve the loss. As always, when I run into something unexpected, I post it on Twitter. I received a number of insightful comments:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
We covered this in some of our earlier courses - lower batch sizes provide more updates, which should give better results for a fixed # epochs.
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1927192030335132090?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>The batch size of 256 was certainly providing more updates in one epoch than a batch size of 1024 or 2048. It’s interesting to note that a batch size of 64, even though providing 4x the number of updates as 256, had a higher loss at the end of the epoch. It’s important to note that I did not measure downstream performance for this experiment.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
TinyStories is a pretty homogeneous dataset, so one doesn't need as large of a batch size to achieve a smooth gradient compared to a more diverse pretraining dataset.<br><br>You'll want to set the batch size balancing speed and performance.
</p>
— Benjamin Warner (<span class="citation" data-cites="benjamin_warner">@benjamin_warner</span>) <a href="https://twitter.com/benjamin_warner/status/1927194448389169190?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This was another interesting point. The benefit of increasing batch size is to get a closer representation to the overall dataset. Since the TinyStories dataset is quite homogenous (all dataset items are children’s stories) a smaller batch size will be sufficiently representative of the full dataset. On the flip side, if we have a dataset like the PETS dataset, and used a small batch size of say 32, we could imagine a scenario where the batch only includes images of a single class. The model, which has been learning about a diverse set of animals to this point will perform poorly and the loss will spike. Larger models, having more parameters, may not recover from this spike like small models can. Furthermore, if the dataset contains mislabeled images and you are unfortunate to get a batch of incorrectly labeled cats, your loss spike will be combined with the model learning incorrect information. These were points discussed in a fastai study group!</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Also, one heuristic that people use is that in most scenarios, you can scale the lr proportionally to the bs.<br><br>Larger bs, better but less frequent updates, can take longer steps.<br><br>Smaller bs, more frequent updates, but need to take smaller steps due to worse direction of updates.
</p>
— Radek Osmulski 🇺🇦 (<span class="citation" data-cites="radekosmulski">@radekosmulski</span>) <a href="https://twitter.com/radekosmulski/status/1927195672056340620?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>In my case, I had used the same learning rate for all batch sizes, and did not utilize the benefit of larger batch sizes taking longer steps (higher learning rate).</p>
<p>Jeremy also encouraged me to do some imagenette speedruns, which is why we’re here!</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
You should maybe try doing some imagenette speed-running – it's a good way to get an intuitive understanding of these issues.
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1927216989837185133?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</section>
<section id="approach-and-results" class="level2">
<h2 class="anchored" data-anchor-id="approach-and-results">Approach and Results</h2>
<p>My data prep and training code can be viewed in the “appendix” below. Before I did this exercise, I ran the code in the <a href="https://docs.fast.ai/tutorial.imagenette.html">fastai “Training Imagenette” tutorial</a> which is where most of the code below comes from. I’ll share my approach and results in this section. I wanted to break this exercise (of trying to get onto the Imagenette leaderboard) into smaller steps, so I focused this notebook on training with a batch size of 64, for three learning rates (1e-4, 1e-3 and 1e-2) for three models: xse_resnext50 (25.6M), xresnet34 (21.3M), xresnet18 (11.2M).</p>
<section id="accuracy-curves" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-curves">Accuracy Curves</h3>
<p>Since I’m most interested in competing on the leaderboard, I’ll focus on observing the accuracy curves of these models, all trained on 5 epochs of the same training/validation split.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Accuracy curves for all 10 training runs"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/1.png" class="img-fluid figure-img" alt="Accuracy curves for all 10 training runs"></a></p>
<figcaption>Accuracy curves for all 10 training runs</figcaption>
</figure>
</div>
<p>The models/learning rate combination with the highest accuracy is xresnet34/1e-2 and xse_resnext50/1e-2. xresnet18/1e-2 is surprisingly competitive at half the parameter count. There is a clear hierarchy of learning rates, 1e-2 performs the best for all three models, followed by 1e-3 and then 1e-4. I used <code>lr_find</code> for each model and found that xresnet18 was stable for 1e-1 though it performs second-to-last place in accuracy for that model.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Model/Learning Rate</th>
<th style="text-align: center;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">xresnet34/1e-2</td>
<td style="text-align: center;">0.7929</td>
</tr>
<tr class="even">
<td style="text-align: center;">xse_resnext50/1e-2</td>
<td style="text-align: center;">0.7926</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet18/1e-2</td>
<td style="text-align: center;">0.7870</td>
</tr>
<tr class="even">
<td style="text-align: center;">xresnet34/1e-3</td>
<td style="text-align: center;">0.7776</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet18/1e-3</td>
<td style="text-align: center;">0.7743</td>
</tr>
<tr class="even">
<td style="text-align: center;">xse_resnext50/1e-3</td>
<td style="text-align: center;">0.7526</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet18/1e-1</td>
<td style="text-align: center;">0.7373</td>
</tr>
<tr class="even">
<td style="text-align: center;">xse_resnext50/1e-4</td>
<td style="text-align: center;">0.6532</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet34/1e-4</td>
<td style="text-align: center;">0.6446</td>
</tr>
<tr class="even">
<td style="text-align: center;">xresnet18/1e-4</td>
<td style="text-align: center;">0.6171</td>
</tr>
</tbody>
</table>
<p>Other notable observations:</p>
<ul>
<li>xse_resnext50/1e-2 starts out with the lowest accuracy, but then quickly catches up and finally beats out all other models/LRs but one.</li>
<li>xresnet18/1e-1 accuracy decreases from epoch 1 to 2, then catches up to finish in 7th place.</li>
<li>xresnet34/1e-2 accuracy increasing at slower rate from epoch 1 to 2 than from epoch 2 to 3, catching up quickly to finish in the top spot.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Notable accuracy curves"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/2.png" class="img-fluid figure-img" alt="Notable accuracy curves"></a></p>
<figcaption>Notable accuracy curves</figcaption>
</figure>
</div>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>I want to focus on a couple of thoughts Jeremy shared:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Maybe on the way you'll want to create some tables like you're making there, but I rarely find them as interesting as small targeted iterations changing one thing at a time.
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1927241575765061916?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Last year I worked through Jeremy’s <a href="https://vishalbakshi.github.io/blog/#category=paddy%20doctor">Kaggle Paddy Docter competition live coding series</a> and learned a ton about just that—small targeted iterations changing one thing at a time.</p>
<p>I’m not quite sure what my plan will be for this Imagenette leaderboard exercise, but I since I started this exploration with the intent to build intuition about batch size/learning rate and downstream performance, it makes sense to pick my best 2-3 models and vary the batch size and learning rate next.</p>
<p>I also am keen on working with Benjamin Warner’s <a href="https://fastxtend.benjaminwarner.dev/callback.progresize.html">fastxtend</a> (which I used last year in the <a href="https://www.kaggle.com/code/vishalbakshi/birdclef-2024-recap-0-61-final-lb-score">BirdCLEF24 Kaggle competition</a> to finish in the top 34%) and <a href="https://optimi.benjaminwarner.dev/">optimi</a> libraries. I’m particularly keen on trying out the different data augmentation techniques provided in fastxtend when I train for longer than 5 epochs.</p>
<p>I’m trying to grow my YouTube channel, so if you like my content, <a href="https://www.youtube.com/@vishal_learner">please subscribe</a>!</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<section id="data-prep" class="level3">
<h3 class="anchored" data-anchor-id="data-prep">Data Prep</h3>
<div id="cell-30" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:37}}" data-outputid="4a1c7bd1-fb16-4c4f-8308-939fe9e2b7c4" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> untar_data(URLs.IMAGENETTE_160)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="99008512" class="" max="99003388" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.01% [99008512/99003388 00:03&lt;00:00]
    </div>
    
</div>
</div>
<div id="cell-31" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">lbl_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>(</span>
<span id="cb3-2">    n01440764<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'tench'</span>,</span>
<span id="cb3-3">    n02102040<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'English springer'</span>,</span>
<span id="cb3-4">    n02979186<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'cassette player'</span>,</span>
<span id="cb3-5">    n03000684<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'chain saw'</span>,</span>
<span id="cb3-6">    n03028079<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'church'</span>,</span>
<span id="cb3-7">    n03394916<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'French horn'</span>,</span>
<span id="cb3-8">    n03417042<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'garbage truck'</span>,</span>
<span id="cb3-9">    n03425413<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'gas pump'</span>,</span>
<span id="cb3-10">    n03445777<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'golf ball'</span>,</span>
<span id="cb3-11">    n03888257<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'parachute'</span></span>
<span id="cb3-12">)</span></code></pre></div>
</div>
<div id="cell-32" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:752}}" data-outputid="73776257-bc3e-4c33-d6cc-ca691b73662c" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">imagenette <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> DataBlock(blocks <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (ImageBlock, CategoryBlock),</span>
<span id="cb4-2">                       get_items <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_image_files,</span>
<span id="cb4-3">                       get_y <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Pipeline([parent_label, lbl_dict.<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">__getitem__</span>]),</span>
<span id="cb4-4">                       splitter <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> GrandparentSplitter(valid_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'val'</span>),</span>
<span id="cb4-5">                       item_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RandomResizedCrop(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">128</span>, min_scale<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.35</span>),</span>
<span id="cb4-6">                       batch_tfms <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Normalize.from_stats(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>imagenet_stats))</span>
<span id="cb4-7"></span>
<span id="cb4-8">dls <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> imagenette.dataloaders(path, bs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>)</span>
<span id="cb4-9">dls.show_batch()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="training-code" class="level3">
<h3 class="anchored" data-anchor-id="training-code">Training Code</h3>
<p>I chose to run everything on a Colab Pro A100 GPU to maximize speed.</p>
<section id="xse_resnext50" class="level4">
<h4 class="anchored" data-anchor-id="xse_resnext50">xse_resnext50</h4>
<div id="cell-36" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:471}}" data-outputid="8338b75d-2a6c-41ec-c54b-dae12a88bc63" data-execution_count="7">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb5-2">learn.lr_find()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>SuggestedLRs(valley=0.0004786300996784121)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index_files/figure-html/cell-6-output-4.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="cell-37" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="542d3515-ed60-4e15-dfd7-73fab5fe583d" data-execution_count="14">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">wandb.login()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>True</code></pre>
</div>
</div>
<div id="cell-38" class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">wandb.init(</span>
<span id="cb9-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb9-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xse_resnext50-bs-64-lr-1e-4"</span>,</span>
<span id="cb9-4">)</span></code></pre></div>
</div>
<div id="cell-39" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="f05260cd-91b1-42a4-8b82-a0465f190a53" data-execution_count="16">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb10-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>2.437292</td>
<td>1.562259</td>
<td>0.498599</td>
<td>00:15</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.898073</td>
<td>1.330338</td>
<td>0.581401</td>
<td>00:15</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1.625788</td>
<td>1.184957</td>
<td>0.630828</td>
<td>00:15</td>
</tr>
<tr class="even">
<td>3</td>
<td>1.491183</td>
<td>1.138762</td>
<td>0.650446</td>
<td>00:15</td>
</tr>
<tr class="odd">
<td>4</td>
<td>1.425214</td>
<td>1.119943</td>
<td>0.653248</td>
<td>00:15</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-40" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">wandb.finish()</span></code></pre></div>
</div>
<div id="cell-41" class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">wandb.init(</span>
<span id="cb12-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb12-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xse_resnext50-bs-64-lr-1e-3"</span>,</span>
<span id="cb12-4">)</span></code></pre></div>
</div>
<div id="cell-42" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="0356a936-1d9c-40ca-9d7e-b645c0c3a3c7" data-execution_count="19">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb13-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>2.115490</td>
<td>1.610692</td>
<td>0.511592</td>
<td>00:15</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.563322</td>
<td>1.359540</td>
<td>0.592866</td>
<td>00:15</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1.205948</td>
<td>1.041064</td>
<td>0.673631</td>
<td>00:15</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.988717</td>
<td>0.896793</td>
<td>0.712611</td>
<td>00:15</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.865071</td>
<td>0.776657</td>
<td>0.752611</td>
<td>00:15</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-43" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">wandb.finish()</span></code></pre></div>
</div>
<div id="cell-44" class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">wandb.init(</span>
<span id="cb15-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb15-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xse_resnext50-bs-64-lr-1e-2"</span>,</span>
<span id="cb15-4">)</span></code></pre></div>
</div>
<div id="cell-45" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="b97a464f-d64e-4797-8814-2034c9d3013d" data-execution_count="23">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb16-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>2.025805</td>
<td>4.565277</td>
<td>0.225478</td>
<td>00:15</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.586654</td>
<td>1.567472</td>
<td>0.527389</td>
<td>00:15</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1.162438</td>
<td>0.994889</td>
<td>0.680255</td>
<td>00:15</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.868640</td>
<td>0.672154</td>
<td>0.780892</td>
<td>00:15</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.703673</td>
<td>0.635068</td>
<td>0.792611</td>
<td>00:15</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-46" class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">wandb.finish()</span></code></pre></div>
</div>
</section>
<section id="xresnet34" class="level4">
<h4 class="anchored" data-anchor-id="xresnet34">xresnet34</h4>
<div id="cell-48" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:471}}" data-outputid="1ca7b389-6205-4651-af2b-35c00be9e633" data-execution_count="27">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy)</span>
<span id="cb18-2">learn.lr_find()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>SuggestedLRs(valley=0.0005754399462603033)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-17-output-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index_files/figure-html/cell-17-output-4.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="cell-49" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="db64c191-eac3-4e90-8146-0ea19c8691a1" data-execution_count="28">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">learn.loss_func</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>FlattenedLoss of CrossEntropyLoss()</code></pre>
</div>
</div>
<div id="cell-50" class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">wandb.init(</span>
<span id="cb22-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb22-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xresnet34-bs-64-lr-1e-4"</span>,</span>
<span id="cb22-4">)</span></code></pre></div>
</div>
<div id="cell-51" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="5ff0c3d6-f0e0-4501-c244-eb567e579c59" data-execution_count="35">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb23-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>2.054720</td>
<td>1.864616</td>
<td>0.371975</td>
<td>00:09</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.605212</td>
<td>1.489624</td>
<td>0.525350</td>
<td>00:09</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1.307533</td>
<td>1.235453</td>
<td>0.619618</td>
<td>00:09</td>
</tr>
<tr class="even">
<td>3</td>
<td>1.180410</td>
<td>1.153767</td>
<td>0.642038</td>
<td>00:09</td>
</tr>
<tr class="odd">
<td>4</td>
<td>1.124177</td>
<td>1.139668</td>
<td>0.644586</td>
<td>00:09</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-52" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">wandb.finish()</span></code></pre></div>
</div>
<div id="cell-53" class="cell">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">wandb.init(</span>
<span id="cb25-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb25-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xresnet34-bs-64-lr-1e-3"</span>,</span>
<span id="cb25-4">)</span></code></pre></div>
</div>
<div id="cell-54" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="307e87f9-20f2-419b-beda-9f1f32a62a2c" data-execution_count="39">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb26-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.607826</td>
<td>1.416133</td>
<td>0.538344</td>
<td>00:10</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.204550</td>
<td>1.263326</td>
<td>0.578853</td>
<td>00:09</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.946661</td>
<td>0.917620</td>
<td>0.710828</td>
<td>00:09</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.784756</td>
<td>0.758046</td>
<td>0.755414</td>
<td>00:09</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.683072</td>
<td>0.704371</td>
<td>0.777580</td>
<td>00:09</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-55" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">wandb.finish()</span></code></pre></div>
</div>
<div id="cell-56" class="cell">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">wandb.init(</span>
<span id="cb28-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb28-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xresnet34-bs-64-lr-1e-2"</span>,</span>
<span id="cb28-4">)</span></code></pre></div>
</div>
<div id="cell-57" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="435b8593-bec7-427e-d136-a51a327efc95" data-execution_count="43">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb29-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.571024</td>
<td>2.439970</td>
<td>0.335541</td>
<td>00:09</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.255883</td>
<td>2.097694</td>
<td>0.395414</td>
<td>00:09</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1.018229</td>
<td>0.989576</td>
<td>0.681529</td>
<td>00:09</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.785577</td>
<td>0.728265</td>
<td>0.762293</td>
<td>00:09</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.623264</td>
<td>0.640818</td>
<td>0.792866</td>
<td>00:09</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-58" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">wandb.finish()</span></code></pre></div>
</div>
</section>
<section id="xresnet18" class="level4">
<h4 class="anchored" data-anchor-id="xresnet18">xresnet18</h4>
<div id="cell-60" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:471}}" data-outputid="3bb76188-48c5-47dd-ad6d-3d66a04be44f" data-execution_count="46">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy)</span>
<span id="cb31-2">learn.lr_find()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>SuggestedLRs(valley=0.0020892962347716093)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-28-output-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index_files/figure-html/cell-28-output-4.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div id="cell-61" class="cell">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">wandb.init(</span>
<span id="cb33-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb33-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xresnet18-bs-64-lr-1e-4"</span>,</span>
<span id="cb33-4">)</span></code></pre></div>
</div>
<div id="cell-62" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="c6dbf534-bb10-48ef-cb77-0eb7b8597ac1" data-execution_count="48">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb34-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>5.608559</td>
<td>4.292247</td>
<td>0.301147</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>1</td>
<td>2.270526</td>
<td>1.728192</td>
<td>0.505478</td>
<td>00:07</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1.517185</td>
<td>1.401804</td>
<td>0.579108</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>3</td>
<td>1.327132</td>
<td>1.287121</td>
<td>0.610446</td>
<td>00:07</td>
</tr>
<tr class="odd">
<td>4</td>
<td>1.274527</td>
<td>1.265958</td>
<td>0.617070</td>
<td>00:07</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-63" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">wandb.finish()</span></code></pre></div>
</div>
<div id="cell-64" class="cell">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">wandb.init(</span>
<span id="cb36-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb36-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xresnet18-bs-64-lr-1e-3"</span>,</span>
<span id="cb36-4">)</span></code></pre></div>
</div>
<div id="cell-65" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="170bf98b-8634-4d14-88fb-e1422e043217" data-execution_count="52">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb37-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>2.134495</td>
<td>1.742504</td>
<td>0.445860</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.249879</td>
<td>1.266531</td>
<td>0.584204</td>
<td>00:07</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.986120</td>
<td>1.082811</td>
<td>0.648153</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.804976</td>
<td>0.767623</td>
<td>0.758471</td>
<td>00:07</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.708721</td>
<td>0.734305</td>
<td>0.774267</td>
<td>00:07</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-66" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">wandb.finish()</span></code></pre></div>
</div>
<div id="cell-67" class="cell">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">wandb.init(</span>
<span id="cb39-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb39-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xresnet18-bs-64-lr-1e-2"</span>,</span>
<span id="cb39-4">)</span></code></pre></div>
</div>
<div id="cell-68" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="43fb4098-6228-4d0e-f708-d395b7324de1" data-execution_count="56">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb40-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.665481</td>
<td>2.706135</td>
<td>0.358726</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.278437</td>
<td>1.516189</td>
<td>0.505987</td>
<td>00:07</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1.017887</td>
<td>1.038873</td>
<td>0.663440</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.801989</td>
<td>0.718528</td>
<td>0.761529</td>
<td>00:07</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.638737</td>
<td>0.650084</td>
<td>0.787006</td>
<td>00:07</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-69" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">wandb.finish()</span></code></pre></div>
</div>
<div id="cell-70" class="cell">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">wandb.init(</span>
<span id="cb42-2">    project<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tinyscale-lab"</span>,</span>
<span id="cb42-3">    name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"imagenette-xresnet18-bs-64-lr-1e-1"</span>,</span>
<span id="cb42-4">)</span></code></pre></div>
</div>
<div id="cell-71" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:206}}" data-outputid="f9e04227-875a-40b7-8fe7-f4790ac3bc32" data-execution_count="61">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">learn <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>WandbCallback())</span>
<span id="cb43-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.755140</td>
<td>2.272295</td>
<td>0.325860</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>1</td>
<td>1.501531</td>
<td>3.738475</td>
<td>0.322293</td>
<td>00:07</td>
</tr>
<tr class="odd">
<td>2</td>
<td>1.238407</td>
<td>1.375671</td>
<td>0.547516</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>3</td>
<td>1.036412</td>
<td>0.896265</td>
<td>0.707516</td>
<td>00:07</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.850425</td>
<td>0.815597</td>
<td>0.737325</td>
<td>00:07</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-72" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">wandb.finish()</span></code></pre></div>
</div>


</section>
</section>
</section>

 ]]></description>
  <category>python</category>
  <category>fastai</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <category>imagenette</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/</guid>
  <pubDate>Sun, 01 Jun 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Understanding the Mean Shift Clustering Algorithm (and PyTorch Broadcasting)</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/</link>
  <description><![CDATA[ 




<div id="cell-1" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> math, matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt, operator, torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> functools <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> partial</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch.distributions.multivariate_normal <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MultivariateNormal</span>
<span id="cb1-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor</span></code></pre></div>
</div>
<div id="cell-2" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">42</span>)</span>
<span id="cb2-2">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post I’ll walk through the Mean Shift Clustering algorithm as introduced <a href="https://github.com/fastai/course22p2/blob/master/nbs/02_meanshift.ipynb">in Lesson 12 of the fastai course (Part 2)</a>.</p>
<p>The algorithm:</p>
<blockquote class="blockquote">
<ul>
<li>For each data point <code>x</code> in the sample <code>X</code>, find the distance between that point <code>x</code> and every other point in <code>X</code></li>
<li>Create weights for each point in <code>X</code> by using the Gaussian kernel of that point’s distance to <code>x</code></li>
<li>This weighting approach penalizes points further away from <code>x</code></li>
<li>The rate at which the weights fall to zero is determined by the bandwidth, which is the standard deviation of the Gaussian</li>
<li>Update <code>x</code> as the weighted average of all other points in <code>X</code>, weighted based on the previous step</li>
</ul>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Conceptual visual showing the mean shift clustering algorithm weighting by distance. The red point is x."><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/1.png" class="img-fluid figure-img" alt="Conceptual visual showing the mean shift clustering algorithm weighting by distance. The red point is x."></a></p>
<figcaption>Conceptual visual showing the mean shift clustering algorithm weighting by distance. The red point is <code>x</code>.</figcaption>
</figure>
</div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/kfl-cUz9iWw?si=nL8PUaUBmqQcYJMk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="generating-clearly-clustered-data" class="level2">
<h2 class="anchored" data-anchor-id="generating-clearly-clustered-data">Generating Clearly Clustered Data</h2>
<p>An important point: we start by creating fake data such that it is knowingly clustered around a set of centroids we can then compare to the final clustering result.</p>
<div id="cell-9" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">n_clusters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span></span>
<span id="cb3-2">n_samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">250</span></span></code></pre></div>
</div>
<div id="cell-10" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.rand(n_clusters, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">70</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35</span></span></code></pre></div>
</div>
<div id="cell-11" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f832bd33-2d31-4058-a7e6-9139a6b3acef" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">centroids.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>torch.Size([6, 2])</code></pre>
</div>
</div>
<div id="cell-12" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="98fe6cdb-34d3-4a22-bb3a-f6f5e2b5019e" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">centroids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[ 26.759,  29.050],
        [ -8.200,  32.151],
        [ -7.669,   7.063],
        [-17.040,  20.555],
        [ 30.854, -25.677],
        [ 30.422,   6.551]])</code></pre>
</div>
</div>
<p>We’ll generate data around these 6 centroids using PyTorch’s <code>MultivariateNormal</code> which:</p>
<blockquote class="blockquote">
<p>Creates a multivariate normal (also called Gaussian) distribution parameterized by a mean vector and a covariance matrix.</p>
</blockquote>
<p>The covariance matrix in our case is a diagonal matrix with 5s on the diagonal.</p>
<p>We generate 250 samples for each mean vector (centroid).</p>
<div id="cell-15" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> sample(m): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> MultivariateNormal(m, torch.diag(tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.</span>]))).sample((n_samples,))</span></code></pre></div>
</div>
<div id="cell-16" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="5684ae06-811e-4a0e-ec3e-f5e9830a41ed" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">torch.diag(tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor([[5., 0.],
        [0., 5.]])</code></pre>
</div>
</div>
<p>From Gemini this covariance matrix shows:</p>
<blockquote class="blockquote">
<ul>
<li><strong>No Correlation</strong>: The two variables are uncorrelated (covariance is 0.0). For a <code>MultivariateNormal</code> distribution, this implies they are independent.</li>
<li><strong>Equal Variance</strong>: Both variables have the same variance of 5.0.</li>
<li><strong>Shape</strong>: If used in a 2D MultivariateNormal distribution, this will produce a circular cloud of data points, equally spread along both the X and Y axes.</li>
</ul>
</blockquote>
<div id="cell-18" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="93047335-d41d-4def-a752-5e331b1e26b4" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">coords <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> MultivariateNormal(centroids[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], torch.diag(tensor([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.</span>,<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.</span>]))).sample((n_samples,))</span>
<span id="cb12-2">coords.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>torch.Size([250, 2])</code></pre>
</div>
</div>
<p>We see how the <code>MultivariateNormal</code> distribution samples are spread out in a circular shape around the mean, with the density of samples decreasing as you move further away from the centroid.</p>
<div id="cell-20" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:430}}" data-outputid="440bb3e9-4b5c-4e69-9934-4ca1a298a0be" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">plt.scatter(coords[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], coords[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.7</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb14-2">plt.scatter(centroids[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], centroids[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'red'</span>, s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb14-3">ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.gca() <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get current axes</span></span>
<span id="cb14-4">ax.set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, adjustable<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We sample from the <code>MultivariateNormal</code> distribution for all six of our centroids and concatenate the result.</p>
<div id="cell-22" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1889ba4c-48d1-46cb-dfe4-7674b1cc04a5" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">slices <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [sample(c) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> c <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> centroids]</span>
<span id="cb15-2">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.cat(slices)</span>
<span id="cb15-3">data.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div id="cell-23" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> plot_data(centroids, data, n_samples, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>):</span>
<span id="cb17-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> ax <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>: _,ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots()</span>
<span id="cb17-3">    ax.set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, adjustable<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>)</span>
<span id="cb17-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, centroid <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(centroids):</span>
<span id="cb17-5">        samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_samples:(i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_samples]</span>
<span id="cb17-6">        ax.scatter(samples[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], samples[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb17-7">        ax.plot(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>centroid, markersize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x"</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>, mew<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span></code></pre></div>
</div>
<div id="cell-24" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:430}}" data-outputid="8b2d7253-df04-4a27-8d32-c8b6ff94647d" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">plot_data(centroids, data, n_samples)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-14-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="generating-sample-weights" class="level2">
<h2 class="anchored" data-anchor-id="generating-sample-weights">Generating Sample Weights</h2>
<p>With our data generated, we’ll now prepare for the third step in the algorithm: <em>create weights</em>.</p>
<blockquote class="blockquote">
<p>Create weights for each point in X by using the Gaussian kernel of that point’s distance to x</p>
</blockquote>
<p>We’ll start by defining a function which takes some distance <code>d</code> and some bandwidth <code>bw</code> and returns the gaussian normal output given these two inputs. This output will be our <em>weights</em>:</p>
<div id="cell-28" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> gaussian(d, bw): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.exp(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>((d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>bw))<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> (bw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>math.sqrt(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>math.pi))</span></code></pre></div>
</div>
<p>(Wikipedia) the probability density function of the normal distribution is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?f(x)=%7B%5Cfrac%20%7B1%7D%7B%5Csqrt%20%7B2%5Cpi%20%5Csigma%20%5E%7B2%7D%7D%7D%7De%5E%7B-%7B%5Cfrac%20%7B(x-%5Cmu%20)%5E%7B2%7D%7D%7B2%5Csigma%20%5E%7B2%7D%7D%7D%7D"></p>
<p>In our case, <code>d</code> (the distance from a point in X to another point in X) is equivalent in this function to <img src="https://latex.codecogs.com/png.latex?x-%5Cmu">, and bandwidth <code>bw</code> is the standard deviation <img src="https://latex.codecogs.com/png.latex?%5Csigma">.</p>
<p>As bandwidth increases, the gaussian distribution flattens out (i.e.&nbsp;weights decay slower as distance increases).</p>
<div id="cell-33" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:430}}" data-outputid="e1629736-ae5f-4857-afff-f8340d8019b6" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb20-2">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.0</span>), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bw = 1.0'</span>)</span>
<span id="cb20-3">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bw = 2.5'</span>)</span>
<span id="cb20-4">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">5.0</span>), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bw = 5.0'</span>)</span>
<span id="cb20-5">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">10.0</span>), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'bw = 10.0'</span>)</span>
<span id="cb20-6">plt.legend()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-16-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We can also try to use a simpler linear function for our weights.</p>
<div id="cell-35" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> tri(d, i): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>d<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>i).clamp_min(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>i</span></code></pre></div>
</div>
<p>Mathematically, this calculates <code>max(0, (i - d) / i)</code> which is equivalent to <code>max(0, 1 - d / i)</code></p>
<p><code>clamp_min</code> ensures that the value of <code>-d+i</code> does not go below <code>0</code>. <code>i</code> becomes the d-intercept.</p>
<p>As <code>i</code> increases, the slope decreases, and weights decay slower as distance increases.</p>
<div id="cell-39" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:430}}" data-outputid="be09317b-d3b8-4bb4-936b-f9f9f8193618" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)</span>
<span id="cb22-2">plt.plot(x, tri(x,i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'i = 3'</span>)</span>
<span id="cb22-3">plt.plot(x, tri(x,i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'i = 8'</span>)</span>
<span id="cb22-4">plt.plot(x, tri(x,i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>), label<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'i = 12'</span>)</span>
<span id="cb22-5">plt.legend()<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-18-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="implementing-the-full-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="implementing-the-full-algorithm">Implementing the Full Algorithm</h2>
<blockquote class="blockquote">
<ul>
<li>For each data point x in the sample X, find the distance between that point x and every other point in X (<code>d = f(x-X)</code>)</li>
<li>Create weights for each point in X by using the Gaussian kernel of that point’s distance to x (<code>weights = gaussian(d)</code>)</li>
<li>Update x as the weighted average of all other points in X, weighted based on the previous step (<code>x = weighted_avg(weights, X)</code>)</li>
</ul>
</blockquote>
<p>Since we are going to update the data after each step of the algorithm, we clone the data to start. As a reminder, these 1500 coordinates come from 250 <code>MultivariateNormal</code> samples given 6 centroids as the mean.</p>
<div id="cell-43" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e19a0afd-3b1f-4189-ea40-f73820d8e75c" data-execution_count="19">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.clone()</span>
<span id="cb23-2">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb23-3">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([29.764, 26.161])</code></pre>
</div>
</div>
<div id="cell-44" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c9005ded-deaa-4406-b70c-119c6584c3f1" data-execution_count="20">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">X.shape, x.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>(torch.Size([1500, 2]), torch.Size([2]))</code></pre>
</div>
</div>
<p>We now calculate <em>the distance between that point x and every other point in X</em>. Since <code>x</code> and <code>X</code> share a dimension <code>2</code>, we can just subtract and PyTorch will use broadcasting.</p>
<div id="cell-46" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b58458b1-4d24-4b3d-87c3-07828202e61b" data-execution_count="21">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div id="cell-47" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="568b564f-4973-4b77-b312-4b94f6a6fa1b" data-execution_count="22">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X)[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># subtracting the first point from itself</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([0., 0.])</code></pre>
</div>
</div>
<div id="cell-48" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="7f96405a-0d6b-4af5-ab8d-1bf57fc26b99" data-execution_count="23">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([29.764, 26.161])</code></pre>
</div>
</div>
<div id="cell-49" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e35d50a5-a69d-46f0-99b2-570902ac3787" data-execution_count="24">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">X[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([[29.764, 26.161],
        [28.472, 30.493],
        [27.549, 23.130],
        [23.500, 26.879],
        [27.327, 28.650]])</code></pre>
</div>
</div>
<div id="cell-50" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8afce871-6987-4f4d-a85b-5eb08f5d18fe" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X)[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([[ 0.000,  0.000],
        [ 1.292, -4.333],
        [ 2.215,  3.030],
        [ 6.264, -0.718],
        [ 2.437, -2.489]])</code></pre>
</div>
</div>
<p>We’ll use Euclidean distance, which is the square root of the sum (across the columns, or rather across coordinates) of the difference in coordinates squared.</p>
<div id="cell-52" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="16661ce5-493e-4029-9f13-ac9120032ec2" data-execution_count="26">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">((x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div id="cell-53" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="092208c5-a396-4f01-cb0e-c6be84342589" data-execution_count="27">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">((x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([[ 0.000,  0.000],
        [ 1.668, 18.772],
        [ 4.906,  9.184],
        [39.239,  0.515],
        [ 5.939,  6.196]])</code></pre>
</div>
</div>
<p>Summing across the columns to get <img src="https://latex.codecogs.com/png.latex?x%5E2+y%5E2">.</p>
<div id="cell-55" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="0919cf3c-5bb0-4e84-9bc4-53c71e956312" data-execution_count="29">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">((x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>torch.Size([1500])</code></pre>
</div>
</div>
<div id="cell-56" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="9e39b39a-6f71-4de2-d839-c6d380711aee" data-execution_count="30">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">((x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor([ 0.000, 20.440, 14.089, 39.754, 12.134])</code></pre>
</div>
</div>
<div id="cell-57" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="442c76ad-4328-4762-a9a0-32c30a8bd601" data-execution_count="31">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">dist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ((x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>).sqrt()</span>
<span id="cb45-2">dist.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>torch.Size([1500])</code></pre>
</div>
</div>
<div id="cell-58" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="433c5588-1779-4bcf-e4b5-21017d014186" data-execution_count="32">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">dist[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([0.000, 4.521, 3.754, 6.305, 3.483])</code></pre>
</div>
</div>
<p>Since we are performing elementwise multiplication following by a summation, we can use Einstein Summation:</p>
<div id="cell-60" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="554d97b7-31a8-45a3-b1d2-4ee4a8d2fb3f" data-execution_count="33">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">torch.einsum(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ij,ij-&gt;i'</span>, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X, x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X).sqrt()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor([ 0.000,  4.521,  3.754,  ..., 21.305, 21.850, 21.958])</code></pre>
</div>
</div>
<p>We can also use matrix multiplication, though IIUC, you have to pluck out the values on the resulting matrix’s diagonal to get the elementwise product between <code>x-X</code> and itself.</p>
<div id="cell-62" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ce689bc7-0002-472e-ab83-2f3e471a9dac" data-execution_count="34">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">(x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X).shape, (x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X).T.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>(torch.Size([1500, 2]), torch.Size([2, 1500]))</code></pre>
</div>
</div>
<div id="cell-63" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="424e1e07-8126-4325-b353-92c59a2375ca" data-execution_count="35">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span> (x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X).T</span>
<span id="cb53-2">res.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>torch.Size([1500, 1500])</code></pre>
</div>
</div>
<div id="cell-64" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3565fc9c-f460-4158-8f7e-8f0926b1cd85" data-execution_count="36">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">torch.diag(res)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor([  0.000,  20.440,  14.089,  ..., 453.898, 477.408, 482.169])</code></pre>
</div>
</div>
<div id="cell-65" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d964c841-d00e-4173-9a53-acdba5e6b33a" data-execution_count="37">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">torch.diag(res).sqrt()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([ 0.000,  4.521,  3.754,  ..., 21.305, 21.850, 21.958])</code></pre>
</div>
</div>
<p>We now <em>create weights for each point in X by using the Gaussian kernel of that point’s distance to x</em>.</p>
<div id="cell-67" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="75f33898-b162-4628-8098-56bc99e441b1" data-execution_count="38">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gaussian(dist, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>)</span>
<span id="cb59-2">weight</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([    0.160,     0.031,     0.052,  ...,     0.000,     0.000,     0.000])</code></pre>
</div>
</div>
<p>We have 1500 weights, one for each distance between our current point <code>x</code> and all of the points in <code>X</code>.</p>
<div id="cell-69" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="5b48ca56-ce3b-426b-dc41-a73ce4596e99" data-execution_count="39">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1">weight.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>torch.Size([1500])</code></pre>
</div>
</div>
<p>We can now move on to the last step in the algorithm: <em>update x as the weighted average of all other points in X, weighted based on the previous step</em>.</p>
<p>The weighted average is the elementwise product of the <code>weights</code> and <code>X</code>, summed down the rows (two get 2 coordinates) and then divided by the sum of the weights.</p>
<p>Starting from the last dimension, <code>weight</code> and <code>X</code> do not have compatible dimensions (1500 is not 2 or 1), so we have to add a unit axis to <code>weight</code> to allow for broadcasting.</p>
<div id="cell-73" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="3c055193-07d4-41b2-9c45-83a7b9c18ddc" data-execution_count="42">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div id="cell-74" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:141}}" data-outputid="e0b2b54d-21ea-4cee-a98f-0f6f9ba44500" data-execution_count="43">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1">weight<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X</span></code></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-43-f3a5e14a550a&gt;</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>weight<span class="ansi-blue-fg">*</span>X

<span class="ansi-red-fg">RuntimeError</span>: The size of tensor a (1500) must match the size of tensor b (2) at non-singleton dimension 1</pre>
</div>
</div>
</div>
<div id="cell-75" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="799bd54d-0612-4a9e-8f4b-adeb29264253" data-execution_count="44">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1">weight[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>torch.Size([1500, 1])</code></pre>
</div>
</div>
<div id="cell-76" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="81c78206-bb4d-4b3d-b05c-77e844403318" data-execution_count="46">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1">weight[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>tensor([[    4.750,     4.175],
        [    0.886,     0.948],
        [    1.424,     1.196],
        ...,
        [    0.000,     0.000],
        [    0.000,     0.000],
        [    0.000,     0.000]])</code></pre>
</div>
</div>
<p>We then sum down the rows to get two coordinates:</p>
<div id="cell-78" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="94a51182-983c-4f79-c54b-59577b97c8b5" data-execution_count="48">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1">(weight[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([296.880, 291.612])</code></pre>
</div>
</div>
<p>This is the same as applying the weights to each column separately:</p>
<div id="cell-80" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="cedc0ce9-89c7-4b77-98dc-be9e885f5cb2" data-execution_count="49">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1">(weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(), (weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> X[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>(tensor(296.880), tensor(291.612))</code></pre>
</div>
</div>
<p>We then divide by the sum of the weights to get our final, updated <code>x</code>:</p>
<div id="cell-82" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="26fcab42-b6a3-448a-b5b8-cf8c85c2f3a6" data-execution_count="50">
<div class="sourceCode cell-code" id="cb74" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1">(weight[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>weight.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>tensor([28.118, 27.619])</code></pre>
</div>
</div>
<p>Wrapping this up into a function for each <code>x</code> in <code>X</code> we calculate the distance between <code>x</code> and all points in <code>X</code>, calculate the weights for those distances and replace <code>x</code> with the weighted average of those weights and all the points.</p>
<div id="cell-84" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> one_update(X):</span>
<span id="cb76-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(X):</span>
<span id="cb76-3">        dist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sqrt(((x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb76-4">        weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gaussian(dist, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>)</span>
<span id="cb76-5">        X[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (weight[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>weight.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span></code></pre></div>
</div>
<div id="cell-85" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="72b4ced3-11b0-4477-e0de-28e7ec8b3e34" data-execution_count="52">
<div class="sourceCode cell-code" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.clone()</span>
<span id="cb77-2">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb77-3">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>tensor([29.764, 26.161])</code></pre>
</div>
</div>
<div id="cell-86" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb79" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1">one_update(X)</span></code></pre></div>
</div>
<div id="cell-87" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4dfc8da8-06c7-4400-a1da-5415bf4bbcaf" data-execution_count="55">
<div class="sourceCode cell-code" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1">X[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>tensor([28.118, 27.619])</code></pre>
</div>
</div>
<p>We can now wrap up into a <code>meanshift</code> function where it performs <code>n</code> such updates.</p>
<div id="cell-89" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb82" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> meanshift(data, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>):</span>
<span id="cb82-2">    X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.clone()</span>
<span id="cb82-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> it <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n): one_update(X)</span>
<span id="cb82-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> X</span></code></pre></div>
</div>
<div id="cell-90" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="120554f2-356c-4445-c260-6590aa44c457" data-execution_count="68">
<div class="sourceCode cell-code" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>time X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>meanshift(data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.39 s, sys: 3.12 ms, total: 1.4 s
Wall time: 1.42 s</code></pre>
</div>
</div>
<p>We can now see that in 5 iterations, the weight updates have resulted in the points to converge at the original centroids!</p>
<div id="cell-92" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb85" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> plot_data(centroids, data, n_samples, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>):</span>
<span id="cb85-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> ax <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">is</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>: _,ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots()</span>
<span id="cb85-3">    ax.set_aspect(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'equal'</span>, adjustable<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'box'</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add this line</span></span>
<span id="cb85-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, centroid <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(centroids):</span>
<span id="cb85-5">        samples <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data[i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_samples:(i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>n_samples]</span>
<span id="cb85-6">        ax.plot(<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>centroid, markersize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">8</span>, marker<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"x"</span>, color<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'k'</span>, mew<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.2</span>)</span>
<span id="cb85-7">        ax.scatter(samples[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>], samples[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>], s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span></code></pre></div>
</div>
<div id="cell-93" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:430}}" data-outputid="2143afe3-6582-445c-d40c-1bf41e2dce13" data-execution_count="70">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1">plot_data(centroids, X, n_samples)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-53-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-53-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="animating-the-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="animating-the-algorithm">Animating the Algorithm</h2>
<div id="cell-95" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> matplotlib.animation <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> FuncAnimation</span>
<span id="cb87-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> HTML</span></code></pre></div>
</div>
<div id="cell-96" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> do_one(d):</span>
<span id="cb88-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> d: one_update(X)</span>
<span id="cb88-3">    ax.clear()</span>
<span id="cb88-4">    plot_data(centroids, X, n_samples, ax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ax, alpha<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>d)</span></code></pre></div>
</div>
<p>We can visualize the “gravity” of the cluster centroids as the data points are “pulled in” via the weighted average.</p>
<div id="cell-98" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:578}}" data-outputid="57402cb2-2ebd-467a-ed23-a962aa25f28a" data-execution_count="73">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.clone()</span>
<span id="cb89-2">fig,ax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> plt.subplots()</span>
<span id="cb89-3">ani <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> FuncAnimation(fig, do_one, frames<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>, interval<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, repeat<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb89-4">plt.close()</span>
<span id="cb89-5">HTML(ani.to_jshtml())</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<script language="javascript">
  function isInternetExplorer() {
    ua = navigator.userAgent;
    /* MSIE used to detect old browsers and Trident used to newer ones*/
    return ua.indexOf("MSIE ") > -1 || ua.indexOf("Trident/") > -1;
  }

  /* Define the Animation class */
  function Animation(frames, img_id, slider_id, interval, loop_select_id){
    this.img_id = img_id;
    this.slider_id = slider_id;
    this.loop_select_id = loop_select_id;
    this.interval = interval;
    this.current_frame = 0;
    this.direction = 0;
    this.timer = null;
    this.frames = new Array(frames.length);

    for (var i=0; i<frames.length; i++)
    {
     this.frames[i] = new Image();
     this.frames[i].src = frames[i];
    }
    var slider = document.getElementById(this.slider_id);
    slider.max = this.frames.length - 1;
    if (isInternetExplorer()) {
        // switch from oninput to onchange because IE <= 11 does not conform
        // with W3C specification. It ignores oninput and onchange behaves
        // like oninput. In contrast, Microsoft Edge behaves correctly.
        slider.setAttribute('onchange', slider.getAttribute('oninput'));
        slider.setAttribute('oninput', null);
    }
    this.set_frame(this.current_frame);
  }

  Animation.prototype.get_loop_state = function(){
    var button_group = document[this.loop_select_id].state;
    for (var i = 0; i < button_group.length; i++) {
        var button = button_group[i];
        if (button.checked) {
            return button.value;
        }
    }
    return undefined;
  }

  Animation.prototype.set_frame = function(frame){
    this.current_frame = frame;
    document.getElementById(this.img_id).src =
            this.frames[this.current_frame].src;
    document.getElementById(this.slider_id).value = this.current_frame;
  }

  Animation.prototype.next_frame = function()
  {
    this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));
  }

  Animation.prototype.previous_frame = function()
  {
    this.set_frame(Math.max(0, this.current_frame - 1));
  }

  Animation.prototype.first_frame = function()
  {
    this.set_frame(0);
  }

  Animation.prototype.last_frame = function()
  {
    this.set_frame(this.frames.length - 1);
  }

  Animation.prototype.slower = function()
  {
    this.interval /= 0.7;
    if(this.direction > 0){this.play_animation();}
    else if(this.direction < 0){this.reverse_animation();}
  }

  Animation.prototype.faster = function()
  {
    this.interval *= 0.7;
    if(this.direction > 0){this.play_animation();}
    else if(this.direction < 0){this.reverse_animation();}
  }

  Animation.prototype.anim_step_forward = function()
  {
    this.current_frame += 1;
    if(this.current_frame < this.frames.length){
      this.set_frame(this.current_frame);
    }else{
      var loop_state = this.get_loop_state();
      if(loop_state == "loop"){
        this.first_frame();
      }else if(loop_state == "reflect"){
        this.last_frame();
        this.reverse_animation();
      }else{
        this.pause_animation();
        this.last_frame();
      }
    }
  }

  Animation.prototype.anim_step_reverse = function()
  {
    this.current_frame -= 1;
    if(this.current_frame >= 0){
      this.set_frame(this.current_frame);
    }else{
      var loop_state = this.get_loop_state();
      if(loop_state == "loop"){
        this.last_frame();
      }else if(loop_state == "reflect"){
        this.first_frame();
        this.play_animation();
      }else{
        this.pause_animation();
        this.first_frame();
      }
    }
  }

  Animation.prototype.pause_animation = function()
  {
    this.direction = 0;
    if (this.timer){
      clearInterval(this.timer);
      this.timer = null;
    }
  }

  Animation.prototype.play_animation = function()
  {
    this.pause_animation();
    this.direction = 1;
    var t = this;
    if (!this.timer) this.timer = setInterval(function() {
        t.anim_step_forward();
    }, this.interval);
  }

  Animation.prototype.reverse_animation = function()
  {
    this.pause_animation();
    this.direction = -1;
    var t = this;
    if (!this.timer) this.timer = setInterval(function() {
        t.anim_step_reverse();
    }, this.interval);
  }
</script>

<style>
.animation {
    display: inline-block;
    text-align: center;
}
input[type=range].anim-slider {
    width: 374px;
    margin-left: auto;
    margin-right: auto;
}
.anim-buttons {
    margin: 8px 0px;
}
.anim-buttons button {
    padding: 0;
    width: 36px;
}
.anim-state label {
    margin-right: 8px;
}
.anim-state input {
    margin: 0;
    vertical-align: middle;
}
</style>

<div class="animation">
  <img id="_anim_imgbf18fa8feeef42df9ff1917d1946c4bf">
  <div class="anim-controls">
    <input id="_anim_sliderbf18fa8feeef42df9ff1917d1946c4bf" type="range" class="anim-slider" name="points" min="0" max="1" step="1" value="0" oninput="animbf18fa8feeef42df9ff1917d1946c4bf.set_frame(parseInt(this.value));">
    <div class="anim-buttons">
      <button title="Decrease speed" aria-label="Decrease speed" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.slower()">
          <i class="fa fa-minus"></i></button>
      <button title="First frame" aria-label="First frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.first_frame()">
        <i class="fa fa-fast-backward"></i></button>
      <button title="Previous frame" aria-label="Previous frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.previous_frame()">
          <i class="fa fa-step-backward"></i></button>
      <button title="Play backwards" aria-label="Play backwards" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.reverse_animation()">
          <i class="fa fa-play fa-flip-horizontal"></i></button>
      <button title="Pause" aria-label="Pause" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.pause_animation()">
          <i class="fa fa-pause"></i></button>
      <button title="Play" aria-label="Play" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.play_animation()">
          <i class="fa fa-play"></i></button>
      <button title="Next frame" aria-label="Next frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.next_frame()">
          <i class="fa fa-step-forward"></i></button>
      <button title="Last frame" aria-label="Last frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.last_frame()">
          <i class="fa fa-fast-forward"></i></button>
      <button title="Increase speed" aria-label="Increase speed" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.faster()">
          <i class="fa fa-plus"></i></button>
    </div>
    <form title="Repetition mode" aria-label="Repetition mode" action="#n" name="_anim_loop_selectbf18fa8feeef42df9ff1917d1946c4bf" class="anim-state">
      <input type="radio" name="state" value="once" id="_anim_radio1_bf18fa8feeef42df9ff1917d1946c4bf" checked="">
      <label for="_anim_radio1_bf18fa8feeef42df9ff1917d1946c4bf">Once</label>
      <input type="radio" name="state" value="loop" id="_anim_radio2_bf18fa8feeef42df9ff1917d1946c4bf">
      <label for="_anim_radio2_bf18fa8feeef42df9ff1917d1946c4bf">Loop</label>
      <input type="radio" name="state" value="reflect" id="_anim_radio3_bf18fa8feeef42df9ff1917d1946c4bf">
      <label for="_anim_radio3_bf18fa8feeef42df9ff1917d1946c4bf">Reflect</label>
    </form>
  </div>
</div>


<script language="javascript">
  /* Instantiate the Animation class. */
  /* The IDs given should match those used in the template above. */
  (function() {
    var img_id = "_anim_imgbf18fa8feeef42df9ff1917d1946c4bf";
    var slider_id = "_anim_sliderbf18fa8feeef42df9ff1917d1946c4bf";
    var loop_select_id = "_anim_loop_selectbf18fa8feeef42df9ff1917d1946c4bf";
    var frames = new Array(5);
    
  frames[0] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAY7dJREFUeJzt3Xl8VNXdP/DPnSQzk3USIAvBsAg0KJshVYhEVEBAaBUFFdqK\
C0tLqbLYFqgL9aeWRR8R+iguUK0bUWnFWhChQeCJEsQQViUVlEVCEhAyE7LMJDP398fNvbl3MjOZ\
hCQzk/t5P6+8IDN37hx47PDJ95zzPYIoiiKIiIiISDcMgR4AEREREbUvBkAiIiIinWEAJCIiItIZ\
BkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIi\
ItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEA\
JCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIi\
nWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAi\
IiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZ\
BkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIi\
ItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinQkP\
9ACImuJyuVBcXIzY2FgIghDo4RARtRlRFFFRUYHU1FQYDKzRUNthAKSgV1xcjLS0tEAPg4io3Zw+\
fRpXXHFFoIdBHRgDIAW92NhYANIHYlxcXIBHQ0TUdmw2G9LS0pTPPaK2wgBIQU+e9o2Li2MAJCJd\
4HIXamtcYEBERESkMwyARERERDrDAEhERESkMwyARERERDrDAEhERESkMwyARERERDrDAEhERESk\
MwyARERERDrDAEitZtmyZRAEAfPmzVMeq6mpwZw5c9C5c2fExMRg0qRJKC0tDdwgiYiIiAGQWsfe\
vXvxyiuvYNCgQZrH58+fj48//hgffPABdu7cieLiYtx5550BGiUREREBDIDUCi5duoRf/vKXeO21\
15CQkKA8brVasW7dOjz//PMYOXIkMjMz8frrr+OLL75Afn5+AEdMRESkbwyAdNnmzJmDCRMmYPTo\
0ZrHCwoKUFtbq3m8X79+6N69O3bv3t3ewyQiIqJ64YEeAIW2nJwc7Nu3D3v37m30XElJCYxGI+Lj\
4zWPJycno6SkxOs97XY77Ha78r3NZmu18ZIHe9cBeSuB7PnAtdMDPRoiImoHrABSi50+fRpz587F\
O++8A7PZ3Gr3Xbp0KSwWi/KVlpbWavcmD/JWAtbT0q9ERKQLDIDUYgUFBSgrK8OQIUMQHh6O8PBw\
7Ny5E6tXr0Z4eDiSk5PhcDhQXl6ueV1paSlSUlK83nfx4sWwWq3K1+nTp9v4T6Jz2fMBS5r0KxER\
6QKngKnFRo0ahUOHDmkee+CBB9CvXz8sXLgQaWlpiIiIQG5uLiZNmgQAKCoqwqlTp5CVleX1viaT\
CSaTqU3HTirXTufULxGRzjAAUovFxsZiwIABmseio6PRuXNn5fHp06djwYIF6NSpE+Li4vDQQw8h\
KysLw4YNC8SQiYiICAyA1MZWrlwJg8GASZMmwW63Y+zYsXjppZcCPSwiIiJdE0RRFAM9CCJfbDYb\
LBYLrFYr4uLiAj0cIqI2w887ai/cBEIU6vauA1YOkH4lIiLyAwMgUahjGxciImomBkCiUMc2LkRE\
1EzcBEIU6tjGhYiImokVQCIiIiKdYQAkIiIi0hkGQCKS+NpNzJ3GREQdCgMgEUl87SbmTmMiog6F\
AZCIJL52E/u705iVQiKikMCTQCjosTN+CFk5QKoUWtKA+YcDPRqikMPPO2ovrAASUetV7tiTkIgo\
JDAAEhGw/Smpcrf9Kf/DoKfrrp0uVf7kvoScEiYiCkoMgEQdUXODV6294Vd/N3z4cx03jxARBSUG\
QKKOyN/gJQdFof77CJP/07j+XMcpYd17O/8khi/bjrfzTwZ6KESkwgBI1BG5By9vFUE5KIabgPAo\
oLocOPlFwzSu++vU37tP93rizzXUoa3ZcRxnyquxZsdxr9cwJBK1PwZAolDmLdi5By856G3+g/ba\
6C7Srwk9AacdgAgc+bDhefdKYmtP6XKNYIc3+6be6BYfidk39fZ6jT8hkYhaFwMgUSjzN5BlzweE\
MEB0StfKwat4v/T82YNA/zsACECYCdgwXXo+bai2kpg2VLpP2lDp+8sNcFwj2OH9algPfL5oJH41\
rIfXa3yFRFYHidoGAyBRKPN3jd2106WAJ4c3OXhFREqP9b8DmLwOsFwB1FVJVUDraeD0noZ+fisH\
AMdzpRB5PFf6Xt493NIAxzWCBN8hsTWqgwyRRI0xABKFMvVUr6dqnPoxObx98xFg/QEwREhr/7oO\
kgLfhukNgazroIawuHcdsOkRKejV2aXnRUjfi7i8AMc1gtQEf6aQm8IpZqLGeBIIBT12xveTp1M4\
5MciE6QNHvDxP3chDFhyofG9HJeA6ovS4+FRQHRnae2gPG3c43qpApg9n0GOgtLb+SexZsdxzL6p\
t8+p6GDAzztqL6wAEoUSX1W+tKFS0LNfang+e742/AlhQGpGw6+WNOlXX2v/1JmxrloKhmcPStXE\
03u4jo8ABPc0qz/rEIn0JjzQAyCiZlCHLfcdvgBgjGn8fI0NSvgb/6znKt2ynkDNReDwBul7xyVg\
4Qnt+8qVQHnN4Ok9DVO/cgWQdEs9zepP0FJX5eTXh0KFjqijYAWQKJR42jShfsz9+byVUqXOW/iT\
q4e1l7SP19obnpPfQ4RUTRz/rLRhRF67x3V8hIa1epk9EvyqBKoDY0vW6AVzxZEoFHANIAU9rom5\
DHvXadfnuX8vV/7cRSZIga/mImBOAEwxjdcXEnkwfNl2nCmvRrf4SHy+aKTX6y63Aujv+4Qaft5R\
e2EFkKgjkqt3hW8BtmLpdI+964DNf0Deoe8begHWlEvXGyK0rx/5OPJO1ki/F8B2LeQ39a5dT1U6\
+TEAyro8f9boud+rNXYHE+kZK4AU9HT5E7F7pa655F28auYE/HnLWTy504Fl4+KxMCsMcNVKz0Um\
NOz0taRh+abjWJRbgyWjLPjz0v9p+fTuhulSixm5zyDpyjVPbkV5dS3iIyOwf8kYAC2v3HXUip87\
XX7eUUCwAkgUjC53Z628+1do+J943n/P48mdDgDAoi3lWL5LXvcnACMfl643JyjhDwCezLUi782n\
G5/0IVcY5V3D3k4COfKhtAZRfbwc6VpzKnfqqh9PCyFqXQyARMHIfcrV25Frvs4CNsYAoqvhlt3D\
sGxCkvL9olw7lufZgQGTlOuX/6dECX8AsGxcPLI7X9AG0fqpZFhPN5wY4i2oyqeP9L+jRX8NFNp+\
PzYd3eIj8fux6cpjvxrWA7Nv6o01O443Cmxv55/ENU9uxTVPblXWCKp3Fnt7HRs9EzUfp4Ap6HFK\
BNrGzNnzG6aH5Uqhp80Ze9cBuU9Ja/h6j1Latiz/+ydY9OI/lMuWLVuGhQsXYvnvJmsfH2XGwt/8\
oqHdizwNLI/FvR0MdwGTn7xN58qPA0CYAEwYlIqCkxeR2SMBBScvotJeh/Lq2kavC6VGz03h5x21\
FwZACnr8QIR2TWDuUw27c/uMat4au/pQuPw/pZpKX6e4aFywVSrfLxtlwsJskzZYymNQnwLCdX3U\
DHJQkwOdHNjUj+/67zlYq2shQgqBT94+AM99WoTy6lpERhjQKdrUoXsH8vOO2gsbQROFArnfHgBs\
f0r6VYBUfZNP5PBH3kqg5iIWZhsBiFiUawcAz+EPkMKeHPwulQDOWukcYYgN6/rcK4CXu4GFOix5\
qhaApoKnfvz3Y9OVwOcUgec+LVKuM4WH4fNFI/Hw+kL860Cx8tqOFACJ2gvXABKFmpGPS5W5kY83\
rBVMG+rfpoy0oQAEICIKC3/zS3SKFDRPd4oObwh/gFTpy31KmvJ11u8Ylk8VkTd3uK8BlKelN//B\
+zhIl7xt5FA/vmbHcZRX12qed19LuOlgsfJc52gjei3ahKse34KH1xcqm0G4MYTIN04BU9DjlEgT\
5E0ZohNSWVAEIqKAqM7aE0HShjbsyjUnYPlOKxZtKW90O6UCKIQBXQcBxYXSE4JBun//O4Ae1zfc\
U10B3LtOqlDKZw+zcTQ1k7q6J08Bu1f4Hl5fiI8PFMMcYUBNrUs5rjpMAJwi0C0+EgBCsm0MP++o\
vXAKmCjUyce9AYAgAKII1FYB1iopGIaZgLoqVV9AoVH46xRlwIUqacfwolw7EBaBhU8/r63sGcKA\
mBQp/KmnpIGG3cjyecHmBOlxxyXpOU4F69Lb+SeVKdzfj033a6q24KTUj1IAEGuO8HjN6qkZKDh5\
EWfKqxFZHwLNEWG45epkZW0h0LBGsCNtEiFqLawAUtDjT8RN8FYBrK2Wfq+QnlueZ1fW/gFSq5eF\
N1rqW8CoHh8Tg4UjOzc0iJbv7WljiP2S9ti4pnYoky6od/V6q8S5HwmnXvPnvuO3pcfHhVITaX7e\
UXvhGkCiUCYHsP53SEFrwCTp1/Tx2uvMCUDqNY3D3ygTFk6/ExCAhSNisGyUWXlu0dZLWL6tRAqT\
6nurj4OTQ54A6blRj0th79rpPD6OMPum3oiPjEB8ZITXxs/qHn7y5g9AqhjGR0ag0l6nrO177tMi\
TV9AT8fHeVr7x2PjiBpjBZCCHn8i9qGp/oCy8CjkfVeJG16vUB7SrPWrXxcIUwyWF0Ri0TtfKdf9\
34xOyL66q+ddvdzxS37wNQX78PpCbDpYjAmDUrHt61JU1zoRGRGGb54ap1Tu5LV98ZERiDaF+6wA\
ql/jaf1gsOPnHbUXVgDpsqxZswaDBg1CXFwc4uLikJWVhU8++UR5vqamBnPmzEHnzp0RExODSZMm\
obS0NIAj7mDUVTY59OU+Ja29i4iCVJoDUFeF7O4CltxoBOAW/uTqodMOWE9j4cBzyokhS240I7tP\
rPfTPq6d3lDx8/d4ONKVt/NPYslHh5XKnXuFruDkRThFee2fXI8Q8Xb+SVyodEAA0D/VouwClqt+\
cuVwyUeHG1X75MDIk0GIvGMFkC7Lxx9/jLCwMPTt2xeiKOLvf/87nn32WRQWFqJ///6YPXs2Nm3a\
hDfeeAMWiwW/+93vYDAY8Pnnn/v9HvyJ2E9yNa7qR2kTCACERajatwAQDMg76UT2wO5SP7+ISGDM\
01KAW9ZTWscHARgwCXk7tyN72mPS6/yp8snVyIY3AyLjpXY1nl7H6qEuXPPkVpRX10IA8NTEAUpw\
k9fjvZ1/Es9s+ho1tS6EhwmodYrSioLICGU6WK78qRtIf/n9Ba+7hT2tFXRvPh2s+HlH7YUBkFpd\
p06d8Oyzz2Ly5MlITEzEu+++i8mTJwMAjh49iquuugq7d+/GsGHD/LofPxDr+RuYlvdUbdwAlM0b\
ABCZACw8oQ1r8iaNDdOBwxvqX+LHMW/u49FsRlHxtglEPX3NTSId0tv5J/H4xsMQIYW4/UvGeJwO\
7rVoE6p/OALzFf010732Oheqa7X/PdX8cAS9B/wUAJQNJoD3TSbu08jBvhGEn3fUXjgFTK3G6XQi\
JycHlZWVyMrKQkFBAWprazF69Gjlmn79+qF79+7YvXu31/vY7XbYbDbNF6FhitfTVKzayMelyh8g\
/TpgkhT8zAnSc4AU2swJ0jSxvb5Vi/o0EdEJHP6H9H6bHpGqg+5Tuu7juXY6MP7Z+g0jk6X7RyZ4\
3wTCTSId3podx5VJ3RE/SWwU/h5eX4jeizehPO8dlL6zENb8DZgwKFWZ7jWFa/+JsuZvQOk7C5F8\
7F/KVC8gVQC9bfCQN4DI9+VGECIJ+wDSZTt06BCysrJQU1ODmJgYfPjhh7j66quxf/9+GI1GxMfH\
a65PTk5GSUmJ1/stXboUTz75ZBuPOgSpN3n4cu30hnAWk+L5vF65orfpEWm6eNMjUlAEVFPIDeux\
UHNRuqf6uDfHJSnkZc/XVgP9rea59xKkkNBUTz11778RP0lEibVaWeMn9+5b8pH038img8WoPH0E\
5Z+vBwCU73wDH0WG4+QnrwHQtoSx5m9A+c43AAAfrluF/tdmI9YsVcjkE0KGL9veaFy/GtZDOW9Y\
7jFIRKwAUitIT0/H/v37sWfPHsyePRv33Xcfvv766xbfb/HixbBarcrX6dOnm36RHqg3XDTFV3VN\
3qyx/SloQt6xXOm36eMbqnjyJhIIDcfNyWGv+qLU808dOJuqTlLIU7dt8fZ8eXUtyqtrUXDyIp68\
fYBSeXPfoDFhUCrMV/RH/I33K68/tWUtpsxZhOHLtmPETxIRJmjDHwAsW7YMH5fEoby6FvY6l9JC\
xtOmEH/HTaQ3rADSZTMajejTpw8AIDMzE3v37sWqVatwzz33wOFwoLy8XFMFLC0tRUpKitf7mUwm\
mEwmr8+TB3vXSbt/nXbp5A+5H5/8nHxs27FcoKYcgChV78wJ0mvC6/++5XWB8mt7XC8FxVq7NCUM\
UdtqRg6Y/lYnKeTJ5/X6mnKVK3dyNc69Uqh+/a7/nkP8zVMxtn8y3ntpOQDgvZeWI/7GUmDcvUg5\
sRXfqcJf4sgH8C/xWtjrpH6W1bXO+hNBwjTh0v09mxo3kd5wEwi1upEjR6J79+5YtWoVEhMTsX79\
ekyaJE0vFhUVoV+/ftwE0trcd+CqN1bIz8n9/mSpGUDl+YbQtv0pqSA46vGGTR3qUz4A6R7jn+XU\
LfnF13Sx3B7GKTbs4v33W2uUEAgABnMsXDUNvSu7jn4QSdn3KLuKLZERsNc5UV3rQmSEAabwMAD+\
HzsXjPh5R+2FFUC6LIsXL8att96K7t27o6KiAu+++y527NiBTz/9FBaLBdOnT8eCBQvQqVMnxMXF\
4aGHHkJWVpbf4Y+8cN+Bmz1fWwFUr8tLGyq9xr0CePagFAjladvqi1JwBLTn+sr9BNUtY4j8IE+7\
Pr7xMJ77tAjRpjCcKa/BoG4W/FjpgLO+/KD07Esbg/gbS5XpXnX4i7/xfvQa9UvMvqm3EhyjTeH4\
/dh0rNlxHJX2OuXoOHnNH8//JfKOawDpspSVlWHatGlIT0/HqFGjsHfvXnz66ae45ZZbAAArV67E\
z372M0yaNAkjRoxASkoK/vnPfwZ41B2Apx24i05IAc0Uo73myIdSIJy8Trpmwv9IQU9uAJ0933ND\
aRHSY+EmACIQ1Vkb/uS1hGz4TPXcmzzLa/5ESOf6nimvAQAcPGNVjomLMAgQAHSONqLSXof4YZNh\
MMdq7mswxyJ+2GQlzKVY5CMLReVIuN+PTdfs8m3Omj9Px8cRdXScAqagxykRD7z1BHQ/Gk7uy9ec\
Xnue+vv5eq/6I+TY0Jnkps/xkRFKZS6zRwJ2/fccAGgqgP96KFu5Xu3Sng34cccbje6dOPIBPP/M\
EiXYyZ6e6Pm4t+ZUAOVegcHQI5Cfd9ReWAEkCkXyjmBAW4VTV/LUffl8bc5wr+S53xvwvPtYfi8B\
3AFMGtbqWmVXbsHJi9i/ZAz2LxmDzxeNwollE/Cvh7I118t7za352vCnrgSe2/465i7+M86UVyNC\
bgCIxse9ydU8AMqxcU2RewVygwjpCSuAFPT4E7EPrXGahrd7+HvvDdOlaeb+d3juOUgdklxhUx+x\
BkBZnycf3yZX4Nwrcrf9NQ8Hz1gRYRCw5Lb++MtfluGbj19W7h9/4/2wDJsMW/4GXFTtAk648X6s\
XvZnAA19AuU+gOq1gO7vHyr4eUfthRVAolDWGqdpeLtH2lBp16+8icSb03ukaWb1SSLU4clTsZsO\
Fitr7X41rIfS9+/3Y9M1FTj3NXkHz1gBALUuEWd25jQKf12uvwvxkRHofvNUJKj6BF7c+Qb+/dYa\
/GpYD0SbwlFeXYs1O44r97fXOREmAPY6l8c1gFzvRyRhACRqYxdzcvDtyFG4mJPT+jdvTnPo5t7D\
V7BTTxvzSDdd8nbEmrwpQ111ezv/pLTBIzICmT0SMHzZdhjqZ3EdPxzBokWLlGsTRz6AHjdPxZLb\
+isBL27YZE2z6PdeWo7HX9mgmbrN7JFQfzScAKcImMINHqd12RCaSMIpYAp6oT4l8u3IUagrLkZ4\
air6bs9t+Y28bcZoK3vXNe4NKGuNqWcKCc1tp+LpevUmCwA4U16tTNFeqLTj7Gdvwfr5enQfN0M5\
Bk6+lzylDECZDrYMn4r+P5uh2bAhv0d8ZITymKd+gMHeHibUP+8odLACSNTGusyaifDUVHSZNfPy\
btQWx635auVy7XTAGNNwDrAaq3660dyKmbz54/GNhzXtYNTHwclTxJk9ElBd60J89i+R/MvlEAZP\
VO4jnyksVygiDAKyJ01H8i+XIz77l8jskYC380/imie34pontyKzR4JyX/XUsDtPFUoiPWIFkIIe\
fyKu1xYVwKYqea3xnu1duaRW1dyKmbq1S1NtVXov3qRU9wAgPjIc+5eMBdBQ0ZOFCUCKJVJ5TN4H\
LCqv1baekTemhFrQ4+cdtRdWAImCRJNrBVtjvZ+7pip5rfGebVG5pHbT3IrZ78emIz4yApERBlTa\
6/B2/slGGy/k7/unWiCoXhttapi+zeyRAAFQ1goaww3I7JGA+MgICJCCn3v1Qq5WFpy8qIyZmz6I\
PGMAJAoS5199DXXFxTj/6mtNX+yvpk7rcA94bXG6B6eLdeVXw3pg/5Ix6BRtarRDV56SlaeJT12o\
Qmr9usAwAZoNGwUnL0IE0NUSiW7xkaiudSk9BZ+aOACREWHKtQKk4Ompn5/83ks+OswQSKTCAEgU\
JJq9VtCfsNbc6ltbVOvaonJJQc/Tuj9PjZbl5568XXuih3xUXKW9TlnfJ+8gBoBO0UblWkv9xg9P\
U9XycXTKecNEBIABkChoJEyZgr7bc5EwZYp/L/AnrDW3+uZv7z+iJshTx0DjYCaf2ys3cPb2enkz\
x6aDxZh9U28UnLyoVBLlgKhe+3emvBrPbPoGvRdvwsPrC5X7yL0J5QDJSiARN4FQCOCiaC8CsSmE\
qJmaOmdX/fzsm3prwqK6DYyn59XkzSrF5dUQIU0pH186oVljCQb8vKP2wgogUagKxKYQIj/Jmy/k\
6Vv19K96Y4Z6eliu4j33aZEy1fvk7QOUqWDA+/m+csXx54NTESYAEwalNrqGZ/4SNWAFkIIefyIm\
Cj2+qm3enpOrePJ5vmGCFADlYNgalTs2giaSsAJI1AxNtWrx9nxrHwfXpsfLEbUCfzZ+uD8nV/FG\
/CQRgLRx47lPi7xe35IWLzwKjkjCAEjUDHKrlpKnnvYYvry1cmlui5emAl6btIwhakW++gc21Vuw\
4ORFj9cD0AS+loQ5TgMTSRgAiZqhy6yZQFgY4HR6DF/eWrnIj0dlZPhVuWsq4LXa8XJEQch9h6/M\
PfC1JMzxKDgiCdcAUtAL5JqYizk5OP/qa+gya6bSnuViTg7KVr4AAEiaP0/zuPu17r4dOQp1xcUI\
T01F3+25Xt8vKiMDVYWFPu9FpDctXb8X7Ov+1LgGkNoLK4BEKu5Tr54qcQlTpsAQHQ2X1aqZCvZn\
Wrapyp18j6rCwub1BCQKcq1xJFtLq3dc90fUGAMgkYp7iPM1pStPBZetfAHfjhyFqIwMr+HuzCO/\
xzf9B6B8wz98vr/6/bjRgzoKuZ+fpxCmDoZtdW4v1/0RNcYpYAp67TUl4m1q19f15199Da7KSris\
ViAsDCmPP+bxdd/0HwA4ncr33qaA1eTpYl/3JQoFctsXua2LuoKnbgkDIOgbNbc1TgFTe2EFkKje\
+Vdfg8tqhSE6ullhKyY72+fGEACIGzcOCAuDecAAvzdveKoyshpIoeTt/JO45smtuFBpR3xkRKPw\
B3g+89dTpa6tqoNEehUe6AEQBYsus2Yqmzi8UW/0UNbrAUh5/DGfr+32P8+h2/8816zxJEyZgqq9\
X8G2ZQtEux119WsO5eeIgt2aHcdRXl0LAOgUbfLaEkZeo1dw8qLHxtDqU0KWfHRYeR0RtRwrgET1\
EqZMaXLjhXqNoHq9nj+vVa/p83d9X1VhIeB0QjCZmqwyEgUL9TFwcjsXX+vvvK3RU2/emH1Tb4QJ\
UnNobuYgunysABK58dXORV0llJ9TBzJfbWDcN5jIv/cVGt2rkk1VKImCgRzcAGD/kjFNXv+rYT08\
VvTkyp+6fYv8PRFdHm4CoaDX3oui5c0XBosFhuhov/r6ISwMQkQExJoaGCwWpO/Jb3Stusffpbw8\
AA2bTfzpIUgUKlq7714o9fG7XNwEQu2FU8BEbuSpXaChSie3cTnzyO8107fhnTpJL3I6IdbUAABE\
hwNA456C8jRxVWGhZrPJxZwclDz1dLOPdmObGApWrX3aBvv4EbU+BkAiN3JQS5o/T1njZ9uyBXA6\
YduyRTOVW3P4cMMLw6UVFWJ1NYqGDkPpsuWoKy5G2coXNGGty6yZMFgscFVWKpU/OJ1AWJjH6V1v\
QY/nAZNe+NPHj7uEiZqHAZA6rOZWyLxV7BKmTFHauMSNG4eojAwgLEz6VUWIiFB+77JalYogoA1r\
6pNEyla+AFdlJQwWC1IefwwAGo3ZW9DzNg6ijsafiiKrhETNwzWAFPRauiamqXN3Ze4NnZu6vmjo\
MGkK12KB6HBArJYWuxssFrhsNkD9P6n6Js4ANGf8yr8qTaQFAYLJBNFuB0RRGYOv5tT+/vmIQp0/\
awA7yjpBrgGk9sIKIHVYTZ27K5MrbACavP5iTo4U8uolL/wjDBYLBLMZABA3fjzCU1MRN2GCtIkk\
JgZVe79SKn0VubmoKy7Gpbw8ZZoZYWGAKEoVQ1FUqnrfjhwlvc5qhevSJc0Ymjp6jqgj8ae619rr\
Dok6OgZA6rD86c0HNATFpPnz/OoDKIe0pPnzAACG6GgIJhP2nj2LqsJC9N2eqzR9dlmtsG3aJIU4\
qxWi3Y6CqirNGOPGjQMEAQgPV6aCqwoLlVDq3v9PaUBd/17cNUwdHc/yJWp97ANIupcwZYrfISoq\
IwO20lKYr7pKqs7VT/m+WFGBF4vPYEn2cPzZ24sFAW+Eh2HF6VP4bU0NHh46DEnz50nNnkUR4UlJ\
mqlc9/5/clUwKiMDVfVj+XbkKLaOoQ7PW59AImo5VgCJ6vmzaeRSXh7gdKLmyBFp7Z4oosBegxeL\
zwAAnly/HsuXLwfQcEawfP7vexnXYEX9ruGXzpVh79mzjU4U8UTdPkaePpbHwl3ARETUEgyARPXk\
qdWylS94DIIXc3Kk0AcAYWHS2r/ISPzUEo8FiYnKdYsWLcKfbhgB2+bNgNMJx+nT+OfYMXhy/Xrl\
mgVdEpEZFdXQR9DLWNThzr0/ISCtWZQrgewHSERE/uIuYAp67bUrTt5xK0/ruu+uVU79gLTjN2n+\
PJQ89bTUww/A2gs/4vlz55TrF3RJxIzOnbGushL/88PpRo8DAMLCEJ6crDl5RD4pRLTbpd3BRqNm\
B7D7qSHcDUzUcXAXMLUXVgDpsixduhTXXnstYmNjkZSUhIkTJ6KoqEhzTU1NDebMmYPOnTsjJiYG\
kyZNQmlpaYBG7J3cn0/e5OE+JRuVkSEFsshIJM2f19DAud6sXldiydSpyvfPnz+HrGPfeg5/Bul/\
ekJEhFQFDAuD6HCgrrhY2TQi1tZCrK6Gy2rVVALdN7f4u9uZiIhIxgBIl2Xnzp2YM2cO8vPzsW3b\
NtTW1mLMmDGorKxUrpk/fz4+/vhjfPDBB9i5cyeKi4tx5513BnDU3slhKuXxxzQVt29HjpLW3oki\
BKNR2ZShbvkCAHNvu00TAq2qgLigSyJmdOki7fR94nGEp6ZCrKmRThNxOiEYjdKOX0BpOm2wWGCw\
WHyGO393OxMREck4BUyt6ty5c0hKSsLOnTsxYsQIWK1WJCYm4t1338XkyZMBAEePHsVVV12F3bt3\
Y9iwYU3eM9BTInLjZ8FsRlinTnBeuCD17BMEpCx5AgCUqWB5GjY+PAJWZ51yD0tYGPZk/hQAlGbT\
XWbN1EwhC5GRiB05ElWFhcr0rq9G0ETU8QT68470gxVAalXW+k0Sneo3NxQUFKC2thajR49WrunX\
rx+6d++O3bt3e7yH3W6HzWbTfAWCXPkT7XYAgGAyocusmcr3EEWcf/U1lC5foYS4qIwM/D6tuyb8\
AVIl8O9GIwBp/WBURgbOv/qacsQcIJ0hXJErreGr2vuVthF0/bFx/o6ZG0KIiMgXBkBqNS6XC/Pm\
zcPw4cMxYMAAAEBJSQmMRiPi4+M11yYnJ6OkpMTjfZYuXQqLxaJ8paWltfXQPZJ34op2u7LpQ2kE\
Dali12XWTM2Zv8+vf1ez5s9iCFN+vzTv//Dqd9/BEB2ttHSpKiyUQmA90W5X1gEqjaAFAQDgstk8\
Bjt16PN2bjAREZEaAyC1mjlz5uDw4cPIuczq0+LFi2G1WpWv06dPN/2iNtBl1kzlmDZDdDQSpkxp\
eAyAWFODspUvwNy/PwBg7Y8/4vmzZ5XXL+iSiN19+2JB167KY8+fP4d3UpLRZdZM6ezgykqlrx/C\
whA3fnzDOkBIvQRTljyhjMNTsFOHPm4IISIif/AkEGoVv/vd7/Dvf/8bu3btwhVXXKE8npKSAofD\
gfLyck0VsLS0FCkpKR7vZTKZYDKZ2nrIHrm3WAG0J3IAgCEmRmkC7bJaURcdjfeGZOB5tz5/cquX\
WWndIYSFK5XBJ9evh+P0D7j30iXA6YTBYlFCW8KUKYi69qfK2sCqwkLlWDn3cci6zJqpGTPXCRIR\
UVO4CYQuiyiKeOihh/Dhhx9ix44d6Nu3r+Z5eRPI+vXrMWnSJABAUVER+vXrF5SbQHz11LuYk9Ow\
aUMQpKlgQcCJe+7G+CefVK5bMnUqpnz9jTI1bB4wAI7Tp/Hq6VOaCuFbad2RGRur2XF85pHfw7Zl\
C8xXXYW6Cxd4zBuRznATCLUXVgDpssyZMwfvvvsuPvroI8TGxirr+iwWCyIjI2GxWDB9+nQsWLAA\
nTp1QlxcHB566CFkZWX5Ff7am7qapqYJf/UtWuTduldNmYI/Hj6MFf/4Bx65Ig1zb7sNZce/UwJg\
zZEjgChiRpwFqK3D8+fPYf6wLAytX0OoDni2LVuko+a++QZXHTncrn92IiLSD1YA6bII9RsU3L3+\
+uu4//77AUiNoB955BGsX78edrsdY8eOxUsvveR1CthdMPxErJwC4hb+yjf8Q+rjB6Cgqko63i01\
Fa7KSmmaWBAgmM0Qq6ulGwkCCgUBtz7xuNLmRT19e+aR38O2eTMEkwnJixay+kekM8HweUf6wABI\
QS+QH4jqKVmHajOKy2qVNnHIZwPXk3cLA9o1e6XLV0CsqVHCoDzFrJ5y7jJrps+j6Iio42MApPbC\
KWAiH9RTsvKZvYLZDAiCx/CXvidf85gcAgWjEWJ1NcTaWiAsTDpWDtop5/OvvtZwTw9H0REREbUW\
BkAiH+LGjZOmZCMiEJWRgSoArsrKht5/9VO8gtGIpPnzNFO6HnvyOZ2AKKKqsBAAGu3a5akfRETU\
HjgFTEEv0FMi8jStwWKBIToaURkZuJSXB9Fuh2AyacKap7WC8vWA1NdPfdRbc3lqU0NEHUegP+9I\
P9gImqgJcnNlAMrpHel78hHWqRNcVivOv/qachpHVEaG1LTZ6YRtyxZ0mTUTVYWF0nFuly55fQ9/\
j3CTq4olTz3N496IiKjFGACJmpAwZQr6bs9F0vx5mlM21KduyMFMc7Sb09mwEUQVCuVp4Ys5OSga\
OgxFQ4ehbOULfh3hpr4Xj3sjIqKW4hpAIj+5r9dTf1+19yvYSkuldYL16/vkjRwJU6ZIz7s1eFZv\
+lCfBtLUGADvp4IQERH5gwGQqIXU6/GqCguVo9vcj2YDoDxfd+GCprVLSzZ98Lg3IiK6XJwCJt3x\
d71dU9S7fLvMmin1BaysBAD03Z6rCWnq6WJZwpQpSN+Tj/Q9+Qx0RETUrhgASXc8tmdpAXWoS5gy\
BYboaGVTiJqvnbutFUaJiIiagwGQdMdTNa4l5M0hcqjzdl9fgbO1wigREVFzMACS7rgHt7a+r7dg\
eDEnB67KShgsFp9hlFVCIiJqbQyARG3MWzCUdwEboqM1z7kHPlYJiYiotTEAEgWI3DRaPhdY5h74\
WmvKmoiISMYASORBe0y7qlvHqLkHvraasiYiIv1iACTyoK2nXX2t/2PgIyKitsYASORBU9Oul1sh\
9Lb+j4iIqD0wABJ50FQV7nIrhFzXR0REgcSj4IhaQH3cW0vwODciIgokQRRFMdCDIPLFZrPBYrHA\
arUiLi4u0MMhImoz/Lyj9sIpYCIiIiKdYQAk6gDeL3ofYzaMwftF7wd6KEREFAIYAIk6gLWH1uJs\
5VmsPbQ20EMhIqIQwABI1AHMGDgDXaO7YsbAGYEeChERhQBuAqGgx0XRRKQX/Lyj9sIKIBEREZHO\
MAASERER6QwDIBEREZHOMAASERF5cWDbZrw250Ec2LY50EMhalUMgERERF58uXEDbOfL8OXGDYEe\
ClGrYgAkIr+w2TTpUWp6PwgGA1LT+wV6KEStigGQiPxyuc2mGSApFBUXHYXocqG46Gigh0LUqhgA\
iQhA0wHtcptN87QSCkXXTZyMuC5JuG7i5EAPhahVsRE0BT02Rm2594vex9pDazFj4AzcnX63z2vH\
bBiDs5Vn0TW6K7ZO3hrQsRDpFT/vqL2wAkjUgTWn6qau8LXFdO3d6Xdj6+StDH/U5i5n5y53/ZJe\
MAASdWC+pm3dQ546oHG6lkLZ5ezcVb+WYZA6MgZAog7MveqmDn2+Qt6MgTNgMVpQWVvJTRsUFJoT\
xi5n3Z76tWwBQx0ZAyBdll27duHnP/85UlNTIQgCNm7cqHleFEU88cQT6Nq1KyIjIzF69Gh8++23\
gRksaUKfr+rg3el3IyoiCjaHrVFA5G5eam8Htm1G7t9e9hjGPAXDwbeMx8wX/4bBt4z3ej9vYVL9\
Wm4AoY6MAZAuS2VlJQYPHowXX3zR4/MrVqzA6tWr8fLLL2PPnj2Ijo7G2LFjUVNT084jJUA7JSxX\
BwF4DHTeAiKnh6m9fblxA0SXC4LB0CiMtaRK5+9rmgqSRKGMAZAuy6233oqnn34ad9xxR6PnRFHE\
Cy+8gMceewy33347Bg0ahDfffBPFxcWNKoV0+fypzN2dfjdmDJyBtYfWKtd5C3TeAuLltoMhai65\
Ejfqwd80CmP+NGqWK35vL56H56fehsi4OFb2SPcYAKnNfP/99ygpKcHo0aOVxywWC4YOHYrdu3cH\
cGQdk6cgpw6F7xe9j+z12Xg6/2nNde6Bzj1I+qr4cTqY2oOvSlxTjZrV08el3x2D6HKh7MR3rOyR\
7jEAUpspKSkBACQnJ2seT05OVp7zxG63w2azab6oaZ4qc+rwtvbQWlgdVogQlesB7UaR94vexzN7\
nvEZEN3vyelgCqSm1unl5bwJ0eUCBAHJV/aBYDAgPSubO3xJ9xgAKegsXboUFotF+UpLSwv0kIKa\
XIUD0KjPnjq8uU/ZeurHt/bQWrhEFwyCwWNA9HRPX9VDorZ0YNtmfLlxA66bONl7NU8UAADmqBj8\
aukLGPXgb1BcdBR569+C7XwZcv/2MkMg6RIDILWZlJQUAEBpaanm8dLSUuU5TxYvXgyr1ap8nT59\
uk3HGep8VeHU6/jWHlqLCEMEAMAcZlauUYc2OdA9OvRRrw2b1YHQPRyyIkhN8VV5a25VLi/nTdjO\
lyEv502vr82eei/iuiQhe+q9ABo2gEAQAUGA6HIhb/1bzXpvVg+pI2AApDbTq1cvpKSkIDc3V3nM\
ZrNhz549yMrK8vo6k8mEuLg4zRd558+mDDmYhQlhMAgGjOw+stFzq/etxtpDa5GRlKFsEpHD4cJd\
Cz1W9twrft7GwsogyXztwG32jt766h5Ewetr5XYucmNnedOIJUn1Q6gg+nxv98DH/oDUETAA0mW5\
dOkS9u/fj/379wOQNn7s378fp06dgiAImDdvHp5++mn861//wqFDhzBt2jSkpqZi4sSJAR13R1NZ\
W4nV+1Z7DVhyMDOGGeESXcg7k6cEu6raKsQZ42B32nG28iw++f6TRmv8tpzYooTE7PXZGL5+uMdm\
0t6Oe2NlkGS+1ux5e86f6p6v+6oDm7xppOzEd4AoQjAYkD1lmub1TQU+9gekjkAQRVEM9CAodO3Y\
sQM333xzo8fvu+8+vPHGGxBFEUuWLMGrr76K8vJyZGdn46WXXsJPfvITv9+Dh6P7Nnz9cNgc0kaZ\
rtFdlSlfT+TQdrHmImqcNRAgQISIrtFdUVVbBavDCnOYGQnmBM2mj4ykDBSWFaKytlJ5rzhjHBxO\
B+xOO27tdSuWj1je5PvK/QeJ/CGv8XNUV6OmsgJxXZIw88W/ebzG0zpA+bnU9H4oLjqK1PR+OLG/\
EBBE9Bw8BMVFRz2+7rU5D8J2vkx5P7/WGrYSft5Re2EApKDHD0Tfstdnw+qwQoCAx4Y95jVgqUPY\
s3ufRY2zBuFCOMIN4bA77UiJTkFpVSnG9RyH5SOWY+GuhdhyYguu6nQVLtRcUALh6n2rIUKEw+lA\
jVNq6N1U8CRqCTmImWNiYDRHKRU3dRh7cfoU1Fy6BHNMDOasy/H4erla9591awBRhDk6FnP+tl5z\
rTrkub9He+LnHbUXBkAKevxA9EwOdHJ1zlN1TR365GlYdbVPrgCqGQQDHh36KJ7Z8wxcokt53Bxm\
hsPlwLie45CZnImn859WXhtnjMPcIXNZ3aNWdWDbZuTlvAmIAnpek4ETB/ahprISEEWlOvfig1NR\
U1kBQ1g4XC4nwo1G3HTvdAy+ZbymAli0O09qBwMAgoDR02drrnHUVKHm0iWPVUZvY2uLkMjPO2ov\
DIAU9PiB6NmYDWOUQOet+iZfI9T/nwsu9O/cHz3iemDz95tR+d9KRP8kGgBggAEuSP9Ado3uioyk\
DGw5sQXJUcn4bv93iOwbqdw3zhgHm8MGg2BATEQMbA4bq4DUJuQqnmAwKAFOMBiUU0HkIGY7X6a8\
xj3EyfdQCzeZEBVrQVWFFXV2Owzh4RBdLqRnZWPCw3/0e1z+BkZ/8fOO2gs3gRCFKH92/84YOAMG\
wQARohLuvrnwDQrLClH6YSm+/8v3OLfpnBIOAUCAgBkDZ2D5iOU4MO0A/vuP/+L4M8dxbuM55b7V\
ddUAgKs6XYW5Q+Yq4+BuX2pt8oaL9KxsmGNiEG40wRQVpTwvnxISbjJpXgM0bB6J9BCk6ux22M6X\
oc5uBwC46uo8nijibQMKN4JQqGMFkIIefyK+PO8XvY/V+1ajsrYSTtGJW3vdiugforHkl0uUa7pP\
6Y64cQ1/t+YwM4xhRvQs6Il3/+dd5fEn33kSW4WtsDqsAKTp4gPTDijP+1OVJGou9XRrQx8/AeER\
RkAAwsON6HlNBnbu2Ilfzp6jTMl6qh4CwKnyClyZ3EWp/Lnq6qQnVFPD8vvm/u1liC5Xq1f6vOHn\
HbUXVgCJQpC3Spunx+9Ovxt5U/OweOhixBnjsP3UdnwqfIoeU3oo15zKOYXzm84r39c4a3D8w+Oa\
8Nftnm7ol9kPUREN1ZerOl2lef8ZA2cgzhiHqtoqr70DSZ8up3myug3LdRMnA4IAiCLqHHbU2e2o\
qazAy2+tx7MfbsaWfYdwYNtmvPjgVFRVWGGOjkV6VjbiuiTBHBOD7d8cx+qtu/CNaEZclyQYTQ1L\
G8IjjEq/QPl9RZcLgsHASh91OKwAUtDjT8SNeau0qR+XN37Im0Tk1i9qFz+5iDPvnVG+7z6lO5Im\
JOHsv89qHk++KxmJExKV+8obRNTvI29CkccgYzWQgMtbM6fezHFifyFqKiuU58JNJpz80YqVmxsa\
zt85LBPXd69v9Fxf1QOAJX9ajI++Oqhc93//93+IrbYhL+dN1DlqUeeQpoPN0bHInnov8ta/BQgi\
sqdMA9A+O4P5eUfthRVAohDkbf2f+nH3Js52p73RfTqP74xly5Yp35/KOYXv5n6nCX/d7umGxAmJ\
AICMpAzcnX43Hh36qPI+q/atwtnKs1i1b5UyBoMgfbSozxQmffNnzZy3KqG8zq+46KgS/gSDAaNn\
/BZz3/wH7pu3AHcOy1Su/2d+AbZ/c1z6RhTxn3Vr8KdHHtGEv/ED++HEpoaTPOpqHQ2/r3Pgy40b\
UFNZAaNZqnjn/u1lnv5BHUp4oAdARM0nn8PrS0ZSBkpPlCp9/DKSMvD5mc8hQkRabBq+/vFrGA1G\
9JrYC8uwDIsWLQIAXLhwQblH8l3JSLg1Qfl+y4ktyEzO1LyPAOk4rgpHBRbuWojCskKM6znOa2sa\
0qfBt4xvsnKmnur1dO11Eydjx5vrUFfrQHpWtnLNlxs34PruKbBXX4VNB74BAGw+JG3mGHlVb2z/\
+pjyPSCFv5FX9Ubpd8fw4w+nlcqfrM7hQGp6P+U95algAMrjRKGOFUCiDkSu+q3atwpbTmyBS3Th\
Qs0FbJ28FZnJmYiKiMLcIXPRI64HRIiocdZg7aG16DWxF8JjtD8PRsREKJU/QAp6LtGlnBksH+02\
vNtwAIAIUak2FpYVejwSjsiXpqqEg28Zj6g4CyCKKNqdhwPbNuPAts1w1FTBHB2L2Q/ej9szByvX\
bz50FE9s3Noo/N1+wzAAQPKVfTSVP4Uo4sSBfZpxCQbpn0v3XcLA5a1vJAoUBkCiDkSeApbDmnoK\
Vg5tq/etxubvG/6h6mTuhIcffxh1l+o096q9VItzm6TWL/0790esMRYAYHfaUVlbCYvRghkDZ+Dz\
M58rr7mq01VNtqYhag73cCWHMdHlQu7fXkbe+rdQc+mSMjW88av9uP2ng5TXVzlqld/LlT8BAh55\
79/41dIX0O/6G6RNJSpxXZIAUdBUI0c9+Bu/zhr2Nm6iYMMASBRifPXauzv9bmydvBUPD3kYXaO7\
4tGhjypVuIykDBgEAyprK5Xr+3fujx1v7kDpB6XKY2HRYcrvSz8oRefdnZHzsxzMHTIXccY42J12\
2Bw2iBCx9tBazdpCudro6zg67gwmbzwFKffHBt8yHulZ2QAgTcsKDfsYi3bnAQBm3vtLRBkjNPeO\
MkZg5NV9IBgMsJ0vw8pfTMSBbZsx4eE/4pGcj9Fv+AgIBgP6DR+BmS/+DdlT71UCX1OnfniqXHr6\
sxAFEwZAohCjnn71Rg6CAJTAVVhWCJfoglN0AgAsRgsKcgo04a/7lO6YnDMZyXclK4/tfGUnekyV\
WsZER0RDhAgBAiocFThbeRbGMCPijHFKRfByx0765SlIeXpMnoYVDAZkT5mmhDc5GL725ruayh8g\
VQI/K/pOWcvnctYh928vKxW6CQ//EaMe/A2Ki47iwLbNysaTwbeMbzLMqa/1NW6iYMI2MBT02BZB\
e6YvAKzatwoOpwOmMBOuiL0CX//4NUxhJvzh2j9oqm9ySxaDYFA2ZshtYUr/XYqDf2/YFZl8VzIG\
3T0IMwbOwFP5T+HcpnONwmHShCRNKxn53GD1e6rH6utsYq4P1LeWnqV7YNtm7HhrHeocDiT36g1r\
aSkgiOg5eAiKi47ii9MleOPjT5Tro4wRHqeBZeq2NN5a1WxavQJFu/P8PibucvDzjtoLAyAFPX4g\
Nu77595rTxZnjEN0RLQSsBbuWqis91P34/t/7/4/zUkgXe/uis7jO6N/5/64UHNBubd7COz1p17K\
2cECBDw27DElyC3ctRBbTmyB0WBEjbNGeT9voY9hUN+a0xdQHRbz1r/V0AewviG0/Htvu323f3Nc\
8/idwzLx4NS7lVB3xVUDlD6DxUVHlapdXs6bgCitD6yprFDG2tLw6g9+3lF74RQwUQhw7/snn7hh\
MVrQv3N/CBBgDjPD4XQoGz0AoLCsULlHRlKG8vutwlYk3i7t8O12Tzd0Gd8FAPD1j1/jYs1F5bqu\
P+uK7lO6AwCSJyYj5icxynOxxlhNcJN3Hdc4a2AQDMr7eZv25XSwvjWnL2BezpsNU7CqNX/SUXBS\
QPvs6Hcewx8gtYIZP7Chfcs/8wvw0trXIbpcOLZ3D/6z9iXYzpfhxP5CzbSvsrlEEDVjlaeE1VPI\
RKGGAZAoBMhr+uTAdXf63fh86ufIm5qHnJ/l4OB9B7H3V3thDDMCkFqyAFJQlPv0ffL9J8rmCxEi\
ku9IxoAnBuCHnB9wa69bYRAMCBPCNFO80RHRSLstDb3+1AtJE5MgQoTFaEHX6K6YO2SuZozjeo6D\
QTDAHGaGS3Qp4dOfptWkP57WzblTzv0VBZhjYuCorkbPwUNgCJdaFnW+Ig39rr8B3/94EZsOfK28\
btmyZdh08Bv0Gz5CeWz0wHT8LKO/8v3mQ0fx/Y8XtW1gBFEJnanp/WCOiYE5OhY9Bw/RjEu9E5mb\
PChUMQASdSBzh8zVhLO70+9GnFGaRpJ37aqvGz9qPMZsGAMASI5KRrhB2wtweLfheHjIw+iT0Qe3\
9roVXaO74uEhD3vc6bt8xHI8OvRRANL0cEZShs9pXvdQS/rhb4sUuUqYPfVeGM1RqKmsQHHRUWUj\
R+l3x3DiwD706pyAW/r3BQD8LKM/Yor248XpU/DfPV8o9zKazbgt6zqlEjh2UD/cetvtCDdKPzSF\
G03InjJNCZ3FRUcxZ10Osqfei6LdeY12IvtqC0MUCngSCFEHoj4hRA5fw7sNV04AmTFwhiaUrdq3\
CjaHDSXflyhVQzW5ildaJa0D9HWm7/tF7ytnBMuvLSwrVKZ5GfRI1tSJHzL59BB1s+frJk7GD98c\
xtHPd0kXiQLiuiRh7qwRuGbHTvSIj9OcFawQBVw3cTIc1dVIT0vFffMewZcbN6DObtes7XNUV8Mc\
E6OZ7hVdLggGgybs+XOyCVEwYwWQqIOS19jlnclTTgC5O/1uzdo7eXrYFGZSzu8FpApenDEOGUkZ\
2Pz9ZrhEF7ac2OLxfeTefqv3rYZLdEGAoLSE4TQvedLcFinyejxjZCQG3zIeEx7+I0bP+K1SHbxu\
4mScOLAPPeLj0POaDJijY2GOiUHylX0AQUC4yYTsqfdi8C3jYYyMRLeYSGUTh/vaPvn8XzncydeM\
evA3msDHRs8U6rgLmIIed8U13/tF72P1vtVKzz6rw+pxVy4A5fcFpQX45PtPNO1k1LuN5R3C6unc\
94vex9P5T0OECHOYGQnmBL939XIXMHniaYdtU7tu5R3Fsn7DR2jatbi3jqm22TzeqzntXpqzi7k5\
+HlH7YUVQKIOaNW+VbA6rKhwVGB4t+HoGt0VGUkZyno/ee3d3el3Y8bAGVh7aK0yTZxgTlACWSdz\
JwDQtIdR79pde2itMnVsDDNq1vQ1deoHdwGTJ56aLrtvGNm0egWen3obNq1eAUCq0pljGnaoy+cE\
yxU6eaoXooiyE9953Xwiry/0dN6vOzZ6plDHAEgUwryFLHlqV4SIwrJCbJ28FZ+f+VzTIka2at8q\
nK08C6vD2ug0j28ufKP86mk6d8bAGbAYLYgzxmHukLma8TQV8Dg9TJ74ClZyqDv6xf9BdLmUo98G\
3zIec9blaE4EyVv/Fmzny7DjrXWoslmVe8inhbjf88C2zc0Kdf7sYiYKZtwEQhTC5E0cq/at0kyj\
PjzkYazatwoCBCVgyZU6980eclgEgIpa7eL5cT3HYcuJLRjXc5xmg4nM/TF5ylie2lVPNbvzdD8i\
X5sr5CbQgsEAURSR1PNKzfMTHv4jrrhqgKZZdJ3DoTSLjuuS1GhqV11xbCrQtWUDaKL2xgogUQiT\
w5s6xAHaPoGAFMyyu2VrWsTI1brh3YbDYrRAgACX6NJU7JaPWI4D0w5g+YjlXquN6sczkjKUJtBs\
80Ktrr4JtLx0vdpma3SJvJEDkM4KTu7VW9kI4qmy15yqX1NnAhOFEgZAohD28JCHld58QOMpYbk1\
y9nKs8pUsBzI5CnawrJC5E3Nw2PDHvM4Jave5dvUiR6FZYWaJtBErSl7yjTEdUlCv+tv8BraUtP7\
KYFv1IO/kUKiKCIq1uKxaudrKtd9py/X/VFHwilgohDmPo2qDmNyyxeX6IJBMCjBTl6fl5GUAZSh\
yTV48j3jjHEeA2JGUgZKT5QiIykDmcmZPqd9iS6HP733iouOAqIIZ20tACm0ydO2zZ3ClSt+eTlv\
Kq9rzR2/RIHECiBRB+LpzOCu0V3x6NBHPVb+PFUE3St88j3mDpnrcUpXXfXjtC+1NW/999RHuKmP\
aVNX+Jo7hStX/CAKnPqlDocBkKgD8XRmsHsga+7ZvE2FOu7mpfYkh7jcv72sCYHqI9y8HdMmh8PU\
9H7KY74aOsvhMXvqvZz6pQ6HjaAp6LExauhis2dqDeqpWwDI/dvLEF0uTRNmX9O7B7ZtRl7Om6ip\
rAREUfO6tmro3FL8vKP2wgogUQfUVBPm9sJmz9Qa3M8Odq/wbVq9Arl/exmp6f08ru2Tj5KDKDY6\
05cbO0ivGACJOqBgCV6cHqbLdWDbZjhqqmCOjlVCmvvO3aLdeZrG0O7kk0LM0bGNzvT1tAuY5/yS\
HnAXMFEH1FQT5vbCZs90ueTqXVyXJK+tWsLCI1BX62h0yofMn93D7u+prjgSdUQMgEQdEIMXdRTq\
Ni6efLlxA+oc9kanfMhrAlPT+6G46GizTu9o6j2JOgJuAqGgx0XRROSNt80f8uYOuSWMvM4v2I9y\
4+cdtReuASTqQIJl8wdRe/F2koe8uSM9K1sT/tjPj0jCKWCiDsT9JJBAYfsXCjRv6/44tUskYQWQ\
2sWLL76Inj17wmw2Y+jQofjyyy8DPaQOKVh23QbLLmQiNV/n/hLpDQMgtbn33nsPCxYswJIlS7Bv\
3z4MHjwYY8eORVlZWaCH1uG05VFszZleDpYgSkREnnETCLW5oUOH4tprr8X//u//AgBcLhfS0tLw\
0EMPYdGiRU2+nouig8OYDWNwtvIsukZ3xdbJWwM9HKIOiZ931F5YAaQ25XA4UFBQgNGjRyuPGQwG\
jB49Grt37w7gyKi5WNUjIuo4uAmE2tT58+fhdDqRnJyseTw5ORlHjx71+Bq73Q673a58b7PZ2nSM\
5B/2FiQi6jhYAaSgs3TpUlgsFuUrLS0t0EMiIiLqUBgAqU116dIFYWFhKC0t1TxeWlqKlJQUj69Z\
vHgxrFar8nX69On2GCoREZFuMABSmzIajcjMzERubq7ymMvlQm5uLrKysjy+xmQyIS4uTvNFRERE\
rYdrAKnNLViwAPfddx9++tOf4rrrrsMLL7yAyspKPPDAA4EeGhERkS4xAFKbu+eee3Du3Dk88cQT\
KCkpwTXXXIMtW7Y02hhCRERE7YN9ACnosS8WEekFP++ovXANIBEREZHOMAASERER6QwDIBEREZHO\
MAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBER\
EZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwD\
IBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER\
6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAAS\
ERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMABSiz3zzDO4/vrrERUVhfj4eI/XnDp1ChMmTEBU\
VBSSkpLwhz/8AXV1de07UCIiItIID/QAKHQ5HA7cddddyMrKwrp16xo973Q6MWHCBKSkpOCLL77A\
2bNnMW3aNEREROAvf/lLAEZMREREACCIoigGehAU2t544w3MmzcP5eXlmsc/+eQT/OxnP0NxcTGS\
k5MBAC+//DIWLlyIc+fOwWg0+nV/m80Gi8UCq9WKuLi41h4+EVHQ4OcdtRdOAVOb2b17NwYOHKiE\
PwAYO3YsbDYbjhw54vV1drsdNptN80VERESthwGQ2kxJSYkm/AFQvi8pKfH6uqVLl8JisShfaWlp\
bTpOIiIivWEAJI1FixZBEASfX0ePHm3TMSxevBhWq1X5On36dJu+HxERkd5wEwhpPPLII7j//vt9\
XnPllVf6da+UlBR8+eWXmsdKS0uV57wxmUwwmUx+vQcRERE1HwMgaSQmJiIxMbFV7pWVlYVnnnkG\
ZWVlSEpKAgBs27YNcXFxuPrqq1vlPYiIiKj5GACpxU6dOoULFy7g1KlTcDqd2L9/PwCgT58+iImJ\
wZgxY3D11Vfj3nvvxYoVK1BSUoLHHnsMc+bMYYWPiIgogNgGhlrs/vvvx9///vdGj3/22We46aab\
AAAnT57E7NmzsWPHDkRHR+O+++7DsmXLEB7u/88ebItARHrBzztqLwyAFPT4gUhEesHPO2ov3AVM\
REREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6\
wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgERE\
REQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMM\
gEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIRERE\
pDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIRES6d3jXGbz5p89xeNeZQA+FqF0wABIRke7t23IC\
FRfs2LflRKCHQtQuGACpRU6cOIHp06ejV69eiIyMRO/evbFkyRI4HA7NdQcPHsQNN9wAs9mMtLQ0\
rFixIkAjJiLybsi4nojtZMKQcT0DPRSidhEe6AFQaDp69ChcLhdeeeUV9OnTB4cPH8bMmTNRWVmJ\
5557DgBgs9kwZswYjB49Gi+//DIOHTqEBx98EPHx8Zg1a1aA/wRERA0GjOiGASO6BXoYRO1GEEVR\
DPQgqGN49tlnsWbNGnz33XcAgDVr1uDRRx9FSUkJjEYjAGDRokXYuHEjjh496vd9bTYbLBYLrFYr\
4uLi2mTsRKRPh3edwb4tJzBkXM+gCID8vKP2wilgajVWqxWdOnVSvt+9ezdGjBihhD8AGDt2LIqK\
inDx4sVADJGISMPftX/cJEIdDQMgtYpjx47hr3/9K379618rj5WUlCA5OVlznfx9SUmJ13vZ7XbY\
bDbNFxFRS/kKb/6u/eMmEepoGABJY9GiRRAEweeX+/TtmTNnMG7cONx1112YOXPmZY9h6dKlsFgs\
yldaWtpl35OIQlNrVN58hbcBI7ph2l+GNzn9y00i1NFwDSBpnDt3Dj/++KPPa6688kplWre4uBg3\
3XQThg0bhjfeeAMGQ8PPFNOmTYPNZsPGjRuVxz777DOMHDkSFy5cQEJCgsf72+122O125XubzYa0\
tDSuiSHSoTf/9DkqLtgR28mEaX8Z3qJ7BNs6P1+4BpDaC3cBk0ZiYiISExP9uvbMmTO4+eabkZmZ\
iddff10T/gAgKysLjz76KGpraxEREQEA2LZtG9LT072GPwAwmUwwmUwt/0MQUYcxZFxPJbw1h3vo\
C/bgR9TeOAVMLXLmzBncdNNN6N69O5577jmcO3cOJSUlmrV9v/jFL2A0GjF9+nQcOXIE7733Hlat\
WoUFCxYEcOREFEr8naJ1xzV7RL6xAkgtsm3bNhw7dgzHjh3DFVdcoXlOXlVgsViwdetWzJkzB5mZ\
mejSpQueeOIJ9gAkojbnb+UwlKaHiVoT1wBS0OOaGCJqC4d3ncGunCKILlzWGsPWxM87ai+cAiYi\
opDSWj359m05AdEFCAZwdy/pDgMgERGFFH/W9/kTEuXWLiOmpHP6l3SHawCJiCjoqdfq+bO+Tx0S\
vYW71todzHWEFIpYASQioqDhrXLnHujUO4M9vSaldzwEg/Srr/u2daNpomDFCiAREQUNb5U7T1U/\
ufLmqHHCXlWnBLD8jcdhr64DRKDkeLnmvvkbj2uqdfkbj8NeVYf8jcdbXL1raa9CokBiACQioqDh\
LUx5mq6VQ50pKlw5pm3flhOwV9UB0G7ukJ9z1Dh9Tg23ZDqXjaYpFDEAEhFR0PAVptzD2ZBxPZG/\
8TicdS44aqRrUnrHo+JiKcIjDBg+uS+Kvy3Hrpwi9MlMVq4PjzDAUePE4V1nMGxib03g9GftoPt4\
UnrHo+R4OdcAUkjhGkAiIgo4f9biua+1GzCiG4zmMNQ5XMoUcMnxckAEImMiMGBENxwrKIXoAr79\
qhS7copgr6qD09lwvft6QnlnsD/TufJ4vv2qVJleJgoVDIBERBRw7uHOPRAe3nUGjhonTFHhSOkd\
rzw3ZFxPhEcYAEGq/rkHuD6ZyRAMQHi4AaJLeq8uabFeQ15zjp6T3ys8nP+UUujhf7VERBRw7sHN\
PRDKa/uM5jCUHC/XTNNGxkYAInCsoBQANAEutW88YuJN6HVNIoT6f/FqKhyNQp6/u4HV18lhcfhd\
fRHbyYRhE3u37l8KURtiACQiooBraipW/b2n5yAAoguaaVj5qLeKC3aUHC/HiCnpXit/+RuPa6Zx\
/WlH423sRKGAm0CIiCjoyJtB5CA2ZFxPzVm98nNrF+wCIE3x1tW6NPdQH/VmjjUqm0HU/QO9tW+R\
28PsXF+kvB/Ali/UcQiiKIqBHgSRLzwcnUi/3vzT56i4YEdsJ5MmAKqfAwBTVDiM5jDNFLJ6d+6u\
nCJpDaAAxCaYkNI7XtkgIhiktYIlx8uR0jsep478qLSSAeDxvdsKP++ovXAKmIiIgpY83ave+KF+\
zhQVDlNUOIZN7K1Mw+a89hEqLtjx/f5zqLhox+cffIsuabHKZhB55+6xM4cASFPHp478CADa8CdI\
wZLVPuqIWAGkoMefiInIVyUQALauO4JjBaXYeuhtfJT3OiYOm4nRg6coz8uvO7zrDPI3Hse/v3gL\
H+1Zi1szp+H2rAdQV+cCRCA8omEque+1yRgzvX+7/RkBft5R+2EFkIiIgp5c7ZMbOLs7ViBV9D7K\
ex0AsDH/NWzbv155Xj4TeMCIbvhk77v4aM9aAMAnBW+i6IcDgChNBYdFNPyzKB8jR9QRMQASEVHA\
NdWGRW76rD7zV61PZjL6dBuIu276jfLYR3vWKiHw+wPnsHbBLky64Tf4Z94ryjV3Zv8a6WmDYYoK\
x4gp6Rg2sbcyrSxP/frbIoYolHAXMBERBZz7EWyezuSVj3KrrqjF2gW7MGxib+W5MdP7Sz3/tvwK\
3dIT8MIrSwFAqfTdcs1UfPLlO8r3ADDv14uR0WkCKi7YlZNDADRq59Kc4+GIQgUrgEREFHBNNYKW\
OWrqUFcrHeW2K6dIc1KI3POvf9Q43O1WCVz4xh2a8Hdn9q+x8uW/NDm1LI+tqWuIQg03gVDQ46Jo\
Iv1RVwCLvy3HsYJShIUbUOdwAUL9RWJD+xdHjRP2qjoIBsBoDoe9qg7b9q/XhD7Z7UNn4JZrpgIC\
0PenycrOX1NUOGY8P8LjeJrahNJa+HlH7YUVQCIiCjrq0zXkfn11tS7EdjLhxqnpuHFqOkxRUtCr\
uGBHrd2J2E4m9MlMhrNO2sV7yzVTEWWK1dw3yhQrhT8AEIFv95ai1u4EADhrXV7X+rlXKLkukEId\
AyAREQVUU2GqT2YyBINUrZNDYfG35ZpmzS6nCEeNE99+VSpVCQFsO7AeVfYKzb2q7BWa3cHya+Wq\
onwcnPt4BozoppwCIlcnPU1RE4UKBkAiIgqopsLUmOn98duXRmp68h0rKG24QAAMYYIUCEXp++1H\
3sdH+Q3Tv+pKoLw72GAQGu4hSi1g1FVF9bnC7uN0rwgShRoGQCIiCqjmhCm5WhgdbwIAJPaIxY1T\
0+Fy1S9nF4Bj4n80rV5uHzoDq377bzw4ab7y2Ed71uK/rm248RfpCI8wAALQvX9nGM1hmvfbuu4I\
Xvrtdmxdd0RzKol6hzKngykUcRMIBT0uiibSN/WGELkKJxignOOr3hxyTPyP0gIGaNjwEdtJCoz/\
3P5Go1YwfQ2jlXOCw8OlMChXBNXHws1ZMxJA4w0hrblBhJ931F5YASQiooDzVUXzNPUqrwuUN4cA\
wPGzhzTh746sWcqGj4oLdphjjRib+QvcPnSGcs0LryxVzgSGKN3LWefShj/UB8N67hVLTgdTKGIA\
JCKiduMt6MkhT93bT+Zp6jW1bzyMZunEjr4/lcJg75SBmJj9AABg2bJl+OcXr8AU1XDewblTFXA5\
RdxyzVQlBN6aOQ29UwciPMKAcKNU/RNd0o5gwSBNMZuiwhEWYcDhXWeUaqQ8lsO7zmh2LBOFCk4B\
U9DjlAhRx+FtulRu5Cy64HUqVf1aQKrqyX0AzbFGnD9dgT6ZySip/i+qixJQV+eCQRCU9YHhEQal\
WigIwLHiQ+iTOhDGSGnjh1zFy994HPZqaUOJ+r3Uv5erj63dF5Cfd9ReWAEkIqJ24226dMCIbhgx\
Jd3nVKr6tfLvASmQnTtVAdEFnDryI1CcJAU9EXC5RKmFzLXJGH5XXwj1/+qJItC760CIgHL+r6NG\
6gdoNIcBorS+UP1e6t/3yUzmtC+FNFYAKejxJ2Ii8kaekq20OuByijCECYgwhcFRXQdRBAwGqQIo\
VwpTesej5Hi5cn240YBfr75JU12UN5uozyFu6v39udYf/Lyj9sIKIBERBSV/26s4apxSM2dIFT97\
VZ3S2DnCHKapFJYcL8e0vwxH7yFJEAxAr8GJALTrDPM3HleqgU1hQ2gKVQyAREQUdOQ1gd5O5lBf\
o96tm9g9VjNFO2xib0z7y3DNNO/hXWdQcrwcogsoOV4OoOHouZLj0gkj9qo6v0IddwBTqApv+hIi\
IqL2IU+pOmqcSp8/AEqVTT3Num/LCaV/HwBABGznqmE0hyG1b7zm5JABI7o1aicj7+Z980+fK1PD\
5lgjKi7aER5h8Bjq3Kd85S+iUMMKIBERBQ05pAHSDtsRU9IxbGJvj1U2ufp249R0pRWMs87ldUpW\
Xa2Tz/Y9VlCKigt25dfzpysAEYiMifAY7DjlSx0FK4BERBQ0vG3AcA9j7pU4uRoYFm5AZExEo7Do\
abOG/BrBAKl9zPFypRLoayeyfB+iUMYASEREQcPfKVV1JU6u5u3bckLpB1j8bblyTu++LSdQfakW\
dQ4X8jceV+7vHuZKjpc3mjoGoGn+LIdDTvtSqOMUMLXYbbfdhu7du8NsNqNr16649957UVxcrLnm\
4MGDuOGGG2A2m5GWloYVK1YEaLRE1JG4b76QQ+C5k1I/wG/3lirBreKCXWkArSZv/ACgbDjxNLUr\
30OeJub0L3UEDIDUYjfffDPef/99FBUV4R//+AeOHz+OyZMnK8/bbDaMGTMGPXr0QEFBAZ599ln8\
+c9/xquvvhrAURNRR+B+/Jq8I1hNfXZw35827Ap2p54K9jS1y+bP1BGxETS1mn/961+YOHEi7HY7\
IiIisGbNGjz66KMoKSmB0WgEACxatAgbN27E0aNH/b4vG6MSUVPkRs4QgPBwA8IiDBg2sbdmqtZb\
02b3x1u7uXNz8POO2gvXAFKruHDhAt555x1cf/31iIiIAADs3r0bI0aMUMIfAIwdOxbLly/HxYsX\
kZCQEKjhElEH48/pHfJUbv7G4z5bubivLyTqiDgFTJdl4cKFiI6ORufOnXHq1Cl89NFHynMlJSVI\
Tk7WXC9/X1JS4vWedrsdNptN80VE5IunKWH35tHu5wd7W8vH5s6kBwyApLFo0SIIguDzSz19+4c/\
/AGFhYXYunUrwsLCMG3aNFzuqoKlS5fCYrEoX2lpaZf7xyIiHVCHPrmKtyunSAmBckj01ldQ5h4m\
iToirgEkjXPnzuHHH3/0ec2VV16pmdaV/fDDD0hLS8MXX3yBrKwsTJs2DTabDRs3blSu+eyzzzBy\
5EhcuHDB6xSw3W6H3W5XvrfZbEhLS+OaGCLySV4HKIe7XTlFEF1SQ2l5t683gVz3p8Y1gNReuAaQ\
NBITE5GYmNii17pcUpsFObxlZWXh0UcfRW1trbIucNu2bUhPT/e5/s9kMsFkMrVoDEQUOIEOUZ7W\
AfrbtJnr/khvWAGkFtmzZw/27t2L7OxsJCQk4Pjx43j88cdRWlqKI0eOwGQywWq1Ij09HWPGjMHC\
hQtx+PBhPPjgg1i5ciVmzZrl93vxJ2Ki0KCuwDVVcQs2vsJrewZbft5Re2EFkFokKioK//znP7Fk\
yRJUVlaia9euGDduHB577DGlemexWLB161bMmTMHmZmZ6NKlC5544olmhT8iCh3tcUza4V1nkL/x\
OAA0avNyOXydQMLqIHVErABS0ONPxEQkU/r9wb+1fa2BFUDqiFgBJCKikDFkXE+lAthebVr8PZ+Y\
KJQwABIRUchgGCNqHewDSERERKQzDIBEREREOsMASERERKQzDIBEREREOsMASERERKQzDIBERERE\
OsMASERERKQzDIBEREREOsMASERERKQzDIBEREREOsMASERERKQzDIBEREREOsMASERERKQz4YEe\
AFFTRFEEANhstgCPhIiobcmfc/LnHlFbYQCkoFdRUQEASEtLC/BIiIjax48//giLxRLoYVAHJoj8\
MYOCnMvlQnFxMWJjYyEIQru/v81mQ1paGk6fPo24uLh2f//LFcrj59gDJ5THH8pjt1qt6N69Oy5e\
vIj4+PhAD4c6MFYAKegZDAZcccUVgR4G4uLiQu4fE7VQHj/HHjihPP5QHrvBwCX61Lb4XxgRERGR\
zjAAEhEREekMAyBRE0wmE5YsWQKTyRToobRIKI+fYw+cUB4/x07UNG4CISIiItIZVgCJiIiIdIYB\
kIiIiEhnGACJiIiIdIYBkIiIiEhnGACJvDhx4gSmT5+OXr16ITIyEr1798aSJUvgcDg01x08eBA3\
3HADzGYz0tLSsGLFigCNuLFnnnkG119/PaKioryeKnDq1ClMmDABUVFRSEpKwh/+8AfU1dW170A9\
ePHFF9GzZ0+YzWYMHToUX375ZaCH5NGuXbvw85//HKmpqRAEARs3btQ8L4oinnjiCXTt2hWRkZEY\
PXo0vv3228AM1s3SpUtx7bXXIjY2FklJSZg4cSKKioo019TU1GDOnDno3LkzYmJiMGnSJJSWlgZo\
xA3WrFmDQYMGKc2es7Ky8MknnyjPB+u4PVm2bBkEQcC8efOUx0Jp/BSaGACJvDh69ChcLhdeeeUV\
HDlyBCtXrsTLL7+MP/3pT8o1NpsNY8aMQY8ePVBQUIBnn30Wf/7zn/Hqq68GcOQNHA4H7rrrLsye\
Pdvj806nExMmTIDD4cAXX3yBv//973jjjTfwxBNPtPNItd577z0sWLAAS5Yswb59+zB48GCMHTsW\
ZWVlAR2XJ5WVlRg8eDBefPFFj8+vWLECq1evxssvv4w9e/YgOjoaY8eORU1NTTuPtLGdO3dizpw5\
yM/Px7Zt21BbW4sxY8agsrJSuWb+/Pn4+OOP8cEHH2Dnzp0oLi7GnXfeGcBRS6644gosW7YMBQUF\
+OqrrzBy5EjcfvvtOHLkCIDgHbe7vXv34pVXXsGgQYM0j4fK+CmEiUTktxUrVoi9evVSvn/ppZfE\
hIQE0W63K48tXLhQTE9PD8TwvHr99ddFi8XS6PHNmzeLBoNBLCkpUR5bs2aNGBcXp/kztbfrrrtO\
nDNnjvK90+kUU1NTxaVLlwZsTP4AIH744YfK9y6XS0xJSRGfffZZ5bHy8nLRZDKJ69evD8AIfSsr\
KxMBiDt37hRFURprRESE+MEHHyjXfPPNNyIAcffu3YEaplcJCQni2rVrQ2bcFRUVYt++fcVt27aJ\
N954ozh37lxRFEPv751CEyuARM1gtVrRqVMn5fvdu3djxIgRMBqNymNjx45FUVERLl68GIghNsvu\
3bsxcOBAJCcnK4+NHTsWNptNqaS0N4fDgYKCAowePVp5zGAwYPTo0di9e3dAxtRS33//PUpKSjR/\
FovFgqFDhwbln8VqtQKA8t94QUEBamtrNePv168funfvHlTjdzqdyMnJQWVlJbKyskJm3HPmzMGE\
CRM04wRC5++dQlt4oAdAFCqOHTuGv/71r3juueeUx0pKStCrVy/NdXKYKikpQUJCQruOsblKSko0\
4Q/Qjj8Qzp8/D6fT6XFcR48eDciYWkr+O/T0ZwnU3683LpcL8+bNw/DhwzFgwAAA0viNRmOj9aPB\
Mv5Dhw4hKysLNTU1iImJwYcffoirr74a+/fvD+pxA0BOTg727duHvXv3Nnou2P/eqWNgBZB0Z9Gi\
RRAEweeXe9A4c+YMxo0bh7vuugszZ84M0MglLRk/UVPmzJmDw4cPIycnJ9BD8Vt6ejr279+PPXv2\
YPbs2bjvvvvw9ddfB3pYTTp9+jTmzp2Ld955B2azOdDDIZ1iBZB055FHHsH999/v85orr7xS+X1x\
cTFuvvlmXH/99Y02d6SkpDTamSd/n5KS0joDdtPc8fuSkpLSaHdtW4+/KV26dEFYWJjHv9dAjaml\
5PGWlpaia9euyuOlpaW45pprAjSqxn73u9/h3//+N3bt2oUrrrhCeTwlJQUOhwPl5eWaalSw/P/C\
aDSiT58+AIDMzEzs3bsXq1atwj333BPU4y4oKEBZWRmGDBmiPOZ0OrFr1y787//+Lz799NOgHj91\
DAyApDuJiYlITEz069ozZ87g5ptvRmZmJl5//XUYDNqieVZWFh599FHU1tYiIiICALBt2zakp6e3\
2fRvc8bflKysLDzzzDMoKytDUlISAGn8cXFxuPrqq1vlPZrLaDQiMzMTubm5mDhxIgBpejI3Nxe/\
+93vAjKmlurVqxdSUlKQm5urBD6bzaZUrAJNFEU89NBD+PDDD7Fjx45GyxkyMzMRERGB3NxcTJo0\
CQBQVFSEU6dOISsrKxBD9snlcsFutwf9uEeNGoVDhw5pHnvggQfQr18/LFy4EGlpaUE9fuogAr0L\
hShY/fDDD2KfPn3EUaNGiT/88IN49uxZ5UtWXl4uJicni/fee694+PBhMScnR4yKihJfeeWVAI68\
wcmTJ8XCwkLxySefFGNiYsTCwkKxsLBQrKioEEVRFOvq6sQBAwaIY8aMEffv3y9u2bJFTExMFBcv\
XhzQcefk5Igmk0l84403xK+//lqcNWuWGB8fr9mtHCwqKiqUv1cA4vPPPy8WFhaKJ0+eFEVRFJct\
WybGx8eLH330kXjw4EHx9ttvF3v16iVWV1cHeOSiOHv2bNFisYg7duzQ/PddVVWlXPOb3/xG7N69\
u7h9+3bxq6++ErOyssSsrKwAjlqyaNEicefOneL3338vHjx4UFy0aJEoCIK4detWURSDd9zeqHcB\
i2LojZ9CDwMgkRevv/66CMDjl9qBAwfE7Oxs0WQyid26dROXLVsWoBE3dt9993kc/2effaZcc+LE\
CfHWW28VIyMjxS5duoiPPPKIWFtbG7hB1/vrX/8qdu/eXTQajeJ1110n5ufnB3pIHn322Wce/47v\
u+8+URSlVjCPP/64mJycLJpMJnHUqFFiUVFRYAddz9t/36+//rpyTXV1tfjb3/5WTEhIEKOiosQ7\
7rhD80NQoDz44INijx49RKPRKCYmJoqjRo1Swp8oBu+4vXEPgKE2fgo9giiKYjsWHImIiIgowLgL\
mIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiI\
dIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJ\
iIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhn\
GACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiI\
iEhn/j+T4Nec091cJAAAAABJRU5ErkJggg==\
"
  frames[1] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAOQpJREFUeJzt3Xl4lPW9///XJGQlzCSQjSUsoo0Lm6YgAaQiKdFaKy2odFGs\
LJUiPQr1CFWx/arFAx43jgUpVvRYRfQUrBUVCgI/NYAiUUBJlbJJmCBKZiCQyTL3749hbjIkbEoy\
y+f5uK65YO65Z/K+9XJ85f1ZbodlWZYAAABgjLhwFwAAAICWRQAEAAAwDAEQAADAMARAAAAAwxAA\
AQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAE\
AAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAA\
AMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAA\
AMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAA\
DEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAw\
DAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMO0CncBwLfh9/tVXl6uNm3ayOFw\
hLscADgly7J08OBBdejQQXFx9GEQHgRARLXy8nLl5eWFuwwAOGO7d+9Wp06dwl0GDEUARFRr06aN\
pMAXqdPpDHM1AHBqXq9XeXl59vcXEA4EQES14LCv0+kkAAKIKkxbQTgx+QAAAMAwBEAAAADDEAAB\
AAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQA\
ADAMARAwwftPS4/2CPwJADAeARAwwTuPSp7dgT8BAMYjAAImGHSH5MoL/AkAMF6rcBcAoAX0HRN4\
AAAgOoAAAADGIQACAAAYhgAIxApW+gIAThMBEIgVrPQFAJwmAiAQK0610pcOIQDgKAIgECv6jpHu\
2Hzi1b6n0yEkJAKAEQiAgAnef1ryHZISUqWaQycOeAwjA4ARCICACVbcL1UfkGqPSEcOSCvvb7rT\
13AYmW4gAMQsNoIGYt37TwfCnyTJklIypFpfIAi+PiVwODhs3HDD6Ed7HOsGsok0AMQUOoBArDja\
sSv9630hz7Xi/tDzan1S3WGVuuslWdLSO5vu8nH7OACIWQ7LsqxwFwF8U16vVy6XSx6PR06nM9zl\
hNejPTRv5TbNK5UmPTBXo7+eFejghXBIkp4t9Wn2+hqNL0jU+ILEQNC7Y3OLlwyYiO8tRAI6gEA0\
azBPrzR7hOaVSkrL0ezZs/XstrZNvMGyw58kzdvoV+mhTLp8AGAYAiAQzRqs2u3z8z9o0gNzA8cr\
tmj24hI9W1oTcvqzpTV2+JOkSWN+rj4Pbwud48fiDwCIeQRAIJodN09v9OjRmtTzkFRfI1l+zV5f\
Y4fA0PDn0KSfDNToP/yl8WeyFQwAxDwCIBCt3n86ENIG3RHSwRvdK0GT+iXaz2evr9EVz1aFdv5+\
MkCju399rMvXsOvH4g9EmOfX7tTAh1bq+bU7w10KEDNYBIKoZvRk6uA2LSkZkqXA+o4r7pWW3SPV\
Hm403Bs0qV+iRvc5GhBTMqS7dhz7LBaDIAINfGil9lQeUcf0FL079Ypwl/OtGf29hYhBBxCIVsFO\
naXAPn9HDtjhT5JG90mUM8kR8hZnkuNY+JMC7wl2/VIyAncLYe4fIsyEy7urY3qKJlzePdylADGD\
AAhEq+C9f4feKyVnBG7zdjT8SYE5f15faIPf67MaLQzRyvsDn5WYFgiSzP1DBGg47PuL/l307tQr\
9Iv+XU563qk+B8AxBEAg2vUdEwiBtUfsQ8cP/zbsBDZcGCIptAvI3D9EiDmrtmlP5RHNWbXtW513\
up8DmIYACMSCdx5VYCy4ia1e+iVq5ejWjRaGhITAlfeHLihhKxiE2cmGfX/z4kZ1n/a6fvPixlMO\
DzN8DDSNRSCIakymPur9p6WV9+vZ9ZWavbZKsvySjlvwoYbh0CHFxWvSpSkafUnK0e6hdWwRCItC\
EMG6T3td9ZYU75C2zbg63OWcMb63EAnoAALRLNipk1RavESz1/tOGP4Ul6DRfRIDnUCHJH+dZq/3\
qfRAqiRLcsQfG/5lOBgR7OpeHRTvCPx5POb8AaeHDiCimvG/SR+3Fcy8kv2a9/4RTeqfotG94o+d\
12Nk4M/Nr0iSnv0kQbNLqjT+xus0/sffa3I/QSBSPL92p+as2qYJl3e3F4Icfyz4vMpXp8ojtRG9\
ZYzx31uICHQA0WzmzJmjXr16yel0yul0qrCwUG+88Yb9enV1tSZOnKh27dopLS1NI0aMUEVFRRgr\
jkLHbQUz/uJ4zf/R0fCXkBro6vUYKY18Wtq9LvAeR7xGX3+t5t/QQeMvSSD8IeIFF3Lcs2SzLrj3\
DTvsNVzcEXwuiTl/wGmgA4hm89prryk+Pl7nnXeeLMvSs88+q1mzZmnjxo266KKLNGHCBL3++uta\
sGCBXC6XbrvtNsXFxendd9897Z/Bb9JHvf+0tOJ+qd4XCIMJSYFNofuOkV4ZI21ZLLXvJR3YcWzT\
6CMHjv7FOrYhNBCBnl+7U/csOTYXNRjwHnz9E1XX+nVN78BQ8Osfl+vqXh30xE8vDlepp4XvLUQC\
AiBaVNu2bTVr1iyNHDlSWVlZeuGFFzRyZGB4cuvWrbrgggtUUlKi/v37n9bn8UV6Gv7QVrLqA93A\
JGdgr79WqVLrdlLVV1Ld4cA+gkPvpRuIiBPs9rVrnagPPtyo1u27q3VSK/22OF/3Ltms4P/AUhLi\
dKTWr/SUBC24Nlt9+vQJZ9knxfcWIgFDwGgR9fX1WrhwoaqqqlRYWKgNGzaotrZWRUVF9jnnn3++\
OnfurJKSkhN+js/nk9frDXkY7XS2a7nox4Hwd9GPAw0/KdAhvGOzVPxAYAg5GP48u9kIGhElOLS7\
5e2/qcOmZ6XPVqvySK3mrNomR4Mb3RypDSx+2vP+mxr0wxt0y9QZYaoYiA4EQDSrTZs2KS0tTUlJ\
Sbr11lu1ePFiXXjhhXK73UpMTFR6enrI+Tk5OXK73Sf8vBkzZsjlctmPvLy8Zr6CCHc6oW3k09IP\
ZgXmAHYfGgh8V9wbeC14N5G+Y1j5i4g04fLuSj+8R9an/5Qk1W9+Q/6yVdrrOSL/ceNXhzatkHfD\
a6qt92vR8wtUWlra8gUDUYIAiGaVn5+v0tJSrVu3ThMmTNDo0aP1ySeffOPPmzZtmjwej/3YvXv3\
Waw2Cp1uaAsGxd3rjgW+4zUMg0CE+EX/Lip9Yry+P3K0Pin3aq/niCrWLpH34xUh5x3atEIHP3zN\
ft6+cLgmvvk128EAJ0AARLNKTEzUueeeq4KCAs2YMUO9e/fW448/rtzcXNXU1KiysjLk/IqKCuXm\
5p7w85KSkuxVxcGH0YKhTTr5UDDdPUS5za0vVurFP7S7fgc/fE2HNgVC4PHhr80l16i2+2BuAQec\
BAEQLcrv98vn86mgoEAJCQlaseLYb/FlZWXatWuXCgsLw1hhlDrVUDDdPUS5gi4ZSus5VG0uucY+\
dvDD1+R+8XeNwl9az6FKSYhTvCPwPgCNtQp3AYhd06ZN01VXXaXOnTvr4MGDeuGFF7Rq1Sq99dZb\
crlcGjNmjCZPnqy2bdvK6XRq0qRJKiwsPO0VwGhg0B3HVvACMeb5tTv12kflkqS0nkMlyQ59Vs1h\
+7xg+JOOLQrZsPNAS5YKRA0CIJrNvn37dNNNN2nv3r1yuVzq1auX3nrrLX3/+9+XJD366KOKi4vT\
iBEj5PP5VFxcrD/96U9hrjpK9R1Ddw8xpeGdPuas2qaG6z3Seg7Voc0rQsKfIzHVDn9B6SkJbAgN\
nAD7ACKqsZ8WEJsGPrRSeyqP2Pf8/fvRDqDUeM5fUMMOoKSIvR0c31uIBMwBBABElOfX7lSVr04O\
SfVWYBi3V0eXpMbhz5GYav+94cIQifl/wMkQAAEAYff82p0a+NBKe+i38kitXCkJ9m3f/j5pkM7z\
bGi04CP3p39stDAkGALX/OvLFr8OIFoQAIFIdTp3+QBiRPCOH8F5fx3TU/Tb4ny9O/UK/aJ/F/3q\
3v9WyWt/tW9m03C4t6nVwYc2rZCvrj4MVwJEBwIgEKm4NRsMEgx9Ey7vrl/072LP3Rv40Eo9+NxS\
/e/TT6m23i9Ljef6SU2HQP+XO1rwCoDoQgAEIhWbN8MgwdD3i/5d7GPBruDS8mS1K/iBpKbDX1Ba\
z6FyXnKN0lMS1KnwGt17c+A9DYeXAQSwChhRjdV0QOxquBWMJN379Guy2nVrdJ5DkiUpIc6h+350\
kXokH9Dm6gzNWbVNBV0y9PrH5aq3ImdVMN9biATsAwgAiEi/6N/F7gg+v3an4jK7qd4K7O8nSZ4j\
tbIke49Av2UdPb+LJh7dRsbtOaJ6S4p3iD0BgQYYAgYARLyH3ypTvRXo9v22OF+l9w3T/cN7qGN6\
inp1dNn7BQYF5xRe3auDOqan6A/X9ggZXgZMRwcQiETvP33s1m7c4QOwuVIS9Iv+Xezh4YIuGdqw\
84D+cG0PSYFFI8GFJAQ+4MQIgEAkargCmAAIwwUXb6SnJOi3xfmSji0QCQ7xzlm1TZLsrWQIf8DJ\
MQQMRCJWAAO24MbQrZNa2d2/Kl+d0lMS7CHeCZd3D9lKBsDJ0QEEIlHfMXT+gKMmXN49ZDVwMBB2\
TE/REz+9OORcOn/A6SEAAgAi2vHz+Y4PhADOHPsAIqqxnxaAhvsFRkMHkO8tRALmAAIAotrDb5Vp\
T+URPfxWWbhLAaIGARAAAMAwBEAAQFT7bXG+Oqan2FvEADg15gAiqjGXBkC04XsLkYAOIAAAgGEI\
gAAAAIYhAAIAABiGAAgAAGAYAiDQDA4sXKjPrhiqAwsXntFrAAC0BAIg0Az2z/uz6srLtX/en8/o\
NQAAWgIBEGgGmePHqVWHDsocP+6MXgMAoCWwDyCiGvtpAYg2fG8hEtABBAAAMAwBEAAAwDAEQAAA\
AMMQAIFvgK1cAADRjAAIfANs5QIAiGYEQEAn7uid6HhTW7nQFQQARAu2gUFUO1vbKXx2xVDVlZer\
VYcOOm/lilMeP9VnZI4fp/3z/qzM8eOUMWrUN64LQOxhGxhEAjqAgJru6G0feZ3qysulVq0adfrK\
Lu2vskv7h3T7MsePU5zLJX9VlfY9+pjqysvlvv8BOoIAgIhDBxBRrbl+kz6wcKHcv/+D/bxhOHTf\
/4BUX28fb6pjKIcjcMCyTqt7CMAcdAARCegAAkcF5/DtmfJbue9/QJ9WV9uvBbt5+x59LBD+HA7F\
uVxKvfhivdq3n93lyxw/ToqPlyxLcU4nt3wDAEQkAiCM1NSCjeDKXu/rr2vRV19peoVbSzyeY2+q\
r5f/8GFJUqv27RXXurX+d/Fi3b1pk/7n97+XJGWMGqXce+9Rqw4dlDZoUEteEgAAp40ACCM1tY1L\
5vhxksOhT6ur9bKnUoqL118PHAgNgbW1kgIdwVc+/VTP7y2XHNIrlZUqLS0N+RmH3nmHrWIAABGJ\
AAgjNbXoI2PUKMU5nbogOVm/aN9B8W3SJKlxCJS0xOPRXw8ckCxJljTKEacuW7cG5g7e/0BgHqDE\
EDAAICKxCARR7WxNpj6wcKH2z/uzUi++WIfeeUf+qiot+eqrQMg76ucZGRruch0Lf8cdlyRHcrKs\
6urAHEGnU9l33M42MABCsAgEkYAAiKjWHPsASrI7eMeHvbT4OB2q99vPG4Y/W3y8HImJso4cYQUw\
gEYIgIgEDAGj2cyYMUN9+/ZVmzZtlJ2dreHDh6usrCzknOrqak2cOFHt2rVTWlqaRowYoYqKihav\
NTgknHrxxarbt88+Ptzl0s8zMuznpwx/klRfL0diIsO/AICIRQBEs1m9erUmTpyotWvXavny5aqt\
rdWwYcNUVVVln3PHHXfotdde08svv6zVq1ervLxcP/nJT1q81oxRo3TeyhU6vHGjVFcX8tpwl0tp\
8aH/qaTFxzUd/hSY95d9x+06b+UKZYwaxS3iAAARhyFgtJgvv/xS2dnZWr16tQYPHiyPx6OsrCy9\
8MILGjlypCRp69atuuCCC1RSUqL+/fuf8jPP5lDKgYULte/Rx+SvqpLq6xXndMrv8TQaBg6yO4AO\
R2Dvv7o6OZKTdX7pxpDzzuR2cgBiH0PAiAR0ANFiPEdX0rZt21aStGHDBtXW1qqoqMg+5/zzz1fn\
zp1VUlLS5Gf4fD55vd6Qx9myf96f5fd41Co7W7n3TW8y/DXsBNqrgy3LDoFthg5t9LlNrTgGACCc\
CIBoEX6/X7fffrsGDhyoHj16SJLcbrcSExOVnp4ecm5OTo7cbneTnzNjxgy5XC77kZeXd9ZqbBjU\
3A882ORq32fyOofMCbRDYG2tVF8v75tvNhrqDQ4vsxoYABApCIBoERMnTtTmzZu18FvOg5s2bZo8\
Ho/92L1791mq8FhQk3TCLWCk0IUhjpQU/bWywT6B9fVs/AwAiHgEQDS72267Tf/4xz/09ttvq1On\
Tvbx3Nxc1dTUqLKyMuT8iooK5ebmNvlZSUlJcjqdIY+zbc1/P9Jk+Ltg66f2NjHBEGj5qgN3DPF6\
tbtvX4Z6AQBRgQCIZmNZlm677TYtXrxYK1euVLdu3UJeLygoUEJCglasOLYwoqysTLt27VJhYWFL\
l2sbPGWybujaRfHpLv08M1PDXS4lHx22Dg4TO1JSAiHQlS7V1+uGvE4a9r/PMdQLAIgKrAJGs/n1\
r3+tF154Qa+++qry8/Pt4y6XSykpKZKkCRMmaOnSpVqwYIGcTqcmTZokSXrvvfdO62ec7TuBZI4f\
Zwe40tJStZ48pckVvMFbvqm+Xp/W1mjIgw8S/ACcFlYBIxLQAUSzmTNnjjwejy6//HK1b9/efrz0\
0kv2OY8++qh++MMfasSIERo8eLByc3P1t7/9rcVr3T/vz6orLw+Zv9enTx9ljh+nOJdL/qqqRos7\
4tLSFOdyhYQ/9vwDAEQDOoCIas3ZAQxqah+/E+3tx55/AE6FDiAiAR1AQCffqqWpffyOPxbs/KVe\
fDELQQAAEY8OIKJapPwmTecPwOmKlO8tmI0OIHAWcLcPAEA0oQOIqMZv0gCiDd9biAR0AAEAAAxD\
AAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwB\
EAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARA\
AAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQCCCLSpbpGGvDNOiskXhLgUAEEMIgEAEm79pvvZW7dX8\
TfPDXQoAIIYQAIEINrbnWLVv3V5je44NdykAgBjisCzLCncRwDfl9Xrlcrnk8XjkdDrDXQ4AnBLf\
W4gEdAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEA\
AAxDAAQAADAMARDNZs2aNbrmmmvUoUMHORwOLVmyJOR1y7I0ffp0tW/fXikpKSoqKtJnn30WnmIB\
ADAIARDNpqqqSr1799aTTz7Z5OszZ87UE088oblz52rdunVq3bq1iouLVV1d3cKVAgBgllbhLgCx\
66qrrtJVV13V5GuWZemxxx7TPffco2uvvVaS9NxzzyknJ0dLlizRqFGjWrJUAACMQgcQYbF9+3a5\
3W4VFRXZx1wuly699FKVlJSc8H0+n09erzfkAQAAzgwBEGHhdrslSTk5OSHHc3Jy7NeaMmPGDLlc\
LvuRl5fXrHUCABCLCICIKtOmTZPH47Efu3fvDndJAABEHQIgwiI3N1eSVFFREXK8oqLCfq0pSUlJ\
cjqdIQ8AAHBmCIAIi27duik3N1crVqywj3m9Xq1bt06FhYVhrAwAgNjHKmA0m0OHDunzzz+3n2/f\
vl2lpaVq27atOnfurNtvv10PPPCAzjvvPHXr1k333nuvOnTooOHDh4evaAA4gY+WL9X6Ja+o3/CR\
6v39H4S7HOBbIQCi2XzwwQcaMmSI/Xzy5MmSpNGjR2vBggX6z//8T1VVVWn8+PGqrKzUoEGD9Oab\
byo5OTlcJQPACa1f8oq8+/dp/ZJXCICIeg7LsqxwFwF8U16vVy6XSx6Ph/mAZ2hR2SLN3zRfY3uO\
1fX514e7HCDina0OIN9biAQEQEQ1vkhP7FQBb9grw7S3aq/at26vZSOXhaFCwEx8byESsAgEiFHz\
N83X3qq9euLDJzTwxYEa9OIgLSpbZL8+tudYtW/dXmN7jg1536KyRRr2yrCQc4FY8dHypfrzxFv0\
0fKlzXI+EC0IgECMujj7Yvl2+eSr98lb45WnxqP5m+Y3eW5paan992BwPNG5QDRrOI/veE2FvZOd\
D0QzFoEAMeq1v76m3ct2y/d9n5wDnUqIS1Db5Lbq+WxPSVJyfLKq66t1z2P3yL3MrVGjR2ne9Hka\
23OsPXQMxJp+w0fa8/ik0Hl9wbD3z6fnaNVzT6tVYoK69r7Efh8QS5gDiKjGXJrGFpUt0qN/f1Tb\
n96uw7WHVeevU9uitsoYlNHo3Oq11Sp/q1x+y694R7ze+ds76tOnT8sXDbSw0tJS9enTR3+eeIu8\
+/fJmZmtfsNHasVf5sry++3zPIrX/3vp1bP6s/neQiSgAwjEmPmb5utQ9iElXJagun/WyZKlr/75\
lSSFhMAD7xyQd6VXDjkkSe2L2xP+YIR58+Zp3rx5mjRpUkhHMLiy952Fz6muplbr/71T/1/Zv3Vg\
1Aj1aueyu4DsBYhYQAcQUY3fpBtbVLZID6x9QJYsHXjngB3+JKldUTtlDMqwjzvkkCVLucNy9V+T\
/4vtYBDTPlq+VP83/ym9WLJBtdXVSkhOVv8unfTdbh0lSa0SEuTKzlXFvz/X+zu+0Luf7bDfe913\
e6p7p05KTEmRd/8+OeLiNPSWW79RCOR7C5GARSBAjAiu3pUkZ2LgfyoZgzLUrqidfc5X//xK2/9r\
ux0KLVlqV9ROaQPStKFiQ8sXDbSg9UtekUv1+m6HLNXX1an60CGt2rJVJWXbVOfzqfrQoSbD38Dz\
uqpjhktyWOo3fKQccXGy/H4WhiCqEQCBGNFw9e5vLvmN2rduL4ccjUJg/ZF6++/BjqAkLd2+VHet\
uavF6wZaSof88+WIi9PVQ76nQd/pZh9/97Mden/HF5LUZPi7tHtXyeFQ196XqPf3f6Cht9xqzxkE\
ohVzAIEY0XD1bnAo94G1D0gKdAIr360MCX/xKfGNFoYs3b5UBTkFDAUjJpWXbZXl98uzz63+3zlH\
lmXZYe/dz3bogx1fyFdbZ58/8Lyu6tu1k/z1dfb7Jan393/A/D9EPTqAQJRrOPS7bOQyXZ9/ve5a\
c5fuX3u/LAWm+B5450BI+JMCncAD7xxo9HnzN81nM2jEpH7DR8qZmS1ZDtX5fOrbtZMGntfVfr2p\
8BfUKilJNUeO2HsEskE0oh2LQBDVTJ9MvahskR5c96D8lt++q8f8TfPlrnKHhL+GC0HiU+JPOAws\
BfYHTIpPkqfGw23iEJM+Wr5U/5z/J/v5nFVrQ8JfUkIrTbi8f9NvdjhUNGaC3nnxf1VddVDJrdto\
4l9ePKOfb/r3FiIDHUAgis3fNF9+y684R5wd/vZW7T1h+GtX1E7d7urWaGFIw05gdX21PDUeuRJd\
bAaNmNRw+Pb944Z9pUAnMDgnsBHLCiz+cBztnTjooSA6MQcQiGJNzfsLdgRPtAWMdGw/wODrTe0T\
6Kv32beDY04gYkHwrh8d8s+X1HjBR1JCKzsMBo83HAaWJDkcjfYDBKIRQ8CIagylNLaobJHuWXSP\
dv9lt30ssyhT6YPSQ85zyCHPux7t/+d+WZYlS5Y639JZiZ0TQ85jGBixInjXD0dcnNb/e1ej1b59\
u3ZqchVw3255Sk5NkxyWBo266VsvAOF7C5GAIWAgxlyff70euP4BZV6eKSnQ+Ts+/F3U7iK1SWwj\
50Cn2g5tqzhHnNpe3laJnROVHJ+sOEfgqyE4tAzEguAikC/iU/Tetl328YYLPhouDHHExWnt9i90\
OO88DfrpjUpMTg1H2UCzYAgYiFFth7RVUrckpXRJ0UXtLtIXB7+Qt8YrS5a+rv7avgVc+qB0tTun\
nfwd/PbcwbSENDnk0G8u+Q3Dv4gZvb//A1lZHfTU2LHK7nqO9u34twZ079xomDf4fNOBKqU4XXr1\
7TWq3bVNLtVr/ZJX2AIGMYEACMSQRWWLNH/TfB2uPSy/5Vfrrq1196V32yEu+Hqwq/fEh0/IkqX/\
+Ml/SAosKqmqrZK3xqv2rdsT/hBz+vTpo/Hjx+vxh2fpsvxzdEmn3MYnORy68ec/0yuvvqb1u936\
j9/eqUu7dWLOH2IKcwAR1ZhLE2rYK8O0t2qvnIlOtU5oHbI45HQ1DIkEQMSij5Yv1XP//V/q4GoT\
crxVYpLkkOpqatQqMVF1Pp88itf/e+nVs/rz+d5CJKADCMSQsT3H6vEPH5dDjm8c4K7Pv57gh5j2\
zsLnjoU/h0OyrMCfDqnO55MUCIHOzGwV0fFDjGIRCBBDrs+/Xq0TWstT47G3cAFwHCsw/zW5dRsV\
jZkgZ2a23fELOn/AZRr35F+Y74eYRQAEYszYnmPtu4J8U9wKDrFs0E9vlDMzW137XGzP62vV6uj2\
Rw6Hisb+Wlf/5j/DWyTQzJgDiKjGXJrmEZxLyB6AiGXBfQGdmdnqN3ykHQabu+vH9xYiAR1AAI2c\
jS4iEOmC+wIGQx9DvjAJHUBENX6TBhBt+N5CJKADCAAAYBgCIAAAgGEIgAAAAIYhAAIAABiGAAgA\
AGAYAiAAAIBhCIAAAACGIQACAAAYhgAIAABgGAIgAACAYQiAAAAAhiEAAgAAGIYACAAAYBgCIAAA\
gGEIgAAAAIYhAAIAABiGAIiwe/LJJ9W1a1clJyfr0ksv1fr168NdEgAAMY0AiLB66aWXNHnyZN13\
33368MMP1bt3bxUXF2vfvn3hLg0AgJhFAERYPfLIIxo3bpx++ctf6sILL9TcuXOVmpqqv/zlL+Eu\
DQCAmEUARNjU1NRow4YNKioqso/FxcWpqKhIJSUlYawMAIDY1ircBcBc+/fvV319vXJyckKO5+Tk\
aOvWrU2+x+fzyefz2c+9Xm+z1ggAQCyiA4ioMmPGDLlcLvuRl5cX7pIAAIg6BECETWZmpuLj41VR\
URFyvKKiQrm5uU2+Z9q0afJ4PPZj9+7dLVEqAAAxhQCIsElMTFRBQYFWrFhhH/P7/VqxYoUKCwub\
fE9SUpKcTmfIAwAAnBnmACKsJk+erNGjR+u73/2u+vXrp8cee0xVVVX65S9/Ge7SAACIWQRAhNUN\
N9ygL7/8UtOnT5fb7VafPn305ptvNloYAgAAzh6HZVlWuIsAvimv1yuXyyWPx8NwMICowPcWIgFz\
AAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMA\
BAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQ\
AADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAA\
AADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEA\
AAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwBEs3nwwQc1YMAApaamKj09vclzdu3apauvvlqp\
qanKzs7WnXfeqbq6upYtFAAAw7QKdwGIXTU1NbruuutUWFiop59+utHr9fX1uvrqq5Wbm6v33ntP\
e/fu1U033aSEhAT98Y9/DEPFAACYwWFZlhXuIhDbFixYoNtvv12VlZUhx9944w398Ic/VHl5uXJy\
ciRJc+fO1V133aUvv/xSiYmJp/xsr9crl8slj8cjp9PZHOUDwFnF9xYiAUPACJuSkhL17NnTDn+S\
VFxcLK/Xqy1btoSxMgAAYhtDwAgbt9sdEv4k2c/dbneT7/H5fPL5fPZzr9fbfAUCABCj6ADijEyd\
OlUOh+Okj61btzbbz58xY4ZcLpf9yMvLa7afBQBArKIDiDMyZcoU3XzzzSc955xzzjmtz8rNzdX6\
9etDjlVUVNivNWXatGmaPHmy/dzr9RICAQA4QwRAnJGsrCxlZWWdlc8qLCzUgw8+qH379ik7O1uS\
tHz5cjmdTl144YVNvicpKUlJSUln5ecDAGAqAiCaza5du/T1119r165dqq+vV2lpqSTp3HPPVVpa\
moYNG6YLL7xQN954o2bOnCm326177rlHEydOJOQBANCM2AYGzebmm2/Ws88+2+j422+/rcsvv1yS\
tHPnTk2YMEGrVq1S69atNXr0aD300ENq1er0fjdhOwUA0YbvLUQCAiCiGl+kAKIN31uIBKwCBgAA\
MAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADA\
MARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADD\
EAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxD\
AAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwB\
EAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEA0ix07dmjMmDHq1q2bUlJS1L17d913332q\
qakJOe/jjz/WZZddpuTkZOXl5WnmzJlhqhgAAHO0CncBiE1bt26V3+/XU089pXPPPVebN2/WuHHj\
VFVVpYcffliS5PV6NWzYMBUVFWnu3LnatGmTbrnlFqWnp2v8+PFhvgIAAGKXw7IsK9xFwAyzZs3S\
nDlz9O9//1uSNGfOHN19991yu91KTEyUJE2dOlVLlizR1q1bT+szvV6vXC6XPB6PnE5ns9UOAGcL\
31uIBAwBo8V4PB61bdvWfl5SUqLBgwfb4U+SiouLVVZWpgMHDjT5GT6fT16vN+QBAADODAEQLeLz\
zz/X7Nmz9atf/co+5na7lZOTE3Je8Lnb7W7yc2bMmCGXy2U/8vLymq9oAABiFAEQZ2Tq1KlyOBwn\
fRw/fLtnzx5deeWVuu666zRu3Lhv9fOnTZsmj8djP3bv3v2tPg8AABOxCARnZMqUKbr55ptPes45\
55xj/728vFxDhgzRgAEDNG/evJDzcnNzVVFREXIs+Dw3N7fJz05KSlJSUtI3qBwAAAQRAHFGsrKy\
lJWVdVrn7tmzR0OGDFFBQYGeeeYZxcWFNpwLCwt19913q7a2VgkJCZKk5cuXKz8/XxkZGWe9dgAA\
EMAQMJrFnj17dPnll6tz5856+OGH9eWXX8rtdofM7fvZz36mxMREjRkzRlu2bNFLL72kxx9/XJMn\
Tw5j5QAAxD46gGgWy5cv1+eff67PP/9cnTp1CnktuPOQy+XSsmXLNHHiRBUUFCgzM1PTp09nD0AA\
AJoZ+wAiqrGfFoBow/cWIgFDwAAAAIYhAAIAABiGAAgAAGAYAiAAAIBhCIAAAACGIQACAAAYhgAI\
AABgGAIgAACAYQiAAAAAhiEAAgBw1OY1e/Tc797V5jV7wl0K0KwIgAAAHPXhmzt08GufPnxzR7hL\
AZoVARAAAAW6fzXV9UpKbaVLruza6DU6g4glBEAAABTo/vkO1ykxOV6SQgIfnUHEGgIgAMA4TXX0\
Lrmyq9q0TdIlV3bV2iXbdPBrn9Yu2dbotRO9H4gmrcJdAAAALS3Y0Vv9YpnWLtmm/sO7q8fgjuox\
uKMk2cEvqOFrDd//4Zs7Qo4D0YIOIAAgpp2o2yeHJEvyHa5rNLTb+aJ2kkOqr/Vr2dNbmnx/Umor\
1VTX0wVEVCIAAgBiWlPz93oM7qiklFb6Yv/nkkNKbpOoP/16pZY9vUWStGvLV5Il1dX69fmGCn36\
ry2N3p+YHN9keASiAQEQABDTjp+/F7Q7rkQL331En+xfrS93HpTllz57v0Kb1+xRra/ePm979Vot\
fPcRbat5J6SbeKLPBaKBw7IsK9xFAN+U1+uVy+WSx+OR0+kMdzkAosDmNXu0+Nnl+t8Vs+Q7UifL\
L32vx3D1zy+WJLVKiFNdrV+StPZfb+lT7wpJ0pFDtfpRr4nq1PZctWmbpJv+OPAb/Xy+txAJ6AAC\
AIzy4Zs71Dahsy7t9kNZgZyn1ZuXaG3ZW5J0LPyVvaX3/vV3fbnroPbtPKjvdrhKndqeK0ec6Poh\
6hEAAQBGueTKrnLESf3zi/W9HsPt4w1D4Nqyt7R68xLV+vyyrECHsN93hqlN2yQNHpXPyl9EPbaB\
AQAYYfOaPfb2LucW5Mi9rVLXDBspOaTVm5ZICoTA9f9apiM1h+33BYeHs7q00fXT+oajdOCsowMI\
ADBC8E4fvsN1+nxDhXK7p+vLXQfV/zuhncCmwp8kpWensvkzYgYBEABghODefXIosOL3gwrp6DLI\
/vnFSklMDTk/JTHVDn9SYIVw8O4gBEFEOwIgAMAIPQZ31NhHBut7P81Xm7ZJinM47NfWlr0V0vmT\
Ap3A4JzAhmqr6+27iBACEa0IgACAmNVw377g3yUFtnA5mv+CCz6CGnYCGy4MCfIHd0+zxCbQiFoE\
QABAzGp4F5Dj7wji91uNwt/3egzXb6757xOuDpak876bo6TUVkpKbcV2MIharAIGAMSsS67sqg/f\
3KFLruyq8s8qdaiyQsltEvXc797VJ/tXa82WJUpIilOtzx+y4CP4ZzAcBv+8ZthIDRtzkaRAdzEY\
JtkWBtGGDiAAIGb1GNxRN/1xoHoM7ij3tkpZfmn/7oP69F9btPSdl5TVuY389VZI+Avqn1+sIb1+\
bD9/Z+uriss+YA8pN3WPYSBaEAABAEYI3rv33IIcXfCdi3TTz38pSRr7y1s14IIrG7/BIV3W+wf6\
Xo/hcjikm37+Sx3e1toOfdwLGNGMewEjqnFPTQDfRmlpqfr06aP5k9fId7hOkhQX55DfbykptZX6\
D++uD9/codTuVRo5Zpjd+bvkyq7feNiX7y1EAuYAAgCM1adPn9ADDql7Qbbc2yrtkNcw6B3/HIhW\
BEAAgJEadvP6D++uNQvLZPkl97bKwDYxJzmfEIhoxxxAAICRGi7i6DG4owaPyj/pnD4WfSCW0AEE\
ABip4RYx0qmHd48/H4hmLAJBVGMyNYBow/cWIgFDwAAAAIYhAAIAIl7De/oC+PYIgACAiMcCDODs\
IgACACIed90Azi5WAQMAIh4bMANnFx1ANJsf/ehH6ty5s5KTk9W+fXvdeOONKi8vDznn448/1mWX\
Xabk5GTl5eVp5syZYaoWAABzEADRbIYMGaJFixaprKxM//d//6dt27Zp5MiR9uter1fDhg1Tly5d\
tGHDBs2aNUu///3vNW/evDBWDQBA7GMfQLSYv//97xo+fLh8Pp8SEhI0Z84c3X333XK73UpMTJQk\
TZ06VUuWLNHWrVtP6zPZTwtAtOF7C5GADiBaxNdff62//vWvGjBggBISEiRJJSUlGjx4sB3+JKm4\
uFhlZWU6cOBAk5/j8/nk9XpDHgAA4MwQANGs7rrrLrVu3Vrt2rXTrl279Oqrr9qvud1u5eTkhJwf\
fO52u5v8vBkzZsjlctmPvLy85iseAIAYRQDEGZk6daocDsdJHw2Hb++8805t3LhRy5YtU3x8vG66\
6SZ9m1kH06ZNk8fjsR+7d+8+G5cFAIBR2AYGZ2TKlCm6+eabT3rOOeecY/89MzNTmZmZ+s53vqML\
LrhAeXl5Wrt2rQoLC5Wbm6uKioqQ9waf5+bmNvnZSUlJSkpK+nYXAQCA4QiAOCNZWVnKysr6Ru/1\
+/2SAvP4JKmwsFB33323amtr7XmBy5cvV35+vjIyMs5OwQAAoBGGgNEs1q1bp//5n/9RaWmpdu7c\
qZUrV+qnP/2punfvrsLCQknSz372MyUmJmrMmDHasmWLXnrpJT3++OOaPHlymKsHACC2EQDRLFJT\
U/W3v/1NQ4cOVX5+vsaMGaNevXpp9erV9hCuy+XSsmXLtH37dhUUFGjKlCmaPn26xo8fH+bqAQCI\
bewDiKjGfloAog3fW4gEdAABAAAMQwAEAAAwDKuAEdWCMxi4IwiAaBH8vmIGFsKJAIiodvDgQUni\
jiAAos7BgwflcrnCXQYMxSIQRDW/36/y8nK1adNGDofjlOd7vV7l5eVp9+7dMTH5muuJbLF2PVLs\
XVM4rseyLB08eFAdOnRQXBwzsRAedAAR1eLi4tSpU6czfp/T6YyJ/3kFcT2RLdauR4q9a2rp66Hz\
h3DjVw8AAADDEAABAAAMQwCEUZKSknTffffZdyOJdlxPZIu165Fi75pi7XqA08UiEAAAAMPQAQQA\
ADAMARAAAMAwBEAAAADDEAABAAAMQwCEEXbs2KExY8aoW7duSklJUffu3XXfffeppqYm5LyPP/5Y\
l112mZKTk5WXl6eZM2eGqeJTe/DBBzVgwAClpqYqPT29yXN27dqlq6++WqmpqcrOztadd96purq6\
li30DDz55JPq2rWrkpOTdemll2r9+vXhLum0rFmzRtdcc406dOggh8OhJUuWhLxuWZamT5+u9u3b\
KyUlRUVFRfrss8/CU+xpmDFjhvr27as2bdooOztbw4cPV1lZWcg51dXVmjhxotq1a6e0tDSNGDFC\
FRUVYar45ObMmaNevXrZmz0XFhbqjTfesF+PpmsBzhYCIIywdetW+f1+PfXUU9qyZYseffRRzZ07\
V7/73e/sc7xer4YNG6YuXbpow4YNmjVrln7/+99r3rx5Yaz8xGpqanTddddpwoQJTb5eX1+vq6++\
WjU1NXrvvff07LPPasGCBZo+fXoLV3p6XnrpJU2ePFn33XefPvzwQ/Xu3VvFxcXat29fuEs7paqq\
KvXu3VtPPvlkk6/PnDlTTzzxhObOnat169apdevWKi4uVnV1dQtXenpWr16tiRMnau3atVq+fLlq\
a2s1bNgwVVVV2efccccdeu211/Tyyy9r9erVKi8v109+8pMwVn1inTp10kMPPaQNGzbogw8+0BVX\
XKFrr71WW7ZskRRd1wKcNRZgqJkzZ1rdunWzn//pT3+yMjIyLJ/PZx+76667rPz8/HCUd9qeeeYZ\
y+VyNTq+dOlSKy4uznK73faxOXPmWE6nM+QaI0W/fv2siRMn2s/r6+utDh06WDNmzAhjVWdOkrV4\
8WL7ud/vt3Jzc61Zs2bZxyorK62kpCTrxRdfDEOFZ27fvn2WJGv16tWWZQXqT0hIsF5++WX7nE8/\
/dSSZJWUlISrzDOSkZFhzZ8/PyauBfgm6ADCWB6PR23btrWfl5SUaPDgwUpMTLSPFRcXq6ysTAcO\
HAhHid9KSUmJevbsqZycHPtYcXGxvF6v3fmIFDU1NdqwYYOKiorsY3FxcSoqKlJJSUkYK/v2tm/f\
LrfbHXJtLpdLl156adRcm8fjkST7v5cNGzaotrY25JrOP/98de7cOeKvqb6+XgsXLlRVVZUKCwuj\
+lqAb4MACCN9/vnnmj17tn71q1/Zx9xud0hYkmQ/d7vdLVrf2RBN17N//37V19c3WW+k1XqmgvVH\
67X5/X7dfvvtGjhwoHr06CEpcE2JiYmN5p5G8jVt2rRJaWlpSkpK0q233qrFixfrwgsvjMprAc4G\
AiCi2tSpU+VwOE762Lp1a8h79uzZoyuvvFLXXXedxo0bF6bKm/ZNrgdoThMnTtTmzZu1cOHCcJfy\
reTn56u0tFTr1q3ThAkTNHr0aH3yySfhLgsIm1bhLgD4NqZMmaKbb775pOecc8459t/Ly8s1ZMgQ\
DRgwoNHijtzc3EYr/4LPc3Nzz07Bp3Cm13Myubm5jVbRtvT1nK7MzEzFx8c3+c8/0mo9U8H6Kyoq\
1L59e/t4RUWF+vTpE6aqTs9tt92mf/zjH1qzZo06depkH8/NzVVNTY0qKytDOmeR/O8rMTFR5557\
riSpoKBA77//vh5//HHdcMMNUXctwNlAAERUy8rKUlZW1mmdu2fPHg0ZMkQFBQV65plnFBcX2gAv\
LCzU3XffrdraWiUkJEiSli9frvz8fGVkZJz12ptyJtdzKoWFhXrwwQe1b98+ZWdnSwpcj9Pp1IUX\
XnhWfsbZkpiYqIKCAq1YsULDhw+XFBh6XLFihW677bbwFvctdevWTbm5uVqxYoUd+Lxer92JikSW\
ZWnSpElavHixVq1apW7duoW8XlBQoISEBK1YsUIjRoyQJJWVlWnXrl0qLCwMR8lnzO/3y+fzxcS1\
AN9IuFehAC3hiy++sM4991xr6NCh1hdffGHt3bvXfgRVVlZaOTk51o033mht3rzZWrhwoZWammo9\
9dRTYaz8xHbu3Glt3LjR+sMf/mClpaVZGzdutDZu3GgdPHjQsizLqqurs3r06GENGzbMKi0ttd58\
800rKyvLmjZtWpgrb9rChQutpKQka8GCBdYnn3xijR8/3kpPTw9ZxRypDh48aP/zl2Q98sgj1saN\
G62dO3dalmVZDz30kJWenm69+uqr1scff2xde+21Vrdu3awjR46EufKmTZgwwXK5XNaqVatC/ls5\
fPiwfc6tt95qde7c2Vq5cqX1wQcfWIWFhVZhYWEYqz6xqVOnWqtXr7a2b99uffzxx9bUqVMth8Nh\
LVu2zLKs6LoW4GwhAMIIzzzzjCWpyUdDH330kTVo0CArKSnJ6tixo/XQQw+FqeJTGz16dJPX8/bb\
b9vn7Nixw7rqqquslJQUKzMz05oyZYpVW1sbvqJPYfbs2Vbnzp2txMREq1+/ftbatWvDXdJpefvt\
t5v8dzF69GjLsgJbwdx7771WTk6OlZSUZA0dOtQqKysLb9EncaL/Vp555hn7nCNHjli//vWvrYyM\
DCs1NdX68Y9/HPILVSS55ZZbrC5duliJiYlWVlaWNXToUDv8WVZ0XQtwtjgsy7JasOEIAACAMGMV\
MAAAgGEIgAAAAIYhAAIAABiGAAgAAGAYAiAAAIBhCIAAAACGIQACAAAYhgAIAABgGAIgAACAYQiA\
AAAAhiEAAgAAGIYACAAAYBgCIAAAgGEIgAAAAIYhAAIAABiGAAgAAGAYAiAAAIBhCIAAAACGIQAC\
AAAYhgAIAABgGAIgAACAYQiAAAAAhiEAAgAAGIYACAAAYBgCIAAAgGEIgAAAAIYhAAIAABiGAAgA\
AGAYAiAAAIBhCIAAAACGIQACAAAY5v8Hf0/s1WeYjUQAAAAASUVORK5CYII=\
"
  frames[2] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAJFNJREFUeJzt3X2QXXWd7/tPR9JNnrohENLkJtFAe4AcAauiQKtjKWbooYgl\
0+A4M3U0KOoMBqogXGdIycP5Q41Fe1C0EOZeZ8C5VTwM5wasTqltKmKoM0bUeFMCmhz7DJpcQjdh\
MN2hNZ2Y7PsHN3to6CRNSPfO7t/rVbWr2Wuv3nxXpVi8s/ZaazdUKpVKAAAoxpRaDwAAwMQSgAAA\
hRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIUR\
gAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAA\
AIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACF\
EYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGA\
AACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhTmh1gPA0Tpw4EB27NiR\
WbNmpaGhodbjAIxZpVLJ7t27M2/evEyZ4lgME08AUrd27NiRBQsW1HoMgKO2ffv2zJ8/v9ZjUCAB\
SN2aNWtWkpd3oM3NzTWeBmDsBgcHs2DBgup+DCaaAKRuHfzYt7m5WQACdcnpK9SKEw8AAAojAAEA\
CiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAKGO9Pb2HtP1ACiTAIQ60d3dna6urvT09Bx2vZ6e\
nnR1daW7u3uCJgOg3ghAqAO9vb1Zu3ZtkmTNmjWHjMCenp6sWbMmSbJ27VpHAgEYlQCEOtDW1pbO\
zs7q89Ei8JXxlySdnZ1pa2ubsBkBqB8CEOpER0fHISNwtPjr6OiY8BkBqA8NlUqlUush4GgMDg6m\
paUlAwMDaW5urvU4E2ZE7O3ckhkvPp2h2f85mXN2EvEH9aDU/RfHjxNqPQDw+hyMuzX/9a+SvS9l\
KEl2b0zmnC3+ABgTHwFDHero6MiMl9OvasaMGeIPgDERgFCHenp6MrR35NkbQ0NDR7xFDAAkAhDq\
zqsv+JjR2FD958PdIgYADhKAUEdGxN/sM9K5uCl33Phf0vnF/7jpswgE4EhcBAJ1oqenJ2v+4YvJ\
c08mp5+bzv/9zuo5fwfP/DsYhwd/OicQgNE4Agh1oLe39+Woe+7JZO9L6Zzz29fE3Wj3CfRNIACM\
RgBCHWhra8uyZctePvL3jnnp+OQto673yghctmyZbwIBYFRuBE3dKvFGqr29vWOKurGuB9RGifsv\
ji+OAHLM3X333TnvvPPS3Nyc5ubmtLe357vf/W719T179mTFihU55ZRTMnPmzFxxxRXp7++v4cT1\
Y6xRJ/4AOBwByDE3f/78fOlLX8qmTZvys5/9LBdffHE+9KEP5emnn06S3HDDDenu7s7DDz+cDRs2\
ZMeOHSPOXQMAxpePgJkQs2fPTldXV6688srMmTMn999/f6688sokyZYtW3LOOedk48aNueiii8b8\
nj5CAeqV/Re15ggg42r//v158MEHMzQ0lPb29mzatCn79u3L0qVLq+ucffbZWbhwYTZu3FjDSYHJ\
YKxXvrtCntIJQMbFk08+mZkzZ6apqSl/+7d/m0ceeSSLFy9OX19fGhsbc9JJJ41Yf+7cuenr6zvs\
ew4PD2dwcHDEY9L66T8mX3nbyz+BMenu7k5XV9cRb4Te09OTrq6udHd3H3Y9mMwEIOPirLPOyubN\
m/PEE0/kmmuuyfLly/PLX/7yDb3n6tWr09LSUn0sWLDgGE17HPofX0kGtr/8Ezii3t7erF27Nsnh\
vw3nld+ms3btWkcCKZYAZFw0Njamra0tS5YsyerVq3P++efnzjvvTGtra/bu3Ztdu3aNWL+/vz+t\
ra2Hfc9Vq1ZlYGCg+ti+ffs4bkGNveeGpGXByz+BI2pra3vNjdBfHYGv/h7tzs5OV8xTLF8Fx4Q4\
cOBAhoeHs2TJkkydOjXr16/PFVdckSTZunVrtm3blvb29sO+R1NTU5qamiZi3Np759UvP4AxO/jt\
OKN9JeJo8eerEimZAOSYW7VqVS699NIsXLgwu3fvzv33358f/vCH6enpSUtLS66++uqsXLkys2fP\
TnNzc6677rq0t7e/riuAAUbz6ghcfuvX8/ub705l33DefMr0vLvtVPEHEYCMg+effz4f+9jH8txz\
z6WlpSXnnXdeenp68qd/+qdJkq985SuZMmVKrrjiigwPD6ejoyPf+MY3ajw1MFm8MgKHhvcn2Z8k\
+e2//z7/7e/EHyTuA0gdcx8t4HBWrlyZ//MHv6o+b5jalMGfPlq7gV7B/otacxEIAJNOT09PhoaG\
Riyr7Bs+4i1ioBQCEIBJ5dUXfDRMffniscYTGg57ixgoiXMAAZg0Xh1/11z1V/nXPfPz7hP/3wz8\
6l+TjLw6GEolAAGYFI50q5eenrmj3iIGSuQjYADqXm9v7xHv89fR0fGam0X7JhBKJQABqHttbW1Z\
tmxZksPf5PmVEbhs2TLfBEKx3AaGuuU2CsCr9fb2jinqxrreeLH/otYcAQRg0hhr1DnyR+kEIABA\
YQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEE\
IABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAA\
QGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIJNeb2/vMV0P\
AOqdAGRS6+7uTldXV3p6eg67Xk9PT7q6utLd3T1BkwFA7QhAJq3e3t6sXbs2SbJmzZpDRmBPT0/W\
rFmTJFm7dq0jgQBMegKQSautrS2dnZ3V56+MwN89+GC2XnhRvnnW2Xmgq6u6TmdnZ9ra2iZ8VgCY\
SCfUegAYTx0dHUlSPcL3QFdXtn3yk3nPjJn5H0MvZd3ulzLlpd1pOvPMdHZ2VtcHgMlMADLpvTIC\
9/zqV1k39Pv869BQfn+gkiQ58ZxzxB8ARfERMMfc6tWr8853vjOzZs3Kaaedlssvvzxbt24dsc6e\
PXuyYsWKnHLKKZk5c2auuOKK9Pf3j9tMHR0d6ezszInnnJMk1fhLkr/67GfFHwBFEYAccxs2bMiK\
FSvy4x//OOvWrcu+fftyySWXZGhoqLrODTfckO7u7jz88MPZsGFDduzYMeJ8vfHQ0dGR2eedN2LZ\
9CkN4g+A4jRUKpXKkVeDo7dz586cdtpp2bBhQ9773vdmYGAgc+bMyf33358rr7wySbJly5acc845\
2bhxYy666KIxve/g4GBaWloyMDCQ5ubmI67/yqt9h//X/8qeX/0qJ55zjiOAwIR7vfsvONacA8i4\
GxgYSJLMnj07SbJp06bs27cvS5cura5z9tlnZ+HChYcNwOHh4QwPD1efDw4OjnmGV8Zfksw+77wM\
nXlmkv+4QEQEAlAKHwEzrg4cOJDrr78+7373u/O2t70tSdLX15fGxsacdNJJI9adO3du+vr6Dvle\
q1evTktLS/WxYMGCMc3w6vjr7OzMHXfccchbxADAZCcAGVcrVqzIU089lQcffPANv9eqVasyMDBQ\
fWzfvv2IvzNa/B080nfwwpCDRCAApfARMOPm2muvzdq1a/P4449n/vz51eWtra3Zu3dvdu3aNeIo\
YH9/f1pbWw/5fk1NTWlqahrzv7+3t/eQ8XfQq+8TuGbNmpx55pluBg3ApOYIIMdcpVLJtddem0ce\
eSQ/+MEPsmjRohGvL1myJFOnTs369eury7Zu3Zpt27alvb39mM3R1taWZcuWJRk9/g565ZHAZcuW\
iT8AJj1XAXPMfeYzn8n999+fb3/72znrrLOqy1taWjJt2rQkyTXXXJPvfOc7ue+++9Lc3Jzrrrsu\
SfKjH/1ozP+esV5F19vbO6aoG+t6AG+Uq4CpNQHIMdfQ0DDq8nvvvTdXXXVVkpdvBH3jjTfmgQce\
yPDwcDo6OvKNb3zjsB8Bv5odKFCv7L+oNQFI3bIDBeqV/Re15hxAAIDCCEAAgMIIQACAwghAAIDC\
CEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghA\
AIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACA\
wghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMII\
QACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEDGxeOPP54PfvCDmTdvXhoa\
GvLoo4+OeL1SqeTWW2/N6aefnmnTpmXp0qX59a9/XZthAaAwApBxMTQ0lPPPPz933XXXqK/ffvvt\
+drXvpZ77rknTzzxRGbMmJGOjo7s2bNngicFgPKcUOsBmJwuvfTSXHrppaO+VqlU8tWvfjU333xz\
PvShDyVJ/vmf/zlz587No48+mr/8y7+cyFEBoDiOADLhnnnmmfT19WXp0qXVZS0tLbnwwguzcePG\
Gk4GAGVwBJAJ19fXlySZO3fuiOVz586tvjaa4eHhDA8PV58PDg6Oz4AAMMk5AkjdWL16dVpaWqqP\
BQsW1HqkCfEvW/8ll/z3S/IvW/+l1qMAMEkIQCZca2trkqS/v3/E8v7+/upro1m1alUGBgaqj+3b\
t4/rnMeLbz75zTw39Fy++eQ3az0KAJOEAGTCLVq0KK2trVm/fn112eDgYJ544om0t7cf8veamprS\
3Nw84lGCT577yZw+4/R88txP1noUACYJ5wAyLl566aX09vZWnz/zzDPZvHlzZs+enYULF+b666/P\
5z//+bz1rW/NokWLcsstt2TevHm5/PLLazf0ceovzvqL/MVZf1HrMQCYRAQg4+JnP/tZ3v/+91ef\
r1y5MkmyfPny3Hffffm7v/u7DA0N5dOf/nR27dqV97znPfne976XE088sVYjA0AxGiqVSqXWQ8DR\
GBwcTEtLSwYGBor5OBiYHOy/qDXnAAIAFEYAAgAURgACABRGAAIAFEYAQp165W12jsV6AJRDAEId\
6u7uTldXV3p6eg67Xk9PT7q6utLd3T1BkwFQDwQg1Jne3t6sXbs2SbJmzZpDRmBPT0/WrFmTJFm7\
dq0jgQBUCUCoM21tbens7Kw+Hy0CXxl/SdLZ2Zm2trYJmxEmE6dbMBkJQKhDHR0dh4zA0eKvo6Nj\
wmeEycDpFkxWvgoO6tTBqDsYewcjcGhoqLqO+IOj9+rTLZKM+t/Tq0+3OOeccxxx57jnCCDUsVce\
CXz4fz6c+/6f+/Lw/3w4ifiDN8rpFkxmvguYuuW7NP/DWZeflZ0DO6vPpzRNyQvfe6GGE8HkcajT\
Kt7I6Rb2X9Saj4ChzvX09IyIvyQ5MHwgPT09jgDCMXCo0y02fvv/rq7zX7/xf/jvjbriI2CoYweP\
QJzcdHKSl4/8JUlDGg57ixjg9Xn1hVebH1tX/edz57eKP+qOAIQ69cqPn5a+eWkeuOmBvPC9F/LA\
TQ/kyv90ZZLD3ycQeH06OjoyY8aMJMkfBgeTJI0nvClntc6p5VhwVAQg1KHDnXt0uFvEAEfvlVfZ\
T/v/z9vb+8f92dq383C/Bscl5wBCnent7T3iieejnbN05plnujoRjtKr/9L19vf/6YhbLjnnlnrj\
CCDUmba2tixbtizJ4a86fOWRwGXLlok/OEqjHXG/4447HGmnrrkNDHWr9Nso9Pb2jinqxroe8FpH\
utXL0d4KpvT9F7XnCCDUqbFGnfiDozPW0y1efSTQdwJTDwQgAIzC6RZMZj4Cpm75CAWYCONxuoX9\
F7XmCCAAHIbTLZiMBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBh\
BCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQg\
AEBhBCAAQGEEIABAYQQgAEBhBCA1ddddd+Utb3lLTjzxxFx44YX5yU9+UuuRAGDSE4DUzEMPPZSV\
K1fmtttuy89//vOcf/756ejoyPPPP1/r0QBgUhOA1Mwdd9yRT33qU/n4xz+exYsX55577sn06dPz\
T//0T7UeDQAmNQFITezduzebNm3K0qVLq8umTJmSpUuXZuPGjaP+zvDwcAYHB0c8AIDXTwBSEy+8\
8EL279+fuXPnjlg+d+7c9PX1jfo7q1evTktLS/WxYMGCiRgVACYdAUjdWLVqVQYGBqqP7du313ok\
AKhLJ9R6AMp06qmn5k1velP6+/tHLO/v709ra+uov9PU1JSmpqaJGA8AJjVHAKmJxsbGLFmyJOvX\
r68uO3DgQNavX5/29vYaTgYAk58jgNTMypUrs3z58rzjHe/IBRdckK9+9asZGhrKxz/+8VqPBgCT\
mgCkZj7ykY9k586dufXWW9PX15e3v/3t+d73vveaC0MAgGOroVKpVGo9BByNwcHBtLS0ZGBgIM3N\
zbUeB2DM7L+oNecAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYA\
AgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIA\
FEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRG\
AAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgAC\
ABRGAAIAFEYAAgAURgByzH3hC1/Iu971rkyfPj0nnXTSqOts27Ytl112WaZPn57TTjstn/3sZ/PH\
P/5xYgcFgEKdUOsBmHz27t2bD3/4w2lvb88//uM/vub1/fv357LLLktra2t+9KMf5bnnnsvHPvax\
TJ06NV/84hdrMDEAlKWhUqlUaj0Ek9N9992X66+/Prt27Rqx/Lvf/W6WLVuWHTt2ZO7cuUmSe+65\
J3//93+fnTt3prGxcUzvPzg4mJaWlgwMDKS5uflYjw8wbuy/qDUfATPhNm7cmHPPPbcaf0nS0dGR\
wcHBPP300zWcDADK4CNgJlxfX9+I+EtSfd7X13fI3xseHs7w8HD1+eDg4PgMCACTnCOAjMlNN92U\
hoaGwz62bNkyrjOsXr06LS0t1ceCBQvG9d8HAJOVI4CMyY033pirrrrqsOucccYZY3qv1tbW/OQn\
PxmxrL+/v/raoaxatSorV66sPh8cHBSBAHAUBCBjMmfOnMyZM+eYvFd7e3u+8IUv5Pnnn89pp52W\
JFm3bl2am5uzePHiQ/5eU1NTmpqajskMAFAyAcgxt23btrz44ovZtm1b9u/fn82bNydJ2traMnPm\
zFxyySVZvHhxPvrRj+b2229PX19fbr755qxYsULgAcAEcBsYjrmrrroq3/rWt16z/LHHHsv73ve+\
JMlvf/vbXHPNNfnhD3+YGTNmZPny5fnSl76UE04Y+99J3EYBqFf2X9SaAKRu2YEC9cr+i1pzFTAA\
QGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBh\
BCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQg\
AEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABA\
YQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEE\
IABAYQQgx9RvfvObXH311Vm0aFGmTZuWM888M7fddlv27t07Yr1f/OIX+ZM/+ZOceOKJWbBgQW6/\
/fYaTQwA5Tmh1gMwuWzZsiUHDhzIP/zDP6StrS1PPfVUPvWpT2VoaChf/vKXkySDg4O55JJLsnTp\
0txzzz158skn84lPfCInnXRSPv3pT9d4CwBg8muoVCqVWg/B5NbV1ZW77747//Zv/5Ykufvuu/O5\
z30ufX19aWxsTJLcdNNNefTRR7Nly5Yxv+/g4GBaWloyMDCQ5ubmcZkdYDzYf1FrPgJm3A0MDGT2\
7NnV5xs3bsx73/veavwlSUdHR7Zu3Zrf/e53tRgRAIoiABlXvb29+frXv56/+Zu/qS7r6+vL3Llz\
R6x38HlfX98h32t4eDiDg4MjHgDA6ycAGZObbropDQ0Nh328+uPbZ599Nn/2Z3+WD3/4w/nUpz71\
hmdYvXp1Wlpaqo8FCxa84fcEgBI5B5Ax2blzZ/793//9sOucccYZ1Y91d+zYkfe973256KKLct99\
92XKlP/4u8bHPvaxDA4O5tFHH60ue+yxx3LxxRfnxRdfzMknnzzq+w8PD2d4eLj6fHBwMAsWLHAO\
DVB3nANIrbkKmDGZM2dO5syZM6Z1n3322bz//e/PkiVLcu+9946IvyRpb2/P5z73uezbty9Tp05N\
kqxbty5nnXXWIeMvSZqamtLU1HT0GwEAJPERMMfYs88+m/e9731ZuHBhvvzlL2fnzp3p6+sbcW7f\
X//1X6exsTFXX311nn766Tz00EO58847s3LlyhpODgDlcASQY2rdunXp7e1Nb29v5s+fP+K1g2cb\
tLS05Pvf/35WrFiRJUuW5NRTT82tt97qHoAAMEGcA0jdcg4NUK/sv6g1HwEDABRGAAIAFEYAAgAU\
RgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYA\
AgAURgACABRGAAIAFEYAAgAURgACABRGAALAGPX29h7T9aBWBCAAjEF3d3e6urrS09Nz2PV6enrS\
1dWV7u7uCZoMXj8BCABH0Nvbm7Vr1yZJ1qxZc8gI7OnpyZo1a5Ika9eudSSQ45YABIAjaGtrS2dn\
Z/X5aBH4yvhLks7OzrS1tU3YjPB6CEAAGIOOjo5DRuBo8dfR0THhM8JYNVQqlUqth4CjMTg4mJaW\
lgwMDKS5ubnW4wCFeHXszZgxI0NDQ9XnY4k/+y9q7YRaDwAA9eRg3H3zrv8rz/Xuqi7/z3/yvzny\
R93wETAAvE4dHR158bd7Riz7w+8q4o+6IQAB4HV46vFn89m/vCPD+0YG4PZf9x/xFjFwvBCAAPA6\
fOsbD2XjL35Qfd54wolJklMXzDrsLWLgeCIAAWCMenp68pvf/zxTm96U09tOyi1fuS4/+MV/zy1f\
uS6zT5+R5PD3CYTjhYtAAGAMDl79O/v0GZl9+owRF3wc/Hnw6uCDP50TyPHKEUAAOILe3t4j3udv\
tPsE+iYQjlcCEACOoK2tLcuWLUty+Pv8vTICly1b5ptAOG65ETR1y41UgYnW29s7pqg70nr2X9Sa\
I4AAMEZjPaLnyB/HOwEIAFAYAQgAUBgBCABQGAEIAFAYAQgAUBgBCABQGAEIAFAYAQgAUBgBCABQ\
mBNqPQAcrYPfYjg4OFjjSQBen4P7Ld/GSq0IQOrW7t27kyQLFiyo8SQAR2f37t1paWmp9RgUqKHi\
rx/UqQMHDmTHjh2ZNWtWGhoaaj3OMTM4OJgFCxZk+/btk/pL4m3n5FHCNibHdjsrlUp2796defPm\
ZcoUZ2Mx8RwBpG5NmTIl8+fPr/UY46a5uXlS/8/0INs5eZSwjcmx205H/qglf+0AACiMAAQAKIwA\
hONMU1NTbrvttjQ1NdV6lHFlOyePErYxKWc7KYOLQAAACuMIIABAYQQgAEBhBCAAQGEEIABAYQQg\
HEe+8IUv5F3velemT5+ek046adR1tm3blssuuyzTp0/Paaedls9+9rP54x//OLGDvkF33XVX3vKW\
t+TEE0/MhRdemJ/85Ce1HukNefzxx/PBD34w8+bNS0NDQx599NERr1cqldx66605/fTTM23atCxd\
ujS//vWvazPsUVq9enXe+c53ZtasWTnttNNy+eWXZ+vWrSPW2bNnT1asWJFTTjklM2fOzBVXXJH+\
/v4aTXx07r777px33nnVmz23t7fnu9/9bvX1ybCNkAhAOK7s3bs3H/7wh3PNNdeM+vr+/ftz2WWX\
Ze/evfnRj36Ub33rW7nvvvty6623TvCkR++hhx7KypUrc9ttt+XnP/95zj///HR0dOT555+v9WhH\
bWhoKOeff37uuuuuUV+//fbb87WvfS333HNPnnjiicyYMSMdHR3Zs2fPBE969DZs2JAVK1bkxz/+\
cdatW5d9+/blkksuydDQUHWdG264Id3d3Xn44YezYcOG7NixI52dnTWc+vWbP39+vvSlL2XTpk35\
2c9+losvvjgf+tCH8vTTTyeZHNsISZIKcNy59957Ky0tLa9Z/p3vfKcyZcqUSl9fX3XZ3XffXWlu\
bq4MDw9P4IRH74ILLqisWLGi+nz//v2VefPmVVavXl3DqY6dJJVHHnmk+vzAgQOV1tbWSldXV3XZ\
rl27Kk1NTZUHHnigBhMeG88//3wlSWXDhg2VSuXlbZo6dWrl4Ycfrq7zq1/9qpKksnHjxlqNeUyc\
fPLJlW9+85uTehspjyOAUEc2btyYc889N3Pnzq0u6+joyODgYPUIxfFs79692bRpU5YuXVpdNmXK\
lCxdujQbN26s4WTj55lnnklfX9+IbW5pacmFF15Y19s8MDCQJJk9e3aSZNOmTdm3b9+I7Tz77LOz\
cOHCut3O/fv358EHH8zQ0FDa29sn5TZSrhNqPQAwdn19fSPiL0n1eV9fXy1Gel1eeOGF7N+/f9Rt\
2LJlS42mGl8H/1xG2+Z6+DMbzYEDB3L99dfn3e9+d972trcleXk7GxsbX3Puaj1u55NPPpn29vbs\
2bMnM2fOzCOPPJLFixdn8+bNk2YbwRFAGGc33XRTGhoaDvuYrPHD5LRixYo89dRTefDBB2s9yrg4\
66yzsnnz5jzxxBO55pprsnz58vzyl7+s9VhwTDkCCOPsxhtvzFVXXXXYdc4444wxvVdra+trrpg9\
eAVia2vrUc03kU499dS86U1ves1Vk/39/XUx/9E4uF39/f05/fTTq8v7+/vz9re/vUZTHb1rr702\
a9euzeOPP5758+dXl7e2tmbv3r3ZtWvXiCNk9fhn29jYmLa2tiTJkiVL8tOf/jR33nlnPvKRj0ya\
bQRHAGGczZkzJ2efffZhH42NjWN6r/b29jz55JMjrphdt25dmpubs3jx4vHahGOmsbExS5Ysyfr1\
66vLDhw4kPXr16e9vb2Gk42fRYsWpbW1dcQ2Dw4O5oknnqirba5UKrn22mvzyCOP5Ac/+EEWLVo0\
4vUlS5Zk6tSpI7Zz69at2bZtW11t52gOHDiQ4eHhSb2NlMcRQDiObNu2LS+++GK2bduW/fv3Z/Pm\
zUmStra2zJw5M5dcckkWL16cj370o7n99tvT19eXm2++OStWrEhTU1Nthx+jlStXZvny5XnHO96R\
Cy64IF/96lczNDSUj3/847Ue7ai99NJL6e3trT5/5plnsnnz5syePTsLFy7M9ddfn89//vN561vf\
mkWLFuWWW27JvHnzcvnll9du6NdpxYoVuf/++/Ptb387s2bNqp7z1tLSkmnTpqWlpSVXX311Vq5c\
mdmzZ6e5uTnXXXdd2tvbc9FFF9V4+rFbtWpVLr300ixcuDC7d+/O/fffnx/+8Ifp6emZNNsISdwG\
Bo4ny5cvryR5zeOxxx6rrvOb3/ymcumll1amTZtWOfXUUys33nhjZd++fbUb+ih8/etfryxcuLDS\
2NhYueCCCyo//vGPaz3SG/LYY4+N+ue2fPnySqXy8q1gbrnllsrcuXMrTU1NlQ984AOVrVu31nbo\
12m07UtSuffee6vr/OEPf6h85jOfqZx88smV6dOnV/78z/+88txzz9Vu6KPwiU98ovLmN7+50tjY\
WJkzZ07lAx/4QOX73/9+9fXJsI1QqVQqDZVKpTLx2QkAQK04BxAAoDACEACgMAIQAKAwAhAAoDAC\
EACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAA\
oDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAw\
AhAAoDACEACgMAIQAKAwAhAAoDD/H6VSUzkOMDChAAAAAElFTkSuQmCC\
"
  frames[3] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAIlZJREFUeJzt3X+M1PWd+PHXouwKwg6isCOyXPFotKSVTaZd3fauUUvhiNfo\
+SPtXa6uluh9vdUE1/ROUsXc91sPg01P26+F++bu1Ms3qPGbQLE5awlF/KMre24zntpCSs4eVJyF\
nmWHkjIgO98/CFMWl2WB3R1m349HMtH5zIfh9QlxfPLez+czdeVyuRwAACRjQrUHAABgbAlAAIDE\
CEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhA\
AIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACA\
xAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQI\
QACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAA\
gMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDEnF/tAeBM9Pf3x+7du2Pq\
1KlRV1dX7XEATlu5XI79+/fHrFmzYsIE6zGMLQFITdq9e3c0NzdXewyAs7Zr166YPXt2tccgMQKQ\
mjR16tSIOPrB2djYWOVpAE5fsViM5ubmyucZjCUBSE069mPfxsZGAQjUNKexUA1OOgAASIwABABI\
jAAEAEiMAAQASIwABABIjAAEAEiMAIQaUSgURnQ/ANIlAKEG9PT0xIYNGyKfzw+5Xz6fjw0bNkRP\
T8/YDAZATRKAcI4rFAqVoOvu7j5pBObz+eju7o6Io8FoJRCAkxGAcI7LZrPR2tpaeT5YBB4ffxER\
ra2tkc1mx2pEAGqMAIQa0NLSctIIHCz+WlpaxnhCAGqJ7wKGGnEs6o7FXnd3d7z55ptRKpUq+4g/\
AIbDCiDUkBNXAsUfAGfCCiDUmJaWlqMrf//vf1S2Ndy6RvwBMGxWAKHG5PP5ASt/EUdXAk91ixgA\
OEYAQg058YKPhvN+/9pQt4gBgOMJQKgRH7na9391Rfv630Xr/+qqbBOBAAyHAIQaMNStXoa6RQwA\
DEYAwjmuUCic8j5/g0WgbwIB4GQEIJzjstls5HK5iBj6Vi/HR2Aul/NNIACclNvAQA3I5XJx2WWX\
nTLqWlpaIpvNij8AhmQFkBG3evXquOqqq6KxsTEaGxujra0tXn755crrBw8ejI6Ojrj44otjypQp\
ccstt0Rvb28VJ64Nw4068QfAqQhARtzs2bPjsccei56ennjjjTfi+uuvjxtvvDHeeeediIi4//77\
46WXXooXX3wxtmzZErt3746bb765ylMDQDrqyuVyudpDMP5Nnz49Hn/88bj11ltjxowZsXbt2rj1\
1lsjImLbtm3xiU98Irq6uuKaa64Z1vsVi8XIZDLR19cXjY2Nozk6wKjwOUY1WQFkVB05ciSef/75\
OHDgQLS1tUVPT08cPnw4Fi5cWNnnyiuvjDlz5kRXV9cQ7wQwPMO9At6V8qTMRSCMirfeeiva2tri\
4MGDMWXKlFi3bl3Mnz8/8vl81NfXx7Rp0wbs39TUNOSHcalUGvD1Z8VicbRGB2pYT09P9PT0DHnF\
fMTv762Zy+UqV9lDSqwAMiquuOKKyOfzsXXr1rjnnnuivb09fvazn53x+61cuTIymUzl0dzcPILT\
AuNBoVCInp6eiBj6hujH31i9p6fHSiBJEoCMivr6+pg3b17kcrlYuXJlLFiwIJ588snIZrNx6NCh\
2Ldv34D9e3t7h7x6dfny5dHX11d57Nq1a5SPAKg12Wz2lN+KM9i36rhynhQJQMZEf39/lEqlyOVy\
MXHixNi0aVPlte3bt8fOnTujra3tpL++oaGhcluZYw+AEw311YhDfaUipMY5gIy45cuXx5IlS2LO\
nDmxf//+WLt2bbz66qvxyiuvRCaTiaVLl0ZnZ2dMnz49Ghsb47777ou2trZhXwEMMJRjUXcs9rq7\
u+PNN98ccB6x+CN1ApARt2fPnrj99tvj/fffj0wmE1dddVW88sor8cUvfjEiIv7hH/4hJkyYELfc\
ckuUSqVYvHhxfO9736vy1MB4cmIEij8YyH0AqUnunwUMx7PPPhudz71Ref7tP/90tLe3V3Gi3/M5\
RjU5BxCAcSmfzw9Y+Ys4uhJ4squDISUCEIBx58QLPurOm1j596FuEQOpcA4gAOPKifG36bGl0dLS\
MmD7sX86F5BUWQEEYNwY6lYvQ90iBlIjAAEYFwqFwinv8zdYBPomEFIkAAEYF7LZbOV7fYe61cvx\
EZjL5XwTCElyDiAA40Yul4vLLrvslFHX0tIS2WxW/JEsK4AAjCvDjTrxR8oEIABAYgQgAEBiBCAA\
QGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBi\
BCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQg\
AEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQg41qhUBjR/QBgPBCA\
jFs9PT2xYcOGyOfzQ+6Xz+djw4YN0dPTMzaDAUCVCUDGpUKhUAm67u7uk0ZgPp+P7u7uiDgajFYC\
AUiBAGRcymaz0draWnk+WAQeH38REa2trZHNZsdqRAComvOrPQCMlpaWloiISuQd+2fDV/48fn7w\
YLx18GBc+j//LiKOxt+x/QFgvLMCyIhbuXJlfOYzn4mpU6fGzJkz46abbort27cP2OfgwYPR0dER\
F198cUyZMiVuueWW6O3tHfFZWlpaPrISuL6vL946eLCyTfwBkBoByIjbsmVLdHR0xOuvvx4bN26M\
w4cPx6JFi+LAgQOVfe6///546aWX4sUXX4wtW7bE7t274+abbx6VeU6MwEPlcuXfxR8AKaorl4/7\
vyGMgr1798bMmTNjy5Yt8fnPfz76+vpixowZsXbt2rj11lsjImLbtm3xiU98Irq6uuKaa6455XsW\
i8XIZDLR19cXjY2Nw5rj2WefjVKpVHne0NAQ7e3tZ3ZQAGfpTD7HYKRYAWTU9fX1RUTE9OnTI+Lo\
1baHDx+OhQsXVva58sorY86cOdHV1TUqM+Tz+QHxFxFRKpVOeYsYABiPXATCqOrv749ly5bF5z73\
ufjkJz8ZEUdv0VJfXx/Tpk0bsG9TU9NJb8NSKpUGBFyxWBz2DCde7dvQ0FB5r2Pb/RgYgJRYAWRU\
dXR0xNtvvx3PP//8Wb3PypUrI5PJVB7Nzc3D+nWD3eqlvb39lLeIAYDxTAAyau699974wQ9+EJs3\
b47Zs2dXtmez2Th06FDs27dvwP69vb0nvQ/f8uXLo6+vr/LYtWvXKX//weLv2ErfYFcHi0AAUiEA\
GXHlcjnuvffeWLduXfz4xz+OuXPnDng9l8vFxIkTY9OmTZVt27dvj507d0ZbW9ug79nQ0BCNjY0D\
HkMpFAonjb9jBotA3wQCQAqcA8iI6+joiLVr18b3v//9mDp1aiWqMplMTJo0KTKZTCxdujQ6Oztj\
+vTp0djYGPfdd1+0tbUN6wrg4chms5HL5aKnp2fIW70cf7PoXC7nm0AASILbwDDi6urqBt3+9NNP\
xx133BERR28E/cADD8Rzzz0XpVIpFi9eHN/73veGHWDDvX1CoVAY1nsOdz+AkeI2MFSTAKQm+eAE\
ap3PMarJOYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkR\
gAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAA\
AIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJ\
EYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGA\
AACJEYAAAIkRgAAAiRGAjLjXXnstvvSlL8WsWbOirq4u1q9fP+D1crkcK1asiEsvvTQmTZoUCxcu\
jF/84hfVGRYAEiQAGXEHDhyIBQsWxFNPPTXo66tWrYrvfOc7sWbNmti6dWtceOGFsXjx4jh48OAY\
TwoAaTq/2gMw/ixZsiSWLFky6GvlcjmeeOKJeOihh+LGG2+MiIh//dd/jaampli/fn185StfGctR\
ASBJVgAZU++++24UCoVYuHBhZVsmk4mrr746urq6qjgZAKTDCiBjqlAoREREU1PTgO1NTU2V1wZT\
KpWiVCpVnheLxdEZEAASYAWQmrBy5crIZDKVR3Nzc7VHAoCaJQAZU9lsNiIient7B2zv7e2tvDaY\
5cuXR19fX+Wxa9euUZ0TAMYzAciYmjt3bmSz2di0aVNlW7FYjK1bt0ZbW9tJf11DQ0M0NjYOeAAA\
Z8Y5gIy43/72t7Fjx47K83fffTfy+XxMnz495syZE8uWLYtvfvOb8fGPfzzmzp0bDz/8cMyaNStu\
uumm6g0NAAkRgIy4N954I6677rrK887OzoiIaG9vj2eeeSb+5m/+Jg4cOBB333137Nu3L/7oj/4o\
fvjDH8YFF1xQrZEBICl15XK5XO0h4HQVi8XIZDLR19fnx8FATfI5RjU5BxAAIDECEAAgMQIQACAx\
AhAAIDECEGrQUF+bdyb7AZAWAQg1pqenJzZs2BD5fH7I/fL5fGzYsCF6enrGZjAAaoYAhBpSKBQq\
Qdfd3X3SCMzn89Hd3R0RR4PRSiAAxxOAUEOy2Wy0trZWng8WgcfHX0REa2vrkN+zDJya0y4YbwQg\
1JiWlpaTRuBg8dfS0jLGE8L44rQLxiNfBQc16FjUHYu97u7uePPNN6NUKlX2EX9w9k487SIiBv3v\
6sTTLi677DIr75zTrABCjTpxJVD8wchz2gXjlRVAqGEtLS2Vlb+/6/q7iIioO78ufnX3r6o8GYwf\
g624H9vutAtqlQCEGpbP5wes/EVElD8sRz6f9z8hGEFOu2C8EYBQo05ceag7vy7KH5YjYuhzlYAz\
c2IElkql2Ph//ndERDRPz8Tdd99drdHgtAlAqEGD/djpV3f/asB2EQgj7/jTLo4577wJcdlFmSpO\
BafPRSBQY4Y652ioW8QAZ2+w0y6OHOmP937TV6WJ4MxYAYQaUigUTnnC+WDnKmWzWVclwlk68S9f\
DQ0N8cW77x3wuhV3aoUVQKgh2Ww2crlcRAx9wvnxK4G5XE78wVkabOW9vb3dijs1ywog1JhcLjes\
m8y2tLRY+YMRcKrTLiIGv0UMnMusAEINGm7UiT84O8M97eLElUDfCcy5TgACwEk47YLxyo+AAWAI\
TrtgPLICCACn4LQLxhsBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgA\
kBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAY\
AQgAkBgBCACQGAEIAJAYAQgAkBgBSFU99dRT8bGPfSwuuOCCuPrqq6O7u7vaIwHAuCcAqZoXXngh\
Ojs745FHHomf/vSnsWDBgli8eHHs2bOn2qMBwLgmAKmab3/723HXXXfFnXfeGfPnz481a9bE5MmT\
41/+5V+qPRoAjGsCkKo4dOhQ9PT0xMKFCyvbJkyYEAsXLoyurq4qTgYA49/51R6ANP3617+OI0eO\
RFNT04DtTU1NsW3bto/sXyqVolQqVZ4Xi8VRnxEAxisrgNSElStXRiaTqTyam5urPRIA1CwBSFVc\
csklcd5550Vvb++A7b29vZHNZj+y//Lly6Ovr6/y2LVr11iNCgDjjgCkKurr6yOXy8WmTZsq2/r7\
+2PTpk3R1tb2kf0bGhqisbFxwAMAODPOAaRqOjs7o729PT796U9Ha2trPPHEE3HgwIG48847qz0a\
AIxrApCq+fKXvxx79+6NFStWRKFQiJaWlvjhD3/4kQtDAICRVVcul8vVHgJOV7FYjEwmE319fX4c\
DNQkn2NUk3MAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQAS\
IwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMA\
AQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEA\
EiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIj\
AAEAEiMAAQASIwABABIjABlxjz76aHz2s5+NyZMnx7Rp0wbdZ+fOnXHDDTfE5MmTY+bMmfH1r389\
Pvzww7EdFAASdX61B2D8OXToUNx2223R1tYW//zP//yR148cORI33HBDZLPZ+MlPfhLvv/9+3H77\
7TFx4sT4+7//+ypMDABpqSuXy+VqD8H49Mwzz8SyZcti3759A7a//PLL8ad/+qexe/fuaGpqioiI\
NWvWxN/+7d/G3r17o76+/pTvXSwWI5PJRF9fXzQ2No7G+ACjyucY1eRHwIy5rq6u+NSnPlWJv4iI\
xYsXR7FYjHfeeaeKkwFAGvwImDFXKBQGxF9EVJ4XCoVBf02pVIpSqVR5XiwWR29AABjnrAAyLA8+\
+GDU1dUN+di2bduo/f4rV66MTCZTeTQ3N4/a7wUA450VQIblgQceiDvuuGPIfS6//PJhvVc2m43u\
7u4B23p7eyuvDWb58uXR2dlZeV4sFkUgAJwhAciwzJgxI2bMmDEi79XW1haPPvpo7NmzJ2bOnBkR\
ERs3bozGxsaYP3/+oL+moaEhGhoaRuT3B4DUCUBG3M6dO+ODDz6InTt3xpEjRyKfz0dExLx582LK\
lCmxaNGimD9/fnz1q1+NVatWRaFQiIceeig6OjpEHgCMAbeBYcTdcccd8eyzz35k++bNm+Paa6+N\
iIj/+q//invuuSdeffXVuPDCC6O9vT0ee+yxOP/84f2dxO0TgFrnc4xqEoDUJB+cQK3zOUY1uQoY\
ACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAg\
MQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDEC\
EAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAA\
IDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAx\
AhAAIDECkBH1y1/+MpYuXRpz586NSZMmxR/+4R/GI488EocOHRqw33/8x3/EH//xH8cFF1wQzc3N\
sWrVqipNDADpOb/aAzC+bNu2Lfr7++Mf//EfY968efH222/HXXfdFQcOHIhvfetbERFRLBZj0aJF\
sXDhwlizZk289dZb8bWvfS2mTZsWd999d5WPAADGv7pyuVyu9hCMb48//nisXr06/vM//zMiIlav\
Xh3f+MY3olAoRH19fUREPPjgg7F+/frYtm3bsN6zWCxGJpOJvr6+aGxsHLXZAUaLzzGqyY+AGXV9\
fX0xffr0yvOurq74/Oc/X4m/iIjFixfH9u3b4ze/+U01RgSApAhARtWOHTviu9/9bvzVX/1VZVuh\
UIimpqYB+x17XigUBn2fUqkUxWJxwAMAODMCkGF58MEHo66ubsjHiT++fe+99+JP/uRP4rbbbou7\
7rrrrH7/lStXRiaTqTyam5vP6v0AIGXOAWRY9u7dG//93/895D6XX3555ce6u3fvjmuvvTauueaa\
eOaZZ2LChN//XeP222+PYrEY69evr2zbvHlzXH/99fHBBx/ERRdd9JH3LpVKUSqVKs+LxWI0Nzc7\
dwaoWc4BpJpcBcywzJgxI2bMmDGsfd9777247rrrIpfLxdNPPz0g/iIi2tra4hvf+EYcPnw4Jk6c\
GBERGzdujCuuuGLQ+IuIaGhoiIaGhrM7CAAgIvwImBH23nvvxbXXXhtz5syJb33rW7F3794oFAoD\
zu37i7/4i6ivr4+lS5fGO++8Ey+88EI8+eST0dnZWcXJASAdVgAZURs3bowdO3bEjh07Yvbs2QNe\
O3a2QSaTiR/96EfR0dERuVwuLrnkklixYoV7AALAGHEOIDXJuTNArfM5RjX5ETAAQGIEIABAYgQg\
AEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABA\
YgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAJyGQqEwovtBNQhAABimnp6e2LBhQ+Tz\
+SH3y+fzsWHDhujp6RmbweA0CUAAGIZCoVAJuu7u7pNGYD6fj+7u7og4GoxWAjkXCUAAGIZsNhut\
ra2V54NF4PHxFxHR2toa2Wx2rEaEYROAADBMLS0tJ43AweKvpaVljCeE4Tm/2gMAQC05FnXHYq+7\
uzvefPPNKJVKlX3EH+c6AQgAp+n4CNz8f7dVtl/3l1eKP2qCHwEDwBloaWmJhoaGAdsaGhrEHzVB\
AALAGcjn8wN+7BsRUSqVTnmLGDgX+BEwAJym4y/4uO4vr4yGhoZKDB7bbiWQc5kVQAA4DYNd7dve\
3n7KW8TAuUQAAsAwDXWrl6FuEQPnGgEIAMNQKBROeZ+/wSLQN4FwLhKAADAM2Ww2crlcRAx9n7/j\
IzCXy/kmEM5JLgIBgGHK5XJx2WWXnTLqWlpaIpvNij/OWVYAAeA0DDfqxB/nMgEIAJAYAQgAkBgB\
CACQGAEIAJAYAQgAkBgBCACQGAEIAJAYN4KmJpXL5YiIKBaLVZ4E4Mwc+/w69nkGY0kAUpP2798f\
ERHNzc1VngTg7Ozfvz8ymUy1xyAxdWV/9aAG9ff3x+7du2Pq1KlRV1dX7XFGVLFYjObm5ti1a1c0\
NjZWe5xR4zjHF8d5+srlcuzfvz9mzZoVEyY4I4uxZQWQmjRhwoSYPXt2tccYVY2NjeP6f6THOM7x\
xXGeHit/VIu/cgAAJEYAAgAkRgDCOaahoSEeeeSRaGhoqPYoo8pxji+OE2qLi0AAABJjBRAAIDEC\
EAAgMQIQACAxAhAAIDECEM4hjz76aHz2s5+NyZMnx7Rp0wbdZ+fOnXHDDTfE5MmTY+bMmfH1r389\
Pvzww7Ed9Cw99dRT8bGPfSwuuOCCuPrqq6O7u7vaI5211157Lb70pS/FrFmzoq6uLtavXz/g9XK5\
HCtWrIhLL700Jk2aFAsXLoxf/OIX1Rn2DK1cuTI+85nPxNSpU2PmzJlx0003xfbt2wfsc/Dgwejo\
6IiLL744pkyZErfcckv09vZWaeIzs3r16rjqqqsqN3tua2uLl19+ufL6eDhGEIBwDjl06FDcdttt\
cc899wz6+pEjR+KGG26IQ4cOxU9+8pN49tln45lnnokVK1aM8aRn7oUXXojOzs545JFH4qc//Wks\
WLAgFi9eHHv27Kn2aGflwIEDsWDBgnjqqacGfX3VqlXxne98J9asWRNbt26NCy+8MBYvXhwHDx4c\
40nP3JYtW6KjoyNef/312LhxYxw+fDgWLVoUBw4cqOxz//33x0svvRQvvvhibNmyJXbv3h0333xz\
Fac+fbNnz47HHnssenp64o033ojrr78+brzxxnjnnXciYnwcI0QZOOc8/fTT5Uwm85Ht//Zv/1ae\
MGFCuVAoVLatXr263NjYWC6VSmM44ZlrbW0td3R0VJ4fOXKkPGvWrPLKlSurONXIiojyunXrKs/7\
+/vL2Wy2/Pjjj1e27du3r9zQ0FB+7rnnqjDhyNizZ085Ispbtmwpl8tHj2nixInlF198sbLPz3/+\
83JElLu6uqo15oi46KKLyv/0T/80ro+RtFgBhBrS1dUVn/rUp6KpqamybfHixVEsFiurE+eyQ4cO\
RU9PTyxcuLCybcKECbFw4cLo6uqq4mSj6913341CoTDguDOZTFx99dU1fdx9fX0RETF9+vSIiOjp\
6YnDhw8POM4rr7wy5syZU7PHeeTIkXj++efjwIED0dbWNi6PkTSdX+0BgOErFAoD4i8iKs8LhUI1\
Rjotv/71r+PIkSODHsO2bduqNNXoO/ZnM9hx18Kf22D6+/tj2bJl8bnPfS4++clPRsTR46yvr//I\
+au1eJxvvfVWtLW1xcGDB2PKlCmxbt26mD9/fuTz+XFzjKTNCiCMsgcffDDq6uqGfIzn+GF86ujo\
iLfffjuef/75ao8yKq644orI5/OxdevWuOeee6K9vT1+9rOfVXssGDFWAGGUPfDAA3HHHXcMuc/l\
l18+rPfKZrMfuWL22NWH2Wz2jOYbS5dcckmcd955H7lisre3tybmP1PHjq23tzcuvfTSyvbe3t5o\
aWmp0lRn7t57740f/OAH8dprr8Xs2bMr27PZbBw6dCj27ds3YIWsFv986+vrY968eRERkcvl4t//\
/d/jySefjC9/+cvj5hhJmxVAGGUzZsyIK6+8cshHfX39sN6rra0t3nrrrQFXzG7cuDEaGxtj/vz5\
o3UII6a+vj5yuVxs2rSpsq2/vz82bdoUbW1tVZxsdM2dOzey2eyA4y4Wi7F169aaOu5yuRz33ntv\
rFu3Ln784x/H3LlzB7yey+Vi4sSJA45z+/btsXPnzpo6zsH09/dHqVQa18dIWqwAwjlk586d8cEH\
H8TOnTvjyJEjkc/nIyJi3rx5MWXKlFi0aFHMnz8/vvrVr8aqVauiUCjEQw89FB0dHdHQ0FDd4Yep\
s7Mz2tvb49Of/nS0trbGE088EQcOHIg777yz2qOdld/+9rexY8eOyvN333038vl8TJ8+PebMmRPL\
li2Lb37zm/Hxj3885s6dGw8//HDMmjUrbrrppuoNfZo6Ojpi7dq18f3vfz+mTp1aOectk8nEpEmT\
IpPJxNKlS6OzszOmT58ejY2Ncd9990VbW1tcc801VZ5++JYvXx5LliyJOXPmxP79+2Pt2rXx6quv\
xiuvvDJujhHcBgbOIe3t7eWI+Mhj8+bNlX1++ctflpcsWVKeNGlS+ZJLLik/8MAD5cOHD1dv6DPw\
3e9+tzxnzpxyfX19ubW1tfz6669Xe6Sztnnz5kH/7Nrb28vl8tFbwTz88MPlpqamckNDQ/kLX/hC\
efv27dUd+jQNdnwRUX766acr+/zud78r//Vf/3X5oosuKk+ePLn8Z3/2Z+X333+/ekOfga997Wvl\
P/iDPyjX19eXZ8yYUf7CF75Q/tGPflR5fTwcI9SVy+Xy2GcnAADV4hxAAIDECEAAgMQIQACAxAhA\
AIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACA\
xAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQI\
QACAxAhAAIDECEAAgMQIQACAxAhAAIDE/H9y3pGjpRPbhwAAAABJRU5ErkJggg==\
"
  frames[4] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAIndJREFUeJzt3X+M1PWd+PHXUtgVHGYQhZ1dWK54NFrSShPqj23vGms5KPEa\
PX+cl8u3oiX24q0miOmdXBXz/aYWo81V21i45O60l2+ofv1+A/1qzlq+FDH5dsVKv/TUHpuSswfZ\
3VnoWXZYUhaWne8fhjkWl2WB3R1m3o9HMsH5zIfh9QlxeO57PvOZulKpVAoAAJIxqdIDAAAwsQQg\
AEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABA\
YgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIE\
IABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAA\
QGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBi\
BCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiJld6ADgXg4OD0dXV\
FdOnT4+6urpKjwNw1kqlUhw6dCiam5tj0iTrMUwsAUhV6urqipaWlkqPAXDe9u3bF3Pnzq30GCRG\
AFKVpk+fHhEfvHBms9kKTwNw9orFYrS0tJRfz2AiCUCq0om3fbPZrAAEqprTWKgEJx0AACRGAAIA\
JEYAAgAkRgACACRGAAIAJEYAAgAkRgBClejr6xvT/QBIlwCEKtDV1RUdHR1RKBRG3K9QKERHR0d0\
dXVN0GQAVCMBCBe4vr6+6O7ujoiIzs7O00ZgoVCIzs7OiIjo7u62EgjAaQlAuMBlMpmYM2dO+f5w\
EXhy/EVEzJkzJzKZzITNCEB1EYBQBfL5/GkjcLj4y+fzEz4jANXDdwFDlTgRdSdir7OzM3p6emJg\
YKC8j/gDYDSsAEIVOXUlUPwBcC6sAEKVyefzH6z8PfPZ8rbJbf9X/AEwalYAocoUCoUhK38RH6wE\
nukSMQBwggCEKnLqBz4mn/R/8EiXiAGAk3kLGKrEhz7t+9/2RD6fH7L9xK/eDgZgJFYAoQqMdKmX\
kS4RAwDDEYBwgevr6zvjdf6Gi0DfBALA6QhAuMBlMploamqKiJEv9XJyBDY1NfkmEABOyzmAUAWa\
m5sjm82eMery+XxkMhnxB8CIrAAy5tavXx9XXXVVZLPZyGaz0draGq+88kr58SNHjkRbW1tceuml\
kclk4tZbb42enp4KTlwdRht14g+AMxGAjLm5c+fG448/Hjt37oy33norbrjhhrjpppvi3XffjYiI\
Bx54IF566aV48cUXY/v27dHV1RW33HJLhacGgHTUlUqlUqWHoPbNnDkznnzyybjtttti1qxZsXHj\
xrjtttsiImL37t3x8Y9/PNrb2+O6664b1fMVi8XI5XLR29sb2Wx2PEcHGBdex6gkK4CMq+PHj8fz\
zz8fhw8fjtbW1ti5c2ccO3YslixZUt7nyiuvjHnz5kV7e3sFJwVqxWg/Ae+T8qTMh0AYF2+//Xa0\
trbGkSNHIpPJxKZNm2LhwoWxa9euqK+vjxkzZgzZv7GxccRr1/X390d/f3/5frFYHK/RgSrW1dUV\
3d3dI35iPuI/r63Z1NQUzc3NEzghXBisADIurrjiiti1a1fs2LEj7r333lixYkX88pe/POfnW7du\
XeRyufKtpaVlDKcFakFfX190d3dHxMgXRD/5wurd3d1WAkmSAGRc1NfXx4IFC2Lx4sWxbt26WLRo\
UTz99NORz+fj6NGjcfDgwSH79/T0jPjT+po1a6K3t7d827dv3zgfAVBtMpnMGb8VZ7hv1fHJeVIk\
AJkQg4OD0d/fH4sXL44pU6bE1q1by491dHTE3r17o7W19bS/v6GhoXxZmRM3gFON9NWII32lIqTG\
OYCMuTVr1sTy5ctj3rx5cejQodi4cWO89tpr8eqrr0Yul4uVK1fG6tWrY+bMmZHNZuP++++P1tbW\
UX8CGGAkJ6LuROx1dnZGT09PDAwMlPcRf6ROADLm9u/fH3feeWd0d3dHLpeLq666Kl599dX4oz/6\
o4iI+Pa3vx2TJk2KW2+9Nfr7+2PZsmXxve99r8JTA7Xk1AgUfzCU6wBSlVw/CxiNX/ziF/HFb79W\
vv+jB66PRYsWVWyek3kdo5KcAwhATSoUCkNW/iI+WAkc6ZJTkAoBCEDNOfUDH3WT/vOfu5EuEQOp\
cA4gADXl1Pj7f4/fEfl8fsj2E786F5BUWQEEoGaMdKmXkS4RA6kRgADUhL6+vjNe52+4CPRNIKRI\
AAJQEzKZTDQ1NUXEyJd6OTkCm5qafBMISXIOIAA1o7m5ObLZ7BmjLp/PRyaTEX8kywogADVltFEn\
/kiZAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABI\
jAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwA\
BABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQA\
SIwApKb19fWN6X4AUAsEIDWrq6srOjo6olAojLhfoVCIjo6O6OrqmqDJAKCyBCA1qa+vL7q7uyMi\
orOz87QRWCgUorOzMyIiuru7rQQCkAQBSE3KZDIxZ86c8v3hIvDk+IuImDNnTmQymQmbEQAqZXKl\
B4Dxks/nIyLKkXfi199e//k4MDAQ+wcGYv7/+p8R8UH8ndgfAGqdFUDG3Lp16+Lqq6+O6dOnx+zZ\
s+Pmm2+Ojo6OIfscOXIk2tra4tJLL41MJhO33npr9PT0jPks+Xz+QyuBu48cif0DA+Vt4g+A1AhA\
xtz27dujra0t3njjjdiyZUscO3Ysli5dGocPHy7v88ADD8RLL70UL774Ymzfvj26urrilltuGZd5\
To3A4yc9Jv4ASFFdqVQqVXoIatuBAwdi9uzZsX379vjc5z4Xvb29MWvWrNi4cWPcdtttERGxe/fu\
+PjHPx7t7e1x3XXXnfE5i8Vi5HK56O3tjWw2O6o5fvGLX8TASSt/kydPjkWLFp3bQQGcp3N5HYOx\
YgWQcdfb2xsRETNnzoyIiJ07d8axY8diyZIl5X2uvPLKmDdvXrS3t4/LDIVCYUj8RUQMDAyc8RIx\
AFCLfAiEcTU4OBirVq2Kz372s/GJT3wiIj6Isfr6+pgxY8aQfRsbG08bZP39/dHf31++XywWRz3D\
qZ/2nTx5cjkGT2z3NjAAKbECyLhqa2uLd955J55//vnzep5169ZFLpcr31paWkb1+4a71MuiRYvO\
eIkYAKhlApBxc99998XLL78c27Zti7lz55a35/P5OHr0aBw8eHDI/j09PaddiVuzZk309vaWb/v2\
7Tvjnz9c/J14/uE+HSwCAUiFAGTMlUqluO+++2LTpk3xk5/8JObPnz/k8cWLF8eUKVNi69at5W0d\
HR2xd+/eaG1tHfY5GxoaIpvNDrmNpK+v77Txd8JwEeibQABIgXMAGXNtbW2xcePG+OEPfxjTp08v\
r6zlcrmYOnVq5HK5WLlyZaxevTpmzpwZ2Ww27r///mhtbR3VJ4BHI5PJRFNTU3R3d494qZeTLxbd\
1NTkm0AASILLwDDm6urqht3+7LPPxl133RURH1wI+sEHH4wf/OAH0d/fH8uWLYvvfe97o/4wxmgv\
n9DX1zeqqBvtfgBjxWVgqCQBSFXywglUO69jVJJzAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwAB\
ABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQAS\
IwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMA\
AQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEA\
EiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwAZc6+//np86Utfiubm5qirq4vN\
mzcPebxUKsXatWujqakppk6dGkuWLIlf/epXlRkWABIkABlzhw8fjkWLFsUzzzwz7ONPPPFEfOc7\
34kNGzbEjh074uKLL45ly5bFkSNHJnhSAEjT5EoPQO1Zvnx5LF++fNjHSqVSPPXUU/Hwww/HTTfd\
FBER//RP/xSNjY2xefPm+LM/+7OJHBUAkmQFkAn13nvvRaFQiCVLlpS35XK5uPbaa6O9vb2CkwFA\
OqwAMqEKhUJERDQ2Ng7Z3tjYWH5sOP39/dHf31++XywWx2dAAEiAFUCqwrp16yKXy5VvLS0tlR4J\
AKqWAGRC5fP5iIjo6ekZsr2np6f82HDWrFkTvb295du+ffvGdU4AqGUCkAk1f/78yOfzsXXr1vK2\
YrEYO3bsiNbW1tP+voaGhshms0NuAMC5cQ4gY66vry/27NlTvv/ee+/Frl27YubMmTFv3rxYtWpV\
fOMb34iPfexjMX/+/HjkkUeiubk5br755soNDQAJEYCMubfeeis+//nPl++vXr06IiJWrFgRzz33\
XPzVX/1VHD58OL761a/GwYMH4w/+4A/iRz/6UVx00UWVGhkAklJXKpVKlR4CzlaxWIxcLhe9vb3e\
DgaqktcxKsk5gAAAiRGAAACJEYAAAIkRgAAAiRGAUIX6+vrGdD8A0iIAocp0dXVFR0fHiN+dHPHB\
9y53dHREV1fXBE0GQLUQgFBF+vr6oru7OyIiOjs7TxuBhUIhOjs7IyKiu7vbSiAAQwhAqCKZTCbm\
zJlTvj9cBJ4cfxERc+bMiUwmM2EzQi1y2gW1RgBClcnn86eNwOHiL5/PT/iMUEucdkEt8lVwUIVO\
RN2J2Ovs7Iyenp4YGBgo7yP+4PydetpFRAz7/9Wpp11ks1kr71zQrABClTp1JVD8wdhz2gW1ygog\
VLF8Pl9e+bvj5Ts+2DgpYs8jeyo7GNSQ4VbcT2x32gXVSgBCFSsUCkNW/iIiYvCD7f4RgrHjtAtq\
jQCEKnXqykNMiojBD/5zpHOVgHNzagQODAzEf39oVUREZKc2xH/93/+nUqPBWROAUIWGe9tpzyN7\
hmwXgTD2Tj7t4oRJk+oiO/WiCk4FZ8+HQKDKjHTO0UiXiAHO33CnXQwOlqL4uyMVmgjOjRVAqCJ9\
fX1nPOF8uHOVMpmMTyXCeTr1h6/JkyfHf3n8qSGPW3GnWlgBhCqSyWSiqakpIkY+4fzklcCmpibx\
B+dpuJX3RYsWWXGnalkBhCrT3Nw8qovM5vN5K38wBs502kXE8JeIgQuZFUCoQqONOvEH52e0p12c\
uhLoO4G50AlAADgNp11Qq7wFDAAjcNoFtcgKIACcgdMuqDUCEAAgMQIQACAxAhAAIDECEAAgMQIQ\
ACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAg\
MQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECkIp65pln4qMf/WhcdNFF\
ce2118abb75Z6ZEAoOYJQCrmhRdeiNWrV8ejjz4aP//5z2PRokWxbNmy2L9/f6VHA4CaJgCpmL/9\
27+Ne+65J+6+++5YuHBhbNiwIaZNmxb/+I//WOnRAKCmCUAq4ujRo7Fz585YsmRJedukSZNiyZIl\
0d7eXsHJAKD2Ta70AKTpN7/5TRw/fjwaGxuHbG9sbIzdu3d/aP/+/v7o7+8v3y8Wi+M+IwDUKiuA\
VIV169ZFLpcr31paWio9EgBULQFIRVx22WXxkY98JHp6eoZs7+npiXw+/6H916xZE729veXbvn37\
JmpUAKg5ApCKqK+vj8WLF8fWrVvL2wYHB2Pr1q3R2tr6of0bGhoim80OuQEA58Y5gFTM6tWrY8WK\
FfHpT386rrnmmnjqqafi8OHDcffdd1d6NACoaQKQirnjjjviwIEDsXbt2igUCvGpT30qfvSjH33o\
gyEAwNiqK5VKpUoPAWerWCxGLpeL3t5ebwcDVcnrGJXkHEAAgMQIQACAxAhAAIDECEAAgMQIQACA\
xAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQI\
QACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAA\
gMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDE\
CEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAxtxjjz0Wn/nMZ2LatGkx\
Y8aMYffZu3dv3HjjjTFt2rSYPXt2fO1rX4uBgYGJHRQAEjW50gNQe44ePRq33357tLa2xj/8wz98\
6PHjx4/HjTfeGPl8Pn76059Gd3d33HnnnTFlypT45je/WYGJASAtdaVSqVTpIahNzz33XKxatSoO\
Hjw4ZPsrr7wSf/zHfxxdXV3R2NgYEREbNmyIv/7rv44DBw5EfX39GZ+7WCxGLpeL3t7eyGaz4zE+\
wLjyOkYleQuYCdfe3h6f/OQny/EXEbFs2bIoFovx7rvvVnAyAEiDt4CZcIVCYUj8RUT5fqFQGPb3\
9Pf3R39/f/l+sVgcvwEBoMZZAWRUHnrooairqxvxtnv37nH789etWxe5XK58a2lpGbc/CwBqnRVA\
RuXBBx+Mu+66a8R9Lr/88lE9Vz6fjzfffHPItp6envJjw1mzZk2sXr26fL9YLIpAADhHApBRmTVr\
VsyaNWtMnqu1tTUee+yx2L9/f8yePTsiIrZs2RLZbDYWLlw47O9paGiIhoaGMfnzASB1ApAxt3fv\
3nj//fdj7969cfz48di1a1dERCxYsCAymUwsXbo0Fi5cGF/+8pfjiSeeiEKhEA8//HC0tbWJPACY\
AC4Dw5i766674vvf//6Htm/bti2uv/76iIj493//97j33nvjtddei4svvjhWrFgRjz/+eEyePLqf\
SVw+Aah2XseoJAFIVfLCCVQ7r2NUkk8BAwAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAk\
RgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYA\
AgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIA\
JEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRG\
AAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGADKmfv3rX8fKlStj/vz5MXXq1Pj93//9ePTR\
R+Po0aND9vuXf/mX+MM//MO46KKLoqWlJZ544okKTQwA6Zlc6QGoLbt3747BwcH4u7/7u1iwYEG8\
8847cc8998Thw4fjW9/6VkREFIvFWLp0aSxZsiQ2bNgQb7/9dnzlK1+JGTNmxFe/+tUKHwEA1L66\
UqlUqvQQ1LYnn3wy1q9fH//2b/8WERHr16+Pr3/961EoFKK+vj4iIh566KHYvHlz7N69e1TPWSwW\
I5fLRW9vb2Sz2XGbHWC8eB2jkrwFzLjr7e2NmTNnlu+3t7fH5z73uXL8RUQsW7YsOjo64re//W0l\
RgSApAhAxtWePXviu9/9bvzFX/xFeVuhUIjGxsYh+524XygUhn2e/v7+KBaLQ24AwLkRgIzKQw89\
FHV1dSPeTn37trOzM774xS/G7bffHvfcc895/fnr1q2LXC5XvrW0tJzX8wFAypwDyKgcOHAg/uM/\
/mPEfS6//PLy27pdXV1x/fXXx3XXXRfPPfdcTJr0nz9r3HnnnVEsFmPz5s3lbdu2bYsbbrgh3n//\
/bjkkks+9Nz9/f3R399fvl8sFqOlpcW5M0DVcg4gleRTwIzKrFmzYtasWaPat7OzMz7/+c/H4sWL\
49lnnx0SfxERra2t8fWvfz2OHTsWU6ZMiYiILVu2xBVXXDFs/EVENDQ0RENDw/kdBAAQEd4CZox1\
dnbG9ddfH/PmzYtvfetbceDAgSgUCkPO7fvzP//zqK+vj5UrV8a7774bL7zwQjz99NOxevXqCk4O\
AOmwAsiY2rJlS+zZsyf27NkTc+fOHfLYibMNcrlc/PjHP462trZYvHhxXHbZZbF27VrXAASACeIc\
QKqSc2eAaud1jEryFjAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBi\
BCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQg\
AJyFvr6+Md0PKkEAAsAodXV1RUdHRxQKhRH3KxQK0dHREV1dXRM0GZwdAQgAo9DX1xfd3d0REdHZ\
2XnaCCwUCtHZ2RkREd3d3VYCuSAJQAAYhUwmE3PmzCnfHy4CT46/iIg5c+ZEJpOZsBlhtAQgAIxS\
Pp8/bQQOF3/5fH7CZ4TRmFzpAQCgmpyIuhOx19nZGT09PTEwMFDeR/xxoROAAHCWTo7A//HNn5W3\
/+nfXC3+qAreAgaAc5DP52Py5KHrKJMnTxZ/VAUBCADnoFAoDHnbNyJiYGDgjJeIgQuBt4AB4Cyd\
/IGPP/2bq2Py5MnlGDyx3UogFzIrgABwFob7tO+iRYvOeIkYuJAIQAAYpZEu9TLSJWLgQiMAAWAU\
+vr6znidv+Ei0DeBcCESgAAwCplMJpqamiJi5Ov8nRyBTU1NvgmEC5IPgQDAKDU3N0c2mz1j1OXz\
+chkMuKPC5YVQAA4C6ONOvHHhUwAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkxoWg\
qUqlUikiIorFYoUnATg3J16/TryewUQSgFSlQ4cORURES0tLhScBOD+HDh2KXC5X6TFITF3Jjx5U\
ocHBwejq6orp06dHXV1dpccZU8ViMVpaWmLfvn2RzWYrPc64cZy1xXGevVKpFIcOHYrm5uaYNMkZ\
WUwsK4BUpUmTJsXcuXMrPca4ymazNf0P6QmOs7Y4zrNj5Y9K8SMHAEBiBCAAQGIEIFxgGhoa4tFH\
H42GhoZKjzKuHGdtcZxQXXwIBAAgMVYAAQASIwABABIjAAEAEiMAAQASIwDhAvLYY4/FZz7zmZg2\
bVrMmDFj2H327t0bN954Y0ybNi1mz54dX/va12JgYGBiBz1PzzzzTHz0ox+Niy66KK699tp48803\
Kz3SeXv99dfjS1/6UjQ3N0ddXV1s3rx5yOOlUinWrl0bTU1NMXXq1FiyZEn86le/qsyw52jdunVx\
9dVXx/Tp02P27Nlx8803R0dHx5B9jhw5Em1tbXHppZdGJpOJW2+9NXp6eio08blZv359XHXVVeWL\
Pbe2tsYrr7xSfrwWjhEEIFxAjh49Grfffnvce++9wz5+/PjxuPHGG+Po0aPx05/+NL7//e/Hc889\
F2vXrp3gSc/dCy+8EKtXr45HH300fv7zn8eiRYti2bJlsX///kqPdl4OHz4cixYtimeeeWbYx594\
4on4zne+Exs2bIgdO3bExRdfHMuWLYsjR45M8KTnbvv27dHW1hZvvPFGbNmyJY4dOxZLly6Nw4cP\
l/d54IEH4qWXXooXX3wxtm/fHl1dXXHLLbdUcOqzN3fu3Hj88cdj586d8dZbb8UNN9wQN910U7z7\
7rsRURvHCFECLjjPPvtsKZfLfWj7P//zP5cmTZpUKhQK5W3r168vZbPZUn9//wROeO6uueaaUltb\
W/n+8ePHS83NzaV169ZVcKqxFRGlTZs2le8PDg6W8vl86cknnyxvO3jwYKmhoaH0gx/8oAITjo39\
+/eXIqK0ffv2Uqn0wTFNmTKl9OKLL5b3+dd//ddSRJTa29srNeaYuOSSS0p///d/X9PHSFqsAEIV\
aW9vj09+8pPR2NhY3rZs2bIoFovl1YkL2dGjR2Pnzp2xZMmS8rZJkybFkiVLor29vYKTja/33nsv\
CoXCkOPO5XJx7bXXVvVx9/b2RkTEzJkzIyJi586dcezYsSHHeeWVV8a8efOq9jiPHz8ezz//fBw+\
fDhaW1tr8hhJ0+RKDwCMXqFQGBJ/EVG+XygUKjHSWfnNb34Tx48fH/YYdu/eXaGpxt+Jv5vhjrsa\
/t6GMzg4GKtWrYrPfvaz8YlPfCIiPjjO+vr6D52/Wo3H+fbbb0dra2scOXIkMplMbNq0KRYuXBi7\
du2qmWMkbVYAYZw99NBDUVdXN+KtluOH2tTW1hbvvPNOPP/885UeZVxcccUVsWvXrtixY0fce++9\
sWLFivjlL39Z6bFgzFgBhHH24IMPxl133TXiPpdffvmoniufz3/oE7MnPn2Yz+fPab6JdNlll8VH\
PvKRD31isqenpyrmP1cnjq2npyeamprK23t6euJTn/pUhaY6d/fdd1+8/PLL8frrr8fcuXPL2/P5\
fBw9ejQOHjw4ZIWsGv9+6+vrY8GCBRERsXjx4vjZz34WTz/9dNxxxx01c4ykzQogjLNZs2bFlVde\
OeKtvr5+VM/V2toab7/99pBPzG7ZsiWy2WwsXLhwvA5hzNTX18fixYtj69at5W2Dg4OxdevWaG1t\
reBk42v+/PmRz+eHHHexWIwdO3ZU1XGXSqW47777YtOmTfGTn/wk5s+fP+TxxYsXx5QpU4YcZ0dH\
R+zdu7eqjnM4g4OD0d/fX9PHSFqsAMIFZO/evfH+++/H3r174/jx47Fr166IiFiwYEFkMplYunRp\
LFy4ML785S/HE088EYVCIR5++OFoa2uLhoaGyg4/SqtXr44VK1bEpz/96bjmmmviqaeeisOHD8fd\
d99d6dHOS19fX+zZs6d8/7333otdu3bFzJkzY968ebFq1ar4xje+ER/72Mdi/vz58cgjj0Rzc3Pc\
fPPNlRv6LLW1tcXGjRvjhz/8YUyfPr18zlsul4upU6dGLpeLlStXxurVq2PmzJmRzWbj/vvvj9bW\
1rjuuusqPP3orVmzJpYvXx7z5s2LQ4cOxcaNG+O1116LV199tWaOEVwGBi4gK1asKEXEh27btm0r\
7/PrX/+6tHz58tLUqVNLl112WenBBx8sHTt2rHJDn4Pvfve7pXnz5pXq6+tL11xzTemNN96o9Ejn\
bdu2bcP+3a1YsaJUKn1wKZhHHnmk1NjYWGpoaCh94QtfKHV0dFR26LM03PFFROnZZ58t7/O73/2u\
9Jd/+ZelSy65pDRt2rTSn/zJn5S6u7srN/Q5+MpXvlL6vd/7vVJ9fX1p1qxZpS984QulH//4x+XH\
a+EYoa5UKpUmPjsBAKgU5wACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYA\
AgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIA\
JEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACTm\
/wM/8peVg/PuJwAAAABJRU5ErkJggg==\
"


    /* set a timeout to make sure all the above elements are created before
       the object is initialized. */
    setTimeout(function() {
        animbf18fa8feeef42df9ff1917d1946c4bf = new Animation(frames, img_id, slider_id, 500.0,
                                 loop_select_id);
    }, 0);
  })()
</script>
</div>
</div>
</section>
<section id="running-the-algorithm-on-the-gpu" class="level2">
<h2 class="anchored" data-anchor-id="running-the-algorithm-on-the-gpu">Running the Algorithm on the GPU</h2>
<p>Instead of updating one data point at a time:</p>
<div class="sourceCode" id="cb90" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> one_update(X):</span>
<span id="cb90-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i, x <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">enumerate</span>(X):</span>
<span id="cb90-3">        dist <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.sqrt(((x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>))</span>
<span id="cb90-4">        weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gaussian(dist, <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>)</span>
<span id="cb90-5">        X[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (weight[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>weight.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span></code></pre></div>
<p>What if we updates one batch at a time on the GPU?</p>
<div id="cell-101" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="4e4708eb-f6ad-4c71-9a8b-dc5ec04ab5b7" data-execution_count="74">
<div class="sourceCode cell-code" id="cb91" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1">bs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span></span>
<span id="cb91-2">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.clone()</span>
<span id="cb91-3">x <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> X[:bs]</span>
<span id="cb91-4">x.shape,X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>(torch.Size([5, 2]), torch.Size([1500, 2]))</code></pre>
</div>
</div>
<p>To calculate the distance between the two, we have to first subtract them. To do this subtraction, the current dimensions won’t work (as 1500 is not compatible with 5):</p>
<div id="cell-103" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:141}}" data-outputid="50d7fd6a-10a3-4dba-bd94-73a600ac094a" data-execution_count="75">
<div class="sourceCode cell-code" id="cb93" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1">x<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X</span></code></pre></div>
<div class="cell-output cell-output-error">
<div class="ansi-escaped-output">
<pre><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-75-d3d3295c0dec&gt;</span> in <span class="ansi-cyan-fg">&lt;cell line: 0&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>x<span class="ansi-blue-fg">-</span>X

<span class="ansi-red-fg">RuntimeError</span>: The size of tensor a (5) must match the size of tensor b (1500) at non-singleton dimension 0</pre>
</div>
</div>
</div>
<p>Let’s think about what we are trying to do here. We want to subtract from each point in the batch <code>x</code> every point in the full set <code>X</code>. So each pair of 1500 coordinates need to be subtracted from each pair of 5 coordinates.</p>
<p>I find it easier to start with “just making the dimensions work” for broadcasting.</p>
<div id="cell-106" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ebd280c5-981b-49d5-b4b1-465cf4cb2c59" data-execution_count="76">
<div class="sourceCode cell-code" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1">x[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>].shape, X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>(torch.Size([1, 5, 2]), torch.Size([1500, 1, 2]))</code></pre>
</div>
</div>
<p>Going right to left: the last dimension matches (2), 1 is compatible with 5 and 1 is compatible with 1500. We can subtract these two tensors.</p>
<div id="cell-108" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b6a5c8c5-dd00-4747-c663-f38bc965afc1" data-execution_count="77">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">(x[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>torch.Size([1500, 5, 2])</code></pre>
</div>
</div>
<p>The result is 1500 sets of 5 coordinate pairs. The 5 coordinate pairs are the difference between the coordinates in batch <code>x</code> and a coordinate in <code>X</code>.</p>
<p>Checking this manually, let’s take the first point in <code>x</code>.</p>
<div id="cell-111" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d5f5ddfb-e497-4742-c175-ebf6db35494a" data-execution_count="78">
<div class="sourceCode cell-code" id="cb98" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1">x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>torch.Size([2])</code></pre>
</div>
</div>
<p>The dimension of 2 is compatible with the last dimension of <code>X</code> so we can subtract these shapes directly.</p>
<div id="cell-113" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="a293bd2c-da84-4dbe-868c-f2a776042d98" data-execution_count="79">
<div class="sourceCode cell-code" id="cb100" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1">(x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<p>This difference is equal to the first item of the batch in the broadcasted version.</p>
<div id="cell-115" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2effa53b-6762-4b72-9419-c7105cf63f07" data-execution_count="81">
<div class="sourceCode cell-code" id="cb102" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1">((x[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> X) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> (x[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>])[:,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>tensor(1.)</code></pre>
</div>
</div>
<p>With that under my belt, I’ll now visualize the broadcasting operation to better understand why the dimensions “just work”.</p>
<p>Adding the unit axis to <code>x</code> (our batch of 5 coordinates) as the first dimension is not as intuitive visually as it just adds a pair of brackets to the outside of the 5 coordinates. However, what this does is allow the set of 5 coordinates (as a group) to be broadcasted across another dimension of any size.</p>
<div id="cell-118" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="892f60a0-7101-4652-94b9-267b74ed5f4e" data-execution_count="82">
<div class="sourceCode cell-code" id="cb104" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<pre><code>tensor([[29.764, 26.161],
        [28.472, 30.493],
        [27.549, 23.130],
        [23.500, 26.879],
        [27.327, 28.650]])</code></pre>
</div>
</div>
<div id="cell-119" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ac571ee7-26d4-40e7-b3a8-08e0e5df58b3" data-execution_count="83">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1">x[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>tensor([[[29.764, 26.161],
         [28.472, 30.493],
         [27.549, 23.130],
         [23.500, 26.879],
         [27.327, 28.650]]])</code></pre>
</div>
</div>
<p>Adding the unit axis as the second dimension to <code>X</code> (our full set of 1500 coordinates) is more visually intuitive—we’ve added a pair of brackets around each pair of coordinates, making them broadcastable to any other dimension.</p>
<div id="cell-121" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c12a9c8b-b0ff-41a4-9fde-23d5d1f6a456" data-execution_count="84">
<div class="sourceCode cell-code" id="cb108" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1">X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>tensor([[29.764, 26.161],
        [28.472, 30.493],
        [27.549, 23.130],
        ...,
        [32.214,  4.997],
        [30.872,  4.339],
        [28.347,  4.248]])</code></pre>
</div>
</div>
<div id="cell-122" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e7b438ba-fae5-44fb-91bd-8cb7b9df97af" data-execution_count="86">
<div class="sourceCode cell-code" id="cb110" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1">X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>tensor([[[29.764, 26.161]],

        [[28.472, 30.493]],

        [[27.549, 23.130]],

        ...,

        [[32.214,  4.997]],

        [[30.872,  4.339]],

        [[28.347,  4.248]]])</code></pre>
</div>
</div>
<p>So our batch of 5 coordinates <code>x</code> can now be broadcasted as many times as needed, and each pair of coordinates in <code>X</code> can also be broadcasted as many times as needed.</p>
<p>The result: each pair of coordinates in <code>X</code> is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch. And the batch is broadcasted 1500 times so that each pair of coordinates in <code>X</code> can be subtracted from it.</p>
<p>Looking at each of those statements visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-7" title="Each pair of coordinates in X is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/2.png" class="img-fluid figure-img" alt="Each pair of coordinates in X is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch"></a></p>
<figcaption>Each pair of coordinates in X is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-8" title="The batch x is broadcasted 1500 times so that each pair of coordinates in X can be subtracted from it."><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/3.png" class="img-fluid figure-img" alt="The batch x is broadcasted 1500 times so that each pair of coordinates in X can be subtracted from it."></a></p>
<figcaption>The batch <code>x</code> is broadcasted 1500 times so that each pair of coordinates in <code>X</code> can be subtracted from it.</figcaption>
</figure>
</div>
<p>With the understood, I can now continue with the batched implementation of the algorithm. With the correct shapes, thanks to adding unit axes, we can create a batched distance function:</p>
<div id="cell-128" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb112" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> dist_b(a,b): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> (((a[<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>b[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>])<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)).sqrt()</span></code></pre></div>
</div>
<div id="cell-129" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ce2e61e4-4895-472b-d120-d0844f6fbe51" data-execution_count="90">
<div class="sourceCode cell-code" id="cb113" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1">dist_b(x,X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>torch.Size([1500, 5])</code></pre>
</div>
</div>
<p>We now have 5 distances for each of the 1500 items in the dataset.</p>
<div id="cell-131" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="46dc7bba-8d45-40f6-c502-90d9438dba39" data-execution_count="91">
<div class="sourceCode cell-code" id="cb115" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1">dist_b(x,X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>tensor([[ 0.000,  4.521,  3.754,  6.305,  3.483],
        [ 4.521,  0.000,  7.421,  6.148,  2.170],
        [ 3.754,  7.421,  0.000,  5.518,  5.524],
        ...,
        [21.305, 25.769, 18.724, 23.553, 24.152],
        [21.850, 26.264, 19.083, 23.714, 24.568],
        [21.958, 26.246, 18.899, 23.144, 24.423]])</code></pre>
</div>
</div>
<p>The first row are the distances between the first coordinate pair in <code>X</code> and each of the coordinate pairs in the batch. The second row contains distances between the <em>second</em> coordinate pair in `X and each of the batch coordinate pairs. And so on an so forth for 1500 rows. Each with 5 distances representing the distances to the batch items.</p>
<p>We pass this tensor into our <code>gaussian</code> and get back our weights.</p>
<div id="cell-134" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="97cadee8-dfa3-4e93-cace-bc52cf9d31bc" data-execution_count="92">
<div class="sourceCode cell-code" id="cb117" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1">weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gaussian(dist_b(x, X), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>)</span>
<span id="cb117-2">weight, weight.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>(tensor([[    0.160,     0.031,     0.052,     0.007,     0.060],
         [    0.031,     0.160,     0.002,     0.008,     0.109],
         [    0.052,     0.002,     0.160,     0.014,     0.014],
         ...,
         [    0.000,     0.000,     0.000,     0.000,     0.000],
         [    0.000,     0.000,     0.000,     0.000,     0.000],
         [    0.000,     0.000,     0.000,     0.000,     0.000]]),
 torch.Size([1500, 5]))</code></pre>
</div>
</div>
<div id="cell-135" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="09929ac2-c816-45e0-ea6c-fd4a2dff55d1" data-execution_count="93">
<div class="sourceCode cell-code" id="cb119" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1">weight[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>tensor([[0.160, 0.031, 0.052, 0.007, 0.060],
        [0.031, 0.160, 0.002, 0.008, 0.109],
        [0.052, 0.002, 0.160, 0.014, 0.014],
        [0.007, 0.008, 0.014, 0.160, 0.038],
        [0.060, 0.109, 0.014, 0.038, 0.160]])</code></pre>
</div>
</div>
<p>Looking at the first 5 rows of our weights we have a square matrix—the weights between the first 5 points (i.e.&nbsp;the points in our batch). From row 6 we have the weights from these 5 points to point 6.</p>
<p>Technically we could have a batch size of 1500 and the weights in full would be a square matrix.</p>
<p>Now for the fun part! Understanding broadcasting so we can perform the weighted average, which starts with an elementwise multiplication betwee the weights and the data points.</p>
<p>Conceptually we want something like this (example shown for the first two batch items’ weights)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-9" title="Multiplying weights by X and summing down the columns to get a pair of coordinates"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/4.png" class="img-fluid figure-img" alt="Multiplying weights by X and summing down the columns to get a pair of coordinates"></a></p>
<figcaption>Multiplying weights by <code>X</code> and summing down the columns to get a pair of coordinates</figcaption>
</figure>
</div>
<div id="cell-141" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e2bc5d14-794d-431b-9fc9-36f9f77748ff" data-execution_count="94">
<div class="sourceCode cell-code" id="cb121" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1">weight.shape,X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>(torch.Size([1500, 5]), torch.Size([1500, 2]))</code></pre>
</div>
</div>
<p>The last dimension of each tensor is not compatible (5 and 2). We need to introduce a unit axis so that we can broadcast the 5 batch items to each of the 1500 coordinate pairs.</p>
<p>We’ll again start by “just making the dimensions work”, adding a unit axis to the end of <code>weight</code> and the beginning of <code>X</code>. Scanning the dimensions left to right: 1 and 2 are compatible, 5 and 1 are compatible, 1500 and 1500 are compatible.</p>
<div id="cell-144" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="eb218202-3664-40fd-878b-e5edefae4afb" data-execution_count="96">
<div class="sourceCode cell-code" id="cb123" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1">weight[...,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>].shape, X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="96">
<pre><code>(torch.Size([1500, 5, 1]), torch.Size([1500, 1, 2]))</code></pre>
</div>
</div>
<div id="cell-145" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="88879916-329f-4984-a4ea-b78bb04ae309" data-execution_count="98">
<div class="sourceCode cell-code" id="cb125" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1">(weight[...,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>torch.Size([1500, 5, 2])</code></pre>
</div>
</div>
<p>We’ll sum down the first dimension to get 5 pairs of coordinate.</p>
<div id="cell-147" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="799cde40-d374-42b5-90e3-71df21d6f19a" data-execution_count="100">
<div class="sourceCode cell-code" id="cb127" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1">(weight[...,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>The first pair of coordinates <code>[296.880, 291.612]</code> are the sum of the first pair of elementwise products in each set of 5 batched items in each of the 1500 rows.</p>
<div id="cell-149" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="38638dce-e5bb-4d73-d797-f327004f65b2" data-execution_count="102">
<div class="sourceCode cell-code" id="cb129" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1">(weight[...,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>tensor([[[    4.750,     4.175],
         [    0.926,     0.814],
         [    1.539,     1.352],
         [    0.197,     0.174],
         [    1.799,     1.581]],

        [[    0.886,     0.948],
         [    4.544,     4.866],
         [    0.055,     0.059],
         [    0.221,     0.237],
         [    3.117,     3.338]],

        [[    1.424,     1.196],
         [    0.054,     0.045],
         [    4.396,     3.691],
         [    0.385,     0.323],
         [    0.383,     0.321]],

        ...,

        [[    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000]],

        [[    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000]],

        [[    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000]]])</code></pre>
</div>
</div>
<div id="cell-150" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="8b9975f5-7a26-4b50-c422-516c074f1457" data-execution_count="101">
<div class="sourceCode cell-code" id="cb131" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1">(weight[...,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>])[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>tensor([[    4.750,     4.175],
        [    0.886,     0.948],
        [    1.424,     1.196],
        ...,
        [    0.000,     0.000],
        [    0.000,     0.000],
        [    0.000,     0.000]])</code></pre>
</div>
</div>
<div id="cell-151" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e933a913-9612-43f7-b045-e1cdfa54246c" data-execution_count="103">
<div class="sourceCode cell-code" id="cb133" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1">(weight[...,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>])[:, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>,:].<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="103">
<pre><code>tensor([296.880, 291.612])</code></pre>
</div>
</div>
<p>Looking at this visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="5.png" class="lightbox" data-gallery="quarto-lightbox-gallery-10" title="Elementwise multiplication of weight[...,None] and X[None] followed by sum(0) down the columns"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/5.png" class="img-fluid figure-img" alt="Elementwise multiplication of weight[...,None] and X[None] followed by sum(0) down the columns"></a></p>
<figcaption>Elementwise multiplication of <code>weight[...,None]</code> and <code>X[None]</code> followed by <code>sum(0)</code> down the columns</figcaption>
</figure>
</div>
<div id="cell-154" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="24c589bb-5afd-4a22-b782-d02fda9014d0" data-execution_count="104">
<div class="sourceCode cell-code" id="cb135" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1">num <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (weight[...,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>X[:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb135-2">num.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<pre><code>torch.Size([5, 2])</code></pre>
</div>
</div>
<div id="cell-155" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c2cd5385-3d97-4466-f358-1909a3052608" data-execution_count="105">
<div class="sourceCode cell-code" id="cb137" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1">num</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="105">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>Since we are performing an elementwise multiplication follow by a sum, we can use Einstein Summation!</p>
<div id="cell-157" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="351261a0-1f6c-42c0-b9a3-59ba6a9d018b" data-execution_count="106">
<div class="sourceCode cell-code" id="cb139" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1">torch.einsum(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ij,ik-&gt;jk'</span>, weight, X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="106">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>Similary, we can also use matrix multiplication:</p>
<div id="cell-159" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="6ac52bec-aa75-4dcf-e09a-b109ceb88075" data-execution_count="107">
<div class="sourceCode cell-code" id="cb141" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1">weight.T<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="107">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>To get our weighted average, we divide by the sum of weights.</p>
<div id="cell-161" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="c26dfad0-c4fe-41b3-c3a6-90e2bd57224b" data-execution_count="108">
<div class="sourceCode cell-code" id="cb143" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1">div <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> weight.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, keepdim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>).T</span>
<span id="cb143-2">div.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>torch.Size([5, 1])</code></pre>
</div>
</div>
<p>We want to perform an elementwise division (each coordinate needs to be divided by the sum of weights) so we <code>keepdim</code>.</p>
<div id="cell-163" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2faf142c-34ee-4d90-9960-0e47b687e9f1" data-execution_count="109">
<div class="sourceCode cell-code" id="cb145" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1">div</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="109">
<pre><code>tensor([[10.558],
        [17.315],
        [ 5.167],
        [10.983],
        [21.347]])</code></pre>
</div>
</div>
<div id="cell-164" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="ff53f7c2-c478-48b9-d730-25c8998caf58" data-execution_count="110">
<div class="sourceCode cell-code" id="cb147" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1">num<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>div</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>tensor([[28.118, 27.619],
        [27.519, 29.689],
        [27.145, 26.016],
        [25.334, 27.974],
        [27.047, 28.810]])</code></pre>
</div>
</div>
<p>Wrapping this into a new <code>meanshift</code> function. Each step now performs batched calculations.</p>
<div id="cell-166" class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb149" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> meanshift(data, bs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>):</span>
<span id="cb149-2">    n <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(data)</span>
<span id="cb149-3">    X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.clone()</span>
<span id="cb149-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> it <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>):</span>
<span id="cb149-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, n, bs):</span>
<span id="cb149-6">            s <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">slice</span>(i, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(i<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span>bs,n))</span>
<span id="cb149-7">            weight <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gaussian(dist_b(X[s], X), <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.5</span>)</span>
<span id="cb149-8">            div <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> weight.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, keepdim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>).T</span>
<span id="cb149-9">            X[s] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> weight.T<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>X<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>div</span>
<span id="cb149-10">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> X</span></code></pre></div>
</div>
<p>We can now utilize the GPU (since we’re doing batched calculations)</p>
<div id="cell-168" class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb150" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1">data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.cuda()</span></code></pre></div>
</div>
<div id="cell-169" class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb151" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1">X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> meanshift(data).cpu()</span></code></pre></div>
</div>
<div id="cell-170" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="e3206486-deea-434b-f00b-1c99fa7dc777" data-execution_count="117">
<div class="sourceCode cell-code" id="cb152" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span> _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>meanshift(data, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1250</span>).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.37 ms ± 43.1 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)</code></pre>
</div>
</div>
<p>Using the GPU we cut the execution time from 1.5 seconds to 6 milliseconds to achieve the same result.</p>
<div id="cell-172" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="78b63bcb-5b59-428e-86a8-4ecb22c7b14c" data-execution_count="118">
<div class="sourceCode cell-code" id="cb154" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1500</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>250.0</code></pre>
</div>
</div>
<div id="cell-173" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:430}}" data-outputid="5e20a9d4-31f5-49c6-a56c-3789affd7708" data-execution_count="119">
<div class="sourceCode cell-code" id="cb156" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1">plot_data(centroids, X, n_samples)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-92-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-92-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>If we perform the unbatched calculation using the GPU, we don’t see this speed up.</p>
<div id="cell-175" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb157" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> meanshift(data, n<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>):</span>
<span id="cb157-2">    X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> data.clone()</span>
<span id="cb157-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> it <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(n): one_update(X)</span>
<span id="cb157-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> X</span></code></pre></div>
</div>
<div id="cell-176" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b21cd686-b3e1-43ca-a8c3-7d419ab3633c" data-execution_count="122">
<div class="sourceCode cell-code" id="cb158" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>time X <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> meanshift(data.cuda()).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.33 s, sys: 969 µs, total: 1.33 s
Wall time: 1.33 s</code></pre>
</div>
</div>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Implementing mean shift clustering become an exercise in understanding broadcasting! The weighted average (elementwise multiplication followed by a summation down an axis) is well suited for broadcasting, Einstein Summation and matrix multiplication. Seeing the relationships between dimensions, and seeing how adding unit axes in a particular spot to allow for broadcasting gave me a deeper understanding of how tensor calculations work. We also saw a clear example of how the GPU only gives you a speedup if you perform batch operations on it.</p>
<p>I’m trying to grow my YouTube channel so if you’re interesting in this type of content, <a href="https://www.youtube.com/@vishal_learner">please subscribe!</a></p>


</section>

 ]]></description>
  <category>python</category>
  <category>machine learning</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/</guid>
  <pubDate>Sat, 31 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Exploring Precision in ColBERT Indexing and Retrieval</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-25-Exploring-ColBERT-Precision/</link>
  <description><![CDATA[ 




<div id="16ca24cb-857d-4d7a-8b56-be00276ccd42" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Ensure faiss-gpu is correctly installed</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> faiss</span>
<span id="cb1-2"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">hasattr</span>(faiss, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"StandardGpuResources"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>True</code></pre>
</div>
</div>
<div id="0a58e29c-75e8-4ffe-b578-02c6d3dec2a1" class="cell" data-execution_count="45">
<details class="code-fold">
<summary>Show imports</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dataset</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Queries</span>
<span id="cb3-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.infra <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Run, RunConfig, ColBERTConfig</span>
<span id="cb3-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Searcher</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb3-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy</span>
<span id="cb3-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb3-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb3-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb3-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> glob</span>
<span id="cb3-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re</span>
<span id="cb3-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pytrec_eval</span>
<span id="cb3-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pickle</span></code></pre></div>
</details>
</div>
<div id="91f7ad5d" class="cell">
<details class="code-fold">
<summary>Show indexing + memory profiling script</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> colbert</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Indexer, Searcher</span>
<span id="cb4-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.infra <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Run, RunConfig, ColBERTConfig</span>
<span id="cb4-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Queries, Collection</span>
<span id="cb4-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dataset</span>
<span id="cb4-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> threading</span>
<span id="cb4-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> time</span>
<span id="cb4-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> psutil</span>
<span id="cb4-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> datetime <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> datetime</span>
<span id="cb4-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pandas <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> pd</span>
<span id="cb4-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb4-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb4-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> argparse </span>
<span id="cb4-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pynvml</span>
<span id="cb4-15"></span>
<span id="cb4-16"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> memory_monitor(stop_event, cpu_readings, gpu_readings):</span>
<span id="cb4-17">    pynvml.nvmlInit()</span>
<span id="cb4-18">    handle <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pynvml.nvmlDeviceGetHandleByIndex(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb4-19">    </span>
<span id="cb4-20">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">while</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> stop_event.is_set():</span>
<span id="cb4-21">        mem_cpu <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> psutil.Process().memory_info().rss <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span></span>
<span id="cb4-22">        info <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pynvml.nvmlDeviceGetMemoryInfo(handle)</span>
<span id="cb4-23">        mem_gpu <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> info.used <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span></span>
<span id="cb4-24">        </span>
<span id="cb4-25">        cpu_readings.append((datetime.now(), mem_cpu))</span>
<span id="cb4-26">        gpu_readings.append((datetime.now(), mem_gpu))</span>
<span id="cb4-27">        time.sleep(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>)</span>
<span id="cb4-28"></span>
<span id="cb4-29"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> log_memory(index_name, passages):</span>
<span id="cb4-30">    stop_event <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> threading.Event()</span>
<span id="cb4-31">    cpu_readings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb4-32">    gpu_readings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb4-33">    monitor_thread <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> threading.Thread(target<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>memory_monitor, args<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(stop_event, cpu_readings, gpu_readings))</span>
<span id="cb4-34">    monitor_thread.start()</span>
<span id="cb4-35"></span>
<span id="cb4-36">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">try</span>:</span>
<span id="cb4-37">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, rank<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)):</span>
<span id="cb4-38">            config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ColBERTConfig(</span>
<span id="cb4-39">                doc_maxlen<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">220</span>,</span>
<span id="cb4-40">                nbits<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,</span>
<span id="cb4-41">                dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96</span>,</span>
<span id="cb4-42">                kmeans_niters<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,</span>
<span id="cb4-43">                index_bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">32</span>,</span>
<span id="cb4-44">                bsize<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">64</span>,</span>
<span id="cb4-45">                checkpoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answerdotai/answerai-colbert-small-v1"</span>,</span>
<span id="cb4-46">                avoid_fork_if_possible<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span></span>
<span id="cb4-47">            )</span>
<span id="cb4-48">        </span>
<span id="cb4-49">            indexer <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Indexer(checkpoint<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answerdotai/answerai-colbert-small-v1"</span>, config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>config)</span>
<span id="cb4-50">            index_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> indexer.index(name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>index_name, collection<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>passages[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"text"</span>], overwrite<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb4-51">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">finally</span>:</span>
<span id="cb4-52">        stop_event.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>()</span>
<span id="cb4-53">        monitor_thread.join()</span>
<span id="cb4-54">    </span>
<span id="cb4-55">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> cpu_readings, gpu_readings</span>
<span id="cb4-56"></span>
<span id="cb4-57"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> main():</span>
<span id="cb4-58">    parser <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> argparse.ArgumentParser(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'fp'</span>)</span>
<span id="cb4-59">    parser.add_argument(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--fp'</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, default<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"fp32"</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">help</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Floating point precision used'</span>)</span>
<span id="cb4-60">    args <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parser.parse_args()</span>
<span id="cb4-61">    fp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> args.fp</span>
<span id="cb4-62">        </span>
<span id="cb4-63">    dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ConditionalQA"</span></span>
<span id="cb4-64">    index_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'ColBERT_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">'</span></span>
<span id="cb4-65">    passages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-corpus"</span>, split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test"</span>)</span>
<span id="cb4-66"></span>
<span id="cb4-67">    cpu_readings, gpu_readings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> log_memory(index_name, passages)</span>
<span id="cb4-68"></span>
<span id="cb4-69">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># CPU RAM artifacts</span></span>
<span id="cb4-70">    start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cpu_readings[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-71">    index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time).total_seconds() <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> t, _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> cpu_readings]</span>
<span id="cb4-72">    cpu_readings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series([mem <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _, mem <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> cpu_readings], index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>index, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mem_gb"</span> )</span>
<span id="cb4-73">    cpu_readings.index.name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"time_secs"</span></span>
<span id="cb4-74">    cpu_readings.plot(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'ColBERT CPU RAM (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)'</span>, xlabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Time (sec)'</span>, ylabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Memory (GB)'</span>)</span>
<span id="cb4-75">    plt.tight_layout()</span>
<span id="cb4-76">    plt.savefig(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'colbert_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_cpu_readings.png'</span>)</span>
<span id="cb4-77">    plt.close()</span>
<span id="cb4-78">    cpu_readings.to_csv(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"colbert_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_cpu_readings.csv"</span>)</span>
<span id="cb4-79"></span>
<span id="cb4-80">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># GPU RAM artifacts</span></span>
<span id="cb4-81">    start_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> gpu_readings[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>][<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-82">    index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [(t <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> start_time).total_seconds() <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> t, _ <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> gpu_readings]</span>
<span id="cb4-83">    gpu_readings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.Series([mem <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> _, mem <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> gpu_readings], index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>index, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"mem_gb"</span> )</span>
<span id="cb4-84">    gpu_readings.index.name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"time_secs"</span></span>
<span id="cb4-85">    gpu_readings.plot(title<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'ColBERT GPU RAM (</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">)'</span>, xlabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Time (sec)'</span>, ylabel<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Memory (GB)'</span>)</span>
<span id="cb4-86">    plt.tight_layout()</span>
<span id="cb4-87">    plt.savefig(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'colbert_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_gpu_readings.png'</span>)</span>
<span id="cb4-88">    plt.close()</span>
<span id="cb4-89">    gpu_readings.to_csv(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"colbert_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>fp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">_gpu_readings.csv"</span>)</span>
<span id="cb4-90"></span>
<span id="cb4-91"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__main__"</span>:</span>
<span id="cb4-92">    main()</span></code></pre></div>
</details>
</div>
<div id="7eded5f6" class="cell">
<details class="code-fold">
<summary>Show Recall calculation script</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> datasets <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> load_dataset</span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.data <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Queries</span>
<span id="cb5-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert.infra <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Run, RunConfig, ColBERTConfig</span>
<span id="cb5-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> colbert <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Searcher</span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> plt</span>
<span id="cb5-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy</span>
<span id="cb5-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb5-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> json</span>
<span id="cb5-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tqdm</span>
<span id="cb5-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> glob</span>
<span id="cb5-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> re</span>
<span id="cb5-15"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pytrec_eval</span>
<span id="cb5-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> argparse </span>
<span id="cb5-17"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pickle</span>
<span id="cb5-18"></span>
<span id="cb5-19"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_qrels(qrels_rows):</span>
<span id="cb5-20">    qrels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb5-21">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> qrel_row <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> qrels_rows:</span>
<span id="cb5-22">        qid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> qrel_row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"query_id"</span>]</span>
<span id="cb5-23">        pid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> qrel_row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"corpus_id"</span>]</span>
<span id="cb5-24">        rel <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> qrel_row[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"score"</span>]</span>
<span id="cb5-25">        qrels.setdefault(qid, {})</span>
<span id="cb5-26">        qrels[qid][pid] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rel</span>
<span id="cb5-27">    </span>
<span id="cb5-28">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> qrels</span>
<span id="cb5-29"></span>
<span id="cb5-30"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> _recall(qrels, res):</span>
<span id="cb5-31">    evaluator <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'recall.10'</span>})</span>
<span id="cb5-32">    metrics <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> evaluator.evaluate(res)</span>
<span id="cb5-33">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(metrics) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">set</span>(qrels_rows[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"query_id"</span>]))</span>
<span id="cb5-34"></span>
<span id="cb5-35">    mean_recall <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'recall_10'</span>] <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> qid <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(metrics)</span>
<span id="cb5-36">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> mean_recall</span>
<span id="cb5-37"></span>
<span id="cb5-38"></span>
<span id="cb5-39">dataset_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ConditionalQA"</span></span>
<span id="cb5-40">queries <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-queries"</span>, split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test"</span>)</span>
<span id="cb5-41">passages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-corpus"</span>, split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test"</span>)</span>
<span id="cb5-42">qrels_rows <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> load_dataset(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">-qrels"</span>, split<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"test"</span>)</span>
<span id="cb5-43">qrels <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> get_qrels(qrels_rows)</span>
<span id="cb5-44"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(dataset_name)</span>
<span id="cb5-45"></span>
<span id="cb5-46">queries_dict <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb5-47"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> item <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> queries: queries_dict[item[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_id'</span>]] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> item[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'text'</span>]</span>
<span id="cb5-48"></span>
<span id="cb5-49"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> main():</span>
<span id="cb5-50">    parser <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> argparse.ArgumentParser(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'index'</span>)</span>
<span id="cb5-51">    parser.add_argument(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'--index'</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">type</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span>, default<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">help</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Index name'</span>)</span>
<span id="cb5-52">    args <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parser.parse_args()</span>
<span id="cb5-53">    index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> args.index</span>
<span id="cb5-54">    </span>
<span id="cb5-55">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)):</span>
<span id="cb5-56">        searcher <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Searcher(</span>
<span id="cb5-57">            index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>index,</span>
<span id="cb5-58">            config<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ColBERTConfig(</span>
<span id="cb5-59">                    ncells<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>,</span>
<span id="cb5-60">                    centroid_score_threshold<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.45</span>,</span>
<span id="cb5-61">                    ndocs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1024</span></span>
<span id="cb5-62">                )</span>
<span id="cb5-63">        )</span>
<span id="cb5-64">    </span>
<span id="cb5-65">        _queries <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Queries(data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>queries_dict)</span>
<span id="cb5-66">        ranking <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> searcher.search_all(_queries, k<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb5-67"></span>
<span id="cb5-68">    colbert_results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {}</span>
<span id="cb5-69"></span>
<span id="cb5-70">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> qid <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> ranking.todict().keys():</span>
<span id="cb5-71">        colbert_scores <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ranking.todict()[qid]</span>
<span id="cb5-72">        colbert_results[qid] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {passages[idx][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_id'</span>]: score <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> idx, _, score <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> colbert_scores}</span>
<span id="cb5-73"></span>
<span id="cb5-74">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"colbert_results_</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>index<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>split(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'_'</span>)[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">.pkl"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'wb'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>: pickle.dump(colbert_results, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>)</span>
<span id="cb5-75">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(_recall(qrels, colbert_results))</span>
<span id="cb5-76"></span>
<span id="cb5-77"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">__name__</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__main__"</span>:</span>
<span id="cb5-78">    main()</span></code></pre></div>
</details>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I ran an experiment to explore the differences between FP32 full precision and mixed precision in ColBERT indexing and retrieval. This was purely a curiosity-driven exploration - not claiming this is best practice, just wanted to see if there were any differences. This notebook shares my findings. I use the <a href="https://huggingface.co/datasets/UKPLab/dapr/viewer/ConditionalQA-docs">UKPLab/DAPR ConditionalQA dataset</a> for this exercise.</p>
<p><strong>What I did:</strong></p>
<ul>
<li>Created <a href="https://github.com/vishalbakshi/ColBERT/commits/mixed_precision_false/">a fork of ColBERT</a> and turned off all mixed precision conversions</li>
<li>Used Claude and ChatGPT to help identify all the places that needed changes (including CUDA kernels)</li>
<li>Ran indexing experiments on the UKPLab’s ConditionalQA dataset (70k documents)</li>
<li>Tracked memory usage during indexing (see script above)</li>
<li>Compared recall performance and retrieved passages (see script above)</li>
<li>Analyzed the resulting index artifacts</li>
</ul>
<p><strong>Key findings:</strong></p>
<ul>
<li>Mixed precision took 2.5x longer to index (180s vs 70s) - wasn’t expecting that</li>
<li>Mixed precision used slightly more GPU memory, full precision used more CPU memory</li>
<li>Full precision gave a tiny 0.3% recall boost (basically negligible)</li>
<li>14% of retrieved passages were different between the two approaches</li>
<li>The centroids created during indexing were significantly different</li>
<li>Different mappings between passage IDs and centroids</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aiNQ4I8YaD0?si=OKvaUtumf7q1qGYf" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="indexing-time" class="level2">
<h2 class="anchored" data-anchor-id="indexing-time">Indexing Time</h2>
<p>I was surprised to see that using mixed precision resulted in a much longer indexing time. I wonder if that would still hold over multiple iterations of indexing.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Indexing Time (seconds)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">fp32</td>
<td style="text-align: center;">70</td>
</tr>
<tr class="even">
<td style="text-align: center;">amp</td>
<td style="text-align: center;">180</td>
</tr>
</tbody>
</table>
</section>
<section id="maximum-memory-usage" class="level2">
<h2 class="anchored" data-anchor-id="maximum-memory-usage">Maximum Memory Usage</h2>
<p>Another surprise—mixed precision actually uses <em>more</em> GPU memory than full precision.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Max GPU Mem (GB)</th>
<th style="text-align: center;">Max CPU Mem (GB)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">fp32</td>
<td style="text-align: center;">5.51</td>
<td style="text-align: center;">0.824</td>
</tr>
<tr class="even">
<td style="text-align: center;">amp</td>
<td style="text-align: center;">5.78</td>
<td style="text-align: center;">0.814</td>
</tr>
</tbody>
</table>
</section>
<section id="recall10" class="level2">
<h2 class="anchored" data-anchor-id="recall10">Recall@10</h2>
<p>The differences in Recall@10 is negligible, the full precision index has a slight advantage.</p>
<p>fp32: 0.13034885692197787</p>
<p>amp: 0.1299388528219369</p>
<div id="1b1033d1-6c8f-4a37-a7d9-7c06947d2954" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.13034885692197787</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1299388528219369</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.1299388528219369</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>0.003155361857802613</code></pre>
</div>
</div>
</section>
<section id="comparing-retrieved-passages-and-scores" class="level2">
<h2 class="anchored" data-anchor-id="comparing-retrieved-passages-and-scores">Comparing Retrieved Passages and Scores</h2>
<p>Out of the 2710 total passages retrieved, 388 passages were retrieved using one index but not the other—that’s about a 14% difference in retrieved passages due to a difference in precision.</p>
<div id="7a3fc579-00a9-4fd1-9172-4b269f58bf8d" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colbert_results_fp32.pkl'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rb'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>: colbert_results_fp32 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pickle.load(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>)</span>
<span id="cb8-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'colbert_results_amp.pkl'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rb'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>: colbert_results_amp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pickle.load(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>)</span></code></pre></div>
</div>
<div id="a028a070-f72f-4696-a990-9a763cdd654f" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">colbert_results_fp32.keys() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> colbert_results_amp.keys()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>True</code></pre>
</div>
</div>
<div id="cabf9a90-e647-4ff9-9ad6-2bef0649e70c" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">colbert_results_fp32[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dev-0'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>{'265-59': 29.345699310302734,
 '8-116': 29.341297149658203,
 '8-118': 29.336307525634766,
 '8-67': 29.32498550415039,
 '8-9': 29.2913875579834,
 '8-70': 29.290199279785156,
 '270-51': 29.28421401977539,
 '40-29': 29.28375244140625,
 '107-110': 29.282079696655273,
 '459-115': 29.28005599975586}</code></pre>
</div>
</div>
<div id="a3bfb4d8-a139-4a0d-8307-0b6711e9c0c6" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">n_diffs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb13-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> qid, fp32_res <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> colbert_results_fp32.items():</span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> pid <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> fp32_res.keys():</span>
<span id="cb13-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> pid <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> colbert_results_amp[qid].keys(): </span>
<span id="cb13-5">            n_diffs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb13-6"> </span>
<span id="cb13-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> qid, amp_res <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> colbert_results_amp.items():</span>
<span id="cb13-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> pid <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> amp_res.keys():</span>
<span id="cb13-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> pid <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> colbert_results_fp32[qid].keys(): </span>
<span id="cb13-10">            n_diffs <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span>
<span id="cb13-11"></span>
<span id="cb13-12">n_diffs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>388</code></pre>
</div>
</div>
<div id="43aea657-c8b9-41af-a76c-7c36b7d8fe79" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">n_diffs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">271</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>0.14317343173431735</code></pre>
</div>
</div>
<div id="78a6ecc6-4888-4cc1-a7f9-05aed541e4fd" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">colbert_results_fp32[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'dev-0'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>{'265-59': 29.345699310302734,
 '8-116': 29.341297149658203,
 '8-118': 29.336307525634766,
 '8-67': 29.32498550415039,
 '8-9': 29.2913875579834,
 '8-70': 29.290199279785156,
 '270-51': 29.28421401977539,
 '40-29': 29.28375244140625,
 '107-110': 29.282079696655273,
 '459-115': 29.28005599975586}</code></pre>
</div>
</div>
<p>Overall, the full precision index results in a slightly lower retrieved passage score.</p>
<div id="53242388-3b1e-4945-a90e-d08ebbcc7977" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">total_amp_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb19-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> qid, amp_res <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> colbert_results_amp.items():</span>
<span id="cb19-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> score <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> amp_res.values(): total_amp_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> score</span>
<span id="cb19-4">total_amp_score</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>80438.375</code></pre>
</div>
</div>
<div id="dbc2a843-0030-409a-8ff6-7008dfd7a0e4" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">total_fp32_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb21-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> qid, fp32_res <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> colbert_results_fp32.items():</span>
<span id="cb21-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> score <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> fp32_res.values(): total_fp32_score <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> score</span>
<span id="cb21-4">total_fp32_score</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>80435.61682701111</code></pre>
</div>
</div>
</section>
<section id="comparing-index-artifacts" class="level2">
<h2 class="anchored" data-anchor-id="comparing-index-artifacts">Comparing Index Artifacts</h2>
<div id="ded306cc-e4b8-4289-be81-c53265a8aa8e" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">colbert_fp32_root <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./experiments/default/indexes/ColBERT_ConditionalQA_fp32"</span></span>
<span id="cb23-2">colbert_amp_root  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"./experiments/default/indexes/ColBERT_ConditionalQA_amp"</span></span></code></pre></div>
</div>
<section id="metadata.json" class="level3">
<h3 class="anchored" data-anchor-id="metadata.json">metadata.json</h3>
<p>Both indexes (full precision and mixed precision) produce the same metadata.json.</p>
<div id="a423ba98-ad7c-4423-9527-8ed471147196" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb24-2">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"index_bsize"</span>,</span>
<span id="cb24-3">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nbits"</span>,</span>
<span id="cb24-4">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kmeans_niters"</span>,</span>
<span id="cb24-5">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dim"</span>,</span>
<span id="cb24-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"rank"</span>,</span>
<span id="cb24-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpus"</span>,</span>
<span id="cb24-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nranks"</span>,</span>
<span id="cb24-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_chunks"</span>,</span>
<span id="cb24-10">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_partitions"</span>,</span>
<span id="cb24-11">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_embeddings"</span>,</span>
<span id="cb24-12">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"avg_doclen"</span></span>
<span id="cb24-13">    ]</span></code></pre></div>
</div>
<div id="467168b7-1129-4701-a929-a8d6bb00c3c3" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>colbert_fp32_root<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/metadata.json"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f: colbert_fp32_metadata <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> json.load(f)</span>
<span id="cb25-2"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>colbert_amp_root<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/metadata.json"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'r'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f: colbert_amp_metadata <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> json.load(f)</span></code></pre></div>
</div>
<div id="ff366466-afa4-499e-af7f-6dce67666fef" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> params:</span>
<span id="cb26-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> p <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_chunks"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_partitions"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"num_embeddings"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"avg_doclen"</span>]: <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> colbert_fp32_metadata[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'config'</span>][p] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> colbert_amp_metadata[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'config'</span>][p], p</span>
<span id="cb26-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> p <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"avg_doclen"</span>: <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> (colbert_fp32_metadata[p] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> colbert_amp_metadata[p]) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-7</span></span>
<span id="cb26-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>: <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">assert</span> colbert_fp32_metadata[p] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> colbert_amp_metadata[p], p</span></code></pre></div>
</div>
</section>
<section id="centroids.pt" class="level3">
<h3 class="anchored" data-anchor-id="centroids.pt">centroids.pt</h3>
<p>There is a significant difference in centroids—meaning that the sampled document token embeddings and their clusters are different based on the type of precision used.</p>
<div id="24a568ec-8c81-49fc-8339-7188e7fbd5c0" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">colbert_fp32_centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>colbert_fp32_root<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/centroids.pt"</span>)</span>
<span id="cb27-2">colbert_amp_centroids <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>colbert_amp_root<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/centroids.pt"</span>)</span></code></pre></div>
</div>
<div id="6623333c-429f-4aa0-ad25-804ba63c0a5e" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">torch.allclose(colbert_fp32_centroids, colbert_amp_centroids.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>())</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>False</code></pre>
</div>
</div>
<div id="1ea3d26f-6eb3-49b8-bc10-84411548adf5" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">torch.allclose(colbert_fp32_centroids.half(), colbert_amp_centroids)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>False</code></pre>
</div>
</div>
<div id="137ce115-b1dd-43fc-aa2c-85a8328eee23" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">torch.allclose(colbert_fp32_centroids, colbert_amp_centroids.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>(), atol<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>True</code></pre>
</div>
</div>
<div id="b37ef31c-449b-4fee-ac32-db53e22aa2c4" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">colbert_fp32_centroids.flatten().shape, colbert_amp_centroids.flatten().shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>(torch.Size([1572864]), torch.Size([1572864]))</code></pre>
</div>
</div>
<div id="ee48d045-d537-4eb8-be77-1cab42e18901" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">plt.scatter(colbert_fp32_centroids.flatten().cpu().numpy(), colbert_amp_centroids.flatten().cpu().numpy(), s<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><a href="index_files/figure-html/cell-24-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-25-Exploring-ColBERT-Precision/index_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="ivf.pid.pt" class="level3">
<h3 class="anchored" data-anchor-id="ivf.pid.pt">ivf.pid.pt</h3>
<p>Finally, there is a difference in mappings between passages IDs and centroid IDs. Interestingly, mixed precision results in more passage IDs mapped to centroids.</p>
<div id="1376756c-c23a-4c52-8781-31bde8702914" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">colbert_fp32_ivf <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>colbert_fp32_root<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/ivf.pid.pt"</span>)</span>
<span id="cb37-2">colbert_amp_ivf  <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.load(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>colbert_amp_root<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">/ivf.pid.pt"</span>)</span></code></pre></div>
</div>
<div id="8550ccb3-21e0-48e4-ab58-19a6a63b7891" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">colbert_fp32_ivf[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape, colbert_amp_ivf[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>(torch.Size([963143]), torch.Size([975457]))</code></pre>
</div>
</div>
<div id="0e13f0a8-4ec1-4dc4-a60c-56661d431875" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">colbert_amp_ivf[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>colbert_fp32_ivf[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>12314</code></pre>
</div>
</div>
<div id="96492aa3-8d5b-45ac-a978-dcbbb30083ef" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">colbert_fp32_ivf[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].shape, colbert_amp_ivf[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>(torch.Size([16384]), torch.Size([16384]))</code></pre>
</div>
</div>
</section>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>This is just one small dataset with short documents (avg 15 tokens). Sample size of one. I also might have missed some precision conversions in my implementation. Don’t take this as definitive - just an interesting exploration of how precision affects the ColBERT pipeline. Here’s a summary again of my key findings:</p>
<ul>
<li>Mixed precision took 2.5x longer to index (180s vs 70s) - wasn’t expecting that</li>
<li>Mixed precision used slightly more GPU memory, full precision used more CPU memory</li>
<li>Full precision gave a tiny 0.3% recall boost (basically negligible)</li>
<li>14% of retrieved passages were different between the two approaches</li>
<li>The centroids created during indexing were significantly different</li>
<li>Different mappings between passage IDs and centroids</li>
</ul>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>ColBERT</category>
  <category>information retrieval</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-25-Exploring-ColBERT-Precision/</guid>
  <pubDate>Sun, 25 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>The Evolution of Matrix Multiplication (fastai course Part 2 Lessons 11 and 12)</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/</link>
  <description><![CDATA[ 




<div id="cell-1" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="47621598-8fd6-4b6a-9893-4dc62cc9ee45" data-execution_count="2">
<details class="code-fold">
<summary>Show setup code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># !conda install -y -c nvidia/label/cuda-12.8.0 cuda-toolkit</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># !conda install -y numba</span></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># !conda install -y fastcore -c fastai</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb1-7"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> pickle, gzip, math, os, time, shutil</span>
<span id="cb1-8"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> urllib.request <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> urlretrieve</span>
<span id="cb1-9"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> torch</span>
<span id="cb1-10"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> torch <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tensor</span>
<span id="cb1-11"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb1-12"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> numba <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> njit</span>
<span id="cb1-13"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> array</span>
<span id="cb1-14"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> fastcore.test <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span></span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> numba <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> cuda</span>
<span id="cb1-17"></span>
<span id="cb1-18">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb1-19">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>, linewidth<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">140</span>)</span>
<span id="cb1-20"></span>
<span id="cb1-21">MNIST_URL<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'</span></span>
<span id="cb1-22">path_data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'data'</span>)</span>
<span id="cb1-23">path_data.mkdir(exist_ok<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb1-24">path_gz <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> path_data<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'mnist.pkl.gz'</span></span>
<span id="cb1-25"></span>
<span id="cb1-26"></span>
<span id="cb1-27"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> path_gz.exists(): urlretrieve(MNIST_URL, path_gz)</span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> gzip.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(path_gz, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'rb'</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f: ((x_train, y_train), (x_valid, y_valid), _) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pickle.load(f, encoding<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'latin-1'</span>)</span>
<span id="cb1-30"></span>
<span id="cb1-31">x_train,y_train,x_valid,y_valid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(tensor, (x_train,y_train,x_valid,y_valid))</span>
<span id="cb1-32">x_train.shape</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>torch.Size([50000, 784])</code></pre>
</div>
</div>
<div id="cell-2" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="a4f3c78a-4f61-4f8c-cf21-4c103270afd9" data-execution_count="3">
<details class="code-fold">
<summary>Show setup code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">torch.manual_seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)</span>
<span id="cb3-2">weights <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.randn(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">784</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb3-3">bias <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>)</span>
<span id="cb3-4"></span>
<span id="cb3-5">m1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_valid[:<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5</span>]</span>
<span id="cb3-6">m2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> weights</span>
<span id="cb3-7"></span>
<span id="cb3-8">m1.shape,m2.shape</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>(torch.Size([5, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/iV63qy4ETJQ?si=RVTeCMWgSHf_IHq0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<section id="digit-subset" class="level3">
<h3 class="anchored" data-anchor-id="digit-subset">5-digit Subset</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">18.1 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">69.2 μs</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">83.1 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Cuda</td>
<td style="text-align: center;">108 μs</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">108 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">203 μs</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">542 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>torch.dot</code></td>
<td style="text-align: center;">1.19 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Element-wise PyTorch Ops</td>
<td style="text-align: center;">1.49 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Nested for-loops</td>
<td style="text-align: center;">604 ms</td>
</tr>
</tbody>
</table>
</section>
<section id="full-dataset-50k-images" class="level3">
<h3 class="anchored" data-anchor-id="full-dataset-50k-images">Full Dataset (50k images)</h3>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>cuda</code></td>
<td style="text-align: center;">541 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">3.91 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">5.8 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">5.87 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">663 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">1.26 s</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">3.71 s</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="version-0-nested-for-loops" class="level2">
<h2 class="anchored" data-anchor-id="version-0-nested-for-loops">Version 0: Nested For-Loops</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Excalidraw diagram showing nested for-loop implementation of matrix multiplication"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/1.png" class="img-fluid figure-img" alt="Excalidraw diagram showing nested for-loop implementation of matrix multiplication"></a></p>
<figcaption>Excalidraw diagram showing nested for-loop implementation of matrix multiplication</figcaption>
</figure>
</div>
<div id="cell-11" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="f1b07e28-eb6a-42f0-9863-d962b0843dff" data-execution_count="70">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">ar,ac <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m1.shape <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># n_rows * n_cols</span></span>
<span id="cb5-2">br,bc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m2.shape</span>
<span id="cb5-3">(ar,ac),(br,bc)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>((5, 784), (784, 10))</code></pre>
</div>
</div>
<div id="cell-12" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="50202d80-fbe0-4ea8-aa39-4fe0691cb4b0" data-execution_count="71">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">t1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb7-2">t1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div id="cell-13" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar):         <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 5</span></span>
<span id="cb9-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(bc):     <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 10</span></span>
<span id="cb9-3">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ac): <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 784</span></span>
<span id="cb9-4">            t1[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> m1[i,k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> m2[k,j]</span></code></pre></div>
</div>
<div id="cell-14" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="de65336e-e04e-4d55-81aa-228a6f7bf7bf" data-execution_count="73">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">t1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div id="cell-15" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="a46dd7f0-06d7-4d86-aa3a-577743471963" data-execution_count="74">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],
        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],
        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],
        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],
        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])</code></pre>
</div>
</div>
<div id="cell-16" class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b):</span>
<span id="cb14-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape,b.shape</span>
<span id="cb14-3">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb14-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar):</span>
<span id="cb14-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(bc):</span>
<span id="cb14-6">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ac): c[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> a[i,k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[k,j]</span>
<span id="cb14-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> c</span></code></pre></div>
</div>
<div id="cell-17" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="75bfe38a-2fc3-4f8d-8934-7fbd7c8036e4" data-execution_count="81">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>time _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 675 ms, sys: 0 ns, total: 675 ms
Wall time: 674 ms</code></pre>
</div>
</div>
</section>
<section id="version-1-numba-dot-product" class="level2">
<h2 class="anchored" data-anchor-id="version-1-numba-dot-product">Version 1: Numba Dot Product</h2>
<p>Replacing the inner-most for-loop with a numba dot-product implementation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Excalidraw diagram showing dot-product implementation of matrix multiplication"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/2.png" class="img-fluid figure-img" alt="Excalidraw diagram showing dot-product implementation of matrix multiplication"></a></p>
<figcaption>Excalidraw diagram showing dot-product implementation of matrix multiplication</figcaption>
</figure>
</div>
<div id="cell-21" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@njit</span></span>
<span id="cb17-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> dot(a,b):</span>
<span id="cb17-3">    res <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb17-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(a)): res<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span>a[i]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>b[i]</span>
<span id="cb17-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> res</span></code></pre></div>
</div>
<div id="cell-22" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="217464df-4573-40a9-f926-37186bb47d53" data-execution_count="83">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>time dot(array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]),array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 124 ms, sys: 0 ns, total: 124 ms
Wall time: 123 ms</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>20.0</code></pre>
</div>
</div>
<div id="cell-23" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="64bc96a7-7cc1-404a-c47b-6b8a54d5c6b6" data-execution_count="84">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>time dot(array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>]),array([<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">2.</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 26 μs, sys: 2 μs, total: 28 μs
Wall time: 32.4 μs</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>20.0</code></pre>
</div>
</div>
<div id="cell-24" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b):</span>
<span id="cb24-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape,b.shape</span>
<span id="cb24-3">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb24-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar):</span>
<span id="cb24-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dot(a[i,:], b[:,j])</span>
<span id="cb24-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> c</span></code></pre></div>
</div>
<div id="cell-25" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">m1a,m2a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m1.numpy(),m2.numpy()</span></code></pre></div>
</div>
<div id="cell-26" class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div id="cell-27" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="10968392-3789-4272-b708-9a99560bad48" data-execution_count="91">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> matmul(m1a,m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>495 μs ± 39.4 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-2-element-wise-operations" class="level2">
<h2 class="anchored" data-anchor-id="version-2-element-wise-operations">Version 2: Element-wise Operations</h2>
<div id="cell-29" class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b):</span>
<span id="cb29-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape,b.shape</span>
<span id="cb29-3">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb29-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar):</span>
<span id="cb29-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[i,:] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[:,j]).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>()</span>
<span id="cb29-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> c</span></code></pre></div>
</div>
<div id="cell-30" class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div id="cell-31" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="fc775c33-b82e-4076-ef1b-5eb260224b56" data-execution_count="94">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.48 ms ± 354 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-3-torch.dot" class="level2">
<h2 class="anchored" data-anchor-id="version-3-torch.dot">Version 3: <code>torch.dot</code></h2>
<div id="cell-33" class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b):</span>
<span id="cb33-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape,b.shape</span>
<span id="cb33-3">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb33-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar):</span>
<span id="cb33-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.dot(a[i,:], b[:,j])</span>
<span id="cb33-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> c</span></code></pre></div>
</div>
<div id="cell-34" class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div id="cell-35" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="b97d9eea-9c0f-4ac5-9db1-c73b3661cfec" data-execution_count="97">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.23 ms ± 380 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-4-pytorch-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="version-4-pytorch-broadcasting">Version 4: PyTorch Broadcasting</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Excalidraw diagram showing broadcasting implementation of matrix multiplication"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/3.png" class="img-fluid figure-img" alt="Excalidraw diagram showing broadcasting implementation of matrix multiplication"></a></p>
<figcaption>Excalidraw diagram showing broadcasting implementation of matrix multiplication</figcaption>
</figure>
</div>
<div id="cell-38" class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b):</span>
<span id="cb37-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape,b.shape</span>
<span id="cb37-3">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb37-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[i,:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb37-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> c</span></code></pre></div>
</div>
<div id="cell-39" class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div id="cell-40" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2acf0524-81f2-4fab-e67d-b2354bacbf36" data-execution_count="109">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>314 μs ± 92.1 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-5-numba-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="version-5-numba-broadcasting">Version 5: Numba Broadcasting</h2>
<div id="cell-42" class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@njit</span></span>
<span id="cb41-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b):</span>
<span id="cb41-3">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape,b.shape</span>
<span id="cb41-4">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((ar, bc))</span>
<span id="cb41-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[i,:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb41-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> c</span></code></pre></div>
</div>
<div id="cell-43" class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div id="cell-44" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="1d46ad9d-a40d-4643-c1cf-f535fa528a2f" data-execution_count="121">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>matmul(m1a, m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>69 μs ± 1.96 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-6-einstein-summation" class="level2">
<h2 class="anchored" data-anchor-id="version-6-einstein-summation">Version 6: Einstein Summation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Excalidraw diagram showing einsum implementation of matrix multiplication"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/4.png" class="img-fluid figure-img" alt="Excalidraw diagram showing einsum implementation of matrix multiplication"></a></p>
<figcaption>Excalidraw diagram showing einsum implementation of matrix multiplication</figcaption>
</figure>
</div>
<div id="cell-47" class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.einsum(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ik,kj-&gt;ij'</span>, a, b)</span></code></pre></div>
</div>
<div id="cell-48" class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div id="cell-49" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="65bbe1b5-0ab3-4162-ef3f-bdeaeb96f800" data-execution_count="124">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>80.8 μs ± 4.18 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-7-pytorch-operator" class="level2">
<h2 class="anchored" data-anchor-id="version-7-pytorch-operator">Version 7: PyTorch <code>@</code> Operator</h2>
<div id="cell-51" class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">test_close(t1,m1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2)</span></code></pre></div>
</div>
<div id="cell-52" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="0bdd14b8-2dbf-42d9-f565-0746be389f63" data-execution_count="126">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span> _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m1<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>16.7 μs ± 1.96 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-8-numba-cuda" class="level2">
<h2 class="anchored" data-anchor-id="version-8-numba-cuda">Version 8: Numba CUDA</h2>
<div id="cell-54" class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@cuda.jit</span></span>
<span id="cb52-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b,c):</span>
<span id="cb52-3">    i, j <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda.grid(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb52-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> j <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]:</span>
<span id="cb52-5">        tmp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb52-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(a.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]): tmp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> a[i, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[k, j]</span>
<span id="cb52-7">        c[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tmp</span></code></pre></div>
</div>
<div id="cell-55" class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> launch_kernel(kernel, grid_x, grid_y, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs):</span>
<span id="cb53-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(grid_x):</span>
<span id="cb53-3">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(grid_y): kernel((i,j), <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span>args, <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">**</span>kwargs)</span></code></pre></div>
</div>
<div id="cell-56" class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1">r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros(t1.shape)</span>
<span id="cb54-2">m1g,m2g,rg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(cuda.to_device, (m1,m2,r))</span></code></pre></div>
</div>
<div id="cell-57" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="2852ccb1-8bed-450f-8864-1928e10117f2" data-execution_count="130">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">m1g.shape, m2g.shape, rg.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="130">
<pre><code>((5, 784), (784, 10), (5, 10))</code></pre>
</div>
</div>
<div id="cell-58" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="d4e0a549-a04f-43db-9d1f-c96e9a6026e7" data-execution_count="131">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">TPB <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span></span>
<span id="cb57-2">rr,rc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> r.shape</span>
<span id="cb57-3">blockspergrid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (math.ceil(rr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> TPB), math.ceil(rc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> TPB))</span>
<span id="cb57-4">blockspergrid</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="131">
<pre><code>(1, 1)</code></pre>
</div>
</div>
<div id="cell-59" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:498}}" data-outputid="bf632387-a756-4efb-ec6a-ce589b1c023a" data-execution_count="132">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)</span>
<span id="cb59-2">r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rg.copy_to_host()</span>
<span id="cb59-3">test_close(t1, r, eps<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/mnt/my4tb/vishal_data/miniconda3/envs/course-numba/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.
  warn(NumbaPerformanceWarning(msg))</code></pre>
</div>
</div>
<div id="cell-60" class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb61-2">matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)</span>
<span id="cb61-3">r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rg.copy_to_host()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>245 μs ± 47.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-9-pytorch-.cuda" class="level2">
<h2 class="anchored" data-anchor-id="version-9-pytorch-.cuda">Version 9: PyTorch <code>.cuda</code></h2>
<div id="cell-62" class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">m1c,m2c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> m1.cuda(),m2.cuda()</span></code></pre></div>
</div>
<div id="cell-63" class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(m1c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2c).cpu()</span>
<span id="cb64-2">test_close(t1, r)</span></code></pre></div>
</div>
<div id="cell-64" class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span> r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(m1c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2c).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>113 μs ± 26.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="comparing-fastest-versions-on-full-dataset" class="level2">
<h2 class="anchored" data-anchor-id="comparing-fastest-versions-on-full-dataset">Comparing Fastest Versions on Full Dataset</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>cuda</code></td>
<td style="text-align: center;">541 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">3.91 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">5.8 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">5.87 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">663 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">1.26 s</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">3.71 s</td>
</tr>
</tbody>
</table>
<section id="numba-dot-product" class="level3">
<h3 class="anchored" data-anchor-id="numba-dot-product">Numba Dot Product</h3>
<div id="cell-68" class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b):</span>
<span id="cb67-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape,b.shape</span>
<span id="cb67-3">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb67-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar):</span>
<span id="cb67-5">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> j <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> dot(a[i,:], b[:,j])</span>
<span id="cb67-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> c</span>
<span id="cb67-7"></span>
<span id="cb67-8">x_train_a,weights_a <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_train.numpy(),weights.numpy()</span>
<span id="cb67-9"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matmul(x_train_a, weights_a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.71 s ± 20.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
</section>
<section id="pytorch-broadcasting" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-broadcasting">PyTorch Broadcasting</h3>
<div id="cell-70" class="cell" data-execution_count="197">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b):</span>
<span id="cb69-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape,b.shape</span>
<span id="cb69-3">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> torch.zeros(ar, bc)</span>
<span id="cb69-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[i,:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(dim<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb69-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> c</span>
<span id="cb69-6"></span>
<span id="cb69-7"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matmul(x_train, weights)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.26 s ± 1.42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<div id="cell-71" class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1">x_train.shape, weights.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="198">
<pre><code>(torch.Size([50000, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
<div id="cell-72" class="cell" data-execution_count="200">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit _ <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> matmul(x_train.cuda(), weights.cuda())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.86 s ± 4.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>Interestingly, putting the tensors on the GPU and then broadcasting is slower than the CPU.</p>
</section>
<section id="numba-cuda" class="level3">
<h3 class="anchored" data-anchor-id="numba-cuda">Numba Cuda</h3>
<div id="cell-75" class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@cuda.jit</span></span>
<span id="cb75-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b,c):</span>
<span id="cb75-3">    i, j <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> cuda.grid(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb75-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> i <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>] <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> j <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]:</span>
<span id="cb75-5">        tmp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.</span></span>
<span id="cb75-6">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> k <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(a.shape[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]): tmp <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+=</span> a[i, k] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b[k, j]</span>
<span id="cb75-7">        c[i,j] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tmp</span></code></pre></div>
</div>
<div id="cell-76" class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1">r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>))</span>
<span id="cb76-2">m1g,m2g,rg <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">map</span>(cuda.to_device, (x_train,weights,r))</span></code></pre></div>
</div>
<div id="cell-77" class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1">TPB <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">16</span></span>
<span id="cb77-2">rr,rc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> r.shape</span>
<span id="cb77-3">blockspergrid <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (math.ceil(rr <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> TPB), math.ceil(rc <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> TPB))</span>
<span id="cb77-4">blockspergrid</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="142">
<pre><code>(3125, 1)</code></pre>
</div>
</div>
<div id="cell-78" class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb79" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span></span>
<span id="cb79-2">matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)</span>
<span id="cb79-3">r <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> rg.copy_to_host()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.91 ms ± 68.6 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="pytorch-cuda" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-cuda">PyTorch <code>cuda</code></h3>
<div id="cell-80" class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">m1c,m2c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> x_train.cuda(),weights.cuda()</span>
<span id="cb81-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span> r<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>(m1c<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>m2c).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>541 μs ± 6.82 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="einstein-summation" class="level3">
<h3 class="anchored" data-anchor-id="einstein-summation">Einstein Summation</h3>
<div id="cell-82" class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b): <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> torch.einsum(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'ik,kj-&gt;ij'</span>, a, b)</span>
<span id="cb83-2"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span> _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>matmul(x_train, weights)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.87 ms ± 229 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="numba-broadcasting" class="level3">
<h3 class="anchored" data-anchor-id="numba-broadcasting">Numba Broadcasting</h3>
<div id="cell-84" class="cell" data-execution_count="191">
<div class="sourceCode cell-code" id="cb85" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@njit</span></span>
<span id="cb85-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> matmul(a,b):</span>
<span id="cb85-3">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> a.shape,b.shape</span>
<span id="cb85-4">    c <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.zeros((ar, bc))</span>
<span id="cb85-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> i <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (a[i,:,<span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> b).<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">sum</span>(axis<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb85-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> c</span></code></pre></div>
</div>
<div id="cell-85" class="cell" data-execution_count="192">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1">_<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>matmul(x_train.numpy(), weights.numpy())</span></code></pre></div>
</div>
<div id="cell-86" class="cell" data-execution_count="193">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>matmul(x_train.numpy(), weights.numpy())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>663 ms ± 378 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
</section>
<section id="pytorch-op" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-op">PyTorch <code>@</code> Op</h3>
<div id="cell-88" class="cell" data-execution_count="194">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%</span>timeit <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>n <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span> _<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>x_train<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">@</span>weights</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.8 ms ± 212 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
</section>
<section id="comparing-5-digit-subset-to-full-dataset-times" class="level2">
<h2 class="anchored" data-anchor-id="comparing-5-digit-subset-to-full-dataset-times">Comparing 5-digit Subset to Full Dataset Times</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Full Dataset Time</th>
<th style="text-align: center;">5-digit Subset Time/Rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>cuda</code></td>
<td style="text-align: center;">541 μs</td>
<td style="text-align: center;">108 μs (4)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">3.91 ms</td>
<td style="text-align: center;">108 μs (4)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">5.8 ms</td>
<td style="text-align: center;">18.1 μs (1)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">5.87 ms</td>
<td style="text-align: center;">83.1 μs (3)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">663 ms</td>
<td style="text-align: center;">69.2 μs (2)</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">1.26 s</td>
<td style="text-align: center;">203 μs (6)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">3.71 s</td>
<td style="text-align: center;">542 μs (7)</td>
</tr>
</tbody>
</table>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>I initially ran into some problems on Colab when implementing <code>@cuda.jit</code> (an error about compute compatibility) so I switched to an RTX 3090 machine and installed the following, which let me successfully run this notebook:</p>
<pre><code>conda install -y -c nvidia/label/cuda-12.8.0 cuda-toolkit
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
conda install -y numba
conda install -y fastcore -c fastai</code></pre>
<p>The glaring takeaway from this exercise is that these methods all scale differently. For the 5-digit subset, PyTorch <code>cuda</code> was about 9 times slower than PyTorch CPU (when using the <code>@</code> operator). Numba cuda and PyTorch <code>cuda</code> were tied for the small subset, but PyTorch <code>cuda</code> was 8 times faster for the larger dataset. I don’t yet understand <em>why</em> these differences exist, so that’s something I’ll keep an eye out for as I learn more about how GPUs work!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>fastai</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/</guid>
  <pubDate>Wed, 21 May 2025 07:00:00 GMT</pubDate>
</item>
</channel>
</rss>
