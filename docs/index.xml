<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Vishal Bakshi&#39;s Blog</title>
<link>https://vishalbakshi.github.io/blog/index.html</link>
<atom:link href="https://vishalbakshi.github.io/blog/index.xml" rel="self" type="application/rss+xml"/>
<description>Machine Learning blog by Vishal Bakshi</description>
<generator>quarto-1.2.335</generator>
<lastBuildDate>Mon, 09 Jun 2025 07:00:00 GMT</lastBuildDate>
<item>
  <title>Proof, Pricing, and Passion: Finding My Path in Machine Learning</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-09-fireside-chat/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Z328Nl6c-8k?si=Ey9ehhiHqoCQfmum" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<p>A recent fireside chat with three successful AI consultants—Jason Liu, Andy Walters, and Vignesh Mohankumar—gave me a much clearer, more realistic perspective on what it takes to build a career in this space. While a previous <a href="https://www.youtube.com/watch?v=nyNQtkiW-ME">paradigm-shifting conversation between Jason Liu and Hamel Husain</a> had inspired me, this conversation answered a critical question I’ve been wrestling with:</p>
<blockquote class="blockquote">
<p>What do you think is the minimum amount of professional experience to have before going full-time consulting?</p>
</blockquote>
<p>I was all ears on this one. Below are the responses from Jason, Vignesh and Andy (emphasis mine)</p>
<blockquote class="blockquote">
<p>Jason: <mark><strong>the thing you want to have is proof.</strong></mark> There are people making a million dollars a year doing Zapier integrations and automations. You can probably just figure that out, just charge very little, do a couple of free jobs, get some proof, maybe if you help a business owner with their automations you can ask if they have anyone they can refer you to, then you get the next job and the next job. I think it depends on what kind of things you’re promising and what kind of solutions you’re promising.</p>
</blockquote>
<blockquote class="blockquote">
<p>Vignesh: I think the fact that I was basically a staff level engineer is really what’s helping me now, but it’s not to say that you don’t need that, I think like you said there’s a lot of things you can do, but <mark><strong>I think for the type of work I’m doing it would be very hard to do if you were less than 5 years of experience, or really, honestly, probably 8</strong></mark>….but it’s about what have you actually done and can you actually prove it.</p>
</blockquote>
<blockquote class="blockquote">
<p>Andy: I started with zero AI knowledge. I was previously a programmer. I never worked at a startup that was successful. I worked at little agencies my whole career. I am where I am today so it’s possible. <mark><strong>It all depends on your skill set. It’s about staffing your weaknesses.</strong></mark> If you want to go big and you’re not good at something if you can partner with somebody who’s good at that thing, now you can move on and go further. It depends on how fast you want to scale, how honest you can be with yourself about your weaknesses and how good you are at acquiring the talent to fill in those weaknesses.</p>
</blockquote>
<p>Jason and Vignesh agreed upon the fact that you can land jobs if you can prove that you can deliver results (at the appropriate scale). For someone like me, who has never worked professionally in ML, getting that proof (at scale, in a setting that emulates a real business) is the tricky part. I would imagine that any proof I can currently collect (research projects, Kaggle competitions, educational content, etc.) will help me get a foot in the door at a company or a lab, which will then unlock my ability to get more proof in a professional setting that could translate to consulting. I could be wrong (tweet at me if I am) but going from 0-to-consulting without any other professional ML experience doesn’t seem likely (or, at least I haven’t seen any examples of this, except for unicorns like Jeremy Howard).</p>
<p>But knowing when to start is only half the battle; understanding the pivotal moments that accelerate a consulting career is just as important, which the speakers addressed next.</p>
</section>
<section id="inflection-points-in-consulting" class="level2">
<h2 class="anchored" data-anchor-id="inflection-points-in-consulting">Inflection points in consulting</h2>
<p>Q: What felt like the inflection point for the way that you were able to bring in revenue or demand higher fees?</p>
<blockquote class="blockquote">
<p>Jason: For me a lot of it was coming down to my writing. At some point it became: “Hey Jason, I’ve seen a couple of your blog posts show up on my Slack, I don’t really know who you are, I finally clicked the website and I realized you were available so can we figure out if it makes sense to work together?” And then I would share another blog post after the call and they would be like “turns out my CTO already read this, what is your availability?”</p>
</blockquote>
<blockquote class="blockquote">
<p>Vignesh: There was one month where I got a project and I finished it in a week or two and it was more money than I had made if I just worked full-time, hourly, for a month and a half. It was a really pressing problem that came up. I realized I’d rather sit there for 29 days a month and find a project-based thing that I could do for one day a month, then work hourly. That’s what shifted it for me.</p>
</blockquote>
<blockquote class="blockquote">
<p>Jason: Going from time-based to project-based pricing, and then getting comfortable understanding the value that your project delivers and increase your fee to reflect the size of the problem.</p>
</blockquote>
<p>In the Hamel/Jason discussion on AI consulting, they talk about how publishing free content is a viable marketing plan. This really resonated with me as a fast.ai community member, encouraged by <a href="https://medium.com/@racheltho/why-you-yes-you-should-blog-7d2544ac1045">Rachel Thomas to blog</a> since “it’s like a resume, only better.” After I watched Jason and Hamel’s discussion, I immediately set a goal to publish 50 ML vidoes and 50 ML blog posts in 2025, and it has been driving me forward ever since. Reading that Jason’s leads often come from people reading his blog further solidified by belief that this is the way. Obviously, what you’re writing about matters, but I think that catches up with quantity over time.</p>
<p>Both of these inflection points are about detaching income from hours and tying it to the value you create. But what’s the upper limit? This led to an interesting exchange about whether AI is removing the ceiling on how much impact a single consultant can have.</p>
</section>
<section id="is-there-a-ceiling-for-one-consultant" class="level2">
<h2 class="anchored" data-anchor-id="is-there-a-ceiling-for-one-consultant">Is there a ceiling for one consultant?</h2>
<p>I’ve heard Jason say some iteration of the following in a couple of videos now:</p>
<blockquote class="blockquote">
<p>Jason: I would be surprised if there’s anybody I know that can be like an individual person even doing $10MM a year just feels very difficult whereas if you just have a couple of small operational staff you can probably get pretty far.</p>
</blockquote>
<p>This was the first video (that I’ve watched) where someone pushed back on that.</p>
<blockquote class="blockquote">
<p>Vignesh: If these tools are going to keep getting better, then I don’t know if there is a limit anymore at some point.</p>
</blockquote>
<p>I think this both an inspiring and realistic take. My own self-prescribed limits have continuously been broken with the help of AI. It’s hard for me to quantify how much my growth in ML has accelerated due to AI (as I obviously don’t have a control to compare for that) but anecdotally, every month and every year that I’ve increased my use of AI to augment my learning and implementation skills, I’ve accomplished tasks that I didn’t expect to. You could argue that every project, blog post, and video I’ve published could not have been possible without the support of AI. How this translates to getting paid (and how much I get paid), only time will tell. Going back to the previous topic on when to start consulting, I think the use of AI can help build that proof needed for a 0-to-consulting trajectory. It may require doing a couple free or low-paying jobs, but I think that’s reasonable to expect. This is probably a controversial take, and I’m not condoning or advocating for exploitation, but I do think that when you work for free as a beginner, you are “paying” (with your labor) to get that proof needed to unlock paid work. Working for free can also look like joining a study group/discord server and taking on tasks that need to be done.</p>
<p>While the potential to scale with AI is an exciting thought experiment, financial upside is rarely the sole motivator for taking the risk of going independent. The conversation also explored the fundamental ‘why’ behind this career path, and Vignesh’s reasons resonated deeply with my own.</p>
</section>
<section id="what-attracts-me-to-consulting" class="level2">
<h2 class="anchored" data-anchor-id="what-attracts-me-to-consulting">What attracts me to consulting</h2>
<blockquote class="blockquote">
<p>Q: Why didn’t you join a startup (or starting a company) versus doing your own thing?</p>
</blockquote>
<blockquote class="blockquote">
<p>Vignesh: I just loving working on new problems all of the time, ideally multiple problems at the same time. I think consulting is really interesting because you can price based on the actual value you’re delivering. That keeps me going in some ways—what’s the most valuable things I can be working on? How can I help people the most? The last piece is that I just love owning the brand. Anything I’m writing, anyone I’m meeting is all tied to me…I scale it by finding more valuable projects and more important problems.</p>
</blockquote>
<p>All of these points resonate with me. As a hobby ML researcher, I value the following freedoms:</p>
<ul>
<li>The freedom to start, pause, or stop a project at will.</li>
<li>The freedom of learning and building in public without the constraints of private, proprietary work.</li>
<li>The freedom to choose my focus.</li>
<li>The freedom to control my pace—going slow. Going fast. Going deep. Staying shallow. I choose at all times which of these modes I’m in.</li>
<li>The freedom from an obsession with results, allowing me to instead chase ideas, concepts, and their clear explanation.</li>
</ul>
<p>The cost of these freedoms, currently, is that I do this work for free. Finding a situation where I can continue to have these freedoms is my next challenge.</p>
<p>Vignesh’s drive for autonomy and interesting problems perfectly mirrors the freedoms I value as a hobby researcher. But what I found most encouraging was the discussion that followed, which highlighted that his path isn’t the only one; different personalities and preferences can also lead to fulfilling consulting careers.</p>
</section>
<section id="on-different-paths-to-consulting" class="level2">
<h2 class="anchored" data-anchor-id="on-different-paths-to-consulting">On different paths to consulting</h2>
<p>Vignesh and Andy had diametrically opposed preferences and paths to consulting (emphasis mine):</p>
<blockquote class="blockquote">
<p>Vignesh: I like coding a lot. I love writing code. I love learning things. So it works. It’s like my dream.</p>
</blockquote>
<blockquote class="blockquote">
<p>Andy: I think I’m different than Vignesh in that like I was an okay engineer, but I was never a great engineer, and I really enjoyed the relationship aspect of it, leading people, that kind of stuff, that’s actually more fun to me. I like meetings…I enjoy it. <mark><strong>It’s all about figuring out what you really enjoy and pushing on that a lot.</strong></mark></p>
</blockquote>
<p>I think it was awesome and important for viewers to see these diverse preferences both leading to fulfilling consulting careers. Ultimately, while landing paid work is goal 1B, doing what I enjoy and excites me is 1A and this confirmed that motivation.</p>
<p>The idea that you should build a career around what you genuinely enjoy is a powerful one. And what makes this path so compelling right now is the shared belief among all the speakers that the opportunity is vast enough to accommodate all of these different approaches.</p>
</section>
<section id="the-work-is-literally-falling-off-trucks" class="level2">
<h2 class="anchored" data-anchor-id="the-work-is-literally-falling-off-trucks">The work is literally falling off trucks</h2>
<p>I’ll end with Andy’s closing thoughts:</p>
<blockquote class="blockquote">
<p>Andy: I think the biggest lesson I’ve learned through all of this is it’s all about breaking your context into the next level. There is this cascading series of contexts you have to break yourself into and it’s always uncomfortable and it feels painful and risky…keep pushing, keep growing, and even when it doesn’t work the first time you just keep pulling the thread. It’s surprising how far you can get. We firmly believe that over the next 5 years there’s at least a trillion dollars of integration services on the table for companies to integrate AI into their offerings. The work is literally falling off the trucks. It’s out there to seize, go seize it.</p>
</blockquote>
<p>When you are constantly pushing yourself to grow and take on the next challenging context, you will find yourself working at the edge of your knowledge and capacity. This is an ideal place to be. However, the downside is never truly knowing or feeling how much you have progressed. It’s a constant state of “I am stuck on X which I need to resolve so I can get to Y”. I think documenting your journey (through writing blog posts/tweets and creating videos) helps balance this bleeding-edge approach by concretely and quantitatively showing you what you have learned and how much you have achieved.</p>
<p>Andy’s point that “the work is literally falling off the trucks” should be inspiring to everyone, regardless of whether or not you want to pursue consulting. I think we are still in the very early stages of AI adoption, which means that there is a lot of implementation work that needs to get done. It can seem (falsely) that the field of AI is accelerating at an unsustainable pace, but what is unsustainble in my opinion is that veneer. The fundamentals still matter. Communicating concepts clearly still matters. These are relatively low-hanging fruit.</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing thoughts</h2>
<p>I thoroughly enjoying this fireside chat. I came away from it with more questions and some answers.</p>
<p>To be honest, I don’t know where my ML journey is going to take me. When I’m feeling optimistic, I imagine myself working in an organization or independently with the same joy that I find myself working on my personal projects today. On my worst days, I wonder if I’ll ever leave the purgatory of hobby ML. I think the key to my success is to be consistent regardless of what I’m feeling.</p>
<p>Hearing Andy talk about staffing weaknesses and Vignesh about AI raising the ceiling made me reflect on my own approach. When it comes to using AI, and what capabilities it will unlock for me, I keep waiting for a “choir of angels” (<a href="https://xkcd.com/310/">xkcd</a>) but instead have found a steady plodding forward, task to task. I think Vignesh is right about AI removing the ceiling, and Andy is right about supplementing your weaknesses with others’ strengths. Combining these two ideas, I think my task is to become more aware about 1) what my current ceiling is/what my current weaknesses are and 2) understanding how to augment them with AI. The sycophantic nature of AI makes it difficult to use it for identifying my weaknesses, but I’ve found success by asking Claude to be a “hardass” (and then asking it to critique the hardass), or using Gemini 2.5-Pro for such questions, which I find is more straightforward and informative and less of a coach/cheerleader.</p>
<p>I’ll end by saying that I don’t usually write posts like these, and keep these thoughts to myself, but I’m finding that to strengthen my relationship with my audience I will have to share more of myself in my writing. This is the first of what I hope will be many posts connecting what I’m learning from experts in the field to my own journey.</p>
<p>You can reach me on <a href="https://x.com/vishal_learner">Twitter</a> and find more content on my <a href="https://www.youtube.com/@vishal_learner">YouTube channel</a>.</p>


</section>

 ]]></description>
  <category>Career</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-09-fireside-chat/index.html</guid>
  <pubDate>Mon, 09 Jun 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>HuggingFace’s Default KV Cache and the flash_attn_varlen_func Docstring</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-03-flash_attn_varlen_func-casual-mask/index.html</link>
  <description><![CDATA[ 



<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;">!</span>pip install <span class="op" style="color: #5E5E5E;">-</span>qq <span class="op" style="color: #5E5E5E;">-</span>U flash<span class="op" style="color: #5E5E5E;">-</span>attn <span class="op" style="color: #5E5E5E;">--</span>no<span class="op" style="color: #5E5E5E;">-</span>build<span class="op" style="color: #5E5E5E;">-</span>isolation</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoTokenizer, AutoModelForCausalLM, GenerationConfig</span>
<span id="cb2-2"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb2-3"><span class="im" style="color: #00769E;">import</span> torch.nn <span class="im" style="color: #00769E;">as</span> nn</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span>)</span>
<span id="cb3-2">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span>, attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>torch.bfloat16).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I have recently been working on a research project which has required me to <a href="https://vishalbakshi.github.io/blog/posts/2025-05-04-Understanding-Sequence-Packing/">better understand sequence packing and Flash Attention</a>, and <a href="https://youtu.be/u_v6HHyv4No">eager attention as well</a>. However, I’ve found that both in terms of my interest, and for practical understanding, that hasn’t been enough!</p>
<p>Tangentially, I also recently started using Gemini Pro 2.5 (the chat UI) and have been thoroughly enjoying it after using a year of daily use of Claude Pro. This seemed like a great opportunity to test out Gemini’s functionality to learn about a topic that is complex and currently outside of my comfort zone.</p>
<p>I fed Gemini the Flash Attention GitHub repo and explained that I wanted to thoroughly understand <code>flash_attn_varlen_func</code> to the point where I could make a detailed video walkthrough with visuals. It provided me with this condensed timeline:</p>
<ul>
<li><strong>Phase 1: Python Layer &amp; Sequence Packing Concepts</strong>
<ul>
<li>Tasks: Understand <code>flash_attn_varlen_func</code>’s Python call stack, the role of <code>cu_seqlens</code>, <code>max_seqlen</code>, and <code>torch.autograd.Function</code>.</li>
<li>Time: 1-2 Weeks</li>
<li>Hours: Approximately 15-30 hours</li>
</ul></li>
<li><strong>Phase 2: Core CUDA Kernel Deep Dive</strong>
<ul>
<li>Tasks: Study the FlashAttention research paper(s).</li>
<li>Analyze the C++/CUDA dispatcher code (e.g., in <code>csrc/flash_attn/flash_api.cpp</code>).</li>
<li>Dissect the core CUDA kernels for variable length forward and backward passes (e.g., in <code>csrc/flash_attn/src/</code> like <code>flash_fwd_kernel.h</code> and <code>flash_bwd_kernel.h</code>).</li>
<li>Time: 6-12 Weeks</li>
<li>Hours: Approximately 125-240 hours</li>
</ul></li>
<li><strong>Phase 3: Content Creation (Video/Blog)</strong>
<ul>
<li>Tasks: Plan the structure for your content, create visuals, draft explanations, and prepare code snippets.</li>
<li>Time: 2-3 Weeks</li>
<li>Hours: Approximately 30-50 hours</li>
</ul></li>
<li><strong>Total Estimated for CUDA Path</strong>
<ul>
<li>Overall Timeline: Roughly 2.5 - 4.5 months</li>
<li>Total Focused Hours: Approximately 170 - 320 hours</li>
</ul></li>
</ul>
<p>This is obviously an amibitious goal and timeline, especially because of my limited C++/CUDA knowledge and experience. However, I do believe this is a case of aim-for-the-stars-land-on-the-moon, as I’ve already experienced growth and learning in the first steps of Phase 1.</p>
<p>As I was reading through <a href="https://github.com/Dao-AILab/flash-attention/blob/df1847a74ad0f9cee007ed186fab44f83fa03fad/flash_attn/flash_attn_interface.py#L1370"><code>flash_attn_varlen_func</code></a> source code, I got stuck on the following piece of the docstring:</p>
<pre><code>If causal=True, the causal mask is aligned to the bottom right corner of the attention matrix.
For example, if seqlen_q = 2 and seqlen_k = 5, the causal mask (1 = keep, 0 = masked out) is:
    1 1 1 1 0
    1 1 1 1 1
If seqlen_q = 5 and seqlen_k = 2, the causal mask is:
    0 0
    0 0
    0 0
    1 0
    1 1
If the row of the mask is all zero, the output will be zero.</code></pre>
<p>I didn’t have hands-on experience working with this concept, where the query length is different than the key and value length. Gemini helped me realize that this happens in the extremely common case of autoregressive generation—the next token (query length of 1) attends to the previous tokens (key/value length &gt; 1). The concept of KV cache also came up in our conversation.</p>
<p>I don’t tend to understand things until I see them in code, so in this notebook, I’ll inspect the shapes of Q, K and V during the HuggingFace <code>model.generate</code> call. I’ll also peel back a couple layers and understand how HugginFace uses KV cache. After that exploration, I’ll return back to the <code>flash_attn_varlen_func</code> docstring and walk through the logic behind how the causal mask is shaped.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/pZpK5uGr7Lo?si=znCX-qawKdcoX0V9" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="understanding-huggingfaces-default-kv-cache" class="level2">
<h2 class="anchored" data-anchor-id="understanding-huggingfaces-default-kv-cache">Understanding HuggingFace’s Default KV Cache</h2>
<p>I’ll start by understanding how HuggingFace uses KV cache (I was surprised to find that it uses it by default!).</p>
<section id="inspecting-model_kwargs-for-caching-method" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-model_kwargs-for-caching-method">Inspecting <code>model_kwargs</code> for Caching Method</h3>
<p>Looking at the <a href="https://github.com/huggingface/transformers/blob/1094dd34f73dae1d9a91a6632635934516612490/src/transformers/generation/utils.py#L2481"><code>generate</code></a> source code, the first method call of interest when it comes to KV cache seems to be <a href="https://github.com/huggingface/transformers/blob/1094dd34f73dae1d9a91a6632635934516612490/src/transformers/generation/utils.py#L1981"><code>_prepare_cache_for_generation</code></a>, which takes the following arguments: <code>generation_config</code>, <code>model_kwargs</code>, <code>assistant_model</code>, <code>batch_size</code>, <code>max_cache_length</code>, <code>device</code>. Going down the different elif statements, <code>_prepare_cache_for_generation</code> sets the following <code>model_kwargs</code> value:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">model_kwargs[cache_name] <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb5-2">    DynamicCache()</span>
<span id="cb5-3">    <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> requires_cross_attention_cache</span>
<span id="cb5-4">    <span class="cf" style="color: #003B4F;">else</span> EncoderDecoderCache(DynamicCache(), DynamicCache())</span>
<span id="cb5-5">)</span></code></pre></div>
<p>Where <code>cache_name</code> is defined earlier in that method as:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">cache_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"past_key_values"</span> <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> is_hybrid_cache <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"cache_params"</span></span></code></pre></div>
<p>I want to inspect what <code>model_kwargs['past_key_values']</code> is.</p>
<p><a href="https://github.com/huggingface/transformers/blob/1094dd34f73dae1d9a91a6632635934516612490/src/transformers/generation/utils.py#L2369"><code>_prepare_generation_config</code></a> is used in <code>generate</code> to produce <code>generation_config</code> and <code>model_kwargs</code>.</p>
<div class="cell" data-outputid="d4927381-46b1-42f6-aec8-9e94d36c16a8" data-execution_count="50">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">generation_config, model_kwargs <span class="op" style="color: #5E5E5E;">=</span> model._prepare_generation_config(<span class="va" style="color: #111111;">None</span>)</span>
<span id="cb7-2">generation_config, model_kwargs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>(GenerationConfig {
   "bos_token_id": 0,
   "eos_token_id": 0
 },
 {})</code></pre>
</div>
</div>
<p>I can now pass those on to <code>_prepare_cache_for_generation</code>, which will internally modify <code>model_kwargs</code>.</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">model._prepare_cache_for_generation(generation_config, model_kwargs, <span class="va" style="color: #111111;">None</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">8192</span>, <span class="st" style="color: #20794D;">"cuda"</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="533d54c0-fad1-4f4a-9b31-4fe867e16454" data-execution_count="53">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">model_kwargs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>{'past_key_values': &lt;transformers.cache_utils.DynamicCache at 0x78c3b80d9850&gt;}</code></pre>
</div>
</div>
<p>I can see now that <code>model_kwargs</code> has a <code>'past_key_values'</code> key which has a <code>DynamicCache</code> value.</p>
</section>
<section id="how-is-past_key_values-used" class="level3">
<h3 class="anchored" data-anchor-id="how-is-past_key_values-used">How is <code>past_key_values</code> Used?</h3>
<p>I think it makes sense to start by looking at <a href="https://github.com/huggingface/transformers/blob/e8b292e35f331d3c3de85f7e5d3496b0e13d3d6f/src/transformers/models/llama/modeling_llama.py#L223">the forward pass of the LlamaAttention module</a>:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">...</span>
<span id="cb12-2"></span>
<span id="cb12-3">key_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.k_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb12-4">value_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.v_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb12-5"></span>
<span id="cb12-6">...</span>
<span id="cb12-7"></span>
<span id="cb12-8"><span class="cf" style="color: #003B4F;">if</span> past_key_value <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb12-9">    key_states, value_states <span class="op" style="color: #5E5E5E;">=</span> past_key_value.update(key_states, value_states, <span class="va" style="color: #111111;">self</span>.layer_idx, cache_kwargs)</span></code></pre></div>
<p>The <code>hidden_states</code> pass through <code>k_proj</code> and <code>v_proj</code> to produce <code>key_states</code> and <code>value_states</code>, respectively, which are then passed to <code>past_key_value.update</code> to produce a new set of <code>key_states</code> and <code>value_states</code>. Looking at <a href=""><code>DynamicCache.update</code></a>:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;"># Update the cache</span></span>
<span id="cb13-2"><span class="cf" style="color: #003B4F;">if</span> key_states <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(<span class="va" style="color: #111111;">self</span>.key_cache) <span class="op" style="color: #5E5E5E;">&lt;=</span> layer_idx:</span>
<span id="cb13-4">        <span class="co" style="color: #5E5E5E;"># There may be skipped layers, fill them with empty lists</span></span>
<span id="cb13-5">        <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(<span class="va" style="color: #111111;">self</span>.key_cache), layer_idx):</span>
<span id="cb13-6">            <span class="va" style="color: #111111;">self</span>.key_cache.append(torch.tensor([]))</span>
<span id="cb13-7">            <span class="va" style="color: #111111;">self</span>.value_cache.append(torch.tensor([]))</span>
<span id="cb13-8">        <span class="va" style="color: #111111;">self</span>.key_cache.append(key_states)</span>
<span id="cb13-9">        <span class="va" style="color: #111111;">self</span>.value_cache.append(value_states)</span>
<span id="cb13-10">    <span class="cf" style="color: #003B4F;">elif</span> (</span>
<span id="cb13-11">        <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">self</span>.key_cache[layer_idx].numel()  <span class="co" style="color: #5E5E5E;"># prefers not t.numel() to len(t) == 0 to export the model</span></span>
<span id="cb13-12">    ):  <span class="co" style="color: #5E5E5E;"># fills previously skipped layers; checking for tensor causes errors</span></span>
<span id="cb13-13">        <span class="va" style="color: #111111;">self</span>.key_cache[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> key_states</span>
<span id="cb13-14">        <span class="va" style="color: #111111;">self</span>.value_cache[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> value_states</span>
<span id="cb13-15">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb13-16">        <span class="va" style="color: #111111;">self</span>.key_cache[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> torch.cat([<span class="va" style="color: #111111;">self</span>.key_cache[layer_idx], key_states], dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb13-17">        <span class="va" style="color: #111111;">self</span>.value_cache[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> torch.cat([<span class="va" style="color: #111111;">self</span>.value_cache[layer_idx], value_states], dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb13-18"></span>
<span id="cb13-19"><span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.key_cache[layer_idx], <span class="va" style="color: #111111;">self</span>.value_cache[layer_idx]</span></code></pre></div>
<p>Let’s walk through each condition in the if-else block.</p>
<section id="if-lenself.key_cache-layer_idx" class="level4">
<h4 class="anchored" data-anchor-id="if-lenself.key_cache-layer_idx"><code>if len(self.key_cache) &lt;= layer_idx</code></h4>
<p>A full <code>key_cache</code> is has <code>n_layers</code> number of elements. If its number of elements is less than or equal to the <code>layer_idx</code> that means that it does not contain <code>key_states</code> for that <code>layer_idx</code> yet (because python starts count from <code>0</code>). For example suppose <code>layer_idx</code> is <code>0</code>, our first layer. <code>if len(self.key_cache) &lt;= layer_idx</code> is <code>True</code>, that means <code>len(self.key_cache)</code> is <code>0</code> and doesn’t contain <code>key_states</code> for the first layer, as would be the case if you were generating the first token of a response. In this case you simply <code>append</code> the <code>key_states</code> to the cache.</p>
<p>If <code>layer_idx</code> is greater than <code>len(self.key_cache)</code> then it appends an empty tensor for the “skipped” layers. This would be a scenario where you were generating the first token of a response (<code>len(self.key_cache)</code> is <code>0</code>) but starting with <code>layer_idx</code> of <code>2</code>.</p>
</section>
<section id="elif-not-self.key_cachelayer_idx.numel" class="level4">
<h4 class="anchored" data-anchor-id="elif-not-self.key_cachelayer_idx.numel"><code>elif not self.key_cache[layer_idx].numel()</code></h4>
<p>If a layer was skipped and it has an empty tensor as its <code>key_cache</code> then this condition is triggered and it simply assigned <code>key_states</code> to that layer’s <code>key_cache</code>.</p>
</section>
<section id="else" class="level4">
<h4 class="anchored" data-anchor-id="else"><code>else</code></h4>
<p>I think this is the most common case, used for autoregressive next-token generation. The <code>key_cache</code> contains a non-empty value for this layer so it concatenates the current value with the new <code>key_states</code>. In this way, the <code>key_cache</code> for this layer grows over the course of next token generation. Specifically, it’s second to last dimension (sequence length) increases by 1 for each token processed.</p>
</section>
<section id="return-self.key_cachelayer_idx-self.value_cachelayer_idx" class="level4">
<h4 class="anchored" data-anchor-id="return-self.key_cachelayer_idx-self.value_cachelayer_idx"><code>return self.key_cache[layer_idx], self.value_cache[layer_idx]</code></h4>
<p>Finally, the concatenated <code>key_cache</code> and <code>value_cache</code> for the given layer are returned. The <code>update</code> step is complete.</p>
<p><code>key_states</code> and <code>value_states</code> after the <code>past_key_values.update</code> step are passed onto the <code>attention_interface</code> which we’ll look at later in this blog post.</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">attn_output, attn_weights <span class="op" style="color: #5E5E5E;">=</span> attention_interface(</span>
<span id="cb14-2">            <span class="va" style="color: #111111;">self</span>,</span>
<span id="cb14-3">            query_states,</span>
<span id="cb14-4">            key_states,</span>
<span id="cb14-5">            value_states,</span>
<span id="cb14-6">            attention_mask,</span>
<span id="cb14-7">            dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.0</span> <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">self</span>.training <span class="cf" style="color: #003B4F;">else</span> <span class="va" style="color: #111111;">self</span>.attention_dropout,</span>
<span id="cb14-8">            scaling<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>.scaling,</span>
<span id="cb14-9">            <span class="op" style="color: #5E5E5E;">**</span>kwargs,</span>
<span id="cb14-10">        )</span></code></pre></div>
</section>
</section>
<section id="visualizing-the-dynamiccache.update" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-dynamiccache.update">Visualizing the <code>DynamicCache.update</code></h3>
<p>To see how the cache update takes place during autoregressive language generation, I’ll monkey-patch a <code>debug_update</code> method.</p>
<div class="cell" data-execution_count="58">
<details>
<summary>Show `debug_update</summary>
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> Any, Dict, Iterable, List, Optional, Tuple, Union</span>
<span id="cb15-2"></span>
<span id="cb15-3"><span class="kw" style="color: #003B4F;">def</span> debug_update(</span>
<span id="cb15-4">    <span class="va" style="color: #111111;">self</span>,</span>
<span id="cb15-5">    key_states: torch.Tensor,</span>
<span id="cb15-6">    value_states: torch.Tensor,</span>
<span id="cb15-7">    layer_idx: <span class="bu" style="color: null;">int</span>,</span>
<span id="cb15-8">    cache_kwargs: Optional[Dict[<span class="bu" style="color: null;">str</span>, Any]] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb15-9">) <span class="op" style="color: #5E5E5E;">-&gt;</span> Tuple[torch.Tensor, torch.Tensor]:</span>
<span id="cb15-10">    <span class="co" style="color: #5E5E5E;">"""</span></span>
<span id="cb15-11"><span class="co" style="color: #5E5E5E;">    Updates the cache with the new `key_states` and `value_states` for the layer `layer_idx`.</span></span>
<span id="cb15-12"></span>
<span id="cb15-13"><span class="co" style="color: #5E5E5E;">    Parameters:</span></span>
<span id="cb15-14"><span class="co" style="color: #5E5E5E;">        key_states (`torch.Tensor`):</span></span>
<span id="cb15-15"><span class="co" style="color: #5E5E5E;">            The new key states to cache.</span></span>
<span id="cb15-16"><span class="co" style="color: #5E5E5E;">        value_states (`torch.Tensor`):</span></span>
<span id="cb15-17"><span class="co" style="color: #5E5E5E;">            The new value states to cache.</span></span>
<span id="cb15-18"><span class="co" style="color: #5E5E5E;">        layer_idx (`int`):</span></span>
<span id="cb15-19"><span class="co" style="color: #5E5E5E;">            The index of the layer to cache the states for.</span></span>
<span id="cb15-20"><span class="co" style="color: #5E5E5E;">        cache_kwargs (`Dict[str, Any]`, `optional`):</span></span>
<span id="cb15-21"><span class="co" style="color: #5E5E5E;">            Additional arguments for the cache subclass. No additional arguments are used in `DynamicCache`.</span></span>
<span id="cb15-22"></span>
<span id="cb15-23"><span class="co" style="color: #5E5E5E;">    Return:</span></span>
<span id="cb15-24"><span class="co" style="color: #5E5E5E;">        A tuple containing the updated key and value states.</span></span>
<span id="cb15-25"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb15-26">    <span class="co" style="color: #5E5E5E;"># Update the number of seen tokens</span></span>
<span id="cb15-27">    <span class="cf" style="color: #003B4F;">if</span> layer_idx <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb15-28">        <span class="va" style="color: #111111;">self</span>._seen_tokens <span class="op" style="color: #5E5E5E;">+=</span> key_states.shape[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>]</span>
<span id="cb15-29"></span>
<span id="cb15-30">    <span class="co" style="color: #5E5E5E;"># Update the cache</span></span>
<span id="cb15-31">    <span class="cf" style="color: #003B4F;">if</span> key_states <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb15-32">        <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(<span class="va" style="color: #111111;">self</span>.key_cache) <span class="op" style="color: #5E5E5E;">&lt;=</span> layer_idx:</span>
<span id="cb15-33">            <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"DEBUG: initializing cache for layer_idx </span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb15-34">            <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(<span class="va" style="color: #111111;">self</span>.key_cache), layer_idx):</span>
<span id="cb15-35">                <span class="va" style="color: #111111;">self</span>.key_cache.append(torch.tensor([]))</span>
<span id="cb15-36">                <span class="va" style="color: #111111;">self</span>.value_cache.append(torch.tensor([]))</span>
<span id="cb15-37">            <span class="va" style="color: #111111;">self</span>.key_cache.append(key_states)</span>
<span id="cb15-38">            <span class="va" style="color: #111111;">self</span>.value_cache.append(value_states)</span>
<span id="cb15-39">        <span class="cf" style="color: #003B4F;">elif</span> (</span>
<span id="cb15-40">            <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">self</span>.key_cache[layer_idx].numel()  <span class="co" style="color: #5E5E5E;"># prefers not t.numel() to len(t) == 0 to export the model</span></span>
<span id="cb15-41">        ):  <span class="co" style="color: #5E5E5E;"># fills previously skipped layers; checking for tensor causes errors</span></span>
<span id="cb15-42">            <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"DEBUG: filling empty cache for layer_idx </span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb15-43">            <span class="va" style="color: #111111;">self</span>.key_cache[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> key_states</span>
<span id="cb15-44">            <span class="va" style="color: #111111;">self</span>.value_cache[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> value_states</span>
<span id="cb15-45">        <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb15-46">            <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"DEBUG: updating/concatenating cache for layer_idx </span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb15-47">            <span class="va" style="color: #111111;">self</span>.key_cache[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> torch.cat([<span class="va" style="color: #111111;">self</span>.key_cache[layer_idx], key_states], dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb15-48">            <span class="va" style="color: #111111;">self</span>.value_cache[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> torch.cat([<span class="va" style="color: #111111;">self</span>.value_cache[layer_idx], value_states], dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb15-49"></span>
<span id="cb15-50">    <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.key_cache[layer_idx], <span class="va" style="color: #111111;">self</span>.value_cache[layer_idx]</span></code></pre></div>
</details>
</div>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="im" style="color: #00769E;">from</span> transformers.cache_utils <span class="im" style="color: #00769E;">import</span> DynamicCache</span>
<span id="cb16-2"><span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'ORIGINAL_DYNAMIC_CACHE_UPDATE'</span> <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">globals</span>():</span>
<span id="cb16-3">    ORIGINAL_DYNAMIC_CACHE_UPDATE <span class="op" style="color: #5E5E5E;">=</span> DynamicCache.update</span>
<span id="cb16-4">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Stored original DynamicCache.update."</span>)</span>
<span id="cb16-5"></span>
<span id="cb16-6">DynamicCache.update <span class="op" style="color: #5E5E5E;">=</span> debug_update</span></code></pre></div>
</div>
<div class="cell" data-outputid="3bbb53b2-9b89-4361-cb26-e980bb510959" data-execution_count="60">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"The quick brown"</span></span>
<span id="cb17-2">input_ids, attention_mask <span class="op" style="color: #5E5E5E;">=</span> tokenizer(prompt, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>).values()</span>
<span id="cb17-3">outputs <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DEBUG: initializing cache for layer_idx 0
DEBUG: initializing cache for layer_idx 1
DEBUG: initializing cache for layer_idx 2
DEBUG: initializing cache for layer_idx 3
DEBUG: initializing cache for layer_idx 4
DEBUG: initializing cache for layer_idx 5
DEBUG: initializing cache for layer_idx 6
DEBUG: initializing cache for layer_idx 7
DEBUG: initializing cache for layer_idx 8
DEBUG: initializing cache for layer_idx 9
DEBUG: initializing cache for layer_idx 10
DEBUG: initializing cache for layer_idx 11
DEBUG: initializing cache for layer_idx 12
DEBUG: initializing cache for layer_idx 13
DEBUG: initializing cache for layer_idx 14
DEBUG: initializing cache for layer_idx 15
DEBUG: initializing cache for layer_idx 16
DEBUG: initializing cache for layer_idx 17
DEBUG: initializing cache for layer_idx 18
DEBUG: initializing cache for layer_idx 19
DEBUG: initializing cache for layer_idx 20
DEBUG: initializing cache for layer_idx 21
DEBUG: initializing cache for layer_idx 22
DEBUG: initializing cache for layer_idx 23
DEBUG: initializing cache for layer_idx 24
DEBUG: initializing cache for layer_idx 25
DEBUG: initializing cache for layer_idx 26
DEBUG: initializing cache for layer_idx 27
DEBUG: initializing cache for layer_idx 28
DEBUG: initializing cache for layer_idx 29
DEBUG: updating/concatenating cache for layer_idx 0
DEBUG: updating/concatenating cache for layer_idx 1
DEBUG: updating/concatenating cache for layer_idx 2
DEBUG: updating/concatenating cache for layer_idx 3
DEBUG: updating/concatenating cache for layer_idx 4
DEBUG: updating/concatenating cache for layer_idx 5
DEBUG: updating/concatenating cache for layer_idx 6
DEBUG: updating/concatenating cache for layer_idx 7
DEBUG: updating/concatenating cache for layer_idx 8
DEBUG: updating/concatenating cache for layer_idx 9
DEBUG: updating/concatenating cache for layer_idx 10
DEBUG: updating/concatenating cache for layer_idx 11
DEBUG: updating/concatenating cache for layer_idx 12
DEBUG: updating/concatenating cache for layer_idx 13
DEBUG: updating/concatenating cache for layer_idx 14
DEBUG: updating/concatenating cache for layer_idx 15
DEBUG: updating/concatenating cache for layer_idx 16
DEBUG: updating/concatenating cache for layer_idx 17
DEBUG: updating/concatenating cache for layer_idx 18
DEBUG: updating/concatenating cache for layer_idx 19
DEBUG: updating/concatenating cache for layer_idx 20
DEBUG: updating/concatenating cache for layer_idx 21
DEBUG: updating/concatenating cache for layer_idx 22
DEBUG: updating/concatenating cache for layer_idx 23
DEBUG: updating/concatenating cache for layer_idx 24
DEBUG: updating/concatenating cache for layer_idx 25
DEBUG: updating/concatenating cache for layer_idx 26
DEBUG: updating/concatenating cache for layer_idx 27
DEBUG: updating/concatenating cache for layer_idx 28
DEBUG: updating/concatenating cache for layer_idx 29</code></pre>
</div>
</div>
<p>As we can see by the printed output, for the first generated token <code>update</code> initializes cache with <code>self.key_cache.append(key_states)</code> and <code>self.value_cache.append(value_states)</code>. For the subsequent tokens, it updates the cache with <code>torch.cat</code>.</p>
<p>I’ll re-assign the original <code>update</code> to <code>DynamicCache</code> to avoid cluttering with print outs.</p>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">DynamicCache.update <span class="op" style="color: #5E5E5E;">=</span> ORIGINAL_DYNAMIC_CACHE_UPDATE</span></code></pre></div>
</div>
</section>
</section>
<section id="inspecting-past_key_values-during-model.generate" class="level2">
<h2 class="anchored" data-anchor-id="inspecting-past_key_values-during-model.generate">Inspecting <code>past_key_values</code> During <code>model.generate</code></h2>
<p>With an understanding of how KV cache is updated, I’ll now turn my attention to the key and value cache contents during autoregressive generation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span>)</span>
<span id="cb20-2">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span>, attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>torch.bfloat16).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="31e79d9e-72c0-4700-a6eb-7e6f795819b0" data-execution_count="63">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"The quick brown"</span></span>
<span id="cb21-2">prompt</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>'The quick brown'</code></pre>
</div>
</div>
<div class="cell" data-outputid="9f2a2d84-afdd-465d-b95e-583cd7a8860a" data-execution_count="64">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">input_ids, attention_mask <span class="op" style="color: #5E5E5E;">=</span> tokenizer(prompt, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>).values()</span>
<span id="cb23-2">input_ids.shape, attention_mask.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>(torch.Size([1, 3]), torch.Size([1, 3]))</code></pre>
</div>
</div>
<p>By setting <code>return_dict_in_generate=True</code> we can retrieve <code>past_key_values</code>.</p>
<div class="cell" data-outputid="8339ed0d-7ce1-45bd-8228-4e3a47f656af" data-execution_count="65">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">outputs <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb25-2">outputs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>GenerateDecoderOnlyOutput(sequences=tensor([[  504,  2365,  6354, 16438, 27003,   690,   260, 23790]],
       device='cuda:0'), scores=None, logits=None, attentions=None, hidden_states=None, past_key_values=&lt;transformers.cache_utils.DynamicCache object at 0x78c4f80c4f50&gt;)</code></pre>
</div>
</div>
<div class="cell" data-outputid="df742156-715e-4ca3-f32e-cacc3303d278" data-execution_count="66">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">tokenizer.decode(outputs.sequences[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>'The quick brown fox jumps over the lazy'</code></pre>
</div>
</div>
<p>We have 8 total tokens—3 from the original prompt and 5 new tokens generated.</p>
<div class="cell" data-outputid="4e26edc9-2958-47a7-eee0-7cc23ad3b7cd" data-execution_count="67">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">outputs.sequences.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>torch.Size([1, 8])</code></pre>
</div>
</div>
<p>Inspecting the values in the KV cache: there are 30 items in <code>key_cache</code> and <code>value_cache</code>, corresponding to the 30 layers in the model. For the last generated token (the 8th token) there were <code>7</code> <code>seen_tokens</code>.</p>
<div class="cell" data-outputid="144271c6-c0d9-443f-b11c-537dd82f3a58" data-execution_count="68">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="bu" style="color: null;">len</span>(outputs.past_key_values.key_cache), <span class="bu" style="color: null;">len</span>(outputs.past_key_values.value_cache)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>(30, 30)</code></pre>
</div>
</div>
<div class="cell" data-outputid="d2af89b4-8842-46d2-c6b5-78e8ad4010d7" data-execution_count="69">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">outputs.past_key_values.seen_tokens</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>7</code></pre>
</div>
</div>
<p>The <code>key_cache</code> tensors all have the same shape: batch size, num_heads, seen_tokens, head_dim.</p>
<div class="cell" data-outputid="df7616f9-08fe-4fa3-f527-615bf9f83a1c" data-execution_count="70">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> outputs.past_key_values.key_cache: <span class="bu" style="color: null;">print</span>(k.shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<div class="cell" data-outputid="b16b73c8-950b-4443-dcea-4701436d9749" data-execution_count="71">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">model.config.num_attention_heads, <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb37-2">model.config.num_hidden_layers, <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb37-3">model.config.num_key_value_heads</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>(9, 30, 3)</code></pre>
</div>
</div>
<div class="cell" data-outputid="41b06ce8-7bfc-4bc6-8ade-8ce7084457ac" data-execution_count="72">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.k_proj.out_features</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>192</code></pre>
</div>
</div>
<div class="cell" data-outputid="316d31cf-cf8b-49e7-ebc7-1cb061de1468" data-execution_count="73">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="dv" style="color: #AD0000;">3</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">64</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>192</code></pre>
</div>
</div>
<p>The <code>value_cache</code> is similarly structured.</p>
<div class="cell" data-outputid="f772dcaa-63fe-4315-e142-0cebb1c9e260" data-execution_count="74">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="cf" style="color: #003B4F;">for</span> v <span class="kw" style="color: #003B4F;">in</span> outputs.past_key_values.value_cache: <span class="bu" style="color: null;">print</span>(v.shape)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<div class="cell" data-outputid="c4db38cf-43f1-4172-ad94-706d347ecea2" data-execution_count="75">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">init_k <span class="op" style="color: #5E5E5E;">=</span> outputs.past_key_values.key_cache[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb45-2">init_k.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<p>While the shapes of the <code>key_cache</code> tensors across layers are the same, their contents are not. This is because each layer has its own self attention module with its own <code>k_proj</code> and <code>v_proj</code> layers with their own learned weights.</p>
<div class="cell" data-outputid="09ec3082-2e2d-44ea-fa9a-1d7517d05b5f" data-execution_count="76">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> outputs.past_key_values.key_cache[<span class="dv" style="color: #AD0000;">1</span>:]: <span class="cf" style="color: #003B4F;">assert</span> torch.allclose(init_k, k)</span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>AssertionError: </code></pre>
</div>
</div>
</section>
<section id="inspecting-intermediate-keyvalue-cache-tensors-during-generation" class="level2">
<h2 class="anchored" data-anchor-id="inspecting-intermediate-keyvalue-cache-tensors-during-generation">Inspecting Intermediate Key/Value Cache Tensors During Generation</h2>
<p>Now to understand how KV cache is used during generation: I want to inspect the shape of the key and value cache tensors as the prompt increases by one token at a time.</p>
<p>To achieve this, I’ll add a hook to the first layer’s self attention module’s forward pass using <code>register_forward_hook</code>. I came to an incorrect conclusion in a <a href="https://youtu.be/4OBQkESiL0M?feature=shared&amp;t=965">previous video</a> and <a href="https://vishalbakshi.github.io/blog/posts/2025-04-02-Composer-Callback-Logging-dtypes/#composer-callback-walkthrough:~:text=Self%20attention%20cannot%20utilize%20register_forward_hook%20because%20the%20LlamaDecoderLayer%20does%20not%20call%20self%20attention%20forward%20pass%20with%20any%20positional%20arguments%3A">blog post</a> that you can’t use <code>register_forward_hook</code> for the Llama attention module because it doesn’t capture keyword arguments. What I didn’t realize is that you can capture kwargs with <code>register_forward_hook</code> by setting <code>with_kwargs=True</code>, which I have done below.</p>
<p>I wrapped <code>hook_fn</code> in <code>create_hook_fn</code> because I wanted to print out the <code>count</code> of total generated tokens.</p>
<div class="cell" data-outputid="222ac421-f62f-444c-d90f-a65a283d8e7b" data-execution_count="77">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="kw" style="color: #003B4F;">def</span> create_hook_fn():</span>
<span id="cb49-2">    count <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb49-3">    <span class="kw" style="color: #003B4F;">def</span> hook_fn(module, args, kwargs, output):</span>
<span id="cb49-4">        <span class="kw" style="color: #003B4F;">nonlocal</span> count</span>
<span id="cb49-5">        <span class="bu" style="color: null;">print</span>(count, kwargs[<span class="st" style="color: #20794D;">'past_key_value'</span>].key_cache[<span class="dv" style="color: #AD0000;">0</span>].shape)</span>
<span id="cb49-6">        count <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb49-7">    <span class="cf" style="color: #003B4F;">return</span> hook_fn</span>
<span id="cb49-8"></span>
<span id="cb49-9">_hook_fn <span class="op" style="color: #5E5E5E;">=</span> create_hook_fn()</span>
<span id="cb49-10">attn_layer <span class="op" style="color: #5E5E5E;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn</span>
<span id="cb49-11">hook_handle <span class="op" style="color: #5E5E5E;">=</span> attn_layer.register_forward_hook(_hook_fn, with_kwargs<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb49-12"></span>
<span id="cb49-13">outputs <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb49-14">hook_handle.remove()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1 torch.Size([1, 3, 3, 64])
2 torch.Size([1, 3, 4, 64])
3 torch.Size([1, 3, 5, 64])
4 torch.Size([1, 3, 6, 64])
5 torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<p>Let’s parse this output:</p>
<ul>
<li>The first new token generated sees only the 3 tokens in the prompt. The KV cache subsequently has a third dimension of <code>3</code>.</li>
<li>Each new token generated sees one more new token, so the third dimension (seen tokens) of <code>key_cache</code> and <code>value_cache</code> increases by <code>1</code></li>
</ul>
<p>I’ll slightly modify <code>hook_fn</code> so it prints out the first few shapes of <code>key_cache</code>, allowing us to see what all layers’ cache is storing from the perspective of <code>layer_idx=0</code>.</p>
<div class="cell" data-outputid="779782e8-dc50-4d92-fc8a-0712826d3cf7" data-execution_count="78">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><span class="kw" style="color: #003B4F;">def</span> create_hook_fn():</span>
<span id="cb51-2">    count <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb51-3">    <span class="kw" style="color: #003B4F;">def</span> hook_fn(module, args, kwargs, output):</span>
<span id="cb51-4">        <span class="kw" style="color: #003B4F;">nonlocal</span> count</span>
<span id="cb51-5">        <span class="bu" style="color: null;">print</span>(count)</span>
<span id="cb51-6">        <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> kwargs[<span class="st" style="color: #20794D;">'past_key_value'</span>].key_cache[:<span class="dv" style="color: #AD0000;">5</span>]: <span class="bu" style="color: null;">print</span>(k.shape)</span>
<span id="cb51-7">        count <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb51-8">    <span class="cf" style="color: #003B4F;">return</span> hook_fn</span>
<span id="cb51-9"></span>
<span id="cb51-10">_hook_fn <span class="op" style="color: #5E5E5E;">=</span> create_hook_fn()</span>
<span id="cb51-11">attn_layer <span class="op" style="color: #5E5E5E;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn</span>
<span id="cb51-12">hook_handle <span class="op" style="color: #5E5E5E;">=</span> attn_layer.register_forward_hook(_hook_fn, with_kwargs<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb51-13"></span>
<span id="cb51-14">outputs <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb51-15">hook_handle.remove()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1
torch.Size([1, 3, 3, 64])
2
torch.Size([1, 3, 4, 64])
torch.Size([1, 3, 3, 64])
torch.Size([1, 3, 3, 64])
torch.Size([1, 3, 3, 64])
torch.Size([1, 3, 3, 64])
3
torch.Size([1, 3, 5, 64])
torch.Size([1, 3, 4, 64])
torch.Size([1, 3, 4, 64])
torch.Size([1, 3, 4, 64])
torch.Size([1, 3, 4, 64])
4
torch.Size([1, 3, 6, 64])
torch.Size([1, 3, 5, 64])
torch.Size([1, 3, 5, 64])
torch.Size([1, 3, 5, 64])
torch.Size([1, 3, 5, 64])
5
torch.Size([1, 3, 7, 64])
torch.Size([1, 3, 6, 64])
torch.Size([1, 3, 6, 64])
torch.Size([1, 3, 6, 64])
torch.Size([1, 3, 6, 64])</code></pre>
</div>
</div>
<p>Since we are capturing the <code>key_cache</code> shapes from the first layer (<code>layer_idx=0</code>), the other subsequent layer’s cache tensors are 1 token “behind”, since the new token’s hidden states have not passed through the model yet.</p>
<p>Ultimately, I want to tie this all back to the <code>flash_attn_varlen_func</code>’s dostring’s causal mask example, so I’ll take a look at the <code>query_states</code> shape, copying code from the <a href="https://github.com/huggingface/transformers/blob/78d771c3c21922642fc9546ccb973cc7a182ab34/src/transformers/models/llama/modeling_llama.py#L232-L235"><code>LlamaAttention</code> forward pass</a>. I’ll also inspect the length of the <code>key_cache</code> and its shape, and the shape of <code>value_cache</code>.</p>
<div class="cell" data-outputid="b70a2dd1-b26f-46f9-cf7e-311cccd3d82b" data-execution_count="79">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="kw" style="color: #003B4F;">def</span> create_hook_fn():</span>
<span id="cb53-2">    count <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb53-3">    <span class="kw" style="color: #003B4F;">def</span> hook_fn(module, args, kwargs, output):</span>
<span id="cb53-4">        <span class="kw" style="color: #003B4F;">nonlocal</span> count</span>
<span id="cb53-5">        input_shape <span class="op" style="color: #5E5E5E;">=</span> kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>].shape[:<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb53-6">        hidden_shape <span class="op" style="color: #5E5E5E;">=</span> (<span class="op" style="color: #5E5E5E;">*</span>input_shape, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, module.head_dim)</span>
<span id="cb53-7">        query_states <span class="op" style="color: #5E5E5E;">=</span> module.q_proj(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>]).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb53-8">        <span class="bu" style="color: null;">print</span>(count, <span class="ss" style="color: #20794D;">f"len(past_key_value): </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(kwargs[<span class="st" style="color: #20794D;">'past_key_value'</span>].key_cache)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">,"</span>, <span class="ss" style="color: #20794D;">f"query_states.shape: </span><span class="sc" style="color: #5E5E5E;">{</span>query_states<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">,"</span>, <span class="ss" style="color: #20794D;">f"k.shape: </span><span class="sc" style="color: #5E5E5E;">{</span>kwargs[<span class="st" style="color: #20794D;">'past_key_value'</span>]<span class="sc" style="color: #5E5E5E;">.</span>key_cache[<span class="dv" style="color: #AD0000;">0</span>]<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">,"</span>, <span class="ss" style="color: #20794D;">f"v.shape: </span><span class="sc" style="color: #5E5E5E;">{</span>kwargs[<span class="st" style="color: #20794D;">'past_key_value'</span>]<span class="sc" style="color: #5E5E5E;">.</span>value_cache[<span class="dv" style="color: #AD0000;">0</span>]<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb53-9">        count <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb53-10">    <span class="cf" style="color: #003B4F;">return</span> hook_fn</span>
<span id="cb53-11"></span>
<span id="cb53-12">_hook_fn <span class="op" style="color: #5E5E5E;">=</span> create_hook_fn()</span>
<span id="cb53-13">attn_layer <span class="op" style="color: #5E5E5E;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn</span>
<span id="cb53-14">hook_handle <span class="op" style="color: #5E5E5E;">=</span> attn_layer.register_forward_hook(_hook_fn, with_kwargs<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb53-15"></span>
<span id="cb53-16">outputs <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb53-17">hook_handle.remove()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1 len(past_key_value): 1, query_states.shape: torch.Size([1, 9, 3, 64]), k.shape: torch.Size([1, 3, 3, 64]), v.shape: torch.Size([1, 3, 3, 64])
2 len(past_key_value): 30, query_states.shape: torch.Size([1, 9, 1, 64]), k.shape: torch.Size([1, 3, 4, 64]), v.shape: torch.Size([1, 3, 4, 64])
3 len(past_key_value): 30, query_states.shape: torch.Size([1, 9, 1, 64]), k.shape: torch.Size([1, 3, 5, 64]), v.shape: torch.Size([1, 3, 5, 64])
4 len(past_key_value): 30, query_states.shape: torch.Size([1, 9, 1, 64]), k.shape: torch.Size([1, 3, 6, 64]), v.shape: torch.Size([1, 3, 6, 64])
5 len(past_key_value): 30, query_states.shape: torch.Size([1, 9, 1, 64]), k.shape: torch.Size([1, 3, 7, 64]), v.shape: torch.Size([1, 3, 7, 64])</code></pre>
</div>
</div>
<p>We see that there are 9 query heads, and 3 KV heads. The total hidden dimension for Q, K and V layers is 3 x 64 = 192.</p>
<p>When the first token is being the generated, the length of the <code>key_cache</code> for <code>layer_idx=0</code> is <code>1</code>, because this is the first attention module’s first forward pass. For subsequent tokens (2, 3, 4, 5) the length of the <code>key_cache</code> is <code>30</code>, as the cache has been instantiated for all 30 layers after the first token is generated.</p>
<p>Finally, we see that the <code>key_cache</code> and <code>value_cache</code> shapes are equal, as expected.</p>
</section>
<section id="which-flash-attention-interface-is-used" class="level2">
<h2 class="anchored" data-anchor-id="which-flash-attention-interface-is-used">Which Flash Attention Interface is Used?</h2>
<p>Since this exercise is part of my journey to understand the <code>flash_attn_varlen_func</code>, I was curious to confirm by visual inspection which Flash Attention interface function was being used. To achieve this, I wrote a “debug” version for the following three functions:</p>
<ul>
<li><a href="https://github.com/huggingface/transformers/blob/78d771c3c21922642fc9546ccb973cc7a182ab34/src/transformers/models/llama/modeling_llama.py#L223"><code>LlamaAttention.forward</code></a></li>
<li><a href="https://github.com/huggingface/transformers/blob/78d771c3c21922642fc9546ccb973cc7a182ab34/src/transformers/integrations/flash_attention.py#L14"><code>flash_attention_forward</code></a></li>
<li><a href="https://github.com/huggingface/transformers/blob/78d771c3c21922642fc9546ccb973cc7a182ab34/src/transformers/modeling_flash_attention_utils.py#L284"><code>_flash_attention_forward</code></a></li>
</ul>
<p>How did I know which functions to modify? Well, largely because I <a href="https://vishalbakshi.github.io/blog/posts/2025-05-04-Understanding-Sequence-Packing/">have done this exercise before</a> when I was trying to understand what triggered the use of <code>flash_attn_varlen_func</code>.</p>
<p>More concisely, I first inspected the forward pass of the attention module:</p>
<div class="cell" data-outputid="fc396455-d320-43da-9491-a9555f6118a5" data-execution_count="80">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="im" style="color: #00769E;">from</span> inspect <span class="im" style="color: #00769E;">import</span> getsource</span>
<span id="cb55-2"><span class="bu" style="color: null;">print</span>(getsource(model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.forward))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>    def forward(
        self,
        hidden_states: torch.Tensor,
        position_embeddings: Tuple[torch.Tensor, torch.Tensor],
        attention_mask: Optional[torch.Tensor],
        past_key_value: Optional[Cache] = None,
        cache_position: Optional[torch.LongTensor] = None,
        **kwargs: Unpack[FlashAttentionKwargs],
    ) -&gt; Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:
        input_shape = hidden_states.shape[:-1]
        hidden_shape = (*input_shape, -1, self.head_dim)

        query_states = self.q_proj(hidden_states).view(hidden_shape).transpose(1, 2)
        key_states = self.k_proj(hidden_states).view(hidden_shape).transpose(1, 2)
        value_states = self.v_proj(hidden_states).view(hidden_shape).transpose(1, 2)

        cos, sin = position_embeddings
        query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)

        if past_key_value is not None:
            # sin and cos are specific to RoPE models; cache_position needed for the static cache
            cache_kwargs = {"sin": sin, "cos": cos, "cache_position": cache_position}
            key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)

        attention_interface: Callable = eager_attention_forward

        if self.config._attn_implementation != "eager":
            if self.config._attn_implementation == "sdpa" and kwargs.get("output_attentions", False):
                logger.warning_once(
                    "`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to "
                    'eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.'
                )
            else:
                attention_interface = ALL_ATTENTION_FUNCTIONS[self.config._attn_implementation]

        attn_output, attn_weights = attention_interface(
            self,
            query_states,
            key_states,
            value_states,
            attention_mask,
            dropout=0.0 if not self.training else self.attention_dropout,
            scaling=self.scaling,
            **kwargs,
        )

        attn_output = attn_output.reshape(*input_shape, -1).contiguous()
        attn_output = self.o_proj(attn_output)
        return attn_output, attn_weights
</code></pre>
</div>
</div>
<p>In there I saw the following lines of interest:</p>
<div class="sourceCode" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.config._attn_implementation <span class="op" style="color: #5E5E5E;">!=</span> <span class="st" style="color: #20794D;">"eager"</span>:</span>
<span id="cb57-2">    <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.config._attn_implementation <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"sdpa"</span> <span class="kw" style="color: #003B4F;">and</span> kwargs.get(<span class="st" style="color: #20794D;">"output_attentions"</span>, <span class="va" style="color: #111111;">False</span>):</span>
<span id="cb57-3">        logger.warning_once(</span>
<span id="cb57-4">            <span class="st" style="color: #20794D;">"`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to "</span></span>
<span id="cb57-5">            <span class="st" style="color: #20794D;">'eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.'</span></span>
<span id="cb57-6">        )</span>
<span id="cb57-7">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb57-8">        attention_interface <span class="op" style="color: #5E5E5E;">=</span> ALL_ATTENTION_FUNCTIONS[<span class="va" style="color: #111111;">self</span>.config._attn_implementation]</span></code></pre></div>
<p>In our case, the <code>else</code> block would trigger and <code>ALL_ATTENTION_FUNCTIONS</code> would be accesssed. Looking at that constant directly we can see that for our model’s <code>_attn_implementation</code> (<code>'flash_attention_2'</code>) the attention interface funtion is <code>flash_attention_forward</code>.</p>
<div class="cell" data-outputid="8d40574b-2e73-4ad6-a6b0-7490e87e4108" data-execution_count="81">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">model.config._attn_implementation</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>'flash_attention_2'</code></pre>
</div>
</div>
<div class="cell" data-outputid="fc2cd815-84be-44c3-8255-4b6a2f33e5c8" data-execution_count="82">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><span class="im" style="color: #00769E;">from</span> transformers.modeling_utils <span class="im" style="color: #00769E;">import</span> ALL_ATTENTION_FUNCTIONS</span>
<span id="cb60-2">ALL_ATTENTION_FUNCTIONS[model.config._attn_implementation]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<div style="max-width:800px; border: 1px solid var(--colab-border-color);"><style>
      pre.function-repr-contents {
        overflow-x: auto;
        padding: 8px 12px;
        max-height: 500px;
      }

      pre.function-repr-contents.function-repr-contents-collapsed {
        cursor: pointer;
        max-height: 100px;
      }
    </style>
    <pre style="white-space: initial; background:
         var(--colab-secondary-surface-color); padding: 8px 12px;
         border-bottom: 1px solid var(--colab-border-color);"><b>transformers.integrations.flash_attention.flash_attention_forward</b><br>def flash_attention_forward(module: torch.nn.Module, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, attention_mask: Optional[torch.Tensor], dropout: float=0.0, scaling: Optional[float]=None, sliding_window: Optional[int]=None, softcap: Optional[float]=None, **kwargs) -&gt; Tuple[torch.Tensor, None]</pre><pre class="function-repr-contents function-repr-contents-collapsed" style="">/usr/local/lib/python3.11/dist-packages/transformers/integrations/flash_attention.py&lt;no docstring&gt;</pre>
      <script>
      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {
        for (const element of document.querySelectorAll('.filepath')) {
          element.style.display = 'block'
          element.onclick = (event) => {
            event.preventDefault();
            event.stopPropagation();
            google.colab.files.view(element.textContent, 11);
          };
        }
      }
      for (const element of document.querySelectorAll('.function-repr-contents')) {
        element.onclick = (event) => {
          event.preventDefault();
          event.stopPropagation();
          element.classList.toggle('function-repr-contents-collapsed');
        };
      }
      </script>
      </div>
</div>
</div>
<div class="cell" data-execution_count="85">
<details>
<summary>Show `_debug_flash_attention_forward</summary>
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> Optional, Tuple</span>
<span id="cb61-2"><span class="im" style="color: #00769E;">import</span> inspect</span>
<span id="cb61-3"><span class="im" style="color: #00769E;">from</span> flash_attn <span class="im" style="color: #00769E;">import</span> flash_attn_func, flash_attn_varlen_func</span>
<span id="cb61-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb61-5"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb61-6"><span class="im" style="color: #00769E;">from</span> transformers.modeling_flash_attention_utils <span class="im" style="color: #00769E;">import</span> is_flash_attn_greater_or_equal, fa_peft_integration_check, _upad_input, pad_input, prepare_fa2_from_position_ids</span>
<span id="cb61-7"></span>
<span id="cb61-8">_flash_supports_window_size <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"window_size"</span> <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">list</span>(inspect.signature(flash_attn_func).parameters)</span>
<span id="cb61-9">flash_241 <span class="op" style="color: #5E5E5E;">=</span> is_flash_attn_greater_or_equal(<span class="st" style="color: #20794D;">"2.4.1"</span>)</span>
<span id="cb61-10">deterministic_g <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb61-11"></span>
<span id="cb61-12"><span class="kw" style="color: #003B4F;">def</span> _debug_flash_attention_forward(</span>
<span id="cb61-13">    query_states: torch.Tensor,</span>
<span id="cb61-14">    key_states: torch.Tensor,</span>
<span id="cb61-15">    value_states: torch.Tensor,</span>
<span id="cb61-16">    attention_mask: Optional[torch.Tensor],</span>
<span id="cb61-17">    query_length: <span class="bu" style="color: null;">int</span>,</span>
<span id="cb61-18">    is_causal: <span class="bu" style="color: null;">bool</span>,</span>
<span id="cb61-19">    dropout: <span class="bu" style="color: null;">float</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.0</span>,</span>
<span id="cb61-20">    position_ids: Optional[torch.Tensor] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-21">    softmax_scale: Optional[<span class="bu" style="color: null;">float</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-22">    sliding_window: Optional[<span class="bu" style="color: null;">int</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-23">    use_top_left_mask: <span class="bu" style="color: null;">bool</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span>,</span>
<span id="cb61-24">    softcap: Optional[<span class="bu" style="color: null;">float</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-25">    deterministic: Optional[<span class="bu" style="color: null;">bool</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-26">    cu_seq_lens_q: Optional[torch.LongTensor] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-27">    cu_seq_lens_k: Optional[torch.LongTensor] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-28">    max_length_q: Optional[<span class="bu" style="color: null;">int</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-29">    max_length_k: Optional[<span class="bu" style="color: null;">int</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-30">    target_dtype: Optional[torch.dtype] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb61-31">    <span class="op" style="color: #5E5E5E;">**</span>kwargs,</span>
<span id="cb61-32">):</span>
<span id="cb61-33"></span>
<span id="cb61-34">    <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> use_top_left_mask:</span>
<span id="cb61-35">        causal <span class="op" style="color: #5E5E5E;">=</span> is_causal</span>
<span id="cb61-36">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb61-37">        <span class="co" style="color: #5E5E5E;"># </span><span class="al" style="color: #AD0000;">TODO</span><span class="co" style="color: #5E5E5E;">: Remove the `query_length != 1` check once Flash Attention for RoCm is bumped to 2.1.</span></span>
<span id="cb61-38">        causal <span class="op" style="color: #5E5E5E;">=</span> is_causal <span class="kw" style="color: #003B4F;">and</span> query_length <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb61-39"></span>
<span id="cb61-40">    <span class="co" style="color: #5E5E5E;"># Assuming 4D tensors, key_states.shape[1] is the key/value sequence length (source length).</span></span>
<span id="cb61-41">    use_sliding_windows <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb61-42">        _flash_supports_window_size <span class="kw" style="color: #003B4F;">and</span> sliding_window <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> key_states.shape[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">&gt;</span> sliding_window</span>
<span id="cb61-43">    )</span>
<span id="cb61-44">    flash_kwargs <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">"window_size"</span>: (sliding_window, sliding_window)} <span class="cf" style="color: #003B4F;">if</span> use_sliding_windows <span class="cf" style="color: #003B4F;">else</span> {}</span>
<span id="cb61-45"></span>
<span id="cb61-46">    <span class="cf" style="color: #003B4F;">if</span> flash_241:</span>
<span id="cb61-47">        <span class="cf" style="color: #003B4F;">if</span> deterministic <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb61-48">            <span class="kw" style="color: #003B4F;">global</span> deterministic_g</span>
<span id="cb61-49">            <span class="cf" style="color: #003B4F;">if</span> deterministic_g <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb61-50">                deterministic_g <span class="op" style="color: #5E5E5E;">=</span> os.environ.get(<span class="st" style="color: #20794D;">"FLASH_ATTENTION_DETERMINISTIC"</span>, <span class="st" style="color: #20794D;">"0"</span>) <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"1"</span></span>
<span id="cb61-51">            deterministic <span class="op" style="color: #5E5E5E;">=</span> deterministic_g</span>
<span id="cb61-52">        flash_kwargs[<span class="st" style="color: #20794D;">"deterministic"</span>] <span class="op" style="color: #5E5E5E;">=</span> deterministic</span>
<span id="cb61-53"></span>
<span id="cb61-54">    <span class="cf" style="color: #003B4F;">if</span> softcap <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb61-55">        flash_kwargs[<span class="st" style="color: #20794D;">"softcap"</span>] <span class="op" style="color: #5E5E5E;">=</span> softcap</span>
<span id="cb61-56"></span>
<span id="cb61-57">    <span class="co" style="color: #5E5E5E;"># PEFT possibly silently casts tensors to fp32, this potentially reconverts to correct dtype or is a no op</span></span>
<span id="cb61-58">    query_states, key_states, value_states <span class="op" style="color: #5E5E5E;">=</span> fa_peft_integration_check(</span>
<span id="cb61-59">        query_states, key_states, value_states, target_dtype</span>
<span id="cb61-60">    )</span>
<span id="cb61-61"></span>
<span id="cb61-62">    <span class="co" style="color: #5E5E5E;"># Contains at least one padding token in the sequence</span></span>
<span id="cb61-63">    <span class="cf" style="color: #003B4F;">if</span> attention_mask <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb61-64">        batch_size <span class="op" style="color: #5E5E5E;">=</span> query_states.shape[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb61-65">        query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens <span class="op" style="color: #5E5E5E;">=</span> _upad_input(</span>
<span id="cb61-66">            query_states, key_states, value_states, attention_mask, query_length</span>
<span id="cb61-67">        )</span>
<span id="cb61-68">        cu_seqlens_q, cu_seqlens_k <span class="op" style="color: #5E5E5E;">=</span> cu_seq_lens</span>
<span id="cb61-69">        max_seqlen_in_batch_q, max_seqlen_in_batch_k <span class="op" style="color: #5E5E5E;">=</span> max_seq_lens</span>
<span id="cb61-70">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"if attention_mask is not None: flash_attn_varlen_func is being used"</span>)</span>
<span id="cb61-71">        attn_output_unpad <span class="op" style="color: #5E5E5E;">=</span> flash_attn_varlen_func(</span>
<span id="cb61-72">            query_states,</span>
<span id="cb61-73">            key_states,</span>
<span id="cb61-74">            value_states,</span>
<span id="cb61-75">            cu_seqlens_q<span class="op" style="color: #5E5E5E;">=</span>cu_seqlens_q,</span>
<span id="cb61-76">            cu_seqlens_k<span class="op" style="color: #5E5E5E;">=</span>cu_seqlens_k,</span>
<span id="cb61-77">            max_seqlen_q<span class="op" style="color: #5E5E5E;">=</span>max_seqlen_in_batch_q,</span>
<span id="cb61-78">            max_seqlen_k<span class="op" style="color: #5E5E5E;">=</span>max_seqlen_in_batch_k,</span>
<span id="cb61-79">            dropout_p<span class="op" style="color: #5E5E5E;">=</span>dropout,</span>
<span id="cb61-80">            softmax_scale<span class="op" style="color: #5E5E5E;">=</span>softmax_scale,</span>
<span id="cb61-81">            causal<span class="op" style="color: #5E5E5E;">=</span>causal,</span>
<span id="cb61-82">            <span class="op" style="color: #5E5E5E;">**</span>flash_kwargs,</span>
<span id="cb61-83">        )</span>
<span id="cb61-84">        attn_output <span class="op" style="color: #5E5E5E;">=</span> pad_input(attn_output_unpad, indices_q, batch_size, query_length)</span>
<span id="cb61-85"></span>
<span id="cb61-86">    <span class="co" style="color: #5E5E5E;"># If position_ids is provided and check all examples do not contain only 1 sequence, If tensor in increasing</span></span>
<span id="cb61-87">    <span class="co" style="color: #5E5E5E;"># then we probably have one sequence, otherwise it is packed. Additionally check we are in pre-fill/training stage.</span></span>
<span id="cb61-88">    <span class="co" style="color: #5E5E5E;"># Use `flash_attn_varlen_func` to prevent cross-example attention and also allow padding free approach</span></span>
<span id="cb61-89">    <span class="cf" style="color: #003B4F;">elif</span> position_ids <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> (</span>
<span id="cb61-90">        max_length_q <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> (query_length <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="kw" style="color: #003B4F;">and</span> <span class="kw" style="color: #003B4F;">not</span> (torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">&gt;=</span> <span class="dv" style="color: #AD0000;">0</span>).<span class="bu" style="color: null;">all</span>())</span>
<span id="cb61-91">    ):</span>
<span id="cb61-92">        batch_size <span class="op" style="color: #5E5E5E;">=</span> query_states.size(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb61-93"></span>
<span id="cb61-94">        <span class="cf" style="color: #003B4F;">if</span> cu_seq_lens_q <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> cu_seq_lens_k <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb61-95">            query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb61-96">                prepare_fa2_from_position_ids(query_states, key_states, value_states, position_ids)</span>
<span id="cb61-97">            )</span>
<span id="cb61-98"></span>
<span id="cb61-99">            cu_seq_lens_q, cu_seq_lens_k <span class="op" style="color: #5E5E5E;">=</span> cu_seq_lens</span>
<span id="cb61-100">            max_length_q, max_length_k <span class="op" style="color: #5E5E5E;">=</span> max_seq_lens</span>
<span id="cb61-101"></span>
<span id="cb61-102">        <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb61-103">            query_states <span class="op" style="color: #5E5E5E;">=</span> query_states.reshape(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, query_states.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>), query_states.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb61-104">            key_states <span class="op" style="color: #5E5E5E;">=</span> key_states.reshape(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, key_states.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>), key_states.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb61-105">            value_states <span class="op" style="color: #5E5E5E;">=</span> value_states.reshape(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, value_states.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>), value_states.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb61-106"></span>
<span id="cb61-107">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"position_ids is not None: flash_attn_varlen_func is being used"</span>)</span>
<span id="cb61-108">        attn_output <span class="op" style="color: #5E5E5E;">=</span> flash_attn_varlen_func(</span>
<span id="cb61-109">            query_states,</span>
<span id="cb61-110">            key_states,</span>
<span id="cb61-111">            value_states,</span>
<span id="cb61-112">            cu_seqlens_q<span class="op" style="color: #5E5E5E;">=</span>cu_seq_lens_q,</span>
<span id="cb61-113">            cu_seqlens_k<span class="op" style="color: #5E5E5E;">=</span>cu_seq_lens_k,</span>
<span id="cb61-114">            max_seqlen_q<span class="op" style="color: #5E5E5E;">=</span>max_length_q,</span>
<span id="cb61-115">            max_seqlen_k<span class="op" style="color: #5E5E5E;">=</span>max_length_k,</span>
<span id="cb61-116">            dropout_p<span class="op" style="color: #5E5E5E;">=</span>dropout,</span>
<span id="cb61-117">            softmax_scale<span class="op" style="color: #5E5E5E;">=</span>softmax_scale,</span>
<span id="cb61-118">            causal<span class="op" style="color: #5E5E5E;">=</span>causal,</span>
<span id="cb61-119">            <span class="op" style="color: #5E5E5E;">**</span>flash_kwargs,</span>
<span id="cb61-120">        )</span>
<span id="cb61-121"></span>
<span id="cb61-122">        attn_output <span class="op" style="color: #5E5E5E;">=</span> attn_output.view(batch_size, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, attn_output.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">2</span>), attn_output.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb61-123"></span>
<span id="cb61-124">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb61-125">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"flash_attn_func is being used"</span>)</span>
<span id="cb61-126">        attn_output <span class="op" style="color: #5E5E5E;">=</span> flash_attn_func(</span>
<span id="cb61-127">            query_states, key_states, value_states, dropout, softmax_scale<span class="op" style="color: #5E5E5E;">=</span>softmax_scale, causal<span class="op" style="color: #5E5E5E;">=</span>causal, <span class="op" style="color: #5E5E5E;">**</span>flash_kwargs</span>
<span id="cb61-128">        )</span>
<span id="cb61-129"></span>
<span id="cb61-130">    <span class="cf" style="color: #003B4F;">return</span> attn_output</span></code></pre></div>
</details>
</div>
<div class="cell" data-execution_count="86">
<details>
<summary>Show `debug_flash_attention_forward</summary>
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> Optional, Tuple</span>
<span id="cb62-2"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb62-3"><span class="im" style="color: #00769E;">from</span> transformers.modeling_flash_attention_utils <span class="im" style="color: #00769E;">import</span> _flash_attention_forward, flash_attn_supports_top_left_mask</span>
<span id="cb62-4"></span>
<span id="cb62-5">_use_top_left_mask <span class="op" style="color: #5E5E5E;">=</span> flash_attn_supports_top_left_mask()</span>
<span id="cb62-6"></span>
<span id="cb62-7"></span>
<span id="cb62-8"><span class="kw" style="color: #003B4F;">def</span> debug_flash_attention_forward(</span>
<span id="cb62-9">    module: torch.nn.Module,</span>
<span id="cb62-10">    query: torch.Tensor,</span>
<span id="cb62-11">    key: torch.Tensor,</span>
<span id="cb62-12">    value: torch.Tensor,</span>
<span id="cb62-13">    attention_mask: Optional[torch.Tensor],</span>
<span id="cb62-14">    dropout: <span class="bu" style="color: null;">float</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.0</span>,</span>
<span id="cb62-15">    scaling: Optional[<span class="bu" style="color: null;">float</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb62-16">    sliding_window: Optional[<span class="bu" style="color: null;">int</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb62-17">    softcap: Optional[<span class="bu" style="color: null;">float</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb62-18">    <span class="op" style="color: #5E5E5E;">**</span>kwargs,</span>
<span id="cb62-19">) <span class="op" style="color: #5E5E5E;">-&gt;</span> Tuple[torch.Tensor, <span class="va" style="color: #111111;">None</span>]:</span>
<span id="cb62-20">    <span class="cf" style="color: #003B4F;">if</span> kwargs.get(<span class="st" style="color: #20794D;">"output_attentions"</span>, <span class="va" style="color: #111111;">False</span>) <span class="kw" style="color: #003B4F;">or</span> kwargs.get(<span class="st" style="color: #20794D;">"head_mask"</span>, <span class="va" style="color: #111111;">None</span>) <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb62-21">        <span class="bu" style="color: null;">print</span>(</span>
<span id="cb62-22">            <span class="st" style="color: #20794D;">"`flash_attention_2` does not support `output_attentions=True` or `head_mask`."</span></span>
<span id="cb62-23">            <span class="st" style="color: #20794D;">" Please set your attention to `eager` if you want any of these features."</span></span>
<span id="cb62-24">        )</span>
<span id="cb62-25"></span>
<span id="cb62-26">    <span class="co" style="color: #5E5E5E;"># This is before the transpose</span></span>
<span id="cb62-27">    seq_len <span class="op" style="color: #5E5E5E;">=</span> query.shape[<span class="dv" style="color: #AD0000;">2</span>]</span>
<span id="cb62-28"></span>
<span id="cb62-29">    <span class="co" style="color: #5E5E5E;"># FA2 uses non-transposed inputs</span></span>
<span id="cb62-30">    query <span class="op" style="color: #5E5E5E;">=</span> query.transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb62-31">    key <span class="op" style="color: #5E5E5E;">=</span> key.transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb62-32">    value <span class="op" style="color: #5E5E5E;">=</span> value.transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb62-33"></span>
<span id="cb62-34">    <span class="co" style="color: #5E5E5E;"># In PEFT, usually we cast the layer norms in float32 for training stability reasons</span></span>
<span id="cb62-35">    <span class="co" style="color: #5E5E5E;"># therefore the input hidden states gets silently casted in float32. Hence, we need</span></span>
<span id="cb62-36">    <span class="co" style="color: #5E5E5E;"># cast them back in the correct dtype just to be sure everything works as expected.</span></span>
<span id="cb62-37">    <span class="co" style="color: #5E5E5E;"># This might slowdown training &amp; inference so it is recommended to not cast the LayerNorms</span></span>
<span id="cb62-38">    <span class="co" style="color: #5E5E5E;"># in fp32. (usually our RMSNorm modules handle it correctly)</span></span>
<span id="cb62-39">    target_dtype <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb62-40">    <span class="cf" style="color: #003B4F;">if</span> query.dtype <span class="op" style="color: #5E5E5E;">==</span> torch.float32:</span>
<span id="cb62-41">        <span class="cf" style="color: #003B4F;">if</span> torch.is_autocast_enabled():</span>
<span id="cb62-42">            target_dtype <span class="op" style="color: #5E5E5E;">=</span> torch.get_autocast_gpu_dtype()</span>
<span id="cb62-43">        <span class="co" style="color: #5E5E5E;"># Handle the case where the model is quantized</span></span>
<span id="cb62-44">        <span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">hasattr</span>(module.config, <span class="st" style="color: #20794D;">"_pre_quantization_dtype"</span>):</span>
<span id="cb62-45">            target_dtype <span class="op" style="color: #5E5E5E;">=</span> module.config._pre_quantization_dtype</span>
<span id="cb62-46">        <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb62-47">            target_dtype <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">next</span>(layer <span class="cf" style="color: #003B4F;">for</span> layer <span class="kw" style="color: #003B4F;">in</span> module.modules() <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(layer, torch.nn.Linear)).weight.dtype</span>
<span id="cb62-48"></span>
<span id="cb62-49">    <span class="co" style="color: #5E5E5E;"># FA2 always relies on the value set in the module, so remove it if present in kwargs to avoid passing it twice</span></span>
<span id="cb62-50">    kwargs.pop(<span class="st" style="color: #20794D;">"is_causal"</span>, <span class="va" style="color: #111111;">None</span>)</span>
<span id="cb62-51"></span>
<span id="cb62-52">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"DEBUG: calling _flash_attention_forward"</span>)</span>
<span id="cb62-53">    attn_output <span class="op" style="color: #5E5E5E;">=</span> _debug_flash_attention_forward(</span>
<span id="cb62-54">        query,</span>
<span id="cb62-55">        key,</span>
<span id="cb62-56">        value,</span>
<span id="cb62-57">        attention_mask,</span>
<span id="cb62-58">        query_length<span class="op" style="color: #5E5E5E;">=</span>seq_len,</span>
<span id="cb62-59">        is_causal<span class="op" style="color: #5E5E5E;">=</span>module.is_causal,</span>
<span id="cb62-60">        dropout<span class="op" style="color: #5E5E5E;">=</span>dropout,</span>
<span id="cb62-61">        softmax_scale<span class="op" style="color: #5E5E5E;">=</span>scaling,</span>
<span id="cb62-62">        sliding_window<span class="op" style="color: #5E5E5E;">=</span>sliding_window,</span>
<span id="cb62-63">        softcap<span class="op" style="color: #5E5E5E;">=</span>softcap,</span>
<span id="cb62-64">        use_top_left_mask<span class="op" style="color: #5E5E5E;">=</span>_use_top_left_mask,</span>
<span id="cb62-65">        target_dtype<span class="op" style="color: #5E5E5E;">=</span>target_dtype,</span>
<span id="cb62-66">        <span class="op" style="color: #5E5E5E;">**</span>kwargs,</span>
<span id="cb62-67">    )</span>
<span id="cb62-68"></span>
<span id="cb62-69">    <span class="cf" style="color: #003B4F;">return</span> attn_output, <span class="va" style="color: #111111;">None</span></span></code></pre></div>
</details>
</div>
<div class="cell" data-execution_count="87">
<details>
<summary>Show `debug_forward</summary>
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> Callable, Optional, Tuple, Union</span>
<span id="cb63-2"><span class="im" style="color: #00769E;">from</span> transformers.modeling_flash_attention_utils <span class="im" style="color: #00769E;">import</span> FlashAttentionKwargs</span>
<span id="cb63-3"><span class="im" style="color: #00769E;">from</span> transformers.cache_utils <span class="im" style="color: #00769E;">import</span> Cache, DynamicCache</span>
<span id="cb63-4"><span class="im" style="color: #00769E;">from</span> transformers.processing_utils <span class="im" style="color: #00769E;">import</span> Unpack</span>
<span id="cb63-5"><span class="im" style="color: #00769E;">from</span> transformers.models.llama.modeling_llama <span class="im" style="color: #00769E;">import</span> apply_rotary_pos_emb</span>
<span id="cb63-6"><span class="im" style="color: #00769E;">from</span> transformers.models.llama.modeling_llama <span class="im" style="color: #00769E;">import</span> eager_attention_forward</span>
<span id="cb63-7"><span class="im" style="color: #00769E;">from</span> transformers.modeling_utils <span class="im" style="color: #00769E;">import</span> ALL_ATTENTION_FUNCTIONS</span>
<span id="cb63-8"></span>
<span id="cb63-9"><span class="kw" style="color: #003B4F;">def</span> debug_forward(</span>
<span id="cb63-10">    <span class="va" style="color: #111111;">self</span>,</span>
<span id="cb63-11">    hidden_states: torch.Tensor,</span>
<span id="cb63-12">    position_embeddings: Tuple[torch.Tensor, torch.Tensor],</span>
<span id="cb63-13">    attention_mask: Optional[torch.Tensor],</span>
<span id="cb63-14">    past_key_value: Optional[Cache] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb63-15">    cache_position: Optional[torch.LongTensor] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb63-16">    <span class="op" style="color: #5E5E5E;">**</span>kwargs: Unpack[FlashAttentionKwargs],</span>
<span id="cb63-17">) <span class="op" style="color: #5E5E5E;">-&gt;</span> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:</span>
<span id="cb63-18">    input_shape <span class="op" style="color: #5E5E5E;">=</span> hidden_states.shape[:<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb63-19">    hidden_shape <span class="op" style="color: #5E5E5E;">=</span> (<span class="op" style="color: #5E5E5E;">*</span>input_shape, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="va" style="color: #111111;">self</span>.head_dim)</span>
<span id="cb63-20"></span>
<span id="cb63-21">    query_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.q_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb63-22">    key_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.k_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb63-23">    value_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.v_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb63-24"></span>
<span id="cb63-25">    cos, sin <span class="op" style="color: #5E5E5E;">=</span> position_embeddings</span>
<span id="cb63-26">    query_states, key_states <span class="op" style="color: #5E5E5E;">=</span> apply_rotary_pos_emb(query_states, key_states, cos, sin)</span>
<span id="cb63-27"></span>
<span id="cb63-28">    <span class="cf" style="color: #003B4F;">if</span> past_key_value <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb63-29">        <span class="co" style="color: #5E5E5E;"># sin and cos are specific to RoPE models; cache_position needed for the static cache</span></span>
<span id="cb63-30">        cache_kwargs <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">"sin"</span>: sin, <span class="st" style="color: #20794D;">"cos"</span>: cos, <span class="st" style="color: #20794D;">"cache_position"</span>: cache_position}</span>
<span id="cb63-31">        key_states, value_states <span class="op" style="color: #5E5E5E;">=</span> past_key_value.update(key_states, value_states, <span class="va" style="color: #111111;">self</span>.layer_idx, cache_kwargs)</span>
<span id="cb63-32"></span>
<span id="cb63-33">    attention_interface: Callable <span class="op" style="color: #5E5E5E;">=</span> eager_attention_forward</span>
<span id="cb63-34"></span>
<span id="cb63-35">    <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.config._attn_implementation <span class="op" style="color: #5E5E5E;">!=</span> <span class="st" style="color: #20794D;">"eager"</span>:</span>
<span id="cb63-36">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.config._attn_implementation <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"sdpa"</span> <span class="kw" style="color: #003B4F;">and</span> kwargs.get(<span class="st" style="color: #20794D;">"output_attentions"</span>, <span class="va" style="color: #111111;">False</span>):</span>
<span id="cb63-37">            <span class="bu" style="color: null;">print</span>(</span>
<span id="cb63-38">                <span class="st" style="color: #20794D;">"`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to "</span></span>
<span id="cb63-39">                <span class="st" style="color: #20794D;">'eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.'</span></span>
<span id="cb63-40">            )</span>
<span id="cb63-41">        <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb63-42">            <span class="co" style="color: #5E5E5E;">#attention_interface = ALL_ATTENTION_FUNCTIONS[self.config._attn_implementation]</span></span>
<span id="cb63-43">            attention_interface <span class="op" style="color: #5E5E5E;">=</span> debug_flash_attention_forward</span>
<span id="cb63-44"></span>
<span id="cb63-45">    attn_output, attn_weights <span class="op" style="color: #5E5E5E;">=</span> attention_interface(</span>
<span id="cb63-46">        <span class="va" style="color: #111111;">self</span>,</span>
<span id="cb63-47">        query_states,</span>
<span id="cb63-48">        key_states,</span>
<span id="cb63-49">        value_states,</span>
<span id="cb63-50">        attention_mask,</span>
<span id="cb63-51">        dropout<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.0</span> <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">self</span>.training <span class="cf" style="color: #003B4F;">else</span> <span class="va" style="color: #111111;">self</span>.attention_dropout,</span>
<span id="cb63-52">        scaling<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>.scaling,</span>
<span id="cb63-53">        <span class="op" style="color: #5E5E5E;">**</span>kwargs,</span>
<span id="cb63-54">    )</span>
<span id="cb63-55"></span>
<span id="cb63-56">    attn_output <span class="op" style="color: #5E5E5E;">=</span> attn_output.reshape(<span class="op" style="color: #5E5E5E;">*</span>input_shape, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>).contiguous()</span>
<span id="cb63-57">    attn_output <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.o_proj(attn_output)</span>
<span id="cb63-58">    <span class="cf" style="color: #003B4F;">return</span> attn_output, attn_weights</span></code></pre></div>
</details>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span>)</span>
<span id="cb64-2">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span>, attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>torch.bfloat16).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span></code></pre></div>
</div>
<p><code>types.MethodType</code> binds a function (<code>debug_forward</code>) as a method for a class (<code>attn_layer_instance</code>).</p>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="im" style="color: #00769E;">import</span> types</span>
<span id="cb65-2">types.MethodType??</span></code></pre></div>
</div>
<pre><code>Init signature: types.MethodType(self, /, *args, **kwargs)
Docstring:      Create a bound instance method object.
Type:           type
Subclasses:    </code></pre>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1">attn_layer_instance <span class="op" style="color: #5E5E5E;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn</span>
<span id="cb67-2"></span>
<span id="cb67-3">original_layer_forward <span class="op" style="color: #5E5E5E;">=</span> attn_layer_instance.forward</span>
<span id="cb67-4"></span>
<span id="cb67-5">attn_layer_instance.forward <span class="op" style="color: #5E5E5E;">=</span> types.MethodType(debug_forward, attn_layer_instance)</span></code></pre></div>
</div>
<div class="cell" data-outputid="f9c3e320-4cc7-4467-bd12-727167ceb4b9" data-execution_count="91">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><span class="kw" style="color: #003B4F;">def</span> create_hook_fn():</span>
<span id="cb68-2">    count <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb68-3">    <span class="kw" style="color: #003B4F;">def</span> hook_fn(module, args, kwargs, output):</span>
<span id="cb68-4">        <span class="kw" style="color: #003B4F;">nonlocal</span> count</span>
<span id="cb68-5">        input_shape <span class="op" style="color: #5E5E5E;">=</span> kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>].shape[:<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb68-6">        hidden_shape <span class="op" style="color: #5E5E5E;">=</span> (<span class="op" style="color: #5E5E5E;">*</span>input_shape, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, module.head_dim)</span>
<span id="cb68-7">        query_states <span class="op" style="color: #5E5E5E;">=</span> module.q_proj(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>]).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb68-8">        <span class="bu" style="color: null;">print</span>(count, <span class="bu" style="color: null;">len</span>(kwargs[<span class="st" style="color: #20794D;">'past_key_value'</span>].key_cache), <span class="ss" style="color: #20794D;">f"query_states.shape: </span><span class="sc" style="color: #5E5E5E;">{</span>query_states<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="ss" style="color: #20794D;">f"k.shape: </span><span class="sc" style="color: #5E5E5E;">{</span>kwargs[<span class="st" style="color: #20794D;">'past_key_value'</span>]<span class="sc" style="color: #5E5E5E;">.</span>key_cache[<span class="dv" style="color: #AD0000;">0</span>]<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb68-9">        <span class="co" style="color: #5E5E5E;"># for k in kwargs['past_key_value'].key_cache: print(k.shape) # do this for v as well</span></span>
<span id="cb68-10">        count <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb68-11">    <span class="cf" style="color: #003B4F;">return</span> hook_fn</span>
<span id="cb68-12"></span>
<span id="cb68-13">_hook_fn <span class="op" style="color: #5E5E5E;">=</span> create_hook_fn()</span>
<span id="cb68-14">attn_layer <span class="op" style="color: #5E5E5E;">=</span> model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn</span>
<span id="cb68-15">hook_handle <span class="op" style="color: #5E5E5E;">=</span> attn_layer.register_forward_hook(_hook_fn, with_kwargs<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb68-16"></span>
<span id="cb68-17">outputs <span class="op" style="color: #5E5E5E;">=</span> model.generate(input_ids, pad_token_id<span class="op" style="color: #5E5E5E;">=</span>tokenizer.eos_token_id, do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, return_dict_in_generate<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, max_new_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb68-18"><span class="bu" style="color: null;">print</span>(outputs.sequences[<span class="dv" style="color: #AD0000;">0</span>].shape)</span>
<span id="cb68-19"></span>
<span id="cb68-20">hook_handle.remove()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DEBUG: calling _flash_attention_forward
flash_attn_func is being used
1 1 query_states.shape: torch.Size([1, 9, 3, 64]) k.shape: torch.Size([1, 3, 3, 64])
DEBUG: calling _flash_attention_forward
flash_attn_func is being used
2 30 query_states.shape: torch.Size([1, 9, 1, 64]) k.shape: torch.Size([1, 3, 4, 64])
DEBUG: calling _flash_attention_forward
flash_attn_func is being used
3 30 query_states.shape: torch.Size([1, 9, 1, 64]) k.shape: torch.Size([1, 3, 5, 64])
DEBUG: calling _flash_attention_forward
flash_attn_func is being used
4 30 query_states.shape: torch.Size([1, 9, 1, 64]) k.shape: torch.Size([1, 3, 6, 64])
DEBUG: calling _flash_attention_forward
flash_attn_func is being used
5 30 query_states.shape: torch.Size([1, 9, 1, 64]) k.shape: torch.Size([1, 3, 7, 64])
torch.Size([8])</code></pre>
</div>
</div>
<p>From the print statements in my <code>_debug_flash_attention_forward</code> function, I can see that <code>flash_attn_func</code>, the non-variable-length interface, is being used for this generation. That makes sense because I only have 1 item in the batch.</p>
</section>
<section id="understanding-the-flash_attn_varlen_func-causal-mask-docstring" class="level2">
<h2 class="anchored" data-anchor-id="understanding-the-flash_attn_varlen_func-causal-mask-docstring">Understanding the <code>flash_attn_varlen_func</code> Causal Mask Docstring</h2>
<p>A quick recap of what we’ve learned so far:</p>
<ul>
<li>HuggingFace’s <code>model.generate</code> uses KV cache by default (<code>DynamicCache</code>) stored as <code>past_key_values</code>.</li>
<li>For most scenarios, the <code>DynamicCache</code> is updated by concatenating the previous token’s <code>key_cache</code> and <code>value_cache</code> with the <code>key_states</code> and <code>value_states</code> generated for the current new token.</li>
<li>As the next token is generated for a given prompt, <code>query_states</code> has a sequence length of <code>1</code>, whereas <code>key_cache</code> and <code>value_cache</code> tensors’ sequence dimension increases by 1. This is directly relates to the <code>flash_attn_varlen_func</code> causal mask docstring example.</li>
<li><code>model.generate</code> utilized the <code>flash_attn_func</code> interface.</li>
</ul>
<p>Let’s look at the <code>flash_attn_varlen_func</code> docstring snippet again:</p>
<pre><code>If causal=True, the causal mask is aligned to the bottom right corner of the attention matrix.
For example, if seqlen_q = 2 and seqlen_k = 5, the causal mask (1 = keep, 0 = masked out) is:
    1 1 1 1 0
    1 1 1 1 1
If seqlen_q = 5 and seqlen_k = 2, the causal mask is:
    0 0
    0 0
    0 0
    1 0
    1 1
If the row of the mask is all zero, the output will be zero.</code></pre>
<p>I’ll annotate the causal mask examples a bit:</p>
<section id="seqlen_q2-and-seqlen_k5" class="level3">
<h3 class="anchored" data-anchor-id="seqlen_q2-and-seqlen_k5"><code>seqlen_q=2</code> and <code>seqlen_k=5</code></h3>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">k_0</th>
<th style="text-align: center;">k_1</th>
<th style="text-align: center;">k_2</th>
<th style="text-align: center;">k_3</th>
<th style="text-align: center;">k_4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>q_0</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_1</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>The final query token (<code>q_1</code>) sees all 5 key tokens. The first query token (<code>q_0</code>) only sees the first four key tokens.</p>
</section>
<section id="seqlen_q5-and-seqlen_k2" class="level3">
<h3 class="anchored" data-anchor-id="seqlen_q5-and-seqlen_k2"><code>seqlen_q=5</code> and <code>seqlen_k=2</code></h3>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">k_0</th>
<th style="text-align: center;">k_1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>q_0</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_1</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>q_2</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_3</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>q_4</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p>Again, the final query token (<code>q_4</code>) sees all key tokens. As a consequence, since there are only two key tokens, the first three query tokens do not see any key tokens.</p>
<p>In each example, we are offsetting the shorter sequence so that its last token aligns with the other sequences’s last token. This is what the <code>flash_attn_varlen_func</code> docstring means by</p>
<blockquote class="blockquote">
<p><code>the causal mask is aligned to the bottom right corner of the attention matrix</code></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Annotated casual masks"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-03-flash_attn_varlen_func-casual-mask/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Annotated casual masks</figcaption><p></p>
</figure>
</div>
<p>In the first case, the query sequence is shorter so we offset it by 3 positions to align with the last two tokens of the key sequence. The “offset” positions are 1s (this satisfies the rule of causality <code>j &lt;= i</code>, query tokens can look back). In the second case, the key sequence is shorter so we offset it by 3 positions to align with the last two tokens of the query sequence. The offset positions are 0s (again, this satisfies causality, the query tokens have nothing to look back to).</p>
<p>The <code>model.generate</code> examples above are like the first case, where there are more key positions than query positions. The query token (the next-token being predicted) can look back at all key tokens.</p>
</section>
<section id="a-math-y-way-to-think-about-it" class="level3">
<h3 class="anchored" data-anchor-id="a-math-y-way-to-think-about-it">A Math-y Way to think About It</h3>
<p>For those of you who like to think through things with math.</p>
<p>Causality (in language modeling) means that a query token vector at the i-th position can only see its own and previous tokens’ key vectors. Having different sequence lengths for Q and K (5 and 2 or 2 and 5 in the <code>flash_attn_varlen_func</code> docstring example or 1 and 3-7 in my inspections above) requires you to pick <em>how</em> Q and K are aligned. In the case of <code>flash_attn_varlen_func</code> they choose to align Q and K such as <em>the last Q token vector is aligned with the last K token vector</em>. This becomes our “present moment” <code>P</code> with causality allowing access to previous tokens only.</p>
<p>Let’s define <code>i</code> as the position of query tokens and <code>j</code> as the position of key tokens. Causality is defined as token pairs that follow the inequality: <code>j &lt;= i + (seqlen_k - seqlen_q)</code>.</p>
<p>For the first causal mask example:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"><code>j</code></th>
<th style="text-align: center;"><code>i</code></th>
<th style="text-align: center;"><code>j &lt;= i + (seqlen_k - seqlen_q)</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0 &lt;= 0 + 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1 &lt;= 0 + 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2 &lt;= 0 + 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">3</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">3 &lt;= 0 + 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">4 &lt;= 0 + 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">4 &lt;= 1 + 3 (<code>True</code>)</td>
</tr>
</tbody>
</table>
<p>Where does <code>j &lt;= i + (seqlen_k - seqlen_q)</code> come from?</p>
<p>Let <code>q_i</code> be a query that is <code>seqlen_q - 1 - i</code> steps before the end of the query sequence, and <code>k_j</code> be a key that is <code>seqlen_k - 1 - j</code> steps before the end of the key sequence. More concretely, for the example where <code>seqlen_q = 2</code> and <code>seqlen_k=5</code>:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">q_i</th>
<th style="text-align: center;">Steps before end</th>
<th style="text-align: center;"><code>seqlen_q - 1 - i</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">q_0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2 - 1 - 0</td>
</tr>
<tr class="even">
<td style="text-align: center;">q_1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">2 - 1 - 1</td>
</tr>
</tbody>
</table>
<p><br></p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">k_j</th>
<th style="text-align: center;">Steps before end</th>
<th style="text-align: center;"><code>seqlen_k - 1 - j</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">k_0</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">5 - 1 - 0</td>
</tr>
<tr class="even">
<td style="text-align: center;">k_1</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">5 - 1 - 1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">k_2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">5 - 2 - 1</td>
</tr>
<tr class="even">
<td style="text-align: center;">k_3</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">5 - 3 - 1</td>
</tr>
<tr class="odd">
<td style="text-align: center;">k_4</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">5 - 4 - 1</td>
</tr>
</tbody>
</table>
<p>By picking a “present moment” <code>P</code> (the last token in each sequence) have a unified timeline <code>p</code> such that causality is defined as: <code>p_j &lt;= p_i</code>. <code>k_j</code> has a position on the timeline <code>p_j = P - (seqlen_k - 1 - j)</code> and <code>q_i</code> has a position on the timeline <code>p_i = P - (seqlen_q - 1 - i)</code>. Causality requires that <code>p_j &lt;= p_i</code> on our “unified timeline”. Writing that out:</p>
<p><code>P - (seqlen_k - 1 - j) &lt;= P - (seqlen_q - 1 - i)</code></p>
<p>Cancelling out the <code>P</code>s and distributing the minus sign:</p>
<p><code>-seqlen_k + 1 + j &lt;= -seqlen_q + 1 + i</code></p>
<p>Isolating <code>j</code> on the lefthand side:</p>
<p><code>j &lt;= -seqlen_q + 1 + i + seqlen_k - 1</code></p>
<p>Simplifying + reordering:</p>
<p><code>j &lt;= i + (seqlen_k - seqlen_q)</code></p>
<p>We can think of this <code>(seqlen_k - seqlen_q)</code> to be an “offset” term between the two sequences.</p>
<p>Looking at this concretely for the second causal mask:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">k_0</th>
<th style="text-align: center;">k_1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>q_0</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_1</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>q_2</strong></td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>q_3</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><strong>q_4</strong></td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
</tr>
</tbody>
</table>
<p><br></p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;"><code>j</code></th>
<th style="text-align: center;"><code>i</code></th>
<th style="text-align: center;"><code>j &lt;= i + (seqlen_k - seqlen_q)</code></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">0 &lt;= 0 - 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0 &lt;= 1 - 3 (<code>False</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0 &lt;= 2 - 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">0</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0 &lt;= 3 - 3 (<code>True</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">0</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0 &lt;= 4 - 3 (<code>True</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">0</td>
<td style="text-align: center;">1 &lt;= 0 - 3 (<code>False</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1 &lt;= 1 - 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1 &lt;= 2 - 3 (<code>False</code>)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">1 &lt;= 3 - 3 (<code>False</code>)</td>
</tr>
<tr class="even">
<td style="text-align: center;">1</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1 &lt;= 4 - 3 (<code>True</code>)</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Understanding <code>flash_attn_varlen_func</code> is going to require a sequence (pun intended) of such deep dives. It took me hours to just get through the docstring!! I’m also working on understanding ModernBERT’s sequence packing implementation (to the point of explaining it with visuals) and I expect it to interweave with my Flash Attention study, especially when understanding how ModernBERT prepares and packs sequences and related artifacts in preparation of passing it through the attention mechanism, utilizing <code>flash_attn_varlen_func</code>. It’s an exciting one-two punch for sure! I’m glad I’m working on them together.</p>
<p>I’ll end with listing out again what I’ve learned in this notebook/exercise, with a couple points added about the causal mask:</p>
<ul>
<li>HuggingFace’s <code>model.generate</code> uses KV cache by default (<code>DynamicCache</code>) stored as <code>past_key_values</code>.</li>
<li>For most scenarios, the <code>DynamicCache</code> is updated by concatenating the previous token’s <code>key_cache</code> and <code>value_cache</code> with the <code>key_states</code> and <code>value_states</code> generated for the current new token.</li>
<li>As the next token is generated for a given prompt, <code>query_states</code> has a sequence length of <code>1</code>, whereas <code>key_cache</code> and <code>value_cache</code> tensors’ sequence dimension increases by 1. This is directly relates to the <code>flash_attn_varlen_func</code> causal mask docstring example.</li>
<li><code>model.generate</code> utilized the <code>flash_attn_func</code> interface.</li>
<li>The causal mask is aligned to the bottom-right of the attention matrix (the last tokens of the Q and K sequence are aligned).</li>
<li>Causality, when <img src="https://latex.codecogs.com/png.latex?Q_i"> and <img src="https://latex.codecogs.com/png.latex?K_j"> sequences are of different length, is satisfied by the equation <code>j &lt;= i + (seqlen_k - seqlen_q)</code>.</li>
<li>When there are more query tokens than key tokens, the “offset” (needed to align the last token of each sequence) results in 0s in the mask as there are no key tokens to “look back at”.</li>
<li>When there are more key tokens than query tokens, the “offset” results in 1s as the query tokens can look back at more key tokens.</li>
</ul>
<p>I’m trying to grow my YouTube channel this year so if you enjoyed this blog post, <a href="https://www.youtube.com/@vishal_learner">please subscribe!</a></p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>Flash Attention</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-03-flash_attn_varlen_func-casual-mask/index.html</guid>
  <pubDate>Tue, 03 Jun 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-06-03-flash_attn_varlen_func-casual-mask/1.png" medium="image" type="image/png" height="109" width="144"/>
</item>
<item>
  <title>Initial Experiments with Imagenette</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index.html</link>
  <description><![CDATA[ 



<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> fastai.vision.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> fastai.callback.wandb <span class="im" style="color: #00769E;">import</span> WandbCallback</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> wandb</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post I’m going to share my initial experiments as I try to get on the <a href="https://github.com/fastai/imagenette">imagenette leaderboard</a>.</p>
<blockquote class="blockquote">
<p>Imagenette is a subset of 10 easily classified classes from Imagenet (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute).</p>
</blockquote>
<p>This exercise is a bit of a detour but related to my <a href="https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/">TinyScaleLab project</a> in which I’m trying to analyze the relationship between downstream capabilities and training dynamics for tiny language models (5M-125M) trained on the TinyStories dataset.</p>
<p>I was running some initial rough 1 epoch training runs with my 5M architecture to find the best batch size for training efficiency (memory usage and training speed). I encountered a peculiar result which was counterintuitive to me:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">Metric</th>
<th style="text-align: left;">bs=64</th>
<th style="text-align: left;">256</th>
<th style="text-align: left;">1024</th>
<th style="text-align: left;">2048</th>
<th style="text-align: left;">4096</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Time</td>
<td style="text-align: left;">3hr</td>
<td style="text-align: left;">1hr</td>
<td style="text-align: left;">0.5hr</td>
<td style="text-align: left;">0.5hr</td>
<td style="text-align: left;">OOM</td>
</tr>
<tr class="even">
<td style="text-align: left;">Train loss</td>
<td style="text-align: left;">3.58</td>
<td style="text-align: left;">3.46</td>
<td style="text-align: left;">4.42</td>
<td style="text-align: left;">5.57</td>
<td style="text-align: left;">OOM</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Eval loss</td>
<td style="text-align: left;">3.58</td>
<td style="text-align: left;">3.46</td>
<td style="text-align: left;">4.43</td>
<td style="text-align: left;">5.57</td>
<td style="text-align: left;">OOM</td>
</tr>
</tbody>
</table>
<p>I was expecting that increase the batch size would:</p>
<ol type="1">
<li>speed up training</li>
<li>decrease loss</li>
</ol>
<p>However, increasing batch size from 1024 to 2048 did not speed up training, and increasing batch size from 256 to 2048 did not improve the loss. As always, when I run into something unexpected, I post it on Twitter. I received a number of insightful comments:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
We covered this in some of our earlier courses - lower batch sizes provide more updates, which should give better results for a fixed # epochs.
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1927192030335132090?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>The batch size of 256 was certainly providing more updates in one epoch than a batch size of 1024 or 2048. It’s interesting to note that a batch size of 64, even though providing 4x the number of updates as 256, had a higher loss at the end of the epoch. It’s important to note that I did not measure downstream performance for this experiment.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
TinyStories is a pretty homogeneous dataset, so one doesn't need as large of a batch size to achieve a smooth gradient compared to a more diverse pretraining dataset.<br><br>You'll want to set the batch size balancing speed and performance.
</p>
— Benjamin Warner (<span class="citation" data-cites="benjamin_warner">@benjamin_warner</span>) <a href="https://twitter.com/benjamin_warner/status/1927194448389169190?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This was another interesting point. The benefit of increasing batch size is to get a closer representation to the overall dataset. Since the TinyStories dataset is quite homogenous (all dataset items are children’s stories) a smaller batch size will be sufficiently representative of the full dataset. On the flip side, if we have a dataset like the PETS dataset, and used a small batch size of say 32, we could imagine a scenario where the batch only includes images of a single class. The model, which has been learning about a diverse set of animals to this point will perform poorly and the loss will spike. Larger models, having more parameters, may not recover from this spike like small models can. Furthermore, if the dataset contains mislabeled images and you are unfortunate to get a batch of incorrectly labeled cats, your loss spike will be combined with the model learning incorrect information. These were points discussed in a fastai study group!</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Also, one heuristic that people use is that in most scenarios, you can scale the lr proportionally to the bs.<br><br>Larger bs, better but less frequent updates, can take longer steps.<br><br>Smaller bs, more frequent updates, but need to take smaller steps due to worse direction of updates.
</p>
— Radek Osmulski 🇺🇦 (<span class="citation" data-cites="radekosmulski">@radekosmulski</span>) <a href="https://twitter.com/radekosmulski/status/1927195672056340620?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>In my case, I had used the same learning rate for all batch sizes, and did not utilize the benefit of larger batch sizes taking longer steps (higher learning rate).</p>
<p>Jeremy also encouraged me to do some imagenette speedruns, which is why we’re here!</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
You should maybe try doing some imagenette speed-running – it's a good way to get an intuitive understanding of these issues.
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1927216989837185133?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</section>
<section id="approach-and-results" class="level2">
<h2 class="anchored" data-anchor-id="approach-and-results">Approach and Results</h2>
<p>My data prep and training code can be viewed in the “appendix” below. Before I did this exercise, I ran the code in the <a href="https://docs.fast.ai/tutorial.imagenette.html">fastai “Training Imagenette” tutorial</a> which is where most of the code below comes from. I’ll share my approach and results in this section. I wanted to break this exercise (of trying to get onto the Imagenette leaderboard) into smaller steps, so I focused this notebook on training with a batch size of 64, for three learning rates (1e-4, 1e-3 and 1e-2) for three models: xse_resnext50 (25.6M), xresnet34 (21.3M), xresnet18 (11.2M).</p>
<section id="accuracy-curves" class="level3">
<h3 class="anchored" data-anchor-id="accuracy-curves">Accuracy Curves</h3>
<p>Since I’m most interested in competing on the leaderboard, I’ll focus on observing the accuracy curves of these models, all trained on 5 epochs of the same training/validation split.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Accuracy curves for all 10 training runs"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Accuracy curves for all 10 training runs</figcaption><p></p>
</figure>
</div>
<p>The models/learning rate combination with the highest accuracy is xresnet34/1e-2 and xse_resnext50/1e-2. xresnet18/1e-2 is surprisingly competitive at half the parameter count. There is a clear hierarchy of learning rates, 1e-2 performs the best for all three models, followed by 1e-3 and then 1e-4. I used <code>lr_find</code> for each model and found that xresnet18 was stable for 1e-1 though it performs second-to-last place in accuracy for that model.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Model/Learning Rate</th>
<th style="text-align: center;">Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">xresnet34/1e-2</td>
<td style="text-align: center;">0.7929</td>
</tr>
<tr class="even">
<td style="text-align: center;">xse_resnext50/1e-2</td>
<td style="text-align: center;">0.7926</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet18/1e-2</td>
<td style="text-align: center;">0.7870</td>
</tr>
<tr class="even">
<td style="text-align: center;">xresnet34/1e-3</td>
<td style="text-align: center;">0.7776</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet18/1e-3</td>
<td style="text-align: center;">0.7743</td>
</tr>
<tr class="even">
<td style="text-align: center;">xse_resnext50/1e-3</td>
<td style="text-align: center;">0.7526</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet18/1e-1</td>
<td style="text-align: center;">0.7373</td>
</tr>
<tr class="even">
<td style="text-align: center;">xse_resnext50/1e-4</td>
<td style="text-align: center;">0.6532</td>
</tr>
<tr class="odd">
<td style="text-align: center;">xresnet34/1e-4</td>
<td style="text-align: center;">0.6446</td>
</tr>
<tr class="even">
<td style="text-align: center;">xresnet18/1e-4</td>
<td style="text-align: center;">0.6171</td>
</tr>
</tbody>
</table>
<p>Other notable observations:</p>
<ul>
<li>xse_resnext50/1e-2 starts out with the lowest accuracy, but then quickly catches up and finally beats out all other models/LRs but one.</li>
<li>xresnet18/1e-1 accuracy decreases from epoch 1 to 2, then catches up to finish in 7th place.</li>
<li>xresnet34/1e-2 accuracy increasing at slower rate from epoch 1 to 2 than from epoch 2 to 3, catching up quickly to finish in the top spot.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Notable accuracy curves"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Notable accuracy curves</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>I want to focus on a couple of thoughts Jeremy shared:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Maybe on the way you'll want to create some tables like you're making there, but I rarely find them as interesting as small targeted iterations changing one thing at a time.
</p>
— Jeremy Howard (<span class="citation" data-cites="jeremyphoward">@jeremyphoward</span>) <a href="https://twitter.com/jeremyphoward/status/1927241575765061916?ref_src=twsrc%5Etfw">May 27, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Last year I worked through Jeremy’s <a href="https://vishalbakshi.github.io/blog/#category=paddy%20doctor">Kaggle Paddy Docter competition live coding series</a> and learned a ton about just that—small targeted iterations changing one thing at a time.</p>
<p>I’m not quite sure what my plan will be for this Imagenette leaderboard exercise, but I since I started this exploration with the intent to build intuition about batch size/learning rate and downstream performance, it makes sense to pick my best 2-3 models and vary the batch size and learning rate next.</p>
<p>I also am keen on working with Benjamin Warner’s <a href="https://fastxtend.benjaminwarner.dev/callback.progresize.html">fastxtend</a> (which I used last year in the <a href="https://www.kaggle.com/code/vishalbakshi/birdclef-2024-recap-0-61-final-lb-score">BirdCLEF24 Kaggle competition</a> to finish in the top 34%) and <a href="https://optimi.benjaminwarner.dev/">optimi</a> libraries. I’m particularly keen on trying out the different data augmentation techniques provided in fastxtend when I train for longer than 5 epochs.</p>
<p>I’m trying to grow my YouTube channel, so if you like my content, <a href="https://www.youtube.com/@vishal_learner">please subscribe</a>!</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<section id="data-prep" class="level3">
<h3 class="anchored" data-anchor-id="data-prep">Data Prep</h3>
<div class="cell" data-outputid="4a1c7bd1-fb16-4c4f-8308-939fe9e2b7c4" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">path <span class="op" style="color: #5E5E5E;">=</span> untar_data(URLs.IMAGENETTE_160)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="99008512" class="" max="99003388" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.01% [99008512/99003388 00:03&lt;00:00]
    </div>
    
</div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">lbl_dict <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(</span>
<span id="cb3-2">    n01440764<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'tench'</span>,</span>
<span id="cb3-3">    n02102040<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'English springer'</span>,</span>
<span id="cb3-4">    n02979186<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cassette player'</span>,</span>
<span id="cb3-5">    n03000684<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'chain saw'</span>,</span>
<span id="cb3-6">    n03028079<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'church'</span>,</span>
<span id="cb3-7">    n03394916<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'French horn'</span>,</span>
<span id="cb3-8">    n03417042<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'garbage truck'</span>,</span>
<span id="cb3-9">    n03425413<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'gas pump'</span>,</span>
<span id="cb3-10">    n03445777<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'golf ball'</span>,</span>
<span id="cb3-11">    n03888257<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'parachute'</span></span>
<span id="cb3-12">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="73776257-bc3e-4c33-d6cc-ca691b73662c" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">imagenette <span class="op" style="color: #5E5E5E;">=</span> DataBlock(blocks <span class="op" style="color: #5E5E5E;">=</span> (ImageBlock, CategoryBlock),</span>
<span id="cb4-2">                       get_items <span class="op" style="color: #5E5E5E;">=</span> get_image_files,</span>
<span id="cb4-3">                       get_y <span class="op" style="color: #5E5E5E;">=</span> Pipeline([parent_label, lbl_dict.<span class="fu" style="color: #4758AB;">__getitem__</span>]),</span>
<span id="cb4-4">                       splitter <span class="op" style="color: #5E5E5E;">=</span> GrandparentSplitter(valid_name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'val'</span>),</span>
<span id="cb4-5">                       item_tfms <span class="op" style="color: #5E5E5E;">=</span> RandomResizedCrop(<span class="dv" style="color: #AD0000;">128</span>, min_scale<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.35</span>),</span>
<span id="cb4-6">                       batch_tfms <span class="op" style="color: #5E5E5E;">=</span> Normalize.from_stats(<span class="op" style="color: #5E5E5E;">*</span>imagenet_stats))</span>
<span id="cb4-7"></span>
<span id="cb4-8">dls <span class="op" style="color: #5E5E5E;">=</span> imagenette.dataloaders(path, bs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>)</span>
<span id="cb4-9">dls.show_batch()</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-5-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="training-code" class="level3">
<h3 class="anchored" data-anchor-id="training-code">Training Code</h3>
<p>I chose to run everything on a Colab Pro A100 GPU to maximize speed.</p>
<section id="xse_resnext50" class="level4">
<h4 class="anchored" data-anchor-id="xse_resnext50">xse_resnext50</h4>
<div class="cell" data-outputid="8338b75d-2a6c-41ec-c54b-dae12a88bc63" data-execution_count="7">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb5-2">learn.lr_find()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>SuggestedLRs(valley=0.0004786300996784121)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-6-output-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index_files/figure-html/cell-6-output-4.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-outputid="542d3515-ed60-4e15-dfd7-73fab5fe583d" data-execution_count="14">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">wandb.login()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">wandb.init(</span>
<span id="cb9-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb9-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xse_resnext50-bs-64-lr-1e-4"</span>,</span>
<span id="cb9-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="f05260cd-91b1-42a4-8b82-a0465f190a53" data-execution_count="16">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb10-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.437292</td>
      <td>1.562259</td>
      <td>0.498599</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.898073</td>
      <td>1.330338</td>
      <td>0.581401</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.625788</td>
      <td>1.184957</td>
      <td>0.630828</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.491183</td>
      <td>1.138762</td>
      <td>0.650446</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.425214</td>
      <td>1.119943</td>
      <td>0.653248</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">wandb.finish()</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">wandb.init(</span>
<span id="cb12-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb12-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xse_resnext50-bs-64-lr-1e-3"</span>,</span>
<span id="cb12-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="0356a936-1d9c-40ca-9d7e-b645c0c3a3c7" data-execution_count="19">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb13-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.115490</td>
      <td>1.610692</td>
      <td>0.511592</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.563322</td>
      <td>1.359540</td>
      <td>0.592866</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.205948</td>
      <td>1.041064</td>
      <td>0.673631</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.988717</td>
      <td>0.896793</td>
      <td>0.712611</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.865071</td>
      <td>0.776657</td>
      <td>0.752611</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">wandb.finish()</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">wandb.init(</span>
<span id="cb15-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb15-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xse_resnext50-bs-64-lr-1e-2"</span>,</span>
<span id="cb15-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="b97a464f-d64e-4797-8814-2034c9d3013d" data-execution_count="23">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">learn <span class="op" style="color: #5E5E5E;">=</span> vision_learner(dls, xse_resnext50, metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, pretrained<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb16-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.025805</td>
      <td>4.565277</td>
      <td>0.225478</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.586654</td>
      <td>1.567472</td>
      <td>0.527389</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.162438</td>
      <td>0.994889</td>
      <td>0.680255</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.868640</td>
      <td>0.672154</td>
      <td>0.780892</td>
      <td>00:15</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.703673</td>
      <td>0.635068</td>
      <td>0.792611</td>
      <td>00:15</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">wandb.finish()</span></code></pre></div>
</div>
</section>
<section id="xresnet34" class="level4">
<h4 class="anchored" data-anchor-id="xresnet34">xresnet34</h4>
<div class="cell" data-outputid="1ca7b389-6205-4651-af2b-35c00be9e633" data-execution_count="27">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>), metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy)</span>
<span id="cb18-2">learn.lr_find()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>SuggestedLRs(valley=0.0005754399462603033)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-17-output-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index_files/figure-html/cell-17-output-4.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-outputid="db64c191-eac3-4e90-8146-0ea19c8691a1" data-execution_count="28">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">learn.loss_func</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>FlattenedLoss of CrossEntropyLoss()</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">wandb.init(</span>
<span id="cb22-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb22-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xresnet34-bs-64-lr-1e-4"</span>,</span>
<span id="cb22-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="5ff0c3d6-f0e0-4501-c244-eb567e579c59" data-execution_count="35">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>), metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb23-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.054720</td>
      <td>1.864616</td>
      <td>0.371975</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.605212</td>
      <td>1.489624</td>
      <td>0.525350</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.307533</td>
      <td>1.235453</td>
      <td>0.619618</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.180410</td>
      <td>1.153767</td>
      <td>0.642038</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.124177</td>
      <td>1.139668</td>
      <td>0.644586</td>
      <td>00:09</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">wandb.finish()</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">wandb.init(</span>
<span id="cb25-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb25-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xresnet34-bs-64-lr-1e-3"</span>,</span>
<span id="cb25-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="307e87f9-20f2-419b-beda-9f1f32a62a2c" data-execution_count="39">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>), metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb26-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.607826</td>
      <td>1.416133</td>
      <td>0.538344</td>
      <td>00:10</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.204550</td>
      <td>1.263326</td>
      <td>0.578853</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.946661</td>
      <td>0.917620</td>
      <td>0.710828</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.784756</td>
      <td>0.758046</td>
      <td>0.755414</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.683072</td>
      <td>0.704371</td>
      <td>0.777580</td>
      <td>00:09</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">wandb.finish()</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">wandb.init(</span>
<span id="cb28-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb28-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xresnet34-bs-64-lr-1e-2"</span>,</span>
<span id="cb28-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="435b8593-bec7-427e-d136-a51a327efc95" data-execution_count="43">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(dls, xresnet34(n_out<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>), metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb29-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.571024</td>
      <td>2.439970</td>
      <td>0.335541</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.255883</td>
      <td>2.097694</td>
      <td>0.395414</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.018229</td>
      <td>0.989576</td>
      <td>0.681529</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.785577</td>
      <td>0.728265</td>
      <td>0.762293</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.623264</td>
      <td>0.640818</td>
      <td>0.792866</td>
      <td>00:09</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">wandb.finish()</span></code></pre></div>
</div>
</section>
<section id="xresnet18" class="level4">
<h4 class="anchored" data-anchor-id="xresnet18">xresnet18</h4>
<div class="cell" data-outputid="3bb76188-48c5-47dd-ad6d-3d66a04be44f" data-execution_count="46">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy)</span>
<span id="cb31-2">learn.lr_find()</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>SuggestedLRs(valley=0.0020892962347716093)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-28-output-4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index_files/figure-html/cell-28-output-4.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">wandb.init(</span>
<span id="cb33-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb33-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xresnet18-bs-64-lr-1e-4"</span>,</span>
<span id="cb33-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="c6dbf534-bb10-48ef-cb77-0eb7b8597ac1" data-execution_count="48">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb34-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>5.608559</td>
      <td>4.292247</td>
      <td>0.301147</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>1</td>
      <td>2.270526</td>
      <td>1.728192</td>
      <td>0.505478</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.517185</td>
      <td>1.401804</td>
      <td>0.579108</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.327132</td>
      <td>1.287121</td>
      <td>0.610446</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>4</td>
      <td>1.274527</td>
      <td>1.265958</td>
      <td>0.617070</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">wandb.finish()</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">wandb.init(</span>
<span id="cb36-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb36-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xresnet18-bs-64-lr-1e-3"</span>,</span>
<span id="cb36-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="170bf98b-8634-4d14-88fb-e1422e043217" data-execution_count="52">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb37-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>2.134495</td>
      <td>1.742504</td>
      <td>0.445860</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.249879</td>
      <td>1.266531</td>
      <td>0.584204</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.986120</td>
      <td>1.082811</td>
      <td>0.648153</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.804976</td>
      <td>0.767623</td>
      <td>0.758471</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.708721</td>
      <td>0.734305</td>
      <td>0.774267</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">wandb.finish()</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">wandb.init(</span>
<span id="cb39-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb39-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xresnet18-bs-64-lr-1e-2"</span>,</span>
<span id="cb39-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="43fb4098-6228-4d0e-f708-d395b7324de1" data-execution_count="56">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb40-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.665481</td>
      <td>2.706135</td>
      <td>0.358726</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.278437</td>
      <td>1.516189</td>
      <td>0.505987</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.017887</td>
      <td>1.038873</td>
      <td>0.663440</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.801989</td>
      <td>0.718528</td>
      <td>0.761529</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.638737</td>
      <td>0.650084</td>
      <td>0.787006</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">wandb.finish()</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">wandb.init(</span>
<span id="cb42-2">    project<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tinyscale-lab"</span>,</span>
<span id="cb42-3">    name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"imagenette-xresnet18-bs-64-lr-1e-1"</span>,</span>
<span id="cb42-4">)</span></code></pre></div>
</div>
<div class="cell" data-outputid="f9e04227-875a-40b7-8fe7-f4790ac3bc32" data-execution_count="61">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">learn <span class="op" style="color: #5E5E5E;">=</span> Learner(dls, xresnet18(), metrics<span class="op" style="color: #5E5E5E;">=</span>accuracy, cbs<span class="op" style="color: #5E5E5E;">=</span>WandbCallback())</span>
<span id="cb43-2">learn.fit_one_cycle(<span class="dv" style="color: #AD0000;">5</span>, <span class="fl" style="color: #AD0000;">1e-1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1.755140</td>
      <td>2.272295</td>
      <td>0.325860</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1.501531</td>
      <td>3.738475</td>
      <td>0.322293</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1.238407</td>
      <td>1.375671</td>
      <td>0.547516</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1.036412</td>
      <td>0.896265</td>
      <td>0.707516</td>
      <td>00:07</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.850425</td>
      <td>0.815597</td>
      <td>0.737325</td>
      <td>00:07</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">wandb.finish()</span></code></pre></div>
</div>


</section>
</section>
</section>

 ]]></description>
  <category>python</category>
  <category>fastai</category>
  <category>deep learning</category>
  <category>tinyscalelab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/index.html</guid>
  <pubDate>Sun, 01 Jun 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-06-01-imagenette/1.png" medium="image" type="image/png" height="73" width="144"/>
</item>
<item>
  <title>Understanding the Mean Shift Clustering Algorithm (and PyTorch Broadcasting)</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index.html</link>
  <description><![CDATA[ 



<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> math, matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt, operator, torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> functools <span class="im" style="color: #00769E;">import</span> partial</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> torch.distributions.multivariate_normal <span class="im" style="color: #00769E;">import</span> MultivariateNormal</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> tensor</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb2-2">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post I’ll walk through the Mean Shift Clustering algorithm as introduced <a href="https://github.com/fastai/course22p2/blob/master/nbs/02_meanshift.ipynb">in Lesson 12 of the fastai course (Part 2)</a>.</p>
<p>The algorithm:</p>
<blockquote class="blockquote">
<ul>
<li>For each data point <code>x</code> in the sample <code>X</code>, find the distance between that point <code>x</code> and every other point in <code>X</code></li>
<li>Create weights for each point in <code>X</code> by using the Gaussian kernel of that point’s distance to <code>x</code></li>
<li>This weighting approach penalizes points further away from <code>x</code></li>
<li>The rate at which the weights fall to zero is determined by the bandwidth, which is the standard deviation of the Gaussian</li>
<li>Update <code>x</code> as the weighted average of all other points in <code>X</code>, weighted based on the previous step</li>
</ul>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" title="Conceptual visual showing the mean shift clustering algorithm weighting by distance. The red point is x." data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Conceptual visual showing the mean shift clustering algorithm weighting by distance. The red point is <code>x</code>.</figcaption><p></p>
</figure>
</div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/kfl-cUz9iWw?si=nL8PUaUBmqQcYJMk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="generating-clearly-clustered-data" class="level2">
<h2 class="anchored" data-anchor-id="generating-clearly-clustered-data">Generating Clearly Clustered Data</h2>
<p>An important point: we start by creating fake data such that it is knowingly clustered around a set of centroids we can then compare to the final clustering result.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">n_clusters<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span></span>
<span id="cb3-2">n_samples <span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">250</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">centroids <span class="op" style="color: #5E5E5E;">=</span> torch.rand(n_clusters, <span class="dv" style="color: #AD0000;">2</span>)<span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">70</span><span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">35</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="f832bd33-2d31-4058-a7e6-9139a6b3acef" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">centroids.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>torch.Size([6, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="98fe6cdb-34d3-4a22-bb3a-f6f5e2b5019e" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">centroids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[ 26.759,  29.050],
        [ -8.200,  32.151],
        [ -7.669,   7.063],
        [-17.040,  20.555],
        [ 30.854, -25.677],
        [ 30.422,   6.551]])</code></pre>
</div>
</div>
<p>We’ll generate data around these 6 centroids using PyTorch’s <code>MultivariateNormal</code> which:</p>
<blockquote class="blockquote">
<p>Creates a multivariate normal (also called Gaussian) distribution parameterized by a mean vector and a covariance matrix.</p>
</blockquote>
<p>The covariance matrix in our case is a diagonal matrix with 5s on the diagonal.</p>
<p>We generate 250 samples for each mean vector (centroid).</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;">def</span> sample(m): <span class="cf" style="color: #003B4F;">return</span> MultivariateNormal(m, torch.diag(tensor([<span class="fl" style="color: #AD0000;">5.</span>,<span class="fl" style="color: #AD0000;">5.</span>]))).sample((n_samples,))</span></code></pre></div>
</div>
<div class="cell" data-outputid="5684ae06-811e-4a0e-ec3e-f5e9830a41ed" data-execution_count="8">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">torch.diag(tensor([<span class="fl" style="color: #AD0000;">5.</span>,<span class="fl" style="color: #AD0000;">5.</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor([[5., 0.],
        [0., 5.]])</code></pre>
</div>
</div>
<p>From Gemini this covariance matrix shows:</p>
<blockquote class="blockquote">
<ul>
<li><strong>No Correlation</strong>: The two variables are uncorrelated (covariance is 0.0). For a <code>MultivariateNormal</code> distribution, this implies they are independent.</li>
<li><strong>Equal Variance</strong>: Both variables have the same variance of 5.0.</li>
<li><strong>Shape</strong>: If used in a 2D MultivariateNormal distribution, this will produce a circular cloud of data points, equally spread along both the X and Y axes.</li>
</ul>
</blockquote>
<div class="cell" data-outputid="93047335-d41d-4def-a752-5e331b1e26b4" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">coords <span class="op" style="color: #5E5E5E;">=</span> MultivariateNormal(centroids[<span class="dv" style="color: #AD0000;">0</span>], torch.diag(tensor([<span class="fl" style="color: #AD0000;">5.</span>,<span class="fl" style="color: #AD0000;">5.</span>]))).sample((n_samples,))</span>
<span id="cb12-2">coords.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>torch.Size([250, 2])</code></pre>
</div>
</div>
<p>We see how the <code>MultivariateNormal</code> distribution samples are spread out in a circular shape around the mean, with the density of samples decreasing as you move further away from the centroid.</p>
<div class="cell" data-outputid="440bb3e9-4b5c-4e69-9934-4ca1a298a0be" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">plt.scatter(coords[:,<span class="dv" style="color: #AD0000;">0</span>], coords[:,<span class="dv" style="color: #AD0000;">1</span>], alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.7</span>, s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">30</span>)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb14-2">plt.scatter(centroids[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>], centroids[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">1</span>], c <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'red'</span>, s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span>)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb14-3">ax <span class="op" style="color: #5E5E5E;">=</span> plt.gca() <span class="co" style="color: #5E5E5E;"># Get current axes</span></span>
<span id="cb14-4">ax.set_aspect(<span class="st" style="color: #20794D;">'equal'</span>, adjustable<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'box'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-11-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We sample from the <code>MultivariateNormal</code> distribution for all six of our centroids and concatenate the result.</p>
<div class="cell" data-outputid="1889ba4c-48d1-46cb-dfe4-7674b1cc04a5" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">slices <span class="op" style="color: #5E5E5E;">=</span> [sample(c) <span class="cf" style="color: #003B4F;">for</span> c <span class="kw" style="color: #003B4F;">in</span> centroids]</span>
<span id="cb15-2">data <span class="op" style="color: #5E5E5E;">=</span> torch.cat(slices)</span>
<span id="cb15-3">data.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="kw" style="color: #003B4F;">def</span> plot_data(centroids, data, n_samples, ax<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb17-2">    <span class="cf" style="color: #003B4F;">if</span> ax <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>: _,ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots()</span>
<span id="cb17-3">    ax.set_aspect(<span class="st" style="color: #20794D;">'equal'</span>, adjustable<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'box'</span>)</span>
<span id="cb17-4">    <span class="cf" style="color: #003B4F;">for</span> i, centroid <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(centroids):</span>
<span id="cb17-5">        samples <span class="op" style="color: #5E5E5E;">=</span> data[i<span class="op" style="color: #5E5E5E;">*</span>n_samples:(i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">*</span>n_samples]</span>
<span id="cb17-6">        ax.scatter(samples[:,<span class="dv" style="color: #AD0000;">0</span>], samples[:,<span class="dv" style="color: #AD0000;">1</span>], s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb17-7">        ax.plot(<span class="op" style="color: #5E5E5E;">*</span>centroid, markersize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>, marker<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"x"</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'k'</span>, mew<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="8b2d7253-df04-4a27-8d32-c8b6ff94647d" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">plot_data(centroids, data, n_samples)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-14-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="generating-sample-weights" class="level2">
<h2 class="anchored" data-anchor-id="generating-sample-weights">Generating Sample Weights</h2>
<p>With our data generated, we’ll now prepare for the third step in the algorithm: <em>create weights</em>.</p>
<blockquote class="blockquote">
<p>Create weights for each point in X by using the Gaussian kernel of that point’s distance to x</p>
</blockquote>
<p>We’ll start by defining a function which takes some distance <code>d</code> and some bandwidth <code>bw</code> and returns the gaussian normal output given these two inputs. This output will be our <em>weights</em>:</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;">def</span> gaussian(d, bw): <span class="cf" style="color: #003B4F;">return</span> torch.exp(<span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.5</span><span class="op" style="color: #5E5E5E;">*</span>((d<span class="op" style="color: #5E5E5E;">/</span>bw))<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>) <span class="op" style="color: #5E5E5E;">/</span> (bw<span class="op" style="color: #5E5E5E;">*</span>math.sqrt(<span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>math.pi))</span></code></pre></div>
</div>
<p>(Wikipedia) the probability density function of the normal distribution is given by:</p>
<p><img src="https://latex.codecogs.com/png.latex?f(x)=%7B%5Cfrac%20%7B1%7D%7B%5Csqrt%20%7B2%5Cpi%20%5Csigma%20%5E%7B2%7D%7D%7D%7De%5E%7B-%7B%5Cfrac%20%7B(x-%5Cmu%20)%5E%7B2%7D%7D%7B2%5Csigma%20%5E%7B2%7D%7D%7D%7D"></p>
<p>In our case, <code>d</code> (the distance from a point in X to another point in X) is equivalent in this function to <img src="https://latex.codecogs.com/png.latex?x-%5Cmu">, and bandwidth <code>bw</code> is the standard deviation <img src="https://latex.codecogs.com/png.latex?%5Csigma">.</p>
<p>As bandwidth increases, the gaussian distribution flattens out (i.e.&nbsp;weights decay slower as distance increases).</p>
<div class="cell" data-outputid="e1629736-ae5f-4857-afff-f8340d8019b6" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">x <span class="op" style="color: #5E5E5E;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">10</span>,<span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb20-2">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1.0</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'bw = 1.0'</span>)</span>
<span id="cb20-3">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">2.5</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'bw = 2.5'</span>)</span>
<span id="cb20-4">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">5.0</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'bw = 5.0'</span>)</span>
<span id="cb20-5">plt.plot(x, gaussian(x, bw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10.0</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'bw = 10.0'</span>)</span>
<span id="cb20-6">plt.legend()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-16-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>We can also try to use a simpler linear function for our weights.</p>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;">def</span> tri(d, i): <span class="cf" style="color: #003B4F;">return</span> (<span class="op" style="color: #5E5E5E;">-</span>d<span class="op" style="color: #5E5E5E;">+</span>i).clamp_min(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">/</span>i</span></code></pre></div>
</div>
<p>Mathematically, this calculates <code>max(0, (i - d) / i)</code> which is equivalent to <code>max(0, 1 - d / i)</code></p>
<p><code>clamp_min</code> ensures that the value of <code>-d+i</code> does not go below <code>0</code>. <code>i</code> becomes the d-intercept.</p>
<p>As <code>i</code> increases, the slope decreases, and weights decay slower as distance increases.</p>
<div class="cell" data-outputid="be09317b-d3b8-4bb4-936b-f9f9f8193618" data-execution_count="18">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">x <span class="op" style="color: #5E5E5E;">=</span> torch.linspace(<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">10</span>,<span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb22-2">plt.plot(x, tri(x,i<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'i = 3'</span>)</span>
<span id="cb22-3">plt.plot(x, tri(x,i<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'i = 8'</span>)</span>
<span id="cb22-4">plt.plot(x, tri(x,i<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'i = 12'</span>)</span>
<span id="cb22-5">plt.legend()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-18-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="implementing-the-full-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="implementing-the-full-algorithm">Implementing the Full Algorithm</h2>
<blockquote class="blockquote">
<ul>
<li>For each data point x in the sample X, find the distance between that point x and every other point in X (<code>d = f(x-X)</code>)</li>
<li>Create weights for each point in X by using the Gaussian kernel of that point’s distance to x (<code>weights = gaussian(d)</code>)</li>
<li>Update x as the weighted average of all other points in X, weighted based on the previous step (<code>x = weighted_avg(weights, X)</code>)</li>
</ul>
</blockquote>
<p>Since we are going to update the data after each step of the algorithm, we clone the data to start. As a reminder, these 1500 coordinates come from 250 <code>MultivariateNormal</code> samples given 6 centroids as the mean.</p>
<div class="cell" data-outputid="e19a0afd-3b1f-4189-ea40-f73820d8e75c" data-execution_count="19">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb23-2">x <span class="op" style="color: #5E5E5E;">=</span> X[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb23-3">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([29.764, 26.161])</code></pre>
</div>
</div>
<div class="cell" data-outputid="c9005ded-deaa-4406-b70c-119c6584c3f1" data-execution_count="20">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">X.shape, x.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>(torch.Size([1500, 2]), torch.Size([2]))</code></pre>
</div>
</div>
<p>We now calculate <em>the distance between that point x and every other point in X</em>. Since <code>x</code> and <code>X</code> share a dimension <code>2</code>, we can just subtract and PyTorch will use broadcasting.</p>
<div class="cell" data-outputid="b58458b1-4d24-4b3d-87c3-07828202e61b" data-execution_count="21">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">(x<span class="op" style="color: #5E5E5E;">-</span>X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="568b564f-4973-4b77-b312-4b94f6a6fa1b" data-execution_count="22">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">(x<span class="op" style="color: #5E5E5E;">-</span>X)[<span class="dv" style="color: #AD0000;">0</span>] <span class="co" style="color: #5E5E5E;"># subtracting the first point from itself</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([0., 0.])</code></pre>
</div>
</div>
<div class="cell" data-outputid="7f96405a-0d6b-4af5-ab8d-1bf57fc26b99" data-execution_count="23">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([29.764, 26.161])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e35d50a5-a69d-46f0-99b2-570902ac3787" data-execution_count="24">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1">X[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([[29.764, 26.161],
        [28.472, 30.493],
        [27.549, 23.130],
        [23.500, 26.879],
        [27.327, 28.650]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="8afce871-6987-4f4d-a85b-5eb08f5d18fe" data-execution_count="25">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">(x<span class="op" style="color: #5E5E5E;">-</span>X)[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([[ 0.000,  0.000],
        [ 1.292, -4.333],
        [ 2.215,  3.030],
        [ 6.264, -0.718],
        [ 2.437, -2.489]])</code></pre>
</div>
</div>
<p>We’ll use Euclidean distance, which is the square root of the sum (across the columns, or rather across coordinates) of the difference in coordinates squared.</p>
<div class="cell" data-outputid="16661ce5-493e-4029-9f13-ac9120032ec2" data-execution_count="26">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="092208c5-a396-4f01-cb0e-c6be84342589" data-execution_count="27">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([[ 0.000,  0.000],
        [ 1.668, 18.772],
        [ 4.906,  9.184],
        [39.239,  0.515],
        [ 5.939,  6.196]])</code></pre>
</div>
</div>
<p>Summing across the columns to get <img src="https://latex.codecogs.com/png.latex?x%5E2+y%5E2">.</p>
<div class="cell" data-outputid="0919cf3c-5bb0-4e84-9bc4-53c71e956312" data-execution_count="29">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>torch.Size([1500])</code></pre>
</div>
</div>
<div class="cell" data-outputid="9e39b39a-6f71-4de2-d839-c6d380711aee" data-execution_count="30">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>)[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor([ 0.000, 20.440, 14.089, 39.754, 12.134])</code></pre>
</div>
</div>
<div class="cell" data-outputid="442c76ad-4328-4762-a9a0-32c30a8bd601" data-execution_count="31">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">dist <span class="op" style="color: #5E5E5E;">=</span> ((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>).sqrt()</span>
<span id="cb45-2">dist.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>torch.Size([1500])</code></pre>
</div>
</div>
<div class="cell" data-outputid="433c5588-1779-4bcf-e4b5-21017d014186" data-execution_count="32">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">dist[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([0.000, 4.521, 3.754, 6.305, 3.483])</code></pre>
</div>
</div>
<p>Since we are performing elementwise multiplication following by a summation, we can use Einstein Summation:</p>
<div class="cell" data-outputid="554d97b7-31a8-45a3-b1d2-4ee4a8d2fb3f" data-execution_count="33">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">torch.einsum(<span class="st" style="color: #20794D;">'ij,ij-&gt;i'</span>, x<span class="op" style="color: #5E5E5E;">-</span>X, x<span class="op" style="color: #5E5E5E;">-</span>X).sqrt()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor([ 0.000,  4.521,  3.754,  ..., 21.305, 21.850, 21.958])</code></pre>
</div>
</div>
<p>We can also use matrix multiplication, though IIUC, you have to pluck out the values on the resulting matrix’s diagonal to get the elementwise product between <code>x-X</code> and itself.</p>
<div class="cell" data-outputid="ce689bc7-0002-472e-ab83-2f3e471a9dac" data-execution_count="34">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">(x<span class="op" style="color: #5E5E5E;">-</span>X).shape, (x<span class="op" style="color: #5E5E5E;">-</span>X).T.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>(torch.Size([1500, 2]), torch.Size([2, 1500]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="424e1e07-8126-4325-b353-92c59a2375ca" data-execution_count="35">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">res <span class="op" style="color: #5E5E5E;">=</span> (x<span class="op" style="color: #5E5E5E;">-</span>X) <span class="op" style="color: #5E5E5E;">@</span> (x<span class="op" style="color: #5E5E5E;">-</span>X).T</span>
<span id="cb53-2">res.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>torch.Size([1500, 1500])</code></pre>
</div>
</div>
<div class="cell" data-outputid="3565fc9c-f460-4158-8f7e-8f0926b1cd85" data-execution_count="36">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">torch.diag(res)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor([  0.000,  20.440,  14.089,  ..., 453.898, 477.408, 482.169])</code></pre>
</div>
</div>
<div class="cell" data-outputid="d964c841-d00e-4173-9a53-acdba5e6b33a" data-execution_count="37">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">torch.diag(res).sqrt()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([ 0.000,  4.521,  3.754,  ..., 21.305, 21.850, 21.958])</code></pre>
</div>
</div>
<p>We now <em>create weights for each point in X by using the Gaussian kernel of that point’s distance to x</em>.</p>
<div class="cell" data-outputid="75f33898-b162-4628-8098-56bc99e441b1" data-execution_count="38">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist, <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb59-2">weight</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([    0.160,     0.031,     0.052,  ...,     0.000,     0.000,     0.000])</code></pre>
</div>
</div>
<p>We have 1500 weights, one for each distance between our current point <code>x</code> and all of the points in <code>X</code>.</p>
<div class="cell" data-outputid="5b48ca56-ce3b-426b-dc41-a73ce4596e99" data-execution_count="39">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1">weight.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>torch.Size([1500])</code></pre>
</div>
</div>
<p>We can now move on to the last step in the algorithm: <em>update x as the weighted average of all other points in X, weighted based on the previous step</em>.</p>
<p>The weighted average is the elementwise product of the <code>weights</code> and <code>X</code>, summed down the rows (two get 2 coordinates) and then divided by the sum of the weights.</p>
<p>Starting from the last dimension, <code>weight</code> and <code>X</code> do not have compatible dimensions (1500 is not 2 or 1), so we have to add a unit axis to <code>weight</code> to allow for broadcasting.</p>
<div class="cell" data-outputid="3c055193-07d4-41b2-9c45-83a7b9c18ddc" data-execution_count="42">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e0b2b54d-21ea-4cee-a98f-0f6f9ba44500" data-execution_count="43">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1">weight<span class="op" style="color: #5E5E5E;">*</span>X</span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: The size of tensor a (1500) must match the size of tensor b (2) at non-singleton dimension 1</code></pre>
</div>
</div>
<div class="cell" data-outputid="799bd54d-0612-4a9e-8f4b-adeb29264253" data-execution_count="44">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1">weight[:,<span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>torch.Size([1500, 1])</code></pre>
</div>
</div>
<div class="cell" data-outputid="81c78206-bb4d-4b3d-b05c-77e844403318" data-execution_count="46">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1">weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>tensor([[    4.750,     4.175],
        [    0.886,     0.948],
        [    1.424,     1.196],
        ...,
        [    0.000,     0.000],
        [    0.000,     0.000],
        [    0.000,     0.000]])</code></pre>
</div>
</div>
<p>We then sum down the rows to get two coordinates:</p>
<div class="cell" data-outputid="94a51182-983c-4f79-c54b-59577b97c8b5" data-execution_count="48">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1">(weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([296.880, 291.612])</code></pre>
</div>
</div>
<p>This is the same as applying the weights to each column separately:</p>
<div class="cell" data-outputid="cedc0ce9-89c7-4b77-98dc-be9e885f5cb2" data-execution_count="49">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1">(weight <span class="op" style="color: #5E5E5E;">*</span> X[:,<span class="dv" style="color: #AD0000;">0</span>]).<span class="bu" style="color: null;">sum</span>(), (weight <span class="op" style="color: #5E5E5E;">*</span> X[:,<span class="dv" style="color: #AD0000;">1</span>]).<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>(tensor(296.880), tensor(291.612))</code></pre>
</div>
</div>
<p>We then divide by the sum of the weights to get our final, updated <code>x</code>:</p>
<div class="cell" data-outputid="26fcab42-b6a3-448a-b5b8-cf8c85c2f3a6" data-execution_count="50">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1">(weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">/</span>weight.<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>tensor([28.118, 27.619])</code></pre>
</div>
</div>
<p>Wrapping this up into a function for each <code>x</code> in <code>X</code> we calculate the distance between <code>x</code> and all points in <code>X</code>, calculate the weights for those distances and replace <code>x</code> with the weighted average of those weights and all the points.</p>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><span class="kw" style="color: #003B4F;">def</span> one_update(X):</span>
<span id="cb77-2">    <span class="cf" style="color: #003B4F;">for</span> i, x <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(X):</span>
<span id="cb77-3">        dist <span class="op" style="color: #5E5E5E;">=</span> torch.sqrt(((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb77-4">        weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist, <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb77-5">        X[i] <span class="op" style="color: #5E5E5E;">=</span> (weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">/</span>weight.<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
</div>
<div class="cell" data-outputid="72b4ced3-11b0-4477-e0de-28e7ec8b3e34" data-execution_count="52">
<div class="sourceCode cell-code" id="cb78" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1">X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb78-2">x <span class="op" style="color: #5E5E5E;">=</span> X[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb78-3">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>tensor([29.764, 26.161])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1">one_update(X)</span></code></pre></div>
</div>
<div class="cell" data-outputid="4dfc8da8-06c7-4400-a1da-5415bf4bbcaf" data-execution_count="55">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">X[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>tensor([28.118, 27.619])</code></pre>
</div>
</div>
<p>We can now wrap up into a <code>meanshift</code> function where it performs <code>n</code> such updates.</p>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><span class="kw" style="color: #003B4F;">def</span> meanshift(data, n<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb83-2">    X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb83-3">    <span class="cf" style="color: #003B4F;">for</span> it <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(n): one_update(X)</span>
<span id="cb83-4">    <span class="cf" style="color: #003B4F;">return</span> X</span></code></pre></div>
</div>
<div class="cell" data-outputid="120554f2-356c-4445-c260-6590aa44c457" data-execution_count="68">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><span class="op" style="color: #5E5E5E;">%</span>time X<span class="op" style="color: #5E5E5E;">=</span>meanshift(data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.39 s, sys: 3.12 ms, total: 1.4 s
Wall time: 1.42 s</code></pre>
</div>
</div>
<p>We can now see that in 5 iterations, the weight updates have resulted in the points to converge at the original centroids!</p>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><span class="kw" style="color: #003B4F;">def</span> plot_data(centroids, data, n_samples, ax<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>):</span>
<span id="cb86-2">    <span class="cf" style="color: #003B4F;">if</span> ax <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>: _,ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots()</span>
<span id="cb86-3">    ax.set_aspect(<span class="st" style="color: #20794D;">'equal'</span>, adjustable<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'box'</span>) <span class="co" style="color: #5E5E5E;"># Add this line</span></span>
<span id="cb86-4">    <span class="cf" style="color: #003B4F;">for</span> i, centroid <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(centroids):</span>
<span id="cb86-5">        samples <span class="op" style="color: #5E5E5E;">=</span> data[i<span class="op" style="color: #5E5E5E;">*</span>n_samples:(i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">*</span>n_samples]</span>
<span id="cb86-6">        ax.plot(<span class="op" style="color: #5E5E5E;">*</span>centroid, markersize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>, marker<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"x"</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'k'</span>, mew<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">-</span> alpha<span class="op" style="color: #5E5E5E;">*</span><span class="fl" style="color: #AD0000;">0.2</span>)</span>
<span id="cb86-7">        ax.scatter(samples[:,<span class="dv" style="color: #AD0000;">0</span>], samples[:,<span class="dv" style="color: #AD0000;">1</span>], s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="2143afe3-6582-445c-d40c-1bf41e2dce13" data-execution_count="70">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1">plot_data(centroids, X, n_samples)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-53-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-53-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="animating-the-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="animating-the-algorithm">Animating the Algorithm</h2>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><span class="im" style="color: #00769E;">from</span> matplotlib.animation <span class="im" style="color: #00769E;">import</span> FuncAnimation</span>
<span id="cb88-2"><span class="im" style="color: #00769E;">from</span> IPython.display <span class="im" style="color: #00769E;">import</span> HTML</span></code></pre></div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><span class="kw" style="color: #003B4F;">def</span> do_one(d):</span>
<span id="cb89-2">    <span class="cf" style="color: #003B4F;">if</span> d: one_update(X)</span>
<span id="cb89-3">    ax.clear()</span>
<span id="cb89-4">    plot_data(centroids, X, n_samples, ax<span class="op" style="color: #5E5E5E;">=</span>ax, alpha<span class="op" style="color: #5E5E5E;">=</span>d)</span></code></pre></div>
</div>
<p>We can visualize the “gravity” of the cluster centroids as the data points are “pulled in” via the weighted average.</p>
<div class="cell" data-outputid="57402cb2-2ebd-467a-ed23-a962aa25f28a" data-execution_count="73">
<div class="sourceCode cell-code" id="cb90" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1">X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb90-2">fig,ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots()</span>
<span id="cb90-3">ani <span class="op" style="color: #5E5E5E;">=</span> FuncAnimation(fig, do_one, frames<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, interval<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">500</span>, repeat<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb90-4">plt.close()</span>
<span id="cb90-5">HTML(ani.to_jshtml())</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
<script language="javascript">
  function isInternetExplorer() {
    ua = navigator.userAgent;
    /* MSIE used to detect old browsers and Trident used to newer ones*/
    return ua.indexOf("MSIE ") > -1 || ua.indexOf("Trident/") > -1;
  }

  /* Define the Animation class */
  function Animation(frames, img_id, slider_id, interval, loop_select_id){
    this.img_id = img_id;
    this.slider_id = slider_id;
    this.loop_select_id = loop_select_id;
    this.interval = interval;
    this.current_frame = 0;
    this.direction = 0;
    this.timer = null;
    this.frames = new Array(frames.length);

    for (var i=0; i<frames.length; i++)
    {
     this.frames[i] = new Image();
     this.frames[i].src = frames[i];
    }
    var slider = document.getElementById(this.slider_id);
    slider.max = this.frames.length - 1;
    if (isInternetExplorer()) {
        // switch from oninput to onchange because IE <= 11 does not conform
        // with W3C specification. It ignores oninput and onchange behaves
        // like oninput. In contrast, Microsoft Edge behaves correctly.
        slider.setAttribute('onchange', slider.getAttribute('oninput'));
        slider.setAttribute('oninput', null);
    }
    this.set_frame(this.current_frame);
  }

  Animation.prototype.get_loop_state = function(){
    var button_group = document[this.loop_select_id].state;
    for (var i = 0; i < button_group.length; i++) {
        var button = button_group[i];
        if (button.checked) {
            return button.value;
        }
    }
    return undefined;
  }

  Animation.prototype.set_frame = function(frame){
    this.current_frame = frame;
    document.getElementById(this.img_id).src =
            this.frames[this.current_frame].src;
    document.getElementById(this.slider_id).value = this.current_frame;
  }

  Animation.prototype.next_frame = function()
  {
    this.set_frame(Math.min(this.frames.length - 1, this.current_frame + 1));
  }

  Animation.prototype.previous_frame = function()
  {
    this.set_frame(Math.max(0, this.current_frame - 1));
  }

  Animation.prototype.first_frame = function()
  {
    this.set_frame(0);
  }

  Animation.prototype.last_frame = function()
  {
    this.set_frame(this.frames.length - 1);
  }

  Animation.prototype.slower = function()
  {
    this.interval /= 0.7;
    if(this.direction > 0){this.play_animation();}
    else if(this.direction < 0){this.reverse_animation();}
  }

  Animation.prototype.faster = function()
  {
    this.interval *= 0.7;
    if(this.direction > 0){this.play_animation();}
    else if(this.direction < 0){this.reverse_animation();}
  }

  Animation.prototype.anim_step_forward = function()
  {
    this.current_frame += 1;
    if(this.current_frame < this.frames.length){
      this.set_frame(this.current_frame);
    }else{
      var loop_state = this.get_loop_state();
      if(loop_state == "loop"){
        this.first_frame();
      }else if(loop_state == "reflect"){
        this.last_frame();
        this.reverse_animation();
      }else{
        this.pause_animation();
        this.last_frame();
      }
    }
  }

  Animation.prototype.anim_step_reverse = function()
  {
    this.current_frame -= 1;
    if(this.current_frame >= 0){
      this.set_frame(this.current_frame);
    }else{
      var loop_state = this.get_loop_state();
      if(loop_state == "loop"){
        this.last_frame();
      }else if(loop_state == "reflect"){
        this.first_frame();
        this.play_animation();
      }else{
        this.pause_animation();
        this.first_frame();
      }
    }
  }

  Animation.prototype.pause_animation = function()
  {
    this.direction = 0;
    if (this.timer){
      clearInterval(this.timer);
      this.timer = null;
    }
  }

  Animation.prototype.play_animation = function()
  {
    this.pause_animation();
    this.direction = 1;
    var t = this;
    if (!this.timer) this.timer = setInterval(function() {
        t.anim_step_forward();
    }, this.interval);
  }

  Animation.prototype.reverse_animation = function()
  {
    this.pause_animation();
    this.direction = -1;
    var t = this;
    if (!this.timer) this.timer = setInterval(function() {
        t.anim_step_reverse();
    }, this.interval);
  }
</script>

<style>
.animation {
    display: inline-block;
    text-align: center;
}
input[type=range].anim-slider {
    width: 374px;
    margin-left: auto;
    margin-right: auto;
}
.anim-buttons {
    margin: 8px 0px;
}
.anim-buttons button {
    padding: 0;
    width: 36px;
}
.anim-state label {
    margin-right: 8px;
}
.anim-state input {
    margin: 0;
    vertical-align: middle;
}
</style>

<div class="animation">
  <img id="_anim_imgbf18fa8feeef42df9ff1917d1946c4bf">
  <div class="anim-controls">
    <input id="_anim_sliderbf18fa8feeef42df9ff1917d1946c4bf" type="range" class="anim-slider" name="points" min="0" max="1" step="1" value="0" oninput="animbf18fa8feeef42df9ff1917d1946c4bf.set_frame(parseInt(this.value));">
    <div class="anim-buttons">
      <button title="Decrease speed" aria-label="Decrease speed" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.slower()">
          <i class="fa fa-minus"></i></button>
      <button title="First frame" aria-label="First frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.first_frame()">
        <i class="fa fa-fast-backward"></i></button>
      <button title="Previous frame" aria-label="Previous frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.previous_frame()">
          <i class="fa fa-step-backward"></i></button>
      <button title="Play backwards" aria-label="Play backwards" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.reverse_animation()">
          <i class="fa fa-play fa-flip-horizontal"></i></button>
      <button title="Pause" aria-label="Pause" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.pause_animation()">
          <i class="fa fa-pause"></i></button>
      <button title="Play" aria-label="Play" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.play_animation()">
          <i class="fa fa-play"></i></button>
      <button title="Next frame" aria-label="Next frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.next_frame()">
          <i class="fa fa-step-forward"></i></button>
      <button title="Last frame" aria-label="Last frame" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.last_frame()">
          <i class="fa fa-fast-forward"></i></button>
      <button title="Increase speed" aria-label="Increase speed" onclick="animbf18fa8feeef42df9ff1917d1946c4bf.faster()">
          <i class="fa fa-plus"></i></button>
    </div>
    <form title="Repetition mode" aria-label="Repetition mode" action="#n" name="_anim_loop_selectbf18fa8feeef42df9ff1917d1946c4bf" class="anim-state">
      <input type="radio" name="state" value="once" id="_anim_radio1_bf18fa8feeef42df9ff1917d1946c4bf" checked="">
      <label for="_anim_radio1_bf18fa8feeef42df9ff1917d1946c4bf">Once</label>
      <input type="radio" name="state" value="loop" id="_anim_radio2_bf18fa8feeef42df9ff1917d1946c4bf">
      <label for="_anim_radio2_bf18fa8feeef42df9ff1917d1946c4bf">Loop</label>
      <input type="radio" name="state" value="reflect" id="_anim_radio3_bf18fa8feeef42df9ff1917d1946c4bf">
      <label for="_anim_radio3_bf18fa8feeef42df9ff1917d1946c4bf">Reflect</label>
    </form>
  </div>
</div>


<script language="javascript">
  /* Instantiate the Animation class. */
  /* The IDs given should match those used in the template above. */
  (function() {
    var img_id = "_anim_imgbf18fa8feeef42df9ff1917d1946c4bf";
    var slider_id = "_anim_sliderbf18fa8feeef42df9ff1917d1946c4bf";
    var loop_select_id = "_anim_loop_selectbf18fa8feeef42df9ff1917d1946c4bf";
    var frames = new Array(5);
    
  frames[0] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAY7dJREFUeJzt3Xl8VNXdP/DPnSQzk3USIAvBsAg0KJshVYhEVEBAaBUFFdqK\
C0tLqbLYFqgL9aeWRR8R+iguUK0bUWnFWhChQeCJEsQQViUVlEVCEhAyE7LMJDP398fNvbl3MjOZ\
hCQzk/t5P6+8IDN37hx47PDJ95zzPYIoiiKIiIiISDcMgR4AEREREbUvBkAiIiIinWEAJCIiItIZ\
BkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIi\
ItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEA\
JCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIi\
nWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAi\
IiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZ\
BkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIi\
ItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinWEAJCIiItIZBkAiIiIinQkP\
9ACImuJyuVBcXIzY2FgIghDo4RARtRlRFFFRUYHU1FQYDKzRUNthAKSgV1xcjLS0tEAPg4io3Zw+\
fRpXXHFFoIdBHRgDIAW92NhYANIHYlxcXIBHQ0TUdmw2G9LS0pTPPaK2wgBIQU+e9o2Li2MAJCJd\
4HIXamtcYEBERESkMwyARERERDrDAEhERESkMwyARERERDrDAEhERESkMwyARERERDrDAEhERESk\
MwyARERERDrDAEitZtmyZRAEAfPmzVMeq6mpwZw5c9C5c2fExMRg0qRJKC0tDdwgiYiIiAGQWsfe\
vXvxyiuvYNCgQZrH58+fj48//hgffPABdu7cieLiYtx5550BGiUREREBDIDUCi5duoRf/vKXeO21\
15CQkKA8brVasW7dOjz//PMYOXIkMjMz8frrr+OLL75Afn5+AEdMRESkbwyAdNnmzJmDCRMmYPTo\
0ZrHCwoKUFtbq3m8X79+6N69O3bv3t3ewyQiIqJ64YEeAIW2nJwc7Nu3D3v37m30XElJCYxGI+Lj\
4zWPJycno6SkxOs97XY77Ha78r3NZmu18ZIHe9cBeSuB7PnAtdMDPRoiImoHrABSi50+fRpz587F\
O++8A7PZ3Gr3Xbp0KSwWi/KVlpbWavcmD/JWAtbT0q9ERKQLDIDUYgUFBSgrK8OQIUMQHh6O8PBw\
7Ny5E6tXr0Z4eDiSk5PhcDhQXl6ueV1paSlSUlK83nfx4sWwWq3K1+nTp9v4T6Jz2fMBS5r0KxER\
6QKngKnFRo0ahUOHDmkee+CBB9CvXz8sXLgQaWlpiIiIQG5uLiZNmgQAKCoqwqlTp5CVleX1viaT\
CSaTqU3HTirXTufULxGRzjAAUovFxsZiwIABmseio6PRuXNn5fHp06djwYIF6NSpE+Li4vDQQw8h\
KysLw4YNC8SQiYiICAyA1MZWrlwJg8GASZMmwW63Y+zYsXjppZcCPSwiIiJdE0RRFAM9CCJfbDYb\
LBYLrFYr4uLiAj0cIqI2w887ai/cBEIU6vauA1YOkH4lIiLyAwMgUahjGxciImomBkCiUMc2LkRE\
1EzcBEIU6tjGhYiImokVQCIiIiKdYQAkIiIi0hkGQCKS+NpNzJ3GREQdCgMgEUl87SbmTmMiog6F\
AZCIJL52E/u705iVQiKikMCTQCjosTN+CFk5QKoUWtKA+YcDPRqikMPPO2ovrAASUetV7tiTkIgo\
JDAAEhGw/Smpcrf9Kf/DoKfrrp0uVf7kvoScEiYiCkoMgEQdUXODV6294Vd/N3z4cx03jxARBSUG\
QKKOyN/gJQdFof77CJP/07j+XMcpYd17O/8khi/bjrfzTwZ6KESkwgBI1BG5By9vFUE5KIabgPAo\
oLocOPlFwzSu++vU37tP93rizzXUoa3ZcRxnyquxZsdxr9cwJBK1PwZAolDmLdi5By856G3+g/ba\
6C7Srwk9AacdgAgc+bDhefdKYmtP6XKNYIc3+6be6BYfidk39fZ6jT8hkYhaFwMgUSjzN5BlzweE\
MEB0StfKwat4v/T82YNA/zsACECYCdgwXXo+bai2kpg2VLpP2lDp+8sNcFwj2OH9algPfL5oJH41\
rIfXa3yFRFYHidoGAyBRKPN3jd2106WAJ4c3OXhFREqP9b8DmLwOsFwB1FVJVUDraeD0noZ+fisH\
AMdzpRB5PFf6Xt493NIAxzWCBN8hsTWqgwyRRI0xABKFMvVUr6dqnPoxObx98xFg/QEwREhr/7oO\
kgLfhukNgazroIawuHcdsOkRKejV2aXnRUjfi7i8AMc1gtQEf6aQm8IpZqLGeBIIBT12xveTp1M4\
5MciE6QNHvDxP3chDFhyofG9HJeA6ovS4+FRQHRnae2gPG3c43qpApg9n0GOgtLb+SexZsdxzL6p\
t8+p6GDAzztqL6wAEoUSX1W+tKFS0LNfang+e742/AlhQGpGw6+WNOlXX2v/1JmxrloKhmcPStXE\
03u4jo8ABPc0qz/rEIn0JjzQAyCiZlCHLfcdvgBgjGn8fI0NSvgb/6znKt2ynkDNReDwBul7xyVg\
4Qnt+8qVQHnN4Ok9DVO/cgWQdEs9zepP0FJX5eTXh0KFjqijYAWQKJR42jShfsz9+byVUqXOW/iT\
q4e1l7SP19obnpPfQ4RUTRz/rLRhRF67x3V8hIa1epk9EvyqBKoDY0vW6AVzxZEoFHANIAU9rom5\
DHvXadfnuX8vV/7cRSZIga/mImBOAEwxjdcXEnkwfNl2nCmvRrf4SHy+aKTX6y63Aujv+4Qaft5R\
e2EFkKgjkqt3hW8BtmLpdI+964DNf0Deoe8begHWlEvXGyK0rx/5OPJO1ki/F8B2LeQ39a5dT1U6\
+TEAyro8f9boud+rNXYHE+kZK4AU9HT5E7F7pa655F28auYE/HnLWTy504Fl4+KxMCsMcNVKz0Um\
NOz0taRh+abjWJRbgyWjLPjz0v9p+fTuhulSixm5zyDpyjVPbkV5dS3iIyOwf8kYAC2v3HXUip87\
XX7eUUCwAkgUjC53Z628+1do+J943n/P48mdDgDAoi3lWL5LXvcnACMfl643JyjhDwCezLUi782n\
G5/0IVcY5V3D3k4COfKhtAZRfbwc6VpzKnfqqh9PCyFqXQyARMHIfcrV25Frvs4CNsYAoqvhlt3D\
sGxCkvL9olw7lufZgQGTlOuX/6dECX8AsGxcPLI7X9AG0fqpZFhPN5wY4i2oyqeP9L+jRX8NFNp+\
PzYd3eIj8fux6cpjvxrWA7Nv6o01O443Cmxv55/ENU9uxTVPblXWCKp3Fnt7HRs9EzUfp4Ap6HFK\
BNrGzNnzG6aH5Uqhp80Ze9cBuU9Ja/h6j1Latiz/+ydY9OI/lMuWLVuGhQsXYvnvJmsfH2XGwt/8\
oqHdizwNLI/FvR0MdwGTn7xN58qPA0CYAEwYlIqCkxeR2SMBBScvotJeh/Lq2kavC6VGz03h5x21\
FwZACnr8QIR2TWDuUw27c/uMat4au/pQuPw/pZpKX6e4aFywVSrfLxtlwsJskzZYymNQnwLCdX3U\
DHJQkwOdHNjUj+/67zlYq2shQgqBT94+AM99WoTy6lpERhjQKdrUoXsH8vOO2gsbQROFArnfHgBs\
f0r6VYBUfZNP5PBH3kqg5iIWZhsBiFiUawcAz+EPkMKeHPwulQDOWukcYYgN6/rcK4CXu4GFOix5\
qhaApoKnfvz3Y9OVwOcUgec+LVKuM4WH4fNFI/Hw+kL860Cx8tqOFACJ2gvXABKFmpGPS5W5kY83\
rBVMG+rfpoy0oQAEICIKC3/zS3SKFDRPd4oObwh/gFTpy31KmvJ11u8Ylk8VkTd3uK8BlKelN//B\
+zhIl7xt5FA/vmbHcZRX12qed19LuOlgsfJc52gjei3ahKse34KH1xcqm0G4MYTIN04BU9DjlEgT\
5E0ZohNSWVAEIqKAqM7aE0HShjbsyjUnYPlOKxZtKW90O6UCKIQBXQcBxYXSE4JBun//O4Ae1zfc\
U10B3LtOqlDKZw+zcTQ1k7q6J08Bu1f4Hl5fiI8PFMMcYUBNrUs5rjpMAJwi0C0+EgBCsm0MP++o\
vXAKmCjUyce9AYAgAKII1FYB1iopGIaZgLoqVV9AoVH46xRlwIUqacfwolw7EBaBhU8/r63sGcKA\
mBQp/KmnpIGG3cjyecHmBOlxxyXpOU4F69Lb+SeVKdzfj033a6q24KTUj1IAEGuO8HjN6qkZKDh5\
EWfKqxFZHwLNEWG45epkZW0h0LBGsCNtEiFqLawAUtDjT8RN8FYBrK2Wfq+QnlueZ1fW/gFSq5eF\
N1rqW8CoHh8Tg4UjOzc0iJbv7WljiP2S9ti4pnYoky6od/V6q8S5HwmnXvPnvuO3pcfHhVITaX7e\
UXvhGkCiUCYHsP53SEFrwCTp1/Tx2uvMCUDqNY3D3ygTFk6/ExCAhSNisGyUWXlu0dZLWL6tRAqT\
6nurj4OTQ54A6blRj0th79rpPD6OMPum3oiPjEB8ZITXxs/qHn7y5g9AqhjGR0ag0l6nrO177tMi\
TV9AT8fHeVr7x2PjiBpjBZCCHn8i9qGp/oCy8CjkfVeJG16vUB7SrPWrXxcIUwyWF0Ri0TtfKdf9\
34xOyL66q+ddvdzxS37wNQX78PpCbDpYjAmDUrHt61JU1zoRGRGGb54ap1Tu5LV98ZERiDaF+6wA\
ql/jaf1gsOPnHbUXVgDpsqxZswaDBg1CXFwc4uLikJWVhU8++UR5vqamBnPmzEHnzp0RExODSZMm\
obS0NIAj7mDUVTY59OU+Ja29i4iCVJoDUFeF7O4CltxoBOAW/uTqodMOWE9j4cBzyokhS240I7tP\
rPfTPq6d3lDx8/d4ONKVt/NPYslHh5XKnXuFruDkRThFee2fXI8Q8Xb+SVyodEAA0D/VouwClqt+\
cuVwyUeHG1X75MDIk0GIvGMFkC7Lxx9/jLCwMPTt2xeiKOLvf/87nn32WRQWFqJ///6YPXs2Nm3a\
hDfeeAMWiwW/+93vYDAY8Pnnn/v9HvyJ2E9yNa7qR2kTCACERajatwAQDMg76UT2wO5SP7+ISGDM\
01KAW9ZTWscHARgwCXk7tyN72mPS6/yp8snVyIY3AyLjpXY1nl7H6qEuXPPkVpRX10IA8NTEAUpw\
k9fjvZ1/Es9s+ho1tS6EhwmodYrSioLICGU6WK78qRtIf/n9Ba+7hT2tFXRvPh2s+HlH7YUBkFpd\
p06d8Oyzz2Ly5MlITEzEu+++i8mTJwMAjh49iquuugq7d+/GsGHD/LofPxDr+RuYlvdUbdwAlM0b\
ABCZACw8oQ1r8iaNDdOBwxvqX+LHMW/u49FsRlHxtglEPX3NTSId0tv5J/H4xsMQIYW4/UvGeJwO\
7rVoE6p/OALzFf010732Oheqa7X/PdX8cAS9B/wUAJQNJoD3TSbu08jBvhGEn3fUXjgFTK3G6XQi\
JycHlZWVyMrKQkFBAWprazF69Gjlmn79+qF79+7YvXu31/vY7XbYbDbNF6FhitfTVKzayMelyh8g\
/TpgkhT8zAnSc4AU2swJ0jSxvb5Vi/o0EdEJHP6H9H6bHpGqg+5Tuu7juXY6MP7Z+g0jk6X7RyZ4\
3wTCTSId3podx5VJ3RE/SWwU/h5eX4jeizehPO8dlL6zENb8DZgwKFWZ7jWFa/+JsuZvQOk7C5F8\
7F/KVC8gVQC9bfCQN4DI9+VGECIJ+wDSZTt06BCysrJQU1ODmJgYfPjhh7j66quxf/9+GI1GxMfH\
a65PTk5GSUmJ1/stXboUTz75ZBuPOgSpN3n4cu30hnAWk+L5vF65orfpEWm6eNMjUlAEVFPIDeux\
UHNRuqf6uDfHJSnkZc/XVgP9rea59xKkkNBUTz11778RP0lEibVaWeMn9+5b8pH038img8WoPH0E\
5Z+vBwCU73wDH0WG4+QnrwHQtoSx5m9A+c43AAAfrluF/tdmI9YsVcjkE0KGL9veaFy/GtZDOW9Y\
7jFIRKwAUitIT0/H/v37sWfPHsyePRv33Xcfvv766xbfb/HixbBarcrX6dOnm36RHqg3XDTFV3VN\
3qyx/SloQt6xXOm36eMbqnjyJhIIDcfNyWGv+qLU808dOJuqTlLIU7dt8fZ8eXUtyqtrUXDyIp68\
fYBSeXPfoDFhUCrMV/RH/I33K68/tWUtpsxZhOHLtmPETxIRJmjDHwAsW7YMH5fEoby6FvY6l9JC\
xtOmEH/HTaQ3rADSZTMajejTpw8AIDMzE3v37sWqVatwzz33wOFwoLy8XFMFLC0tRUpKitf7mUwm\
mEwmr8+TB3vXSbt/nXbp5A+5H5/8nHxs27FcoKYcgChV78wJ0mvC6/++5XWB8mt7XC8FxVq7NCUM\
UdtqRg6Y/lYnKeTJ5/X6mnKVK3dyNc69Uqh+/a7/nkP8zVMxtn8y3ntpOQDgvZeWI/7GUmDcvUg5\
sRXfqcJf4sgH8C/xWtjrpH6W1bXO+hNBwjTh0v09mxo3kd5wEwi1upEjR6J79+5YtWoVEhMTsX79\
ekyaJE0vFhUVoV+/ftwE0trcd+CqN1bIz8n9/mSpGUDl+YbQtv0pqSA46vGGTR3qUz4A6R7jn+XU\
LfnF13Sx3B7GKTbs4v33W2uUEAgABnMsXDUNvSu7jn4QSdn3KLuKLZERsNc5UV3rQmSEAabwMAD+\
HzsXjPh5R+2FFUC6LIsXL8att96K7t27o6KiAu+++y527NiBTz/9FBaLBdOnT8eCBQvQqVMnxMXF\
4aGHHkJWVpbf4Y+8cN+Bmz1fWwFUr8tLGyq9xr0CePagFAjladvqi1JwBLTn+sr9BNUtY4j8IE+7\
Pr7xMJ77tAjRpjCcKa/BoG4W/FjpgLO+/KD07Esbg/gbS5XpXnX4i7/xfvQa9UvMvqm3EhyjTeH4\
/dh0rNlxHJX2OuXoOHnNH8//JfKOawDpspSVlWHatGlIT0/HqFGjsHfvXnz66ae45ZZbAAArV67E\
z372M0yaNAkjRoxASkoK/vnPfwZ41B2Apx24i05IAc0Uo73myIdSIJy8Trpmwv9IQU9uAJ0933ND\
aRHSY+EmACIQ1Vkb/uS1hGz4TPXcmzzLa/5ESOf6nimvAQAcPGNVjomLMAgQAHSONqLSXof4YZNh\
MMdq7mswxyJ+2GQlzKVY5CMLReVIuN+PTdfs8m3Omj9Px8cRdXScAqagxykRD7z1BHQ/Gk7uy9ec\
Xnue+vv5eq/6I+TY0Jnkps/xkRFKZS6zRwJ2/fccAGgqgP96KFu5Xu3Sng34cccbje6dOPIBPP/M\
EiXYyZ6e6Pm4t+ZUAOVegcHQI5Cfd9ReWAEkCkXyjmBAW4VTV/LUffl8bc5wr+S53xvwvPtYfi8B\
3AFMGtbqWmVXbsHJi9i/ZAz2LxmDzxeNwollE/Cvh7I118t7za352vCnrgSe2/465i7+M86UVyNC\
bgCIxse9ydU8AMqxcU2RewVygwjpCSuAFPT4E7EPrXGahrd7+HvvDdOlaeb+d3juOUgdklxhUx+x\
BkBZnycf3yZX4Nwrcrf9NQ8Hz1gRYRCw5Lb++MtfluGbj19W7h9/4/2wDJsMW/4GXFTtAk648X6s\
XvZnAA19AuU+gOq1gO7vHyr4eUfthRVAolDWGqdpeLtH2lBp16+8icSb03ukaWb1SSLU4clTsZsO\
Fitr7X41rIfS9+/3Y9M1FTj3NXkHz1gBALUuEWd25jQKf12uvwvxkRHofvNUJKj6BF7c+Qb+/dYa\
/GpYD0SbwlFeXYs1O44r97fXOREmAPY6l8c1gFzvRyRhACRqYxdzcvDtyFG4mJPT+jdvTnPo5t7D\
V7BTTxvzSDdd8nbEmrwpQ111ezv/pLTBIzICmT0SMHzZdhjqZ3EdPxzBokWLlGsTRz6AHjdPxZLb\
+isBL27YZE2z6PdeWo7HX9mgmbrN7JFQfzScAKcImMINHqd12RCaSMIpYAp6oT4l8u3IUagrLkZ4\
air6bs9t+Y28bcZoK3vXNe4NKGuNqWcKCc1tp+LpevUmCwA4U16tTNFeqLTj7Gdvwfr5enQfN0M5\
Bk6+lzylDECZDrYMn4r+P5uh2bAhv0d8ZITymKd+gMHeHibUP+8odLACSNTGusyaifDUVHSZNfPy\
btQWx635auVy7XTAGNNwDrAaq3660dyKmbz54/GNhzXtYNTHwclTxJk9ElBd60J89i+R/MvlEAZP\
VO4jnyksVygiDAKyJ01H8i+XIz77l8jskYC380/imie34pontyKzR4JyX/XUsDtPFUoiPWIFkIIe\
fyKu1xYVwKYqea3xnu1duaRW1dyKmbq1S1NtVXov3qRU9wAgPjIc+5eMBdBQ0ZOFCUCKJVJ5TN4H\
LCqv1baekTemhFrQ4+cdtRdWAImCRJNrBVtjvZ+7pip5rfGebVG5pHbT3IrZ78emIz4yApERBlTa\
6/B2/slGGy/k7/unWiCoXhttapi+zeyRAAFQ1goaww3I7JGA+MgICJCCn3v1Qq5WFpy8qIyZmz6I\
PGMAJAoS5199DXXFxTj/6mtNX+yvpk7rcA94bXG6B6eLdeVXw3pg/5Ix6BRtarRDV56SlaeJT12o\
Qmr9usAwAZoNGwUnL0IE0NUSiW7xkaiudSk9BZ+aOACREWHKtQKk4Ompn5/83ks+OswQSKTCAEgU\
JJq9VtCfsNbc6ltbVOvaonJJQc/Tuj9PjZbl5568XXuih3xUXKW9TlnfJ+8gBoBO0UblWkv9xg9P\
U9XycXTKecNEBIABkChoJEyZgr7bc5EwZYp/L/AnrDW3+uZv7z+iJshTx0DjYCaf2ys3cPb2enkz\
x6aDxZh9U28UnLyoVBLlgKhe+3emvBrPbPoGvRdvwsPrC5X7yL0J5QDJSiARN4FQCOCiaC8CsSmE\
qJmaOmdX/fzsm3prwqK6DYyn59XkzSrF5dUQIU0pH186oVljCQb8vKP2wgogUagKxKYQIj/Jmy/k\
6Vv19K96Y4Z6eliu4j33aZEy1fvk7QOUqWDA+/m+csXx54NTESYAEwalNrqGZ/4SNWAFkIIefyIm\
Cj2+qm3enpOrePJ5vmGCFADlYNgalTs2giaSsAJI1AxNtWrx9nxrHwfXpsfLEbUCfzZ+uD8nV/FG\
/CQRgLRx47lPi7xe35IWLzwKjkjCAEjUDHKrlpKnnvYYvry1cmlui5emAl6btIwhakW++gc21Vuw\
4ORFj9cD0AS+loQ5TgMTSRgAiZqhy6yZQFgY4HR6DF/eWrnIj0dlZPhVuWsq4LXa8XJEQch9h6/M\
PfC1JMzxKDgiCdcAUtAL5JqYizk5OP/qa+gya6bSnuViTg7KVr4AAEiaP0/zuPu17r4dOQp1xcUI\
T01F3+25Xt8vKiMDVYWFPu9FpDctXb8X7Ov+1LgGkNoLK4BEKu5Tr54qcQlTpsAQHQ2X1aqZCvZn\
Wrapyp18j6rCwub1BCQKcq1xJFtLq3dc90fUGAMgkYp7iPM1pStPBZetfAHfjhyFqIwMr+HuzCO/\
xzf9B6B8wz98vr/6/bjRgzoKuZ+fpxCmDoZtdW4v1/0RNcYpYAp67TUl4m1q19f15199Da7KSris\
ViAsDCmPP+bxdd/0HwA4ncr33qaA1eTpYl/3JQoFctsXua2LuoKnbgkDIOgbNbc1TgFTe2EFkKje\
+Vdfg8tqhSE6ullhKyY72+fGEACIGzcOCAuDecAAvzdveKoyshpIoeTt/JO45smtuFBpR3xkRKPw\
B3g+89dTpa6tqoNEehUe6AEQBYsus2Yqmzi8UW/0UNbrAUh5/DGfr+32P8+h2/8816zxJEyZgqq9\
X8G2ZQtEux119WsO5eeIgt2aHcdRXl0LAOgUbfLaEkZeo1dw8qLHxtDqU0KWfHRYeR0RtRwrgET1\
EqZMaXLjhXqNoHq9nj+vVa/p83d9X1VhIeB0QjCZmqwyEgUL9TFwcjsXX+vvvK3RU2/emH1Tb4QJ\
UnNobuYgunysABK58dXORV0llJ9TBzJfbWDcN5jIv/cVGt2rkk1VKImCgRzcAGD/kjFNXv+rYT08\
VvTkyp+6fYv8PRFdHm4CoaDX3oui5c0XBosFhuhov/r6ISwMQkQExJoaGCwWpO/Jb3Stusffpbw8\
AA2bTfzpIUgUKlq7714o9fG7XNwEQu2FU8BEbuSpXaChSie3cTnzyO8107fhnTpJL3I6IdbUAABE\
hwNA456C8jRxVWGhZrPJxZwclDz1dLOPdmObGApWrX3aBvv4EbU+BkAiN3JQS5o/T1njZ9uyBXA6\
YduyRTOVW3P4cMMLw6UVFWJ1NYqGDkPpsuWoKy5G2coXNGGty6yZMFgscFVWKpU/OJ1AWJjH6V1v\
QY/nAZNe+NPHj7uEiZqHAZA6rOZWyLxV7BKmTFHauMSNG4eojAwgLEz6VUWIiFB+77JalYogoA1r\
6pNEyla+AFdlJQwWC1IefwwAGo3ZW9DzNg6ijsafiiKrhETNwzWAFPRauiamqXN3Ze4NnZu6vmjo\
MGkK12KB6HBArJYWuxssFrhsNkD9P6n6Js4ANGf8yr8qTaQFAYLJBNFuB0RRGYOv5tT+/vmIQp0/\
awA7yjpBrgGk9sIKIHVYTZ27K5MrbACavP5iTo4U8uolL/wjDBYLBLMZABA3fjzCU1MRN2GCtIkk\
JgZVe79SKn0VubmoKy7Gpbw8ZZoZYWGAKEoVQ1FUqnrfjhwlvc5qhevSJc0Ymjp6jqgj8ae619rr\
Dok6OgZA6rD86c0HNATFpPnz/OoDKIe0pPnzAACG6GgIJhP2nj2LqsJC9N2eqzR9dlmtsG3aJIU4\
qxWi3Y6CqirNGOPGjQMEAQgPV6aCqwoLlVDq3v9PaUBd/17cNUwdHc/yJWp97ANIupcwZYrfISoq\
IwO20lKYr7pKqs7VT/m+WFGBF4vPYEn2cPzZ24sFAW+Eh2HF6VP4bU0NHh46DEnz50nNnkUR4UlJ\
mqlc9/5/clUwKiMDVfVj+XbkKLaOoQ7PW59AImo5VgCJ6vmzaeRSXh7gdKLmyBFp7Z4oosBegxeL\
zwAAnly/HsuXLwfQcEawfP7vexnXYEX9ruGXzpVh79mzjU4U8UTdPkaePpbHwl3ARETUEgyARPXk\
qdWylS94DIIXc3Kk0AcAYWHS2r/ISPzUEo8FiYnKdYsWLcKfbhgB2+bNgNMJx+nT+OfYMXhy/Xrl\
mgVdEpEZFdXQR9DLWNThzr0/ISCtWZQrgewHSERE/uIuYAp67bUrTt5xK0/ruu+uVU79gLTjN2n+\
PJQ89bTUww/A2gs/4vlz55TrF3RJxIzOnbGushL/88PpRo8DAMLCEJ6crDl5RD4pRLTbpd3BRqNm\
B7D7qSHcDUzUcXAXMLUXVgDpsixduhTXXnstYmNjkZSUhIkTJ6KoqEhzTU1NDebMmYPOnTsjJiYG\
kyZNQmlpaYBG7J3cn0/e5OE+JRuVkSEFsshIJM2f19DAud6sXldiydSpyvfPnz+HrGPfeg5/Bul/\
ekJEhFQFDAuD6HCgrrhY2TQi1tZCrK6Gy2rVVALdN7f4u9uZiIhIxgBIl2Xnzp2YM2cO8vPzsW3b\
NtTW1mLMmDGorKxUrpk/fz4+/vhjfPDBB9i5cyeKi4tx5513BnDU3slhKuXxxzQVt29HjpLW3oki\
BKNR2ZShbvkCAHNvu00TAq2qgLigSyJmdOki7fR94nGEp6ZCrKmRThNxOiEYjdKOX0BpOm2wWGCw\
WHyGO393OxMREck4BUyt6ty5c0hKSsLOnTsxYsQIWK1WJCYm4t1338XkyZMBAEePHsVVV12F3bt3\
Y9iwYU3eM9BTInLjZ8FsRlinTnBeuCD17BMEpCx5AgCUqWB5GjY+PAJWZ51yD0tYGPZk/hQAlGbT\
XWbN1EwhC5GRiB05ElWFhcr0rq9G0ETU8QT68470gxVAalXW+k0Sneo3NxQUFKC2thajR49WrunX\
rx+6d++O3bt3e7yH3W6HzWbTfAWCXPkT7XYAgGAyocusmcr3EEWcf/U1lC5foYS4qIwM/D6tuyb8\
AVIl8O9GIwBp/WBURgbOv/qacsQcIJ0hXJErreGr2vuVthF0/bFx/o6ZG0KIiMgXBkBqNS6XC/Pm\
zcPw4cMxYMAAAEBJSQmMRiPi4+M11yYnJ6OkpMTjfZYuXQqLxaJ8paWltfXQPZJ34op2u7LpQ2kE\
Dali12XWTM2Zv8+vf1ez5s9iCFN+vzTv//Dqd9/BEB2ttHSpKiyUQmA90W5X1gEqjaAFAQDgstk8\
Bjt16PN2bjAREZEaAyC1mjlz5uDw4cPIuczq0+LFi2G1WpWv06dPN/2iNtBl1kzlmDZDdDQSpkxp\
eAyAWFODspUvwNy/PwBg7Y8/4vmzZ5XXL+iSiN19+2JB167KY8+fP4d3UpLRZdZM6ezgykqlrx/C\
whA3fnzDOkBIvQRTljyhjMNTsFOHPm4IISIif/AkEGoVv/vd7/Dvf/8bu3btwhVXXKE8npKSAofD\
gfLyck0VsLS0FCkpKR7vZTKZYDKZ2nrIHrm3WAG0J3IAgCEmRmkC7bJaURcdjfeGZOB5tz5/cquX\
WWndIYSFK5XBJ9evh+P0D7j30iXA6YTBYlFCW8KUKYi69qfK2sCqwkLlWDn3cci6zJqpGTPXCRIR\
UVO4CYQuiyiKeOihh/Dhhx9ix44d6Nu3r+Z5eRPI+vXrMWnSJABAUVER+vXrF5SbQHz11LuYk9Ow\
aUMQpKlgQcCJe+7G+CefVK5bMnUqpnz9jTI1bB4wAI7Tp/Hq6VOaCuFbad2RGRur2XF85pHfw7Zl\
C8xXXYW6Cxd4zBuRznATCLUXVgDpssyZMwfvvvsuPvroI8TGxirr+iwWCyIjI2GxWDB9+nQsWLAA\
nTp1QlxcHB566CFkZWX5Ff7am7qapqYJf/UtWuTduldNmYI/Hj6MFf/4Bx65Ig1zb7sNZce/UwJg\
zZEjgChiRpwFqK3D8+fPYf6wLAytX0OoDni2LVuko+a++QZXHTncrn92IiLSD1YA6bII9RsU3L3+\
+uu4//77AUiNoB955BGsX78edrsdY8eOxUsvveR1CthdMPxErJwC4hb+yjf8Q+rjB6Cgqko63i01\
Fa7KSmmaWBAgmM0Qq6ulGwkCCgUBtz7xuNLmRT19e+aR38O2eTMEkwnJixay+kekM8HweUf6wABI\
QS+QH4jqKVmHajOKy2qVNnHIZwPXk3cLA9o1e6XLV0CsqVHCoDzFrJ5y7jJrps+j6Iio42MApPbC\
KWAiH9RTsvKZvYLZDAiCx/CXvidf85gcAgWjEWJ1NcTaWiAsTDpWDtop5/OvvtZwTw9H0REREbUW\
BkAiH+LGjZOmZCMiEJWRgSoArsrKht5/9VO8gtGIpPnzNFO6HnvyOZ2AKKKqsBAAGu3a5akfRETU\
HjgFTEEv0FMi8jStwWKBIToaURkZuJSXB9Fuh2AyacKap7WC8vWA1NdPfdRbc3lqU0NEHUegP+9I\
P9gImqgJcnNlAMrpHel78hHWqRNcVivOv/qachpHVEaG1LTZ6YRtyxZ0mTUTVYWF0nFuly55fQ9/\
j3CTq4olTz3N496IiKjFGACJmpAwZQr6bs9F0vx5mlM21KduyMFMc7Sb09mwEUQVCuVp4Ys5OSga\
OgxFQ4ehbOULfh3hpr4Xj3sjIqKW4hpAIj+5r9dTf1+19yvYSkuldYL16/vkjRwJU6ZIz7s1eFZv\
+lCfBtLUGADvp4IQERH5gwGQqIXU6/GqCguVo9vcj2YDoDxfd+GCprVLSzZ98Lg3IiK6XJwCJt3x\
d71dU9S7fLvMmin1BaysBAD03Z6rCWnq6WJZwpQpSN+Tj/Q9+Qx0RETUrhgASXc8tmdpAXWoS5gy\
BYboaGVTiJqvnbutFUaJiIiagwGQdMdTNa4l5M0hcqjzdl9fgbO1wigREVFzMACS7rgHt7a+r7dg\
eDEnB67KShgsFp9hlFVCIiJqbQyARG3MWzCUdwEboqM1z7kHPlYJiYiotTEAEgWI3DRaPhdY5h74\
WmvKmoiISMYASORBe0y7qlvHqLkHvraasiYiIv1iACTyoK2nXX2t/2PgIyKitsYASORBU9Oul1sh\
9Lb+j4iIqD0wABJ50FQV7nIrhFzXR0REgcSj4IhaQH3cW0vwODciIgokQRRFMdCDIPLFZrPBYrHA\
arUiLi4u0MMhImoz/Lyj9sIpYCIiIiKdYQAk6gDeL3ofYzaMwftF7wd6KEREFAIYAIk6gLWH1uJs\
5VmsPbQ20EMhIqIQwABI1AHMGDgDXaO7YsbAGYEeChERhQBuAqGgx0XRRKQX/Lyj9sIKIBEREZHO\
MAASERER6QwDIBEREZHOMAASERF5cWDbZrw250Ec2LY50EMhalUMgERERF58uXEDbOfL8OXGDYEe\
ClGrYgAkIr+w2TTpUWp6PwgGA1LT+wV6KEStigGQiPxyuc2mGSApFBUXHYXocqG46Gigh0LUqhgA\
iQhA0wHtcptN87QSCkXXTZyMuC5JuG7i5EAPhahVsRE0BT02Rm2594vex9pDazFj4AzcnX63z2vH\
bBiDs5Vn0TW6K7ZO3hrQsRDpFT/vqL2wAkjUgTWn6qau8LXFdO3d6Xdj6+StDH/U5i5n5y53/ZJe\
MAASdWC+pm3dQ546oHG6lkLZ5ezcVb+WYZA6MgZAog7MveqmDn2+Qt6MgTNgMVpQWVvJTRsUFJoT\
xi5n3Z76tWwBQx0ZAyBdll27duHnP/85UlNTIQgCNm7cqHleFEU88cQT6Nq1KyIjIzF69Gh8++23\
gRksaUKfr+rg3el3IyoiCjaHrVFA5G5eam8Htm1G7t9e9hjGPAXDwbeMx8wX/4bBt4z3ej9vYVL9\
Wm4AoY6MAZAuS2VlJQYPHowXX3zR4/MrVqzA6tWr8fLLL2PPnj2Ijo7G2LFjUVNT084jJUA7JSxX\
BwF4DHTeAiKnh6m9fblxA0SXC4LB0CiMtaRK5+9rmgqSRKGMAZAuy6233oqnn34ad9xxR6PnRFHE\
Cy+8gMceewy33347Bg0ahDfffBPFxcWNKoV0+fypzN2dfjdmDJyBtYfWKtd5C3TeAuLltoMhai65\
Ejfqwd80CmP+NGqWK35vL56H56fehsi4OFb2SPcYAKnNfP/99ygpKcHo0aOVxywWC4YOHYrdu3cH\
cGQdk6cgpw6F7xe9j+z12Xg6/2nNde6Bzj1I+qr4cTqY2oOvSlxTjZrV08el3x2D6HKh7MR3rOyR\
7jEAUpspKSkBACQnJ2seT05OVp7zxG63w2azab6oaZ4qc+rwtvbQWlgdVogQlesB7UaR94vexzN7\
nvEZEN3vyelgCqSm1unl5bwJ0eUCBAHJV/aBYDAgPSubO3xJ9xgAKegsXboUFotF+UpLSwv0kIKa\
XIUD0KjPnjq8uU/ZeurHt/bQWrhEFwyCwWNA9HRPX9VDorZ0YNtmfLlxA66bONl7NU8UAADmqBj8\
aukLGPXgb1BcdBR569+C7XwZcv/2MkMg6RIDILWZlJQUAEBpaanm8dLSUuU5TxYvXgyr1ap8nT59\
uk3HGep8VeHU6/jWHlqLCEMEAMAcZlauUYc2OdA9OvRRrw2b1YHQPRyyIkhN8VV5a25VLi/nTdjO\
lyEv502vr82eei/iuiQhe+q9ABo2gEAQAUGA6HIhb/1bzXpvVg+pI2AApDbTq1cvpKSkIDc3V3nM\
ZrNhz549yMrK8vo6k8mEuLg4zRd558+mDDmYhQlhMAgGjOw+stFzq/etxtpDa5GRlKFsEpHD4cJd\
Cz1W9twrft7GwsogyXztwG32jt766h5Ewetr5XYucmNnedOIJUn1Q6gg+nxv98DH/oDUETAA0mW5\
dOkS9u/fj/379wOQNn7s378fp06dgiAImDdvHp5++mn861//wqFDhzBt2jSkpqZi4sSJAR13R1NZ\
W4nV+1Z7DVhyMDOGGeESXcg7k6cEu6raKsQZ42B32nG28iw++f6TRmv8tpzYooTE7PXZGL5+uMdm\
0t6Oe2NlkGS+1ux5e86f6p6v+6oDm7xppOzEd4AoQjAYkD1lmub1TQU+9gekjkAQRVEM9CAodO3Y\
sQM333xzo8fvu+8+vPHGGxBFEUuWLMGrr76K8vJyZGdn46WXXsJPfvITv9+Dh6P7Nnz9cNgc0kaZ\
rtFdlSlfT+TQdrHmImqcNRAgQISIrtFdUVVbBavDCnOYGQnmBM2mj4ykDBSWFaKytlJ5rzhjHBxO\
B+xOO27tdSuWj1je5PvK/QeJ/CGv8XNUV6OmsgJxXZIw88W/ebzG0zpA+bnU9H4oLjqK1PR+OLG/\
EBBE9Bw8BMVFRz2+7rU5D8J2vkx5P7/WGrYSft5Re2EApKDHD0Tfstdnw+qwQoCAx4Y95jVgqUPY\
s3ufRY2zBuFCOMIN4bA77UiJTkFpVSnG9RyH5SOWY+GuhdhyYguu6nQVLtRcUALh6n2rIUKEw+lA\
jVNq6N1U8CRqCTmImWNiYDRHKRU3dRh7cfoU1Fy6BHNMDOasy/H4erla9591awBRhDk6FnP+tl5z\
rTrkub9He+LnHbUXBkAKevxA9EwOdHJ1zlN1TR365GlYdbVPrgCqGQQDHh36KJ7Z8wxcokt53Bxm\
hsPlwLie45CZnImn859WXhtnjMPcIXNZ3aNWdWDbZuTlvAmIAnpek4ETB/ahprISEEWlOvfig1NR\
U1kBQ1g4XC4nwo1G3HTvdAy+ZbymAli0O09qBwMAgoDR02drrnHUVKHm0iWPVUZvY2uLkMjPO2ov\
DIAU9PiB6NmYDWOUQOet+iZfI9T/nwsu9O/cHz3iemDz95tR+d9KRP8kGgBggAEuSP9Ado3uioyk\
DGw5sQXJUcn4bv93iOwbqdw3zhgHm8MGg2BATEQMbA4bq4DUJuQqnmAwKAFOMBiUU0HkIGY7X6a8\
xj3EyfdQCzeZEBVrQVWFFXV2Owzh4RBdLqRnZWPCw3/0e1z+BkZ/8fOO2gs3gRCFKH92/84YOAMG\
wQARohLuvrnwDQrLClH6YSm+/8v3OLfpnBIOAUCAgBkDZ2D5iOU4MO0A/vuP/+L4M8dxbuM55b7V\
ddUAgKs6XYW5Q+Yq4+BuX2pt8oaL9KxsmGNiEG40wRQVpTwvnxISbjJpXgM0bB6J9BCk6ux22M6X\
oc5uBwC46uo8nijibQMKN4JQqGMFkIIefyK+PO8XvY/V+1ajsrYSTtGJW3vdiugforHkl0uUa7pP\
6Y64cQ1/t+YwM4xhRvQs6Il3/+dd5fEn33kSW4WtsDqsAKTp4gPTDijP+1OVJGou9XRrQx8/AeER\
RkAAwsON6HlNBnbu2Ilfzp6jTMl6qh4CwKnyClyZ3EWp/Lnq6qQnVFPD8vvm/u1liC5Xq1f6vOHn\
HbUXVgCJQpC3Spunx+9Ovxt5U/OweOhixBnjsP3UdnwqfIoeU3oo15zKOYXzm84r39c4a3D8w+Oa\
8Nftnm7ol9kPUREN1ZerOl2lef8ZA2cgzhiHqtoqr70DSZ8up3myug3LdRMnA4IAiCLqHHbU2e2o\
qazAy2+tx7MfbsaWfYdwYNtmvPjgVFRVWGGOjkV6VjbiuiTBHBOD7d8cx+qtu/CNaEZclyQYTQ1L\
G8IjjEq/QPl9RZcLgsHASh91OKwAUtDjT8SNeau0qR+XN37Im0Tk1i9qFz+5iDPvnVG+7z6lO5Im\
JOHsv89qHk++KxmJExKV+8obRNTvI29CkccgYzWQgMtbM6fezHFifyFqKiuU58JNJpz80YqVmxsa\
zt85LBPXd69v9Fxf1QOAJX9ajI++Oqhc93//93+IrbYhL+dN1DlqUeeQpoPN0bHInnov8ta/BQgi\
sqdMA9A+O4P5eUfthRVAohDkbf2f+nH3Js52p73RfTqP74xly5Yp35/KOYXv5n6nCX/d7umGxAmJ\
AICMpAzcnX43Hh36qPI+q/atwtnKs1i1b5UyBoMgfbSozxQmffNnzZy3KqG8zq+46KgS/gSDAaNn\
/BZz3/wH7pu3AHcOy1Su/2d+AbZ/c1z6RhTxn3Vr8KdHHtGEv/ED++HEpoaTPOpqHQ2/r3Pgy40b\
UFNZAaNZqnjn/u1lnv5BHUp4oAdARM0nn8PrS0ZSBkpPlCp9/DKSMvD5mc8hQkRabBq+/vFrGA1G\
9JrYC8uwDIsWLQIAXLhwQblH8l3JSLg1Qfl+y4ktyEzO1LyPAOk4rgpHBRbuWojCskKM6znOa2sa\
0qfBt4xvsnKmnur1dO11Eydjx5vrUFfrQHpWtnLNlxs34PruKbBXX4VNB74BAGw+JG3mGHlVb2z/\
+pjyPSCFv5FX9Ubpd8fw4w+nlcqfrM7hQGp6P+U95algAMrjRKGOFUCiDkSu+q3atwpbTmyBS3Th\
Qs0FbJ28FZnJmYiKiMLcIXPRI64HRIiocdZg7aG16DWxF8JjtD8PRsREKJU/QAp6LtGlnBksH+02\
vNtwAIAIUak2FpYVejwSjsiXpqqEg28Zj6g4CyCKKNqdhwPbNuPAts1w1FTBHB2L2Q/ej9szByvX\
bz50FE9s3Noo/N1+wzAAQPKVfTSVP4Uo4sSBfZpxCQbpn0v3XcLA5a1vJAoUBkCiDkSeApbDmnoK\
Vg5tq/etxubvG/6h6mTuhIcffxh1l+o096q9VItzm6TWL/0790esMRYAYHfaUVlbCYvRghkDZ+Dz\
M58rr7mq01VNtqYhag73cCWHMdHlQu7fXkbe+rdQc+mSMjW88av9uP2ng5TXVzlqld/LlT8BAh55\
79/41dIX0O/6G6RNJSpxXZIAUdBUI0c9+Bu/zhr2Nm6iYMMASBRifPXauzv9bmydvBUPD3kYXaO7\
4tGhjypVuIykDBgEAyprK5Xr+3fujx1v7kDpB6XKY2HRYcrvSz8oRefdnZHzsxzMHTIXccY42J12\
2Bw2iBCx9tBazdpCudro6zg67gwmbzwFKffHBt8yHulZ2QAgTcsKDfsYi3bnAQBm3vtLRBkjNPeO\
MkZg5NV9IBgMsJ0vw8pfTMSBbZsx4eE/4pGcj9Fv+AgIBgP6DR+BmS/+DdlT71UCX1OnfniqXHr6\
sxAFEwZAohCjnn71Rg6CAJTAVVhWCJfoglN0AgAsRgsKcgo04a/7lO6YnDMZyXclK4/tfGUnekyV\
WsZER0RDhAgBAiocFThbeRbGMCPijHFKRfByx0765SlIeXpMnoYVDAZkT5mmhDc5GL725ruayh8g\
VQI/K/pOWcvnctYh928vKxW6CQ//EaMe/A2Ki47iwLbNysaTwbeMbzLMqa/1NW6iYMI2MBT02BZB\
e6YvAKzatwoOpwOmMBOuiL0CX//4NUxhJvzh2j9oqm9ySxaDYFA2ZshtYUr/XYqDf2/YFZl8VzIG\
3T0IMwbOwFP5T+HcpnONwmHShCRNKxn53GD1e6rH6utsYq4P1LeWnqV7YNtm7HhrHeocDiT36g1r\
aSkgiOg5eAiKi47ii9MleOPjT5Tro4wRHqeBZeq2NN5a1WxavQJFu/P8PibucvDzjtoLAyAFPX4g\
Nu77595rTxZnjEN0RLQSsBbuWqis91P34/t/7/4/zUkgXe/uis7jO6N/5/64UHNBubd7COz1p17K\
2cECBDw27DElyC3ctRBbTmyB0WBEjbNGeT9voY9hUN+a0xdQHRbz1r/V0AewviG0/Htvu323f3Nc\
8/idwzLx4NS7lVB3xVUDlD6DxUVHlapdXs6bgCitD6yprFDG2tLw6g9+3lF74RQwUQhw7/snn7hh\
MVrQv3N/CBBgDjPD4XQoGz0AoLCsULlHRlKG8vutwlYk3i7t8O12Tzd0Gd8FAPD1j1/jYs1F5bqu\
P+uK7lO6AwCSJyYj5icxynOxxlhNcJN3Hdc4a2AQDMr7eZv25XSwvjWnL2BezpsNU7CqNX/SUXBS\
QPvs6Hcewx8gtYIZP7Chfcs/8wvw0trXIbpcOLZ3D/6z9iXYzpfhxP5CzbSvsrlEEDVjlaeE1VPI\
RKGGAZAoBMhr+uTAdXf63fh86ufIm5qHnJ/l4OB9B7H3V3thDDMCkFqyAFJQlPv0ffL9J8rmCxEi\
ku9IxoAnBuCHnB9wa69bYRAMCBPCNFO80RHRSLstDb3+1AtJE5MgQoTFaEHX6K6YO2SuZozjeo6D\
QTDAHGaGS3Qp4dOfptWkP57WzblTzv0VBZhjYuCorkbPwUNgCJdaFnW+Ig39rr8B3/94EZsOfK28\
btmyZdh08Bv0Gz5CeWz0wHT8LKO/8v3mQ0fx/Y8XtW1gBFEJnanp/WCOiYE5OhY9Bw/RjEu9E5mb\
PChUMQASdSBzh8zVhLO70+9GnFGaRpJ37aqvGz9qPMZsGAMASI5KRrhB2wtweLfheHjIw+iT0Qe3\
9roVXaO74uEhD3vc6bt8xHI8OvRRANL0cEZShs9pXvdQS/rhb4sUuUqYPfVeGM1RqKmsQHHRUWUj\
R+l3x3DiwD706pyAW/r3BQD8LKM/Yor248XpU/DfPV8o9zKazbgt6zqlEjh2UD/cetvtCDdKPzSF\
G03InjJNCZ3FRUcxZ10Osqfei6LdeY12IvtqC0MUCngSCFEHoj4hRA5fw7sNV04AmTFwhiaUrdq3\
CjaHDSXflyhVQzW5ildaJa0D9HWm7/tF7ytnBMuvLSwrVKZ5GfRI1tSJHzL59BB1s+frJk7GD98c\
xtHPd0kXiQLiuiRh7qwRuGbHTvSIj9OcFawQBVw3cTIc1dVIT0vFffMewZcbN6DObtes7XNUV8Mc\
E6OZ7hVdLggGgybs+XOyCVEwYwWQqIOS19jlnclTTgC5O/1uzdo7eXrYFGZSzu8FpApenDEOGUkZ\
2Pz9ZrhEF7ac2OLxfeTefqv3rYZLdEGAoLSE4TQvedLcFinyejxjZCQG3zIeEx7+I0bP+K1SHbxu\
4mScOLAPPeLj0POaDJijY2GOiUHylX0AQUC4yYTsqfdi8C3jYYyMRLeYSGUTh/vaPvn8XzncydeM\
evA3msDHRs8U6rgLmIIed8U13/tF72P1vtVKzz6rw+pxVy4A5fcFpQX45PtPNO1k1LuN5R3C6unc\
94vex9P5T0OECHOYGQnmBL939XIXMHniaYdtU7tu5R3Fsn7DR2jatbi3jqm22TzeqzntXpqzi7k5\
+HlH7YUVQKIOaNW+VbA6rKhwVGB4t+HoGt0VGUkZyno/ee3d3el3Y8bAGVh7aK0yTZxgTlACWSdz\
JwDQtIdR79pde2itMnVsDDNq1vQ1deoHdwGTJ56aLrtvGNm0egWen3obNq1eAUCq0pljGnaoy+cE\
yxU6eaoXooiyE9953Xwiry/0dN6vOzZ6plDHAEgUwryFLHlqV4SIwrJCbJ28FZ+f+VzTIka2at8q\
nK08C6vD2ug0j28ufKP86mk6d8bAGbAYLYgzxmHukLma8TQV8Dg9TJ74ClZyqDv6xf9BdLmUo98G\
3zIec9blaE4EyVv/Fmzny7DjrXWoslmVe8inhbjf88C2zc0Kdf7sYiYKZtwEQhTC5E0cq/at0kyj\
PjzkYazatwoCBCVgyZU6980eclgEgIpa7eL5cT3HYcuJLRjXc5xmg4nM/TF5ylie2lVPNbvzdD8i\
X5sr5CbQgsEAURSR1PNKzfMTHv4jrrhqgKZZdJ3DoTSLjuuS1GhqV11xbCrQtWUDaKL2xgogUQiT\
w5s6xAHaPoGAFMyyu2VrWsTI1brh3YbDYrRAgACX6NJU7JaPWI4D0w5g+YjlXquN6sczkjKUJtBs\
80Ktrr4JtLx0vdpma3SJvJEDkM4KTu7VW9kI4qmy15yqX1NnAhOFEgZAohD28JCHld58QOMpYbk1\
y9nKs8pUsBzI5CnawrJC5E3Nw2PDHvM4Jave5dvUiR6FZYWaJtBErSl7yjTEdUlCv+tv8BraUtP7\
KYFv1IO/kUKiKCIq1uKxaudrKtd9py/X/VFHwilgohDmPo2qDmNyyxeX6IJBMCjBTl6fl5GUAZSh\
yTV48j3jjHEeA2JGUgZKT5QiIykDmcmZPqd9iS6HP733iouOAqIIZ20tACm0ydO2zZ3ClSt+eTlv\
Kq9rzR2/RIHECiBRB+LpzOCu0V3x6NBHPVb+PFUE3St88j3mDpnrcUpXXfXjtC+1NW/999RHuKmP\
aVNX+Jo7hStX/CAKnPqlDocBkKgD8XRmsHsga+7ZvE2FOu7mpfYkh7jcv72sCYHqI9y8HdMmh8PU\
9H7KY74aOsvhMXvqvZz6pQ6HjaAp6LExauhis2dqDeqpWwDI/dvLEF0uTRNmX9O7B7ZtRl7Om6ip\
rAREUfO6tmro3FL8vKP2wgogUQfUVBPm9sJmz9Qa3M8Odq/wbVq9Arl/exmp6f08ru2Tj5KDKDY6\
05cbO0ivGACJOqBgCV6cHqbLdWDbZjhqqmCOjlVCmvvO3aLdeZrG0O7kk0LM0bGNzvT1tAuY5/yS\
HnAXMFEH1FQT5vbCZs90ueTqXVyXJK+tWsLCI1BX62h0yofMn93D7u+prjgSdUQMgEQdEIMXdRTq\
Ni6efLlxA+oc9kanfMhrAlPT+6G46GizTu9o6j2JOgJuAqGgx0XRROSNt80f8uYOuSWMvM4v2I9y\
4+cdtReuASTqQIJl8wdRe/F2koe8uSM9K1sT/tjPj0jCKWCiDsT9JJBAYfsXCjRv6/44tUskYQWQ\
2sWLL76Inj17wmw2Y+jQofjyyy8DPaQOKVh23QbLLmQiNV/n/hLpDQMgtbn33nsPCxYswJIlS7Bv\
3z4MHjwYY8eORVlZWaCH1uG05VFszZleDpYgSkREnnETCLW5oUOH4tprr8X//u//AgBcLhfS0tLw\
0EMPYdGiRU2+nouig8OYDWNwtvIsukZ3xdbJWwM9HKIOiZ931F5YAaQ25XA4UFBQgNGjRyuPGQwG\
jB49Grt37w7gyKi5WNUjIuo4uAmE2tT58+fhdDqRnJyseTw5ORlHjx71+Bq73Q673a58b7PZ2nSM\
5B/2FiQi6jhYAaSgs3TpUlgsFuUrLS0t0EMiIiLqUBgAqU116dIFYWFhKC0t1TxeWlqKlJQUj69Z\
vHgxrFar8nX69On2GCoREZFuMABSmzIajcjMzERubq7ymMvlQm5uLrKysjy+xmQyIS4uTvNFRERE\
rYdrAKnNLViwAPfddx9++tOf4rrrrsMLL7yAyspKPPDAA4EeGhERkS4xAFKbu+eee3Du3Dk88cQT\
KCkpwTXXXIMtW7Y02hhCRERE7YN9ACnosS8WEekFP++ovXANIBEREZHOMAASERER6QwDIBEREZHO\
MAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBER\
EZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwD\
IBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER\
6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMAAS\
ERER6QwDIBEREZHOMAASERER6QwDIBEREZHOMABSiz3zzDO4/vrrERUVhfj4eI/XnDp1ChMmTEBU\
VBSSkpLwhz/8AXV1de07UCIiItIID/QAKHQ5HA7cddddyMrKwrp16xo973Q6MWHCBKSkpOCLL77A\
2bNnMW3aNEREROAvf/lLAEZMREREACCIoigGehAU2t544w3MmzcP5eXlmsc/+eQT/OxnP0NxcTGS\
k5MBAC+//DIWLlyIc+fOwWg0+nV/m80Gi8UCq9WKuLi41h4+EVHQ4OcdtRdOAVOb2b17NwYOHKiE\
PwAYO3YsbDYbjhw54vV1drsdNptN80VERESthwGQ2kxJSYkm/AFQvi8pKfH6uqVLl8JisShfaWlp\
bTpOIiIivWEAJI1FixZBEASfX0ePHm3TMSxevBhWq1X5On36dJu+HxERkd5wEwhpPPLII7j//vt9\
XnPllVf6da+UlBR8+eWXmsdKS0uV57wxmUwwmUx+vQcRERE1HwMgaSQmJiIxMbFV7pWVlYVnnnkG\
ZWVlSEpKAgBs27YNcXFxuPrqq1vlPYiIiKj5GACpxU6dOoULFy7g1KlTcDqd2L9/PwCgT58+iImJ\
wZgxY3D11Vfj3nvvxYoVK1BSUoLHHnsMc+bMYYWPiIgogNgGhlrs/vvvx9///vdGj3/22We46aab\
AAAnT57E7NmzsWPHDkRHR+O+++7DsmXLEB7u/88ebItARHrBzztqLwyAFPT4gUhEesHPO2ov3AVM\
REREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6\
wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgERE\
REQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMM\
gEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIRERE\
pDMMgEREREQ6wwBIREREpDMMgEREREQ6wwBIRES6d3jXGbz5p89xeNeZQA+FqF0wABIRke7t23IC\
FRfs2LflRKCHQtQuGACpRU6cOIHp06ejV69eiIyMRO/evbFkyRI4HA7NdQcPHsQNN9wAs9mMtLQ0\
rFixIkAjJiLybsi4nojtZMKQcT0DPRSidhEe6AFQaDp69ChcLhdeeeUV9OnTB4cPH8bMmTNRWVmJ\
5557DgBgs9kwZswYjB49Gi+//DIOHTqEBx98EPHx8Zg1a1aA/wRERA0GjOiGASO6BXoYRO1GEEVR\
DPQgqGN49tlnsWbNGnz33XcAgDVr1uDRRx9FSUkJjEYjAGDRokXYuHEjjh496vd9bTYbLBYLrFYr\
4uLi2mTsRKRPh3edwb4tJzBkXM+gCID8vKP2wilgajVWqxWdOnVSvt+9ezdGjBihhD8AGDt2LIqK\
inDx4sVADJGISMPftX/cJEIdDQMgtYpjx47hr3/9K379618rj5WUlCA5OVlznfx9SUmJ13vZ7XbY\
bDbNFxFRS/kKb/6u/eMmEepoGABJY9GiRRAEweeX+/TtmTNnMG7cONx1112YOXPmZY9h6dKlsFgs\
yldaWtpl35OIQlNrVN58hbcBI7ph2l+GNzn9y00i1NFwDSBpnDt3Dj/++KPPa6688kplWre4uBg3\
3XQThg0bhjfeeAMGQ8PPFNOmTYPNZsPGjRuVxz777DOMHDkSFy5cQEJCgsf72+122O125XubzYa0\
tDSuiSHSoTf/9DkqLtgR28mEaX8Z3qJ7BNs6P1+4BpDaC3cBk0ZiYiISExP9uvbMmTO4+eabkZmZ\
iddff10T/gAgKysLjz76KGpraxEREQEA2LZtG9LT072GPwAwmUwwmUwt/0MQUYcxZFxPJbw1h3vo\
C/bgR9TeOAVMLXLmzBncdNNN6N69O5577jmcO3cOJSUlmrV9v/jFL2A0GjF9+nQcOXIE7733Hlat\
WoUFCxYEcOREFEr8naJ1xzV7RL6xAkgtsm3bNhw7dgzHjh3DFVdcoXlOXlVgsViwdetWzJkzB5mZ\
mejSpQueeOIJ9gAkojbnb+UwlKaHiVoT1wBS0OOaGCJqC4d3ncGunCKILlzWGsPWxM87ai+cAiYi\
opDSWj359m05AdEFCAZwdy/pDgMgERGFFH/W9/kTEuXWLiOmpHP6l3SHawCJiCjoqdfq+bO+Tx0S\
vYW71todzHWEFIpYASQioqDhrXLnHujUO4M9vSaldzwEg/Srr/u2daNpomDFCiAREQUNb5U7T1U/\
ufLmqHHCXlWnBLD8jcdhr64DRKDkeLnmvvkbj2uqdfkbj8NeVYf8jcdbXL1raa9CokBiACQioqDh\
LUx5mq6VQ50pKlw5pm3flhOwV9UB0G7ukJ9z1Dh9Tg23ZDqXjaYpFDEAEhFR0PAVptzD2ZBxPZG/\
8TicdS44aqRrUnrHo+JiKcIjDBg+uS+Kvy3Hrpwi9MlMVq4PjzDAUePE4V1nMGxib03g9GftoPt4\
UnrHo+R4OdcAUkjhGkAiIgo4f9biua+1GzCiG4zmMNQ5XMoUcMnxckAEImMiMGBENxwrKIXoAr79\
qhS7copgr6qD09lwvft6QnlnsD/TufJ4vv2qVJleJgoVDIBERBRw7uHOPRAe3nUGjhonTFHhSOkd\
rzw3ZFxPhEcYAEGq/rkHuD6ZyRAMQHi4AaJLeq8uabFeQ15zjp6T3ys8nP+UUujhf7VERBRw7sHN\
PRDKa/uM5jCUHC/XTNNGxkYAInCsoBQANAEutW88YuJN6HVNIoT6f/FqKhyNQp6/u4HV18lhcfhd\
fRHbyYRhE3u37l8KURtiACQiooBraipW/b2n5yAAoguaaVj5qLeKC3aUHC/HiCnpXit/+RuPa6Zx\
/WlH423sRKGAm0CIiCjoyJtB5CA2ZFxPzVm98nNrF+wCIE3x1tW6NPdQH/VmjjUqm0HU/QO9tW+R\
28PsXF+kvB/Ali/UcQiiKIqBHgSRLzwcnUi/3vzT56i4YEdsJ5MmAKqfAwBTVDiM5jDNFLJ6d+6u\
nCJpDaAAxCaYkNI7XtkgIhiktYIlx8uR0jsep478qLSSAeDxvdsKP++ovXAKmIiIgpY83ave+KF+\
zhQVDlNUOIZN7K1Mw+a89hEqLtjx/f5zqLhox+cffIsuabHKZhB55+6xM4cASFPHp478CADa8CdI\
wZLVPuqIWAGkoMefiInIVyUQALauO4JjBaXYeuhtfJT3OiYOm4nRg6coz8uvO7zrDPI3Hse/v3gL\
H+1Zi1szp+H2rAdQV+cCRCA8omEque+1yRgzvX+7/RkBft5R+2EFkIiIgp5c7ZMbOLs7ViBV9D7K\
ex0AsDH/NWzbv155Xj4TeMCIbvhk77v4aM9aAMAnBW+i6IcDgChNBYdFNPyzKB8jR9QRMQASEVHA\
NdWGRW76rD7zV61PZjL6dBuIu276jfLYR3vWKiHw+wPnsHbBLky64Tf4Z94ryjV3Zv8a6WmDYYoK\
x4gp6Rg2sbcyrSxP/frbIoYolHAXMBERBZz7EWyezuSVj3KrrqjF2gW7MGxib+W5MdP7Sz3/tvwK\
3dIT8MIrSwFAqfTdcs1UfPLlO8r3ADDv14uR0WkCKi7YlZNDADRq59Kc4+GIQgUrgEREFHBNNYKW\
OWrqUFcrHeW2K6dIc1KI3POvf9Q43O1WCVz4xh2a8Hdn9q+x8uW/NDm1LI+tqWuIQg03gVDQ46Jo\
Iv1RVwCLvy3HsYJShIUbUOdwAUL9RWJD+xdHjRP2qjoIBsBoDoe9qg7b9q/XhD7Z7UNn4JZrpgIC\
0PenycrOX1NUOGY8P8LjeJrahNJa+HlH7YUVQCIiCjrq0zXkfn11tS7EdjLhxqnpuHFqOkxRUtCr\
uGBHrd2J2E4m9MlMhrNO2sV7yzVTEWWK1dw3yhQrhT8AEIFv95ai1u4EADhrXV7X+rlXKLkukEId\
AyAREQVUU2GqT2YyBINUrZNDYfG35ZpmzS6nCEeNE99+VSpVCQFsO7AeVfYKzb2q7BWa3cHya+Wq\
onwcnPt4BozoppwCIlcnPU1RE4UKBkAiIgqopsLUmOn98duXRmp68h0rKG24QAAMYYIUCEXp++1H\
3sdH+Q3Tv+pKoLw72GAQGu4hSi1g1FVF9bnC7uN0rwgShRoGQCIiCqjmhCm5WhgdbwIAJPaIxY1T\
0+Fy1S9nF4Bj4n80rV5uHzoDq377bzw4ab7y2Ed71uK/rm248RfpCI8wAALQvX9nGM1hmvfbuu4I\
Xvrtdmxdd0RzKol6hzKngykUcRMIBT0uiibSN/WGELkKJxignOOr3hxyTPyP0gIGaNjwEdtJCoz/\
3P5Go1YwfQ2jlXOCw8OlMChXBNXHws1ZMxJA4w0hrblBhJ931F5YASQiooDzVUXzNPUqrwuUN4cA\
wPGzhzTh746sWcqGj4oLdphjjRib+QvcPnSGcs0LryxVzgSGKN3LWefShj/UB8N67hVLTgdTKGIA\
JCKiduMt6MkhT93bT+Zp6jW1bzyMZunEjr4/lcJg75SBmJj9AABg2bJl+OcXr8AU1XDewblTFXA5\
RdxyzVQlBN6aOQ29UwciPMKAcKNU/RNd0o5gwSBNMZuiwhEWYcDhXWeUaqQ8lsO7zmh2LBOFCk4B\
U9DjlAhRx+FtulRu5Cy64HUqVf1aQKrqyX0AzbFGnD9dgT6ZySip/i+qixJQV+eCQRCU9YHhEQal\
WigIwLHiQ+iTOhDGSGnjh1zFy994HPZqaUOJ+r3Uv5erj63dF5Cfd9ReWAEkIqJ24226dMCIbhgx\
Jd3nVKr6tfLvASmQnTtVAdEFnDryI1CcJAU9EXC5RKmFzLXJGH5XXwj1/+qJItC760CIgHL+r6NG\
6gdoNIcBorS+UP1e6t/3yUzmtC+FNFYAKejxJ2Ii8kaekq20OuByijCECYgwhcFRXQdRBAwGqQIo\
VwpTesej5Hi5cn240YBfr75JU12UN5uozyFu6v39udYf/Lyj9sIKIBERBSV/26s4apxSM2dIFT97\
VZ3S2DnCHKapFJYcL8e0vwxH7yFJEAxAr8GJALTrDPM3HleqgU1hQ2gKVQyAREQUdOQ1gd5O5lBf\
o96tm9g9VjNFO2xib0z7y3DNNO/hXWdQcrwcogsoOV4OoOHouZLj0gkj9qo6v0IddwBTqApv+hIi\
IqL2IU+pOmqcSp8/AEqVTT3Num/LCaV/HwBABGznqmE0hyG1b7zm5JABI7o1aicj7+Z980+fK1PD\
5lgjKi7aER5h8Bjq3Kd85S+iUMMKIBERBQ05pAHSDtsRU9IxbGJvj1U2ufp249R0pRWMs87ldUpW\
Xa2Tz/Y9VlCKigt25dfzpysAEYiMifAY7DjlSx0FK4BERBQ0vG3AcA9j7pU4uRoYFm5AZExEo7Do\
abOG/BrBAKl9zPFypRLoayeyfB+iUMYASEREQcPfKVV1JU6u5u3bckLpB1j8bblyTu++LSdQfakW\
dQ4X8jceV+7vHuZKjpc3mjoGoGn+LIdDTvtSqOMUMLXYbbfdhu7du8NsNqNr16649957UVxcrLnm\
4MGDuOGGG2A2m5GWloYVK1YEaLRE1JG4b76QQ+C5k1I/wG/3lirBreKCXWkArSZv/ACgbDjxNLUr\
30OeJub0L3UEDIDUYjfffDPef/99FBUV4R//+AeOHz+OyZMnK8/bbDaMGTMGPXr0QEFBAZ599ln8\
+c9/xquvvhrAURNRR+B+/Jq8I1hNfXZw35827Ap2p54K9jS1y+bP1BGxETS1mn/961+YOHEi7HY7\
IiIisGbNGjz66KMoKSmB0WgEACxatAgbN27E0aNH/b4vG6MSUVPkRs4QgPBwA8IiDBg2sbdmqtZb\
02b3x1u7uXNz8POO2gvXAFKruHDhAt555x1cf/31iIiIAADs3r0bI0aMUMIfAIwdOxbLly/HxYsX\
kZCQEKjhElEH48/pHfJUbv7G4z5bubivLyTqiDgFTJdl4cKFiI6ORufOnXHq1Cl89NFHynMlJSVI\
Tk7WXC9/X1JS4vWedrsdNptN80VE5IunKWH35tHu5wd7W8vH5s6kBwyApLFo0SIIguDzSz19+4c/\
/AGFhYXYunUrwsLCMG3aNFzuqoKlS5fCYrEoX2lpaZf7xyIiHVCHPrmKtyunSAmBckj01ldQ5h4m\
iToirgEkjXPnzuHHH3/0ec2VV16pmdaV/fDDD0hLS8MXX3yBrKwsTJs2DTabDRs3blSu+eyzzzBy\
5EhcuHDB6xSw3W6H3W5XvrfZbEhLS+OaGCLySV4HKIe7XTlFEF1SQ2l5t683gVz3p8Y1gNReuAaQ\
NBITE5GYmNii17pcUpsFObxlZWXh0UcfRW1trbIucNu2bUhPT/e5/s9kMsFkMrVoDEQUOIEOUZ7W\
AfrbtJnr/khvWAGkFtmzZw/27t2L7OxsJCQk4Pjx43j88cdRWlqKI0eOwGQywWq1Ij09HWPGjMHC\
hQtx+PBhPPjgg1i5ciVmzZrl93vxJ2Ki0KCuwDVVcQs2vsJrewZbft5Re2EFkFokKioK//znP7Fk\
yRJUVlaia9euGDduHB577DGlemexWLB161bMmTMHmZmZ6NKlC5544olmhT8iCh3tcUza4V1nkL/x\
OAA0avNyOXydQMLqIHVErABS0ONPxEQkU/r9wb+1fa2BFUDqiFgBJCKikDFkXE+lAthebVr8PZ+Y\
KJQwABIRUchgGCNqHewDSERERKQzDIBEREREOsMASERERKQzDIBEREREOsMASERERKQzDIBERERE\
OsMASERERKQzDIBEREREOsMASERERKQzDIBEREREOsMASERERKQzDIBEREREOsMASERERKQz4YEe\
AFFTRFEEANhstgCPhIiobcmfc/LnHlFbYQCkoFdRUQEASEtLC/BIiIjax48//giLxRLoYVAHJoj8\
MYOCnMvlQnFxMWJjYyEIQru/v81mQ1paGk6fPo24uLh2f//LFcrj59gDJ5THH8pjt1qt6N69Oy5e\
vIj4+PhAD4c6MFYAKegZDAZcccUVgR4G4uLiQu4fE7VQHj/HHjihPP5QHrvBwCX61Lb4XxgRERGR\
zjAAEhEREekMAyBRE0wmE5YsWQKTyRToobRIKI+fYw+cUB4/x07UNG4CISIiItIZVgCJiIiIdIYB\
kIiIiEhnGACJiIiIdIYBkIiIiEhnGACJvDhx4gSmT5+OXr16ITIyEr1798aSJUvgcDg01x08eBA3\
3HADzGYz0tLSsGLFigCNuLFnnnkG119/PaKioryeKnDq1ClMmDABUVFRSEpKwh/+8AfU1dW170A9\
ePHFF9GzZ0+YzWYMHToUX375ZaCH5NGuXbvw85//HKmpqRAEARs3btQ8L4oinnjiCXTt2hWRkZEY\
PXo0vv3228AM1s3SpUtx7bXXIjY2FklJSZg4cSKKioo019TU1GDOnDno3LkzYmJiMGnSJJSWlgZo\
xA3WrFmDQYMGKc2es7Ky8MknnyjPB+u4PVm2bBkEQcC8efOUx0Jp/BSaGACJvDh69ChcLhdeeeUV\
HDlyBCtXrsTLL7+MP/3pT8o1NpsNY8aMQY8ePVBQUIBnn30Wf/7zn/Hqq68GcOQNHA4H7rrrLsye\
Pdvj806nExMmTIDD4cAXX3yBv//973jjjTfwxBNPtPNItd577z0sWLAAS5Yswb59+zB48GCMHTsW\
ZWVlAR2XJ5WVlRg8eDBefPFFj8+vWLECq1evxssvv4w9e/YgOjoaY8eORU1NTTuPtLGdO3dizpw5\
yM/Px7Zt21BbW4sxY8agsrJSuWb+/Pn4+OOP8cEHH2Dnzp0oLi7GnXfeGcBRS6644gosW7YMBQUF\
+OqrrzBy5EjcfvvtOHLkCIDgHbe7vXv34pVXXsGgQYM0j4fK+CmEiUTktxUrVoi9evVSvn/ppZfE\
hIQE0W63K48tXLhQTE9PD8TwvHr99ddFi8XS6PHNmzeLBoNBLCkpUR5bs2aNGBcXp/kztbfrrrtO\
nDNnjvK90+kUU1NTxaVLlwZsTP4AIH744YfK9y6XS0xJSRGfffZZ5bHy8nLRZDKJ69evD8AIfSsr\
KxMBiDt37hRFURprRESE+MEHHyjXfPPNNyIAcffu3YEaplcJCQni2rVrQ2bcFRUVYt++fcVt27aJ\
N954ozh37lxRFEPv751CEyuARM1gtVrRqVMn5fvdu3djxIgRMBqNymNjx45FUVERLl68GIghNsvu\
3bsxcOBAJCcnK4+NHTsWNptNqaS0N4fDgYKCAowePVp5zGAwYPTo0di9e3dAxtRS33//PUpKSjR/\
FovFgqFDhwbln8VqtQKA8t94QUEBamtrNePv168funfvHlTjdzqdyMnJQWVlJbKyskJm3HPmzMGE\
CRM04wRC5++dQlt4oAdAFCqOHTuGv/71r3juueeUx0pKStCrVy/NdXKYKikpQUJCQruOsblKSko0\
4Q/Qjj8Qzp8/D6fT6XFcR48eDciYWkr+O/T0ZwnU3683LpcL8+bNw/DhwzFgwAAA0viNRmOj9aPB\
Mv5Dhw4hKysLNTU1iImJwYcffoirr74a+/fvD+pxA0BOTg727duHvXv3Nnou2P/eqWNgBZB0Z9Gi\
RRAEweeXe9A4c+YMxo0bh7vuugszZ84M0MglLRk/UVPmzJmDw4cPIycnJ9BD8Vt6ejr279+PPXv2\
YPbs2bjvvvvw9ddfB3pYTTp9+jTmzp2Ld955B2azOdDDIZ1iBZB055FHHsH999/v85orr7xS+X1x\
cTFuvvlmXH/99Y02d6SkpDTamSd/n5KS0joDdtPc8fuSkpLSaHdtW4+/KV26dEFYWJjHv9dAjaml\
5PGWlpaia9euyuOlpaW45pprAjSqxn73u9/h3//+N3bt2oUrrrhCeTwlJQUOhwPl5eWaalSw/P/C\
aDSiT58+AIDMzEzs3bsXq1atwj333BPU4y4oKEBZWRmGDBmiPOZ0OrFr1y787//+Lz799NOgHj91\
DAyApDuJiYlITEz069ozZ87g5ptvRmZmJl5//XUYDNqieVZWFh599FHU1tYiIiICALBt2zakp6e3\
2fRvc8bflKysLDzzzDMoKytDUlISAGn8cXFxuPrqq1vlPZrLaDQiMzMTubm5mDhxIgBpejI3Nxe/\
+93vAjKmlurVqxdSUlKQm5urBD6bzaZUrAJNFEU89NBD+PDDD7Fjx45GyxkyMzMRERGB3NxcTJo0\
CQBQVFSEU6dOISsrKxBD9snlcsFutwf9uEeNGoVDhw5pHnvggQfQr18/LFy4EGlpaUE9fuogAr0L\
hShY/fDDD2KfPn3EUaNGiT/88IN49uxZ5UtWXl4uJicni/fee694+PBhMScnR4yKihJfeeWVAI68\
wcmTJ8XCwkLxySefFGNiYsTCwkKxsLBQrKioEEVRFOvq6sQBAwaIY8aMEffv3y9u2bJFTExMFBcv\
XhzQcefk5Igmk0l84403xK+//lqcNWuWGB8fr9mtHCwqKiqUv1cA4vPPPy8WFhaKJ0+eFEVRFJct\
WybGx8eLH330kXjw4EHx9ttvF3v16iVWV1cHeOSiOHv2bNFisYg7duzQ/PddVVWlXPOb3/xG7N69\
u7h9+3bxq6++ErOyssSsrKwAjlqyaNEicefOneL3338vHjx4UFy0aJEoCIK4detWURSDd9zeqHcB\
i2LojZ9CDwMgkRevv/66CMDjl9qBAwfE7Oxs0WQyid26dROXLVsWoBE3dt9993kc/2effaZcc+LE\
CfHWW28VIyMjxS5duoiPPPKIWFtbG7hB1/vrX/8qdu/eXTQajeJ1110n5ufnB3pIHn322Wce/47v\
u+8+URSlVjCPP/64mJycLJpMJnHUqFFiUVFRYAddz9t/36+//rpyTXV1tfjb3/5WTEhIEKOiosQ7\
7rhD80NQoDz44INijx49RKPRKCYmJoqjRo1Swp8oBu+4vXEPgKE2fgo9giiKYjsWHImIiIgowLgL\
mIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiI\
dIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJ\
iIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhn\
GACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiIiEhnGACJiIiIdIYBkIiI\
iEhn/j+T4Nec091cJAAAAABJRU5ErkJggg==\
"
  frames[1] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAOQpJREFUeJzt3Xl4lPW9///XJGQlzCSQjSUsoo0Lm6YgAaQiKdFaKy2odFGs\
LJUiPQr1CFWx/arFAx43jgUpVvRYRfQUrBUVCgI/NYAiUUBJlbJJmCBKZiCQyTL3749hbjIkbEoy\
y+f5uK65YO65Z/K+9XJ85f1ZbodlWZYAAABgjLhwFwAAAICWRQAEAAAwDAEQAADAMARAAAAAwxAA\
AQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAE\
AAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAA\
AMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAA\
AMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAA\
DEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAw\
DAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMO0CncBwLfh9/tVXl6uNm3ayOFw\
hLscADgly7J08OBBdejQQXFx9GEQHgRARLXy8nLl5eWFuwwAOGO7d+9Wp06dwl0GDEUARFRr06aN\
pMAXqdPpDHM1AHBqXq9XeXl59vcXEA4EQES14LCv0+kkAAKIKkxbQTgx+QAAAMAwBEAAAADDEAAB\
AAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQA\
ADAMARAwwftPS4/2CPwJADAeARAwwTuPSp7dgT8BAMYjAAImGHSH5MoL/AkAMF6rcBcAoAX0HRN4\
AAAgOoAAAADGIQACAAAYhgAIxApW+gIAThMBEIgVrPQFAJwmAiAQK0610pcOIQDgKAIgECv6jpHu\
2Hzi1b6n0yEkJAKAEQiAgAnef1ryHZISUqWaQycOeAwjA4ARCICACVbcL1UfkGqPSEcOSCvvb7rT\
13AYmW4gAMQsNoIGYt37TwfCnyTJklIypFpfIAi+PiVwODhs3HDD6Ed7HOsGsok0AMQUOoBArDja\
sSv9630hz7Xi/tDzan1S3WGVuuslWdLSO5vu8nH7OACIWQ7LsqxwFwF8U16vVy6XSx6PR06nM9zl\
hNejPTRv5TbNK5UmPTBXo7+eFejghXBIkp4t9Wn2+hqNL0jU+ILEQNC7Y3OLlwyYiO8tRAI6gEA0\
azBPrzR7hOaVSkrL0ezZs/XstrZNvMGyw58kzdvoV+mhTLp8AGAYAiAQzRqs2u3z8z9o0gNzA8cr\
tmj24hI9W1oTcvqzpTV2+JOkSWN+rj4Pbwud48fiDwCIeQRAIJodN09v9OjRmtTzkFRfI1l+zV5f\
Y4fA0PDn0KSfDNToP/yl8WeyFQwAxDwCIBCt3n86ENIG3RHSwRvdK0GT+iXaz2evr9EVz1aFdv5+\
MkCju399rMvXsOvH4g9EmOfX7tTAh1bq+bU7w10KEDNYBIKoZvRk6uA2LSkZkqXA+o4r7pWW3SPV\
Hm403Bs0qV+iRvc5GhBTMqS7dhz7LBaDIAINfGil9lQeUcf0FL079Ypwl/OtGf29hYhBBxCIVsFO\
naXAPn9HDtjhT5JG90mUM8kR8hZnkuNY+JMC7wl2/VIyAncLYe4fIsyEy7urY3qKJlzePdylADGD\
AAhEq+C9f4feKyVnBG7zdjT8SYE5f15faIPf67MaLQzRyvsDn5WYFgiSzP1DBGg47PuL/l307tQr\
9Iv+XU563qk+B8AxBEAg2vUdEwiBtUfsQ8cP/zbsBDZcGCIptAvI3D9EiDmrtmlP5RHNWbXtW513\
up8DmIYACMSCdx5VYCy4ia1e+iVq5ejWjRaGhITAlfeHLihhKxiE2cmGfX/z4kZ1n/a6fvPixlMO\
DzN8DDSNRSCIakymPur9p6WV9+vZ9ZWavbZKsvySjlvwoYbh0CHFxWvSpSkafUnK0e6hdWwRCItC\
EMG6T3td9ZYU75C2zbg63OWcMb63EAnoAALRLNipk1RavESz1/tOGP4Ul6DRfRIDnUCHJH+dZq/3\
qfRAqiRLcsQfG/5lOBgR7OpeHRTvCPx5POb8AaeHDiCimvG/SR+3Fcy8kv2a9/4RTeqfotG94o+d\
12Nk4M/Nr0iSnv0kQbNLqjT+xus0/sffa3I/QSBSPL92p+as2qYJl3e3F4Icfyz4vMpXp8ojtRG9\
ZYzx31uICHQA0WzmzJmjXr16yel0yul0qrCwUG+88Yb9enV1tSZOnKh27dopLS1NI0aMUEVFRRgr\
jkLHbQUz/uJ4zf/R0fCXkBro6vUYKY18Wtq9LvAeR7xGX3+t5t/QQeMvSSD8IeIFF3Lcs2SzLrj3\
DTvsNVzcEXwuiTl/wGmgA4hm89prryk+Pl7nnXeeLMvSs88+q1mzZmnjxo266KKLNGHCBL3++uta\
sGCBXC6XbrvtNsXFxendd9897Z/Bb9JHvf+0tOJ+qd4XCIMJSYFNofuOkV4ZI21ZLLXvJR3YcWzT\
6CMHjv7FOrYhNBCBnl+7U/csOTYXNRjwHnz9E1XX+nVN78BQ8Osfl+vqXh30xE8vDlepp4XvLUQC\
AiBaVNu2bTVr1iyNHDlSWVlZeuGFFzRyZGB4cuvWrbrgggtUUlKi/v37n9bn8UV6Gv7QVrLqA93A\
JGdgr79WqVLrdlLVV1Ld4cA+gkPvpRuIiBPs9rVrnagPPtyo1u27q3VSK/22OF/3Ltms4P/AUhLi\
dKTWr/SUBC24Nlt9+vQJZ9knxfcWIgFDwGgR9fX1WrhwoaqqqlRYWKgNGzaotrZWRUVF9jnnn3++\
OnfurJKSkhN+js/nk9frDXkY7XS2a7nox4Hwd9GPAw0/KdAhvGOzVPxAYAg5GP48u9kIGhElOLS7\
5e2/qcOmZ6XPVqvySK3mrNomR4Mb3RypDSx+2vP+mxr0wxt0y9QZYaoYiA4EQDSrTZs2KS0tTUlJ\
Sbr11lu1ePFiXXjhhXK73UpMTFR6enrI+Tk5OXK73Sf8vBkzZsjlctmPvLy8Zr6CCHc6oW3k09IP\
ZgXmAHYfGgh8V9wbeC14N5G+Y1j5i4g04fLuSj+8R9an/5Qk1W9+Q/6yVdrrOSL/ceNXhzatkHfD\
a6qt92vR8wtUWlra8gUDUYIAiGaVn5+v0tJSrVu3ThMmTNDo0aP1ySeffOPPmzZtmjwej/3YvXv3\
Waw2Cp1uaAsGxd3rjgW+4zUMg0CE+EX/Lip9Yry+P3K0Pin3aq/niCrWLpH34xUh5x3atEIHP3zN\
ft6+cLgmvvk128EAJ0AARLNKTEzUueeeq4KCAs2YMUO9e/fW448/rtzcXNXU1KiysjLk/IqKCuXm\
5p7w85KSkuxVxcGH0YKhTTr5UDDdPUS5za0vVurFP7S7fgc/fE2HNgVC4PHhr80l16i2+2BuAQec\
BAEQLcrv98vn86mgoEAJCQlaseLYb/FlZWXatWuXCgsLw1hhlDrVUDDdPUS5gi4ZSus5VG0uucY+\
dvDD1+R+8XeNwl9az6FKSYhTvCPwPgCNtQp3AYhd06ZN01VXXaXOnTvr4MGDeuGFF7Rq1Sq99dZb\
crlcGjNmjCZPnqy2bdvK6XRq0qRJKiwsPO0VwGhg0B3HVvACMeb5tTv12kflkqS0nkMlyQ59Vs1h\
+7xg+JOOLQrZsPNAS5YKRA0CIJrNvn37dNNNN2nv3r1yuVzq1auX3nrrLX3/+9+XJD366KOKi4vT\
iBEj5PP5VFxcrD/96U9hrjpK9R1Ddw8xpeGdPuas2qaG6z3Seg7Voc0rQsKfIzHVDn9B6SkJbAgN\
nAD7ACKqsZ8WEJsGPrRSeyqP2Pf8/fvRDqDUeM5fUMMOoKSIvR0c31uIBMwBBABElOfX7lSVr04O\
SfVWYBi3V0eXpMbhz5GYav+94cIQifl/wMkQAAEAYff82p0a+NBKe+i38kitXCkJ9m3f/j5pkM7z\
bGi04CP3p39stDAkGALX/OvLFr8OIFoQAIFIdTp3+QBiRPCOH8F5fx3TU/Tb4ny9O/UK/aJ/F/3q\
3v9WyWt/tW9m03C4t6nVwYc2rZCvrj4MVwJEBwIgEKm4NRsMEgx9Ey7vrl/072LP3Rv40Eo9+NxS\
/e/TT6m23i9Ljef6SU2HQP+XO1rwCoDoQgAEIhWbN8MgwdD3i/5d7GPBruDS8mS1K/iBpKbDX1Ba\
z6FyXnKN0lMS1KnwGt17c+A9DYeXAQSwChhRjdV0QOxquBWMJN379Guy2nVrdJ5DkiUpIc6h+350\
kXokH9Dm6gzNWbVNBV0y9PrH5aq3ImdVMN9biATsAwgAiEi/6N/F7gg+v3an4jK7qd4K7O8nSZ4j\
tbIke49Av2UdPb+LJh7dRsbtOaJ6S4p3iD0BgQYYAgYARLyH3ypTvRXo9v22OF+l9w3T/cN7qGN6\
inp1dNn7BQYF5xRe3auDOqan6A/X9ggZXgZMRwcQiETvP33s1m7c4QOwuVIS9Iv+Xezh4YIuGdqw\
84D+cG0PSYFFI8GFJAQ+4MQIgEAkargCmAAIwwUXb6SnJOi3xfmSji0QCQ7xzlm1TZLsrWQIf8DJ\
MQQMRCJWAAO24MbQrZNa2d2/Kl+d0lMS7CHeCZd3D9lKBsDJ0QEEIlHfMXT+gKMmXN49ZDVwMBB2\
TE/REz+9OORcOn/A6SEAAgAi2vHz+Y4PhADOHPsAIqqxnxaAhvsFRkMHkO8tRALmAAIAotrDb5Vp\
T+URPfxWWbhLAaIGARAAAMAwBEAAQFT7bXG+Oqan2FvEADg15gAiqjGXBkC04XsLkYAOIAAAgGEI\
gAAAAIYhAAIAABiGAAgAAGAYAiDQDA4sXKjPrhiqAwsXntFrAAC0BAIg0Az2z/uz6srLtX/en8/o\
NQAAWgIBEGgGmePHqVWHDsocP+6MXgMAoCWwDyCiGvtpAYg2fG8hEtABBAAAMAwBEAAAwDAEQAAA\
AMMQAIFvgK1cAADRjAAIfANs5QIAiGYEQEAn7uid6HhTW7nQFQQARAu2gUFUO1vbKXx2xVDVlZer\
VYcOOm/lilMeP9VnZI4fp/3z/qzM8eOUMWrUN64LQOxhGxhEAjqAgJru6G0feZ3qysulVq0adfrK\
Lu2vskv7h3T7MsePU5zLJX9VlfY9+pjqysvlvv8BOoIAgIhDBxBRrbl+kz6wcKHcv/+D/bxhOHTf\
/4BUX28fb6pjKIcjcMCyTqt7CMAcdAARCegAAkcF5/DtmfJbue9/QJ9WV9uvBbt5+x59LBD+HA7F\
uVxKvfhivdq3n93lyxw/ToqPlyxLcU4nt3wDAEQkAiCM1NSCjeDKXu/rr2vRV19peoVbSzyeY2+q\
r5f/8GFJUqv27RXXurX+d/Fi3b1pk/7n97+XJGWMGqXce+9Rqw4dlDZoUEteEgAAp40ACCM1tY1L\
5vhxksOhT6ur9bKnUoqL118PHAgNgbW1kgIdwVc+/VTP7y2XHNIrlZUqLS0N+RmH3nmHrWIAABGJ\
AAgjNbXoI2PUKMU5nbogOVm/aN9B8W3SJKlxCJS0xOPRXw8ckCxJljTKEacuW7cG5g7e/0BgHqDE\
EDAAICKxCARR7WxNpj6wcKH2z/uzUi++WIfeeUf+qiot+eqrQMg76ucZGRruch0Lf8cdlyRHcrKs\
6urAHEGnU9l33M42MABCsAgEkYAAiKjWHPsASrI7eMeHvbT4OB2q99vPG4Y/W3y8HImJso4cYQUw\
gEYIgIgEDAGj2cyYMUN9+/ZVmzZtlJ2dreHDh6usrCzknOrqak2cOFHt2rVTWlqaRowYoYqKihav\
NTgknHrxxarbt88+Ptzl0s8zMuznpwx/klRfL0diIsO/AICIRQBEs1m9erUmTpyotWvXavny5aqt\
rdWwYcNUVVVln3PHHXfotdde08svv6zVq1ervLxcP/nJT1q81oxRo3TeyhU6vHGjVFcX8tpwl0tp\
8aH/qaTFxzUd/hSY95d9x+06b+UKZYwaxS3iAAARhyFgtJgvv/xS2dnZWr16tQYPHiyPx6OsrCy9\
8MILGjlypCRp69atuuCCC1RSUqL+/fuf8jPP5lDKgYULte/Rx+SvqpLq6xXndMrv8TQaBg6yO4AO\
R2Dvv7o6OZKTdX7pxpDzzuR2cgBiH0PAiAR0ANFiPEdX0rZt21aStGHDBtXW1qqoqMg+5/zzz1fn\
zp1VUlLS5Gf4fD55vd6Qx9myf96f5fd41Co7W7n3TW8y/DXsBNqrgy3LDoFthg5t9LlNrTgGACCc\
CIBoEX6/X7fffrsGDhyoHj16SJLcbrcSExOVnp4ecm5OTo7cbneTnzNjxgy5XC77kZeXd9ZqbBjU\
3A882ORq32fyOofMCbRDYG2tVF8v75tvNhrqDQ4vsxoYABApCIBoERMnTtTmzZu18FvOg5s2bZo8\
Ho/92L1791mq8FhQk3TCLWCk0IUhjpQU/bWywT6B9fVs/AwAiHgEQDS72267Tf/4xz/09ttvq1On\
Tvbx3Nxc1dTUqLKyMuT8iooK5ebmNvlZSUlJcjqdIY+zbc1/P9Jk+Ltg66f2NjHBEGj5qgN3DPF6\
tbtvX4Z6AQBRgQCIZmNZlm677TYtXrxYK1euVLdu3UJeLygoUEJCglasOLYwoqysTLt27VJhYWFL\
l2sbPGWybujaRfHpLv08M1PDXS4lHx22Dg4TO1JSAiHQlS7V1+uGvE4a9r/PMdQLAIgKrAJGs/n1\
r3+tF154Qa+++qry8/Pt4y6XSykpKZKkCRMmaOnSpVqwYIGcTqcmTZokSXrvvfdO62ec7TuBZI4f\
Zwe40tJStZ48pckVvMFbvqm+Xp/W1mjIgw8S/ACcFlYBIxLQAUSzmTNnjjwejy6//HK1b9/efrz0\
0kv2OY8++qh++MMfasSIERo8eLByc3P1t7/9rcVr3T/vz6orLw+Zv9enTx9ljh+nOJdL/qqqRos7\
4tLSFOdyhYQ/9vwDAEQDOoCIas3ZAQxqah+/E+3tx55/AE6FDiAiAR1AQCffqqWpffyOPxbs/KVe\
fDELQQAAEY8OIKJapPwmTecPwOmKlO8tmI0OIHAWcLcPAEA0oQOIqMZv0gCiDd9biAR0AAEAAAxD\
AAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwB\
EAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARA\
AAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQCCCLSpbpGGvDNOiskXhLgUAEEMIgEAEm79pvvZW7dX8\
TfPDXQoAIIYQAIEINrbnWLVv3V5je44NdykAgBjisCzLCncRwDfl9Xrlcrnk8XjkdDrDXQ4AnBLf\
W4gEdAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEA\
AAxDAAQAADAMARDNZs2aNbrmmmvUoUMHORwOLVmyJOR1y7I0ffp0tW/fXikpKSoqKtJnn30WnmIB\
ADAIARDNpqqqSr1799aTTz7Z5OszZ87UE088oblz52rdunVq3bq1iouLVV1d3cKVAgBgllbhLgCx\
66qrrtJVV13V5GuWZemxxx7TPffco2uvvVaS9NxzzyknJ0dLlizRqFGjWrJUAACMQgcQYbF9+3a5\
3W4VFRXZx1wuly699FKVlJSc8H0+n09erzfkAQAAzgwBEGHhdrslSTk5OSHHc3Jy7NeaMmPGDLlc\
LvuRl5fXrHUCABCLCICIKtOmTZPH47Efu3fvDndJAABEHQIgwiI3N1eSVFFREXK8oqLCfq0pSUlJ\
cjqdIQ8AAHBmCIAIi27duik3N1crVqywj3m9Xq1bt06FhYVhrAwAgNjHKmA0m0OHDunzzz+3n2/f\
vl2lpaVq27atOnfurNtvv10PPPCAzjvvPHXr1k333nuvOnTooOHDh4evaAA4gY+WL9X6Ja+o3/CR\
6v39H4S7HOBbIQCi2XzwwQcaMmSI/Xzy5MmSpNGjR2vBggX6z//8T1VVVWn8+PGqrKzUoEGD9Oab\
byo5OTlcJQPACa1f8oq8+/dp/ZJXCICIeg7LsqxwFwF8U16vVy6XSx6Ph/mAZ2hR2SLN3zRfY3uO\
1fX514e7HCDina0OIN9biAQEQEQ1vkhP7FQBb9grw7S3aq/at26vZSOXhaFCwEx8byESsAgEiFHz\
N83X3qq9euLDJzTwxYEa9OIgLSpbZL8+tudYtW/dXmN7jg1536KyRRr2yrCQc4FY8dHypfrzxFv0\
0fKlzXI+EC0IgECMujj7Yvl2+eSr98lb45WnxqP5m+Y3eW5paan992BwPNG5QDRrOI/veE2FvZOd\
D0QzFoEAMeq1v76m3ct2y/d9n5wDnUqIS1Db5Lbq+WxPSVJyfLKq66t1z2P3yL3MrVGjR2ne9Hka\
23OsPXQMxJp+w0fa8/ik0Hl9wbD3z6fnaNVzT6tVYoK69r7Efh8QS5gDiKjGXJrGFpUt0qN/f1Tb\
n96uw7WHVeevU9uitsoYlNHo3Oq11Sp/q1x+y694R7ze+ds76tOnT8sXDbSw0tJS9enTR3+eeIu8\
+/fJmZmtfsNHasVf5sry++3zPIrX/3vp1bP6s/neQiSgAwjEmPmb5utQ9iElXJagun/WyZKlr/75\
lSSFhMAD7xyQd6VXDjkkSe2L2xP+YIR58+Zp3rx5mjRpUkhHMLiy952Fz6muplbr/71T/1/Zv3Vg\
1Aj1aueyu4DsBYhYQAcQUY3fpBtbVLZID6x9QJYsHXjngB3+JKldUTtlDMqwjzvkkCVLucNy9V+T\
/4vtYBDTPlq+VP83/ym9WLJBtdXVSkhOVv8unfTdbh0lSa0SEuTKzlXFvz/X+zu+0Luf7bDfe913\
e6p7p05KTEmRd/8+OeLiNPSWW79RCOR7C5GARSBAjAiu3pUkZ2LgfyoZgzLUrqidfc5X//xK2/9r\
ux0KLVlqV9ROaQPStKFiQ8sXDbSg9UtekUv1+m6HLNXX1an60CGt2rJVJWXbVOfzqfrQoSbD38Dz\
uqpjhktyWOo3fKQccXGy/H4WhiCqEQCBGNFw9e5vLvmN2rduL4ccjUJg/ZF6++/BjqAkLd2+VHet\
uavF6wZaSof88+WIi9PVQ76nQd/pZh9/97Mden/HF5LUZPi7tHtXyeFQ196XqPf3f6Cht9xqzxkE\
ohVzAIEY0XD1bnAo94G1D0gKdAIr360MCX/xKfGNFoYs3b5UBTkFDAUjJpWXbZXl98uzz63+3zlH\
lmXZYe/dz3bogx1fyFdbZ58/8Lyu6tu1k/z1dfb7Jan393/A/D9EPTqAQJRrOPS7bOQyXZ9/ve5a\
c5fuX3u/LAWm+B5450BI+JMCncAD7xxo9HnzN81nM2jEpH7DR8qZmS1ZDtX5fOrbtZMGntfVfr2p\
8BfUKilJNUeO2HsEskE0oh2LQBDVTJ9MvahskR5c96D8lt++q8f8TfPlrnKHhL+GC0HiU+JPOAws\
BfYHTIpPkqfGw23iEJM+Wr5U/5z/J/v5nFVrQ8JfUkIrTbi8f9NvdjhUNGaC3nnxf1VddVDJrdto\
4l9ePKOfb/r3FiIDHUAgis3fNF9+y684R5wd/vZW7T1h+GtX1E7d7urWaGFIw05gdX21PDUeuRJd\
bAaNmNRw+Pb944Z9pUAnMDgnsBHLCiz+cBztnTjooSA6MQcQiGJNzfsLdgRPtAWMdGw/wODrTe0T\
6Kv32beDY04gYkHwrh8d8s+X1HjBR1JCKzsMBo83HAaWJDkcjfYDBKIRQ8CIagylNLaobJHuWXSP\
dv9lt30ssyhT6YPSQ85zyCHPux7t/+d+WZYlS5Y639JZiZ0TQ85jGBixInjXD0dcnNb/e1ej1b59\
u3ZqchVw3255Sk5NkxyWBo266VsvAOF7C5GAIWAgxlyff70euP4BZV6eKSnQ+Ts+/F3U7iK1SWwj\
50Cn2g5tqzhHnNpe3laJnROVHJ+sOEfgqyE4tAzEguAikC/iU/Tetl328YYLPhouDHHExWnt9i90\
OO88DfrpjUpMTg1H2UCzYAgYiFFth7RVUrckpXRJ0UXtLtIXB7+Qt8YrS5a+rv7avgVc+qB0tTun\
nfwd/PbcwbSENDnk0G8u+Q3Dv4gZvb//A1lZHfTU2LHK7nqO9u34twZ079xomDf4fNOBKqU4XXr1\
7TWq3bVNLtVr/ZJX2AIGMYEACMSQRWWLNH/TfB2uPSy/5Vfrrq1196V32yEu+Hqwq/fEh0/IkqX/\
+Ml/SAosKqmqrZK3xqv2rdsT/hBz+vTpo/Hjx+vxh2fpsvxzdEmn3MYnORy68ec/0yuvvqb1u936\
j9/eqUu7dWLOH2IKcwAR1ZhLE2rYK8O0t2qvnIlOtU5oHbI45HQ1DIkEQMSij5Yv1XP//V/q4GoT\
crxVYpLkkOpqatQqMVF1Pp88itf/e+nVs/rz+d5CJKADCMSQsT3H6vEPH5dDjm8c4K7Pv57gh5j2\
zsLnjoU/h0OyrMCfDqnO55MUCIHOzGwV0fFDjGIRCBBDrs+/Xq0TWstT47G3cAFwHCsw/zW5dRsV\
jZkgZ2a23fELOn/AZRr35F+Y74eYRQAEYszYnmPtu4J8U9wKDrFs0E9vlDMzW137XGzP62vV6uj2\
Rw6Hisb+Wlf/5j/DWyTQzJgDiKjGXJrmEZxLyB6AiGXBfQGdmdnqN3ykHQabu+vH9xYiAR1AAI2c\
jS4iEOmC+wIGQx9DvjAJHUBENX6TBhBt+N5CJKADCAAAYBgCIAAAgGEIgAAAAIYhAAIAABiGAAgA\
AGAYAiAAAIBhCIAAAACGIQACAAAYhgAIAABgGAIgAACAYQiAAAAAhiEAAgAAGIYACAAAYBgCIAAA\
gGEIgAAAAIYhAAIAABiGAIiwe/LJJ9W1a1clJyfr0ksv1fr168NdEgAAMY0AiLB66aWXNHnyZN13\
33368MMP1bt3bxUXF2vfvn3hLg0AgJhFAERYPfLIIxo3bpx++ctf6sILL9TcuXOVmpqqv/zlL+Eu\
DQCAmEUARNjU1NRow4YNKioqso/FxcWpqKhIJSUlYawMAIDY1ircBcBc+/fvV319vXJyckKO5+Tk\
aOvWrU2+x+fzyefz2c+9Xm+z1ggAQCyiA4ioMmPGDLlcLvuRl5cX7pIAAIg6BECETWZmpuLj41VR\
URFyvKKiQrm5uU2+Z9q0afJ4PPZj9+7dLVEqAAAxhQCIsElMTFRBQYFWrFhhH/P7/VqxYoUKCwub\
fE9SUpKcTmfIAwAAnBnmACKsJk+erNGjR+u73/2u+vXrp8cee0xVVVX65S9/Ge7SAACIWQRAhNUN\
N9ygL7/8UtOnT5fb7VafPn305ptvNloYAgAAzh6HZVlWuIsAvimv1yuXyyWPx8NwMICowPcWIgFz\
AAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMA\
BAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQ\
AADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAA\
AADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEA\
AAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwBEs3nwwQc1YMAApaamKj09vclzdu3apauvvlqp\
qanKzs7WnXfeqbq6upYtFAAAw7QKdwGIXTU1NbruuutUWFiop59+utHr9fX1uvrqq5Wbm6v33ntP\
e/fu1U033aSEhAT98Y9/DEPFAACYwWFZlhXuIhDbFixYoNtvv12VlZUhx9944w398Ic/VHl5uXJy\
ciRJc+fO1V133aUvv/xSiYmJp/xsr9crl8slj8cjp9PZHOUDwFnF9xYiAUPACJuSkhL17NnTDn+S\
VFxcLK/Xqy1btoSxMgAAYhtDwAgbt9sdEv4k2c/dbneT7/H5fPL5fPZzr9fbfAUCABCj6ADijEyd\
OlUOh+Okj61btzbbz58xY4ZcLpf9yMvLa7afBQBArKIDiDMyZcoU3XzzzSc955xzzjmtz8rNzdX6\
9etDjlVUVNivNWXatGmaPHmy/dzr9RICAQA4QwRAnJGsrCxlZWWdlc8qLCzUgw8+qH379ik7O1uS\
tHz5cjmdTl144YVNvicpKUlJSUln5ecDAGAqAiCaza5du/T1119r165dqq+vV2lpqSTp3HPPVVpa\
moYNG6YLL7xQN954o2bOnCm326177rlHEydOJOQBANCM2AYGzebmm2/Ws88+2+j422+/rcsvv1yS\
tHPnTk2YMEGrVq1S69atNXr0aD300ENq1er0fjdhOwUA0YbvLUQCAiCiGl+kAKIN31uIBKwCBgAA\
MAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADA\
MARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEAAAADD\
EAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwBEAAAwDAEQAAAAMMQAAEAAAxD\
AAQAADAMARAAAMAwBEAAAADDEAABAAAMQwAEAAAwDAEQAADAMARAAAAAwxAAAQAADEMABAAAMAwB\
EAAAwDAEQAAAAMMQAAEAAAxDAAQAADAMARAAAMAwBEA0ix07dmjMmDHq1q2bUlJS1L17d913332q\
qakJOe/jjz/WZZddpuTkZOXl5WnmzJlhqhgAAHO0CncBiE1bt26V3+/XU089pXPPPVebN2/WuHHj\
VFVVpYcffliS5PV6NWzYMBUVFWnu3LnatGmTbrnlFqWnp2v8+PFhvgIAAGKXw7IsK9xFwAyzZs3S\
nDlz9O9//1uSNGfOHN19991yu91KTEyUJE2dOlVLlizR1q1bT+szvV6vXC6XPB6PnE5ns9UOAGcL\
31uIBAwBo8V4PB61bdvWfl5SUqLBgwfb4U+SiouLVVZWpgMHDjT5GT6fT16vN+QBAADODAEQLeLz\
zz/X7Nmz9atf/co+5na7lZOTE3Je8Lnb7W7yc2bMmCGXy2U/8vLymq9oAABiFAEQZ2Tq1KlyOBwn\
fRw/fLtnzx5deeWVuu666zRu3Lhv9fOnTZsmj8djP3bv3v2tPg8AABOxCARnZMqUKbr55ptPes45\
55xj/728vFxDhgzRgAEDNG/evJDzcnNzVVFREXIs+Dw3N7fJz05KSlJSUtI3qBwAAAQRAHFGsrKy\
lJWVdVrn7tmzR0OGDFFBQYGeeeYZxcWFNpwLCwt19913q7a2VgkJCZKk5cuXKz8/XxkZGWe9dgAA\
EMAQMJrFnj17dPnll6tz5856+OGH9eWXX8rtdofM7fvZz36mxMREjRkzRlu2bNFLL72kxx9/XJMn\
Tw5j5QAAxD46gGgWy5cv1+eff67PP/9cnTp1CnktuPOQy+XSsmXLNHHiRBUUFCgzM1PTp09nD0AA\
AJoZ+wAiqrGfFoBow/cWIgFDwAAAAIYhAAIAABiGAAgAAGAYAiAAAIBhCIAAAACGIQACAAAYhgAI\
AABgGAIgAACAYQiAAAAAhiEAAgBw1OY1e/Tc797V5jV7wl0K0KwIgAAAHPXhmzt08GufPnxzR7hL\
AZoVARAAAAW6fzXV9UpKbaVLruza6DU6g4glBEAAABTo/vkO1ykxOV6SQgIfnUHEGgIgAMA4TXX0\
Lrmyq9q0TdIlV3bV2iXbdPBrn9Yu2dbotRO9H4gmrcJdAAAALS3Y0Vv9YpnWLtmm/sO7q8fgjuox\
uKMk2cEvqOFrDd//4Zs7Qo4D0YIOIAAgpp2o2yeHJEvyHa5rNLTb+aJ2kkOqr/Vr2dNbmnx/Umor\
1VTX0wVEVCIAAgBiWlPz93oM7qiklFb6Yv/nkkNKbpOoP/16pZY9vUWStGvLV5Il1dX69fmGCn36\
ry2N3p+YHN9keASiAQEQABDTjp+/F7Q7rkQL331En+xfrS93HpTllz57v0Kb1+xRra/ePm979Vot\
fPcRbat5J6SbeKLPBaKBw7IsK9xFAN+U1+uVy+WSx+OR0+kMdzkAosDmNXu0+Nnl+t8Vs+Q7UifL\
L32vx3D1zy+WJLVKiFNdrV+StPZfb+lT7wpJ0pFDtfpRr4nq1PZctWmbpJv+OPAb/Xy+txAJ6AAC\
AIzy4Zs71Dahsy7t9kNZgZyn1ZuXaG3ZW5J0LPyVvaX3/vV3fbnroPbtPKjvdrhKndqeK0ec6Poh\
6hEAAQBGueTKrnLESf3zi/W9HsPt4w1D4Nqyt7R68xLV+vyyrECHsN93hqlN2yQNHpXPyl9EPbaB\
AQAYYfOaPfb2LucW5Mi9rVLXDBspOaTVm5ZICoTA9f9apiM1h+33BYeHs7q00fXT+oajdOCsowMI\
ADBC8E4fvsN1+nxDhXK7p+vLXQfV/zuhncCmwp8kpWensvkzYgYBEABghODefXIosOL3gwrp6DLI\
/vnFSklMDTk/JTHVDn9SYIVw8O4gBEFEOwIgAMAIPQZ31NhHBut7P81Xm7ZJinM47NfWlr0V0vmT\
Ap3A4JzAhmqr6+27iBACEa0IgACAmNVw377g3yUFtnA5mv+CCz6CGnYCGy4MCfIHd0+zxCbQiFoE\
QABAzGp4F5Dj7wji91uNwt/3egzXb6757xOuDpak876bo6TUVkpKbcV2MIharAIGAMSsS67sqg/f\
3KFLruyq8s8qdaiyQsltEvXc797VJ/tXa82WJUpIilOtzx+y4CP4ZzAcBv+8ZthIDRtzkaRAdzEY\
JtkWBtGGDiAAIGb1GNxRN/1xoHoM7ij3tkpZfmn/7oP69F9btPSdl5TVuY389VZI+Avqn1+sIb1+\
bD9/Z+uriss+YA8pN3WPYSBaEAABAEYI3rv33IIcXfCdi3TTz38pSRr7y1s14IIrG7/BIV3W+wf6\
Xo/hcjikm37+Sx3e1toOfdwLGNGMewEjqnFPTQDfRmlpqfr06aP5k9fId7hOkhQX55DfbykptZX6\
D++uD9/codTuVRo5Zpjd+bvkyq7feNiX7y1EAuYAAgCM1adPn9ADDql7Qbbc2yrtkNcw6B3/HIhW\
BEAAgJEadvP6D++uNQvLZPkl97bKwDYxJzmfEIhoxxxAAICRGi7i6DG4owaPyj/pnD4WfSCW0AEE\
ABip4RYx0qmHd48/H4hmLAJBVGMyNYBow/cWIgFDwAAAAIYhAAIAIl7De/oC+PYIgACAiMcCDODs\
IgACACIed90Azi5WAQMAIh4bMANnFx1ANJsf/ehH6ty5s5KTk9W+fXvdeOONKi8vDznn448/1mWX\
Xabk5GTl5eVp5syZYaoWAABzEADRbIYMGaJFixaprKxM//d//6dt27Zp5MiR9uter1fDhg1Tly5d\
tGHDBs2aNUu///3vNW/evDBWDQBA7GMfQLSYv//97xo+fLh8Pp8SEhI0Z84c3X333XK73UpMTJQk\
TZ06VUuWLNHWrVtP6zPZTwtAtOF7C5GADiBaxNdff62//vWvGjBggBISEiRJJSUlGjx4sB3+JKm4\
uFhlZWU6cOBAk5/j8/nk9XpDHgAA4MwQANGs7rrrLrVu3Vrt2rXTrl279Oqrr9qvud1u5eTkhJwf\
fO52u5v8vBkzZsjlctmPvLy85iseAIAYRQDEGZk6daocDsdJHw2Hb++8805t3LhRy5YtU3x8vG66\
6SZ9m1kH06ZNk8fjsR+7d+8+G5cFAIBR2AYGZ2TKlCm6+eabT3rOOeecY/89MzNTmZmZ+s53vqML\
LrhAeXl5Wrt2rQoLC5Wbm6uKioqQ9waf5+bmNvnZSUlJSkpK+nYXAQCA4QiAOCNZWVnKysr6Ru/1\
+/2SAvP4JKmwsFB33323amtr7XmBy5cvV35+vjIyMs5OwQAAoBGGgNEs1q1bp//5n/9RaWmpdu7c\
qZUrV+qnP/2punfvrsLCQknSz372MyUmJmrMmDHasmWLXnrpJT3++OOaPHlymKsHACC2EQDRLFJT\
U/W3v/1NQ4cOVX5+vsaMGaNevXpp9erV9hCuy+XSsmXLtH37dhUUFGjKlCmaPn26xo8fH+bqAQCI\
bewDiKjGfloAog3fW4gEdAABAAAMQwAEAAAwDKuAEdWCMxi4IwiAaBH8vmIGFsKJAIiodvDgQUni\
jiAAos7BgwflcrnCXQYMxSIQRDW/36/y8nK1adNGDofjlOd7vV7l5eVp9+7dMTH5muuJbLF2PVLs\
XVM4rseyLB08eFAdOnRQXBwzsRAedAAR1eLi4tSpU6czfp/T6YyJ/3kFcT2RLdauR4q9a2rp66Hz\
h3DjVw8AAADDEAABAAAMQwCEUZKSknTffffZdyOJdlxPZIu165Fi75pi7XqA08UiEAAAAMPQAQQA\
ADAMARAAAMAwBEAAAADDEAABAAAMQwCEEXbs2KExY8aoW7duSklJUffu3XXfffeppqYm5LyPP/5Y\
l112mZKTk5WXl6eZM2eGqeJTe/DBBzVgwAClpqYqPT29yXN27dqlq6++WqmpqcrOztadd96purq6\
li30DDz55JPq2rWrkpOTdemll2r9+vXhLum0rFmzRtdcc406dOggh8OhJUuWhLxuWZamT5+u9u3b\
KyUlRUVFRfrss8/CU+xpmDFjhvr27as2bdooOztbw4cPV1lZWcg51dXVmjhxotq1a6e0tDSNGDFC\
FRUVYar45ObMmaNevXrZmz0XFhbqjTfesF+PpmsBzhYCIIywdetW+f1+PfXUU9qyZYseffRRzZ07\
V7/73e/sc7xer4YNG6YuXbpow4YNmjVrln7/+99r3rx5Yaz8xGpqanTddddpwoQJTb5eX1+vq6++\
WjU1NXrvvff07LPPasGCBZo+fXoLV3p6XnrpJU2ePFn33XefPvzwQ/Xu3VvFxcXat29fuEs7paqq\
KvXu3VtPPvlkk6/PnDlTTzzxhObOnat169apdevWKi4uVnV1dQtXenpWr16tiRMnau3atVq+fLlq\
a2s1bNgwVVVV2efccccdeu211/Tyyy9r9erVKi8v109+8pMwVn1inTp10kMPPaQNGzbogw8+0BVX\
XKFrr71WW7ZskRRd1wKcNRZgqJkzZ1rdunWzn//pT3+yMjIyLJ/PZx+76667rPz8/HCUd9qeeeYZ\
y+VyNTq+dOlSKy4uznK73faxOXPmWE6nM+QaI0W/fv2siRMn2s/r6+utDh06WDNmzAhjVWdOkrV4\
8WL7ud/vt3Jzc61Zs2bZxyorK62kpCTrxRdfDEOFZ27fvn2WJGv16tWWZQXqT0hIsF5++WX7nE8/\
/dSSZJWUlISrzDOSkZFhzZ8/PyauBfgm6ADCWB6PR23btrWfl5SUaPDgwUpMTLSPFRcXq6ysTAcO\
HAhHid9KSUmJevbsqZycHPtYcXGxvF6v3fmIFDU1NdqwYYOKiorsY3FxcSoqKlJJSUkYK/v2tm/f\
LrfbHXJtLpdLl156adRcm8fjkST7v5cNGzaotrY25JrOP/98de7cOeKvqb6+XgsXLlRVVZUKCwuj\
+lqAb4MACCN9/vnnmj17tn71q1/Zx9xud0hYkmQ/d7vdLVrf2RBN17N//37V19c3WW+k1XqmgvVH\
67X5/X7dfvvtGjhwoHr06CEpcE2JiYmN5p5G8jVt2rRJaWlpSkpK0q233qrFixfrwgsvjMprAc4G\
AiCi2tSpU+VwOE762Lp1a8h79uzZoyuvvFLXXXedxo0bF6bKm/ZNrgdoThMnTtTmzZu1cOHCcJfy\
reTn56u0tFTr1q3ThAkTNHr0aH3yySfhLgsIm1bhLgD4NqZMmaKbb775pOecc8459t/Ly8s1ZMgQ\
DRgwoNHijtzc3EYr/4LPc3Nzz07Bp3Cm13Myubm5jVbRtvT1nK7MzEzFx8c3+c8/0mo9U8H6Kyoq\
1L59e/t4RUWF+vTpE6aqTs9tt92mf/zjH1qzZo06depkH8/NzVVNTY0qKytDOmeR/O8rMTFR5557\
riSpoKBA77//vh5//HHdcMMNUXctwNlAAERUy8rKUlZW1mmdu2fPHg0ZMkQFBQV65plnFBcX2gAv\
LCzU3XffrdraWiUkJEiSli9frvz8fGVkZJz12ptyJtdzKoWFhXrwwQe1b98+ZWdnSwpcj9Pp1IUX\
XnhWfsbZkpiYqIKCAq1YsULDhw+XFBh6XLFihW677bbwFvctdevWTbm5uVqxYoUd+Lxer92JikSW\
ZWnSpElavHixVq1apW7duoW8XlBQoISEBK1YsUIjRoyQJJWVlWnXrl0qLCwMR8lnzO/3y+fzxcS1\
AN9IuFehAC3hiy++sM4991xr6NCh1hdffGHt3bvXfgRVVlZaOTk51o033mht3rzZWrhwoZWammo9\
9dRTYaz8xHbu3Glt3LjR+sMf/mClpaVZGzdutDZu3GgdPHjQsizLqqurs3r06GENGzbMKi0ttd58\
800rKyvLmjZtWpgrb9rChQutpKQka8GCBdYnn3xijR8/3kpPTw9ZxRypDh48aP/zl2Q98sgj1saN\
G62dO3dalmVZDz30kJWenm69+uqr1scff2xde+21Vrdu3awjR46EufKmTZgwwXK5XNaqVatC/ls5\
fPiwfc6tt95qde7c2Vq5cqX1wQcfWIWFhVZhYWEYqz6xqVOnWqtXr7a2b99uffzxx9bUqVMth8Nh\
LVu2zLKs6LoW4GwhAMIIzzzzjCWpyUdDH330kTVo0CArKSnJ6tixo/XQQw+FqeJTGz16dJPX8/bb\
b9vn7Nixw7rqqquslJQUKzMz05oyZYpVW1sbvqJPYfbs2Vbnzp2txMREq1+/ftbatWvDXdJpefvt\
t5v8dzF69GjLsgJbwdx7771WTk6OlZSUZA0dOtQqKysLb9EncaL/Vp555hn7nCNHjli//vWvrYyM\
DCs1NdX68Y9/HPILVSS55ZZbrC5duliJiYlWVlaWNXToUDv8WVZ0XQtwtjgsy7JasOEIAACAMGMV\
MAAAgGEIgAAAAIYhAAIAABiGAAgAAGAYAiAAAIBhCIAAAACGIQACAAAYhgAIAABgGAIgAACAYQiA\
AAAAhiEAAgAAGIYACAAAYBgCIAAAgGEIgAAAAIYhAAIAABiGAAgAAGAYAiAAAIBhCIAAAACGIQAC\
AAAYhgAIAABgGAIgAACAYQiAAAAAhiEAAgAAGIYACAAAYBgCIAAAgGEIgAAAAIYhAAIAABiGAAgA\
AGAYAiAAAIBhCIAAAACGIQACAAAY5v8Hf0/s1WeYjUQAAAAASUVORK5CYII=\
"
  frames[2] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAJFNJREFUeJzt3X2QXXWd7/tPR9JNnrohENLkJtFAe4AcAauiQKtjKWbooYgl\
0+A4M3U0KOoMBqogXGdIycP5Q41Fe1C0EOZeZ8C5VTwM5wasTqltKmKoM0bUeFMCmhz7DJpcQjdh\
MN2hNZ2Y7PsHN3to6CRNSPfO7t/rVbWr2Wuv3nxXpVi8s/ZaazdUKpVKAAAoxpRaDwAAwMQSgAAA\
hRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIUR\
gAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAA\
AIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACF\
EYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGA\
AACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhRGAAACFEYAAAIURgAAAhTmh1gPA0Tpw4EB27NiR\
WbNmpaGhodbjAIxZpVLJ7t27M2/evEyZ4lgME08AUrd27NiRBQsW1HoMgKO2ffv2zJ8/v9ZjUCAB\
SN2aNWtWkpd3oM3NzTWeBmDsBgcHs2DBgup+DCaaAKRuHfzYt7m5WQACdcnpK9SKEw8AAAojAAEA\
CiMAAQAKIwABAAojAAEACiMAAQAKIwABAAojAKGO9Pb2HtP1ACiTAIQ60d3dna6urvT09Bx2vZ6e\
nnR1daW7u3uCJgOg3ghAqAO9vb1Zu3ZtkmTNmjWHjMCenp6sWbMmSbJ27VpHAgEYlQCEOtDW1pbO\
zs7q89Ei8JXxlySdnZ1pa2ubsBkBqB8CEOpER0fHISNwtPjr6OiY8BkBqA8NlUqlUush4GgMDg6m\
paUlAwMDaW5urvU4E2ZE7O3ckhkvPp2h2f85mXN2EvEH9aDU/RfHjxNqPQDw+hyMuzX/9a+SvS9l\
KEl2b0zmnC3+ABgTHwFDHero6MiMl9OvasaMGeIPgDERgFCHenp6MrR35NkbQ0NDR7xFDAAkAhDq\
zqsv+JjR2FD958PdIgYADhKAUEdGxN/sM9K5uCl33Phf0vnF/7jpswgE4EhcBAJ1oqenJ2v+4YvJ\
c08mp5+bzv/9zuo5fwfP/DsYhwd/OicQgNE4Agh1oLe39+Woe+7JZO9L6Zzz29fE3Wj3CfRNIACM\
RgBCHWhra8uyZctePvL3jnnp+OQto673yghctmyZbwIBYFRuBE3dKvFGqr29vWOKurGuB9RGifsv\
ji+OAHLM3X333TnvvPPS3Nyc5ubmtLe357vf/W719T179mTFihU55ZRTMnPmzFxxxRXp7++v4cT1\
Y6xRJ/4AOBwByDE3f/78fOlLX8qmTZvys5/9LBdffHE+9KEP5emnn06S3HDDDenu7s7DDz+cDRs2\
ZMeOHSPOXQMAxpePgJkQs2fPTldXV6688srMmTMn999/f6688sokyZYtW3LOOedk48aNueiii8b8\
nj5CAeqV/Re15ggg42r//v158MEHMzQ0lPb29mzatCn79u3L0qVLq+ucffbZWbhwYTZu3FjDSYHJ\
YKxXvrtCntIJQMbFk08+mZkzZ6apqSl/+7d/m0ceeSSLFy9OX19fGhsbc9JJJ41Yf+7cuenr6zvs\
ew4PD2dwcHDEY9L66T8mX3nbyz+BMenu7k5XV9cRb4Te09OTrq6udHd3H3Y9mMwEIOPirLPOyubN\
m/PEE0/kmmuuyfLly/PLX/7yDb3n6tWr09LSUn0sWLDgGE17HPofX0kGtr/8Ezii3t7erF27Nsnh\
vw3nld+ms3btWkcCKZYAZFw0Njamra0tS5YsyerVq3P++efnzjvvTGtra/bu3Ztdu3aNWL+/vz+t\
ra2Hfc9Vq1ZlYGCg+ti+ffs4bkGNveeGpGXByz+BI2pra3vNjdBfHYGv/h7tzs5OV8xTLF8Fx4Q4\
cOBAhoeHs2TJkkydOjXr16/PFVdckSTZunVrtm3blvb29sO+R1NTU5qamiZi3Np759UvP4AxO/jt\
OKN9JeJo8eerEimZAOSYW7VqVS699NIsXLgwu3fvzv33358f/vCH6enpSUtLS66++uqsXLkys2fP\
TnNzc6677rq0t7e/riuAAUbz6ghcfuvX8/ub705l33DefMr0vLvtVPEHEYCMg+effz4f+9jH8txz\
z6WlpSXnnXdeenp68qd/+qdJkq985SuZMmVKrrjiigwPD6ejoyPf+MY3ajw1MFm8MgKHhvcn2Z8k\
+e2//z7/7e/EHyTuA0gdcx8t4HBWrlyZ//MHv6o+b5jalMGfPlq7gV7B/otacxEIAJNOT09PhoaG\
Riyr7Bs+4i1ioBQCEIBJ5dUXfDRMffniscYTGg57ixgoiXMAAZg0Xh1/11z1V/nXPfPz7hP/3wz8\
6l+TjLw6GEolAAGYFI50q5eenrmj3iIGSuQjYADqXm9v7xHv89fR0fGam0X7JhBKJQABqHttbW1Z\
tmxZksPf5PmVEbhs2TLfBEKx3AaGuuU2CsCr9fb2jinqxrreeLH/otYcAQRg0hhr1DnyR+kEIABA\
YQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEE\
IABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAA\
QGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIJNeb2/vMV0P\
AOqdAGRS6+7uTldXV3p6eg67Xk9PT7q6utLd3T1BkwFA7QhAJq3e3t6sXbs2SbJmzZpDRmBPT0/W\
rFmTJFm7dq0jgQBMegKQSautrS2dnZ3V56+MwN89+GC2XnhRvnnW2Xmgq6u6TmdnZ9ra2iZ8VgCY\
SCfUegAYTx0dHUlSPcL3QFdXtn3yk3nPjJn5H0MvZd3ulzLlpd1pOvPMdHZ2VtcHgMlMADLpvTIC\
9/zqV1k39Pv869BQfn+gkiQ58ZxzxB8ARfERMMfc6tWr8853vjOzZs3Kaaedlssvvzxbt24dsc6e\
PXuyYsWKnHLKKZk5c2auuOKK9Pf3j9tMHR0d6ezszInnnJMk1fhLkr/67GfFHwBFEYAccxs2bMiK\
FSvy4x//OOvWrcu+fftyySWXZGhoqLrODTfckO7u7jz88MPZsGFDduzYMeJ8vfHQ0dGR2eedN2LZ\
9CkN4g+A4jRUKpXKkVeDo7dz586cdtpp2bBhQ9773vdmYGAgc+bMyf33358rr7wySbJly5acc845\
2bhxYy666KIxve/g4GBaWloyMDCQ5ubmI67/yqt9h//X/8qeX/0qJ55zjiOAwIR7vfsvONacA8i4\
GxgYSJLMnj07SbJp06bs27cvS5cura5z9tlnZ+HChYcNwOHh4QwPD1efDw4OjnmGV8Zfksw+77wM\
nXlmkv+4QEQEAlAKHwEzrg4cOJDrr78+7373u/O2t70tSdLX15fGxsacdNJJI9adO3du+vr6Dvle\
q1evTktLS/WxYMGCMc3w6vjr7OzMHXfccchbxADAZCcAGVcrVqzIU089lQcffPANv9eqVasyMDBQ\
fWzfvv2IvzNa/B080nfwwpCDRCAApfARMOPm2muvzdq1a/P4449n/vz51eWtra3Zu3dvdu3aNeIo\
YH9/f1pbWw/5fk1NTWlqahrzv7+3t/eQ8XfQq+8TuGbNmpx55pluBg3ApOYIIMdcpVLJtddem0ce\
eSQ/+MEPsmjRohGvL1myJFOnTs369eury7Zu3Zpt27alvb39mM3R1taWZcuWJRk9/g565ZHAZcuW\
iT8AJj1XAXPMfeYzn8n999+fb3/72znrrLOqy1taWjJt2rQkyTXXXJPvfOc7ue+++9Lc3Jzrrrsu\
SfKjH/1ozP+esV5F19vbO6aoG+t6AG+Uq4CpNQHIMdfQ0DDq8nvvvTdXXXVVkpdvBH3jjTfmgQce\
yPDwcDo6OvKNb3zjsB8Bv5odKFCv7L+oNQFI3bIDBeqV/Re15hxAAIDCCEAAgMIIQACAwghAAIDC\
CEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghA\
AIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACA\
wghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMII\
QACAwghAAIDCCEAAgMIIQACAwghAAIDCCEAAgMIIQACAwghAAIDCCEDGxeOPP54PfvCDmTdvXhoa\
GvLoo4+OeL1SqeTWW2/N6aefnmnTpmXp0qX59a9/XZthAaAwApBxMTQ0lPPPPz933XXXqK/ffvvt\
+drXvpZ77rknTzzxRGbMmJGOjo7s2bNngicFgPKcUOsBmJwuvfTSXHrppaO+VqlU8tWvfjU333xz\
PvShDyVJ/vmf/zlz587No48+mr/8y7+cyFEBoDiOADLhnnnmmfT19WXp0qXVZS0tLbnwwguzcePG\
Gk4GAGVwBJAJ19fXlySZO3fuiOVz586tvjaa4eHhDA8PV58PDg6Oz4AAMMk5AkjdWL16dVpaWqqP\
BQsW1HqkCfEvW/8ll/z3S/IvW/+l1qMAMEkIQCZca2trkqS/v3/E8v7+/upro1m1alUGBgaqj+3b\
t4/rnMeLbz75zTw39Fy++eQ3az0KAJOEAGTCLVq0KK2trVm/fn112eDgYJ544om0t7cf8veamprS\
3Nw84lGCT577yZw+4/R88txP1noUACYJ5wAyLl566aX09vZWnz/zzDPZvHlzZs+enYULF+b666/P\
5z//+bz1rW/NokWLcsstt2TevHm5/PLLazf0ceovzvqL/MVZf1HrMQCYRAQg4+JnP/tZ3v/+91ef\
r1y5MkmyfPny3Hffffm7v/u7DA0N5dOf/nR27dqV97znPfne976XE088sVYjA0AxGiqVSqXWQ8DR\
GBwcTEtLSwYGBor5OBiYHOy/qDXnAAIAFEYAAgAURgACABRGAAIAFEYAQp165W12jsV6AJRDAEId\
6u7uTldXV3p6eg67Xk9PT7q6utLd3T1BkwFQDwQg1Jne3t6sXbs2SbJmzZpDRmBPT0/WrFmTJFm7\
dq0jgQBUCUCoM21tbens7Kw+Hy0CXxl/SdLZ2Zm2trYJmxEmE6dbMBkJQKhDHR0dh4zA0eKvo6Nj\
wmeEycDpFkxWvgoO6tTBqDsYewcjcGhoqLqO+IOj9+rTLZKM+t/Tq0+3OOeccxxx57jnCCDUsVce\
CXz4fz6c+/6f+/Lw/3w4ifiDN8rpFkxmvguYuuW7NP/DWZeflZ0DO6vPpzRNyQvfe6GGE8HkcajT\
Kt7I6Rb2X9Saj4ChzvX09IyIvyQ5MHwgPT09jgDCMXCo0y02fvv/rq7zX7/xf/jvjbriI2CoYweP\
QJzcdHKSl4/8JUlDGg57ixjg9Xn1hVebH1tX/edz57eKP+qOAIQ69cqPn5a+eWkeuOmBvPC9F/LA\
TQ/kyv90ZZLD3ycQeH06OjoyY8aMJMkfBgeTJI0nvClntc6p5VhwVAQg1KHDnXt0uFvEAEfvlVfZ\
T/v/z9vb+8f92dq383C/Bscl5wBCnent7T3iieejnbN05plnujoRjtKr/9L19vf/6YhbLjnnlnrj\
CCDUmba2tixbtizJ4a86fOWRwGXLlok/OEqjHXG/4447HGmnrrkNDHWr9Nso9Pb2jinqxroe8FpH\
utXL0d4KpvT9F7XnCCDUqbFGnfiDozPW0y1efSTQdwJTDwQgAIzC6RZMZj4Cpm75CAWYCONxuoX9\
F7XmCCAAHIbTLZiMBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBh\
BCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQg\
AEBhBCAAQGEEIABAYQQgAEBhBCA1ddddd+Utb3lLTjzxxFx44YX5yU9+UuuRAGDSE4DUzEMPPZSV\
K1fmtttuy89//vOcf/756ejoyPPPP1/r0QBgUhOA1Mwdd9yRT33qU/n4xz+exYsX55577sn06dPz\
T//0T7UeDQAmNQFITezduzebNm3K0qVLq8umTJmSpUuXZuPGjaP+zvDwcAYHB0c8AIDXTwBSEy+8\
8EL279+fuXPnjlg+d+7c9PX1jfo7q1evTktLS/WxYMGCiRgVACYdAUjdWLVqVQYGBqqP7du313ok\
AKhLJ9R6AMp06qmn5k1velP6+/tHLO/v709ra+uov9PU1JSmpqaJGA8AJjVHAKmJxsbGLFmyJOvX\
r68uO3DgQNavX5/29vYaTgYAk58jgNTMypUrs3z58rzjHe/IBRdckK9+9asZGhrKxz/+8VqPBgCT\
mgCkZj7ykY9k586dufXWW9PX15e3v/3t+d73vveaC0MAgGOroVKpVGo9BByNwcHBtLS0ZGBgIM3N\
zbUeB2DM7L+oNecAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYA\
AgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIA\
FEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRG\
AAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgAC\
ABRGAAIAFEYAAgAURgByzH3hC1/Iu971rkyfPj0nnXTSqOts27Ytl112WaZPn57TTjstn/3sZ/PH\
P/5xYgcFgEKdUOsBmHz27t2bD3/4w2lvb88//uM/vub1/fv357LLLktra2t+9KMf5bnnnsvHPvax\
TJ06NV/84hdrMDEAlKWhUqlUaj0Ek9N9992X66+/Prt27Rqx/Lvf/W6WLVuWHTt2ZO7cuUmSe+65\
J3//93+fnTt3prGxcUzvPzg4mJaWlgwMDKS5uflYjw8wbuy/qDUfATPhNm7cmHPPPbcaf0nS0dGR\
wcHBPP300zWcDADK4CNgJlxfX9+I+EtSfd7X13fI3xseHs7w8HD1+eDg4PgMCACTnCOAjMlNN92U\
hoaGwz62bNkyrjOsXr06LS0t1ceCBQvG9d8HAJOVI4CMyY033pirrrrqsOucccYZY3qv1tbW/OQn\
PxmxrL+/v/raoaxatSorV66sPh8cHBSBAHAUBCBjMmfOnMyZM+eYvFd7e3u+8IUv5Pnnn89pp52W\
JFm3bl2am5uzePHiQ/5eU1NTmpqajskMAFAyAcgxt23btrz44ovZtm1b9u/fn82bNydJ2traMnPm\
zFxyySVZvHhxPvrRj+b2229PX19fbr755qxYsULgAcAEcBsYjrmrrroq3/rWt16z/LHHHsv73ve+\
JMlvf/vbXHPNNfnhD3+YGTNmZPny5fnSl76UE04Y+99J3EYBqFf2X9SaAKRu2YEC9cr+i1pzFTAA\
QGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBh\
BCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQg\
AEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABA\
YQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEEIABAYQQgAEBhBCAAQGEE\
IABAYQQgx9RvfvObXH311Vm0aFGmTZuWM888M7fddlv27t07Yr1f/OIX+ZM/+ZOceOKJWbBgQW6/\
/fYaTQwA5Tmh1gMwuWzZsiUHDhzIP/zDP6StrS1PPfVUPvWpT2VoaChf/vKXkySDg4O55JJLsnTp\
0txzzz158skn84lPfCInnXRSPv3pT9d4CwBg8muoVCqVWg/B5NbV1ZW77747//Zv/5Ykufvuu/O5\
z30ufX19aWxsTJLcdNNNefTRR7Nly5Yxv+/g4GBaWloyMDCQ5ubmcZkdYDzYf1FrPgJm3A0MDGT2\
7NnV5xs3bsx73/veavwlSUdHR7Zu3Zrf/e53tRgRAIoiABlXvb29+frXv56/+Zu/qS7r6+vL3Llz\
R6x38HlfX98h32t4eDiDg4MjHgDA6ycAGZObbropDQ0Nh328+uPbZ599Nn/2Z3+WD3/4w/nUpz71\
hmdYvXp1Wlpaqo8FCxa84fcEgBI5B5Ax2blzZ/793//9sOucccYZ1Y91d+zYkfe973256KKLct99\
92XKlP/4u8bHPvaxDA4O5tFHH60ue+yxx3LxxRfnxRdfzMknnzzq+w8PD2d4eLj6fHBwMAsWLHAO\
DVB3nANIrbkKmDGZM2dO5syZM6Z1n3322bz//e/PkiVLcu+9946IvyRpb2/P5z73uezbty9Tp05N\
kqxbty5nnXXWIeMvSZqamtLU1HT0GwEAJPERMMfYs88+m/e9731ZuHBhvvzlL2fnzp3p6+sbcW7f\
X//1X6exsTFXX311nn766Tz00EO58847s3LlyhpODgDlcASQY2rdunXp7e1Nb29v5s+fP+K1g2cb\
tLS05Pvf/35WrFiRJUuW5NRTT82tt97qHoAAMEGcA0jdcg4NUK/sv6g1HwEDABRGAAIAFEYAAgAU\
RgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYAAgAURgACABRGAAIAFEYA\
AgAURgACABRGAAIAFEYAAgAURgACABRGAALAGPX29h7T9aBWBCAAjEF3d3e6urrS09Nz2PV6enrS\
1dWV7u7uCZoMXj8BCABH0Nvbm7Vr1yZJ1qxZc8gI7OnpyZo1a5Ika9eudSSQ45YABIAjaGtrS2dn\
Z/X5aBH4yvhLks7OzrS1tU3YjPB6CEAAGIOOjo5DRuBo8dfR0THhM8JYNVQqlUqth4CjMTg4mJaW\
lgwMDKS5ubnW4wCFeHXszZgxI0NDQ9XnY4k/+y9q7YRaDwAA9eRg3H3zrv8rz/Xuqi7/z3/yvzny\
R93wETAAvE4dHR158bd7Riz7w+8q4o+6IQAB4HV46vFn89m/vCPD+0YG4PZf9x/xFjFwvBCAAPA6\
fOsbD2XjL35Qfd54wolJklMXzDrsLWLgeCIAAWCMenp68pvf/zxTm96U09tOyi1fuS4/+MV/zy1f\
uS6zT5+R5PD3CYTjhYtAAGAMDl79O/v0GZl9+owRF3wc/Hnw6uCDP50TyPHKEUAAOILe3t4j3udv\
tPsE+iYQjlcCEACOoK2tLcuWLUty+Pv8vTICly1b5ptAOG65ETR1y41UgYnW29s7pqg70nr2X9Sa\
I4AAMEZjPaLnyB/HOwEIAFAYAQgAUBgBCABQGAEIAFAYAQgAUBgBCABQGAEIAFAYAQgAUBgBCABQ\
mBNqPQAcrYPfYjg4OFjjSQBen4P7Ld/GSq0IQOrW7t27kyQLFiyo8SQAR2f37t1paWmp9RgUqKHi\
rx/UqQMHDmTHjh2ZNWtWGhoaaj3OMTM4OJgFCxZk+/btk/pL4m3n5FHCNibHdjsrlUp2796defPm\
ZcoUZ2Mx8RwBpG5NmTIl8+fPr/UY46a5uXlS/8/0INs5eZSwjcmx205H/qglf+0AACiMAAQAKIwA\
hONMU1NTbrvttjQ1NdV6lHFlOyePErYxKWc7KYOLQAAACuMIIABAYQQgAEBhBCAAQGEEIABAYQQg\
HEe+8IUv5F3velemT5+ek046adR1tm3blssuuyzTp0/Paaedls9+9rP54x//OLGDvkF33XVX3vKW\
t+TEE0/MhRdemJ/85Ce1HukNefzxx/PBD34w8+bNS0NDQx599NERr1cqldx66605/fTTM23atCxd\
ujS//vWvazPsUVq9enXe+c53ZtasWTnttNNy+eWXZ+vWrSPW2bNnT1asWJFTTjklM2fOzBVXXJH+\
/v4aTXx07r777px33nnVmz23t7fnu9/9bvX1ybCNkAhAOK7s3bs3H/7wh3PNNdeM+vr+/ftz2WWX\
Ze/evfnRj36Ub33rW7nvvvty6623TvCkR++hhx7KypUrc9ttt+XnP/95zj///HR0dOT555+v9WhH\
bWhoKOeff37uuuuuUV+//fbb87WvfS333HNPnnjiicyYMSMdHR3Zs2fPBE969DZs2JAVK1bkxz/+\
cdatW5d9+/blkksuydDQUHWdG264Id3d3Xn44YezYcOG7NixI52dnTWc+vWbP39+vvSlL2XTpk35\
2c9+losvvjgf+tCH8vTTTyeZHNsISZIKcNy59957Ky0tLa9Z/p3vfKcyZcqUSl9fX3XZ3XffXWlu\
bq4MDw9P4IRH74ILLqisWLGi+nz//v2VefPmVVavXl3DqY6dJJVHHnmk+vzAgQOV1tbWSldXV3XZ\
rl27Kk1NTZUHHnigBhMeG88//3wlSWXDhg2VSuXlbZo6dWrl4Ycfrq7zq1/9qpKksnHjxlqNeUyc\
fPLJlW9+85uTehspjyOAUEc2btyYc889N3Pnzq0u6+joyODgYPUIxfFs79692bRpU5YuXVpdNmXK\
lCxdujQbN26s4WTj55lnnklfX9+IbW5pacmFF15Y19s8MDCQJJk9e3aSZNOmTdm3b9+I7Tz77LOz\
cOHCut3O/fv358EHH8zQ0FDa29sn5TZSrhNqPQAwdn19fSPiL0n1eV9fXy1Gel1eeOGF7N+/f9Rt\
2LJlS42mGl8H/1xG2+Z6+DMbzYEDB3L99dfn3e9+d972trcleXk7GxsbX3Puaj1u55NPPpn29vbs\
2bMnM2fOzCOPPJLFixdn8+bNk2YbwRFAGGc33XRTGhoaDvuYrPHD5LRixYo89dRTefDBB2s9yrg4\
66yzsnnz5jzxxBO55pprsnz58vzyl7+s9VhwTDkCCOPsxhtvzFVXXXXYdc4444wxvVdra+trrpg9\
eAVia2vrUc03kU499dS86U1ves1Vk/39/XUx/9E4uF39/f05/fTTq8v7+/vz9re/vUZTHb1rr702\
a9euzeOPP5758+dXl7e2tmbv3r3ZtWvXiCNk9fhn29jYmLa2tiTJkiVL8tOf/jR33nlnPvKRj0ya\
bQRHAGGczZkzJ2efffZhH42NjWN6r/b29jz55JMjrphdt25dmpubs3jx4vHahGOmsbExS5Ysyfr1\
66vLDhw4kPXr16e9vb2Gk42fRYsWpbW1dcQ2Dw4O5oknnqirba5UKrn22mvzyCOP5Ac/+EEWLVo0\
4vUlS5Zk6tSpI7Zz69at2bZtW11t52gOHDiQ4eHhSb2NlMcRQDiObNu2LS+++GK2bduW/fv3Z/Pm\
zUmStra2zJw5M5dcckkWL16cj370o7n99tvT19eXm2++OStWrEhTU1Nthx+jlStXZvny5XnHO96R\
Cy64IF/96lczNDSUj3/847Ue7ai99NJL6e3trT5/5plnsnnz5syePTsLFy7M9ddfn89//vN561vf\
mkWLFuWWW27JvHnzcvnll9du6NdpxYoVuf/++/Ptb387s2bNqp7z1tLSkmnTpqWlpSVXX311Vq5c\
mdmzZ6e5uTnXXXdd2tvbc9FFF9V4+rFbtWpVLr300ixcuDC7d+/O/fffnx/+8Ifp6emZNNsISdwG\
Bo4ny5cvryR5zeOxxx6rrvOb3/ymcumll1amTZtWOfXUUys33nhjZd++fbUb+ih8/etfryxcuLDS\
2NhYueCCCyo//vGPaz3SG/LYY4+N+ue2fPnySqXy8q1gbrnllsrcuXMrTU1NlQ984AOVrVu31nbo\
12m07UtSuffee6vr/OEPf6h85jOfqZx88smV6dOnV/78z/+88txzz9Vu6KPwiU98ovLmN7+50tjY\
WJkzZ07lAx/4QOX73/9+9fXJsI1QqVQqDZVKpTLx2QkAQK04BxAAoDACEACgMAIQAKAwAhAAoDAC\
EACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAA\
oDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAwAhAAoDACEACgMAIQAKAw\
AhAAoDACEACgMAIQAKAwAhAAoDD/H6VSUzkOMDChAAAAAElFTkSuQmCC\
"
  frames[3] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAIlZJREFUeJzt3X+M1PWd+PHXouwKwg6isCOyXPFotKSVTaZd3fauUUvhiNfo\
+SPtXa6uluh9vdUE1/ROUsXc91sPg01P26+F++bu1Ms3qPGbQLE5awlF/KMre24zntpCSs4eVJyF\
nmWHkjIgO98/CFMWl2WB3R1m349HMtH5zIfh9QlxfPLez+czdeVyuRwAACRjQrUHAABgbAlAAIDE\
CEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhA\
AIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACA\
xAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQI\
QACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAA\
gMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDEnF/tAeBM9Pf3x+7du2Pq\
1KlRV1dX7XEATlu5XI79+/fHrFmzYsIE6zGMLQFITdq9e3c0NzdXewyAs7Zr166YPXt2tccgMQKQ\
mjR16tSIOPrB2djYWOVpAE5fsViM5ubmyucZjCUBSE069mPfxsZGAQjUNKexUA1OOgAASIwABABI\
jAAEAEiMAAQASIwABABIjAAEAEiMAIQaUSgURnQ/ANIlAKEG9PT0xIYNGyKfzw+5Xz6fjw0bNkRP\
T8/YDAZATRKAcI4rFAqVoOvu7j5pBObz+eju7o6Io8FoJRCAkxGAcI7LZrPR2tpaeT5YBB4ffxER\
ra2tkc1mx2pEAGqMAIQa0NLSctIIHCz+WlpaxnhCAGqJ7wKGGnEs6o7FXnd3d7z55ptRKpUq+4g/\
AIbDCiDUkBNXAsUfAGfCCiDUmJaWlqMrf//vf1S2Ndy6RvwBMGxWAKHG5PP5ASt/EUdXAk91ixgA\
OEYAQg058YKPhvN+/9pQt4gBgOMJQKgRH7na9391Rfv630Xr/+qqbBOBAAyHAIQaMNStXoa6RQwA\
DEYAwjmuUCic8j5/g0WgbwIB4GQEIJzjstls5HK5iBj6Vi/HR2Aul/NNIACclNvAQA3I5XJx2WWX\
nTLqWlpaIpvNij8AhmQFkBG3evXquOqqq6KxsTEaGxujra0tXn755crrBw8ejI6Ojrj44otjypQp\
ccstt0Rvb28VJ64Nw4068QfAqQhARtzs2bPjsccei56ennjjjTfi+uuvjxtvvDHeeeediIi4//77\
46WXXooXX3wxtmzZErt3746bb765ylMDQDrqyuVyudpDMP5Nnz49Hn/88bj11ltjxowZsXbt2rj1\
1lsjImLbtm3xiU98Irq6uuKaa64Z1vsVi8XIZDLR19cXjY2Nozk6wKjwOUY1WQFkVB05ciSef/75\
OHDgQLS1tUVPT08cPnw4Fi5cWNnnyiuvjDlz5kRXV9cQ7wQwPMO9At6V8qTMRSCMirfeeiva2tri\
4MGDMWXKlFi3bl3Mnz8/8vl81NfXx7Rp0wbs39TUNOSHcalUGvD1Z8VicbRGB2pYT09P9PT0DHnF\
fMTv762Zy+UqV9lDSqwAMiquuOKKyOfzsXXr1rjnnnuivb09fvazn53x+61cuTIymUzl0dzcPILT\
AuNBoVCInp6eiBj6hujH31i9p6fHSiBJEoCMivr6+pg3b17kcrlYuXJlLFiwIJ588snIZrNx6NCh\
2Ldv34D9e3t7h7x6dfny5dHX11d57Nq1a5SPAKg12Wz2lN+KM9i36rhynhQJQMZEf39/lEqlyOVy\
MXHixNi0aVPlte3bt8fOnTujra3tpL++oaGhcluZYw+AEw311YhDfaUipMY5gIy45cuXx5IlS2LO\
nDmxf//+WLt2bbz66qvxyiuvRCaTiaVLl0ZnZ2dMnz49Ghsb47777ou2trZhXwEMMJRjUXcs9rq7\
u+PNN98ccB6x+CN1ApARt2fPnrj99tvj/fffj0wmE1dddVW88sor8cUvfjEiIv7hH/4hJkyYELfc\
ckuUSqVYvHhxfO9736vy1MB4cmIEij8YyH0AqUnunwUMx7PPPhudz71Ref7tP/90tLe3V3Gi3/M5\
RjU5BxCAcSmfzw9Y+Ys4uhJ4squDISUCEIBx58QLPurOm1j596FuEQOpcA4gAOPKifG36bGl0dLS\
MmD7sX86F5BUWQEEYNwY6lYvQ90iBlIjAAEYFwqFwinv8zdYBPomEFIkAAEYF7LZbOV7fYe61cvx\
EZjL5XwTCElyDiAA40Yul4vLLrvslFHX0tIS2WxW/JEsK4AAjCvDjTrxR8oEIABAYgQgAEBiBCAA\
QGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBi\
BCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQg\
AEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQg41qhUBjR/QBgPBCA\
jFs9PT2xYcOGyOfzQ+6Xz+djw4YN0dPTMzaDAUCVCUDGpUKhUAm67u7uk0ZgPp+P7u7uiDgajFYC\
AUiBAGRcymaz0draWnk+WAQeH38REa2trZHNZsdqRAComvOrPQCMlpaWloiISuQd+2fDV/48fn7w\
YLx18GBc+j//LiKOxt+x/QFgvLMCyIhbuXJlfOYzn4mpU6fGzJkz46abbort27cP2OfgwYPR0dER\
F198cUyZMiVuueWW6O3tHfFZWlpaPrISuL6vL946eLCyTfwBkBoByIjbsmVLdHR0xOuvvx4bN26M\
w4cPx6JFi+LAgQOVfe6///546aWX4sUXX4wtW7bE7t274+abbx6VeU6MwEPlcuXfxR8AKaorl4/7\
vyGMgr1798bMmTNjy5Yt8fnPfz76+vpixowZsXbt2rj11lsjImLbtm3xiU98Irq6uuKaa6455XsW\
i8XIZDLR19cXjY2Nw5rj2WefjVKpVHne0NAQ7e3tZ3ZQAGfpTD7HYKRYAWTU9fX1RUTE9OnTI+Lo\
1baHDx+OhQsXVva58sorY86cOdHV1TUqM+Tz+QHxFxFRKpVOeYsYABiPXATCqOrv749ly5bF5z73\
ufjkJz8ZEUdv0VJfXx/Tpk0bsG9TU9NJb8NSKpUGBFyxWBz2DCde7dvQ0FB5r2Pb/RgYgJRYAWRU\
dXR0xNtvvx3PP//8Wb3PypUrI5PJVB7Nzc3D+nWD3eqlvb39lLeIAYDxTAAyau699974wQ9+EJs3\
b47Zs2dXtmez2Th06FDs27dvwP69vb0nvQ/f8uXLo6+vr/LYtWvXKX//weLv2ErfYFcHi0AAUiEA\
GXHlcjnuvffeWLduXfz4xz+OuXPnDng9l8vFxIkTY9OmTZVt27dvj507d0ZbW9ug79nQ0BCNjY0D\
HkMpFAonjb9jBotA3wQCQAqcA8iI6+joiLVr18b3v//9mDp1aiWqMplMTJo0KTKZTCxdujQ6Oztj\
+vTp0djYGPfdd1+0tbUN6wrg4chms5HL5aKnp2fIW70cf7PoXC7nm0AASILbwDDi6urqBt3+9NNP\
xx133BERR28E/cADD8Rzzz0XpVIpFi9eHN/73veGHWDDvX1CoVAY1nsOdz+AkeI2MFSTAKQm+eAE\
ap3PMarJOYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkR\
gAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAA\
AIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJ\
EYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGAAACJEYAAAIkRgAAAiRGA\
AACJEYAAAIkRgAAAiRGAjLjXXnstvvSlL8WsWbOirq4u1q9fP+D1crkcK1asiEsvvTQmTZoUCxcu\
jF/84hfVGRYAEiQAGXEHDhyIBQsWxFNPPTXo66tWrYrvfOc7sWbNmti6dWtceOGFsXjx4jh48OAY\
TwoAaTq/2gMw/ixZsiSWLFky6GvlcjmeeOKJeOihh+LGG2+MiIh//dd/jaampli/fn185StfGctR\
ASBJVgAZU++++24UCoVYuHBhZVsmk4mrr746urq6qjgZAKTDCiBjqlAoREREU1PTgO1NTU2V1wZT\
KpWiVCpVnheLxdEZEAASYAWQmrBy5crIZDKVR3Nzc7VHAoCaJQAZU9lsNiIient7B2zv7e2tvDaY\
5cuXR19fX+Wxa9euUZ0TAMYzAciYmjt3bmSz2di0aVNlW7FYjK1bt0ZbW9tJf11DQ0M0NjYOeAAA\
Z8Y5gIy43/72t7Fjx47K83fffTfy+XxMnz495syZE8uWLYtvfvOb8fGPfzzmzp0bDz/8cMyaNStu\
uumm6g0NAAkRgIy4N954I6677rrK887OzoiIaG9vj2eeeSb+5m/+Jg4cOBB333137Nu3L/7oj/4o\
fvjDH8YFF1xQrZEBICl15XK5XO0h4HQVi8XIZDLR19fnx8FATfI5RjU5BxAAIDECEAAgMQIQACAx\
AhAAIDECEGrQUF+bdyb7AZAWAQg1pqenJzZs2BD5fH7I/fL5fGzYsCF6enrGZjAAaoYAhBpSKBQq\
Qdfd3X3SCMzn89Hd3R0RR4PRSiAAxxOAUEOy2Wy0trZWng8WgcfHX0REa2vrkN+zDJya0y4YbwQg\
1JiWlpaTRuBg8dfS0jLGE8L44rQLxiNfBQc16FjUHYu97u7uePPNN6NUKlX2EX9w9k487SIiBv3v\
6sTTLi677DIr75zTrABCjTpxJVD8wchz2gXjlRVAqGEtLS2Vlb+/6/q7iIioO78ufnX3r6o8GYwf\
g624H9vutAtqlQCEGpbP5wes/EVElD8sRz6f9z8hGEFOu2C8EYBQo05ceag7vy7KH5YjYuhzlYAz\
c2IElkql2Ph//ndERDRPz8Tdd99drdHgtAlAqEGD/djpV3f/asB2EQgj7/jTLo4577wJcdlFmSpO\
BafPRSBQY4Y652ioW8QAZ2+w0y6OHOmP937TV6WJ4MxYAYQaUigUTnnC+WDnKmWzWVclwlk68S9f\
DQ0N8cW77x3wuhV3aoUVQKgh2Ww2crlcRAx9wvnxK4G5XE78wVkabOW9vb3dijs1ywog1JhcLjes\
m8y2tLRY+YMRcKrTLiIGv0UMnMusAEINGm7UiT84O8M97eLElUDfCcy5TgACwEk47YLxyo+AAWAI\
TrtgPLICCACn4LQLxhsBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgA\
kBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAYAQgAkBgBCACQGAEIAJAY\
AQgAkBgBCACQGAEIAJAYAQgAkBgBSFU99dRT8bGPfSwuuOCCuPrqq6O7u7vaIwHAuCcAqZoXXngh\
Ojs745FHHomf/vSnsWDBgli8eHHs2bOn2qMBwLgmAKmab3/723HXXXfFnXfeGfPnz481a9bE5MmT\
41/+5V+qPRoAjGsCkKo4dOhQ9PT0xMKFCyvbJkyYEAsXLoyurq4qTgYA49/51R6ANP3617+OI0eO\
RFNT04DtTU1NsW3bto/sXyqVolQqVZ4Xi8VRnxEAxisrgNSElStXRiaTqTyam5urPRIA1CwBSFVc\
csklcd5550Vvb++A7b29vZHNZj+y//Lly6Ovr6/y2LVr11iNCgDjjgCkKurr6yOXy8WmTZsq2/r7\
+2PTpk3R1tb2kf0bGhqisbFxwAMAODPOAaRqOjs7o729PT796U9Ha2trPPHEE3HgwIG48847qz0a\
AIxrApCq+fKXvxx79+6NFStWRKFQiJaWlvjhD3/4kQtDAICRVVcul8vVHgJOV7FYjEwmE319fX4c\
DNQkn2NUk3MAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQAS\
IwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMA\
AQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEA\
EiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIj\
AAEAEiMAAQASIwABABIjABlxjz76aHz2s5+NyZMnx7Rp0wbdZ+fOnXHDDTfE5MmTY+bMmfH1r389\
Pvzww7EdFAASdX61B2D8OXToUNx2223R1tYW//zP//yR148cORI33HBDZLPZ+MlPfhLvv/9+3H77\
7TFx4sT4+7//+ypMDABpqSuXy+VqD8H49Mwzz8SyZcti3759A7a//PLL8ad/+qexe/fuaGpqioiI\
NWvWxN/+7d/G3r17o76+/pTvXSwWI5PJRF9fXzQ2No7G+ACjyucY1eRHwIy5rq6u+NSnPlWJv4iI\
xYsXR7FYjHfeeaeKkwFAGvwImDFXKBQGxF9EVJ4XCoVBf02pVIpSqVR5XiwWR29AABjnrAAyLA8+\
+GDU1dUN+di2bduo/f4rV66MTCZTeTQ3N4/a7wUA450VQIblgQceiDvuuGPIfS6//PJhvVc2m43u\
7u4B23p7eyuvDWb58uXR2dlZeV4sFkUgAJwhAciwzJgxI2bMmDEi79XW1haPPvpo7NmzJ2bOnBkR\
ERs3bozGxsaYP3/+oL+moaEhGhoaRuT3B4DUCUBG3M6dO+ODDz6InTt3xpEjRyKfz0dExLx582LK\
lCmxaNGimD9/fnz1q1+NVatWRaFQiIceeig6OjpEHgCMAbeBYcTdcccd8eyzz35k++bNm+Paa6+N\
iIj/+q//invuuSdeffXVuPDCC6O9vT0ee+yxOP/84f2dxO0TgFrnc4xqEoDUJB+cQK3zOUY1uQoY\
ACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAg\
MQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDEC\
EAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAA\
IDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAx\
AhAAIDECkBH1y1/+MpYuXRpz586NSZMmxR/+4R/GI488EocOHRqw33/8x3/EH//xH8cFF1wQzc3N\
sWrVqipNDADpOb/aAzC+bNu2Lfr7++Mf//EfY968efH222/HXXfdFQcOHIhvfetbERFRLBZj0aJF\
sXDhwlizZk289dZb8bWvfS2mTZsWd999d5WPAADGv7pyuVyu9hCMb48//nisXr06/vM//zMiIlav\
Xh3f+MY3olAoRH19fUREPPjgg7F+/frYtm3bsN6zWCxGJpOJvr6+aGxsHLXZAUaLzzGqyY+AGXV9\
fX0xffr0yvOurq74/Oc/X4m/iIjFixfH9u3b4ze/+U01RgSApAhARtWOHTviu9/9bvzVX/1VZVuh\
UIimpqYB+x17XigUBn2fUqkUxWJxwAMAODMCkGF58MEHo66ubsjHiT++fe+99+JP/uRP4rbbbou7\
7rrrrH7/lStXRiaTqTyam5vP6v0AIGXOAWRY9u7dG//93/895D6XX3555ce6u3fvjmuvvTauueaa\
eOaZZ2LChN//XeP222+PYrEY69evr2zbvHlzXH/99fHBBx/ERRdd9JH3LpVKUSqVKs+LxWI0Nzc7\
dwaoWc4BpJpcBcywzJgxI2bMmDGsfd9777247rrrIpfLxdNPPz0g/iIi2tra4hvf+EYcPnw4Jk6c\
GBERGzdujCuuuGLQ+IuIaGhoiIaGhrM7CAAgIvwImBH23nvvxbXXXhtz5syJb33rW7F3794oFAoD\
zu37i7/4i6ivr4+lS5fGO++8Ey+88EI8+eST0dnZWcXJASAdVgAZURs3bowdO3bEjh07Yvbs2QNe\
O3a2QSaTiR/96EfR0dERuVwuLrnkklixYoV7AALAGHEOIDXJuTNArfM5RjX5ETAAQGIEIABAYgQg\
AEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABA\
YgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAJyGQqEwovtBNQhAABimnp6e2LBhQ+Tz\
+SH3y+fzsWHDhujp6RmbweA0CUAAGIZCoVAJuu7u7pNGYD6fj+7u7og4GoxWAjkXCUAAGIZsNhut\
ra2V54NF4PHxFxHR2toa2Wx2rEaEYROAADBMLS0tJ43AweKvpaVljCeE4Tm/2gMAQC05FnXHYq+7\
uzvefPPNKJVKlX3EH+c6AQgAp+n4CNz8f7dVtl/3l1eKP2qCHwEDwBloaWmJhoaGAdsaGhrEHzVB\
AALAGcjn8wN+7BsRUSqVTnmLGDgX+BEwAJym4y/4uO4vr4yGhoZKDB7bbiWQc5kVQAA4DYNd7dve\
3n7KW8TAuUQAAsAwDXWrl6FuEQPnGgEIAMNQKBROeZ+/wSLQN4FwLhKAADAM2Ww2crlcRAx9n7/j\
IzCXy/kmEM5JLgIBgGHK5XJx2WWXnTLqWlpaIpvNij/OWVYAAeA0DDfqxB/nMgEIAJAYAQgAkBgB\
CACQGAEIAJAYAQgAkBgBCACQGAEIAJAYN4KmJpXL5YiIKBaLVZ4E4Mwc+/w69nkGY0kAUpP2798f\
ERHNzc1VngTg7Ozfvz8ymUy1xyAxdWV/9aAG9ff3x+7du2Pq1KlRV1dX7XFGVLFYjObm5ti1a1c0\
NjZWe5xR4zjHF8d5+srlcuzfvz9mzZoVEyY4I4uxZQWQmjRhwoSYPXt2tccYVY2NjeP6f6THOM7x\
xXGeHit/VIu/cgAAJEYAAgAkRgDCOaahoSEeeeSRaGhoqPYoo8pxji+OE2qLi0AAABJjBRAAIDEC\
EAAgMQIQACAxAhAAIDECEM4hjz76aHz2s5+NyZMnx7Rp0wbdZ+fOnXHDDTfE5MmTY+bMmfH1r389\
Pvzww7Ed9Cw99dRT8bGPfSwuuOCCuPrqq6O7u7vaI5211157Lb70pS/FrFmzoq6uLtavXz/g9XK5\
HCtWrIhLL700Jk2aFAsXLoxf/OIX1Rn2DK1cuTI+85nPxNSpU2PmzJlx0003xfbt2wfsc/Dgwejo\
6IiLL744pkyZErfcckv09vZWaeIzs3r16rjqqqsqN3tua2uLl19+ufL6eDhGEIBwDjl06FDcdttt\
cc899wz6+pEjR+KGG26IQ4cOxU9+8pN49tln45lnnokVK1aM8aRn7oUXXojOzs545JFH4qc//Wks\
WLAgFi9eHHv27Kn2aGflwIEDsWDBgnjqqacGfX3VqlXxne98J9asWRNbt26NCy+8MBYvXhwHDx4c\
40nP3JYtW6KjoyNef/312LhxYxw+fDgWLVoUBw4cqOxz//33x0svvRQvvvhibNmyJXbv3h0333xz\
Fac+fbNnz47HHnssenp64o033ojrr78+brzxxnjnnXciYnwcI0QZOOc8/fTT5Uwm85Ht//Zv/1ae\
MGFCuVAoVLatXr263NjYWC6VSmM44ZlrbW0td3R0VJ4fOXKkPGvWrPLKlSurONXIiojyunXrKs/7\
+/vL2Wy2/Pjjj1e27du3r9zQ0FB+7rnnqjDhyNizZ085Ispbtmwpl8tHj2nixInlF198sbLPz3/+\
83JElLu6uqo15oi46KKLyv/0T/80ro+RtFgBhBrS1dUVn/rUp6KpqamybfHixVEsFiurE+eyQ4cO\
RU9PTyxcuLCybcKECbFw4cLo6uqq4mSj6913341CoTDguDOZTFx99dU1fdx9fX0RETF9+vSIiOjp\
6YnDhw8POM4rr7wy5syZU7PHeeTIkXj++efjwIED0dbWNi6PkTSdX+0BgOErFAoD4i8iKs8LhUI1\
Rjotv/71r+PIkSODHsO2bduqNNXoO/ZnM9hx18Kf22D6+/tj2bJl8bnPfS4++clPRsTR46yvr//I\
+au1eJxvvfVWtLW1xcGDB2PKlCmxbt26mD9/fuTz+XFzjKTNCiCMsgcffDDq6uqGfIzn+GF86ujo\
iLfffjuef/75ao8yKq644orI5/OxdevWuOeee6K9vT1+9rOfVXssGDFWAGGUPfDAA3HHHXcMuc/l\
l18+rPfKZrMfuWL22NWH2Wz2jOYbS5dcckmcd955H7lisre3tybmP1PHjq23tzcuvfTSyvbe3t5o\
aWmp0lRn7t57740f/OAH8dprr8Xs2bMr27PZbBw6dCj27ds3YIWsFv986+vrY968eRERkcvl4t//\
/d/jySefjC9/+cvj5hhJmxVAGGUzZsyIK6+8cshHfX39sN6rra0t3nrrrQFXzG7cuDEaGxtj/vz5\
o3UII6a+vj5yuVxs2rSpsq2/vz82bdoUbW1tVZxsdM2dOzey2eyA4y4Wi7F169aaOu5yuRz33ntv\
rFu3Ln784x/H3LlzB7yey+Vi4sSJA45z+/btsXPnzpo6zsH09/dHqVQa18dIWqwAwjlk586d8cEH\
H8TOnTvjyJEjkc/nIyJi3rx5MWXKlFi0aFHMnz8/vvrVr8aqVauiUCjEQw89FB0dHdHQ0FDd4Yep\
s7Mz2tvb49Of/nS0trbGE088EQcOHIg777yz2qOdld/+9rexY8eOyvN333038vl8TJ8+PebMmRPL\
li2Lb37zm/Hxj3885s6dGw8//HDMmjUrbrrppuoNfZo6Ojpi7dq18f3vfz+mTp1aOectk8nEpEmT\
IpPJxNKlS6OzszOmT58ejY2Ncd9990VbW1tcc801VZ5++JYvXx5LliyJOXPmxP79+2Pt2rXx6quv\
xiuvvDJujhHcBgbOIe3t7eWI+Mhj8+bNlX1++ctflpcsWVKeNGlS+ZJLLik/8MAD5cOHD1dv6DPw\
3e9+tzxnzpxyfX19ubW1tfz6669Xe6Sztnnz5kH/7Nrb28vl8tFbwTz88MPlpqamckNDQ/kLX/hC\
efv27dUd+jQNdnwRUX766acr+/zud78r//Vf/3X5oosuKk+ePLn8Z3/2Z+X333+/ekOfga997Wvl\
P/iDPyjX19eXZ8yYUf7CF75Q/tGPflR5fTwcI9SVy+Xy2GcnAADV4hxAAIDECEAAgMQIQACAxAhA\
AIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACA\
xAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQI\
QACAxAhAAIDECEAAgMQIQACAxAhAAIDE/H9y3pGjpRPbhwAAAABJRU5ErkJggg==\
"
  frames[4] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAoAAAAHgCAYAAAA10dzkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90\
bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAP\
YQAAD2EBqD+naQAAIndJREFUeJzt3X+M1PWd+PHXUtgVHGYQhZ1dWK54NFrSShPqj23vGms5KPEa\
PX+cl8u3oiX24q0miOmdXBXz/aYWo81V21i45O60l2+ofv1+A/1qzlq+FDH5dsVKv/TUHpuSswfZ\
3VnoWXZYUhaWne8fhjkWl2WB3R1m3o9HMsH5zIfh9QlxeO57PvOZulKpVAoAAJIxqdIDAAAwsQQg\
AEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABA\
YgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIE\
IABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAA\
QGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBi\
BCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiJld6ADgXg4OD0dXV\
FdOnT4+6urpKjwNw1kqlUhw6dCiam5tj0iTrMUwsAUhV6urqipaWlkqPAXDe9u3bF3Pnzq30GCRG\
AFKVpk+fHhEfvHBms9kKTwNw9orFYrS0tJRfz2AiCUCq0om3fbPZrAAEqprTWKgEJx0AACRGAAIA\
JEYAAgAkRgACACRGAAIAJEYAAgAkRgBClejr6xvT/QBIlwCEKtDV1RUdHR1RKBRG3K9QKERHR0d0\
dXVN0GQAVCMBCBe4vr6+6O7ujoiIzs7O00ZgoVCIzs7OiIjo7u62EgjAaQlAuMBlMpmYM2dO+f5w\
EXhy/EVEzJkzJzKZzITNCEB1EYBQBfL5/GkjcLj4y+fzEz4jANXDdwFDlTgRdSdir7OzM3p6emJg\
YKC8j/gDYDSsAEIVOXUlUPwBcC6sAEKVyefzH6z8PfPZ8rbJbf9X/AEwalYAocoUCoUhK38RH6wE\
nukSMQBwggCEKnLqBz4mn/R/8EiXiAGAk3kLGKrEhz7t+9/2RD6fH7L9xK/eDgZgJFYAoQqMdKmX\
kS4RAwDDEYBwgevr6zvjdf6Gi0DfBALA6QhAuMBlMploamqKiJEv9XJyBDY1NfkmEABOyzmAUAWa\
m5sjm82eMery+XxkMhnxB8CIrAAy5tavXx9XXXVVZLPZyGaz0draGq+88kr58SNHjkRbW1tceuml\
kclk4tZbb42enp4KTlwdRht14g+AMxGAjLm5c+fG448/Hjt37oy33norbrjhhrjpppvi3XffjYiI\
Bx54IF566aV48cUXY/v27dHV1RW33HJLhacGgHTUlUqlUqWHoPbNnDkznnzyybjtttti1qxZsXHj\
xrjtttsiImL37t3x8Y9/PNrb2+O6664b1fMVi8XI5XLR29sb2Wx2PEcHGBdex6gkK4CMq+PHj8fz\
zz8fhw8fjtbW1ti5c2ccO3YslixZUt7nyiuvjHnz5kV7e3sFJwVqxWg/Ae+T8qTMh0AYF2+//Xa0\
trbGkSNHIpPJxKZNm2LhwoWxa9euqK+vjxkzZgzZv7GxccRr1/X390d/f3/5frFYHK/RgSrW1dUV\
3d3dI35iPuI/r63Z1NQUzc3NEzghXBisADIurrjiiti1a1fs2LEj7r333lixYkX88pe/POfnW7du\
XeRyufKtpaVlDKcFakFfX190d3dHxMgXRD/5wurd3d1WAkmSAGRc1NfXx4IFC2Lx4sWxbt26WLRo\
UTz99NORz+fj6NGjcfDgwSH79/T0jPjT+po1a6K3t7d827dv3zgfAVBtMpnMGb8VZ7hv1fHJeVIk\
AJkQg4OD0d/fH4sXL44pU6bE1q1by491dHTE3r17o7W19bS/v6GhoXxZmRM3gFON9NWII32lIqTG\
OYCMuTVr1sTy5ctj3rx5cejQodi4cWO89tpr8eqrr0Yul4uVK1fG6tWrY+bMmZHNZuP++++P1tbW\
UX8CGGAkJ6LuROx1dnZGT09PDAwMlPcRf6ROADLm9u/fH3feeWd0d3dHLpeLq666Kl599dX4oz/6\
o4iI+Pa3vx2TJk2KW2+9Nfr7+2PZsmXxve99r8JTA7Xk1AgUfzCU6wBSlVw/CxiNX/ziF/HFb79W\
vv+jB66PRYsWVWyek3kdo5KcAwhATSoUCkNW/iI+WAkc6ZJTkAoBCEDNOfUDH3WT/vOfu5EuEQOp\
cA4gADXl1Pj7f4/fEfl8fsj2E786F5BUWQEEoGaMdKmXkS4RA6kRgADUhL6+vjNe52+4CPRNIKRI\
AAJQEzKZTDQ1NUXEyJd6OTkCm5qafBMISXIOIAA1o7m5ObLZ7BmjLp/PRyaTEX8kywogADVltFEn\
/kiZAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABI\
jAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwA\
BABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQA\
SIwApKb19fWN6X4AUAsEIDWrq6srOjo6olAojLhfoVCIjo6O6OrqmqDJAKCyBCA1qa+vL7q7uyMi\
orOz87QRWCgUorOzMyIiuru7rQQCkAQBSE3KZDIxZ86c8v3hIvDk+IuImDNnTmQymQmbEQAqZXKl\
B4Dxks/nIyLKkXfi199e//k4MDAQ+wcGYv7/+p8R8UH8ndgfAGqdFUDG3Lp16+Lqq6+O6dOnx+zZ\
s+Pmm2+Ojo6OIfscOXIk2tra4tJLL41MJhO33npr9PT0jPks+Xz+QyuBu48cif0DA+Vt4g+A1AhA\
xtz27dujra0t3njjjdiyZUscO3Ysli5dGocPHy7v88ADD8RLL70UL774Ymzfvj26urrilltuGZd5\
To3A4yc9Jv4ASFFdqVQqVXoIatuBAwdi9uzZsX379vjc5z4Xvb29MWvWrNi4cWPcdtttERGxe/fu\
+PjHPx7t7e1x3XXXnfE5i8Vi5HK56O3tjWw2O6o5fvGLX8TASSt/kydPjkWLFp3bQQGcp3N5HYOx\
YgWQcdfb2xsRETNnzoyIiJ07d8axY8diyZIl5X2uvPLKmDdvXrS3t4/LDIVCYUj8RUQMDAyc8RIx\
AFCLfAiEcTU4OBirVq2Kz372s/GJT3wiIj6Isfr6+pgxY8aQfRsbG08bZP39/dHf31++XywWRz3D\
qZ/2nTx5cjkGT2z3NjAAKbECyLhqa2uLd955J55//vnzep5169ZFLpcr31paWkb1+4a71MuiRYvO\
eIkYAKhlApBxc99998XLL78c27Zti7lz55a35/P5OHr0aBw8eHDI/j09PaddiVuzZk309vaWb/v2\
7Tvjnz9c/J14/uE+HSwCAUiFAGTMlUqluO+++2LTpk3xk5/8JObPnz/k8cWLF8eUKVNi69at5W0d\
HR2xd+/eaG1tHfY5GxoaIpvNDrmNpK+v77Txd8JwEeibQABIgXMAGXNtbW2xcePG+OEPfxjTp08v\
r6zlcrmYOnVq5HK5WLlyZaxevTpmzpwZ2Ww27r///mhtbR3VJ4BHI5PJRFNTU3R3d494qZeTLxbd\
1NTkm0AASILLwDDm6urqht3+7LPPxl133RURH1wI+sEHH4wf/OAH0d/fH8uWLYvvfe97o/4wxmgv\
n9DX1zeqqBvtfgBjxWVgqCQBSFXywglUO69jVJJzAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwAB\
ABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQAS\
IwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMA\
AQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEA\
EiMAAQASIwABABIjAAEAEiMAAQASIwABABIjAAEAEiMAAQASIwAZc6+//np86Utfiubm5qirq4vN\
mzcPebxUKsXatWujqakppk6dGkuWLIlf/epXlRkWABIkABlzhw8fjkWLFsUzzzwz7ONPPPFEfOc7\
34kNGzbEjh074uKLL45ly5bFkSNHJnhSAEjT5EoPQO1Zvnx5LF++fNjHSqVSPPXUU/Hwww/HTTfd\
FBER//RP/xSNjY2xefPm+LM/+7OJHBUAkmQFkAn13nvvRaFQiCVLlpS35XK5uPbaa6O9vb2CkwFA\
OqwAMqEKhUJERDQ2Ng7Z3tjYWH5sOP39/dHf31++XywWx2dAAEiAFUCqwrp16yKXy5VvLS0tlR4J\
AKqWAGRC5fP5iIjo6ekZsr2np6f82HDWrFkTvb295du+ffvGdU4AqGUCkAk1f/78yOfzsXXr1vK2\
YrEYO3bsiNbW1tP+voaGhshms0NuAMC5cQ4gY66vry/27NlTvv/ee+/Frl27YubMmTFv3rxYtWpV\
fOMb34iPfexjMX/+/HjkkUeiubk5br755soNDQAJEYCMubfeeis+//nPl++vXr06IiJWrFgRzz33\
XPzVX/1VHD58OL761a/GwYMH4w/+4A/iRz/6UVx00UWVGhkAklJXKpVKlR4CzlaxWIxcLhe9vb3e\
DgaqktcxKsk5gAAAiRGAAACJEYAAAIkRgAAAiRGAUIX6+vrGdD8A0iIAocp0dXVFR0fHiN+dHPHB\
9y53dHREV1fXBE0GQLUQgFBF+vr6oru7OyIiOjs7TxuBhUIhOjs7IyKiu7vbSiAAQwhAqCKZTCbm\
zJlTvj9cBJ4cfxERc+bMiUwmM2EzQi1y2gW1RgBClcnn86eNwOHiL5/PT/iMUEucdkEt8lVwUIVO\
RN2J2Ovs7Iyenp4YGBgo7yP+4PydetpFRAz7/9Wpp11ks1kr71zQrABClTp1JVD8wdhz2gW1ygog\
VLF8Pl9e+bvj5Ts+2DgpYs8jeyo7GNSQ4VbcT2x32gXVSgBCFSsUCkNW/iIiYvCD7f4RgrHjtAtq\
jQCEKnXqykNMiojBD/5zpHOVgHNzagQODAzEf39oVUREZKc2xH/93/+nUqPBWROAUIWGe9tpzyN7\
hmwXgTD2Tj7t4oRJk+oiO/WiCk4FZ8+HQKDKjHTO0UiXiAHO33CnXQwOlqL4uyMVmgjOjRVAqCJ9\
fX1nPOF8uHOVMpmMTyXCeTr1h6/JkyfHf3n8qSGPW3GnWlgBhCqSyWSiqakpIkY+4fzklcCmpibx\
B+dpuJX3RYsWWXGnalkBhCrT3Nw8qovM5vN5K38wBs502kXE8JeIgQuZFUCoQqONOvEH52e0p12c\
uhLoO4G50AlAADgNp11Qq7wFDAAjcNoFtcgKIACcgdMuqDUCEAAgMQIQACAxAhAAIDECEAAgMQIQ\
ACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAg\
MQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECkIp65pln4qMf/WhcdNFF\
ce2118abb75Z6ZEAoOYJQCrmhRdeiNWrV8ejjz4aP//5z2PRokWxbNmy2L9/f6VHA4CaJgCpmL/9\
27+Ne+65J+6+++5YuHBhbNiwIaZNmxb/+I//WOnRAKCmCUAq4ujRo7Fz585YsmRJedukSZNiyZIl\
0d7eXsHJAKD2Ta70AKTpN7/5TRw/fjwaGxuHbG9sbIzdu3d/aP/+/v7o7+8v3y8Wi+M+IwDUKiuA\
VIV169ZFLpcr31paWio9EgBULQFIRVx22WXxkY98JHp6eoZs7+npiXw+/6H916xZE729veXbvn37\
JmpUAKg5ApCKqK+vj8WLF8fWrVvL2wYHB2Pr1q3R2tr6of0bGhoim80OuQEA58Y5gFTM6tWrY8WK\
FfHpT386rrnmmnjqqafi8OHDcffdd1d6NACoaQKQirnjjjviwIEDsXbt2igUCvGpT30qfvSjH33o\
gyEAwNiqK5VKpUoPAWerWCxGLpeL3t5ebwcDVcnrGJXkHEAAgMQIQACAxAhAAIDECEAAgMQIQACA\
xAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQI\
QACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAA\
gMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDE\
CEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAAIDECEAAgMQIQACAxAhAxtxjjz0Wn/nMZ2LatGkx\
Y8aMYffZu3dv3HjjjTFt2rSYPXt2fO1rX4uBgYGJHRQAEjW50gNQe44ePRq33357tLa2xj/8wz98\
6PHjx4/HjTfeGPl8Pn76059Gd3d33HnnnTFlypT45je/WYGJASAtdaVSqVTpIahNzz33XKxatSoO\
Hjw4ZPsrr7wSf/zHfxxdXV3R2NgYEREbNmyIv/7rv44DBw5EfX39GZ+7WCxGLpeL3t7eyGaz4zE+\
wLjyOkYleQuYCdfe3h6f/OQny/EXEbFs2bIoFovx7rvvVnAyAEiDt4CZcIVCYUj8RUT5fqFQGPb3\
9Pf3R39/f/l+sVgcvwEBoMZZAWRUHnrooairqxvxtnv37nH789etWxe5XK58a2lpGbc/CwBqnRVA\
RuXBBx+Mu+66a8R9Lr/88lE9Vz6fjzfffHPItp6envJjw1mzZk2sXr26fL9YLIpAADhHApBRmTVr\
VsyaNWtMnqu1tTUee+yx2L9/f8yePTsiIrZs2RLZbDYWLlw47O9paGiIhoaGMfnzASB1ApAxt3fv\
3nj//fdj7969cfz48di1a1dERCxYsCAymUwsXbo0Fi5cGF/+8pfjiSeeiEKhEA8//HC0tbWJPACY\
AC4Dw5i766674vvf//6Htm/bti2uv/76iIj493//97j33nvjtddei4svvjhWrFgRjz/+eEyePLqf\
SVw+Aah2XseoJAFIVfLCCVQ7r2NUkk8BAwAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAk\
RgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYA\
AgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIA\
JEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRG\
AAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGADKmfv3rX8fKlStj/vz5MXXq1Pj93//9ePTR\
R+Po0aND9vuXf/mX+MM//MO46KKLoqWlJZ544okKTQwA6Zlc6QGoLbt3747BwcH4u7/7u1iwYEG8\
8847cc8998Thw4fjW9/6VkREFIvFWLp0aSxZsiQ2bNgQb7/9dnzlK1+JGTNmxFe/+tUKHwEA1L66\
UqlUqvQQ1LYnn3wy1q9fH//2b/8WERHr16+Pr3/961EoFKK+vj4iIh566KHYvHlz7N69e1TPWSwW\
I5fLRW9vb2Sz2XGbHWC8eB2jkrwFzLjr7e2NmTNnlu+3t7fH5z73uXL8RUQsW7YsOjo64re//W0l\
RgSApAhAxtWePXviu9/9bvzFX/xFeVuhUIjGxsYh+524XygUhn2e/v7+KBaLQ24AwLkRgIzKQw89\
FHV1dSPeTn37trOzM774xS/G7bffHvfcc895/fnr1q2LXC5XvrW0tJzX8wFAypwDyKgcOHAg/uM/\
/mPEfS6//PLy27pdXV1x/fXXx3XXXRfPPfdcTJr0nz9r3HnnnVEsFmPz5s3lbdu2bYsbbrgh3n//\
/bjkkks+9Nz9/f3R399fvl8sFqOlpcW5M0DVcg4gleRTwIzKrFmzYtasWaPat7OzMz7/+c/H4sWL\
49lnnx0SfxERra2t8fWvfz2OHTsWU6ZMiYiILVu2xBVXXDFs/EVENDQ0RENDw/kdBAAQEd4CZox1\
dnbG9ddfH/PmzYtvfetbceDAgSgUCkPO7fvzP//zqK+vj5UrV8a7774bL7zwQjz99NOxevXqCk4O\
AOmwAsiY2rJlS+zZsyf27NkTc+fOHfLYibMNcrlc/PjHP462trZYvHhxXHbZZbF27VrXAASACeIc\
QKqSc2eAaud1jEryFjAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBi\
BCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQgAEBiBCAAQGIEIABAYgQg\
AJyFvr6+Md0PKkEAAsAodXV1RUdHRxQKhRH3KxQK0dHREV1dXRM0GZwdAQgAo9DX1xfd3d0REdHZ\
2XnaCCwUCtHZ2RkREd3d3VYCuSAJQAAYhUwmE3PmzCnfHy4CT46/iIg5c+ZEJpOZsBlhtAQgAIxS\
Pp8/bQQOF3/5fH7CZ4TRmFzpAQCgmpyIuhOx19nZGT09PTEwMFDeR/xxoROAAHCWTo7A//HNn5W3\
/+nfXC3+qAreAgaAc5DP52Py5KHrKJMnTxZ/VAUBCADnoFAoDHnbNyJiYGDgjJeIgQuBt4AB4Cyd\
/IGPP/2bq2Py5MnlGDyx3UogFzIrgABwFob7tO+iRYvOeIkYuJAIQAAYpZEu9TLSJWLgQiMAAWAU\
+vr6znidv+Ei0DeBcCESgAAwCplMJpqamiJi5Ov8nRyBTU1NvgmEC5IPgQDAKDU3N0c2mz1j1OXz\
+chkMuKPC5YVQAA4C6ONOvHHhUwAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkxoWg\
qUqlUikiIorFYoUnATg3J16/TryewUQSgFSlQ4cORURES0tLhScBOD+HDh2KXC5X6TFITF3Jjx5U\
ocHBwejq6orp06dHXV1dpccZU8ViMVpaWmLfvn2RzWYrPc64cZy1xXGevVKpFIcOHYrm5uaYNMkZ\
WUwsK4BUpUmTJsXcuXMrPca4ymazNf0P6QmOs7Y4zrNj5Y9K8SMHAEBiBCAAQGIEIFxgGhoa4tFH\
H42GhoZKjzKuHGdtcZxQXXwIBAAgMVYAAQASIwABABIjAAEAEiMAAQASIwDhAvLYY4/FZz7zmZg2\
bVrMmDFj2H327t0bN954Y0ybNi1mz54dX/va12JgYGBiBz1PzzzzTHz0ox+Niy66KK699tp48803\
Kz3SeXv99dfjS1/6UjQ3N0ddXV1s3rx5yOOlUinWrl0bTU1NMXXq1FiyZEn86le/qsyw52jdunVx\
9dVXx/Tp02P27Nlx8803R0dHx5B9jhw5Em1tbXHppZdGJpOJW2+9NXp6eio08blZv359XHXVVeWL\
Pbe2tsYrr7xSfrwWjhEEIFxAjh49Grfffnvce++9wz5+/PjxuPHGG+Po0aPx05/+NL7//e/Hc889\
F2vXrp3gSc/dCy+8EKtXr45HH300fv7zn8eiRYti2bJlsX///kqPdl4OHz4cixYtimeeeWbYx594\
4on4zne+Exs2bIgdO3bExRdfHMuWLYsjR45M8KTnbvv27dHW1hZvvPFGbNmyJY4dOxZLly6Nw4cP\
l/d54IEH4qWXXooXX3wxtm/fHl1dXXHLLbdUcOqzN3fu3Hj88cdj586d8dZbb8UNN9wQN910U7z7\
7rsRURvHCFECLjjPPvtsKZfLfWj7P//zP5cmTZpUKhQK5W3r168vZbPZUn9//wROeO6uueaaUltb\
W/n+8ePHS83NzaV169ZVcKqxFRGlTZs2le8PDg6W8vl86cknnyxvO3jwYKmhoaH0gx/8oAITjo39\
+/eXIqK0ffv2Uqn0wTFNmTKl9OKLL5b3+dd//ddSRJTa29srNeaYuOSSS0p///d/X9PHSFqsAEIV\
aW9vj09+8pPR2NhY3rZs2bIoFovl1YkL2dGjR2Pnzp2xZMmS8rZJkybFkiVLor29vYKTja/33nsv\
CoXCkOPO5XJx7bXXVvVx9/b2RkTEzJkzIyJi586dcezYsSHHeeWVV8a8efOq9jiPHz8ezz//fBw+\
fDhaW1tr8hhJ0+RKDwCMXqFQGBJ/EVG+XygUKjHSWfnNb34Tx48fH/YYdu/eXaGpxt+Jv5vhjrsa\
/t6GMzg4GKtWrYrPfvaz8YlPfCIiPjjO+vr6D52/Wo3H+fbbb0dra2scOXIkMplMbNq0KRYuXBi7\
du2qmWMkbVYAYZw99NBDUVdXN+KtluOH2tTW1hbvvPNOPP/885UeZVxcccUVsWvXrtixY0fce++9\
sWLFivjlL39Z6bFgzFgBhHH24IMPxl133TXiPpdffvmoniufz3/oE7MnPn2Yz+fPab6JdNlll8VH\
PvKRD31isqenpyrmP1cnjq2npyeamprK23t6euJTn/pUhaY6d/fdd1+8/PLL8frrr8fcuXPL2/P5\
fBw9ejQOHjw4ZIWsGv9+6+vrY8GCBRERsXjx4vjZz34WTz/9dNxxxx01c4ykzQogjLNZs2bFlVde\
OeKtvr5+VM/V2toab7/99pBPzG7ZsiWy2WwsXLhwvA5hzNTX18fixYtj69at5W2Dg4OxdevWaG1t\
reBk42v+/PmRz+eHHHexWIwdO3ZU1XGXSqW47777YtOmTfGTn/wk5s+fP+TxxYsXx5QpU4YcZ0dH\
R+zdu7eqjnM4g4OD0d/fX9PHSFqsAMIFZO/evfH+++/H3r174/jx47Fr166IiFiwYEFkMplYunRp\
LFy4ML785S/HE088EYVCIR5++OFoa2uLhoaGyg4/SqtXr44VK1bEpz/96bjmmmviqaeeisOHD8fd\
d99d6dHOS19fX+zZs6d8/7333otdu3bFzJkzY968ebFq1ar4xje+ER/72Mdi/vz58cgjj0Rzc3Pc\
fPPNlRv6LLW1tcXGjRvjhz/8YUyfPr18zlsul4upU6dGLpeLlStXxurVq2PmzJmRzWbj/vvvj9bW\
1rjuuusqPP3orVmzJpYvXx7z5s2LQ4cOxcaNG+O1116LV199tWaOEVwGBi4gK1asKEXEh27btm0r\
7/PrX/+6tHz58tLUqVNLl112WenBBx8sHTt2rHJDn4Pvfve7pXnz5pXq6+tL11xzTemNN96o9Ejn\
bdu2bcP+3a1YsaJUKn1wKZhHHnmk1NjYWGpoaCh94QtfKHV0dFR26LM03PFFROnZZ58t7/O73/2u\
9Jd/+ZelSy65pDRt2rTSn/zJn5S6u7srN/Q5+MpXvlL6vd/7vVJ9fX1p1qxZpS984QulH//4x+XH\
a+EYoa5UKpUmPjsBAKgU5wACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYA\
AgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIA\
JEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACRGAAIAJEYAAgAkRgACACTm\
/wM/8peVg/PuJwAAAABJRU5ErkJggg==\
"


    /* set a timeout to make sure all the above elements are created before
       the object is initialized. */
    setTimeout(function() {
        animbf18fa8feeef42df9ff1917d1946c4bf = new Animation(frames, img_id, slider_id, 500.0,
                                 loop_select_id);
    }, 0);
  })()
</script>
</div>
</div>
</section>
<section id="running-the-algorithm-on-the-gpu" class="level2">
<h2 class="anchored" data-anchor-id="running-the-algorithm-on-the-gpu">Running the Algorithm on the GPU</h2>
<p>Instead of updating one data point at a time:</p>
<div class="sourceCode" id="cb91" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><span class="kw" style="color: #003B4F;">def</span> one_update(X):</span>
<span id="cb91-2">    <span class="cf" style="color: #003B4F;">for</span> i, x <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(X):</span>
<span id="cb91-3">        dist <span class="op" style="color: #5E5E5E;">=</span> torch.sqrt(((x<span class="op" style="color: #5E5E5E;">-</span>X)<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb91-4">        weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist, <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb91-5">        X[i] <span class="op" style="color: #5E5E5E;">=</span> (weight[:,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)<span class="op" style="color: #5E5E5E;">/</span>weight.<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<p>What if we updates one batch at a time on the GPU?</p>
<div class="cell" data-outputid="4e4708eb-f6ad-4c71-9a8b-dc5ec04ab5b7" data-execution_count="74">
<div class="sourceCode cell-code" id="cb92" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1">bs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb92-2">X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb92-3">x <span class="op" style="color: #5E5E5E;">=</span> X[:bs]</span>
<span id="cb92-4">x.shape,X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>(torch.Size([5, 2]), torch.Size([1500, 2]))</code></pre>
</div>
</div>
<p>To calculate the distance between the two, we have to first subtract them. To do this subtraction, the current dimensions won’t work (as 1500 is not compatible with 5):</p>
<div class="cell" data-outputid="50d7fd6a-10a3-4dba-bd94-73a600ac094a" data-execution_count="75">
<div class="sourceCode cell-code" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1">x<span class="op" style="color: #5E5E5E;">-</span>X</span></code></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: The size of tensor a (5) must match the size of tensor b (1500) at non-singleton dimension 0</code></pre>
</div>
</div>
<p>Let’s think about what we are trying to do here. We want to subtract from each point in the batch <code>x</code> every point in the full set <code>X</code>. So each pair of 1500 coordinates need to be subtracted from each pair of 5 coordinates.</p>
<p>I find it easier to start with “just making the dimensions work” for broadcasting.</p>
<div class="cell" data-outputid="ebd280c5-981b-49d5-b4b1-465cf4cb2c59" data-execution_count="76">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">x[<span class="va" style="color: #111111;">None</span>].shape, X[:,<span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>(torch.Size([1, 5, 2]), torch.Size([1500, 1, 2]))</code></pre>
</div>
</div>
<p>Going right to left: the last dimension matches (2), 1 is compatible with 5 and 1 is compatible with 1500. We can subtract these two tensors.</p>
<div class="cell" data-outputid="b6a5c8c5-dd00-4747-c663-f38bc965afc1" data-execution_count="77">
<div class="sourceCode cell-code" id="cb98" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1">(x[<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">-</span>X[:,<span class="va" style="color: #111111;">None</span>]).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>torch.Size([1500, 5, 2])</code></pre>
</div>
</div>
<p>The result is 1500 sets of 5 coordinate pairs. The 5 coordinate pairs are the difference between the coordinates in batch <code>x</code> and a coordinate in <code>X</code>.</p>
<p>Checking this manually, let’s take the first point in <code>x</code>.</p>
<div class="cell" data-outputid="d5f5ddfb-e497-4742-c175-ebf6db35494a" data-execution_count="78">
<div class="sourceCode cell-code" id="cb100" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1">x[<span class="dv" style="color: #AD0000;">0</span>,:].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>torch.Size([2])</code></pre>
</div>
</div>
<p>The dimension of 2 is compatible with the last dimension of <code>X</code> so we can subtract these shapes directly.</p>
<div class="cell" data-outputid="a293bd2c-da84-4dbe-868c-f2a776042d98" data-execution_count="79">
<div class="sourceCode cell-code" id="cb102" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1">(x[<span class="dv" style="color: #AD0000;">0</span>,:] <span class="op" style="color: #5E5E5E;">-</span> X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>torch.Size([1500, 2])</code></pre>
</div>
</div>
<p>This difference is equal to the first item of the batch in the broadcasted version.</p>
<div class="cell" data-outputid="2effa53b-6762-4b72-9419-c7105cf63f07" data-execution_count="81">
<div class="sourceCode cell-code" id="cb104" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1">((x[<span class="dv" style="color: #AD0000;">0</span>,:] <span class="op" style="color: #5E5E5E;">-</span> X) <span class="op" style="color: #5E5E5E;">==</span> (x[<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">-</span>X[:,<span class="va" style="color: #111111;">None</span>])[:,<span class="dv" style="color: #AD0000;">0</span>,:]).<span class="bu" style="color: null;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>tensor(1.)</code></pre>
</div>
</div>
<p>With that under my belt, I’ll now visualize the broadcasting operation to better understand why the dimensions “just work”.</p>
<p>Adding the unit axis to <code>x</code> (our batch of 5 coordinates) as the first dimension is not as intuitive visually as it just adds a pair of brackets to the outside of the 5 coordinates. However, what this does is allow the set of 5 coordinates (as a group) to be broadcasted across another dimension of any size.</p>
<div class="cell" data-outputid="892f60a0-7101-4652-94b9-267b74ed5f4e" data-execution_count="82">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1">x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="82">
<pre><code>tensor([[29.764, 26.161],
        [28.472, 30.493],
        [27.549, 23.130],
        [23.500, 26.879],
        [27.327, 28.650]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ac571ee7-26d4-40e7-b3a8-08e0e5df58b3" data-execution_count="83">
<div class="sourceCode cell-code" id="cb108" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1">x[<span class="va" style="color: #111111;">None</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>tensor([[[29.764, 26.161],
         [28.472, 30.493],
         [27.549, 23.130],
         [23.500, 26.879],
         [27.327, 28.650]]])</code></pre>
</div>
</div>
<p>Adding the unit axis as the second dimension to <code>X</code> (our full set of 1500 coordinates) is more visually intuitive—we’ve added a pair of brackets around each pair of coordinates, making them broadcastable to any other dimension.</p>
<div class="cell" data-outputid="c12a9c8b-b0ff-41a4-9fde-23d5d1f6a456" data-execution_count="84">
<div class="sourceCode cell-code" id="cb110" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1">X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>tensor([[29.764, 26.161],
        [28.472, 30.493],
        [27.549, 23.130],
        ...,
        [32.214,  4.997],
        [30.872,  4.339],
        [28.347,  4.248]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e7b438ba-fae5-44fb-91bd-8cb7b9df97af" data-execution_count="86">
<div class="sourceCode cell-code" id="cb112" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1">X[:,<span class="va" style="color: #111111;">None</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>tensor([[[29.764, 26.161]],

        [[28.472, 30.493]],

        [[27.549, 23.130]],

        ...,

        [[32.214,  4.997]],

        [[30.872,  4.339]],

        [[28.347,  4.248]]])</code></pre>
</div>
</div>
<p>So our batch of 5 coordinates <code>x</code> can now be broadcasted as many times as needed, and each pair of coordinates in <code>X</code> can also be broadcasted as many times as needed.</p>
<p>The result: each pair of coordinates in <code>X</code> is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch. And the batch is broadcasted 1500 times so that each pair of coordinates in <code>X</code> can be subtracted from it.</p>
<p>Looking at each of those statements visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" title="Each pair of coordinates in X is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch" data-gallery="quarto-lightbox-gallery-7"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Each pair of coordinates in X is broadcasted 5 times so they can be subtracted from each pair of coordinates in the batch</figcaption><p></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" title="The batch x is broadcasted 1500 times so that each pair of coordinates in X can be subtracted from it." data-gallery="quarto-lightbox-gallery-8"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/3.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">The batch <code>x</code> is broadcasted 1500 times so that each pair of coordinates in <code>X</code> can be subtracted from it.</figcaption><p></p>
</figure>
</div>
<p>With the understood, I can now continue with the batched implementation of the algorithm. With the correct shapes, thanks to adding unit axes, we can create a batched distance function:</p>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb114" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><span class="kw" style="color: #003B4F;">def</span> dist_b(a,b): <span class="cf" style="color: #003B4F;">return</span> (((a[<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">-</span>b[:,<span class="va" style="color: #111111;">None</span>])<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">2</span>)).sqrt()</span></code></pre></div>
</div>
<div class="cell" data-outputid="ce2e61e4-4895-472b-d120-d0844f6fbe51" data-execution_count="90">
<div class="sourceCode cell-code" id="cb115" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1">dist_b(x,X).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>torch.Size([1500, 5])</code></pre>
</div>
</div>
<p>We now have 5 distances for each of the 1500 items in the dataset.</p>
<div class="cell" data-outputid="46dc7bba-8d45-40f6-c502-90d9438dba39" data-execution_count="91">
<div class="sourceCode cell-code" id="cb117" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1">dist_b(x,X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>tensor([[ 0.000,  4.521,  3.754,  6.305,  3.483],
        [ 4.521,  0.000,  7.421,  6.148,  2.170],
        [ 3.754,  7.421,  0.000,  5.518,  5.524],
        ...,
        [21.305, 25.769, 18.724, 23.553, 24.152],
        [21.850, 26.264, 19.083, 23.714, 24.568],
        [21.958, 26.246, 18.899, 23.144, 24.423]])</code></pre>
</div>
</div>
<p>The first row are the distances between the first coordinate pair in <code>X</code> and each of the coordinate pairs in the batch. The second row contains distances between the <em>second</em> coordinate pair in `X and each of the batch coordinate pairs. And so on an so forth for 1500 rows. Each with 5 distances representing the distances to the batch items.</p>
<p>We pass this tensor into our <code>gaussian</code> and get back our weights.</p>
<div class="cell" data-outputid="97cadee8-dfa3-4e93-cace-bc52cf9d31bc" data-execution_count="92">
<div class="sourceCode cell-code" id="cb119" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1">weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist_b(x, X), <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb119-2">weight, weight.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>(tensor([[    0.160,     0.031,     0.052,     0.007,     0.060],
         [    0.031,     0.160,     0.002,     0.008,     0.109],
         [    0.052,     0.002,     0.160,     0.014,     0.014],
         ...,
         [    0.000,     0.000,     0.000,     0.000,     0.000],
         [    0.000,     0.000,     0.000,     0.000,     0.000],
         [    0.000,     0.000,     0.000,     0.000,     0.000]]),
 torch.Size([1500, 5]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="09929ac2-c816-45e0-ea6c-fd4a2dff55d1" data-execution_count="93">
<div class="sourceCode cell-code" id="cb121" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1">weight[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>tensor([[0.160, 0.031, 0.052, 0.007, 0.060],
        [0.031, 0.160, 0.002, 0.008, 0.109],
        [0.052, 0.002, 0.160, 0.014, 0.014],
        [0.007, 0.008, 0.014, 0.160, 0.038],
        [0.060, 0.109, 0.014, 0.038, 0.160]])</code></pre>
</div>
</div>
<p>Looking at the first 5 rows of our weights we have a square matrix—the weights between the first 5 points (i.e.&nbsp;the points in our batch). From row 6 we have the weights from these 5 points to point 6.</p>
<p>Technically we could have a batch size of 1500 and the weights in full would be a square matrix.</p>
<p>Now for the fun part! Understanding broadcasting so we can perform the weighted average, which starts with an elementwise multiplication betwee the weights and the data points.</p>
<p>Conceptually we want something like this (example shown for the first two batch items’ weights)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="4.png" class="lightbox" title="Multiplying weights by X and summing down the columns to get a pair of coordinates" data-gallery="quarto-lightbox-gallery-9"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/4.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Multiplying weights by <code>X</code> and summing down the columns to get a pair of coordinates</figcaption><p></p>
</figure>
</div>
<div class="cell" data-outputid="e2bc5d14-794d-431b-9fc9-36f9f77748ff" data-execution_count="94">
<div class="sourceCode cell-code" id="cb123" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1">weight.shape,X.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>(torch.Size([1500, 5]), torch.Size([1500, 2]))</code></pre>
</div>
</div>
<p>The last dimension of each tensor is not compatible (5 and 2). We need to introduce a unit axis so that we can broadcast the 5 batch items to each of the 1500 coordinate pairs.</p>
<p>We’ll again start by “just making the dimensions work”, adding a unit axis to the end of <code>weight</code> and the beginning of <code>X</code>. Scanning the dimensions left to right: 1 and 2 are compatible, 5 and 1 are compatible, 1500 and 1500 are compatible.</p>
<div class="cell" data-outputid="eb218202-3664-40fd-878b-e5edefae4afb" data-execution_count="96">
<div class="sourceCode cell-code" id="cb125" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1">weight[...,<span class="va" style="color: #111111;">None</span>].shape, X[:,<span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="96">
<pre><code>(torch.Size([1500, 5, 1]), torch.Size([1500, 1, 2]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="88879916-329f-4984-a4ea-b78bb04ae309" data-execution_count="98">
<div class="sourceCode cell-code" id="cb127" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>]).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>torch.Size([1500, 5, 2])</code></pre>
</div>
</div>
<p>We’ll sum down the first dimension to get 5 pairs of coordinate.</p>
<div class="cell" data-outputid="799cde40-d374-42b5-90e3-71df21d6f19a" data-execution_count="100">
<div class="sourceCode cell-code" id="cb129" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>]).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>The first pair of coordinates <code>[296.880, 291.612]</code> are the sum of the first pair of elementwise products in each set of 5 batched items in each of the 1500 rows.</p>
<div class="cell" data-outputid="38638dce-e5bb-4d73-d797-f327004f65b2" data-execution_count="102">
<div class="sourceCode cell-code" id="cb131" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb131-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="102">
<pre><code>tensor([[[    4.750,     4.175],
         [    0.926,     0.814],
         [    1.539,     1.352],
         [    0.197,     0.174],
         [    1.799,     1.581]],

        [[    0.886,     0.948],
         [    4.544,     4.866],
         [    0.055,     0.059],
         [    0.221,     0.237],
         [    3.117,     3.338]],

        [[    1.424,     1.196],
         [    0.054,     0.045],
         [    4.396,     3.691],
         [    0.385,     0.323],
         [    0.383,     0.321]],

        ...,

        [[    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000]],

        [[    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000]],

        [[    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000],
         [    0.000,     0.000]]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="8b9975f5-7a26-4b50-c422-516c074f1457" data-execution_count="101">
<div class="sourceCode cell-code" id="cb133" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>])[:, <span class="dv" style="color: #AD0000;">0</span>,:]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>tensor([[    4.750,     4.175],
        [    0.886,     0.948],
        [    1.424,     1.196],
        ...,
        [    0.000,     0.000],
        [    0.000,     0.000],
        [    0.000,     0.000]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="e933a913-9612-43f7-b045-e1cdfa54246c" data-execution_count="103">
<div class="sourceCode cell-code" id="cb135" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb135-1">(weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>])[:, <span class="dv" style="color: #AD0000;">0</span>,:].<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="103">
<pre><code>tensor([296.880, 291.612])</code></pre>
</div>
</div>
<p>Looking at this visually:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="5.png" class="lightbox" title="Elementwise multiplication of weight[...,None] and X[None] followed by sum(0) down the columns" data-gallery="quarto-lightbox-gallery-10"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/5.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Elementwise multiplication of <code>weight[...,None]</code> and <code>X[None]</code> followed by <code>sum(0)</code> down the columns</figcaption><p></p>
</figure>
</div>
<div class="cell" data-outputid="24c589bb-5afd-4a22-b782-d02fda9014d0" data-execution_count="104">
<div class="sourceCode cell-code" id="cb137" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1">num <span class="op" style="color: #5E5E5E;">=</span> (weight[...,<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span>X[:,<span class="va" style="color: #111111;">None</span>]).<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb137-2">num.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<pre><code>torch.Size([5, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="c2cd5385-3d97-4466-f358-1909a3052608" data-execution_count="105">
<div class="sourceCode cell-code" id="cb139" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1">num</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="105">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>Since we are performing an elementwise multiplication follow by a sum, we can use Einstein Summation!</p>
<div class="cell" data-outputid="351261a0-1f6c-42c0-b9a3-59ba6a9d018b" data-execution_count="106">
<div class="sourceCode cell-code" id="cb141" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1">torch.einsum(<span class="st" style="color: #20794D;">'ij,ik-&gt;jk'</span>, weight, X)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="106">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>Similary, we can also use matrix multiplication:</p>
<div class="cell" data-outputid="6ac52bec-aa75-4dcf-e09a-b109ceb88075" data-execution_count="107">
<div class="sourceCode cell-code" id="cb143" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1">weight.T<span class="op" style="color: #5E5E5E;">@</span>X</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="107">
<pre><code>tensor([[296.880, 291.612],
        [476.489, 514.066],
        [140.263, 134.432],
        [278.256, 307.251],
        [577.373, 615.003]])</code></pre>
</div>
</div>
<p>To get our weighted average, we divide by the sum of weights.</p>
<div class="cell" data-outputid="c26dfad0-c4fe-41b3-c3a6-90e2bd57224b" data-execution_count="108">
<div class="sourceCode cell-code" id="cb145" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1">div <span class="op" style="color: #5E5E5E;">=</span> weight.<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>, keepdim<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>).T</span>
<span id="cb145-2">div.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>torch.Size([5, 1])</code></pre>
</div>
</div>
<p>We want to perform an elementwise division (each coordinate needs to be divided by the sum of weights) so we <code>keepdim</code>.</p>
<div class="cell" data-outputid="2faf142c-34ee-4d90-9960-0e47b687e9f1" data-execution_count="109">
<div class="sourceCode cell-code" id="cb147" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1">div</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="109">
<pre><code>tensor([[10.558],
        [17.315],
        [ 5.167],
        [10.983],
        [21.347]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ff53f7c2-c478-48b9-d730-25c8998caf58" data-execution_count="110">
<div class="sourceCode cell-code" id="cb149" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1">num<span class="op" style="color: #5E5E5E;">/</span>div</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>tensor([[28.118, 27.619],
        [27.519, 29.689],
        [27.145, 26.016],
        [25.334, 27.974],
        [27.047, 28.810]])</code></pre>
</div>
</div>
<p>Wrapping this into a new <code>meanshift</code> function. Each step now performs batched calculations.</p>
<div class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb151" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><span class="kw" style="color: #003B4F;">def</span> meanshift(data, bs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">500</span>):</span>
<span id="cb151-2">    n <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(data)</span>
<span id="cb151-3">    X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb151-4">    <span class="cf" style="color: #003B4F;">for</span> it <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb151-5">        <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">0</span>, n, bs):</span>
<span id="cb151-6">            s <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">slice</span>(i, <span class="bu" style="color: null;">min</span>(i<span class="op" style="color: #5E5E5E;">+</span>bs,n))</span>
<span id="cb151-7">            weight <span class="op" style="color: #5E5E5E;">=</span> gaussian(dist_b(X[s], X), <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb151-8">            div <span class="op" style="color: #5E5E5E;">=</span> weight.<span class="bu" style="color: null;">sum</span>(<span class="dv" style="color: #AD0000;">0</span>, keepdim<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>).T</span>
<span id="cb151-9">            X[s] <span class="op" style="color: #5E5E5E;">=</span> weight.T<span class="op" style="color: #5E5E5E;">@</span>X<span class="op" style="color: #5E5E5E;">/</span>div</span>
<span id="cb151-10">    <span class="cf" style="color: #003B4F;">return</span> X</span></code></pre></div>
</div>
<p>We can now utilize the GPU (since we’re doing batched calculations)</p>
<div class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb152" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1">data <span class="op" style="color: #5E5E5E;">=</span> data.cuda()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb153" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1">X <span class="op" style="color: #5E5E5E;">=</span> meanshift(data).cpu()</span></code></pre></div>
</div>
<div class="cell" data-outputid="e3206486-deea-434b-f00b-1c99fa7dc777" data-execution_count="117">
<div class="sourceCode cell-code" id="cb154" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">5</span> _<span class="op" style="color: #5E5E5E;">=</span>meanshift(data, <span class="dv" style="color: #AD0000;">1250</span>).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.37 ms ± 43.1 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)</code></pre>
</div>
</div>
<p>Using the GPU we cut the execution time from 1.5 seconds to 6 milliseconds to achieve the same result.</p>
<div class="cell" data-outputid="78b63bcb-5b59-428e-86a8-4ecb22c7b14c" data-execution_count="118">
<div class="sourceCode cell-code" id="cb156" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><span class="dv" style="color: #AD0000;">1500</span><span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">6</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>250.0</code></pre>
</div>
</div>
<div class="cell" data-outputid="5e20a9d4-31f5-49c6-a56c-3789affd7708" data-execution_count="119">
<div class="sourceCode cell-code" id="cb158" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1">plot_data(centroids, X, n_samples)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-92-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-11"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index_files/figure-html/cell-92-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>If we perform the unbatched calculation using the GPU, we don’t see this speed up.</p>
<div class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb159" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1"><span class="kw" style="color: #003B4F;">def</span> meanshift(data, n<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>):</span>
<span id="cb159-2">    X <span class="op" style="color: #5E5E5E;">=</span> data.clone()</span>
<span id="cb159-3">    <span class="cf" style="color: #003B4F;">for</span> it <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(n): one_update(X)</span>
<span id="cb159-4">    <span class="cf" style="color: #003B4F;">return</span> X</span></code></pre></div>
</div>
<div class="cell" data-outputid="b21cd686-b3e1-43ca-a8c3-7d419ab3633c" data-execution_count="122">
<div class="sourceCode cell-code" id="cb160" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><span class="op" style="color: #5E5E5E;">%</span>time X <span class="op" style="color: #5E5E5E;">=</span> meanshift(data.cuda()).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.33 s, sys: 969 µs, total: 1.33 s
Wall time: 1.33 s</code></pre>
</div>
</div>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Implementing mean shift clustering become an exercise in understanding broadcasting! The weighted average (elementwise multiplication followed by a summation down an axis) is well suited for broadcasting, Einstein Summation and matrix multiplication. Seeing the relationships between dimensions, and seeing how adding unit axes in a particular spot to allow for broadcasting gave me a deeper understanding of how tensor calculations work. We also saw a clear example of how the GPU only gives you a speedup if you perform batch operations on it.</p>
<p>I’m trying to grow my YouTube channel so if you’re interesting in this type of content, <a href="https://www.youtube.com/@vishal_learner">please subscribe!</a></p>


</section>

 ]]></description>
  <category>python</category>
  <category>machine learning</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/index.html</guid>
  <pubDate>Sat, 31 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-05-30-meanshift/1.png" medium="image" type="image/png" height="81" width="144"/>
</item>
<item>
  <title>Exploring Precision in ColBERT Indexing and Retrieval</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-25-Exploring-ColBERT-Precision/index.html</link>
  <description><![CDATA[ 



<div class="cell" data-execution_count="4">
<details>
<summary>Ensure faiss-gpu is correctly installed</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> faiss</span>
<span id="cb1-2"><span class="bu" style="color: null;">hasattr</span>(faiss, <span class="st" style="color: #20794D;">"StandardGpuResources"</span>)</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<details>
<summary>Show imports</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb3-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="im" style="color: #00769E;">from</span> colbert.data <span class="im" style="color: #00769E;">import</span> Queries</span>
<span id="cb3-5"><span class="im" style="color: #00769E;">from</span> colbert.infra <span class="im" style="color: #00769E;">import</span> Run, RunConfig, ColBERTConfig</span>
<span id="cb3-6"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Searcher</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb3-9"><span class="im" style="color: #00769E;">import</span> numpy</span>
<span id="cb3-10"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb3-11"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb3-12"><span class="im" style="color: #00769E;">import</span> tqdm</span>
<span id="cb3-13"><span class="im" style="color: #00769E;">import</span> glob</span>
<span id="cb3-14"><span class="im" style="color: #00769E;">import</span> re</span>
<span id="cb3-15"><span class="im" style="color: #00769E;">import</span> pytrec_eval</span>
<span id="cb3-16"><span class="im" style="color: #00769E;">import</span> pickle</span></code></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Show indexing + memory profiling script</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;">import</span> colbert</span>
<span id="cb4-2"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Indexer, Searcher</span>
<span id="cb4-3"><span class="im" style="color: #00769E;">from</span> colbert.infra <span class="im" style="color: #00769E;">import</span> Run, RunConfig, ColBERTConfig</span>
<span id="cb4-4"><span class="im" style="color: #00769E;">from</span> colbert.data <span class="im" style="color: #00769E;">import</span> Queries, Collection</span>
<span id="cb4-5"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb4-6"><span class="im" style="color: #00769E;">import</span> threading</span>
<span id="cb4-7"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb4-8"><span class="im" style="color: #00769E;">import</span> psutil</span>
<span id="cb4-9"><span class="im" style="color: #00769E;">from</span> datetime <span class="im" style="color: #00769E;">import</span> datetime</span>
<span id="cb4-10"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb4-11"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb4-12"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb4-13"><span class="im" style="color: #00769E;">import</span> argparse </span>
<span id="cb4-14"><span class="im" style="color: #00769E;">import</span> pynvml</span>
<span id="cb4-15"></span>
<span id="cb4-16"><span class="kw" style="color: #003B4F;">def</span> memory_monitor(stop_event, cpu_readings, gpu_readings):</span>
<span id="cb4-17">    pynvml.nvmlInit()</span>
<span id="cb4-18">    handle <span class="op" style="color: #5E5E5E;">=</span> pynvml.nvmlDeviceGetHandleByIndex(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb4-19">    </span>
<span id="cb4-20">    <span class="cf" style="color: #003B4F;">while</span> <span class="kw" style="color: #003B4F;">not</span> stop_event.is_set():</span>
<span id="cb4-21">        mem_cpu <span class="op" style="color: #5E5E5E;">=</span> psutil.Process().memory_info().rss <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb4-22">        info <span class="op" style="color: #5E5E5E;">=</span> pynvml.nvmlDeviceGetMemoryInfo(handle)</span>
<span id="cb4-23">        mem_gpu <span class="op" style="color: #5E5E5E;">=</span> info.used <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb4-24">        </span>
<span id="cb4-25">        cpu_readings.append((datetime.now(), mem_cpu))</span>
<span id="cb4-26">        gpu_readings.append((datetime.now(), mem_gpu))</span>
<span id="cb4-27">        time.sleep(<span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb4-28"></span>
<span id="cb4-29"><span class="kw" style="color: #003B4F;">def</span> log_memory(index_name, passages):</span>
<span id="cb4-30">    stop_event <span class="op" style="color: #5E5E5E;">=</span> threading.Event()</span>
<span id="cb4-31">    cpu_readings <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-32">    gpu_readings <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-33">    monitor_thread <span class="op" style="color: #5E5E5E;">=</span> threading.Thread(target<span class="op" style="color: #5E5E5E;">=</span>memory_monitor, args<span class="op" style="color: #5E5E5E;">=</span>(stop_event, cpu_readings, gpu_readings))</span>
<span id="cb4-34">    monitor_thread.start()</span>
<span id="cb4-35"></span>
<span id="cb4-36">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb4-37">        <span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, rank<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)):</span>
<span id="cb4-38">            config <span class="op" style="color: #5E5E5E;">=</span> ColBERTConfig(</span>
<span id="cb4-39">                doc_maxlen<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">220</span>,</span>
<span id="cb4-40">                nbits<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>,</span>
<span id="cb4-41">                dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">96</span>,</span>
<span id="cb4-42">                kmeans_niters<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb4-43">                index_bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32</span>,</span>
<span id="cb4-44">                bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb4-45">                checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>,</span>
<span id="cb4-46">                avoid_fork_if_possible<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span></span>
<span id="cb4-47">            )</span>
<span id="cb4-48">        </span>
<span id="cb4-49">            indexer <span class="op" style="color: #5E5E5E;">=</span> Indexer(checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>, config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb4-50">            index_path <span class="op" style="color: #5E5E5E;">=</span> indexer.index(name<span class="op" style="color: #5E5E5E;">=</span>index_name, collection<span class="op" style="color: #5E5E5E;">=</span>passages[<span class="st" style="color: #20794D;">"text"</span>], overwrite<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb4-51">    <span class="cf" style="color: #003B4F;">finally</span>:</span>
<span id="cb4-52">        stop_event.<span class="bu" style="color: null;">set</span>()</span>
<span id="cb4-53">        monitor_thread.join()</span>
<span id="cb4-54">    </span>
<span id="cb4-55">    <span class="cf" style="color: #003B4F;">return</span> cpu_readings, gpu_readings</span>
<span id="cb4-56"></span>
<span id="cb4-57"><span class="kw" style="color: #003B4F;">def</span> main():</span>
<span id="cb4-58">    parser <span class="op" style="color: #5E5E5E;">=</span> argparse.ArgumentParser(description<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'fp'</span>)</span>
<span id="cb4-59">    parser.add_argument(<span class="st" style="color: #20794D;">'--fp'</span>, <span class="bu" style="color: null;">type</span><span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span>, default<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"fp32"</span>, <span class="bu" style="color: null;">help</span><span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Floating point precision used'</span>)</span>
<span id="cb4-60">    args <span class="op" style="color: #5E5E5E;">=</span> parser.parse_args()</span>
<span id="cb4-61">    fp <span class="op" style="color: #5E5E5E;">=</span> args.fp</span>
<span id="cb4-62">        </span>
<span id="cb4-63">    dataset_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"ConditionalQA"</span></span>
<span id="cb4-64">    index_name <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'ColBERT_</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb4-65">    passages <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-corpus"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb4-66"></span>
<span id="cb4-67">    cpu_readings, gpu_readings <span class="op" style="color: #5E5E5E;">=</span> log_memory(index_name, passages)</span>
<span id="cb4-68"></span>
<span id="cb4-69">    <span class="co" style="color: #5E5E5E;"># CPU RAM artifacts</span></span>
<span id="cb4-70">    start_time <span class="op" style="color: #5E5E5E;">=</span> cpu_readings[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb4-71">    index <span class="op" style="color: #5E5E5E;">=</span> [(t <span class="op" style="color: #5E5E5E;">-</span> start_time).total_seconds() <span class="cf" style="color: #003B4F;">for</span> t, _ <span class="kw" style="color: #003B4F;">in</span> cpu_readings]</span>
<span id="cb4-72">    cpu_readings <span class="op" style="color: #5E5E5E;">=</span> pd.Series([mem <span class="cf" style="color: #003B4F;">for</span> _, mem <span class="kw" style="color: #003B4F;">in</span> cpu_readings], index<span class="op" style="color: #5E5E5E;">=</span>index, name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"mem_gb"</span> )</span>
<span id="cb4-73">    cpu_readings.index.name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"time_secs"</span></span>
<span id="cb4-74">    cpu_readings.plot(title<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f'ColBERT CPU RAM (</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">)'</span>, xlabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Time (sec)'</span>, ylabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Memory (GB)'</span>)</span>
<span id="cb4-75">    plt.tight_layout()</span>
<span id="cb4-76">    plt.savefig(<span class="ss" style="color: #20794D;">f'colbert_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_cpu_readings.png'</span>)</span>
<span id="cb4-77">    plt.close()</span>
<span id="cb4-78">    cpu_readings.to_csv(<span class="ss" style="color: #20794D;">f"colbert_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_cpu_readings.csv"</span>)</span>
<span id="cb4-79"></span>
<span id="cb4-80">    <span class="co" style="color: #5E5E5E;"># GPU RAM artifacts</span></span>
<span id="cb4-81">    start_time <span class="op" style="color: #5E5E5E;">=</span> gpu_readings[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb4-82">    index <span class="op" style="color: #5E5E5E;">=</span> [(t <span class="op" style="color: #5E5E5E;">-</span> start_time).total_seconds() <span class="cf" style="color: #003B4F;">for</span> t, _ <span class="kw" style="color: #003B4F;">in</span> gpu_readings]</span>
<span id="cb4-83">    gpu_readings <span class="op" style="color: #5E5E5E;">=</span> pd.Series([mem <span class="cf" style="color: #003B4F;">for</span> _, mem <span class="kw" style="color: #003B4F;">in</span> gpu_readings], index<span class="op" style="color: #5E5E5E;">=</span>index, name<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"mem_gb"</span> )</span>
<span id="cb4-84">    gpu_readings.index.name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"time_secs"</span></span>
<span id="cb4-85">    gpu_readings.plot(title<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f'ColBERT GPU RAM (</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">)'</span>, xlabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Time (sec)'</span>, ylabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Memory (GB)'</span>)</span>
<span id="cb4-86">    plt.tight_layout()</span>
<span id="cb4-87">    plt.savefig(<span class="ss" style="color: #20794D;">f'colbert_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_gpu_readings.png'</span>)</span>
<span id="cb4-88">    plt.close()</span>
<span id="cb4-89">    gpu_readings.to_csv(<span class="ss" style="color: #20794D;">f"colbert_</span><span class="sc" style="color: #5E5E5E;">{</span>fp<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_gpu_readings.csv"</span>)</span>
<span id="cb4-90"></span>
<span id="cb4-91"><span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">__name__</span> <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"__main__"</span>:</span>
<span id="cb4-92">    main()</span></code></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Show Recall calculation script</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb5-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="im" style="color: #00769E;">from</span> colbert.data <span class="im" style="color: #00769E;">import</span> Queries</span>
<span id="cb5-5"><span class="im" style="color: #00769E;">from</span> colbert.infra <span class="im" style="color: #00769E;">import</span> Run, RunConfig, ColBERTConfig</span>
<span id="cb5-6"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Searcher</span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb5-9"><span class="im" style="color: #00769E;">import</span> numpy</span>
<span id="cb5-10"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb5-11"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb5-12"><span class="im" style="color: #00769E;">import</span> tqdm</span>
<span id="cb5-13"><span class="im" style="color: #00769E;">import</span> glob</span>
<span id="cb5-14"><span class="im" style="color: #00769E;">import</span> re</span>
<span id="cb5-15"><span class="im" style="color: #00769E;">import</span> pytrec_eval</span>
<span id="cb5-16"><span class="im" style="color: #00769E;">import</span> argparse </span>
<span id="cb5-17"><span class="im" style="color: #00769E;">import</span> pickle</span>
<span id="cb5-18"></span>
<span id="cb5-19"><span class="kw" style="color: #003B4F;">def</span> get_qrels(qrels_rows):</span>
<span id="cb5-20">    qrels <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb5-21">    <span class="cf" style="color: #003B4F;">for</span> qrel_row <span class="kw" style="color: #003B4F;">in</span> qrels_rows:</span>
<span id="cb5-22">        qid <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"query_id"</span>]</span>
<span id="cb5-23">        pid <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"corpus_id"</span>]</span>
<span id="cb5-24">        rel <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"score"</span>]</span>
<span id="cb5-25">        qrels.setdefault(qid, {})</span>
<span id="cb5-26">        qrels[qid][pid] <span class="op" style="color: #5E5E5E;">=</span> rel</span>
<span id="cb5-27">    </span>
<span id="cb5-28">    <span class="cf" style="color: #003B4F;">return</span> qrels</span>
<span id="cb5-29"></span>
<span id="cb5-30"><span class="kw" style="color: #003B4F;">def</span> _recall(qrels, res):</span>
<span id="cb5-31">    evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb5-32">    metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(res)</span>
<span id="cb5-33">    <span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb5-34"></span>
<span id="cb5-35">    mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb5-36">    <span class="cf" style="color: #003B4F;">return</span> mean_recall</span>
<span id="cb5-37"></span>
<span id="cb5-38"></span>
<span id="cb5-39">dataset_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"ConditionalQA"</span></span>
<span id="cb5-40">queries <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-queries"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb5-41">passages <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-corpus"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb5-42">qrels_rows <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-qrels"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb5-43">qrels <span class="op" style="color: #5E5E5E;">=</span> get_qrels(qrels_rows)</span>
<span id="cb5-44"><span class="bu" style="color: null;">print</span>(dataset_name)</span>
<span id="cb5-45"></span>
<span id="cb5-46">queries_dict <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb5-47"><span class="cf" style="color: #003B4F;">for</span> item <span class="kw" style="color: #003B4F;">in</span> queries: queries_dict[item[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> item[<span class="st" style="color: #20794D;">'text'</span>]</span>
<span id="cb5-48"></span>
<span id="cb5-49"><span class="kw" style="color: #003B4F;">def</span> main():</span>
<span id="cb5-50">    parser <span class="op" style="color: #5E5E5E;">=</span> argparse.ArgumentParser(description<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'index'</span>)</span>
<span id="cb5-51">    parser.add_argument(<span class="st" style="color: #20794D;">'--index'</span>, <span class="bu" style="color: null;">type</span><span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span>, default<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">""</span>, <span class="bu" style="color: null;">help</span><span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Index name'</span>)</span>
<span id="cb5-52">    args <span class="op" style="color: #5E5E5E;">=</span> parser.parse_args()</span>
<span id="cb5-53">    index <span class="op" style="color: #5E5E5E;">=</span> args.index</span>
<span id="cb5-54">    </span>
<span id="cb5-55">    <span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb5-56">        searcher <span class="op" style="color: #5E5E5E;">=</span> Searcher(</span>
<span id="cb5-57">            index<span class="op" style="color: #5E5E5E;">=</span>index,</span>
<span id="cb5-58">            config<span class="op" style="color: #5E5E5E;">=</span>ColBERTConfig(</span>
<span id="cb5-59">                    ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb5-60">                    centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.45</span>,</span>
<span id="cb5-61">                    ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb5-62">                )</span>
<span id="cb5-63">        )</span>
<span id="cb5-64">    </span>
<span id="cb5-65">        _queries <span class="op" style="color: #5E5E5E;">=</span> Queries(data<span class="op" style="color: #5E5E5E;">=</span>queries_dict)</span>
<span id="cb5-66">        ranking <span class="op" style="color: #5E5E5E;">=</span> searcher.search_all(_queries, k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb5-67"></span>
<span id="cb5-68">    colbert_results <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb5-69"></span>
<span id="cb5-70">    <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> ranking.todict().keys():</span>
<span id="cb5-71">        colbert_scores <span class="op" style="color: #5E5E5E;">=</span> ranking.todict()[qid]</span>
<span id="cb5-72">        colbert_results[qid] <span class="op" style="color: #5E5E5E;">=</span> {passages[idx][<span class="st" style="color: #20794D;">'_id'</span>]: score <span class="cf" style="color: #003B4F;">for</span> idx, _, score <span class="kw" style="color: #003B4F;">in</span> colbert_scores}</span>
<span id="cb5-73"></span>
<span id="cb5-74">    <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"colbert_results_</span><span class="sc" style="color: #5E5E5E;">{</span>index<span class="sc" style="color: #5E5E5E;">.</span>split(<span class="st" style="color: #20794D;">'_'</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">.pkl"</span>, <span class="st" style="color: #20794D;">'wb'</span>) <span class="im" style="color: #00769E;">as</span> <span class="bu" style="color: null;">file</span>: pickle.dump(colbert_results, <span class="bu" style="color: null;">file</span>)</span>
<span id="cb5-75">    <span class="bu" style="color: null;">print</span>(_recall(qrels, colbert_results))</span>
<span id="cb5-76"></span>
<span id="cb5-77"><span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">__name__</span> <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"__main__"</span>:</span>
<span id="cb5-78">    main()</span></code></pre></div>
</details>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I ran an experiment to explore the differences between FP32 full precision and mixed precision in ColBERT indexing and retrieval. This was purely a curiosity-driven exploration - not claiming this is best practice, just wanted to see if there were any differences. This notebook shares my findings. I use the <a href="https://huggingface.co/datasets/UKPLab/dapr/viewer/ConditionalQA-docs">UKPLab/DAPR ConditionalQA dataset</a> for this exercise.</p>
<p><strong>What I did:</strong></p>
<ul>
<li>Created <a href="https://github.com/vishalbakshi/ColBERT/commits/mixed_precision_false/">a fork of ColBERT</a> and turned off all mixed precision conversions</li>
<li>Used Claude and ChatGPT to help identify all the places that needed changes (including CUDA kernels)</li>
<li>Ran indexing experiments on the UKPLab’s ConditionalQA dataset (70k documents)</li>
<li>Tracked memory usage during indexing (see script above)</li>
<li>Compared recall performance and retrieved passages (see script above)</li>
<li>Analyzed the resulting index artifacts</li>
</ul>
<p><strong>Key findings:</strong></p>
<ul>
<li>Mixed precision took 2.5x longer to index (180s vs 70s) - wasn’t expecting that</li>
<li>Mixed precision used slightly more GPU memory, full precision used more CPU memory</li>
<li>Full precision gave a tiny 0.3% recall boost (basically negligible)</li>
<li>14% of retrieved passages were different between the two approaches</li>
<li>The centroids created during indexing were significantly different</li>
<li>Different mappings between passage IDs and centroids</li>
</ul>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aiNQ4I8YaD0?si=OKvaUtumf7q1qGYf" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="indexing-time" class="level2">
<h2 class="anchored" data-anchor-id="indexing-time">Indexing Time</h2>
<p>I was surprised to see that using mixed precision resulted in a much longer indexing time. I wonder if that would still hold over multiple iterations of indexing.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Indexing Time (seconds)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">fp32</td>
<td style="text-align: center;">70</td>
</tr>
<tr class="even">
<td style="text-align: center;">amp</td>
<td style="text-align: center;">180</td>
</tr>
</tbody>
</table>
</section>
<section id="maximum-memory-usage" class="level2">
<h2 class="anchored" data-anchor-id="maximum-memory-usage">Maximum Memory Usage</h2>
<p>Another surprise—mixed precision actually uses <em>more</em> GPU memory than full precision.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Precision</th>
<th style="text-align: center;">Max GPU Mem (GB)</th>
<th style="text-align: center;">Max CPU Mem (GB)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">fp32</td>
<td style="text-align: center;">5.51</td>
<td style="text-align: center;">0.824</td>
</tr>
<tr class="even">
<td style="text-align: center;">amp</td>
<td style="text-align: center;">5.78</td>
<td style="text-align: center;">0.814</td>
</tr>
</tbody>
</table>
</section>
<section id="recall10" class="level2">
<h2 class="anchored" data-anchor-id="recall10">Recall@10</h2>
<p>The differences in Recall@10 is negligible, the full precision index has a slight advantage.</p>
<p>fp32: 0.13034885692197787</p>
<p>amp: 0.1299388528219369</p>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">(<span class="fl" style="color: #AD0000;">0.13034885692197787</span> <span class="op" style="color: #5E5E5E;">-</span> <span class="fl" style="color: #AD0000;">0.1299388528219369</span>)<span class="op" style="color: #5E5E5E;">/</span><span class="fl" style="color: #AD0000;">0.1299388528219369</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>0.003155361857802613</code></pre>
</div>
</div>
</section>
<section id="comparing-retrieved-passages-and-scores" class="level2">
<h2 class="anchored" data-anchor-id="comparing-retrieved-passages-and-scores">Comparing Retrieved Passages and Scores</h2>
<p>Out of the 2710 total passages retrieved, 388 passages were retrieved using one index but not the other—that’s about a 14% difference in retrieved passages due to a difference in precision.</p>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'colbert_results_fp32.pkl'</span>, <span class="st" style="color: #20794D;">'rb'</span>) <span class="im" style="color: #00769E;">as</span> <span class="bu" style="color: null;">file</span>: colbert_results_fp32 <span class="op" style="color: #5E5E5E;">=</span> pickle.load(<span class="bu" style="color: null;">file</span>)</span>
<span id="cb8-2"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="st" style="color: #20794D;">'colbert_results_amp.pkl'</span>, <span class="st" style="color: #20794D;">'rb'</span>) <span class="im" style="color: #00769E;">as</span> <span class="bu" style="color: null;">file</span>: colbert_results_amp <span class="op" style="color: #5E5E5E;">=</span> pickle.load(<span class="bu" style="color: null;">file</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">colbert_results_fp32.keys() <span class="op" style="color: #5E5E5E;">==</span> colbert_results_amp.keys()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">colbert_results_fp32[<span class="st" style="color: #20794D;">'dev-0'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>{'265-59': 29.345699310302734,
 '8-116': 29.341297149658203,
 '8-118': 29.336307525634766,
 '8-67': 29.32498550415039,
 '8-9': 29.2913875579834,
 '8-70': 29.290199279785156,
 '270-51': 29.28421401977539,
 '40-29': 29.28375244140625,
 '107-110': 29.282079696655273,
 '459-115': 29.28005599975586}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">n_diffs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb13-2"><span class="cf" style="color: #003B4F;">for</span> qid, fp32_res <span class="kw" style="color: #003B4F;">in</span> colbert_results_fp32.items():</span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;">for</span> pid <span class="kw" style="color: #003B4F;">in</span> fp32_res.keys():</span>
<span id="cb13-4">        <span class="cf" style="color: #003B4F;">if</span> pid <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> colbert_results_amp[qid].keys(): </span>
<span id="cb13-5">            n_diffs <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb13-6"> </span>
<span id="cb13-7"><span class="cf" style="color: #003B4F;">for</span> qid, amp_res <span class="kw" style="color: #003B4F;">in</span> colbert_results_amp.items():</span>
<span id="cb13-8">    <span class="cf" style="color: #003B4F;">for</span> pid <span class="kw" style="color: #003B4F;">in</span> amp_res.keys():</span>
<span id="cb13-9">        <span class="cf" style="color: #003B4F;">if</span> pid <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> colbert_results_fp32[qid].keys(): </span>
<span id="cb13-10">            n_diffs <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb13-11"></span>
<span id="cb13-12">n_diffs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>388</code></pre>
</div>
</div>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">n_diffs<span class="op" style="color: #5E5E5E;">/</span>(<span class="dv" style="color: #AD0000;">271</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>0.14317343173431735</code></pre>
</div>
</div>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">colbert_results_fp32[<span class="st" style="color: #20794D;">'dev-0'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>{'265-59': 29.345699310302734,
 '8-116': 29.341297149658203,
 '8-118': 29.336307525634766,
 '8-67': 29.32498550415039,
 '8-9': 29.2913875579834,
 '8-70': 29.290199279785156,
 '270-51': 29.28421401977539,
 '40-29': 29.28375244140625,
 '107-110': 29.282079696655273,
 '459-115': 29.28005599975586}</code></pre>
</div>
</div>
<p>Overall, the full precision index results in a slightly lower retrieved passage score.</p>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">total_amp_score <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb19-2"><span class="cf" style="color: #003B4F;">for</span> qid, amp_res <span class="kw" style="color: #003B4F;">in</span> colbert_results_amp.items():</span>
<span id="cb19-3">    <span class="cf" style="color: #003B4F;">for</span> score <span class="kw" style="color: #003B4F;">in</span> amp_res.values(): total_amp_score <span class="op" style="color: #5E5E5E;">+=</span> score</span>
<span id="cb19-4">total_amp_score</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>80438.375</code></pre>
</div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">total_fp32_score <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb21-2"><span class="cf" style="color: #003B4F;">for</span> qid, fp32_res <span class="kw" style="color: #003B4F;">in</span> colbert_results_fp32.items():</span>
<span id="cb21-3">    <span class="cf" style="color: #003B4F;">for</span> score <span class="kw" style="color: #003B4F;">in</span> fp32_res.values(): total_fp32_score <span class="op" style="color: #5E5E5E;">+=</span> score</span>
<span id="cb21-4">total_fp32_score</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>80435.61682701111</code></pre>
</div>
</div>
</section>
<section id="comparing-index-artifacts" class="level2">
<h2 class="anchored" data-anchor-id="comparing-index-artifacts">Comparing Index Artifacts</h2>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">colbert_fp32_root <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"./experiments/default/indexes/ColBERT_ConditionalQA_fp32"</span></span>
<span id="cb23-2">colbert_amp_root  <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"./experiments/default/indexes/ColBERT_ConditionalQA_amp"</span></span></code></pre></div>
</div>
<section id="metadata.json" class="level3">
<h3 class="anchored" data-anchor-id="metadata.json">metadata.json</h3>
<p>Both indexes (full precision and mixed precision) produce the same metadata.json.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">params <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb24-2">    <span class="st" style="color: #20794D;">"index_bsize"</span>,</span>
<span id="cb24-3">    <span class="st" style="color: #20794D;">"nbits"</span>,</span>
<span id="cb24-4">    <span class="st" style="color: #20794D;">"kmeans_niters"</span>,</span>
<span id="cb24-5">    <span class="st" style="color: #20794D;">"dim"</span>,</span>
<span id="cb24-6">    <span class="st" style="color: #20794D;">"rank"</span>,</span>
<span id="cb24-7">    <span class="st" style="color: #20794D;">"gpus"</span>,</span>
<span id="cb24-8">    <span class="st" style="color: #20794D;">"nranks"</span>,</span>
<span id="cb24-9">    <span class="st" style="color: #20794D;">"num_chunks"</span>,</span>
<span id="cb24-10">    <span class="st" style="color: #20794D;">"num_partitions"</span>,</span>
<span id="cb24-11">    <span class="st" style="color: #20794D;">"num_embeddings"</span>,</span>
<span id="cb24-12">    <span class="st" style="color: #20794D;">"avg_doclen"</span></span>
<span id="cb24-13">    ]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_fp32_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f: colbert_fp32_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb25-2"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_amp_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f: colbert_amp_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> params:</span>
<span id="cb26-2">    <span class="cf" style="color: #003B4F;">if</span> p <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> [<span class="st" style="color: #20794D;">"num_chunks"</span>, <span class="st" style="color: #20794D;">"num_partitions"</span>, <span class="st" style="color: #20794D;">"num_embeddings"</span>, <span class="st" style="color: #20794D;">"avg_doclen"</span>]: <span class="cf" style="color: #003B4F;">assert</span> colbert_fp32_metadata[<span class="st" style="color: #20794D;">'config'</span>][p] <span class="op" style="color: #5E5E5E;">==</span> colbert_amp_metadata[<span class="st" style="color: #20794D;">'config'</span>][p], p</span>
<span id="cb26-3">    <span class="cf" style="color: #003B4F;">elif</span> p <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"avg_doclen"</span>: <span class="cf" style="color: #003B4F;">assert</span> (colbert_fp32_metadata[p] <span class="op" style="color: #5E5E5E;">-</span> colbert_amp_metadata[p]) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="fl" style="color: #AD0000;">1e-7</span></span>
<span id="cb26-4">    <span class="cf" style="color: #003B4F;">else</span>: <span class="cf" style="color: #003B4F;">assert</span> colbert_fp32_metadata[p] <span class="op" style="color: #5E5E5E;">==</span> colbert_amp_metadata[p], p</span></code></pre></div>
</div>
</section>
<section id="centroids.pt" class="level3">
<h3 class="anchored" data-anchor-id="centroids.pt">centroids.pt</h3>
<p>There is a significant difference in centroids—meaning that the sampled document token embeddings and their clusters are different based on the type of precision used.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">colbert_fp32_centroids <span class="op" style="color: #5E5E5E;">=</span> torch.load(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_fp32_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/centroids.pt"</span>)</span>
<span id="cb27-2">colbert_amp_centroids <span class="op" style="color: #5E5E5E;">=</span> torch.load(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_amp_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/centroids.pt"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">torch.allclose(colbert_fp32_centroids, colbert_amp_centroids.<span class="bu" style="color: null;">float</span>())</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>False</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">torch.allclose(colbert_fp32_centroids.half(), colbert_amp_centroids)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>False</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">torch.allclose(colbert_fp32_centroids, colbert_amp_centroids.<span class="bu" style="color: null;">float</span>(), atol<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1e-0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">colbert_fp32_centroids.flatten().shape, colbert_amp_centroids.flatten().shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>(torch.Size([1572864]), torch.Size([1572864]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">plt.scatter(colbert_fp32_centroids.flatten().cpu().numpy(), colbert_amp_centroids.flatten().cpu().numpy(), s<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-24-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-25-Exploring-ColBERT-Precision/index_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="ivf.pid.pt" class="level3">
<h3 class="anchored" data-anchor-id="ivf.pid.pt">ivf.pid.pt</h3>
<p>Finally, there is a difference in mappings between passages IDs and centroid IDs. Interestingly, mixed precision results in more passage IDs mapped to centroids.</p>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">colbert_fp32_ivf <span class="op" style="color: #5E5E5E;">=</span> torch.load(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_fp32_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/ivf.pid.pt"</span>)</span>
<span id="cb37-2">colbert_amp_ivf  <span class="op" style="color: #5E5E5E;">=</span> torch.load(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>colbert_amp_root<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/ivf.pid.pt"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">colbert_fp32_ivf[<span class="dv" style="color: #AD0000;">0</span>].shape, colbert_amp_ivf[<span class="dv" style="color: #AD0000;">0</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>(torch.Size([963143]), torch.Size([975457]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">colbert_amp_ivf[<span class="dv" style="color: #AD0000;">0</span>].shape[<span class="dv" style="color: #AD0000;">0</span>]<span class="op" style="color: #5E5E5E;">-</span>colbert_fp32_ivf[<span class="dv" style="color: #AD0000;">0</span>].shape[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>12314</code></pre>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">colbert_fp32_ivf[<span class="dv" style="color: #AD0000;">1</span>].shape, colbert_amp_ivf[<span class="dv" style="color: #AD0000;">1</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>(torch.Size([16384]), torch.Size([16384]))</code></pre>
</div>
</div>
</section>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>This is just one small dataset with short documents (avg 15 tokens). Sample size of one. I also might have missed some precision conversions in my implementation. Don’t take this as definitive - just an interesting exploration of how precision affects the ColBERT pipeline. Here’s a summary again of my key findings:</p>
<ul>
<li>Mixed precision took 2.5x longer to index (180s vs 70s) - wasn’t expecting that</li>
<li>Mixed precision used slightly more GPU memory, full precision used more CPU memory</li>
<li>Full precision gave a tiny 0.3% recall boost (basically negligible)</li>
<li>14% of retrieved passages were different between the two approaches</li>
<li>The centroids created during indexing were significantly different</li>
<li>Different mappings between passage IDs and centroids</li>
</ul>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>ColBERT</category>
  <category>information retrieval</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-25-Exploring-ColBERT-Precision/index.html</guid>
  <pubDate>Sun, 25 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>The Evolution of Matrix Multiplication (fastai course Part 2 Lessons 11 and 12)</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/index.html</link>
  <description><![CDATA[ 



<div class="cell" data-outputid="47621598-8fd6-4b6a-9893-4dc62cc9ee45" data-execution_count="2">
<details>
<summary>Show setup code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># !conda install -y -c nvidia/label/cuda-12.8.0 cuda-toolkit</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;"># !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128</span></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;"># !conda install -y numba</span></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;"># !conda install -y fastcore -c fastai</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> pickle, gzip, math, os, time, shutil</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> urllib.request <span class="im" style="color: #00769E;">import</span> urlretrieve</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> tensor</span>
<span id="cb1-11"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-12"><span class="im" style="color: #00769E;">from</span> numba <span class="im" style="color: #00769E;">import</span> njit</span>
<span id="cb1-13"><span class="im" style="color: #00769E;">from</span> numpy <span class="im" style="color: #00769E;">import</span> array</span>
<span id="cb1-14"><span class="im" style="color: #00769E;">from</span> fastcore.test <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="im" style="color: #00769E;">from</span> numba <span class="im" style="color: #00769E;">import</span> cuda</span>
<span id="cb1-17"></span>
<span id="cb1-18">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb1-19">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>)</span>
<span id="cb1-20"></span>
<span id="cb1-21">MNIST_URL<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'</span></span>
<span id="cb1-22">path_data <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'data'</span>)</span>
<span id="cb1-23">path_data.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb1-24">path_gz <span class="op" style="color: #5E5E5E;">=</span> path_data<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'mnist.pkl.gz'</span></span>
<span id="cb1-25"></span>
<span id="cb1-26"></span>
<span id="cb1-27"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> path_gz.exists(): urlretrieve(MNIST_URL, path_gz)</span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="cf" style="color: #003B4F;">with</span> gzip.<span class="bu" style="color: null;">open</span>(path_gz, <span class="st" style="color: #20794D;">'rb'</span>) <span class="im" style="color: #00769E;">as</span> f: ((x_train, y_train), (x_valid, y_valid), _) <span class="op" style="color: #5E5E5E;">=</span> pickle.load(f, encoding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'latin-1'</span>)</span>
<span id="cb1-30"></span>
<span id="cb1-31">x_train,y_train,x_valid,y_valid <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(tensor, (x_train,y_train,x_valid,y_valid))</span>
<span id="cb1-32">x_train.shape</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>torch.Size([50000, 784])</code></pre>
</div>
</div>
<div class="cell" data-outputid="a4f3c78a-4f61-4f8c-cf21-4c103270afd9" data-execution_count="3">
<details>
<summary>Show setup code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb3-2">weights <span class="op" style="color: #5E5E5E;">=</span> torch.randn(<span class="dv" style="color: #AD0000;">784</span>,<span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb3-3">bias <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(<span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb3-4"></span>
<span id="cb3-5">m1 <span class="op" style="color: #5E5E5E;">=</span> x_valid[:<span class="dv" style="color: #AD0000;">5</span>]</span>
<span id="cb3-6">m2 <span class="op" style="color: #5E5E5E;">=</span> weights</span>
<span id="cb3-7"></span>
<span id="cb3-8">m1.shape,m2.shape</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>(torch.Size([5, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
<iframe width="560" height="315" src="https://www.youtube.com/embed/iV63qy4ETJQ?si=RVTeCMWgSHf_IHq0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<section id="digit-subset" class="level3">
<h3 class="anchored" data-anchor-id="digit-subset">5-digit Subset</h3>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">18.1 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">69.2 μs</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">83.1 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Cuda</td>
<td style="text-align: center;">108 μs</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">108 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">203 μs</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">542 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>torch.dot</code></td>
<td style="text-align: center;">1.19 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Element-wise PyTorch Ops</td>
<td style="text-align: center;">1.49 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Nested for-loops</td>
<td style="text-align: center;">604 ms</td>
</tr>
</tbody>
</table>
</section>
<section id="full-dataset-50k-images" class="level3">
<h3 class="anchored" data-anchor-id="full-dataset-50k-images">Full Dataset (50k images)</h3>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>cuda</code></td>
<td style="text-align: center;">541 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">3.91 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">5.8 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">5.87 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">663 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">1.26 s</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">3.71 s</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="version-0-nested-for-loops" class="level2">
<h2 class="anchored" data-anchor-id="version-0-nested-for-loops">Version 0: Nested For-Loops</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" title="Excalidraw diagram showing nested for-loop implementation of matrix multiplication" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Excalidraw diagram showing nested for-loop implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<div class="cell" data-outputid="f1b07e28-eb6a-42f0-9863-d962b0843dff" data-execution_count="70">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">ar,ac <span class="op" style="color: #5E5E5E;">=</span> m1.shape <span class="co" style="color: #5E5E5E;"># n_rows * n_cols</span></span>
<span id="cb5-2">br,bc <span class="op" style="color: #5E5E5E;">=</span> m2.shape</span>
<span id="cb5-3">(ar,ac),(br,bc)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>((5, 784), (784, 10))</code></pre>
</div>
</div>
<div class="cell" data-outputid="50202d80-fbe0-4ea8-aa39-4fe0691cb4b0" data-execution_count="71">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">t1 <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb7-2">t1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):         <span class="co" style="color: #5E5E5E;"># 5</span></span>
<span id="cb9-2">    <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc):     <span class="co" style="color: #5E5E5E;"># 10</span></span>
<span id="cb9-3">        <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ac): <span class="co" style="color: #5E5E5E;"># 784</span></span>
<span id="cb9-4">            t1[i,j] <span class="op" style="color: #5E5E5E;">+=</span> m1[i,k] <span class="op" style="color: #5E5E5E;">*</span> m2[k,j]</span></code></pre></div>
</div>
<div class="cell" data-outputid="de65336e-e04e-4d55-81aa-228a6f7bf7bf" data-execution_count="73">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">t1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div class="cell" data-outputid="a46dd7f0-06d7-4d86-aa3a-577743471963" data-execution_count="74">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],
        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],
        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],
        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],
        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb14-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb14-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb14-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb14-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc):</span>
<span id="cb14-6">            <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ac): c[i,j] <span class="op" style="color: #5E5E5E;">+=</span> a[i,k] <span class="op" style="color: #5E5E5E;">*</span> b[k,j]</span>
<span id="cb14-7">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-outputid="75bfe38a-2fc3-4f8d-8934-7fbd7c8036e4" data-execution_count="81">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="op" style="color: #5E5E5E;">%</span>time _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 675 ms, sys: 0 ns, total: 675 ms
Wall time: 674 ms</code></pre>
</div>
</div>
</section>
<section id="version-1-numba-dot-product" class="level2">
<h2 class="anchored" data-anchor-id="version-1-numba-dot-product">Version 1: Numba Dot Product</h2>
<p>Replacing the inner-most for-loop with a numba dot-product implementation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" title="Excalidraw diagram showing dot-product implementation of matrix multiplication" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Excalidraw diagram showing dot-product implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb17-2"><span class="kw" style="color: #003B4F;">def</span> dot(a,b):</span>
<span id="cb17-3">    res <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.</span></span>
<span id="cb17-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(a)): res<span class="op" style="color: #5E5E5E;">+=</span>a[i]<span class="op" style="color: #5E5E5E;">*</span>b[i]</span>
<span id="cb17-5">    <span class="cf" style="color: #003B4F;">return</span> res</span></code></pre></div>
</div>
<div class="cell" data-outputid="217464df-4573-40a9-f926-37186bb47d53" data-execution_count="83">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="op" style="color: #5E5E5E;">%</span>time dot(array([<span class="fl" style="color: #AD0000;">1.</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>]),array([<span class="fl" style="color: #AD0000;">2.</span>,<span class="dv" style="color: #AD0000;">3</span>,<span class="dv" style="color: #AD0000;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 124 ms, sys: 0 ns, total: 124 ms
Wall time: 123 ms</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>20.0</code></pre>
</div>
</div>
<div class="cell" data-outputid="64bc96a7-7cc1-404a-c47b-6b8a54d5c6b6" data-execution_count="84">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="op" style="color: #5E5E5E;">%</span>time dot(array([<span class="fl" style="color: #AD0000;">1.</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>]),array([<span class="fl" style="color: #AD0000;">2.</span>,<span class="dv" style="color: #AD0000;">3</span>,<span class="dv" style="color: #AD0000;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 26 μs, sys: 2 μs, total: 28 μs
Wall time: 32.4 μs</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>20.0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb24-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb24-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb24-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb24-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> dot(a[i,:], b[:,j])</span>
<span id="cb24-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">m1a,m2a <span class="op" style="color: #5E5E5E;">=</span> m1.numpy(),m2.numpy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div class="cell" data-outputid="10968392-3789-4272-b708-9a99560bad48" data-execution_count="91">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> matmul(m1a,m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>495 μs ± 39.4 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-2-element-wise-operations" class="level2">
<h2 class="anchored" data-anchor-id="version-2-element-wise-operations">Version 2: Element-wise Operations</h2>
<div class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb29-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb29-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb29-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb29-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:] <span class="op" style="color: #5E5E5E;">*</span> b[:,j]).<span class="bu" style="color: null;">sum</span>()</span>
<span id="cb29-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="fc775c33-b82e-4076-ef1b-5eb260224b56" data-execution_count="94">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.48 ms ± 354 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-3-torch.dot" class="level2">
<h2 class="anchored" data-anchor-id="version-3-torch.dot">Version 3: <code>torch.dot</code></h2>
<div class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb33" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb33-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb33-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb33-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb33-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> torch.dot(a[i,:], b[:,j])</span>
<span id="cb33-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="b97d9eea-9c0f-4ac5-9db1-c73b3661cfec" data-execution_count="97">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.23 ms ± 380 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-4-pytorch-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="version-4-pytorch-broadcasting">Version 4: PyTorch Broadcasting</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" title="Excalidraw diagram showing broadcasting implementation of matrix multiplication" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/3.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Excalidraw diagram showing broadcasting implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb37-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb37-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb37-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb37-5">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="2acf0524-81f2-4fab-e67d-b2354bacbf36" data-execution_count="109">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>314 μs ± 92.1 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-5-numba-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="version-5-numba-broadcasting">Version 5: Numba Broadcasting</h2>
<div class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb41-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb41-3">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb41-4">    c <span class="op" style="color: #5E5E5E;">=</span> np.zeros((ar, bc))</span>
<span id="cb41-5">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb41-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div class="cell" data-outputid="1d46ad9d-a40d-4643-c1cf-f535fa528a2f" data-execution_count="121">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1a, m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>69 μs ± 1.96 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-6-einstein-summation" class="level2">
<h2 class="anchored" data-anchor-id="version-6-einstein-summation">Version 6: Einstein Summation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="4.png" class="lightbox" title="Excalidraw diagram showing einsum implementation of matrix multiplication" data-gallery="quarto-lightbox-gallery-4"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/4.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Excalidraw diagram showing einsum implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<div class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b): <span class="cf" style="color: #003B4F;">return</span> torch.einsum(<span class="st" style="color: #20794D;">'ik,kj-&gt;ij'</span>, a, b)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="65bbe1b5-0ab3-4162-ef3f-bdeaeb96f800" data-execution_count="124">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>80.8 μs ± 4.18 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-7-pytorch-operator" class="level2">
<h2 class="anchored" data-anchor-id="version-7-pytorch-operator">Version 7: PyTorch <code>@</code> Operator</h2>
<div class="cell" data-execution_count="125">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">test_close(t1,m1<span class="op" style="color: #5E5E5E;">@</span>m2)</span></code></pre></div>
</div>
<div class="cell" data-outputid="0bdd14b8-2dbf-42d9-f565-0746be389f63" data-execution_count="126">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>m1<span class="op" style="color: #5E5E5E;">@</span>m2</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>16.7 μs ± 1.96 μs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-8-numba-cuda" class="level2">
<h2 class="anchored" data-anchor-id="version-8-numba-cuda">Version 8: Numba CUDA</h2>
<div class="cell" data-execution_count="127">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="at" style="color: #657422;">@cuda.jit</span></span>
<span id="cb52-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b,c):</span>
<span id="cb52-3">    i, j <span class="op" style="color: #5E5E5E;">=</span> cuda.grid(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb52-4">    <span class="cf" style="color: #003B4F;">if</span> i <span class="op" style="color: #5E5E5E;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;">0</span>] <span class="kw" style="color: #003B4F;">and</span> j <span class="op" style="color: #5E5E5E;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;">1</span>]:</span>
<span id="cb52-5">        tmp <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.</span></span>
<span id="cb52-6">        <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(a.shape[<span class="dv" style="color: #AD0000;">1</span>]): tmp <span class="op" style="color: #5E5E5E;">+=</span> a[i, k] <span class="op" style="color: #5E5E5E;">*</span> b[k, j]</span>
<span id="cb52-7">        c[i,j] <span class="op" style="color: #5E5E5E;">=</span> tmp</span></code></pre></div>
</div>
<div class="cell" data-execution_count="128">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="kw" style="color: #003B4F;">def</span> launch_kernel(kernel, grid_x, grid_y, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb53-2">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(grid_x):</span>
<span id="cb53-3">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(grid_y): kernel((i,j), <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="129">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1">r <span class="op" style="color: #5E5E5E;">=</span> np.zeros(t1.shape)</span>
<span id="cb54-2">m1g,m2g,rg <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(cuda.to_device, (m1,m2,r))</span></code></pre></div>
</div>
<div class="cell" data-outputid="2852ccb1-8bed-450f-8864-1928e10117f2" data-execution_count="130">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1">m1g.shape, m2g.shape, rg.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="130">
<pre><code>((5, 784), (784, 10), (5, 10))</code></pre>
</div>
</div>
<div class="cell" data-outputid="d4e0a549-a04f-43db-9d1f-c96e9a6026e7" data-execution_count="131">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">TPB <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">16</span></span>
<span id="cb57-2">rr,rc <span class="op" style="color: #5E5E5E;">=</span> r.shape</span>
<span id="cb57-3">blockspergrid <span class="op" style="color: #5E5E5E;">=</span> (math.ceil(rr <span class="op" style="color: #5E5E5E;">/</span> TPB), math.ceil(rc <span class="op" style="color: #5E5E5E;">/</span> TPB))</span>
<span id="cb57-4">blockspergrid</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="131">
<pre><code>(1, 1)</code></pre>
</div>
</div>
<div class="cell" data-outputid="bf632387-a756-4efb-ec6a-ce589b1c023a" data-execution_count="132">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)</span>
<span id="cb59-2">r <span class="op" style="color: #5E5E5E;">=</span> rg.copy_to_host()</span>
<span id="cb59-3">test_close(t1, r, eps<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1e-3</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/mnt/my4tb/vishal_data/miniconda3/envs/course-numba/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.
  warn(NumbaPerformanceWarning(msg))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="133">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><span class="op" style="color: #5E5E5E;">%%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb61-2">matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)</span>
<span id="cb61-3">r <span class="op" style="color: #5E5E5E;">=</span> rg.copy_to_host()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>245 μs ± 47.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="version-9-pytorch-.cuda" class="level2">
<h2 class="anchored" data-anchor-id="version-9-pytorch-.cuda">Version 9: PyTorch <code>.cuda</code></h2>
<div class="cell" data-execution_count="134">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">m1c,m2c <span class="op" style="color: #5E5E5E;">=</span> m1.cuda(),m2.cuda()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">r<span class="op" style="color: #5E5E5E;">=</span>(m1c<span class="op" style="color: #5E5E5E;">@</span>m2c).cpu()</span>
<span id="cb64-2">test_close(t1, r)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="136">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span> r<span class="op" style="color: #5E5E5E;">=</span>(m1c<span class="op" style="color: #5E5E5E;">@</span>m2c).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>113 μs ± 26.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="comparing-fastest-versions-on-full-dataset" class="level2">
<h2 class="anchored" data-anchor-id="comparing-fastest-versions-on-full-dataset">Comparing Fastest Versions on Full Dataset</h2>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>cuda</code></td>
<td style="text-align: center;">541 μs</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">3.91 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">5.8 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">5.87 ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">663 ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">1.26 s</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">3.71 s</td>
</tr>
</tbody>
</table>
<section id="numba-dot-product" class="level3">
<h3 class="anchored" data-anchor-id="numba-dot-product">Numba Dot Product</h3>
<div class="cell" data-execution_count="137">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb67-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb67-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb67-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb67-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> dot(a[i,:], b[:,j])</span>
<span id="cb67-6">    <span class="cf" style="color: #003B4F;">return</span> c</span>
<span id="cb67-7"></span>
<span id="cb67-8">x_train_a,weights_a <span class="op" style="color: #5E5E5E;">=</span> x_train.numpy(),weights.numpy()</span>
<span id="cb67-9"><span class="op" style="color: #5E5E5E;">%</span>timeit _ <span class="op" style="color: #5E5E5E;">=</span> matmul(x_train_a, weights_a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.71 s ± 20.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
</section>
<section id="pytorch-broadcasting" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-broadcasting">PyTorch Broadcasting</h3>
<div class="cell" data-execution_count="197">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb69-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb69-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb69-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb69-5">    <span class="cf" style="color: #003B4F;">return</span> c</span>
<span id="cb69-6"></span>
<span id="cb69-7"><span class="op" style="color: #5E5E5E;">%</span>timeit _ <span class="op" style="color: #5E5E5E;">=</span> matmul(x_train, weights)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.26 s ± 1.42 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1">x_train.shape, weights.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="198">
<pre><code>(torch.Size([50000, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="200">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><span class="op" style="color: #5E5E5E;">%</span>timeit _ <span class="op" style="color: #5E5E5E;">=</span> matmul(x_train.cuda(), weights.cuda())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2.86 s ± 4.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
<p>Interestingly, putting the tensors on the GPU and then broadcasting is slower than the CPU.</p>
</section>
<section id="numba-cuda" class="level3">
<h3 class="anchored" data-anchor-id="numba-cuda">Numba Cuda</h3>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><span class="at" style="color: #657422;">@cuda.jit</span></span>
<span id="cb75-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b,c):</span>
<span id="cb75-3">    i, j <span class="op" style="color: #5E5E5E;">=</span> cuda.grid(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb75-4">    <span class="cf" style="color: #003B4F;">if</span> i <span class="op" style="color: #5E5E5E;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;">0</span>] <span class="kw" style="color: #003B4F;">and</span> j <span class="op" style="color: #5E5E5E;">&lt;</span> c.shape[<span class="dv" style="color: #AD0000;">1</span>]:</span>
<span id="cb75-5">        tmp <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.</span></span>
<span id="cb75-6">        <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(a.shape[<span class="dv" style="color: #AD0000;">1</span>]): tmp <span class="op" style="color: #5E5E5E;">+=</span> a[i, k] <span class="op" style="color: #5E5E5E;">*</span> b[k, j]</span>
<span id="cb75-7">        c[i,j] <span class="op" style="color: #5E5E5E;">=</span> tmp</span></code></pre></div>
</div>
<div class="cell" data-execution_count="141">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1">r <span class="op" style="color: #5E5E5E;">=</span> np.zeros((<span class="dv" style="color: #AD0000;">50000</span>, <span class="dv" style="color: #AD0000;">10</span>))</span>
<span id="cb76-2">m1g,m2g,rg <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(cuda.to_device, (x_train,weights,r))</span></code></pre></div>
</div>
<div class="cell" data-execution_count="142">
<div class="sourceCode cell-code" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1">TPB <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">16</span></span>
<span id="cb77-2">rr,rc <span class="op" style="color: #5E5E5E;">=</span> r.shape</span>
<span id="cb77-3">blockspergrid <span class="op" style="color: #5E5E5E;">=</span> (math.ceil(rr <span class="op" style="color: #5E5E5E;">/</span> TPB), math.ceil(rc <span class="op" style="color: #5E5E5E;">/</span> TPB))</span>
<span id="cb77-4">blockspergrid</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="142">
<pre><code>(3125, 1)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="144">
<div class="sourceCode cell-code" id="cb79" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><span class="op" style="color: #5E5E5E;">%%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb79-2">matmul[blockspergrid, (TPB,TPB)](m1g,m2g,rg)</span>
<span id="cb79-3">r <span class="op" style="color: #5E5E5E;">=</span> rg.copy_to_host()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.91 ms ± 68.6 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="pytorch-cuda" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-cuda">PyTorch <code>cuda</code></h3>
<div class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">m1c,m2c <span class="op" style="color: #5E5E5E;">=</span> x_train.cuda(),weights.cuda()</span>
<span id="cb81-2"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span> r<span class="op" style="color: #5E5E5E;">=</span>(m1c<span class="op" style="color: #5E5E5E;">@</span>m2c).cpu()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>541 μs ± 6.82 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="einstein-summation" class="level3">
<h3 class="anchored" data-anchor-id="einstein-summation">Einstein Summation</h3>
<div class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b): <span class="cf" style="color: #003B4F;">return</span> torch.einsum(<span class="st" style="color: #20794D;">'ik,kj-&gt;ij'</span>, a, b)</span>
<span id="cb83-2"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train, weights)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.87 ms ± 229 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
<section id="numba-broadcasting" class="level3">
<h3 class="anchored" data-anchor-id="numba-broadcasting">Numba Broadcasting</h3>
<div class="cell" data-execution_count="191">
<div class="sourceCode cell-code" id="cb85" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb85-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb85-3">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb85-4">    c <span class="op" style="color: #5E5E5E;">=</span> np.zeros((ar, bc))</span>
<span id="cb85-5">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb85-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="192">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1">_<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train.numpy(), weights.numpy())</span></code></pre></div>
</div>
<div class="cell" data-execution_count="193">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><span class="op" style="color: #5E5E5E;">%</span>timeit _<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train.numpy(), weights.numpy())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>663 ms ± 378 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre>
</div>
</div>
</section>
<section id="pytorch-op" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-op">PyTorch <code>@</code> Op</h3>
<div class="cell" data-execution_count="194">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">10</span> _<span class="op" style="color: #5E5E5E;">=</span>x_train<span class="op" style="color: #5E5E5E;">@</span>weights</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.8 ms ± 212 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
</div>
</section>
</section>
<section id="comparing-5-digit-subset-to-full-dataset-times" class="level2">
<h2 class="anchored" data-anchor-id="comparing-5-digit-subset-to-full-dataset-times">Comparing 5-digit Subset to Full Dataset Times</h2>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Full Dataset Time</th>
<th style="text-align: center;">5-digit Subset Time/Rank</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>cuda</code></td>
<td style="text-align: center;">541 μs</td>
<td style="text-align: center;">108 μs (4)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba Cuda</td>
<td style="text-align: center;">3.91 ms</td>
<td style="text-align: center;">108 μs (4)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch <code>@</code> Op</td>
<td style="text-align: center;">5.8 ms</td>
<td style="text-align: center;">18.1 μs (1)</td>
</tr>
<tr class="even">
<td style="text-align: center;">Einstein Summation</td>
<td style="text-align: center;">5.87 ms</td>
<td style="text-align: center;">83.1 μs (3)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Broadcasting</td>
<td style="text-align: center;">663 ms</td>
<td style="text-align: center;">69.2 μs (2)</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">1.26 s</td>
<td style="text-align: center;">203 μs (6)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Numba Dot Product</td>
<td style="text-align: center;">3.71 s</td>
<td style="text-align: center;">542 μs (7)</td>
</tr>
</tbody>
</table>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>I initially ran into some problems on Colab when implementing <code>@cuda.jit</code> (an error about compute compatibility) so I switched to an RTX 3090 machine and installed the following, which let me successfully run this notebook:</p>
<pre><code>conda install -y -c nvidia/label/cuda-12.8.0 cuda-toolkit
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
conda install -y numba
conda install -y fastcore -c fastai</code></pre>
<p>The glaring takeaway from this exercise is that these methods all scale differently. For the 5-digit subset, PyTorch <code>cuda</code> was about 9 times slower than PyTorch CPU (when using the <code>@</code> operator). Numba cuda and PyTorch <code>cuda</code> were tied for the small subset, but PyTorch <code>cuda</code> was 8 times faster for the larger dataset. I don’t yet understand <em>why</em> these differences exist, so that’s something I’ll keep an eye out for as I learn more about how GPUs work!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>fastai</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/index.html</guid>
  <pubDate>Wed, 21 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-05-21-matmul-2/1.png" medium="image" type="image/png" height="51" width="144"/>
</item>
<item>
  <title>DataInspector with BinPackCollator: Inspecting Packed Dataloader Items</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<iframe width="560" height="315" src="https://www.youtube.com/embed/DUwJ9o-Ut5g?si=G8QiwIx_Y7W_LRZF" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<p>I recently learned (via a desperation google search “llm foundry sequence packing”) that LLM-Foundry has a built-in sequence packer called <a href="https://github.com/mosaicml/llm-foundry/blob/dedcfe3b760b847091642526e9fb303f39742a51/llmfoundry/data/packing.py#L24"><code>BinPackCollator</code></a>. To use it, you simply set two values in the training YAML: <code>train_loader.name=finetuning</code> and <code>train_loader.dataset.packing_ratio</code> to <code>auto</code> or a number greater than <code>1.0</code>. I haven’t fully/thoroughly understood/traced how <code>BinPackCollator</code> is activated, but here’s what I have found:</p>
<ul>
<li><a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/data/finetuning/dataloader.py#L668"><code>build_collate_fn</code></a> uses the <code>packing_ratio</code> config value. If <code>packing_ratio</code> is <code>1.0</code> it returns the <code>Seq2SeqFinetuningCollator</code>. If it’s <code>auto</code>, it calls the function <a href="https://github.com/mosaicml/llm-foundry/blob/dedcfe3b760b847091642526e9fb303f39742a51/llmfoundry/data/packing.py#L364"><code>auto_packing_ratio</code></a> which profiles the dataset to determine the optimal <code>packing_ratio</code> (a <code>packing_ratio</code> with zero waste). If <code>packing_ratio</code> is greater than <code>1.0</code>, it then <a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/data/finetuning/dataloader.py#L705">instantiates <code>BinPackCollator</code></a> as the <code>collate_fn</code>.</li>
<li><a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/data/finetuning/dataloader.py#L235"><code>build_finetuning_dataloader</code></a> constructs the <code>collate_fn</code> from <code>registry.collators</code> (tbh, I haven’t yet grasped the concept of registry and how it works in LLM-Foundry, on my to-do list).</li>
<li>The main training script, command_utils/train.py <a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/command_utils/train.py#L461">uses <code>build_dataloader</code></a> which takes the training loader config and uses <a href="https://github.com/mosaicml/llm-foundry/blob/7993aebe3207aae60aed0aab2a107e0114410e83/llmfoundry/data/dataloader.py#L32">the <code>name</code> attribute in the config (which is <code>finetuning</code> in our case)</a> to <code>construct_from_registry</code> which I do not understand how it works yet.</li>
</ul>
<p>Here’s an example YAML snippet which shows the necessary attributes (<code>name</code> and <code>packing_ratio</code>) to utilize <code>BinPackCollator</code>:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"><span id="cb1-1"><span class="fu" style="color: #4758AB;">train_loader</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-2"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">name</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> finetuning</span></span>
<span id="cb1-3"><span class="at" style="color: #657422;">  </span><span class="fu" style="color: #4758AB;">dataset</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-4"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">streams</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-5"><span class="at" style="color: #657422;">      </span><span class="fu" style="color: #4758AB;">my_data</span><span class="kw" style="color: #003B4F;">:</span></span>
<span id="cb1-6"><span class="at" style="color: #657422;">        </span><span class="fu" style="color: #4758AB;">local</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ${variables.data_local}</span></span>
<span id="cb1-7"><span class="at" style="color: #657422;">        </span><span class="fu" style="color: #4758AB;">remote</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ${variables.data_remote}</span></span>
<span id="cb1-8"><span class="at" style="color: #657422;">        </span><span class="fu" style="color: #4758AB;">split</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> train</span></span>
<span id="cb1-9"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">shuffle</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">true</span></span>
<span id="cb1-10"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">max_seq_len</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ${variables.max_seq_len}</span></span>
<span id="cb1-11"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">shuffle_seed</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> ${variables.global_seed}</span></span>
<span id="cb1-12"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">decoder_only_format</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="ch" style="color: #20794D;">true</span></span>
<span id="cb1-13"><span class="at" style="color: #657422;">    </span><span class="fu" style="color: #4758AB;">packing_ratio</span><span class="kw" style="color: #003B4F;">:</span><span class="at" style="color: #657422;"> </span><span class="fl" style="color: #AD0000;">5.0</span></span></code></pre></div>
<p>In this blog post, I’m going to share a custom Composer callback I wrote to inspect data during training and ensure that sequences are being packed!</p>
</section>
<section id="datainspector" class="level2">
<h2 class="anchored" data-anchor-id="datainspector"><code>DataInspector</code></h2>
<p>I’ll start by sharing the full code for my callback:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">class</span> DataInspector(Callback):</span>
<span id="cb2-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, save_path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/model-checkpoints/binpackcollator"</span>):</span>
<span id="cb2-3">        <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">=</span> Path(save_path)</span>
<span id="cb2-4">        <span class="va" style="color: #111111;">self</span>.log <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'log'</span>: {}}</span>
<span id="cb2-5"></span>
<span id="cb2-6">    <span class="kw" style="color: #003B4F;">def</span> after_dataloader(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-7">        <span class="va" style="color: #111111;">self</span>._log(</span>
<span id="cb2-8">            state, </span>
<span id="cb2-9">            <span class="st" style="color: #20794D;">"after_dataloader"</span>, </span>
<span id="cb2-10">            <span class="bu" style="color: null;">str</span>(state.timestamp.batch.value), </span>
<span id="cb2-11">            [</span>
<span id="cb2-12">                (<span class="st" style="color: #20794D;">'collate_fn'</span>, <span class="bu" style="color: null;">str</span>(state.dataloader.collate_fn.base_collator)),</span>
<span id="cb2-13">                (<span class="st" style="color: #20794D;">'input_ids_shape'</span>, <span class="bu" style="color: null;">str</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>].shape)), </span>
<span id="cb2-14">                (<span class="st" style="color: #20794D;">'total_tokens'</span>, <span class="bu" style="color: null;">str</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>].shape[<span class="dv" style="color: #AD0000;">1</span>])),</span>
<span id="cb2-15">                (<span class="st" style="color: #20794D;">'decoded_tokens'</span>, <span class="bu" style="color: null;">str</span>(state.model.tokenizer.decode(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]))),</span>
<span id="cb2-16">                (<span class="st" style="color: #20794D;">'padding_tokens'</span>, <span class="bu" style="color: null;">str</span>(<span class="bu" style="color: null;">len</span>([o <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">list</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]) <span class="cf" style="color: #003B4F;">if</span> o.item() <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>]))),</span>
<span id="cb2-17">                (<span class="st" style="color: #20794D;">'non_padding_tokens'</span>, <span class="bu" style="color: null;">str</span>(<span class="bu" style="color: null;">len</span>([o <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">list</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]) <span class="cf" style="color: #003B4F;">if</span> o.item() <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">0</span>]))),</span>
<span id="cb2-18">                (<span class="st" style="color: #20794D;">'input_ids[0]'</span>, <span class="bu" style="color: null;">str</span>(<span class="bu" style="color: null;">list</span>(state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]))),</span>
<span id="cb2-19">                </span>
<span id="cb2-20">            ])</span>
<span id="cb2-21"></span>
<span id="cb2-22">    <span class="kw" style="color: #003B4F;">def</span> _log(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>, batch_num: <span class="bu" style="color: null;">str</span>, values: <span class="bu" style="color: null;">list</span>[<span class="bu" style="color: null;">str</span>]) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-23">        <span class="cf" style="color: #003B4F;">for</span> label, value <span class="kw" style="color: #003B4F;">in</span> values: <span class="va" style="color: #111111;">self</span>.log[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_</span><span class="sc" style="color: #5E5E5E;">{</span>batch_num<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_</span><span class="sc" style="color: #5E5E5E;">{</span>label<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>] <span class="op" style="color: #5E5E5E;">=</span> value</span>
<span id="cb2-24">        <span class="va" style="color: #111111;">self</span>._save()</span>
<span id="cb2-25"></span>
<span id="cb2-26">    <span class="kw" style="color: #003B4F;">def</span> _save(<span class="va" style="color: #111111;">self</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-27">        os.makedirs(<span class="va" style="color: #111111;">self</span>.save_path, exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-28">        log_file <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">/</span> <span class="st" style="color: #20794D;">"datainspector_logs.json"</span></span>
<span id="cb2-29">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(log_file, <span class="st" style="color: #20794D;">'w'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb2-30">            json.dump(<span class="va" style="color: #111111;">self</span>.log, f, indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<p>I started testing the callback by writing a very basic version first:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">class</span> DataInspector(Callback):</span>
<span id="cb3-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, save_path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/model-checkpoints/binpackcollator"</span>):</span>
<span id="cb3-3">        <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">=</span> Path(save_path)</span>
<span id="cb3-4">        <span class="va" style="color: #111111;">self</span>.log <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'log'</span>: {}}</span>
<span id="cb3-5"></span>
<span id="cb3-6">    <span class="kw" style="color: #003B4F;">def</span> after_dataloader(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb3-7">        <span class="va" style="color: #111111;">self</span>._log(state, <span class="st" style="color: #20794D;">"after_dataloader"</span>, <span class="st" style="color: #20794D;">"some value"</span>)</span>
<span id="cb3-8"></span>
<span id="cb3-9">    <span class="kw" style="color: #003B4F;">def</span> _log(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>, value: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb3-10">        <span class="va" style="color: #111111;">self</span>.log[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>] <span class="op" style="color: #5E5E5E;">=</span> value</span>
<span id="cb3-11">        <span class="va" style="color: #111111;">self</span>._save()</span>
<span id="cb3-12"></span>
<span id="cb3-13">    <span class="kw" style="color: #003B4F;">def</span> _save(<span class="va" style="color: #111111;">self</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb3-14">        os.makedirs(<span class="va" style="color: #111111;">self</span>.save_path, exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb3-15">        log_file <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">/</span> <span class="st" style="color: #20794D;">"datainspector_logs.json"</span></span>
<span id="cb3-16">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(log_file, <span class="st" style="color: #20794D;">'w'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb3-17">            json.dump(<span class="va" style="color: #111111;">self</span>.log, f, indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<p>The <code>__init__</code> and <code>_save</code> methods are pretty straigtforward, as they instantiate the <code>save_path</code> and <code>log</code> and then save to the <code>log</code> at that <code>save_path</code>. I could have chosen any number of events to trigger logging, but I chose <code>after_loader</code> since I wanted to inspect the data after the dataloader was constructed. The <code>_log</code> basically takes in as input the strings you want to save in the <code>self.log</code> dictionary. Once this initial functionality was working, I added different items for logging one at a time, starting with <code>input_ids</code>, <code>non_padding_tokens</code> and <code>padding_tokens</code> (which are counts of tokens), inspecting the logs visually before I moved on to the next item. Along the way I learned that the dataloader’s <code>collate_fn</code> was <code>LossGeneratingTokensCollatorWrapper</code> and that its <code>base_collator</code> function was <code>BinPackCollator</code>.</p>
<p>Here’s a snippet of the log:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode json code-with-copy"><code class="sourceCode json"><span id="cb4-1"><span class="er" style="color: #AD0000;">"log":</span> <span class="fu" style="color: #4758AB;">{</span></span>
<span id="cb4-2">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_collate_fn"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"&lt;llmfoundry.data.packing.BinPackCollator object at 0x2ad36237cc20&gt;"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-3">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_input_ids_shape"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"torch.Size([4, 2048])"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-4">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_total_tokens"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"2048"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-5">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_padding_tokens"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"102"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-6">    <span class="dt" style="color: #AD0000;">"after_dataloader_0_non_padding_tokens"</span><span class="fu" style="color: #4758AB;">:</span> <span class="st" style="color: #20794D;">"1946"</span><span class="fu" style="color: #4758AB;">,</span></span>
<span id="cb4-7">    <span class="er" style="color: #AD0000;">...</span></span></code></pre></div>
<p>Here are screenshots of the actual log, first <strong>without</strong> using <code>BinPackCollator</code>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" title="log without using BinPackCollator. Note that the number of padding tokens represent ~90% of the max sequence length of 2048" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">log without using <code>BinPackCollator</code>. Note that the number of padding tokens represent ~90% of the max sequence length of 2048</figcaption><p></p>
</figure>
</div>
<p>And with using <code>BinPackCollator</code>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" title="log when using BinPackCollator. Now the non-padding token represent 90% of the sequence length" data-gallery="quarto-lightbox-gallery-2"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">log when using <code>BinPackCollator</code>. Now the non-padding token represent 90% of the sequence length</figcaption><p></p>
</figure>
</div>
<p>Using <code>BinPackCollator</code>, we are now using more than 90% of the maximum sequence length with loss generating tokens!</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>This is the fourth or fifth custom Composer callback I’ve written and I am really enjoyin writing and using them! The callback system makes it so easy to “look at your data”, and visually inspect and confirm that the model and/or data artifacts are correct. Expect more blog posts around Composer callbacks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="ChatGPT generated graphic for `DataInspector`.png" class="lightbox" title="3.png" data-gallery="quarto-lightbox-gallery-3"><img src="https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/ChatGPT generated graphic for `DataInspector`.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">3.png</figcaption><p></p>
</figure>
</div>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>LLM-Foundry</category>
  <category>Custom Composer Callback</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/index.html</guid>
  <pubDate>Tue, 13 May 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-05-13-DataInspector-BinPackCollator/1.png" medium="image" type="image/png" height="85" width="144"/>
</item>
<item>
  <title>Comparing RAGatouille and ColBERT Indexes and Search Results</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-10-RAGatouille-ColBERT-Comparisons/index.html</link>
  <description><![CDATA[ 



<div class="cell">
<details>
<summary>Show setup</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> faiss</span>
<span id="cb1-2"><span class="bu" style="color: null;">hasattr</span>(faiss, <span class="st" style="color: #20794D;">"StandardGpuResources"</span>)</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="im" style="color: #00769E;">from</span> datasets <span class="im" style="color: #00769E;">import</span> load_dataset</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> ragatouille <span class="im" style="color: #00769E;">import</span> RAGPretrainedModel</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> time</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> pytrec_eval</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> ranx <span class="im" style="color: #00769E;">import</span> evaluate</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">from</span> ranx <span class="im" style="color: #00769E;">import</span> Qrels, Run</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">import</span> pickle</span>
<span id="cb1-11"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb1-12"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-13"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-14"><span class="im" style="color: #00769E;">import</span> srsly</span>
<span id="cb1-15"></span>
<span id="cb1-16"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Indexer</span>
<span id="cb1-17"><span class="im" style="color: #00769E;">from</span> colbert.infra <span class="im" style="color: #00769E;">import</span> RunConfig, ColBERTConfig</span>
<span id="cb1-18"><span class="im" style="color: #00769E;">from</span> colbert.infra.run <span class="im" style="color: #00769E;">import</span> Run</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="im" style="color: #00769E;">from</span> colbert.data <span class="im" style="color: #00769E;">import</span> Queries</span>
<span id="cb1-21"><span class="im" style="color: #00769E;">from</span> colbert <span class="im" style="color: #00769E;">import</span> Searcher</span></code></pre></div>
</details>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this notebook I am trying to answer two questions:</p>
<ol type="1">
<li>For a given document collection and indexing configuration, do RAGatouille and ColBERT produce the same index?</li>
<li>For a given index and search configuration, do RAGatouille and ColBERT retrieve the same passages/Recall@10?</li>
</ol>
<p>For this exercise, I’m using the UKPLab/DAPR’s ConditionalQA document collection which is 69k rows. If this exercise is successful, I’ll scale to larger document collections.</p>
<p>Here’s my rough plan:</p>
<ol type="1">
<li>Index the ConditionalQA document collection using RAGatouille and ColBERT. Be very thorough in ensuring the same configuration values are used.</li>
<li>Compare artifacts of the index (json and pt files). Document differences.</li>
<li>If successful, I would expect both indexes to largely be identical. If not, that’s a deeper dive.</li>
<li>Assuming successful equality of indexes, I’ll then perform search on the index using each framework, and compare retrieved passages and Recall@10. Initially, I’ll use RAGatouille search on the RAGatouille index, and ColBERT search on the ColBERT index. If that goes well, I might use one framework to search on the other’s index. RAGatouille requires some additional files so I’ll likely have to create them manually from the ColBERT index artifacts.</li>
<li>If I get similar Recall@10 and retrieved passages, great! If not, that’s a deeper dive.</li>
</ol>
</section>
<section id="load-the-data" class="level2">
<h2 class="anchored" data-anchor-id="load-the-data">Load the Data</h2>
<div class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">dataset_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"ConditionalQA"</span></span>
<span id="cb2-2">dataset_name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="150">
<pre><code>'ConditionalQA'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="292">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">passages <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-corpus"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb4-2">queries <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-queries"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span>
<span id="cb4-3">qrels_rows <span class="op" style="color: #5E5E5E;">=</span> load_dataset(<span class="st" style="color: #20794D;">"UKPLab/dapr"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">-qrels"</span>, split<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"test"</span>)</span></code></pre></div>
</div>
</section>
<section id="create-ragatouille-index-1k-subset" class="level2">
<h2 class="anchored" data-anchor-id="create-ragatouille-index-1k-subset">Create RAGatouille Index (1k subset)</h2>
<div class="cell" data-execution_count="152">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">RAG <span class="op" style="color: #5E5E5E;">=</span> RAGPretrainedModel.from_pretrained(<span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="153">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">n_items <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1000</span></span>
<span id="cb6-2">n_items</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="153">
<pre><code>1000</code></pre>
</div>
</div>
<p>Notes about <code>RAG.model.config</code> before indexing:</p>
<ul>
<li>The following values are <code>None</code>: <code>ncells</code>, <code>centroid_score_threshold</code>, <code>ndocs</code></li>
<li><code>kmeans_niters=4</code></li>
<li><code>nbits=1</code></li>
<li><code>index_bsize=64</code></li>
<li><code>bsize=32</code></li>
<li><code>dim=96</code></li>
<li><code>doc_maxlen=300</code></li>
<li><code>rank=0</code></li>
<li><code>nranks=4</code></li>
<li><code>gpus=4</code></li>
</ul>
<div class="cell" data-execution_count="154">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">RAG.model.config</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="154">
<pre><code>ColBERTConfig(query_token_id='[unused0]', doc_token_id='[unused1]', query_token='[Q]', doc_token='[D]', ncells=None, centroid_score_threshold=None, ndocs=None, load_index_with_mmap=False, index_path=None, index_bsize=64, nbits=1, kmeans_niters=4, resume=False, pool_factor=1, clustering_mode='hierarchical', protected_tokens=0, similarity='cosine', bsize=32, accumsteps=1, lr=1e-05, maxsteps=15626, save_every=None, warmup=781, warmup_bert=None, relu=False, nway=32, use_ib_negatives=False, reranker=False, distillation_alpha=1.0, ignore_scores=False, model_name='answerdotai/AnswerAI-ColBERTv2.5-small', query_maxlen=32, attend_to_mask_tokens=False, interaction='colbert', dim=96, doc_maxlen=300, mask_punctuation=True, checkpoint='/home/vishal/.cache/huggingface/hub/models--answerdotai--answerai-colbert-small-v1/snapshots/be1703c55532145a844da800eea4c9a692d7e267/', triples='/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl', collection='/home/bclavie/colbertv2.5_en/data/msmarco/collection.tsv', queries='/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv', index_name=None, overwrite=False, root='.ragatouille/', experiment='colbert', index_root=None, name='2024-08/07/08.16.20', rank=0, nranks=4, amp=True, gpus=4, avoid_fork_if_possible=False)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="155">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;">#!rm -rf .ragatouille/colbert/indexes/ConditionalQA_RAGatouille_index_1k</span></span></code></pre></div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">RAG_index_path <span class="op" style="color: #5E5E5E;">=</span> RAG.index(</span>
<span id="cb11-2">    index_name<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_RAGatouille_index_1k"</span>,</span>
<span id="cb11-3">    collection<span class="op" style="color: #5E5E5E;">=</span>passages[:n_items][<span class="st" style="color: #20794D;">"text"</span>],</span>
<span id="cb11-4">    document_ids<span class="op" style="color: #5E5E5E;">=</span>passages[:n_items][<span class="st" style="color: #20794D;">"_id"</span>],</span>
<span id="cb11-5">    use_faiss<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span> <span class="co" style="color: #5E5E5E;"># to match ColBERT</span></span>
<span id="cb11-6">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="157">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="op" style="color: #5E5E5E;">!</span>du <span class="op" style="color: #5E5E5E;">-</span>sh {RAG_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.2M    .ragatouille/colbert/indexes/ConditionalQA_RAGatouille_index_1k</code></pre>
</div>
</div>
<div class="cell" data-execution_count="158">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="op" style="color: #5E5E5E;">!</span>ls {RAG_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.codes.pt   avg_residual.pt  collection.json  metadata.json
0.metadata.json  buckets.pt   doclens.0.json   pid_docid_map.json
0.residuals.pt   centroids.pt     ivf.pid.pt       plan.json</code></pre>
</div>
</div>
<p>Notes about <code>metadata.json</code> <em>after</em> indexing:</p>
<ul>
<li>The following values are still <code>None</code>: <code>ncells</code>, <code>centroid_score_threshold</code>, <code>ndocs</code></li>
<li><code>kmeans_niters=20</code> (up from 4)</li>
<li><code>nbits=4</code> (up from 1)</li>
<li><code>index_bsize=64</code></li>
<li><code>bsize=64</code> (up from 32)</li>
<li><code>dim=96</code></li>
<li><code>doc_maxlen=256</code> (down from 300)</li>
<li><code>rank=0</code></li>
<li><code>nranks=1</code> (down from 4)</li>
<li><code>gpus=1</code> (down from 4)</li>
<li><code>'num_partitions'=1024</code> (not in original config)</li>
</ul>
<p>Inspecting the RAGatouille metadata:</p>
<div class="cell" data-scrolled="true" data-execution_count="159">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb16-2">    RAG_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb16-3">RAG_metadata</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="159">
<pre><code>{'config': {'query_token_id': '[unused0]',
  'doc_token_id': '[unused1]',
  'query_token': '[Q]',
  'doc_token': '[D]',
  'ncells': None,
  'centroid_score_threshold': None,
  'ndocs': None,
  'load_index_with_mmap': False,
  'index_path': None,
  'index_bsize': 32,
  'nbits': 4,
  'kmeans_niters': 20,
  'resume': False,
  'pool_factor': 1,
  'clustering_mode': 'hierarchical',
  'protected_tokens': 0,
  'similarity': 'cosine',
  'bsize': 64,
  'accumsteps': 1,
  'lr': 1e-05,
  'maxsteps': 15626,
  'save_every': None,
  'warmup': 781,
  'warmup_bert': None,
  'relu': False,
  'nway': 32,
  'use_ib_negatives': False,
  'reranker': False,
  'distillation_alpha': 1.0,
  'ignore_scores': False,
  'model_name': 'answerdotai/AnswerAI-ColBERTv2.5-small',
  'query_maxlen': 32,
  'attend_to_mask_tokens': False,
  'interaction': 'colbert',
  'dim': 96,
  'doc_maxlen': 256,
  'mask_punctuation': True,
  'checkpoint': 'answerdotai/answerai-colbert-small-v1',
  'triples': '/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl',
  'collection': ['list with 1000 elements starting with...',
   ['Overview',
    'You can only make a claim for Child Tax Credit if you already get Working Tax Credit.',
    'If you cannot apply for Child Tax Credit, you can apply for Universal Credit instead.']],
  'queries': '/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv',
  'index_name': 'ConditionalQA_RAGatouille_index_1k',
  'overwrite': False,
  'root': '.ragatouille/',
  'experiment': 'colbert',
  'index_root': None,
  'name': '2025-05/09/10.30.23',
  'rank': 0,
  'nranks': 1,
  'amp': True,
  'gpus': 1,
  'avoid_fork_if_possible': False},
 'num_chunks': 1,
 'num_partitions': 1024,
 'num_embeddings': 15198,
 'avg_doclen': 15.198,
 'RAGatouille': {'index_config': {'index_type': 'PLAID',
   'index_name': 'ConditionalQA_RAGatouille_index_1k'}}}</code></pre>
</div>
</div>
<table class="table">
<colgroup>
<col style="width: 22%">
<col style="width: 32%">
<col style="width: 30%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Before Indexing</th>
<th>After Indexing</th>
<th>Impact</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>kmeans_niters</code></td>
<td>4</td>
<td>20</td>
<td>5× more iterations for clustering</td>
</tr>
<tr class="even">
<td><code>nbits</code></td>
<td>1</td>
<td>4</td>
<td>4× more bits for residual compression</td>
</tr>
<tr class="odd">
<td><code>bsize</code></td>
<td>32</td>
<td>64</td>
<td>Doubled batch size</td>
</tr>
<tr class="even">
<td><code>doc_maxlen</code></td>
<td>300</td>
<td>256</td>
<td>Reduced document length limit</td>
</tr>
<tr class="odd">
<td><code>nranks</code></td>
<td>4</td>
<td>1</td>
<td>Changed to single-process execution</td>
</tr>
<tr class="even">
<td><code>gpus</code></td>
<td>4</td>
<td>1</td>
<td>Changed to single-GPU execution</td>
</tr>
<tr class="odd">
<td><code>num_partitions</code></td>
<td>(not set)</td>
<td>1024</td>
<td>New parameter added during indexing</td>
</tr>
</tbody>
</table>
<p>The following are search parameters so they are not set/used for indexing: <code>ncells</code>, <code>centroid_score_threshold</code>, <code>ndocs</code>.</p>
</section>
<section id="create-vanilla-colbert-index-1k-subset" class="level2">
<h2 class="anchored" data-anchor-id="create-vanilla-colbert-index-1k-subset">Create Vanilla ColBERT Index (1k subset)</h2>
<p>Next, I’ll index the same document collection using vanilla ColBERT (which is installed with RAGatouille).</p>
<div class="cell" data-execution_count="160">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">dataset_name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="160">
<pre><code>'ConditionalQA'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="161">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">ColBERTConfig()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="161">
<pre><code>ColBERTConfig(query_token_id='[unused0]', doc_token_id='[unused1]', query_token='[Q]', doc_token='[D]', ncells=None, centroid_score_threshold=None, ndocs=None, load_index_with_mmap=False, index_path=None, index_bsize=64, nbits=1, kmeans_niters=4, resume=False, pool_factor=1, clustering_mode='hierarchical', protected_tokens=0, similarity='cosine', bsize=32, accumsteps=1, lr=3e-06, maxsteps=500000, save_every=None, warmup=None, warmup_bert=None, relu=False, nway=2, use_ib_negatives=False, reranker=False, distillation_alpha=1.0, ignore_scores=False, model_name=None, query_maxlen=32, attend_to_mask_tokens=False, interaction='colbert', dim=128, doc_maxlen=220, mask_punctuation=True, checkpoint=None, triples=None, collection=None, queries=None, index_name=None, overwrite=False, root='/mnt/my4tb/vishal_data/SuperPassage/experiments', experiment='default', index_root=None, name='2025-05/09/10.30.23', rank=0, nranks=1, amp=True, gpus=1, avoid_fork_if_possible=False)</code></pre>
</div>
</div>
<p>Key differences from this initial config and RAGatouille’s post-indexing metadata:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Parameter</th>
<th style="text-align: center;">RAGatouille value</th>
<th style="text-align: center;">ColBERT value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><code>kmeans_iter</code></td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">4</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>nbits</code></td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">1</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>dim</code></td>
<td style="text-align: center;">96</td>
<td style="text-align: center;">128</td>
</tr>
<tr class="even">
<td style="text-align: center;"><code>doc_maxlen</code></td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">220</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><code>index_bsize</code></td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">64</td>
</tr>
</tbody>
</table>
<p>I will set these explicitly in the ColBERTConfig before indexing.</p>
<div class="cell" data-execution_count="162">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">n_items</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="162">
<pre><code>1000</code></pre>
</div>
</div>
<p>The following environmental variable needs to be set otherwise the script won’t run.</p>
<div class="cell" data-execution_count="189">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">os.environ[<span class="st" style="color: #20794D;">"MKL_SERVICE_FORCE_INTEL"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"1"</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;">#!rm -rf /mnt/my4tb/vishal_data/SuperPassage/.ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_1k</span></span></code></pre></div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb26-2">    config <span class="op" style="color: #5E5E5E;">=</span> ColBERTConfig(</span>
<span id="cb26-3">        doc_maxlen<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>,      </span>
<span id="cb26-4">        nbits<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,             </span>
<span id="cb26-5">        dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">96</span>,             </span>
<span id="cb26-6">        kmeans_niters<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">20</span>,</span>
<span id="cb26-7">        index_bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32</span>,</span>
<span id="cb26-8">        bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb26-9">        checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>,</span>
<span id="cb26-10">    )</span>
<span id="cb26-11">    </span>
<span id="cb26-12">    indexer <span class="op" style="color: #5E5E5E;">=</span> Indexer(checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>, config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb26-13">    indexer.index(name<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_ColBERT_index_1k"</span>, collection<span class="op" style="color: #5E5E5E;">=</span>passages[:n_items][<span class="st" style="color: #20794D;">"text"</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">ColBERT_index_path <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">".ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_1k"</span></span></code></pre></div>
</div>
<p>The ColBERT index is a tiny bit smaller than RAGatouille, likely because it doesn’t store the collection as a JSON file and doesn’t store pid to docid map as a JSON file (which RAGatouille does—something we’ll encounter later on during search).</p>
<div class="cell" data-execution_count="168">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="op" style="color: #5E5E5E;">!</span>du <span class="op" style="color: #5E5E5E;">-</span>sh {ColBERT_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.1M    .ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_1k</code></pre>
</div>
</div>
<div class="cell" data-execution_count="169">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="op" style="color: #5E5E5E;">!</span>ls {ColBERT_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.codes.pt   0.residuals.pt   buckets.pt    doclens.0.json  metadata.json
0.metadata.json  avg_residual.pt  centroids.pt  ivf.pid.pt  plan.json</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="170">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb32-2">    ColBERT_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb32-3">ColBERT_metadata</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="170">
<pre><code>{'config': {'query_token_id': '[unused0]',
  'doc_token_id': '[unused1]',
  'query_token': '[Q]',
  'doc_token': '[D]',
  'ncells': None,
  'centroid_score_threshold': None,
  'ndocs': None,
  'load_index_with_mmap': False,
  'index_path': None,
  'index_bsize': 32,
  'nbits': 4,
  'kmeans_niters': 20,
  'resume': False,
  'pool_factor': 1,
  'clustering_mode': 'hierarchical',
  'protected_tokens': 0,
  'similarity': 'cosine',
  'bsize': 64,
  'accumsteps': 1,
  'lr': 1e-05,
  'maxsteps': 15626,
  'save_every': None,
  'warmup': 781,
  'warmup_bert': None,
  'relu': False,
  'nway': 32,
  'use_ib_negatives': False,
  'reranker': False,
  'distillation_alpha': 1.0,
  'ignore_scores': False,
  'model_name': 'answerdotai/AnswerAI-ColBERTv2.5-small',
  'query_maxlen': 32,
  'attend_to_mask_tokens': False,
  'interaction': 'colbert',
  'dim': 96,
  'doc_maxlen': 256,
  'mask_punctuation': True,
  'checkpoint': 'answerdotai/answerai-colbert-small-v1',
  'triples': '/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl',
  'collection': ['list with 1000 elements starting with...',
   ['Overview',
    'You can only make a claim for Child Tax Credit if you already get Working Tax Credit.',
    'If you cannot apply for Child Tax Credit, you can apply for Universal Credit instead.']],
  'queries': '/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv',
  'index_name': 'ConditionalQA_ColBERT_index_1k',
  'overwrite': False,
  'root': '.ragatouille/',
  'experiment': 'colbert',
  'index_root': None,
  'name': '2025-05/09/10.30.23',
  'rank': 0,
  'nranks': 1,
  'amp': True,
  'gpus': 1,
  'avoid_fork_if_possible': False},
 'num_chunks': 1,
 'num_partitions': 1024,
 'num_embeddings': 15198,
 'avg_doclen': 15.198}</code></pre>
</div>
</div>
</section>
<section id="comparing-1k-subset-index-artifacts" class="level2">
<h2 class="anchored" data-anchor-id="comparing-1k-subset-index-artifacts">Comparing 1k subset Index Artifacts</h2>
<p>RAGatouille files:</p>
<ul>
<li>0.codes.pt<br>
</li>
<li>0.residuals.pt</li>
<li>buckets.pt<br>
</li>
<li>doclens.0.json</li>
<li>metadata.json</li>
<li>0.metadata.json</li>
<li>avg_residual.pt</li>
<li>centroids.pt</li>
<li>ivf.pid.pt</li>
<li>plan.json</li>
<li>collection.json (unique to RAGatouille)</li>
<li>pid_docid_map.json (unique to RAGatouille)</li>
</ul>
<p>ColBERT files:</p>
<ul>
<li>0.codes.pt</li>
<li>0.residuals.pt</li>
<li>buckets.pt</li>
<li>doclens.0.json</li>
<li>metadata.json</li>
<li>0.metadata.json</li>
<li>avg_residual.pt</li>
<li>centroids.pt<br>
</li>
<li>ivf.pid.pt<br>
</li>
<li>plan.json</li>
</ul>
<p>All parameters relevant to indexing are matching in the corresponding metadata.json files:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;">Parameter</th>
<th style="text-align: left;">Value</th>
<th style="text-align: center;">Status</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>index_bsize</code></td>
<td style="text-align: left;">32</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>nbits</code></td>
<td style="text-align: left;">4</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>kmeans_niters</code></td>
<td style="text-align: left;">20</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>dim</code></td>
<td style="text-align: left;">96</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>doc_maxlen</code></td>
<td style="text-align: left;">256</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>num_partitions</code></td>
<td style="text-align: left;">1024</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>num_embeddings</code></td>
<td style="text-align: left;">15198</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>avg_doclen</code></td>
<td style="text-align: left;">15.198</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>checkpoint</code></td>
<td style="text-align: left;">‘answerdotai/answerai-colbert-small-v1’</td>
<td style="text-align: center;">✅ Matches</td>
</tr>
</tbody>
</table>
<p>Walking through each file and comparing contents:</p>
<div class="cell" data-execution_count="171">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="kw" style="color: #003B4F;">def</span> _compare_pt(r_path, c_path):</span>
<span id="cb34-2">    r <span class="op" style="color: #5E5E5E;">=</span> torch.load(r_path)</span>
<span id="cb34-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.load(c_path)</span>
<span id="cb34-4">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(r,<span class="bu" style="color: null;">tuple</span>):</span>
<span id="cb34-5">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"0 shape:"</span>, r[<span class="dv" style="color: #AD0000;">0</span>].shape, c[<span class="dv" style="color: #AD0000;">0</span>].shape)</span>
<span id="cb34-6">        <span class="bu" style="color: null;">print</span>(r[<span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb34-7">        <span class="bu" style="color: null;">print</span>(c[<span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb34-8">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-9">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"0 match: "</span>, (r[<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">0</span>]).<span class="bu" style="color: null;">float</span>().mean())</span>
<span id="cb34-10">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-11">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'#'</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">30</span>)</span>
<span id="cb34-12">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-13">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"1 shape:"</span>, r[<span class="dv" style="color: #AD0000;">1</span>].shape, c[<span class="dv" style="color: #AD0000;">1</span>].shape)</span>
<span id="cb34-14">        <span class="bu" style="color: null;">print</span>(r[<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb34-15">        <span class="bu" style="color: null;">print</span>(c[<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb34-16">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-17">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"1 match: "</span>, (r[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">1</span>]).<span class="bu" style="color: null;">float</span>().mean())</span>
<span id="cb34-18">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb34-19">        <span class="bu" style="color: null;">print</span>(r)</span>
<span id="cb34-20">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-21">        <span class="bu" style="color: null;">print</span>(c)</span>
<span id="cb34-22">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-23">        <span class="bu" style="color: null;">print</span>(r.shape, c.shape)</span>
<span id="cb34-24">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>)</span>
<span id="cb34-25">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"match: "</span>,(r <span class="op" style="color: #5E5E5E;">==</span> c).<span class="bu" style="color: null;">float</span>().mean())</span></code></pre></div>
</div>
<section id="codes.pt" class="level3">
<h3 class="anchored" data-anchor-id="codes.pt">0.codes.pt</h3>
<div class="cell" data-execution_count="173">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/0.codes.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/0.codes.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([345, 288, 647,  ..., 232, 767,  29], dtype=torch.int32)


tensor([345, 288, 647,  ..., 232, 767,  29], dtype=torch.int32)


torch.Size([15198]) torch.Size([15198])


match:  tensor(1.)</code></pre>
</div>
</div>
</section>
<section id="residuals.pt" class="level3">
<h3 class="anchored" data-anchor-id="residuals.pt">0.residuals.pt</h3>
<div class="cell" data-execution_count="175">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/0.residuals.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/0.residuals.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 30, 225, 225,  ..., 238, 238,  30],
        [238, 238, 238,  ..., 238, 238, 238],
        [240, 254, 253,  ..., 175, 240, 128],
        ...,
        [ 99, 105, 231,  ...,  40,  95,  48],
        [ 85, 241,  87,  ..., 128,   8, 179],
        [ 89, 106, 150,  ..., 162, 238,  22]], dtype=torch.uint8)


tensor([[ 30, 225, 225,  ..., 238, 238,  30],
        [238, 238, 238,  ..., 238, 238, 238],
        [240, 254, 253,  ..., 175, 240, 128],
        ...,
        [ 99, 105, 231,  ...,  40,  95,  48],
        [ 85, 241,  87,  ..., 128,   8, 179],
        [ 89, 106, 150,  ..., 162, 238,  22]], dtype=torch.uint8)


torch.Size([15198, 48]) torch.Size([15198, 48])


match:  tensor(1.)</code></pre>
</div>
</div>
</section>
<section id="centroids.pt" class="level3">
<h3 class="anchored" data-anchor-id="centroids.pt">centroids.pt</h3>
<div class="cell" data-execution_count="176">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/centroids.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/centroids.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[-0.0701,  0.0035, -0.0785,  ...,  0.1628,  0.0201, -0.0419],
        [-0.0350, -0.0082, -0.0715,  ...,  0.1119, -0.0159, -0.1164],
        [-0.0753,  0.0172, -0.0513,  ...,  0.1070,  0.1476, -0.0699],
        ...,
        [-0.1425,  0.1393, -0.2316,  ...,  0.0169,  0.0897, -0.0431],
        [-0.0690,  0.0513, -0.0935,  ...,  0.1311,  0.0324, -0.0705],
        [-0.0812,  0.0511, -0.0482,  ...,  0.1010,  0.0365, -0.0582]],
       device='cuda:0', dtype=torch.float16)


tensor([[-0.0701,  0.0035, -0.0785,  ...,  0.1628,  0.0201, -0.0419],
        [-0.0350, -0.0082, -0.0715,  ...,  0.1119, -0.0159, -0.1164],
        [-0.0753,  0.0172, -0.0513,  ...,  0.1070,  0.1476, -0.0699],
        ...,
        [-0.1425,  0.1393, -0.2316,  ...,  0.0169,  0.0897, -0.0431],
        [-0.0690,  0.0513, -0.0935,  ...,  0.1311,  0.0324, -0.0705],
        [-0.0812,  0.0511, -0.0482,  ...,  0.1010,  0.0365, -0.0582]],
       device='cuda:0', dtype=torch.float16)


torch.Size([1024, 96]) torch.Size([1024, 96])


match:  tensor(1., device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="ivf.pid.pt" class="level3">
<h3 class="anchored" data-anchor-id="ivf.pid.pt">ivf.pid.pt</h3>
<div class="cell" data-execution_count="177">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/ivf.pid.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/ivf.pid.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0 shape: torch.Size([11696]) torch.Size([11696])
tensor([889, 894, 916,  ...,   0,   0,   0], dtype=torch.int32)
tensor([889, 894, 916,  ...,   0,   0,   0], dtype=torch.int32)


0 match:  tensor(1.)


##############################


1 shape: torch.Size([1024]) torch.Size([1024])
tensor([ 5, 46, 16,  ...,  7, 11,  3])
tensor([ 5, 46, 16,  ...,  7, 11,  3])


1 match:  tensor(1.)</code></pre>
</div>
</div>
</section>
<section id="buckets.pt" class="level3">
<h3 class="anchored" data-anchor-id="buckets.pt">buckets.pt</h3>
<div class="cell" data-execution_count="178">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/buckets.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/buckets.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0 shape: torch.Size([15]) torch.Size([15])
tensor([-0.0310, -0.0208, -0.0148, -0.0101, -0.0065, -0.0037, -0.0015,  0.0000,
         0.0016,  0.0037,  0.0067,  0.0103,  0.0150,  0.0210,  0.0312],
       device='cuda:0')
tensor([-0.0310, -0.0208, -0.0148, -0.0101, -0.0065, -0.0037, -0.0015,  0.0000,
         0.0016,  0.0037,  0.0067,  0.0103,  0.0150,  0.0210,  0.0312],
       device='cuda:0')


0 match:  tensor(1., device='cuda:0')


##############################


1 shape: torch.Size([16]) torch.Size([16])
tensor([-0.0417, -0.0248, -0.0175, -0.0123, -0.0082, -0.0050, -0.0025, -0.0006,
         0.0007,  0.0026,  0.0051,  0.0084,  0.0125,  0.0178,  0.0251,  0.0417],
       device='cuda:0', dtype=torch.float16)
tensor([-0.0417, -0.0248, -0.0175, -0.0123, -0.0082, -0.0050, -0.0025, -0.0006,
         0.0007,  0.0026,  0.0051,  0.0084,  0.0125,  0.0178,  0.0251,  0.0417],
       device='cuda:0', dtype=torch.float16)


1 match:  tensor(1., device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="avg_residual.pt" class="level3">
<h3 class="anchored" data-anchor-id="avg_residual.pt">avg_residual.pt</h3>
<div class="cell" data-execution_count="179">
<div class="sourceCode cell-code" id="cb45" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1">_compare_pt(r_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/avg_residual.pt"</span>, c_path<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/avg_residual.pt"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(0.0150, device='cuda:0', dtype=torch.float16)


tensor(0.0150, device='cuda:0', dtype=torch.float16)


torch.Size([]) torch.Size([])


match:  tensor(1., device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="doclens.0.json" class="level3">
<h3 class="anchored" data-anchor-id="doclens.0.json">doclens.0.json</h3>
<div class="cell" data-execution_count="180">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/doclens.0.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb47-2">    RAGatouille_doclens <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb47-3">RAGatouille_doclens[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="180">
<pre><code>[4, 20, 18, 23, 8]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="181">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/doclens.0.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb49-2">    ColBERT_doclens <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span>
<span id="cb49-3">ColBERT_doclens[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="181">
<pre><code>[4, 20, 18, 23, 8]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="182">
<div class="sourceCode cell-code" id="cb51" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1">RAGatouille_doclens <span class="op" style="color: #5E5E5E;">==</span> ColBERT_doclens</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="182">
<pre><code>True</code></pre>
</div>
</div>
<p>Based on these comparisons, I can conclude that ColBERT and RAGatouille do indeed produce identical index artifacts given the same configuration and document collection!</p>
</section>
</section>
<section id="indexing-full-conditionalqa-comparing-artifacts" class="level2">
<h2 class="anchored" data-anchor-id="indexing-full-conditionalqa-comparing-artifacts">Indexing Full ConditionalQA + Comparing Artifacts</h2>
<p>With a 1k subset confirmed, I’ll now index the full ConditionalQA document collection, which contains ~70k rows.</p>
<div class="cell" data-execution_count="183">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">dataset_name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="183">
<pre><code>'ConditionalQA'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="186">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="bu" style="color: null;">len</span>(passages)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="186">
<pre><code>69199</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1">RAG <span class="op" style="color: #5E5E5E;">=</span> RAGPretrainedModel.from_pretrained(<span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>)</span>
<span id="cb57-2">RAG_index_path <span class="op" style="color: #5E5E5E;">=</span> RAG.index(</span>
<span id="cb57-3">    index_name<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_RAGatouille_index_full"</span>,</span>
<span id="cb57-4">    collection<span class="op" style="color: #5E5E5E;">=</span>passages[<span class="st" style="color: #20794D;">"text"</span>],</span>
<span id="cb57-5">    document_ids<span class="op" style="color: #5E5E5E;">=</span>passages[<span class="st" style="color: #20794D;">"_id"</span>],</span>
<span id="cb57-6">    use_faiss<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span> <span class="co" style="color: #5E5E5E;"># to match ColBERT</span></span>
<span id="cb57-7">)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="187">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><span class="op" style="color: #5E5E5E;">!</span>du <span class="op" style="color: #5E5E5E;">-</span>sh {RAG_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>45M .ragatouille/colbert/indexes/ConditionalQA_RAGatouille_index_full</code></pre>
</div>
</div>
<div class="cell" data-execution_count="188">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><span class="op" style="color: #5E5E5E;">!</span>ls {RAG_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.codes.pt   1.residuals.pt   buckets.pt       doclens.2.json
0.metadata.json  2.codes.pt   centroids.pt     ivf.pid.pt
0.residuals.pt   2.metadata.json  collection.json  metadata.json
1.codes.pt   2.residuals.pt   doclens.0.json   pid_docid_map.json
1.metadata.json  avg_residual.pt  doclens.1.json   plan.json</code></pre>
</div>
</div>
<div class="cell" data-execution_count="196">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><span class="co" style="color: #5E5E5E;">#!rm -rf .ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_full</span></span></code></pre></div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1">os.environ[<span class="st" style="color: #20794D;">"MKL_SERVICE_FORCE_INTEL"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"1"</span></span>
<span id="cb63-2"><span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb63-3">    config <span class="op" style="color: #5E5E5E;">=</span> ColBERTConfig(</span>
<span id="cb63-4">        doc_maxlen<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>,      </span>
<span id="cb63-5">        nbits<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>,  <span class="co" style="color: #5E5E5E;"># to match RAGatouille           </span></span>
<span id="cb63-6">        dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">96</span>,             </span>
<span id="cb63-7">        kmeans_niters<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>, <span class="co" style="color: #5E5E5E;"># to match RAGatouille</span></span>
<span id="cb63-8">        index_bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32</span>,</span>
<span id="cb63-9">        bsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb63-10">        checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>,</span>
<span id="cb63-11">    )</span>
<span id="cb63-12">    </span>
<span id="cb63-13">    indexer <span class="op" style="color: #5E5E5E;">=</span> Indexer(checkpoint<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"answerdotai/answerai-colbert-small-v1"</span>, config<span class="op" style="color: #5E5E5E;">=</span>config)</span>
<span id="cb63-14">    indexer.index(name<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>dataset_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_ColBERT_index_full"</span>, collection<span class="op" style="color: #5E5E5E;">=</span>passages[<span class="st" style="color: #20794D;">"text"</span>])</span></code></pre></div>
</div>
<div class="cell" data-execution_count="198">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">ColBERT_index_path <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">".ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_full"</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="199">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="op" style="color: #5E5E5E;">!</span>du <span class="op" style="color: #5E5E5E;">-</span>sh {ColBERT_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>38M .ragatouille/colbert/indexes/ConditionalQA_ColBERT_index_full</code></pre>
</div>
</div>
<div class="cell" data-execution_count="200">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="op" style="color: #5E5E5E;">!</span>ls {ColBERT_index_path}</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.codes.pt   1.residuals.pt   buckets.pt      ivf.pid.pt
0.metadata.json  2.codes.pt   centroids.pt    metadata.json
0.residuals.pt   2.metadata.json  doclens.0.json  plan.json
1.codes.pt   2.residuals.pt   doclens.1.json
1.metadata.json  avg_residual.pt  doclens.2.json</code></pre>
</div>
</div>
<section id="comparing-metadata" class="level3">
<h3 class="anchored" data-anchor-id="comparing-metadata">Comparing Metadata</h3>
<p>All key metadata parameters are equivalent between the RAGatouille and ColBERT indexes.</p>
<div class="cell" data-execution_count="221">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1">params <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"index_bsize"</span>, <span class="st" style="color: #20794D;">"nbits"</span>, <span class="st" style="color: #20794D;">"kmeans_niters"</span>, <span class="st" style="color: #20794D;">"bsize"</span>, <span class="st" style="color: #20794D;">"dim"</span>, <span class="st" style="color: #20794D;">"rank"</span>, <span class="st" style="color: #20794D;">"gpus"</span>, <span class="st" style="color: #20794D;">"nranks"</span>, <span class="st" style="color: #20794D;">"num_chunks"</span>, <span class="st" style="color: #20794D;">"num_partitions"</span>, <span class="st" style="color: #20794D;">"num_embeddings"</span>, <span class="st" style="color: #20794D;">"avg_doclen"</span>]</span></code></pre></div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="222">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb70-2">    RAG_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="223">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/metadata.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb71-2">    ColBERT_metadata <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="232">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> params: </span>
<span id="cb72-2">    <span class="cf" style="color: #003B4F;">if</span> p <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> [<span class="st" style="color: #20794D;">"num_chunks"</span>, <span class="st" style="color: #20794D;">"num_partitions"</span>, <span class="st" style="color: #20794D;">"num_embeddings"</span>, <span class="st" style="color: #20794D;">"avg_doclen"</span>]: <span class="cf" style="color: #003B4F;">assert</span> RAG_metadata[<span class="st" style="color: #20794D;">'config'</span>][p] <span class="op" style="color: #5E5E5E;">==</span> ColBERT_metadata[<span class="st" style="color: #20794D;">'config'</span>][p], p</span>
<span id="cb72-3">    <span class="cf" style="color: #003B4F;">elif</span> p <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"avg_doclen"</span>: <span class="cf" style="color: #003B4F;">assert</span> (RAG_metadata[p] <span class="op" style="color: #5E5E5E;">-</span> ColBERT_metadata[p]) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="fl" style="color: #AD0000;">1e-7</span></span>
<span id="cb72-4">    <span class="cf" style="color: #003B4F;">else</span>: <span class="cf" style="color: #003B4F;">assert</span> RAG_metadata[p] <span class="op" style="color: #5E5E5E;">==</span> ColBERT_metadata[p], p</span></code></pre></div>
</div>
</section>
<section id="comparing-index-artifacts" class="level3">
<h3 class="anchored" data-anchor-id="comparing-index-artifacts">Comparing Index Artifacts</h3>
<div class="cell" data-execution_count="236">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><span class="kw" style="color: #003B4F;">def</span> _compare_pt(r_path, c_path):</span>
<span id="cb73-2">    r <span class="op" style="color: #5E5E5E;">=</span> torch.load(r_path)</span>
<span id="cb73-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.load(c_path)</span>
<span id="cb73-4">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(r,<span class="bu" style="color: null;">tuple</span>):</span>
<span id="cb73-5">        <span class="cf" style="color: #003B4F;">assert</span> r[<span class="dv" style="color: #AD0000;">0</span>].shape <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">0</span>].shape</span>
<span id="cb73-6">        <span class="cf" style="color: #003B4F;">assert</span> (r[<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">0</span>]).<span class="bu" style="color: null;">float</span>().mean() <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb73-7">        <span class="cf" style="color: #003B4F;">assert</span> (r[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> c[<span class="dv" style="color: #AD0000;">1</span>]).<span class="bu" style="color: null;">float</span>().mean() <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb73-8">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb73-9">        <span class="cf" style="color: #003B4F;">assert</span> r.shape <span class="op" style="color: #5E5E5E;">==</span> c.shape</span>
<span id="cb73-10">        <span class="cf" style="color: #003B4F;">assert</span> (r <span class="op" style="color: #5E5E5E;">==</span> c).<span class="bu" style="color: null;">float</span>().mean() <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="237">
<div class="sourceCode cell-code" id="cb74" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1">files <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb74-2">    <span class="st" style="color: #20794D;">"0.codes.pt"</span>,</span>
<span id="cb74-3">    <span class="st" style="color: #20794D;">"0.residuals.pt"</span>,</span>
<span id="cb74-4">    <span class="st" style="color: #20794D;">"centroids.pt"</span>,</span>
<span id="cb74-5">    <span class="st" style="color: #20794D;">"ivf.pid.pt"</span>,</span>
<span id="cb74-6">    <span class="st" style="color: #20794D;">"buckets.pt"</span>,</span>
<span id="cb74-7">    <span class="st" style="color: #20794D;">"avg_residual.pt"</span>,</span>
<span id="cb74-8">    <span class="st" style="color: #20794D;">"doclens.0.json"</span></span>
<span id="cb74-9">]</span></code></pre></div>
</div>
<div class="cell" data-execution_count="241">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><span class="cf" style="color: #003B4F;">for</span> f <span class="kw" style="color: #003B4F;">in</span> files:</span>
<span id="cb75-2">    <span class="cf" style="color: #003B4F;">if</span> f <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">"doclens.0.json"</span>: </span>
<span id="cb75-3">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{</span>f<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> _f: RAG_doclens <span class="op" style="color: #5E5E5E;">=</span> json.load(_f)</span>
<span id="cb75-4">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{</span>f<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> _f: ColBERT_doclens <span class="op" style="color: #5E5E5E;">=</span> json.load(_f)</span>
<span id="cb75-5">        <span class="cf" style="color: #003B4F;">assert</span> RAG_doclens <span class="op" style="color: #5E5E5E;">==</span> ColBERT_doclens</span>
<span id="cb75-6">    <span class="cf" style="color: #003B4F;">else</span>: _compare_pt(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{</span>f<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/</span><span class="sc" style="color: #5E5E5E;">{</span>f<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
</div>
<p>All index artifacts are equivalent! This further confirms the equivalency of the indexes created by RAGatouille and ColBERT.</p>
</section>
</section>
<section id="comparing-search-results" class="level2">
<h2 class="anchored" data-anchor-id="comparing-search-results">Comparing Search Results</h2>
<p>To reset, I had started this exploration with two questions:</p>
<ol type="1">
<li>For a given document collection and indexing configuration, do RAGatouille and ColBERT produce the same index?</li>
<li>For a given index and search configuration, do RAGatouille and ColBERT retrieve the same passages/Recall@10?</li>
</ol>
<p>The answer to the first question is YES. Let’s move on to answering the second question, starting by searching the RAGatouille index with RAGatouille.</p>
<section id="searching-ragatouille-index-with-ragatouille" class="level3">
<h3 class="anchored" data-anchor-id="searching-ragatouille-index-with-ragatouille">Searching RAGatouille Index with RAGatouille</h3>
<p>I will explicitly set search parameters for RAGatouille, even though they get set based on document collection size in <a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L266"><code>PLAIDModelIndex._load_searcher</code></a>:</p>
<div class="sourceCode" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> force_fast:</span>
<span id="cb76-2">    <span class="va" style="color: #111111;">self</span>.searcher.configure(ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span>)</span>
<span id="cb76-3">    <span class="va" style="color: #111111;">self</span>.searcher.configure(ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb76-4">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">len</span>(<span class="va" style="color: #111111;">self</span>.searcher.collection) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">10000</span>:</span>
<span id="cb76-5">        <span class="va" style="color: #111111;">self</span>.searcher.configure(ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>)</span>
<span id="cb76-6">        <span class="va" style="color: #111111;">self</span>.searcher.configure(centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.4</span>)</span>
<span id="cb76-7">    <span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">len</span>(<span class="va" style="color: #111111;">self</span>.searcher.collection) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="dv" style="color: #AD0000;">100000</span>:</span>
<span id="cb76-8">        <span class="va" style="color: #111111;">self</span>.searcher.configure(ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>)</span>
<span id="cb76-9">        <span class="va" style="color: #111111;">self</span>.searcher.configure(centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.45</span>)</span>
<span id="cb76-10">    <span class="co" style="color: #5E5E5E;"># Otherwise, use defaults for k</span></span>
<span id="cb76-11"><span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb76-12">    <span class="co" style="color: #5E5E5E;"># Use fast settingss</span></span>
<span id="cb76-13">    <span class="va" style="color: #111111;">self</span>.searcher.configure(ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb76-14">    <span class="va" style="color: #111111;">self</span>.searcher.configure(centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>)</span>
<span id="cb76-15">    <span class="va" style="color: #111111;">self</span>.searcher.configure(ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>)</span></code></pre></div>
<div class="cell" data-execution_count="244">
<div class="sourceCode cell-code" id="cb77" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1">RAG.model.config.ncells <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb77-2">RAG.model.config.centroid_score_threshold <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.45</span></span>
<span id="cb77-3">RAG.model.config.ndocs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb77-4">RAG.model.config</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="244">
<pre><code>ColBERTConfig(query_token_id='[unused0]', doc_token_id='[unused1]', query_token='[Q]', doc_token='[D]', ncells=4, centroid_score_threshold=0.45, ndocs=1024, load_index_with_mmap=False, index_path=None, index_bsize=32, nbits=2, kmeans_niters=10, resume=False, pool_factor=1, clustering_mode='hierarchical', protected_tokens=0, similarity='cosine', bsize=32, accumsteps=1, lr=1e-05, maxsteps=15626, save_every=None, warmup=781, warmup_bert=None, relu=False, nway=32, use_ib_negatives=False, reranker=False, distillation_alpha=1.0, ignore_scores=False, model_name='answerdotai/AnswerAI-ColBERTv2.5-small', query_maxlen=32, attend_to_mask_tokens=False, interaction='colbert', dim=96, doc_maxlen=256, mask_punctuation=True, checkpoint='/home/vishal/.cache/huggingface/hub/models--answerdotai--answerai-colbert-small-v1/snapshots/be1703c55532145a844da800eea4c9a692d7e267/', triples='/home/bclavie/colbertv2.5_en/data/msmarco/triplets.jsonl', collection='/home/bclavie/colbertv2.5_en/data/msmarco/collection.tsv', queries='/home/bclavie/colbertv2.5_en/data/msmarco/queries.tsv', index_name=None, overwrite=False, root='.ragatouille/colbert/indexes', experiment='colbert', index_root=None, name='2024-08/07/08.16.20', rank=0, nranks=4, amp=True, gpus=4, avoid_fork_if_possible=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="422">
<div class="sourceCode cell-code" id="cb79" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1">ragatouille_results <span class="op" style="color: #5E5E5E;">=</span> {}</span></code></pre></div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="423">
<div class="sourceCode cell-code" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><span class="cf" style="color: #003B4F;">for</span> q <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb80-2">    results <span class="op" style="color: #5E5E5E;">=</span> RAG.search(q[<span class="st" style="color: #20794D;">'text'</span>], k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb80-3">    ragatouille_results[q[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> {result[<span class="st" style="color: #20794D;">'document_id'</span>]: <span class="bu" style="color: null;">float</span>(result[<span class="st" style="color: #20794D;">'score'</span>]) <span class="cf" style="color: #003B4F;">for</span> result <span class="kw" style="color: #003B4F;">in</span> results}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="424">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">ragatouille_results[<span class="st" style="color: #20794D;">'dev-0'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="424">
<pre><code>{'107-242': 69.9375,
 '496-116': 69.9375,
 '86-28': 69.875,
 '254-4': 69.875,
 '107-103': 69.875,
 '8-67': 69.8125,
 '98-46': 69.8125,
 '8-80': 69.8125,
 '8-116': 69.8125,
 '107-43': 69.8125}</code></pre>
</div>
</div>
<p>The mean Recall@10 for all 271 queries is 0.29.</p>
<div class="cell" data-execution_count="429">
<div class="sourceCode cell-code" id="cb83" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1">qrels <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb83-2"><span class="cf" style="color: #003B4F;">for</span> qrel_row <span class="kw" style="color: #003B4F;">in</span> qrels_rows:</span>
<span id="cb83-3">    qid <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"query_id"</span>]</span>
<span id="cb83-4">    pid <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"corpus_id"</span>]</span>
<span id="cb83-5">    rel <span class="op" style="color: #5E5E5E;">=</span> qrel_row[<span class="st" style="color: #20794D;">"score"</span>]</span>
<span id="cb83-6">    qrels.setdefault(qid, {})</span>
<span id="cb83-7">    qrels[qid][pid] <span class="op" style="color: #5E5E5E;">=</span> rel</span></code></pre></div>
</div>
<div class="cell" data-execution_count="430">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1">evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb84-2">metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(ragatouille_results)</span>
<span id="cb84-3"><span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb84-4"></span>
<span id="cb84-5">mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb84-6">mean_recall</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="430">
<pre><code>0.2855810510889169</code></pre>
</div>
</div>
</section>
<section id="searching-the-colbert-index-with-colbert" class="level3">
<h3 class="anchored" data-anchor-id="searching-the-colbert-index-with-colbert">Searching the ColBERT Index with ColBERT</h3>
<p>Next, I’ll search the ColBERT index with ColBERT, setting the same configuration values as RAGatouille.</p>
<div class="cell" data-execution_count="297">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1">RAG.model.config.ncells, <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb86-2">RAG.model.config.centroid_score_threshold, <span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb86-3">RAG.model.config.ndocs</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="297">
<pre><code>(4, 0.45, 1024)</code></pre>
</div>
</div>
<p>ColBERT expects the queries to be structured as a dictionary, so I’ll prepare that accordingly:</p>
<div class="cell" data-execution_count="425">
<div class="sourceCode cell-code" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1">queries_dict <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb88-2"><span class="cf" style="color: #003B4F;">for</span> item <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb88-3">    queries_dict[item[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> item[<span class="st" style="color: #20794D;">'text'</span>]</span>
<span id="cb88-4"></span>
<span id="cb88-5"><span class="bu" style="color: null;">len</span>(queries_dict)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="425">
<pre><code>271</code></pre>
</div>
</div>
<p>I was posting on Twitter about how I wasn’t getting the same search results when using RAGatouille and vanilla ColBERT given the same index. <a href="https://ben.clavie.eu/">Benjamin Clavie</a>, the author of RAGatouille, kindly took some time to explain a core difference in how RAGatouille and ColBERT process queries:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Oh that'll be because ragatouille has a policy to never truncate queries so it updates the querylen to be <em>at least</em> the actual query length (further tests show it should be querylen + 8 at least, to get better augmentation). Your colbert (stanford) config is truncating to 32…
</p>
— Ben Clavié (<span class="citation" data-cites="bclavie">@bclavie</span>) <a href="https://twitter.com/bclavie/status/1921056639739678751?ref_src=twsrc%5Etfw">May 10, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>As was shared in his tweet, <a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L298">RAGatouille uses a larger maximum query length than ColBERT</a>. ColBERT uses a default of 32. So to replicate the same scores (and therefore the same top-k retrieved passages) I needed to mimic RAGatouille’s query length maximum.</p>
<p>Note that ColBERT doesn’t store original passage <code>_id</code>s like RAGatouille does, so I have to extract it from the original <code>passages</code> with <code>passages[idx]['_id']</code>.</p>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb90" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1">current_dir <span class="op" style="color: #5E5E5E;">=</span> os.path.abspath(<span class="st" style="color: #20794D;">"."</span>)</span>
<span id="cb90-2">index_root <span class="op" style="color: #5E5E5E;">=</span> os.path.join(current_dir, <span class="st" style="color: #20794D;">".ragatouille"</span>, <span class="st" style="color: #20794D;">"colbert"</span>, <span class="st" style="color: #20794D;">"indexes"</span>)</span>
<span id="cb90-3">colbert_results <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb90-4"></span>
<span id="cb90-5"><span class="cf" style="color: #003B4F;">for</span> q <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb90-6">    query_length <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(<span class="bu" style="color: null;">len</span>(q[<span class="st" style="color: #20794D;">'text'</span>].split(<span class="st" style="color: #20794D;">" "</span>)) <span class="op" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">1.35</span>) <span class="co" style="color: #5E5E5E;"># this lines comes from RAGatouille</span></span>
<span id="cb90-7">    <span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb90-8">        searcher <span class="op" style="color: #5E5E5E;">=</span> Searcher(</span>
<span id="cb90-9">            index<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ConditionalQA_ColBERT_index_full"</span>,</span>
<span id="cb90-10">            index_root<span class="op" style="color: #5E5E5E;">=</span>index_root,  </span>
<span id="cb90-11">            config<span class="op" style="color: #5E5E5E;">=</span>ColBERTConfig(</span>
<span id="cb90-12">                ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb90-13">                centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.45</span>,</span>
<span id="cb90-14">                ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span>,</span>
<span id="cb90-15">                query_maxlen<span class="op" style="color: #5E5E5E;">=</span>query_length</span>
<span id="cb90-16">            )</span>
<span id="cb90-17">        )</span>
<span id="cb90-18">    </span>
<span id="cb90-19">        ranking <span class="op" style="color: #5E5E5E;">=</span> searcher.search(q[<span class="st" style="color: #20794D;">'text'</span>], k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb90-20">        colbert_results[q[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> {passages[idx][<span class="st" style="color: #20794D;">'_id'</span>]: score <span class="cf" style="color: #003B4F;">for</span> idx, score <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">list</span>(<span class="bu" style="color: null;">zip</span>(ranking[<span class="dv" style="color: #AD0000;">0</span>], ranking[<span class="dv" style="color: #AD0000;">2</span>]))}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="427">
<div class="sourceCode cell-code" id="cb91" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1">evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb91-2">metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(colbert_results)</span>
<span id="cb91-3"><span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb91-4"></span>
<span id="cb91-5">mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb91-6">mean_recall</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="427">
<pre><code>0.2855810510889169</code></pre>
</div>
</div>
<p>With the maximum query length adjusted, ColBERT yields the same Recall@10 as RAGatouille! This makes sense because as Benjamin said in another tweet reply:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
It's most likely down to the default search settings in ragatouille being a bit more aggressive, so you end up with better results. If you change ncells/score_thresh/ndocs to more aggressive values I reckon the colbert library would match it? All ragatouille does under the hood is wrap things with strong defaults/abstractions 😄
</p>
— Ben Clavié (<span class="citation" data-cites="bclavie">@bclavie</span>) <a href="https://twitter.com/bclavie/status/1921052397314732447?ref_src=twsrc%5Etfw">May 10, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>While the exact same recall is a good check, I’ll double check that for each query, the retrieved passage IDs and scores are identical between RAGatouille and ColBERT.</p>
<div class="cell" data-execution_count="428">
<div class="sourceCode cell-code" id="cb93" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> colbert_results.keys():</span>
<span id="cb93-2">    <span class="cf" style="color: #003B4F;">for</span> pid, score <span class="kw" style="color: #003B4F;">in</span> colbert_results[i].items():</span>
<span id="cb93-3">        <span class="cf" style="color: #003B4F;">assert</span> ragatouille_results[i][pid] <span class="op" style="color: #5E5E5E;">==</span> score</span></code></pre></div>
</div>
</section>
<section id="searching-ragatouille-index-with-colbert-and-vice-versa" class="level3">
<h3 class="anchored" data-anchor-id="searching-ragatouille-index-with-colbert-and-vice-versa">Searching RAGatouille Index with ColBERT (and vice versa)</h3>
<p>As a final check of consistency, I’ll search the RAGatouille index with ColBERT and search the ColBERT index with RAGatouille and confirm that they yield the same retrieved passages and Recall@10.</p>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1">current_dir <span class="op" style="color: #5E5E5E;">=</span> os.path.abspath(<span class="st" style="color: #20794D;">"."</span>)</span>
<span id="cb94-2">index_root <span class="op" style="color: #5E5E5E;">=</span> os.path.join(current_dir, <span class="st" style="color: #20794D;">".ragatouille"</span>, <span class="st" style="color: #20794D;">"colbert"</span>, <span class="st" style="color: #20794D;">"indexes"</span>)</span>
<span id="cb94-3">colbert_results2 <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb94-4"></span>
<span id="cb94-5"><span class="cf" style="color: #003B4F;">for</span> q <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb94-6">    query_length <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(<span class="bu" style="color: null;">len</span>(q[<span class="st" style="color: #20794D;">'text'</span>].split(<span class="st" style="color: #20794D;">" "</span>)) <span class="op" style="color: #5E5E5E;">*</span> <span class="fl" style="color: #AD0000;">1.35</span>)</span>
<span id="cb94-7">    <span class="cf" style="color: #003B4F;">with</span> Run().context(RunConfig(nranks<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)):</span>
<span id="cb94-8">        searcher <span class="op" style="color: #5E5E5E;">=</span> Searcher(</span>
<span id="cb94-9">            index<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"ConditionalQA_RAGatouille_index_full"</span>,</span>
<span id="cb94-10">            index_root<span class="op" style="color: #5E5E5E;">=</span>index_root,  </span>
<span id="cb94-11">            config<span class="op" style="color: #5E5E5E;">=</span>ColBERTConfig(</span>
<span id="cb94-12">                ncells<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>,</span>
<span id="cb94-13">                centroid_score_threshold<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.45</span>,</span>
<span id="cb94-14">                ndocs<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span>,</span>
<span id="cb94-15">                query_maxlen<span class="op" style="color: #5E5E5E;">=</span>query_length</span>
<span id="cb94-16">            )</span>
<span id="cb94-17">        )</span>
<span id="cb94-18">    </span>
<span id="cb94-19">        ranking <span class="op" style="color: #5E5E5E;">=</span> searcher.search(q[<span class="st" style="color: #20794D;">'text'</span>], k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb94-20">        colbert_results2[q[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> {passages[idx][<span class="st" style="color: #20794D;">'_id'</span>]: score <span class="cf" style="color: #003B4F;">for</span> idx, score <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">list</span>(<span class="bu" style="color: null;">zip</span>(ranking[<span class="dv" style="color: #AD0000;">0</span>], ranking[<span class="dv" style="color: #AD0000;">2</span>]))}</span></code></pre></div>
</div>
<p>We get the same results as searching the ColBERT index with ColBERT! This again further proves that these two frameworks produce the same indexes (which is to be expected).</p>
<div class="cell" data-execution_count="432">
<div class="sourceCode cell-code" id="cb95" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> colbert_results.keys():</span>
<span id="cb95-2">    <span class="cf" style="color: #003B4F;">for</span> pid, score <span class="kw" style="color: #003B4F;">in</span> colbert_results[i].items():</span>
<span id="cb95-3">        <span class="cf" style="color: #003B4F;">assert</span> colbert_results2[i][pid] <span class="op" style="color: #5E5E5E;">==</span> score</span></code></pre></div>
</div>
<div class="cell" data-execution_count="433">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb96-2">metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(colbert_results2)</span>
<span id="cb96-3"><span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb96-4"></span>
<span id="cb96-5">mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb96-6">mean_recall</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="433">
<pre><code>0.2855810510889169</code></pre>
</div>
</div>
<p>Finally, as the last piece of this exercise, I’ll search the ColBERT index with RAGatouille and see if I get the same result. I certainly expect to!</p>
</section>
<section id="searching-colbert-index-with-ragatouille" class="level3">
<h3 class="anchored" data-anchor-id="searching-colbert-index-with-ragatouille">Searching ColBERT Index with RAGatouille</h3>
<p>RAGatouille creates two files (collection.json and pid_docid_map.json) which ColBERT does not, so we have to create them manually for RAGatouille to search the ColBERT Index.</p>
<p>collection.json is just a list of the document collection text.</p>
<div class="cell" data-execution_count="434">
<div class="sourceCode cell-code" id="cb98" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/collection.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb98-2">    RAG_collection <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="435">
<div class="sourceCode cell-code" id="cb99" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><span class="bu" style="color: null;">len</span>(RAG_collection)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="435">
<pre><code>69199</code></pre>
</div>
</div>
<div class="cell" data-execution_count="436">
<div class="sourceCode cell-code" id="cb101" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1">RAG_collection[:<span class="dv" style="color: #AD0000;">5</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="436">
<pre><code>['Overview',
 'You can only make a claim for Child Tax Credit if you already get Working Tax Credit.',
 'If you cannot apply for Child Tax Credit, you can apply for Universal Credit instead.',
 'You might be able to apply for Pension Credit if you and your partner are State Pension age or over.',
 'What you’ll get']</code></pre>
</div>
</div>
<p>pid_docid_map.json is a dictionary where the keys are the index in the collection and the values are the dataset’s defined <code>_id</code> string.</p>
<div class="cell" data-execution_count="437">
<div class="sourceCode cell-code" id="cb103" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>RAG_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/pid_docid_map.json"</span>, <span class="st" style="color: #20794D;">'r'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb103-2">    RAG_pid_docid_map <span class="op" style="color: #5E5E5E;">=</span> json.load(f)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="438">
<div class="sourceCode cell-code" id="cb104" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><span class="bu" style="color: null;">list</span>(RAG_pid_docid_map.items())[<span class="dv" style="color: #AD0000;">0</span>], <span class="bu" style="color: null;">list</span>(RAG_pid_docid_map.items())[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="438">
<pre><code>(('0', '0-0'), ('69198', '651-91'))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="439">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1">passages[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="439">
<pre><code>{'_id': '651-91',
 'text': 'Trade union reps can be on picket lines at different workplaces if they’re responsible for organising workers in those workplaces.',
 'title': 'Taking part in industrial action and strikes',
 'doc_id': '651',
 'paragraph_no': 91,
 'total_paragraphs': 92,
 'is_candidate': True}</code></pre>
</div>
</div>
<p>Saving the collection as a JSON is simple enough, I just dump <code>passages['text']</code> into a JSON file.</p>
<div class="cell" data-execution_count="289">
<div class="sourceCode cell-code" id="cb108" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1">srsly.write_json(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/collection.json"</span>, passages[<span class="st" style="color: #20794D;">'text'</span>])</span></code></pre></div>
</div>
<p>Creating pid_docid_map.json is also quite straightforward. I map from the index of the passage item to its <code>_id</code>.</p>
<div class="cell" data-execution_count="440">
<div class="sourceCode cell-code" id="cb109" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1">pid_docid_map <span class="op" style="color: #5E5E5E;">=</span> {<span class="bu" style="color: null;">str</span>(i): p[<span class="st" style="color: #20794D;">'_id'</span>] <span class="cf" style="color: #003B4F;">for</span> i,p <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(passages)}</span></code></pre></div>
</div>
<div class="cell" data-execution_count="441">
<div class="sourceCode cell-code" id="cb110" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><span class="bu" style="color: null;">list</span>(pid_docid_map.items())[<span class="dv" style="color: #AD0000;">0</span>], <span class="bu" style="color: null;">list</span>(pid_docid_map.items())[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="441">
<pre><code>(('0', '0-0'), ('69198', '651-91'))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="287">
<div class="sourceCode cell-code" id="cb112" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1">srsly.write_json(<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>ColBERT_index_path<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">/pid_docid_map.json"</span>, pid_docid_map)</span></code></pre></div>
</div>
<p>Let’s make sure these match the RAGatouille-built artifacts:</p>
<div class="cell" data-execution_count="442">
<div class="sourceCode cell-code" id="cb113" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><span class="cf" style="color: #003B4F;">for</span> i, _id <span class="kw" style="color: #003B4F;">in</span> RAG_pid_docid_map.items(): <span class="cf" style="color: #003B4F;">assert</span> _id <span class="op" style="color: #5E5E5E;">==</span> pid_docid_map[i]</span>
<span id="cb113-2"><span class="cf" style="color: #003B4F;">for</span> i, _id <span class="kw" style="color: #003B4F;">in</span> pid_docid_map.items(): <span class="cf" style="color: #003B4F;">assert</span> _id <span class="op" style="color: #5E5E5E;">==</span> RAG_pid_docid_map[i]</span></code></pre></div>
</div>
<p>With those two files created, I can now create a <code>RAGPretrainedModel</code> object <code>from_index</code> using the ColBERT index.</p>
<div class="cell" data-execution_count="443">
<div class="sourceCode cell-code" id="cb114" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1">RAG2 <span class="op" style="color: #5E5E5E;">=</span> RAGPretrainedModel.from_index(ColBERT_index_path)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Constructing default index configuration for index `None` as it does not contain RAGatouille specific metadata.</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true">
<div class="sourceCode cell-code" id="cb116" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1">RAG2.model.config.ncells <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">4</span></span>
<span id="cb116-2">RAG2.model.config.centroid_score_threshold <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.45</span></span>
<span id="cb116-3">RAG2.model.config.ndocs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb116-4"></span>
<span id="cb116-5">ragatouille_results2 <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb116-6"></span>
<span id="cb116-7"></span>
<span id="cb116-8"><span class="cf" style="color: #003B4F;">for</span> q <span class="kw" style="color: #003B4F;">in</span> queries:</span>
<span id="cb116-9">    results <span class="op" style="color: #5E5E5E;">=</span> RAG2.search(q[<span class="st" style="color: #20794D;">'text'</span>], k<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb116-10">    ragatouille_results2[q[<span class="st" style="color: #20794D;">'_id'</span>]] <span class="op" style="color: #5E5E5E;">=</span> {result[<span class="st" style="color: #20794D;">'document_id'</span>]: <span class="bu" style="color: null;">float</span>(result[<span class="st" style="color: #20794D;">'score'</span>]) <span class="cf" style="color: #003B4F;">for</span> result <span class="kw" style="color: #003B4F;">in</span> results}</span></code></pre></div>
</div>
<p>We get the same results as searching the RAGatouille index with RAGatouille, searching the ColBERT index with ColBERT and searching the RAGatouille index with ColBERT!</p>
<div class="cell" data-execution_count="445">
<div class="sourceCode cell-code" id="cb117" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> colbert_results.keys():</span>
<span id="cb117-2">    <span class="cf" style="color: #003B4F;">for</span> pid, score <span class="kw" style="color: #003B4F;">in</span> colbert_results[i].items():</span>
<span id="cb117-3">        <span class="cf" style="color: #003B4F;">assert</span> ragatouille_results2[i][pid] <span class="op" style="color: #5E5E5E;">==</span> score</span></code></pre></div>
</div>
<div class="cell" data-execution_count="446">
<div class="sourceCode cell-code" id="cb118" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1">evaluator <span class="op" style="color: #5E5E5E;">=</span> pytrec_eval.RelevanceEvaluator(qrels, {<span class="st" style="color: #20794D;">'recall.10'</span>})</span>
<span id="cb118-2">metrics <span class="op" style="color: #5E5E5E;">=</span> evaluator.evaluate(ragatouille_results2)</span>
<span id="cb118-3"><span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(metrics) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(<span class="bu" style="color: null;">set</span>(qrels_rows[<span class="st" style="color: #20794D;">"query_id"</span>]))</span>
<span id="cb118-4"></span>
<span id="cb118-5">mean_recall <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sum</span>(metrics[qid][<span class="st" style="color: #20794D;">'recall_10'</span>] <span class="cf" style="color: #003B4F;">for</span> qid <span class="kw" style="color: #003B4F;">in</span> metrics.keys()) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(metrics)</span>
<span id="cb118-6">mean_recall</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="446">
<pre><code>0.2855810510889169</code></pre>
</div>
</div>
</section>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>Every interaction I’ve had with RAGatouille and ColBERT has been an awesome learning experience. I feel like inspecting their behavior and artifacts as left me with a better understanding of information retrieval in general. One small learning that I left out: ColBERT uses FAISS for k-means clustering while for small document collections (such as my initial 1k subset) RAGatouille uses a PyTorch implementation. This difference, even though all relevant configuration parameters were equal, resulted in different index artifacts. There was only about a 15% overlap between the <code>centroids.pt</code> tensors of the resulting RAGatouille and ColBERT indexes.</p>
<p>Another piece of motivation for me is that I needed to use both RAGatouille and ColBERT for indexing the full set of UKPLab/DAPR document collections, as ColBERT was able to index the larger collections (6M+) without crashing the kernel, while RAGatouille was not. In some initial experiments I was getting different mean Recall@10 values when using RAGatouille versus when using ColBERT (because I hadn’t incorporated the max query length code and probably had different configs). So I felt like this was a good opportunity, once and for all, to answer the two questions I listed at the start of this notebook:</p>
<ol type="1">
<li>For a given document collection and indexing configuration, do RAGatouille and ColBERT produce the same index?</li>
<li>For a given index and search configuration, do RAGatouille and ColBERT retrieve the same passages/Recall@10?</li>
</ol>
<p>The answer for both, is a resounding yes! With this knowledge in my belt, I can now move forward with indexing and searching with either library as I please.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>information retrieval</category>
  <category>RAGatouille</category>
  <category>ColBERT</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-10-RAGatouille-ColBERT-Comparisons/index.html</guid>
  <pubDate>Sat, 10 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TIL: Resolving RAGatouille OOM Error and faiss-gpu Warning</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-08-TIL-RAGatouille/index.html</link>
  <description><![CDATA[ 



<p>I’m in the process of indexing the UKPLab/DAPR datasets, which span in size from ~70k to ~32M documents. Using a RTX3090, I ran into an OOM error (during search) and a warning stating that faiss-cpu was being used instead of faiss-gpu, causing the indexing process to take longer.</p>
<p>I found <a href="https://github.com/AnswerDotAI/RAGatouille/issues/177">this RAGatouille GitHub issue</a> which recommended lowering the <code>batch_size</code> in ColBERT’s <a href="https://github.com/stanford-futuredata/ColBERT/blob/8627585ad290c21720eaa54e325e7c8c301d15f6/colbert/search/index_storage.py#L121"><code>IndexScorer.score_pids</code> method</a>. I made that change (from 2^20 to 2^16) and that resolved the OOM error, at least for the 2.68M document collection (NaturalQuestions).</p>
<p>When I was using Google Colab GPUs, the following install commands correctly installed faiss-gpu after installing RAGatouille:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">pip uninstall <span class="op" style="color: #5E5E5E;">-</span>y faiss<span class="op" style="color: #5E5E5E;">-</span>cpu</span>
<span id="cb1-2">pip install faiss<span class="op" style="color: #5E5E5E;">-</span>gpu<span class="op" style="color: #5E5E5E;">-</span>cu12</span></code></pre></div>
<p>Using an RTX3090 (not on Colab), this was not correctly installing faiss-gpu, leading to the following RAGatouille warning during indexing, and as a result, using the CPU for indexing (which eventually crashed the kernel):</p>
<pre><code>________________________________________________________________________________
WARNING! You have a GPU available, but only `faiss-cpu` is currently installed.
This means that indexing will be slow. To make use of your GPU
Please install `faiss-gpu` by running:
pip uninstall --y faiss-cpu &amp; pip install faiss-gpu
________________________________________________________________________________</code></pre>
<p>This warning is thrown in RAGatouille’s <a href="https://github.com/AnswerDotAI/RAGatouille/blob/2bd4d2ed01c847854be78704a012f9ab35d679b2/ragatouille/models/index.py#L226"><code>PLAIDModelIndex.build</code></a> if <code>hasattr(faiss, "StandardGpuResources")</code> is <code>False</code>.</p>
<p>Looking at the <a href="https://github.com/facebookresearch/faiss/tree/main#:~:text=faiss%2Dcpu%2C-,faiss%2Dgpu,-and%20faiss%2Dgpu">faiss repo</a>, they recommend using conda for installation. I ran <code>conda install pytorch::faiss-gpu</code>, restarted the kernel, confirmed that <code>hasattr(faiss, "StandardGpuResources")</code> returns <code>True</code> and was successfully able to circumvent that warning. As a result, RAGatouille was able to use faiss-gpu and it was able to index 2M document.</p>
<p>It’s still TBD if this allows me to finish indexing all of my datasets (especially the 13M and 32M ones).</p>
<p>In a conversation with Claude, I outlined a few different scenarios that I may have to (get to) pursue:</p>
<blockquote class="blockquote">
<p>Since both repos are open sourced, I can fork them (which I have) and add print statements/modify code to debug as needed.</p>
<p>I am running into a couple issues that I’m trying to resolve. I don’t want you to suggest any code yet, let’s think this through.</p>
<ol type="1">
<li>When performing retrieval on a 2.6M document collection on an RTX3090, RAGatouille.search throws an OOM error.</li>
<li>So I chose to run retrieval on the RAGatouille index using vanilla ColBERT and it did not run out of memory.</li>
<li>However, the retrieval results are <em>significantly</em> different between ColBERT and RAGatouille.</li>
</ol>
<p>Each of these gives me a uniquely interesting direction to pursue:</p>
<ol type="1">
<li>Why does RAGatouille throw the OOM error? 2.6M documents (index with 8.5GB disk space) is not small, but not terribly large. There’s an issue open in RAGatouille where they note that changing batch_size in score_pids in IndexScorer resolves an OOM error during search. I want to give this a try!</li>
<li>Why does ColBERT not run out of memory? But RAGatouille does?</li>
<li>Why are the retrieval results between RAGatouille and ColBERT different? The RAGatouille documentation says the following, which leads me to believe they should yield the same results:</li>
</ol>
<p>If you’d like to use more than RAGatouille, ColBERT has a growing number of integrations, and they all fully support models trained or fine-tuned with RAGatouille! The official ColBERT implementation has a built-in query server (using Flask), which you can easily query via API requests and does support indexes generated with RAGatouille! This should be enough for most small applications, so long as you can persist the index on disk.</p>
<p>Each of these explorations are fascinating, and I think I’m going to pursue each one.</p>
<ol type="1">
<li>resolving the RAGatouille OOM error would solve my immediate problem. ideally I tackle this first.</li>
<li>Understanding memory usage between RAGatouille and ColBERT has been an ongoing interest of mine. I have memory profiled both before during indexing, but not during search. This would be a very interesting research task.</li>
<li>Debugging the searching/scoring difference would be probably the hardest task. I would likely have to trace down all function calls, checking intermedite values, comparing them between the two frameworks. Absolutely fascinating and would learn a ton. Would also be a significant achievement to resolve the discrepancy (maybe something in the Config? Maybe something more fundamental?)</li>
</ol>
</blockquote>
<p>TBD on whether I pursue points 2 and 3.</p>



 ]]></description>
  <category>information retrieval</category>
  <category>deep learning</category>
  <category>RAGatouille</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-08-TIL-RAGatouille/index.html</guid>
  <pubDate>Thu, 08 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>DataInspector: Inspecting input_ids Token Statistics in LLM-Foundry with packing_ratio=5.0</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-08-DataInspector/index.html</link>
  <description><![CDATA[ 






 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-08-DataInspector/index.html</guid>
  <pubDate>Thu, 08 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Understanding Sequence Packing - Initial Musings</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-04-Understanding-Sequence-Packing/index.html</link>
  <description><![CDATA[ 



<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<div class="cell">
<details>
<summary>Show pip installs and imports</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="op" style="color: #5E5E5E;">!</span>pip install <span class="op" style="color: #5E5E5E;">-</span>qq <span class="op" style="color: #5E5E5E;">-</span>U flash<span class="op" style="color: #5E5E5E;">-</span>attn <span class="op" style="color: #5E5E5E;">--</span>no<span class="op" style="color: #5E5E5E;">-</span>build<span class="op" style="color: #5E5E5E;">-</span>isolation</span>
<span id="cb1-2"><span class="op" style="color: #5E5E5E;">!</span>pip uninstall transformers <span class="op" style="color: #5E5E5E;">-</span>y</span>
<span id="cb1-3"><span class="op" style="color: #5E5E5E;">!</span>pip install git<span class="op" style="color: #5E5E5E;">+</span>https:<span class="op" style="color: #5E5E5E;">//</span>github.com<span class="op" style="color: #5E5E5E;">/</span>vishalbakshi<span class="op" style="color: #5E5E5E;">/</span>transformers.git <span class="op" style="color: #5E5E5E;">-</span>qq</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoModelForCausalLM, AutoTokenizer</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> inspect</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">import</span> torch.nn.functional <span class="im" style="color: #00769E;">as</span> F</span>
<span id="cb1-9"></span>
<span id="cb1-10">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span></span>
<span id="cb1-11"></span>
<span id="cb1-12">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(</span>
<span id="cb1-13">    model_name,</span>
<span id="cb1-14">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb1-15">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span>torch.bfloat16,</span>
<span id="cb1-16">    device_map<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"auto"</span>)</span>
<span id="cb1-17"></span>
<span id="cb1-18">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(model_name)</span></code></pre></div>
</details>
</div>
</section>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this blog post, I’m walking through <code>transformers</code> code to start exploring functionality between sequence packing and Flash Attention. I’m new to both concepts, so this is purely an exploratory exercise.</p>
<p>To assist my exploration, I’ve forked the Transformers library and added print statements at key junctures related to sequence packing and FA2. Referencing the original repo here’s where I’ve inserted print statements:</p>
<ul>
<li>Right after the function signature for <code>flash_attention_forward</code> in <a href="https://github.com/huggingface/transformers/blob/2932f318a20d9e54cc7aea052e040164d85de7d6/src/transformers/integrations/flash_attention.py#L22">src/transformers/integrations/flash_attention.py</a> (which is called from inside <code>model.model.layers[0].self_attn.forward</code>).</li>
</ul>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">=== FLASH_ATTENTION_FORWARD ENTRY ==="</span>)</span>
<span id="cb2-2"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"kwargs received: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">list</span>(kwargs.keys())<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<ul>
<li>Right after the function signature/docstring for <code>_flash_attention_forward</code> in <a href="https://github.com/huggingface/transformers/blob/2932f318a20d9e54cc7aea052e040164d85de7d6/src/transformers/modeling_flash_attention_utils.py#L324">src/transformers/modeling_flash_attention_utils.py</a>:</li>
</ul>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">=== _FLASH_ATTENTION_FORWARD ENTRY ==="</span>)</span>
<span id="cb3-2"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"kwargs received: </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">list</span>(kwargs.keys())<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;"> attention_mask"</span>)</span>
<span id="cb3-5"><span class="bu" style="color: null;">print</span>(attention_mask)</span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;"> position_ids"</span>)</span>
<span id="cb3-8"><span class="bu" style="color: null;">print</span>(position_ids)</span></code></pre></div>
<p>In the same file, later on:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Contains at least one padding token in the sequence</span></span>
<span id="cb4-2"><span class="cf" style="color: #003B4F;">if</span> attention_mask <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-3">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"attention_mask is not None"</span>)</span>
<span id="cb4-4">    ...</span></code></pre></div>
<p>and later on further in the <code>_flash_attention_forward</code> function definition:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="cf" style="color: #003B4F;">elif</span> position_ids <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> (</span>
<span id="cb5-2">    max_length_q <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> (query_length <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="kw" style="color: #003B4F;">and</span> <span class="kw" style="color: #003B4F;">not</span> (torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">&gt;=</span> <span class="dv" style="color: #AD0000;">0</span>).<span class="bu" style="color: null;">all</span>())</span>
<span id="cb5-3">):</span>
<span id="cb5-4">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"position_ids is not None and max_length_q check"</span>)</span>
<span id="cb5-5">    batch_size <span class="op" style="color: #5E5E5E;">=</span> query_states.size(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb5-6"></span>
<span id="cb5-7">    <span class="cf" style="color: #003B4F;">if</span> cu_seq_lens_q <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> cu_seq_lens_k <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb5-8">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"cu_seq_lens_q is None: </span><span class="sc" style="color: #5E5E5E;">{</span>cu_seq_lens_q <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb5-9">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"cu_seq_lens_k is None: </span><span class="sc" style="color: #5E5E5E;">{</span>cu_seq_lens_q <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb5-10">        query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb5-11">            prepare_fa2_from_position_ids(query_states, key_states, value_states, position_ids)</span>
<span id="cb5-12">        )</span>
<span id="cb5-13"></span>
<span id="cb5-14">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;"> cu_seq_lens"</span>)</span>
<span id="cb5-15">        <span class="bu" style="color: null;">print</span>(cu_seq_lens)</span>
<span id="cb5-16">        cu_seq_lens_q, cu_seq_lens_k <span class="op" style="color: #5E5E5E;">=</span> cu_seq_lens</span>
<span id="cb5-17">        max_length_q, max_length_k <span class="op" style="color: #5E5E5E;">=</span> max_seq_lens</span>
<span id="cb5-18"></span>
<span id="cb5-19">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb5-20">        ...</span></code></pre></div>
<p>I originally identified these functions by using the <code>inspect</code> library, e.g.:</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="bu" style="color: null;">print</span>(inspect.getsource(model.model.layers[<span class="dv" style="color: #AD0000;">0</span>].self_attn.forward))</span></code></pre></div>
<p>The goal of these print functions initially was to understand how <code>cu_seqlens</code> is utilized (if at all) and then after realizing it wasn’t being used, my goal became to understand which function form <code>flash_attn</code> is being used: <code>flash_attn_func</code> or <code>flash_attn_varlen_func</code>?</p>
</section>
<section id="initial-example-passing-in-input_ids-cu_seqlens-and-max_seqlen-to-the-smollm2-135m-forward-pass" class="level2">
<h2 class="anchored" data-anchor-id="initial-example-passing-in-input_ids-cu_seqlens-and-max_seqlen-to-the-smollm2-135m-forward-pass">Initial Example: Passing in <code>input_ids</code>, <code>cu_seqlens</code> and <code>max_seqlen</code> to the SmolLM2-135M Forward Pass</h2>
<p>At first, based on a Claude-generated example, I passed in the following fake input data.</p>
<div class="cell" data-outputid="6bc4c7d5-d953-4f4b-911c-b1b2936fbb5c" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb7-2">test_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb7-3">    <span class="st" style="color: #20794D;">'input_ids'</span>: torch.randint(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">10</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">10</span>)).to(<span class="st" style="color: #20794D;">"cuda"</span>),</span>
<span id="cb7-4">    <span class="st" style="color: #20794D;">'cu_seqlens'</span>: [torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32).to(<span class="st" style="color: #20794D;">"cuda"</span>)],</span>
<span id="cb7-5">    <span class="st" style="color: #20794D;">'max_seqlen'</span>: [<span class="dv" style="color: #AD0000;">10</span>]</span>
<span id="cb7-6">}</span>
<span id="cb7-7">test_params</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>{'input_ids': tensor([[7, 6, 8, 5, 1, 3, 8, 6, 5, 3]], device='cuda:0'),
 'cu_seqlens': [tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32)],
 'max_seqlen': [10]}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb9-2"><span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): output <span class="op" style="color: #5E5E5E;">=</span> model(<span class="op" style="color: #5E5E5E;">**</span>test_params)</span></code></pre></div>
</div>
<p>The following was printed out for each attention mechanism call in each of the model’s 30 layers:</p>
<pre><code>=== FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['position_ids', 'output_attentions', 'use_cache', 'cu_seqlens', 'max_seqlen']

=== _FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['output_attentions', 'use_cache', 'cu_seqlens', 'max_seqlen']

 attention_mask
None

 position_ids
tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]], device='cuda:0')
flash_attn_func is called
flash_kwargs received: ['deterministic']</code></pre>
<p>I was surprised to see that <code>flash_attn_func</code> was called, because IIUC that doesn’t handle sequence packed inputs. Looking at <a href="https://github.com/Dao-AILab/flash-attention/blob/fd2fc9d85c8e54e5c20436465bca709bc1a6c5a1/hopper/flash_attn_interface.py#L501">its function signature</a>, there’s no <code>cu_seqlens</code> or similar parameter:</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="kw" style="color: #003B4F;">def</span> flash_attn_func(</span>
<span id="cb11-2">    q,</span>
<span id="cb11-3">    k,</span>
<span id="cb11-4">    v,</span>
<span id="cb11-5">    softmax_scale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb11-6">    causal<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb11-7">    qv<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb11-8">    q_descale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, k_descale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, v_descale<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb11-9">    window_size<span class="op" style="color: #5E5E5E;">=</span>(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>),</span>
<span id="cb11-10">    attention_chunk<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb11-11">    softcap<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.0</span>,</span>
<span id="cb11-12">    num_splits<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb11-13">    pack_gqa<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb11-14">    deterministic<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb11-15">    sm_margin<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb11-16">)</span></code></pre></div>
<p>Additionally, <code>position_ids</code> is defined even though I didn’t pass it in. IIUC, that’s done in the model’s forward pass with the line:</p>
<div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="cf" style="color: #003B4F;">if</span> position_ids <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb12-2">    position_ids <span class="op" style="color: #5E5E5E;">=</span> cache_position.unsqueeze(<span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<p>Where <code>cache_position</code> is defined earlier in that forward pass. This can be observed by running:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">forward_method <span class="op" style="color: #5E5E5E;">=</span> inspect.getsource(model.model.forward)</span>
<span id="cb13-2"><span class="bu" style="color: null;">print</span>(forward_method)</span></code></pre></div>
</section>
<section id="second-attempt-passing-in-position_ids-to-the-forward-pass-as-well" class="level2">
<h2 class="anchored" data-anchor-id="second-attempt-passing-in-position_ids-to-the-forward-pass-as-well">Second Attempt: Passing in <code>position_ids</code> to the Forward Pass as Well</h2>
<p>Claude helped me understand that what triggers the function call of <code>flash_attn_varlen_func</code> is the following conditional in <a href="https://github.com/huggingface/transformers/blob/2932f318a20d9e54cc7aea052e040164d85de7d6/src/transformers/modeling_flash_attention_utils.py#L378"><code>_flash_attention_forward</code></a>:</p>
<div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="cf" style="color: #003B4F;">elif</span> position_ids <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> (</span>
<span id="cb14-2">        max_length_q <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">or</span> (query_length <span class="op" style="color: #5E5E5E;">!=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="kw" style="color: #003B4F;">and</span> <span class="kw" style="color: #003B4F;">not</span> (torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">&gt;=</span> <span class="dv" style="color: #AD0000;">0</span>).<span class="bu" style="color: null;">all</span>())</span>
<span id="cb14-3">    )</span></code></pre></div>
<p>In particular, this line was of interest: <code>torch.diff(position_ids, dim=-1) &gt;= 0</code></p>
<p>In the following contrived example, <code>position_ids</code> is not a list of consecutive numbers (which seems to be the default value constructed is no <code>position_ids</code> value is passed to the model’s forward pass).</p>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">input_ids <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">10</span>, <span class="dv" style="color: #AD0000;">11</span>, <span class="dv" style="color: #AD0000;">12</span>, <span class="dv" style="color: #AD0000;">13</span>, <span class="dv" style="color: #AD0000;">14</span>, <span class="dv" style="color: #AD0000;">15</span>, <span class="dv" style="color: #AD0000;">16</span>]]).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb15-2">position_ids <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">6</span>]]).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb15-3">cu_seqlens <span class="op" style="color: #5E5E5E;">=</span> [torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32).to(<span class="st" style="color: #20794D;">"cuda"</span>)]</span></code></pre></div>
</div>
<div class="cell" data-outputid="46c76718-2cd2-411b-eb4e-5822cb0d73d7" data-execution_count="12">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">(torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">&gt;=</span> <span class="dv" style="color: #AD0000;">0</span>).<span class="bu" style="color: null;">all</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor(False, device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="5bed5591-9d67-4d15-cb42-8b1ab15f3089" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">&gt;=</span> <span class="dv" style="color: #AD0000;">0</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([[ True,  True, False,  True,  True,  True,  True,  True,  True]],
       device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="d15b4b7a-5cee-4651-e5b3-861f7c4d03b6" data-execution_count="15">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">torch.diff(position_ids, dim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([[ 1,  1, -2,  1,  1,  1,  1,  1,  1]], device='cuda:0')</code></pre>
</div>
</div>
<p>Some diffs between consecutive elements in <code>position_ids</code> are negative (because we are defining two sequences’ position ids).</p>
<p>I would now expect <code>flash_attn_varlen_func</code> to be called.</p>
<div class="cell" data-outputid="bbd565ce-415c-4756-98f0-364a438ed5ed" data-execution_count="43">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb22-2">test_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb22-3">    <span class="st" style="color: #20794D;">'input_ids'</span>: torch.randint(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">10</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">10</span>)).to(<span class="st" style="color: #20794D;">"cuda"</span>),</span>
<span id="cb22-4">    <span class="st" style="color: #20794D;">'position_ids'</span>: torch.tensor([[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">6</span>]]).to(<span class="st" style="color: #20794D;">"cuda"</span>),</span>
<span id="cb22-5">    <span class="st" style="color: #20794D;">'cu_seqlens'</span>: [torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32).to(<span class="st" style="color: #20794D;">"cuda"</span>)],</span>
<span id="cb22-6">    <span class="st" style="color: #20794D;">'max_seqlen'</span>: [<span class="dv" style="color: #AD0000;">7</span>]</span>
<span id="cb22-7">}</span>
<span id="cb22-8">test_params</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>{'input_ids': tensor([[7, 6, 8, 5, 1, 3, 8, 6, 5, 3]], device='cuda:0'),
 'position_ids': tensor([[0, 1, 2, 0, 1, 2, 3, 4, 5, 6]], device='cuda:0'),
 'cu_seqlens': [tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32)],
 'max_seqlen': [7]}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb24-2"><span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): output <span class="op" style="color: #5E5E5E;">=</span> model(<span class="op" style="color: #5E5E5E;">**</span>test_params)</span></code></pre></div>
</div>
<p>Passing <code>test_params</code> through the model’s forward pass yields:</p>
<pre><code>=== FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['position_ids', 'output_attentions', 'use_cache', 'cu_seqlens', 'max_seqlen']

=== _FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['output_attentions', 'use_cache', 'cu_seqlens', 'max_seqlen']

 attention_mask
None

 position_ids
tensor([[0, 1, 2, 0, 1, 2, 3, 4, 5, 6]], device='cuda:0')
position_ids is not None and max_length_q check
cu_seq_lens_q is None: True
cu_seq_lens_k is None: True

 cu_seq_lens
(tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32), tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32))</code></pre>
<p>The <code>position_ids</code> are as passed in. However, it does not use <code>cu_seqlens</code> directly from <code>kwargs</code>. Instead it builds it <a href="https://github.com/huggingface/transformers/blob/2932f318a20d9e54cc7aea052e040164d85de7d6/src/transformers/modeling_flash_attention_utils.py#L383">in the following line</a>:</p>
<div class="sourceCode" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb26-2">    prepare_fa2_from_position_ids(query_states, key_states, value_states, position_ids)</span>
<span id="cb26-3">)</span></code></pre></div>
<p>The value of <code>cu_seqlens</code> is the tuple:</p>
<div class="sourceCode" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">(tensor([ <span class="dv" style="color: #AD0000;">0</span>,  <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cuda:0'</span>, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32), tensor([ <span class="dv" style="color: #AD0000;">0</span>,  <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], device<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'cuda:0'</span>, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32))</span></code></pre></div>
<p>Which is deconstructed into <code>cu_seq_lens_q</code> and <code>cu_seql_lens_k</code> which are then passed as arguments to <code>flash_attn_varlen_func</code>.</p>
<p>The main takeaway from this: Flash Attention will not handle sequence packing correctly unless you pass in <code>position_ids</code>.</p>
</section>
<section id="packed-sequence-loss" class="level2">
<h2 class="anchored" data-anchor-id="packed-sequence-loss">Packed Sequence Loss</h2>
<p>In the remaining sections of this blog post, I’ll explore how to correctly handle calculating loss for a packed sequence.</p>
<div class="cell" data-outputid="05592fff-ecf2-4adf-e347-a4526778898f" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">output.logits.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>torch.Size([1, 10, 49152])</code></pre>
</div>
</div>
<p>Following how labels are constructed in HuggingFace’s <a href="https://github.com/RhuiDih/transformers/blob/90305596c1f14376bb2049f408a4c53e024b2450/src/transformers/data/data_collator.py#L1643"><code>DataCollatorWithFlattening</code></a>, the first token in each sequence is replaced with <code>-100</code>. This is because the HuggingFace CausalLM loss function handles the shifting of labels to allow next-token prediction.</p>
<div class="cell" data-outputid="0df22f75-897e-4207-8285-5b4edffc30c7" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">labels <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">3</span>]).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb30-2">labels</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([-100,    6,    8, -100,    1,    3,    8,    6,    5,    3],
       device='cuda:0')</code></pre>
</div>
</div>
<p>The following two lines are taken from the model’s loss function which can be inspected with <code>print(inspect.getsource(model.loss_function))</code>:</p>
<div class="cell" data-outputid="19309094-2315-487f-badc-574c5b8fab60" data-execution_count="20">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">_labels <span class="op" style="color: #5E5E5E;">=</span> torch.nn.functional.pad(labels, (<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb32-2">shift_labels <span class="op" style="color: #5E5E5E;">=</span> _labels[..., <span class="dv" style="color: #AD0000;">1</span>:].contiguous()</span>
<span id="cb32-3">shift_labels</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([   6,    8, -100,    1,    3,    8,    6,    5,    3, -100],
       device='cuda:0')</code></pre>
</div>
</div>
<p>We can see that the labels have been shifted to the left by 1 element, and a <code>-100</code> ignore index has been added to the right, which is needed because the last token in the input doesn’t predict anything.</p>
<p>Calculating the loss using <code>F.cross_entropy</code> directly and the model’s <code>loss_function</code> (providing it unshifted <code>labels</code>):</p>
<div class="cell" data-outputid="d77b6fcb-8635-4fc2-dc2b-e767fd428d7c" data-execution_count="21">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">loss <span class="op" style="color: #5E5E5E;">=</span> F.cross_entropy(</span>
<span id="cb34-2">    output.logits.reshape(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>, output.logits.size(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)).<span class="bu" style="color: null;">float</span>(),</span>
<span id="cb34-3">    shift_labels.reshape(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb34-4">)</span>
<span id="cb34-5">loss</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor(20.2832, device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="91c2e8da-2901-44a0-e234-5dbe77787361" data-execution_count="22">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">model.loss_function(output.logits, labels, <span class="dv" style="color: #AD0000;">49152</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor(20.2832, device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="padded-batch-loss" class="level2">
<h2 class="anchored" data-anchor-id="padded-batch-loss">Padded Batch Loss</h2>
<p>Sequence packing shouldn’t change the loss value of a given input batch. To test this, I’ll construct a padded batch from our fake data and calculate its outputs, labels and loss.</p>
<div class="cell" data-outputid="e7066f5a-18f6-43b6-a247-bf162df07b79" data-execution_count="23">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">input_ids <span class="op" style="color: #5E5E5E;">=</span> test_params[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb38-2">input_ids</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([7, 6, 8, 5, 1, 3, 8, 6, 5, 3], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="8c2cc60a-1319-480c-e975-b60ea1e94a7a" data-execution_count="24">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">cu_seqlens <span class="op" style="color: #5E5E5E;">=</span> test_params[<span class="st" style="color: #20794D;">'cu_seqlens'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb40-2">cu_seqlens</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32)</code></pre>
</div>
</div>
<div class="cell" data-outputid="bbb44c85-d6d9-4d4a-d91d-7ced9a893f42" data-execution_count="25">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">seq_boundaries <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">list</span>(<span class="bu" style="color: null;">zip</span>(cu_seqlens[:<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>], cu_seqlens[<span class="dv" style="color: #AD0000;">1</span>:]))</span>
<span id="cb42-2">seq_boundaries</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>[(tensor(0, device='cuda:0', dtype=torch.int32),
  tensor(3, device='cuda:0', dtype=torch.int32)),
 (tensor(3, device='cuda:0', dtype=torch.int32),
  tensor(10, device='cuda:0', dtype=torch.int32))]</code></pre>
</div>
</div>
<div class="cell" data-outputid="eca4d729-ec35-4d60-b6d3-0504fd4cda7a" data-execution_count="26">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">seq1 <span class="op" style="color: #5E5E5E;">=</span> input_ids[seq_boundaries[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]: seq_boundaries[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">1</span>]]</span>
<span id="cb44-2">seq2 <span class="op" style="color: #5E5E5E;">=</span> input_ids[seq_boundaries[<span class="dv" style="color: #AD0000;">1</span>][<span class="dv" style="color: #AD0000;">0</span>]: seq_boundaries[<span class="dv" style="color: #AD0000;">1</span>][<span class="dv" style="color: #AD0000;">1</span>]]</span>
<span id="cb44-3">seq1, seq2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>(tensor([7, 6, 8], device='cuda:0'),
 tensor([5, 1, 3, 8, 6, 5, 3], device='cuda:0'))</code></pre>
</div>
</div>
<p>The first item in the batch has 3 elements, and the second item in the batch has 7 elements. We need to pad the first item so it’s 7 elements long.</p>
<div class="cell" data-outputid="2260cb77-daca-41dc-9d40-5fce0bf2d638" data-execution_count="27">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1">seq1 <span class="op" style="color: #5E5E5E;">=</span> torch.cat([seq1, torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>]).to(<span class="st" style="color: #20794D;">"cuda"</span>)])</span>
<span id="cb46-2">seq1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([7, 6, 8, 0, 0, 0, 0], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="99b50860-f6ea-472e-b244-0424fa99d756" data-execution_count="28">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1">padded_batch <span class="op" style="color: #5E5E5E;">=</span> torch.stack([seq1, seq2], dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb48-2">padded_batch, padded_batch.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>(tensor([[7, 6, 8, 0, 0, 0, 0],
         [5, 1, 3, 8, 6, 5, 3]], device='cuda:0'),
 torch.Size([2, 7]))</code></pre>
</div>
</div>
<p>Similarly, we need to construct <code>labels</code> such that the last four elements in the first batch item are ignored.</p>
<div class="cell" data-outputid="79c4035c-71f7-4d78-f722-05623c1f5c7f" data-execution_count="29">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1">seq1 <span class="op" style="color: #5E5E5E;">=</span> input_ids[seq_boundaries[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">0</span>]: seq_boundaries[<span class="dv" style="color: #AD0000;">0</span>][<span class="dv" style="color: #AD0000;">1</span>]]</span>
<span id="cb50-2">seq2 <span class="op" style="color: #5E5E5E;">=</span> input_ids[seq_boundaries[<span class="dv" style="color: #AD0000;">1</span>][<span class="dv" style="color: #AD0000;">0</span>]: seq_boundaries[<span class="dv" style="color: #AD0000;">1</span>][<span class="dv" style="color: #AD0000;">1</span>]]</span>
<span id="cb50-3">seq1, seq2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>(tensor([7, 6, 8], device='cuda:0'),
 tensor([5, 1, 3, 8, 6, 5, 3], device='cuda:0'))</code></pre>
</div>
</div>
<div class="cell" data-outputid="ea05103b-0a1e-4a5d-89ca-a7e243c5f66a" data-execution_count="30">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1">seq1 <span class="op" style="color: #5E5E5E;">=</span> torch.cat([seq1, torch.tensor([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>]).to(<span class="st" style="color: #20794D;">"cuda"</span>)])</span>
<span id="cb52-2">seq1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor([   7,    6,    8, -100, -100, -100, -100], device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="bf8a766d-0c21-4ce8-c288-7d654906f228" data-execution_count="31">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1">padded_labels <span class="op" style="color: #5E5E5E;">=</span> torch.stack([seq1, seq2], dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb54-2">padded_labels</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor([[   7,    6,    8, -100, -100, -100, -100],
        [   5,    1,    3,    8,    6,    5,    3]], device='cuda:0')</code></pre>
</div>
</div>
<p>Calculating the logits:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1">model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb56-2"><span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): padded_output <span class="op" style="color: #5E5E5E;">=</span> model(input_ids<span class="op" style="color: #5E5E5E;">=</span>padded_batch)</span></code></pre></div>
</div>
<p>Noting that I haven’t pass any <code>position_ids</code> and the printed output shows us that <code>flash_attn_func</code> is indeed the “vanilla” implementation of Flash Attention for padded batches:</p>
<pre><code>=== FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['position_ids', 'output_attentions', 'use_cache']

=== _FLASH_ATTENTION_FORWARD ENTRY ===
kwargs received: ['output_attentions', 'use_cache']

 attention_mask
None

 position_ids
tensor([[0, 1, 2, 3, 4, 5, 6]], device='cuda:0')
flash_attn_func is called
flash_kwargs received: ['deterministic']</code></pre>
<p>Comparing the packed output logits with the padded output logits. The shapes are different but the values are the same.</p>
<div class="cell" data-outputid="3aadf767-b684-4d5a-b77d-c61d133baa74" data-execution_count="33">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">output.logits.shape, padded_output.logits.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>(torch.Size([1, 10, 49152]), torch.Size([2, 7, 49152]))</code></pre>
</div>
</div>
<div class="cell" data-outputid="070e6ffd-013f-4ecd-befc-9ac8dae7cc91" data-execution_count="34">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1">(output.logits[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">3</span>, :] <span class="op" style="color: #5E5E5E;">==</span> padded_output.logits[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">0</span>:<span class="dv" style="color: #AD0000;">3</span>, :]).<span class="bu" style="color: null;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor(1., device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="8598f24d-6e50-4bc8-ce46-e04918d5afc2" data-execution_count="35">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1">(output.logits[<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>:, :] <span class="op" style="color: #5E5E5E;">==</span> padded_output.logits[<span class="dv" style="color: #AD0000;">1</span>, :, :]).<span class="bu" style="color: null;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor(1., device='cuda:0')</code></pre>
</div>
</div>
<p>Finally, calculating the padded batch’s loss gives us the same value as the sequence packed loss:</p>
<div class="cell" data-outputid="d4daac3a-2429-438a-deb4-c09d5bca924c" data-execution_count="36">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">padded_loss <span class="op" style="color: #5E5E5E;">=</span> model.loss_function(padded_output.logits, padded_labels, vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">49152</span>)</span>
<span id="cb64-2">padded_loss</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor(20.2832, device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="not-passing-in-position_ids-with-packed-sequence" class="level2">
<h2 class="anchored" data-anchor-id="not-passing-in-position_ids-with-packed-sequence">Not Passing in <code>position_ids</code> With Packed Sequence</h2>
<p>To confirm that not passing in position_ids does in indeed make HuggingFace use the wrong Flash Attention implementation for a packed sequence, I’ll compare the logits and loss:</p>
<div class="cell" data-outputid="990a6acb-870f-46fd-e6e1-8e9c49adde95" data-execution_count="50">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">42</span>)</span>
<span id="cb66-2">test_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb66-3">    <span class="st" style="color: #20794D;">'input_ids'</span>: torch.randint(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">10</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">10</span>)).to(<span class="st" style="color: #20794D;">"cuda"</span>),</span>
<span id="cb66-4">    <span class="st" style="color: #20794D;">'cu_seqlens'</span>: [torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">10</span>], dtype<span class="op" style="color: #5E5E5E;">=</span>torch.int32).to(<span class="st" style="color: #20794D;">"cuda"</span>)],</span>
<span id="cb66-5">    <span class="st" style="color: #20794D;">'max_seqlen'</span>: [<span class="dv" style="color: #AD0000;">10</span>]</span>
<span id="cb66-6">}</span>
<span id="cb66-7">test_params</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>{'input_ids': tensor([[7, 6, 8, 5, 1, 3, 8, 6, 5, 3]], device='cuda:0'),
 'cu_seqlens': [tensor([ 0,  3, 10], device='cuda:0', dtype=torch.int32)],
 'max_seqlen': [10]}</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1">model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb68-2"><span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): output2 <span class="op" style="color: #5E5E5E;">=</span> model(<span class="op" style="color: #5E5E5E;">**</span>test_params)</span></code></pre></div>
</div>
<p>The logits are not the same as when <code>flash_attn_varlen_func</code> is used.</p>
<div class="cell" data-outputid="91d780a7-01bb-4650-e622-6901fc72cc7b" data-execution_count="52">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1">(output.logits <span class="op" style="color: #5E5E5E;">==</span> output2.logits).<span class="bu" style="color: null;">float</span>().mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>tensor(0.3012, device='cuda:0')</code></pre>
</div>
</div>
<p>It follows that the loss value is not the same either.</p>
<div class="cell" data-outputid="6ec37ab6-7dac-4d44-f171-901f927ad8b0" data-execution_count="40">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1">labels <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">3</span>]).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb71-2">model.loss_function(output.logits, labels, <span class="dv" style="color: #AD0000;">49152</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>tensor(17.4632, device='cuda:0')</code></pre>
</div>
</div>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>I’ll reiterate that I’m not familiar with how sequence packing is implemented (in HuggingFace or ModernBERT) and even less familiar with how Flash Attention is implemented. That being said, this cursory investigation allowed me to understand high-level concepts of how these two interact. My key takeaway is that the correct <code>position_ids</code> need to be passed to the model otherwise HuggingFace will not use the correct <code>flash_attn_varlen_func</code> for sequence packed inputs and that will result in incorrect logits and loss values.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-04-Understanding-Sequence-Packing/index.html</guid>
  <pubDate>Sun, 04 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Initial Manual Scoring Results for TinyStories Models</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-05-01-TSL-Initial-Scoring-Results/index.html</link>
  <description><![CDATA[ 



<section id="recap" class="level2">
<h2 class="anchored" data-anchor-id="recap">Recap</h2>
<p>In this post, I’m going to analyze the initial manual scoring results for my baseline models’ text generations given my 150 evaluation prompts across six scoring categories and 18 criteria. A quick recap of what I’ve done so far:</p>
<ul>
<li>Defined scoring criteria</li>
<li>Curated a set of eval prompts based on each scoring category</li>
<li>Created a fast HTML app where I can perform my scoring activities</li>
</ul>
<p>The raw scores analyzed in this blog post can be found in <a href="https://github.com/vishalbakshi/TinyScaleLab">my TinyScaleLab repo</a>.</p>
</section>
<section id="evaluation-categories" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-categories">Evaluation Categories</h2>
<p>I have six scoring categories that I’m evaluating my models on:</p>
<section id="foundational-language-capabilities" class="level3">
<h3 class="anchored" data-anchor-id="foundational-language-capabilities">Foundational language capabilities</h3>
<ul>
<li>Grammar</li>
<li>Context-Tracking (Consistency)</li>
</ul>
</section>
<section id="emergent-capabilities" class="level3">
<h3 class="anchored" data-anchor-id="emergent-capabilities">Emergent capabilities</h3>
<ul>
<li>Factual Knowledge</li>
<li>Reasoning</li>
<li>Creativity</li>
</ul>
</section>
<section id="story-related-capabilities" class="level3">
<h3 class="anchored" data-anchor-id="story-related-capabilities">Story-related capabilities</h3>
<ul>
<li>Plot</li>
</ul>
<p>My goal was to generate prompts that either isolate (Factual Knowledge, Reasoning, Context-Tracking) or elicit opportunities to exhibit (Plot, Creativity) scoring categories. I wanted to make the job easier first for myself, and then use that as a proxy of making the job of the LLM judge easier to evaluate scoring categories in a focused way.</p>
</section>
</section>
<section id="baseline-models" class="level2">
<h2 class="anchored" data-anchor-id="baseline-models">Baseline Models</h2>
<p>I’ve chosen three models as my baseline because they’re similar in size to the models that I’m going to be training in this project:</p>
<ul>
<li>TinyStories-1M (~3.7 million parameters)</li>
<li>TinyStories-8M (~20 million parameters)</li>
<li>TinyStories-28M (~60 million parameters)</li>
</ul>
</section>
<section id="generation-script" class="level2">
<h2 class="anchored" data-anchor-id="generation-script">Generation Script</h2>
<p>I’m using a pretty standard generation script. Things I want to highlight:</p>
<ul>
<li>Making sure the padding side is left so that we’re not generating tokens based on padding tokens</li>
<li><code>model.eval()</code> and <code>torch.no_grad()</code> are things that I always make sure to do so that it’s somewhat deterministic when it’s expected to be deterministic</li>
<li>I’m doing <code>do_sample=False</code> and <code>num_beams=5</code> because that was published by the authors as their parameters for generation</li>
<li>I have a minimum and maximum length, which I’ll talk about at the end about how I think that might change moving forward</li>
</ul>
</section>
<section id="eval-prompts" class="level2">
<h2 class="anchored" data-anchor-id="eval-prompts">Eval Prompts</h2>
<p>My current eval prompts set includes:</p>
<ul>
<li>25 unique prompts for Reasoning</li>
<li>25 unique prompts for Factual Knowledge</li>
<li>25 prompts each for Context-Tracking, Plot and Creativity (with some overlap)</li>
<li>25 prompts for Grammar (5 prompts sampled from the other 5 categories)</li>
</ul>
<p>That’s 150 total prompts.</p>
</section>
<section id="scoring-methodology" class="level2">
<h2 class="anchored" data-anchor-id="scoring-methodology">Scoring Methodology</h2>
<p>I have six categories across 18 criteria, evaluating generations from three models on 150 prompts each. The scores that I’m providing for each criteria are either 0, 0.5, and 1.0, taken from the Tiny Stories paper (though they didn’t quite use it the same way I’m using it), in Section 4.2 (Figures 9/10/11) where they use scoring levels success (green), failure (red), and partial success (yellow).</p>
</section>
<section id="overall-results" class="level2">
<h2 class="anchored" data-anchor-id="overall-results">Overall Results</h2>
<p>First, let’s look at the average value across all categories and criteria for each model:</p>
<table class="table">
<thead>
<tr class="header">
<th>model_name</th>
<th>score_value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>roneneneldan/TinyStories-1M</td>
<td>0.25</td>
</tr>
<tr class="even">
<td>roneneneldan/TinyStories-8M</td>
<td>0.49</td>
</tr>
<tr class="odd">
<td>roneneneldan/TinyStories-28M</td>
<td>0.61</td>
</tr>
</tbody>
</table>
<p>As I would expect, as model size increases, the average score value increases. The 1M parameter model (which actually has 3.7M parameters) has an average score of 0.25. The 8M parameter model (which is closer to 20M parameters) has an average score of about 0.5. And the 28M parameter model (which has about 60M parameters) has an average score of 0.61.</p>
<p>A parameter count <em>increase</em> of 4x (16.3M increase from 3.7M to 20M) yields an overall mean score <em>increase</em> of 1x (0.25 to 0.50). A parameter count <em>increase</em> of 2x (40M increase from 20M to 60M) yields an overall mean score <em>increase</em> of 25% (0.49 to 0.61). There are decreasing gains overall when increasing parameter count. For a 125M parameter model (that I’m planning to train), I would expect &lt;10% increase from a mean overall score of 0.61.</p>
</section>
<section id="scores-by-category" class="level2">
<h2 class="anchored" data-anchor-id="scores-by-category">Scores by Category</h2>
<p>Next, let’s look at how these models are doing for each of the categories overall:</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Context-Tracking</td>
<td>0.14</td>
<td>0.51</td>
<td>0.63</td>
</tr>
<tr class="even">
<td>Creativity</td>
<td>0.12</td>
<td>0.16</td>
<td>0.32</td>
</tr>
<tr class="odd">
<td>Factual Knowledge</td>
<td>0.08</td>
<td>0.32</td>
<td>0.40</td>
</tr>
<tr class="even">
<td>Grammar</td>
<td>0.59</td>
<td>0.82</td>
<td>0.86</td>
</tr>
<tr class="odd">
<td>Plot</td>
<td>0.10</td>
<td>0.42</td>
<td>0.60</td>
</tr>
<tr class="even">
<td>Reasoning</td>
<td>0.20</td>
<td>0.44</td>
<td>0.70</td>
</tr>
</tbody>
</table>
<p>Some interesting things to point out:</p>
<p>The highest category by score for my 1M parameter model is grammar, by farL 0.59. That’s about three times as large as any other category. This is in line with what I read in the TinyStories paper, that grammar appears first as a capability.</p>
<p>The worst categories, even for the largest model that I tested, were Creativity and Factual Knowledge. Creativity in particular was the lowest scoring, and this also tracks with the TinyStories paper, because they had shown that creativity only really appears at large hidden dimension sizes. And even then, the maximum value of creativity (8s and 9s out of 10) was only available for models like GPT-4.</p>
<p>Factual Knowledge was also significantly lower than the other four categories.</p>
<p>The other category I want to highlight is Reasoning. The Reasoning score for the smallest model is 0.2, it doubles to 0.44 at 8M, and then it goes up by another 60 percent to 0.7 for the 28M model. That’s pretty solid! 70%, 7 out of 10. So, if we were talking about school grades, a 70 percent is passing. Very cool to see reasoning potential, even for the tiniest model evaluated.</p>
<p>In every case, there is an increase as we go from 1M to 8M to 28M model name. In some cases, the jump comes later, such as for Creativity. In most cases, the jump happens between the 1M and 8M models.</p>
</section>
<section id="scoring-by-criteria" class="level2">
<h2 class="anchored" data-anchor-id="scoring-by-criteria">Scoring by Criteria</h2>
<p>Now let’s look at each criteria for each category:</p>
<section id="emergent-capabilities-creativity-factual-knowledge-and-reasoning" class="level3">
<h3 class="anchored" data-anchor-id="emergent-capabilities-creativity-factual-knowledge-and-reasoning">Emergent Capabilities: Creativity, Factual Knowledge and Reasoning</h3>
<table class="table">
<colgroup>
<col style="width: 78%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 7%">
</colgroup>
<thead>
<tr class="header">
<th>Factual Knowledge</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Completion contains only correct factual information relevant to the prompt</td>
<td>0.08</td>
<td>0.32</td>
<td>0.4</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 79%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th>Reasoning</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Completion demonstrates correct logical reasoning relevant to the prompt</td>
<td>0.2</td>
<td>0.44</td>
<td>0.7</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 73%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th>Creativity</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Character behavioral and emotional responses are innovative</td>
<td>0.00</td>
<td>0.04</td>
<td>0.22</td>
</tr>
<tr class="even">
<td>The completion contains unique details to the story world</td>
<td>0.02</td>
<td>0.12</td>
<td>0.34</td>
</tr>
<tr class="odd">
<td>The completion creates fresh situations</td>
<td>0.00</td>
<td>0.08</td>
<td>0.20</td>
</tr>
<tr class="even">
<td>The completion offers unexpected or novel elements</td>
<td>0.48</td>
<td>0.42</td>
<td>0.50</td>
</tr>
</tbody>
</table>
<p>Factual Knowledge and Reasoning only had one criteria each. For Factual Knowledge, I was assessing if the completion contains only correct factual information relevant to the prompt. For Reasoning, I was assessing if the completion demonstrates correct logical reasoning relevant to the prompt.</p>
<p>For Creativity, note that the smallest model performs well for the criteria “The completion offers unexpected or novel elements.” Since I was isolating Grammar, Plot and Context-Tracking from Creativity, the tiniest model could deviate from Plot/Context and still get a high score for this criterion, making it the lowest bar to cross. For the other three Creativity criteria, the 1M model has negligible skill.</p>
</section>
<section id="foundational-language-capabilities-grammar-and-context-tracking" class="level3">
<h3 class="anchored" data-anchor-id="foundational-language-capabilities-grammar-and-context-tracking">Foundational Language Capabilities: Grammar and Context-Tracking</h3>
<table class="table">
<colgroup>
<col style="width: 73%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th>Grammar</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Age-appropriate vocabulary usage</td>
<td>1.00</td>
<td>1.00</td>
<td>0.98</td>
</tr>
<tr class="even">
<td>Dialogue formatting and punctuation</td>
<td>1.00</td>
<td>0.96</td>
<td>0.98</td>
</tr>
<tr class="odd">
<td>Proper use of pronouns and referents</td>
<td>0.56</td>
<td>0.88</td>
<td>0.90</td>
</tr>
<tr class="even">
<td>Sentence structure logic, clarity and completion</td>
<td>0.14</td>
<td>0.62</td>
<td>0.70</td>
</tr>
<tr class="odd">
<td>Tense consistency throughout the completion</td>
<td>0.26</td>
<td>0.66</td>
<td>0.74</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 79%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th>Context-Tracking</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Completion maintains complete coherence with prompt</td>
<td>0.20</td>
<td>0.62</td>
<td>0.64</td>
</tr>
<tr class="even">
<td>Correctly references/tracks all objects, characters, and their attributes</td>
<td>0.20</td>
<td>0.52</td>
<td>0.68</td>
</tr>
<tr class="odd">
<td>Maintains consistent narrative flow</td>
<td>0.02</td>
<td>0.40</td>
<td>0.56</td>
</tr>
</tbody>
</table>
<p>For Grammar, the age-appropriate vocabulary usage was the easiest to score. These models don’t really generate anything that’s not within the TinyStories dataset.</p>
<p>Sentence structure, logic, clarity, and completion had the biggest jump from 1M to 8M, going from 0.14 to 0.62. That matches my experiencing scoring: the small model had terrible structure, logic, clarity, and completion in its completions.</p>
<p>For context tracking, I was looking at three criteria. The biggest jump is from 2% to 40% for maintaining a consistent narrative flow. The medium-sized models were definitely not perfect, but was much better at following the narrative flow of the story.</p>
</section>
<section id="story-related-capabilities-plot" class="level3">
<h3 class="anchored" data-anchor-id="story-related-capabilities-plot">Story-Related Capabilities: Plot</h3>
<table class="table">
<colgroup>
<col style="width: 81%">
<col style="width: 6%">
<col style="width: 6%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th>Plot</th>
<th>1M</th>
<th>8M</th>
<th>28M</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Conflicts are addressed rather than abandoned</td>
<td>0.00</td>
<td>0.42</td>
<td>0.60</td>
</tr>
<tr class="even">
<td>The pacing is appropriate (not too rushed or dragging)</td>
<td>0.00</td>
<td>0.14</td>
<td>0.24</td>
</tr>
<tr class="odd">
<td>The story has a clear beginning, middle, and end appropriate to age level</td>
<td>0.26</td>
<td>0.50</td>
<td>0.72</td>
</tr>
<tr class="even">
<td>The story maintains focus on the central conflict/theme without random diversions</td>
<td>0.12</td>
<td>0.64</td>
<td>0.84</td>
</tr>
</tbody>
</table>
<p>For Plot, I found the pacing to be the worst category across all models. This checks out with my experience as I was grading these stories - I didn’t really get a sense that there was a well-paced story. Either it was dragging and repeating itself slightly, or it was just one or two sentences and insufficient.</p>
<p>For “conflicts are addressed” we go from 0% to 42% from 1M to 8M. The smallest model simply ignored or abandoned conflicts that were in the premise and the prompt. The other big jump is for “focusing on the central theme” - the smallest to medium model had almost a 3x jump, and then there was still a considerable 30% jump from the medium to large model.</p>
</section>
</section>
<section id="comparison-to-tinystories-paper" class="level2">
<h2 class="anchored" data-anchor-id="comparison-to-tinystories-paper">Comparison to TinyStories Paper</h2>
<p>I’m going to revisit the targets that I established from Figure 4 of the TinyStories paper, where they showed the different scores based on hidden dimension and number of layers. I matched that up with the three models that I’m testing:</p>
<section id="creativity" class="level3">
<h3 class="anchored" data-anchor-id="creativity">Creativity</h3>
<p>The TinyStories paper reported:</p>
<ul>
<li>1M: 0.47</li>
<li>8M: 0.65</li>
<li>28M: 0.69</li>
</ul>
<p>My scores:</p>
<ul>
<li>1M: 0.12</li>
<li>8M: 0.16</li>
<li>28M: 0.32</li>
</ul>
<p>This was really interesting - I was expecting my assessment to be maybe a little lenient, but it turns out that’s not the case. My scores were significantly lower. The 28M parameter model (which is actually 60M) got 70% for creativity in the paper, while mine was at 30%. I might have to change that criteria over the course of this project, or it might turn out that for creativity, I have a stricter judge.</p>
</section>
<section id="grammar" class="level3">
<h3 class="anchored" data-anchor-id="grammar">Grammar</h3>
<p>TinyStories:</p>
<ul>
<li>1M: 0.61</li>
<li>8M: 0.77</li>
<li>28M: 0.83</li>
</ul>
<p>My scores:</p>
<ul>
<li>1M: 0.59</li>
<li>8M: 0.82</li>
<li>28M: 0.86</li>
</ul>
<p>This matched out pretty well! 61%/59%, 77%/82%, and 83%/86%. The most common baseline capability matches between the targets and my relatively rough evaluation, so thumbs up!</p>
</section>
<section id="context-tracking-consistency" class="level3">
<h3 class="anchored" data-anchor-id="context-tracking-consistency">Context-Tracking (Consistency)</h3>
<p>TinyStories:</p>
<ul>
<li>1M: 0.45</li>
<li>8M: 0.80</li>
<li>28M: 0.90</li>
</ul>
<p>My scores:</p>
<ul>
<li>1M: 0.14</li>
<li>8M: 0.51</li>
<li>28M: 0.63</li>
</ul>
<p>Similar to creativity, it turns out that my criteria or my judging is a lot stricter than the GPT-4 evaluator used in the paper. The highest score in the paper was 90%, whereas mine was 63%. I’m not too worried about this - I would much rather be stricter than not. However, I’ll be open to changing my approach later on if that turns out to be a problem.</p>
</section>
<section id="plot" class="level3">
<h3 class="anchored" data-anchor-id="plot">Plot</h3>
<p>TinyStories: - 1M: 0.44 - 8M: 0.72 - 28M: 0.73</p>
<p>My scores: - 1M: 0.10 - 8M: 0.42 - 28M: 0.60</p>
<p>The 28M scores for Plot are in the same range but medium-sized and small model scores are significantly different.</p>
<p>Factual Knowledge and Reasoning were not quantitatively assessed in the TinyStories paper in the way that these other scores were listed, so I don’t have those reference points for my evaluation.</p>
</section>
</section>
<section id="observations-from-manual-scoring" class="level2">
<h2 class="anchored" data-anchor-id="observations-from-manual-scoring">Observations From Manual Scoring</h2>
<p>After manually scoring 450 stories, I have some observations:</p>
<ol type="1">
<li><p>Judging quality improves (and changes) over time</p>
<ul>
<li>Implicit judging criteria surfaces over time.</li>
<li>By the time I was doing the last hundred, I realized that I was a lot more definitive in giving 0s, 0.5s, and 1s.</li>
<li>Thee largest model likely has the strictest scores (it was graded last).</li>
</ul></li>
<li><p>Phrasing of scoring criteria improved</p>
<ul>
<li>I wanted to be able to answer the question as fast as I could (450 stories to get through!) with a quick yes, no, maybe (1, 0, 0.5).</li>
<li>Initially, some of the criteria were phrased as questions, requiring more cognitive work. I expect that rephrasing the criteria as statements will also ease the “cognitive load” for my LLM judge.</li>
</ul></li>
<li><p>I identified one duplicate prompt and replaced it</p></li>
<li><p>Pros and cons of isolating scoring categories</p>
<ul>
<li>I scored each category in isolation.</li>
<li>More times than not, I found this very liberating—I could assess Creativity without worrying about Context-Tracking or Plot.</li>
<li>However, language is very difficult to compartmentalize. If something’s not factually correct, it will be a distraction when assessing Reasoning. If the context is not being tracked, it makes it harder to assess plot.</li>
<li>Regardless, I thought this isolation of scoring categories overall benefited my approach</li>
</ul></li>
</ol>
</section>
<section id="exciting-discoveries" class="level2">
<h2 class="anchored" data-anchor-id="exciting-discoveries">Exciting Discoveries</h2>
<p>The main takeaway for me, which was very cool to see, is that Reasoning and Factual Knowledge capabilities exists even for the smallest model. The 1M model scored 20% on Reasoning - that’s not nothing!</p>
<p>The fact that there are non-zero values for these tiny models is really mind-blowing to me. It’s really exciting because there’s potential. We can do something with this, especially as these are just pre-trained models—we haven’t fine-tuned them yet. What can we do with this Reasoning and Factual Knowledge capability? That’s what really excites me moving forward.</p>
</section>
<section id="process-improvements" class="level2">
<h2 class="anchored" data-anchor-id="process-improvements">Process Improvements</h2>
<p>When generating completions for my Reasoning and Factual Knowledge, I want to remove the <code>min_length</code> parameter for <code>model.generate()</code> because I don’t want there to be a minimum generation length when the answer can be a few tokens, forcing the model to uneccesarily elongate the story. However, I won’t make this change for my LLM judge as I want to compare its scores with mine for the same prompt/completion pairs.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>With a full eval set scored, I can now move on to prompt engineering an LLM judge (I’ll be using Gemini 2.5 Flash and Claude Haiku 3.5). My goal is for a 90%+ alignment between my scores and the LLM judge before I choose to use it for future experiments.</p>
<p>Follow along this project (and others) in my <a href="https://www.youtube.com/@vishal_learner">YouTube channel!</a>.</p>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-05-01-TSL-Initial-Scoring-Results/index.html</guid>
  <pubDate>Thu, 01 May 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Curating Evaluation Prompts, Defining Scoring Criteria, and Designing an LLM Judge Prompt Template</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/index.html</link>
  <description><![CDATA[ 



<section id="recap-and-initial-approach" class="level2">
<h2 class="anchored" data-anchor-id="recap-and-initial-approach">Recap and Initial Approach</h2>
<p>Initially, I planned to use the 44 evaluation prompts from the Tiny Stories dataset HuggingFace repo. These were the same prompts used in the paper to evaluate various model sizes.</p>
<p>I also documented the target scores for evaluation based on the TinyStories’ 10-point scoring rubric for my TinyScaleLab architectures:</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Similar to</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Num Layers</th>
<th style="text-align: center;">Eval Loss</th>
<th style="text-align: center;">Creativity</th>
<th style="text-align: center;">Grammar</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Plot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">TSL-5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">2.02</td>
<td style="text-align: center;">4.84</td>
<td style="text-align: center;">6.19</td>
<td style="text-align: center;">4.75</td>
<td style="text-align: center;">4.39</td>
</tr>
<tr class="even">
<td style="text-align: center;">TSL-25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.38</td>
<td style="text-align: center;">6.54</td>
<td style="text-align: center;">7.72</td>
<td style="text-align: center;">8.02</td>
<td style="text-align: center;">7.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;">TSL-60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">Average of 4 and 8 scores</td>
<td style="text-align: center;">1.23</td>
<td style="text-align: center;">6.8</td>
<td style="text-align: center;">8.35</td>
<td style="text-align: center;">8.7</td>
<td style="text-align: center;">7.31</td>
</tr>
<tr class="even">
<td style="text-align: center;">TSL-125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.18</td>
<td style="text-align: center;">7.02</td>
<td style="text-align: center;">8.62</td>
<td style="text-align: center;">9.34</td>
<td style="text-align: center;">7.34</td>
</tr>
</tbody>
</table>
<p>I am particularly interested in matching the scores shown in the table above, which presents results from GPT-4 evaluations of models with different hidden dimensions and layer counts.</p>
</section>
<section id="one-prompt-to-score-them-all" class="level2">
<h2 class="anchored" data-anchor-id="one-prompt-to-score-them-all">One Prompt to Score them All?</h2>
<p>The Tiny Stories paper used distinct approaches for different capabilities in Section 4.2 (“Knowledge, reasoning and context-tracking”):</p>
<ul>
<li><strong>Factual prompts</strong> - testing models’ knowledge of common sense facts</li>
<li><strong>Reasoning prompts</strong> - testing basic reasoning abilities</li>
<li><strong>Consistency (context-tracking) prompts</strong> - testing models’ ability to maintain coherence</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Knowledge, Reasoning and Context-Tracking Section"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Knowledge, Reasoning and Context-Tracking Section</figcaption><p></p>
</figure>
</div>
<p>What caught my attention was how they assessed these differently, using qualitative measures (success, failure, or partial success) rather than the numerical scores used for other categories.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Performance Table Example"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Performance Table Example</figcaption><p></p>
</figure>
</div>
</section>
<section id="analyzing-the-44-prompts" class="level2">
<h2 class="anchored" data-anchor-id="analyzing-the-44-prompts">Analyzing the 44 Prompts</h2>
<p>I asked Claude to analyze the 44 prompts from the dataset repository to identify which ones were good evaluators for factual knowledge, reasoning, and context-tracking capabilities.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Claude Prompt Analysis"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/3.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Claude Prompt Analysis</figcaption><p></p>
</figure>
</div>
<p>When Claude assessed the prompts, I noticed:</p>
<ol type="1">
<li>Factual knowledge prompts were the most specific/easiest to isolate.</li>
<li>Context-tracking prompts were dime a dozen (found everywhere).</li>
<li>Reasoning was hard to isolate from context-tracking.</li>
</ol>
<p>This led me to an important realization: <strong>I needed to curate specific prompts for each scoring category rather than using one set for all</strong>.</p>
</section>
<section id="prompts-for-creativity-and-plot" class="level2">
<h2 class="anchored" data-anchor-id="prompts-for-creativity-and-plot">Prompts for Creativity and Plot</h2>
<p>For creativity and plot, the challenge was different. Here, I needed prompts that <strong>provided opportunities</strong> for models to exhibit these capabilities.</p>
<p>When flagging good candidates for creativity, I looked for prompts that allowed creative responses <strong>without sacrificing consistency or plot</strong>. Not all prompts are equal in this regard.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="4.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Creativity Example"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/4.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Creativity Example</figcaption><p></p>
</figure>
</div>
<p>For plot, I sought prompts that provided strong opportunities to resolve conflict or pursue adventure—elements that test a model’s ability to construct a coherent narrative arc.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="5.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Plot Example"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/5.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Plot Example</figcaption><p></p>
</figure>
</div>
</section>
<section id="curating-category-specific-prompts" class="level2">
<h2 class="anchored" data-anchor-id="curating-category-specific-prompts">Curating Category-Specific Prompts</h2>
<p>Using the factual and reasoning prompts from the paper as a foundation, I worked with Claude to generate additional prompts for each category. Here are examples for factual knowledge:</p>
<ul>
<li>Alice was so tired when she got back home so she went</li>
<li>Jack and Lily saw a rain- bow after a rainy day. They were amazed by the colors. Jack said, “Look, Lily. A rainbow has</li>
<li>Jack and Lily liked to watch the moon at night. They noticed that the moon changed its shape every night. Sometimes the moon was big and round, and sometimes it was</li>
<li>Jack wanted to read a book, so he went to</li>
</ul>
<p>And reasoning prompts:</p>
<ul>
<li>Lily likes cats and dogs. She asked her mom for a dog and her mom said no, so instead she asked</li>
<li>Jack told Mary, ‘If you give me your banana, I’ll give you my apple’. Mary gave Jack her banana so</li>
<li>On weekends Jack went to visit his grandmother whereas on weekdays he would go to school. Last weekend, when Jack was on his way to</li>
<li>Lily and Ben were having an argument. Ben said that cake is much better than ice cream and Lily said that</li>
<li>Lily and Ben are having an argument. They are trying to decide between the park and the swimming pool. Ben says, ‘I want to go to the park’. Lily says</li>
</ul>
<p>I followed a similar process for plot prompts:</p>
<ul>
<li>Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend’s house, she realized she’s starting to feel sick. She was so weak she could</li>
<li>One day a girl walked into the living room and noticed something very strange. There was a huge cabinet standing in the corner. It looked very old and heavy. She walked over and tried to open it, when suddenly</li>
<li>Once upon a time, there lived a hamster in the forest. Every day, he would walked around the forest looking for adventures. One day, he heard someone calling out from behind the bushes. The hamster listened carefully. He realised that it was a small mouse calling out for help. It got stuck under a heavy log and couldn’t get out. The hamster immediately realized that</li>
<li>Alice walked into the kitchen and saw Ben who was looking for something but looked frustrated. She said, “Ben, why are you</li>
</ul>
<p>And creativity:</p>
<ul>
<li>One day a girl walked into the living room and noticed something very strange. There was a huge cabinet standing in the corner. It looked very old and heavy. She walked over and tried to open it, when suddenly</li>
<li>Once upon a time, there was tiger who liked to play the guitar. One day, a bunny heard the guitar from a distance and</li>
<li>One day, a bird was flying high over the sea. At some point the bird noticed small boat with a boy sitting inside. The boy looked lost so</li>
</ul>
<p>I used most of the original 44 prompts for context-tracking, and sampled 5 from each of the non-Grammar categories for Grammar.</p>
</section>
<section id="current-evaluation-prompt-set" class="level2">
<h2 class="anchored" data-anchor-id="current-evaluation-prompt-set">Current Evaluation Prompt Set</h2>
<p>My final evaluation set includes: - 25 unique prompts for Reasoning - 25 unique prompts for Factual Knowledge - 25 prompts each for Context-Tracking, Plot, and Creativity (with some overlap) - 25 prompts for Grammar (5 prompts sampled from the other 5 categories)</p>
<p>This gives me a total of 150 prompts—significantly more than the original 44, but with targeted coverage of each capability.</p>
</section>
<section id="scoring-category-rubrics" class="level2">
<h2 class="anchored" data-anchor-id="scoring-category-rubrics">Scoring Category Rubrics</h2>
<p>For each scoring category, I developed specific rubrics, taking many of them wholesale from the TinyHackathon competition I recently participated in:</p>
<section id="grammar" class="level3">
<h3 class="anchored" data-anchor-id="grammar">Grammar</h3>
<ul>
<li>Dialogue formatting and punctuation</li>
<li>Tense consistency throughout the narrative</li>
<li>Sentence structure logic, clarity and completion</li>
<li>Age-appropriate vocabulary usage</li>
<li>Proper use of pronouns and referents</li>
</ul>
</section>
<section id="creativity" class="level3">
<h3 class="anchored" data-anchor-id="creativity">Creativity</h3>
<ul>
<li>Does the completion offer unexpected or novel elements?</li>
<li>Are character behavioral and emotional responses predictable or innovative?</li>
<li>Does the story rely on cliches or create fresh situations?</li>
<li>Does the writer add unique details to the story world?</li>
</ul>
</section>
<section id="plot" class="level3">
<h3 class="anchored" data-anchor-id="plot">Plot</h3>
<ul>
<li>Is there a clear beginning, middle, and end appropriate to age level?</li>
<li>Are conflicts addressed rather than abandoned?</li>
<li>Is the pacing appropriate (not too rushed or dragging)?</li>
<li>Does the story maintain focus on the central conflict/theme without random diversions?</li>
</ul>
</section>
<section id="factual-knowledge" class="level3">
<h3 class="anchored" data-anchor-id="factual-knowledge">Factual Knowledge</h3>
<ul>
<li>Completion contains only correct factual information relevant to the prompt</li>
</ul>
</section>
</section>
<section id="reasoning" class="level2">
<h2 class="anchored" data-anchor-id="reasoning">Reasoning</h2>
<ul>
<li>Completion demonstrates correct logical reasoning relevant to the prompt</li>
</ul>
<section id="context-tracking" class="level3">
<h3 class="anchored" data-anchor-id="context-tracking">Context-Tracking</h3>
<ul>
<li>Competion maintains complete coherence with prompt</li>
<li>Correctly references/tracks all objects, characters, and their attributes</li>
<li>Maintains consistent narrative flow</li>
</ul>
<p>Notice that different categories have different numbers of criteria:</p>
<ul>
<li>Grammar: 5 criteria</li>
<li>Creativity: 4 criteria</li>
<li>Plot: 4 criteria</li>
<li>Context-tracking: 3 criteria</li>
<li>Factual knowledge: 1 criterion</li>
<li>Reasoning: 1 criterion</li>
</ul>
<p>This means raw scores aren’t directly comparable across categories, which will require normalization during analysis.</p>
</section>
</section>
<section id="llm-judge-prompt-template" class="level2">
<h2 class="anchored" data-anchor-id="llm-judge-prompt-template">LLM Judge Prompt Template</h2>
<p>Instead of using one prompt for all categories, I created a specific judge prompt template for each category:</p>
<pre><code>&lt;instruction-prompt id="Evaluation"&gt;
&lt;instruction&gt;
You are an expert evaluator for tiny language models trained on children's stories. Your task is to score the given model completion (generated using the provided prompt) using the rubric below. Provide a detailed assessment followed by a final total score.
&lt;/instruction&gt;

&lt;rubric&gt;
&lt;criteria&gt;
&lt;criterion id="A"&gt;&lt;/criterion&gt;
&lt;criterion id="B"&gt;&lt;/criterion&gt;
&lt;criterion id="C"&gt;&lt;/criterion&gt;
&lt;criterion id="D"&gt;&lt;/criterion&gt;
&lt;criterion id="E"&gt;&lt;/criterion&gt;
&lt;/criteria&gt;

&lt;scoring-scale&gt;
&lt;level value="1.0"&gt;Criterion is fully satisfied&lt;/level&gt;
&lt;level value="0.5"&gt;Criterion is partially satisfied&lt;/level&gt;
&lt;level value="0.0"&gt;Criterion is not satisfied&lt;/level&gt;
&lt;/scoring-scale&gt;

&lt;scoring-instructions&gt;
For each criterion A-E, assign a score of 1.0, 0.5, or 0.0 based on how well the completion satisfies that criterion. The final score is the sum of all criterion scores.
&lt;/scoring-instructions&gt;
&lt;/rubric&gt;

&lt;generation-prompt&gt;
{prompt}
&lt;/generation-prompt&gt;

&lt;completion&gt;
{completion}
&lt;/completion&gt;

&lt;response-format&gt;
Provide your assessment of each criterion with specific examples from the text, then calculate the final score (sum of all criterion scores).

Format your response as:
&lt;evaluation&gt;
&lt;criterion-A-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-A-score&gt;
&lt;criterion-A-explanation&gt;Your explanation here&lt;/criterion-A-explanation&gt;

&lt;criterion-B-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-B-score&gt;
&lt;criterion-B-explanation&gt;Your explanation here&lt;/criterion-B-explanation&gt;

&lt;criterion-C-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-C-score&gt;
&lt;criterion-C-explanation&gt;Your explanation here&lt;/criterion-C-explanation&gt;

&lt;criterion-D-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-D-score&gt;
&lt;criterion-D-explanation&gt;Your explanation here&lt;/criterion-D-explanation&gt;

&lt;criterion-E-score&gt;[0.0, 0.5, or 1.0]&lt;/criterion-E-score&gt;
&lt;criterion-E-explanation&gt;Your explanation here&lt;/criterion-E-explanation&gt;

&lt;final-score&gt;[Sum of all criterion scores, between #.# and #.#]&lt;/final-score&gt;
&lt;/evaluation&gt;
&lt;/response-format&gt;
&lt;/instruction-prompt&gt;</code></pre>
<p>The template includes:</p>
<ul>
<li>Instructions for the judge</li>
<li>Criteria specific to the category being evaluated</li>
<li>Scoring scale (0, 0.5, 1.0)</li>
<li>Scoring instructions</li>
<li>Response format</li>
</ul>
</section>
<section id="initial-testing" class="level2">
<h2 class="anchored" data-anchor-id="initial-testing">Initial Testing</h2>
<p>I tested the approach with Claude Haiku 3.5, and the results were promising. When evaluating grammar, it gave a weaker model a score of 3.5/5. When I gave it a larger model’s completion, it scored it 5/5. This suggests the approach can successfully differentiate between model capabilities.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<p>My immediate next steps are:</p>
<ol type="1">
<li>Generate 150 completions, one for each the 150 prompts, per TinyStories model (1M, 8M, 28M).</li>
<li>Build an evaluation interface to help grade model responses using FastHTML.</li>
<li>Score all completions using the 0/0.5/1.0 methodology.</li>
<li>Compare results with the targets from the Tiny Stories paper.</li>
<li>Refine scoring rubric if needed.</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="6.png" class="lightbox" data-gallery="quarto-lightbox-gallery-6" title="Evaluation Interface Mockup"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/6.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Evaluation Interface Mockup</figcaption><p></p>
</figure>
</div>
<p>I expect this to take several days as generating completions, building the interface, and evaluating 450 prompts (150 for each of three models) is no small task! Thankfully, it’s terribly large either.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The journey from a simple plan to use 44 prompts to a comprehensive evaluation approach with 150 category-specific prompts shows how even “squishy” concepts like language can be systematically evaluated with the right structure.</p>
<p>By distinguishing between capabilities that need to be isolated (factual knowledge, reasoning, context-tracking) and those that need opportunities to be exhibited (creativity and plot), I’ve created what I believe is a robust evaluation methodology. Obviously, time, very quickly and definitely, will tell.</p>
<p>I’m excited to see if this approach gives me scores comparable to those in the Tiny Stories paper. Stay tuned for the results!</p>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/index.html</guid>
  <pubDate>Mon, 28 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-04-28-TSL-Curating-Eval-Prompts/1.png" medium="image" type="image/png" height="46" width="144"/>
</item>
<item>
  <title>TinyScaleLab Update: Training Cost Analysis and Evaluation Infrastructure Plans</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-27-TSL-Initial-Training-Runs/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this notebook I’ll share results from some quick and dirty training runs executed so I get a rough but reasonable estimate of training time and costs using L4 and A100 GPUs on Google Colab Pro.</p>
</section>
<section id="model-sizes" class="level2">
<h2 class="anchored" data-anchor-id="model-sizes">Model Sizes</h2>
<p>In these experiments, I’m training four model sizes: 5M, 25M, 60M and 125M. I’ve chosen to roughly follow the TinyStories models, using the hidden dimension and intermediate dimension for the TinyStories-1M, -8M, -28M and -33M models, in each case there is a 4x increase from hidden to intermediate dimension in the MLP layers. These are just initial architectural choices which might change over the course of the project as I learn more about what results in a better performing model.</p>
<p>For now, I’m using 8 attention heads (for all models) and the Llama-2 tokenizer with a 32000 vocab size.</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Intermediate Dim</th>
<th style="text-align: center;">Number of Layers</th>
<th style="text-align: center;">Number of Params</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">4_949_696</td>
</tr>
<tr class="even">
<td style="text-align: center;">25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">24_776_960</td>
</tr>
<tr class="odd">
<td style="text-align: center;">60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">57_940_480</td>
</tr>
<tr class="even">
<td style="text-align: center;">125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">124_662_528</td>
</tr>
</tbody>
</table>
</section>
<section id="training-dataset" class="level2">
<h2 class="anchored" data-anchor-id="training-dataset">Training Dataset</h2>
<p>I’ve tokenized the <a href="https://huggingface.co/datasets/roneneldan/TinyStories/blob/main/TinyStories_all_data.tar.gz">TinyStories_all_data.tar.gz</a> dataset which contains 4.9M stories generated by GPT3.5 and GPT4, using the <code>meta-llama/Llama-2-7b-hf</code> tokenizer. I haven’t performed any data cleaning (yet). The total number of tokens in this dataset is little over 1B: <strong>1_028_013_532</strong>.</p>
</section>
<section id="training-duration" class="level2">
<h2 class="anchored" data-anchor-id="training-duration">Training Duration</h2>
<p>I’m training all initial runs for 1 epoch.</p>
</section>
<section id="training-gpus" class="level2">
<h2 class="anchored" data-anchor-id="training-gpus">Training GPUs</h2>
<p>I trained the 5M and 25M models on both L4 (22.5 GB VRAM) and A100 (40GB VRAM) GPUs. I trained the 60M and 125M models on the A100 GPU.</p>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>All models are trained for 1 epoch (1.03 tokens):</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Hardware</th>
<th style="text-align: center;">Model Size</th>
<th style="text-align: center;">Time (hr)</th>
<th style="text-align: center;">Batch Size</th>
<th style="text-align: center;">Max Memory</th>
<th style="text-align: center;">Cost</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">L4</td>
<td style="text-align: center;">5M</td>
<td style="text-align: center;">0.87</td>
<td style="text-align: center;">384</td>
<td style="text-align: center;">20%</td>
<td style="text-align: center;">$0.18</td>
</tr>
<tr class="even">
<td style="text-align: center;">L4</td>
<td style="text-align: center;">25M</td>
<td style="text-align: center;">1.45</td>
<td style="text-align: center;">288</td>
<td style="text-align: center;">65%</td>
<td style="text-align: center;">$0.30</td>
</tr>
<tr class="odd">
<td style="text-align: center;">A100-40GB</td>
<td style="text-align: center;">5M</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">78%</td>
<td style="text-align: center;">$0.25</td>
</tr>
<tr class="even">
<td style="text-align: center;">A100-40GB</td>
<td style="text-align: center;">25M</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">1536</td>
<td style="text-align: center;">98%</td>
<td style="text-align: center;">$0.27</td>
</tr>
<tr class="odd">
<td style="text-align: center;">A100-40GB</td>
<td style="text-align: center;">60M</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">1152</td>
<td style="text-align: center;">86%</td>
<td style="text-align: center;">$0.41</td>
</tr>
<tr class="even">
<td style="text-align: center;">A100-40GB</td>
<td style="text-align: center;">125M</td>
<td style="text-align: center;">1.10</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">99%</td>
<td style="text-align: center;">$0.84</td>
</tr>
</tbody>
</table>
</section>
<section id="takeaways" class="level2">
<h2 class="anchored" data-anchor-id="takeaways">Takeaways</h2>
<p>From this analysis, only the 5M model makes sense to train on the L4. It’s 3 cents cheaper per hour to train the 25M model on the A100, though I’m flirting with OOM so I should reduce the batch size.</p>
<p>I’ll need to perform longer trainings to get a sense of how many full epochs I need to produce coherent language-generating models, but from my TinyHackathon experience, it took 20 epochs for the 60M model to perform decently (3/5 LLM Judge overall score). I would expect the 125M model to require less epochs, and the smaller models more epochs, to achieve comparable performance. But we’ll see!</p>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<p>Here are the <code>LlamaConfig</code> objects for each model:</p>
<section id="m" class="level3">
<h3 class="anchored" data-anchor-id="m">5M</h3>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">config <span class="op" style="color: #5E5E5E;">=</span> LlamaConfig(</span>
<span id="cb1-2">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>,</span>
<span id="cb1-3">    hidden_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">64</span>,</span>
<span id="cb1-4">    intermediate_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>,</span>
<span id="cb1-5">    num_hidden_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">13</span>,</span>
<span id="cb1-6">    num_attention_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb1-7">    max_position_embeddings<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb1-8">    rope_theta<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10000.0</span>,</span>
<span id="cb1-9">    attention_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb1-10">    mlp_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb1-11">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb1-12">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"bfloat16"</span></span>
<span id="cb1-13">)</span></code></pre></div>
</section>
<section id="m-1" class="level3">
<h3 class="anchored" data-anchor-id="m-1">25M</h3>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">config <span class="op" style="color: #5E5E5E;">=</span> LlamaConfig(</span>
<span id="cb2-2">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>,</span>
<span id="cb2-3">    hidden_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>,</span>
<span id="cb2-4">    intermediate_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1024</span>,</span>
<span id="cb2-5">    num_hidden_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb2-6">    num_attention_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb2-7">    max_position_embeddings<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb2-8">    rope_theta<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10000.0</span>,</span>
<span id="cb2-9">    attention_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb2-10">    mlp_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb2-11">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb2-12">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"bfloat16"</span></span>
<span id="cb2-13">)</span></code></pre></div>
</section>
<section id="m-2" class="level3">
<h3 class="anchored" data-anchor-id="m-2">60M</h3>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">config <span class="op" style="color: #5E5E5E;">=</span> LlamaConfig(</span>
<span id="cb3-2">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>,</span>
<span id="cb3-3">    hidden_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb3-4">    intermediate_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2048</span>,</span>
<span id="cb3-5">    num_hidden_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">6</span>,</span>
<span id="cb3-6">    num_attention_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb3-7">    max_position_embeddings<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb3-8">    rope_theta<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10000.0</span>,</span>
<span id="cb3-9">    attention_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb3-10">    mlp_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb3-11">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb3-12">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"bfloat16"</span></span>
<span id="cb3-13">)</span></code></pre></div>
</section>
<section id="m-3" class="level3">
<h3 class="anchored" data-anchor-id="m-3">125M</h3>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">config <span class="op" style="color: #5E5E5E;">=</span> LlamaConfig(</span>
<span id="cb4-2">    vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">32000</span>,</span>
<span id="cb4-3">    hidden_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">768</span>,</span>
<span id="cb4-4">    intermediate_size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3072</span>,</span>
<span id="cb4-5">    num_hidden_layers<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb4-6">    num_attention_heads<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">8</span>,</span>
<span id="cb4-7">    max_position_embeddings<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">512</span>,</span>
<span id="cb4-8">    rope_theta<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">10000.0</span>,</span>
<span id="cb4-9">    attention_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb4-10">    mlp_bias<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>,</span>
<span id="cb4-11">    attn_implementation<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"flash_attention_2"</span>,</span>
<span id="cb4-12">    torch_dtype<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"bfloat16"</span></span>
<span id="cb4-13">)</span></code></pre></div>


</section>
</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-27-TSL-Initial-Training-Runs/index.html</guid>
  <pubDate>Sun, 27 Apr 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TinyScale Lab Update: Setting Eval Targets and Generating Completions for LLM Judge Development</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-27-TSL-Setting-Eval-Targets/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this notebook I’m going to generate story completions using the TinyStories 1M, 8M, 28M models. The actual HF model size for these models is 3.7M, 19.7M and 52M, respectively. Since I’m training 5M, 25M, 60M and 125M models, these three TinyStories models will serve as proxies for my first three sizes, and I will expect my 125M model to generate stories that receive higher scores than my 60M (by how much higher is TBD).</p>
<p>Ronen Eldan, the TinyStories paper author, has listed on <a href="https://huggingface.co/roneneldan/TinyStories-33M/discussions/9#64f94b050a2884a831b29eb6">this HF model card discussion forum</a>:</p>
<blockquote class="blockquote">
<p>we used temp=0, beams=5</p>
</blockquote>
<p>So I’ll be using those two settings during inference.</p>
<p>Here are some key architectural details for my initial quick-and-dirty models:</p>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Intermediate Dim</th>
<th style="text-align: center;">Number of Layers</th>
<th style="text-align: center;">Number of Params</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">4_949_696</td>
</tr>
<tr class="even">
<td style="text-align: center;">25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">24_776_960</td>
</tr>
<tr class="odd">
<td style="text-align: center;">60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">57_940_480</td>
</tr>
<tr class="even">
<td style="text-align: center;">125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">124_662_528</td>
</tr>
</tbody>
</table>
<p>Here are my initial scoring categories, based on type of language model capability:</p>
<ul>
<li><strong>Foundational language capabilities</strong>: Grammar and Context-Tracking (Consistency)</li>
<li><strong>Emergent capabilities</strong>: Factual Knowledge, Reasoning, Creativity</li>
<li><strong>Story-related capabilities</strong>: Plot</li>
</ul>
<p>Referencing Figure 4 in the <a href="https://arxiv.org/abs/2305.07759">TinyStories paper</a> I would expect to achieve LLM Judge for these models close to the following (TSL = TinyScale Lab):</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Similar to</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Num Layers</th>
<th style="text-align: center;">Eval Loss</th>
<th style="text-align: center;">Creativity</th>
<th style="text-align: center;">Grammar</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Plot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">TSL-5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">2.02</td>
<td style="text-align: center;">4.84</td>
<td style="text-align: center;">6.19</td>
<td style="text-align: center;">4.75</td>
<td style="text-align: center;">4.39</td>
</tr>
<tr class="even">
<td style="text-align: center;">TSL-25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.38</td>
<td style="text-align: center;">6.54</td>
<td style="text-align: center;">7.72</td>
<td style="text-align: center;">8.02</td>
<td style="text-align: center;">7.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;">TSL-60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">Average of 4 and 8 scores</td>
<td style="text-align: center;">1.23</td>
<td style="text-align: center;">6.8</td>
<td style="text-align: center;">8.35</td>
<td style="text-align: center;">8.7</td>
<td style="text-align: center;">7.31</td>
</tr>
<tr class="even">
<td style="text-align: center;">TSL-125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.18</td>
<td style="text-align: center;">7.02</td>
<td style="text-align: center;">8.62</td>
<td style="text-align: center;">9.34</td>
<td style="text-align: center;">7.34</td>
</tr>
</tbody>
</table>
<p>Mapping the Figure 4 scores to the official 1M, 8M and 28M models directly:</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">TinyStories</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Num Layers</th>
<th style="text-align: center;">Eval Loss</th>
<th style="text-align: center;">Creativity</th>
<th style="text-align: center;">Grammar</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Plot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">2.08</td>
<td style="text-align: center;">4.68</td>
<td style="text-align: center;">6.14</td>
<td style="text-align: center;">4.45</td>
<td style="text-align: center;">4.40</td>
</tr>
<tr class="even">
<td style="text-align: center;">8M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.38</td>
<td style="text-align: center;">6.54</td>
<td style="text-align: center;">7.72</td>
<td style="text-align: center;">8.02</td>
<td style="text-align: center;">7.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;">28M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.20</td>
<td style="text-align: center;">6.85</td>
<td style="text-align: center;">8.34</td>
<td style="text-align: center;">8.95</td>
<td style="text-align: center;">7.26</td>
</tr>
</tbody>
</table>
<p>The two scoring categories I’m using that are not assessed quantitatively in the TinyStories paper: Factual Knowledge and Reasoning. If my LLM Judge scores match Figure 4 for the other four categories and match my manual evaluations for all six categories, I should expect the LLM Judge to assess these two categories correctly.</p>
</section>
<section id="evaluation-prompts" class="level2">
<h2 class="anchored" data-anchor-id="evaluation-prompts">Evaluation Prompts</h2>
<p>Lucky for me, the TinyStories authors have published their <a href="https://huggingface.co/datasets/roneneldan/TinyStories/blob/main/Evaluation%20prompts.yaml">evaluation prompts</a>.</p>
<div class="cell" data-outputid="6457a149-b8a1-44fe-9171-592115dbf3af" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> requests</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> yaml</span>
<span id="cb1-3">url <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"https://huggingface.co/datasets/roneneldan/TinyStories/raw/main/Evaluation%20prompts.yaml"</span></span>
<span id="cb1-4">response <span class="op" style="color: #5E5E5E;">=</span> requests.get(url)</span>
<span id="cb1-5">data <span class="op" style="color: #5E5E5E;">=</span> yaml.safe_load(response.text)</span>
<span id="cb1-6"><span class="bu" style="color: null;">len</span>(data)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>44</code></pre>
</div>
</div>
<div class="cell" data-outputid="c65bbed1-af12-43b2-98a4-a8a702fa16e4" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">data[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could"</code></pre>
</div>
</div>
</section>
<section id="generating-story-completions" class="level2">
<h2 class="anchored" data-anchor-id="generating-story-completions">Generating Story Completions</h2>
<p>I’ll walk through some basic generation code to make sure it works before I apply it to the full dataset.</p>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoTokenizer, AutoModelForCausalLM</span>
<span id="cb5-2"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb5-3"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(<span class="st" style="color: #20794D;">"roneneldan/TinyStories-1M"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb6-2">tokz <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(<span class="st" style="color: #20794D;">"roneneldan/TinyStories-1M"</span>)</span>
<span id="cb6-3">tokz.pad_token_id</span></code></pre></div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">tokz.pad_token <span class="op" style="color: #5E5E5E;">=</span> tokz.eos_token</span></code></pre></div>
</div>
<p>To my knowledge, you want tokz.padding_side to be “left” during batched inference, and the default here is “right”. Examples of difference shown for batched prompts. Padding right starts the next token prediction with the pad token, padding left with the last tok in prompt.</p>
<div class="cell" data-outputid="91b9d304-8ca3-4080-a601-60ec83e1e0a6" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">tokz.bos_token_id, tokz.eos_token_id, tokz.pad_token_id, tokz.padding_side</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>(50256, 50256, 50256, 'right')</code></pre>
</div>
</div>
<div class="cell" data-outputid="cf22cd11-a1b7-4458-e2f4-a8fc94b411b1" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">inputs <span class="op" style="color: #5E5E5E;">=</span> tokz(data, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb10-2">tokz.decode(inputs.input_ids[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>"Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;"</code></pre>
</div>
</div>
<div class="cell" data-outputid="bb4b5968-acbe-43dc-a4dc-952fad6e2b5c" data-execution_count="10">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">tokz.padding_side <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"left"</span></span>
<span id="cb12-2">inputs <span class="op" style="color: #5E5E5E;">=</span> tokz(data, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb12-3">tokz.decode(inputs.input_ids[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>"&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;&lt;|endoftext|&gt;Once upon a time, there lived a bunny in a field. Her name was Lucy. Lucy loved to have feasts and parties with her bunny friends. One day, when Lucy was about to leave for a feast at a friend's house, she realized she's starting to feel sick. She was so weak she could"</code></pre>
</div>
</div>
<div class="cell" data-outputid="8cab2d05-e8e7-4b77-e76c-5b1df238f698" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">inputs.input_ids[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
        50256, 50256, 50256, 50256, 50256,  7454,  2402,   257,   640,    11,
          612,  5615,   257, 44915,   287,   257,  2214,    13,  2332,  1438,
          373, 22162,    13, 22162,  6151,   284,   423,   730,  5773,   290,
         4671,   351,   607, 44915,  2460,    13,  1881,  1110,    11,   618,
        22162,   373,   546,   284,  2666,   329,   257, 26951,   379,   257,
         1545,   338,  2156,    11,   673,  6939,   673,   338,  3599,   284,
         1254,  6639,    13,  1375,   373,   523,  4939,   673,   714],
       device='cuda:0')</code></pre>
</div>
</div>
<div class="cell" data-outputid="947c8522-53fd-489f-e333-d53212214fb0" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">inputs.attention_mask[<span class="dv" style="color: #AD0000;">0</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>torch.Size([119])</code></pre>
</div>
</div>
<p>Reusing the generation code I used for the TinyHackthon competition, but setting <code>do_sample=False</code> and <code>num_beams=5</code>:</p>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="kw" style="color: #003B4F;">def</span> _generate(model, prompts, max_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">384</span>, min_length<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">120</span>):</span>
<span id="cb18-2">    tokz.padding_side <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"left"</span></span>
<span id="cb18-3">    inputs <span class="op" style="color: #5E5E5E;">=</span> tokz(prompts, padding<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb18-4"></span>
<span id="cb18-5">    model.<span class="bu" style="color: null;">eval</span>()</span>
<span id="cb18-6">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb18-7">        outputs <span class="op" style="color: #5E5E5E;">=</span> model.generate(</span>
<span id="cb18-8">            inputs.input_ids,</span>
<span id="cb18-9">            attention_mask<span class="op" style="color: #5E5E5E;">=</span>inputs.attention_mask,</span>
<span id="cb18-10">            max_length<span class="op" style="color: #5E5E5E;">=</span>max_length,</span>
<span id="cb18-11">            min_length<span class="op" style="color: #5E5E5E;">=</span>min_length,</span>
<span id="cb18-12">            num_beams<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>,</span>
<span id="cb18-13">            do_sample<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>,</span>
<span id="cb18-14">            pad_token_id<span class="op" style="color: #5E5E5E;">=</span>tokz.eos_token_id</span>
<span id="cb18-15">        )</span>
<span id="cb18-16"></span>
<span id="cb18-17">        input_length <span class="op" style="color: #5E5E5E;">=</span> inputs.input_ids[<span class="dv" style="color: #AD0000;">0</span>].size(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb18-18">        completion_tokens <span class="op" style="color: #5E5E5E;">=</span> outputs[<span class="dv" style="color: #AD0000;">0</span>][input_length:]</span>
<span id="cb18-19">        completion_text <span class="op" style="color: #5E5E5E;">=</span> tokz.decode(completion_tokens, skip_special_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb18-20"></span>
<span id="cb18-21">        completions <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb18-22"></span>
<span id="cb18-23">        <span class="cf" style="color: #003B4F;">for</span> j, output <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(outputs):</span>
<span id="cb18-24">            input_length <span class="op" style="color: #5E5E5E;">=</span> inputs.input_ids[j].size(<span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb18-25">            completion_tokens <span class="op" style="color: #5E5E5E;">=</span> output[input_length:]</span>
<span id="cb18-26">            completion_text <span class="op" style="color: #5E5E5E;">=</span> tokz.decode(completion_tokens, skip_special_tokens<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb18-27">            completions.append(completion_text)</span>
<span id="cb18-28"></span>
<span id="cb18-29">        <span class="cf" style="color: #003B4F;">assert</span> outputs.shape[<span class="dv" style="color: #AD0000;">0</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(prompts)</span>
<span id="cb18-30">        <span class="cf" style="color: #003B4F;">assert</span> outputs.shape[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">==</span> max_length</span>
<span id="cb18-31">        <span class="cf" style="color: #003B4F;">assert</span> <span class="bu" style="color: null;">len</span>(completions) <span class="op" style="color: #5E5E5E;">==</span> <span class="bu" style="color: null;">len</span>(prompts)</span>
<span id="cb18-32">        <span class="cf" style="color: #003B4F;">return</span> completions</span>
<span id="cb18-33"></span>
<span id="cb18-34">completions <span class="op" style="color: #5E5E5E;">=</span> _generate(model, data)</span></code></pre></div>
</div>
<div class="cell" data-outputid="5bb67862-93ee-47f1-ff95-0996af4f1843" data-execution_count="41">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="bu" style="color: null;">print</span>(completions[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> not sleep.

Lucy asked her mom, "What's wrong, Mommy?" Her mom replied, "It's okay, sweetie. I'll help you."

Lucy smiled and said, "I'm sorry, Mommy. I'll help you." Her mom smiled and said, "It's okay, Lucy. I'm glad you're safe."

Lucy smiled and said, "Thank you, Mommy. I love you." Her mom smiled and said, "I love you too, Lucy."
</code></pre>
</div>
</div>
<div class="cell" data-outputid="c303089b-c591-4950-c77a-9f0b9ba2a294" data-execution_count="42">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="bu" style="color: null;">print</span>(completions[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> go to the hospital. The little boy was very sad and he didn't want to go to the hospital. 

His mom said, "Don't worry, I'll help you." But the little boy didn't listen. He said, "I'm sorry, mom. I won't do it again." 

His mom smiled and said, "It's okay, I'll help you." 

The little boy was so happy and thanked his mom. From that day on, he always made sure to always be careful when playing outside.
</code></pre>
</div>
</div>
<div class="cell" data-outputid="1e8db0c5-13bc-4dee-b57e-1f6088dee7e6" data-execution_count="43">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="bu" style="color: null;">print</span>(completions[<span class="dv" style="color: #AD0000;">22</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> room. 

The little girl asked her daddy, "Daddy, can you help me?" 

Daddy said, "Yes, I can help you." 

The little girl was so happy. She said, "Thank you, Daddy!" 

Daddy smiled and said, "You're welcome, sweetheart. I'm glad you're safe." 

The little girl smiled and said, "Thank you, Daddy!"

Daddy smiled and said, "You're welcome, sweetheart. I'm glad you're safe." 

The little girl smiled and said, "I'm glad you're safe."
</code></pre>
</div>
</div>
<p>I’ll now iterate through a list of all three models, generate story completions, and save it to CSV for evaluation.</p>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">model_names <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">"roneneldan/TinyStories-1M"</span>, <span class="st" style="color: #20794D;">"roneneldan/TinyStories-8M"</span>, <span class="st" style="color: #20794D;">"roneneldan/TinyStories-28M"</span>]</span></code></pre></div>
</div>
<div class="cell" data-outputid="856cc1fd-21ca-4452-a8d1-afd4664a0f18" data-execution_count="52">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame({<span class="st" style="color: #20794D;">"prompt"</span>: data, <span class="st" style="color: #20794D;">"1M"</span>: [<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span><span class="bu" style="color: null;">len</span>(data), <span class="st" style="color: #20794D;">"8M"</span>: [<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span><span class="bu" style="color: null;">len</span>(data), <span class="st" style="color: #20794D;">"28M"</span>: [<span class="va" style="color: #111111;">None</span>]<span class="op" style="color: #5E5E5E;">*</span><span class="bu" style="color: null;">len</span>(data)})</span>
<span id="cb26-2">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">


  <div id="df-d3226fdd-e225-4ef3-a087-845fa3564beb" class="colab-df-container">
    <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>prompt</th>
      <th>1M</th>
      <th>8M</th>
      <th>28M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Once upon a time, there lived a bunny in a fie...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>1</th>
      <td>One day a girl walked into the living room and...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Once upon a time, there lived a hamster in the...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jack asked his mom if he could ride the bike a...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Alice was bored and wanted to find some advent...</td>
      <td>None</td>
      <td>None</td>
      <td>None</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-d3226fdd-e225-4ef3-a087-845fa3564beb')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-d3226fdd-e225-4ef3-a087-845fa3564beb button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-d3226fdd-e225-4ef3-a087-845fa3564beb');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-1cd2bf3d-8fce-4357-9c1a-a3becd941453">
      <button class="colab-df-quickchart" onclick="quickchart('df-1cd2bf3d-8fce-4357-9c1a-a3becd941453')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-1cd2bf3d-8fce-4357-9c1a-a3becd941453 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="cf" style="color: #003B4F;">for</span> name <span class="kw" style="color: #003B4F;">in</span> model_names:</span>
<span id="cb27-2">    model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(name).to(<span class="st" style="color: #20794D;">"cuda"</span>)</span>
<span id="cb27-3">    tokz <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(name)</span>
<span id="cb27-4">    tokz.pad_token <span class="op" style="color: #5E5E5E;">=</span> tokz.eos_token</span>
<span id="cb27-5">    completions <span class="op" style="color: #5E5E5E;">=</span> _generate(model, data)</span>
<span id="cb27-6">    df[name.split(<span class="st" style="color: #20794D;">"-"</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]] <span class="op" style="color: #5E5E5E;">=</span> completions</span></code></pre></div>
</div>
<div class="cell" data-outputid="7a079003-5f3c-4bda-f762-87b14b3f333a" data-execution_count="55">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">


  <div id="df-46266037-47c6-4550-91a9-93f2cb686066" class="colab-df-container">
    <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>prompt</th>
      <th>1M</th>
      <th>8M</th>
      <th>28M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Once upon a time, there lived a bunny in a fie...</td>
      <td>not sleep.\n\nLucy asked her mom, "What's wro...</td>
      <td>hardly move.\n\nLucy's friend, a wise old owl...</td>
      <td>barely move. \n\nLucy's bunny friends noticed...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>One day a girl walked into the living room and...</td>
      <td>, she heard a voice.\n\n"What are you doing he...</td>
      <td>she heard a voice.\n\n"Who are you?" the voic...</td>
      <td>a voice came from behind her.\n\n"What do you...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Once upon a time, there lived a hamster in the...</td>
      <td>it was too late.\n\nThe next day, the hamster...</td>
      <td>the mouse was trying to help him.\n\nThe hams...</td>
      <td>he had to help the mouse.\n\nHe used all his ...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jack asked his mom if he could ride the bike a...</td>
      <td>thank you" to his daughter.\n\nThe next day, J...</td>
      <td>no" and he knew that he had to be careful.\n\n...</td>
      <td>Don't ride too fast, be careful!"\n\nSo Jack s...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Alice was bored and wanted to find some advent...</td>
      <td>go to the park?"\n\nTom said, "I don't want t...</td>
      <td>go on an adventure together?"\n\nBen smiled a...</td>
      <td>go on an adventure?"\n\nBen thought for a mom...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-46266037-47c6-4550-91a9-93f2cb686066')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-46266037-47c6-4550-91a9-93f2cb686066 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-46266037-47c6-4550-91a9-93f2cb686066');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


    <div id="df-de0c88ef-903d-4b9a-9c0a-53db68fe08e1">
      <button class="colab-df-quickchart" onclick="quickchart('df-de0c88ef-903d-4b9a-9c0a-53db68fe08e1')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
      </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

      <script>
        async function quickchart(key) {
          const quickchartButtonEl =
            document.querySelector('#' + key + ' button');
          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
          quickchartButtonEl.classList.add('colab-df-spinner');
          try {
            const charts = await google.colab.kernel.invokeFunction(
                'suggestCharts', [key], {});
          } catch (error) {
            console.error('Error during call to suggestCharts:', error);
          }
          quickchartButtonEl.classList.remove('colab-df-spinner');
          quickchartButtonEl.classList.add('colab-df-quickchart-complete');
        }
        (() => {
          let quickchartButtonEl =
            document.querySelector('#df-de0c88ef-903d-4b9a-9c0a-53db68fe08e1 button');
          quickchartButtonEl.style.display =
            google.colab.kernel.accessAllowed ? 'block' : 'none';
        })();
      </script>
    </div>

    </div>
  </div>
</div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1">df.to_csv(<span class="st" style="color: #20794D;">"2025-04-27-evals.csv"</span>, index<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
</div>
<p>While we’re, I’ll calculat the average prompt and completion length in tokens.</p>
<div class="cell" data-outputid="223dae72-f5c1-45a8-f350-e998d5714008" data-execution_count="57">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">tokz(data[<span class="dv" style="color: #AD0000;">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>{'input_ids': [7454, 2402, 257, 640, 11, 612, 5615, 257, 44915, 287, 257, 2214, 13, 2332, 1438, 373, 22162, 13, 22162, 6151, 284, 423, 730, 5773, 290, 4671, 351, 607, 44915, 2460, 13, 1881, 1110, 11, 618, 22162, 373, 546, 284, 2666, 329, 257, 26951, 379, 257, 1545, 338, 2156, 11, 673, 6939, 673, 338, 3599, 284, 1254, 6639, 13, 1375, 373, 523, 4939, 673, 714], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}</code></pre>
</div>
</div>
<div class="cell" data-outputid="e14c1c7a-3e2e-4a00-91b6-66ab4f19762d" data-execution_count="61">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">toks <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb32-2"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> data: toks <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">len</span>(tokz(p).input_ids)</span>
<span id="cb32-3">toks<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">44</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>62</code></pre>
</div>
</div>
<div class="cell" data-outputid="a64f24ca-762c-4043-a601-d3b5949cc900" data-execution_count="62">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1">toks <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb34-2"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> df[<span class="st" style="color: #20794D;">"1M"</span>]: toks <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">len</span>(tokz(p).input_ids)</span>
<span id="cb34-3">toks<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">44</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>164</code></pre>
</div>
</div>
<div class="cell" data-outputid="eeef388e-08ab-436e-c300-a30cc625ec66" data-execution_count="63">
<div class="sourceCode cell-code" id="cb36" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1">toks <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb36-2"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> df[<span class="st" style="color: #20794D;">"8M"</span>]: toks <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">len</span>(tokz(p).input_ids)</span>
<span id="cb36-3">toks<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">44</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>153</code></pre>
</div>
</div>
<div class="cell" data-outputid="057638d1-c550-43af-ef0c-afd026dd85cc" data-execution_count="64">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">toks <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb38-2"><span class="cf" style="color: #003B4F;">for</span> p <span class="kw" style="color: #003B4F;">in</span> df[<span class="st" style="color: #20794D;">"28M"</span>]: toks <span class="op" style="color: #5E5E5E;">+=</span> <span class="bu" style="color: null;">len</span>(tokz(p).input_ids)</span>
<span id="cb38-3">toks<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">44</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>140</code></pre>
</div>
</div>
<div class="cell" data-outputid="a85210bb-79b9-45c3-fb4a-b1ee8c4a7ca6" data-execution_count="65">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="dv" style="color: #AD0000;">62</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">164</span>, <span class="dv" style="color: #AD0000;">64</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">153</span>, <span class="dv" style="color: #AD0000;">64</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">140</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>(226, 217, 204)</code></pre>
</div>
</div>
<p>The prompt (62) and completions (140, 153, 164) average about 200 tokens in length. This is a different tokenizer than I’m using so results will vary for my trained models</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>I have established two key elements for my evals:</p>
<ul>
<li>Targets based on the literature (for my reference models and experiment models)</li>
</ul>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
<col style="width: 12%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">TinyStories</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Num Layers</th>
<th style="text-align: center;">Eval Loss</th>
<th style="text-align: center;">Creativity</th>
<th style="text-align: center;">Grammar</th>
<th style="text-align: center;">Consistency</th>
<th style="text-align: center;">Plot</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">2.08</td>
<td style="text-align: center;">4.68</td>
<td style="text-align: center;">6.14</td>
<td style="text-align: center;">4.45</td>
<td style="text-align: center;">4.40</td>
</tr>
<tr class="even">
<td style="text-align: center;">8M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.38</td>
<td style="text-align: center;">6.54</td>
<td style="text-align: center;">7.72</td>
<td style="text-align: center;">8.02</td>
<td style="text-align: center;">7.23</td>
</tr>
<tr class="odd">
<td style="text-align: center;">28M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">1.20</td>
<td style="text-align: center;">6.85</td>
<td style="text-align: center;">8.34</td>
<td style="text-align: center;">8.95</td>
<td style="text-align: center;">7.26</td>
</tr>
</tbody>
</table>
<table class="table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Model Name</th>
<th style="text-align: center;">Hidden Dim</th>
<th style="text-align: center;">Intermediate Dim</th>
<th style="text-align: center;">Number of Layers</th>
<th style="text-align: center;">Number of Params</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">5M</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">4_949_696</td>
</tr>
<tr class="even">
<td style="text-align: center;">25M</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;">1024</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">24_776_960</td>
</tr>
<tr class="odd">
<td style="text-align: center;">60M</td>
<td style="text-align: center;">512</td>
<td style="text-align: center;">2048</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">57_940_480</td>
</tr>
<tr class="even">
<td style="text-align: center;">125M</td>
<td style="text-align: center;">768</td>
<td style="text-align: center;">3072</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">124_662_528</td>
</tr>
</tbody>
</table>
<ul>
<li>Generations using reference models for evaluation prompts from literature
<ul>
<li>44 prompts (62 tokens on average)</li>
</ul></li>
</ul>
<p>My next steps:</p>
<ul>
<li>Evaluate a sample of prompts from each model by hand for my six scoring categories:
<ul>
<li><strong>Foundational language capabilities</strong>: Grammar and Context-Tracking (Consistency)</li>
<li><strong>Emergent capabilities</strong>: Factual Knowledge, Reasoning, Creativity</li>
<li><strong>Story-related capabilities</strong>: Plot</li>
</ul></li>
<li>Prompt different LLMs, iterating on prompts until LLM Judge scores match mine 90%+ of the time.</li>
</ul>
<p>Both steps will take considerable, so I’ll break them down to smaller steps and publish blog posts and videos along the way. Make sure to subscribe to my YouTube channel or check the <a href="https://www.youtube.com/playlist?list=PLVaenshL7UUD8iFmDDUpLCcuB-K_72mwI">TinyScale Lab playlist</a> for latest content!</p>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-27-TSL-Setting-Eval-Targets/index.html</guid>
  <pubDate>Sun, 27 Apr 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>TinyScaleLab: Bridging Training Dynamics and Model Capabilities</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/index.html</link>
  <description><![CDATA[ 



<iframe width="560" height="315" src="https://www.youtube.com/embed/82mE39Ef5eY?si=5h9fdvnAF0071VcA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>I’m excited to announce the kickoff of TinyScale Lab, a research project focused on exploring the connection between training dynamics and model capabilities. This research is motivated by two papers that I’ve studied in detail: <a href="https://arxiv.org/abs/2305.07759">“TinyStories: How Small Can Language Models Be and Still Speak Coherent English?” by Ronen Eldan and Yuanzhi Li</a>, and <a href="https://arxiv.org/abs/2309.14322">“Small-scale proxies for Large-scale Transformer Training Instabilities” by Wortsman, et al</a>.</p>
<p>Most LLM training-related research requires computational resources that are financially out of reach for individual researchers or small teams. At the same time, recent work has shown that tiny models exhibit emergent capabilities (as demonstrated in the TinyStories paper) and exhibit large-scale training dynamics (as shown in the Small-scale proxies paper).</p>
<p>While I don’t claim to be creating a definitive blueprint, I believe this approach—using tiny models as proxies to study phenomena relevant to models of all sizes—represents an underexplored path that could benefit other resource-constrained researchers.</p>
<p>I think this is how most of the world’s potential researchers would need to work. Making ML research accessible to resource-constrained environments isn’t trivial - it’s essential for the field’s diversity and progress.</p>
</section>
<section id="research-hypotheses" class="level2">
<h2 class="anchored" data-anchor-id="research-hypotheses">Research Hypotheses</h2>
<p>I’ve developed four main hypotheses that will guide my research:</p>
<ol type="1">
<li><strong>H1</strong>: Training stability directly affects specific model capabilities in predictable ways.</li>
<li><strong>H2</strong>: Different model capabilities (like grammar or consistency) respond differently to training adjustments.</li>
<li><strong>H3</strong>: Early training signals can predict which capabilities a model will or won’t develop before training is complete.</li>
<li><strong>H4</strong>: Techniques that stabilize training will have varying effects on different types of model capabilities.</li>
</ol>
<p>I’ve kept these hypotheses general at a high level because I really don’t know what I’m going to learn, but I do have a sense based on the TinyStories and Small-scale proxies papers that there is something around these four elements that I’m going to experience, and I expect to see some relationships.</p>
<p>I want to bridge the TinyStories paper analysis on emergent capabilities (grammar, consistency, factual knowledge, reasoning, etc.) with the Small-scale proxies paper training dynamics analysis (attention logits, training instabilities, learning rates, etc.).</p>
</section>
<section id="experimental-design" class="level2">
<h2 class="anchored" data-anchor-id="experimental-design">Experimental Design</h2>
<p>For my experimental design, I’ve decided to focus on four model sizes:</p>
<ul>
<li>~3M parameters</li>
<li>~20M parameters</li>
<li>~60M parameters</li>
<li>~120M parameters</li>
</ul>
<p>This follows the TinyStories paper closely, with the addition of a 120M parameter model.</p>
<p>I’ll use the same learning rates as the Small-scale proxies paper, ranging from 3e-4 to 3e-1 with seven learning rates in total: <code>{3e-4, 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1}</code></p>
<p>I’ll implement two stability techniques from the Small-scale proxies paper:</p>
<ul>
<li>QK layer norm (to mitigate attention logit growth)</li>
<li>Z loss (to mitigate output logit divergence)</li>
</ul>
<p>What will remain fixed across all training runs are the datasets, the number of training steps, and other hyperparameters like weight decay and warm-up steps.</p>
<p>The training dynamics I’ll log throughout training include:</p>
<ul>
<li>Logits</li>
<li>Gradients</li>
<li>Parameters</li>
<li>Loss</li>
</ul>
<p>For each of these, I’ll capture norms, means, maximum values, and RMS values.</p>
<p>The capabilities I want to evaluate are split into three categories:</p>
<ol type="1">
<li><strong>Foundational language</strong>: Grammar and context-tracking (consistency)</li>
<li><strong>Emergent capabilities</strong>: Factual knowledge, reasoning, and creativity</li>
<li><strong>Story-related</strong>: Plot</li>
</ol>
<p>The relationship between these training dynamics and capabilities is what I want to explore.</p>
</section>
<section id="success-criteria" class="level2">
<h2 class="anchored" data-anchor-id="success-criteria">Success Criteria</h2>
<p>My success criteria are simple but not easy: establishing clear connections between training dynamics and tiny model capabilities. This work is exploratory, and I’m open to discovering that the relationships might be more complex or different than initially hypothesized.</p>
</section>
<section id="risk-assessment" class="level2">
<h2 class="anchored" data-anchor-id="risk-assessment">Risk Assessment</h2>
<p>I’ve identified several risks that could impact this project:</p>
<ol type="1">
<li>Lack of connection between training dynamics and tiny model capabilities</li>
<li>Technical challenges in monitoring complex training dynamics</li>
<li>Sub-optimal parameter usage</li>
<li>Compute and inference costs ballooning beyond budget</li>
</ol>
</section>
<section id="risk-mitigation" class="level2">
<h2 class="anchored" data-anchor-id="risk-mitigation">Risk Mitigation</h2>
<p>To mitigate these risks, I plan to:</p>
<ol type="1">
<li>Shorten the iteration loop</li>
<li>Ensure evaluations are robust from the start</li>
<li>Start at the tiniest scale and progressively increase model size</li>
<li>Implement early stopping to avoid wasting compute</li>
</ol>
<p>I learned from the fastAI course and community that you want to shorten the iteration loop and ensure that evals are robust from the start. This gives you quick, immediate, robust, clear signal when you get feedback on how your model is performing.</p>
</section>
<section id="deliverables" class="level2">
<h2 class="anchored" data-anchor-id="deliverables">Deliverables</h2>
<p>My commitment is to produce:</p>
<ol type="1">
<li>Comprehensive research repositories including code, trained models, and detailed datasets (training dynamics and LLM Judge scores)</li>
<li>Weekly video content and blog posts</li>
<li>Technical report</li>
<li>Interactive visualizations</li>
</ol>
<p>The main thing I want to emphasize is that I’ll be doing this publicly and open-source. All models, code, and findings will be freely available to enable broader participation in ML research.</p>
</section>
<section id="timeline-and-budget" class="level2">
<h2 class="anchored" data-anchor-id="timeline-and-budget">Timeline and Budget</h2>
<p>I’ve broken the project into four phases:</p>
<ol type="1">
<li><strong>Phase 1</strong>: Eval/Logging Setup, Initial Training Runs (2-3 months)</li>
<li><strong>Phase 2</strong>: Experimental Implementation (3-4 months)</li>
<li><strong>Phase 3</strong>: Analysis &amp; Synthesis (2-3 months)</li>
<li><strong>Phase 4</strong>: Documentation &amp; Finalization (1 month)</li>
</ol>
<p>At minimum, I think this work will take eight months, and it could go well past a year.</p>
<p>For the budget, I’m estimating: - <strong>Training</strong>: $1700 (approximately 100 training runs on 25B tokens) - <strong>Inference</strong>: $200 (using Gemini 2.5 Flash for LLM Judge scoring) - <strong>Total</strong>: $2000</p>
<p>At this point, I’m considering whether it makes sense to buy my own GPU rig. If this is going to cost $2,000, why not spend a little more or twice as much and get a GPU rig that I can own? There are a lot of variables when it comes to budget and timeline, so I’m going to take it one week at a time and make adjustments as necessary.</p>
</section>
<section id="closing-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>To recap, TinyScale Lab aims to:</p>
<ol type="1">
<li>Bridge training dynamics and model capabilities to understand what makes tiny models effective</li>
<li>Create a systematic framework for understanding how training choices affect specific model capabilities</li>
<li>Demonstrate that meaningful ML research is accessible with modest computational resources</li>
<li>Open-source all models, code, and findings to enable broader participation in ML research</li>
</ol>
<p>As Nick Sirianni (championship winning coach of the Philadelphia Eagles) said, “You cannot be great without the greatness of others.” I truly stand on the shoulders of giants, especially the authors of the TinyStories and Small-scale proxies papers. Without their work and contributions in the open source space, I would not be able to even approach this kind of research.</p>
<p>If someone with similar interests sees this work and it inspires them, or they can use something I built that saves them time, saves them money, or gives them insight–that would be the best reward that comes out of this work.</p>
<p>I hope you’ll follow along with this journey. I’ll be keeping everything in the <a href="https://www.youtube.com/playlist?list=PLVaenshL7UUD8iFmDDUpLCcuB-K_72mwI">TinyScale Lab playlist on my YouTube</a> and will tag related posts on my blog.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" title="TinyScale-Lab bridges the gap between tiny model capabilities and training dynamics" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">TinyScale-Lab bridges the gap between tiny model capabilities and training dynamics</figcaption><p></p>
</figure>
</div>


</section>

 ]]></description>
  <category>LLM</category>
  <category>deep learning</category>
  <category>TinyScaleLab</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/index.html</guid>
  <pubDate>Sat, 26 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-04-26-TinyScale-Lab-Kickoff/1.png" medium="image" type="image/png" height="216" width="144"/>
</item>
<item>
  <title>LossInspector: A Deep Dive Into LLM-Foundry’s Next-Token Prediction with a Custom Composer Callback</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-22-LossInspector/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I’m working on a research project where we’ll be fine-tuning small models with various techniques and datasets using LLM-Foundry. As part of our infrastructure setup, we wanted to make sure that we thoroughly understood how a batch of data is prepared by LLM-Foundry, and how the outputs of a model, along with the labels, are passed to the loss function to calculate the loss. To do so, with the help of Claude, I wrote up a custom Composer Callback. This is the third custom callback I’ve written for Composer/LLM-Foundry, you can read more about <a href="https://vishalbakshi.github.io/blog/posts/2025-03-30-Composer-Callback/">my first</a> and <a href="https://vishalbakshi.github.io/blog/posts/2025-04-02-Composer-Callback-Logging-dtypes/">second</a> callbacks.</p>
<p>I was initially going to have two or three callbacks: one to inspect inputs/outputs to the embedding, one to inspect the input/outputs to the model’s forward pass, and one to inspect the loss function. 27 commits later, I had a relatively lean single callback that gave me all the information I needed.</p>
<p>I focused on three events during Composer’s <a href="https://docs.mosaicml.com/projects/composer/en/stable/trainer/events.html">training loop</a>:</p>
<ul>
<li><code>before_loss</code>: to store the “untouched” batch from Composer’s <code>state</code>.</li>
<li><code>before_forward</code>: to store the untouched <code>input_ids</code> and <code>labels</code> from the state’s batch.</li>
<li><code>after_loss</code>: to both capture the calculated loss and “manually” calculate the loss using the model’s loss function.</li>
</ul>
<p>Before we go further into detail, here’s the callback code (and necessary imports):</p>
<p>Here’s my video walkthrough of the code in this notebook:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/9ffnmeiDF_M?si=DVAZhHFDfxkuzG6n" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="lossinspector-callback" class="level2">
<h2 class="anchored" data-anchor-id="lossinspector-callback"><code>LossInspector</code> Callback</h2>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> composer.core.callback <span class="im" style="color: #00769E;">import</span> Callback</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> composer.core <span class="im" style="color: #00769E;">import</span> State</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> composer.loggers <span class="im" style="color: #00769E;">import</span> Logger</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-5"></span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="kw" style="color: #003B4F;">class</span> LossInspector(Callback):       </span>
<span id="cb1-8">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb1-9">        <span class="bu" style="color: null;">super</span>().<span class="fu" style="color: #4758AB;">__init__</span>()</span>
<span id="cb1-10">        <span class="va" style="color: #111111;">self</span>.inspected <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb1-11">        <span class="va" style="color: #111111;">self</span>.input_ids <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb1-12">        <span class="va" style="color: #111111;">self</span>.labels <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb1-13">    </span>
<span id="cb1-14">    <span class="kw" style="color: #003B4F;">def</span> before_loss(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-15">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.inspected:</span>
<span id="cb1-16">            <span class="cf" style="color: #003B4F;">return</span></span>
<span id="cb1-17">        <span class="va" style="color: #111111;">self</span>.state_outputs <span class="op" style="color: #5E5E5E;">=</span> state.outputs</span>
<span id="cb1-18">        <span class="va" style="color: #111111;">self</span>.state_batch <span class="op" style="color: #5E5E5E;">=</span> state.batch</span>
<span id="cb1-19">        </span>
<span id="cb1-20"></span>
<span id="cb1-21">    <span class="kw" style="color: #003B4F;">def</span> before_forward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-22">        <span class="co" style="color: #5E5E5E;"># check that input_ids and labels are the same as after loss</span></span>
<span id="cb1-23">        <span class="va" style="color: #111111;">self</span>.input_ids <span class="op" style="color: #5E5E5E;">=</span> state.batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>].detach().cpu()</span>
<span id="cb1-24">        <span class="va" style="color: #111111;">self</span>.labels <span class="op" style="color: #5E5E5E;">=</span> state.batch[<span class="st" style="color: #20794D;">'labels'</span>][<span class="dv" style="color: #AD0000;">0</span>].detach().cpu()</span>
<span id="cb1-25">    </span>
<span id="cb1-26">    <span class="kw" style="color: #003B4F;">def</span> after_loss(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-27">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.inspected:</span>
<span id="cb1-28">            <span class="cf" style="color: #003B4F;">return</span></span>
<span id="cb1-29">            </span>
<span id="cb1-30">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">=== LOSS CALCULATION INSPECTION ==="</span>)</span>
<span id="cb1-31">        </span>
<span id="cb1-32">        <span class="co" style="color: #5E5E5E;"># Get the framework loss from state</span></span>
<span id="cb1-33">        framework_loss <span class="op" style="color: #5E5E5E;">=</span> state.loss.item()</span>
<span id="cb1-34">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Framework loss: </span><span class="sc" style="color: #5E5E5E;">{</span>framework_loss<span class="sc" style="color: #5E5E5E;">:.6f}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-35">        </span>
<span id="cb1-36">        <span class="co" style="color: #5E5E5E;"># Access model's loss_function directly</span></span>
<span id="cb1-37">        logits <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.state_outputs[<span class="st" style="color: #20794D;">'logits'</span>]</span>
<span id="cb1-38">        labels <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.state_batch[<span class="st" style="color: #20794D;">'labels'</span>]</span>
<span id="cb1-39">        vocab_size <span class="op" style="color: #5E5E5E;">=</span> state.model.model.config.vocab_size</span>
<span id="cb1-40">        </span>
<span id="cb1-41">        direct_loss <span class="op" style="color: #5E5E5E;">=</span> state.model.model.loss_function(</span>
<span id="cb1-42">            logits<span class="op" style="color: #5E5E5E;">=</span>logits,</span>
<span id="cb1-43">            labels<span class="op" style="color: #5E5E5E;">=</span>labels,</span>
<span id="cb1-44">            vocab_size<span class="op" style="color: #5E5E5E;">=</span>vocab_size</span>
<span id="cb1-45">        )</span>
<span id="cb1-46">        </span>
<span id="cb1-47">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Direct call to model.loss_function: </span><span class="sc" style="color: #5E5E5E;">{</span>direct_loss<span class="sc" style="color: #5E5E5E;">.</span>item()<span class="sc" style="color: #5E5E5E;">:.6f}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-48">        </span>
<span id="cb1-49">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">-------- input_ids --------"</span>)</span>
<span id="cb1-50">        input_ids <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.state_batch[<span class="st" style="color: #20794D;">'input_ids'</span>][<span class="dv" style="color: #AD0000;">0</span>].detach().cpu()</span>
<span id="cb1-51">        <span class="bu" style="color: null;">print</span>(input_ids.tolist())</span>
<span id="cb1-52">        decoded_input <span class="op" style="color: #5E5E5E;">=</span> state.model.tokenizer.decode(input_ids)</span>
<span id="cb1-53">        <span class="bu" style="color: null;">print</span>(decoded_input[:<span class="dv" style="color: #AD0000;">1000</span>])</span>
<span id="cb1-54">        </span>
<span id="cb1-55">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">-------- labels --------"</span>)</span>
<span id="cb1-56">        labels <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.state_batch[<span class="st" style="color: #20794D;">'labels'</span>][<span class="dv" style="color: #AD0000;">0</span>].detach().cpu()</span>
<span id="cb1-57">        <span class="bu" style="color: null;">print</span>(labels.tolist())</span>
<span id="cb1-58">        valid_labels <span class="op" style="color: #5E5E5E;">=</span> labels[labels <span class="op" style="color: #5E5E5E;">!=</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">100</span>]</span>
<span id="cb1-59">        decoded_labels <span class="op" style="color: #5E5E5E;">=</span> state.model.tokenizer.decode(valid_labels)</span>
<span id="cb1-60">        <span class="bu" style="color: null;">print</span>(decoded_labels)</span>
<span id="cb1-61"></span>
<span id="cb1-62">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">-------- matches before_forward values? --------"</span>)</span>
<span id="cb1-63">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"input_ids: </span><span class="sc" style="color: #5E5E5E;">{</span>torch<span class="sc" style="color: #5E5E5E;">.</span>allclose(input_ids, <span class="va" style="color: #111111;">self</span>.input_ids)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-64">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"labels: </span><span class="sc" style="color: #5E5E5E;">{</span>torch<span class="sc" style="color: #5E5E5E;">.</span>allclose(labels, <span class="va" style="color: #111111;">self</span>.labels)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb1-65">        </span>
<span id="cb1-66">        <span class="va" style="color: #111111;">self</span>.inspected <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span></code></pre></div>
<p>The callback is then appended to the <code>callbacks</code> list before passed to the Composer trainer.</p>
</section>
<section id="smollm2-135m-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="smollm2-135m-loss-function">SmolLM2-135M Loss Function</h2>
<p>It was surprisingly difficult to inspect the loss function. Or rather my lack of Composer/HuggingFace internals knowledge immediately surfaced with this task! Looking through the Composer GitHub repo and documentation, I found the following references to the model’s loss function—all quite helpful but too general:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">loss <span class="op" style="color: #5E5E5E;">=</span> model.loss(outputs, targets)</span></code></pre></div>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;">for</span> epoch <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(NUM_EPOCHS):</span>
<span id="cb3-2">    <span class="cf" style="color: #003B4F;">for</span> inputs, targets <span class="kw" style="color: #003B4F;">in</span> dataloader:</span>
<span id="cb3-3">        outputs <span class="op" style="color: #5E5E5E;">=</span> model.forward(inputs)</span>
<span id="cb3-4">        loss <span class="op" style="color: #5E5E5E;">=</span> model.loss(outputs, targets)</span>
<span id="cb3-5">        loss.backward()</span>
<span id="cb3-6">        optimizer.step()</span>
<span id="cb3-7">        optimizer.zero_grad()</span></code></pre></div>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;">def</span> loss(<span class="va" style="color: #111111;">self</span>, outputs, batch):</span>
<span id="cb4-2">    <span class="co" style="color: #5E5E5E;"># pass batches and `forward` outputs to the loss</span></span>
<span id="cb4-3">    _, targets <span class="op" style="color: #5E5E5E;">=</span> batch</span>
<span id="cb4-4">    <span class="cf" style="color: #003B4F;">return</span> F.cross_entropy(outputs, targets)</span></code></pre></div>
<p>I looked at their MixUp algorithm’s source code in hopes for more detail but found none—though it did help me confirm how batches are handled:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;">class</span> MixUp(Algorithm):</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;">def</span> match(<span class="va" style="color: #111111;">self</span>, event: Event, state: State) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="bu" style="color: null;">bool</span>:</span>
<span id="cb5-3">        <span class="co" style="color: #5E5E5E;">"""Determines whether the algorithm should run on a given event."""</span></span>
<span id="cb5-4">        <span class="cf" style="color: #003B4F;">return</span> event <span class="kw" style="color: #003B4F;">in</span> [Event.AFTER_DATALOADER, Event.AFTER_LOSS]</span>
<span id="cb5-5"></span>
<span id="cb5-6">    <span class="kw" style="color: #003B4F;">def</span> <span class="bu" style="color: null;">apply</span>(<span class="va" style="color: #111111;">self</span>, event: Event, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb5-7">        <span class="co" style="color: #5E5E5E;">"""Run the algorithm by modifying the State."""</span></span>
<span id="cb5-8">        <span class="bu" style="color: null;">input</span>, target <span class="op" style="color: #5E5E5E;">=</span> state.batch</span>
<span id="cb5-9"></span>
<span id="cb5-10">        <span class="cf" style="color: #003B4F;">if</span> event <span class="op" style="color: #5E5E5E;">==</span> Event.AFTER_DATALOADER:</span>
<span id="cb5-11">            new_input, <span class="va" style="color: #111111;">self</span>.permuted_target, <span class="va" style="color: #111111;">self</span>.mixing <span class="op" style="color: #5E5E5E;">=</span> mixup_batch(<span class="bu" style="color: null;">input</span>, target, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>)</span>
<span id="cb5-12">            state.batch <span class="op" style="color: #5E5E5E;">=</span> (new_input, target)</span>
<span id="cb5-13"></span>
<span id="cb5-14">        <span class="cf" style="color: #003B4F;">if</span> event <span class="op" style="color: #5E5E5E;">==</span> Event.AFTER_LOSS:</span>
<span id="cb5-15">            modified_batch <span class="op" style="color: #5E5E5E;">=</span> (<span class="bu" style="color: null;">input</span>, <span class="va" style="color: #111111;">self</span>.permuted_target)</span>
<span id="cb5-16">            new_loss <span class="op" style="color: #5E5E5E;">=</span> state.model.loss(state.outputs, modified_batch)</span>
<span id="cb5-17">            state.loss <span class="op" style="color: #5E5E5E;">*=</span> (<span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">-</span> <span class="va" style="color: #111111;">self</span>.mixing)</span>
<span id="cb5-18">            state.loss <span class="op" style="color: #5E5E5E;">+=</span> <span class="va" style="color: #111111;">self</span>.mixing <span class="op" style="color: #5E5E5E;">*</span> new_loss</span></code></pre></div>
<p>Looking at Composer’s <code>HuggingFaceModel</code> did not give me the necessary detail, but provided the key for the next step: the loss was stored in <code>outputs</code>.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;">def</span> loss(<span class="va" style="color: #111111;">self</span>, outputs, batch):</span>
<span id="cb6-2">    <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.config.use_return_dict:</span>
<span id="cb6-3">        <span class="cf" style="color: #003B4F;">return</span> outputs[<span class="st" style="color: #20794D;">'loss'</span>]</span>
<span id="cb6-4">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb6-5">        <span class="co" style="color: #5E5E5E;"># loss is at index 0 in the output tuple</span></span>
<span id="cb6-6">        <span class="cf" style="color: #003B4F;">return</span> outputs[<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<p>Did this mean that the loss function was tucked away in the forward pass? Let’s take a look.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> AutoModelForCausalLM, AutoTokenizer</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"HuggingFaceTB/SmolLM2-135M"</span></span>
<span id="cb8-2">tokenizer <span class="op" style="color: #5E5E5E;">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb8-3">model <span class="op" style="color: #5E5E5E;">=</span> AutoModelForCausalLM.from_pretrained(model_name)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;">import</span> inspect</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">forward_method <span class="op" style="color: #5E5E5E;">=</span> inspect.getsource(model.forward)</span>
<span id="cb10-2"><span class="bu" style="color: null;">print</span>(forward_method)</span></code></pre></div>
</div>
<p>I won’t print out the whole forward method, but will highlight that tucked away in there was the loss function call!</p>
<div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">loss <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb11-2"><span class="cf" style="color: #003B4F;">if</span> labels <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb11-3">    loss <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.loss_function(logits<span class="op" style="color: #5E5E5E;">=</span>logits, labels<span class="op" style="color: #5E5E5E;">=</span>labels, vocab_size<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">self</span>.config.vocab_size, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
<p>Aha! The function in question is <code>loss_function</code>. Inspecting that in more detail:</p>
<div class="cell" data-outputid="d9ba0d35-319f-444b-e060-7842ce9c6ebf" data-execution_count="6">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="bu" style="color: null;">print</span>(<span class="bu" style="color: null;">hasattr</span>(model, <span class="st" style="color: #20794D;">'loss_function'</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<p>This was a great opportunity for a refresher on the next-token objective and auto-regressive nature of this model.</p>
<div class="cell" data-outputid="be12edc7-9551-4d19-99f6-16d6af06abe1" data-execution_count="16">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="bu" style="color: null;">print</span>(inspect.getsource(model.loss_function))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>def ForCausalLMLoss(
    logits,
    labels,
    vocab_size: int,
    num_items_in_batch: Optional[int] = None,
    ignore_index: int = -100,
    shift_labels: Optional[torch.Tensor] = None,
    **kwargs,
) -&gt; torch.Tensor:
    # Upcast to float if we need to compute the loss to avoid potential precision issues
    logits = logits.float()

    if shift_labels is None:
        # Shift so that tokens &lt; n predict n
        labels = nn.functional.pad(labels, (0, 1), value=ignore_index)
        shift_labels = labels[..., 1:].contiguous()

    # Flatten the tokens
    logits = logits.view(-1, vocab_size)
    shift_labels = shift_labels.view(-1)
    # Enable model parallelism
    shift_labels = shift_labels.to(logits.device)
    loss = fixed_cross_entropy(logits, shift_labels, num_items_in_batch, ignore_index, **kwargs)
    return loss
</code></pre>
</div>
</div>
<p>The key for understanding next-token prediction are the following lines:</p>
<div class="sourceCode" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="cf" style="color: #003B4F;">if</span> shift_labels <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb16-2">    <span class="co" style="color: #5E5E5E;"># Shift so that tokens &lt; n predict n</span></span>
<span id="cb16-3">    labels <span class="op" style="color: #5E5E5E;">=</span> nn.functional.pad(labels, (<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=</span>ignore_index)</span>
<span id="cb16-4">    shift_labels <span class="op" style="color: #5E5E5E;">=</span> labels[..., <span class="dv" style="color: #AD0000;">1</span>:].contiguous()</span></code></pre></div>
<p><code>nn.functional.pad</code> adds padding tokens to <code>labels</code>, specifically <code>0</code> to the left-most end of the last dimension and <code>1</code> padding token to the right-most end. The token it uses as padding is <code>ignore_index</code>, which is <code>-100</code>.</p>
<p>Next, it <em>shifts</em> the labels by 1 element to the left with <code>labels[..., 1:]</code>. I took a moment to realize what this meant: the <code>input_ids</code> and <code>labels</code>, in terms of position, are the same! To align the <code>labels</code> with the <code>logits</code> (which are already “shifted” in the sense that the first position in <code>logits</code> corresponds to the first predicted token: the second token in the context) we have to shift the <code>labels</code> by 1. To ensure that the final token in <code>input_ids</code> doesn’t predict anything, we pad <code>labels</code> with <code>-100</code>, the value ignored in the loss calculation.</p>
<p>As a reminder, if the context we’re training our model on is “the cat sat on the table”, each next token is predicted based on all previous tokens:</p>
<pre><code>the --&gt; cat
the cat --&gt; sat
the cat sat --&gt; on
the cat sat on --&gt; the
the cat sat on the --&gt; table</code></pre>
<p>This is a good time to return to our callback and analyze its output, but before I do, here’s a quick demo of the label shifting operation:</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="im" style="color: #00769E;">from</span> torch.nn.functional <span class="im" style="color: #00769E;">import</span> pad</span>
<span id="cb18-2"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> tensor</span></code></pre></div>
</div>
<div class="cell" data-outputid="71616038-3f2d-43e5-85f2-adcc9b90a766" data-execution_count="10">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">labels <span class="op" style="color: #5E5E5E;">=</span> tensor([<span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">6</span>, <span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">2</span>])</span>
<span id="cb19-2">labels</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor([3, 6, 4, 2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="72be094b-fdd3-4317-fea6-53ce914d3b3d" data-execution_count="11">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">pad(labels, (<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([   3,    6,    4,    2, -100])</code></pre>
</div>
</div>
<div class="cell" data-outputid="1184fe03-3d4d-41db-e07f-3d0cf1de0823" data-execution_count="12">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">pad(labels, (<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">0</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor([-100,    3,    6,    4,    2])</code></pre>
</div>
</div>
<div class="cell" data-outputid="5893adca-e559-46bd-c16c-c02c7a876779" data-execution_count="13">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">pad(labels, (<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([-100,    3,    6,    4,    2, -100])</code></pre>
</div>
</div>
<div class="cell" data-outputid="4d957eab-06ec-4c64-9c1e-54b4a13e8a59" data-execution_count="14">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">pad(labels, (<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">1</span>), value<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">100</span>)[...,<span class="dv" style="color: #AD0000;">1</span>:]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([   6,    4,    2, -100])</code></pre>
</div>
</div>
</section>
<section id="callback-logs" class="level2">
<h2 class="anchored" data-anchor-id="callback-logs">Callback Logs</h2>
<p>There were four key print statements of interest in my callback. I’ll display each and show their printed value:</p>
<ol type="1">
<li><code>print(f"Framework loss: {framework_loss:.6f}")</code></li>
</ol>
<pre><code>Framework loss: 1.067513</code></pre>
<ol start="2" type="1">
<li><code>print(f"Direct call to model.loss_function: {direct_loss.item():.6f}")</code></li>
</ol>
<pre><code>Direct call to model.loss_function: 1.067513</code></pre>
<ol start="3" type="1">
<li><code>print(input_ids.tolist())</code></li>
<li><code>print(labels.tolist())</code></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="input_ids (top) and labels (bottom) with the response highlighted in yellow"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-22-LossInspector/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption"><code>input_ids</code> (top) and <code>labels</code> (bottom) with the response highlighted in yellow</figcaption><p></p>
</figure>
</div>
<p>The first two print statements confirmed that I was calling <code>state.model.loss_function</code> correctly. It also confirmed that the loss function doesn’t take in the <code>input_ids</code>.</p>
<p>The last two print statements confirmed my understanding: positionally speaking, the <code>input_ids</code> and <code>labels</code> are the same. In <code>labels</code> the positions of <code>input_ids</code> tokens that contain the prompt (and EOS tokens) are replaced with <code>-100</code> and the tokens that represent the response are kept as is. For reference, here’s what <code>input_ids</code> looks like (both the prompt and the response) coming from an item of the MetaMathQA dataset (I have ommitted the hundreds of padding EOS tokens and formatted the text for clearer presentation):</p>
<pre><code>A box with a volume of 16 $\text{cm}^3$ can hold X paperclips.
How many paperclips could a box with a volume of 48 $\text{cm}^3$ hold?
If we know the answer to the above question is 150, what is the value of unknown variable X?

We are given that a box with a volume of 16 $\text{cm}^3$ can hold $X$ paperclips.
To find out how many paperclips a box with a volume of 48 $\text{cm}^3$ can hold, we can set up a proportion using the given information.
We can write the proportion as:
16 $\text{cm}^3$ / $X$ paperclips = 48 $\text{cm}^3$ / 150 paperclips
We can cross-multiply and solve for $X$:
16 * 150 = 48 * $X$
2400 = 48 * $X$
Dividing both sides by 48, we get:
$X$ = 50
The value of $X$ is 50.
The answer is: 50&lt;|endoftext|&gt;</code></pre>
<p><code>labels</code> has the prompt replaced with <code>-100</code>s, and the loss function then left-shifts the <code>labels</code> tokens by 1 spot to align with the logits for next-token prediction comparison.</p>
<p>Unsurprisingly, the <code>input_ids</code> and <code>labels</code> before the forward pass and after the loss calculation are the same:</p>
<pre><code>print("\n-------- matches before_forward values? --------")
print(f"input_ids: {torch.allclose(input_ids, self.input_ids)}")
print(f"labels: {torch.allclose(labels, self.labels)}")</code></pre>
<pre><code>-------- matches before_forward values? --------
input_ids: True
labels: True</code></pre>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>With this baseline established, I can use this callback everytime we have processed a new dataset for training, inspecting the tokens, decoded text and loss values to ensure that the training loop will run properly for next-token prediction, whether it’s a continued pretraining or instruction fine-tuning dataset! Working with LLM-Foundry is a steep learning curve but I am learning a TON.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-22-LossInspector/index.html</guid>
  <pubDate>Tue, 22 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-04-22-LossInspector/1.png" medium="image" type="image/png" height="70" width="144"/>
</item>
<item>
  <title>Optimizing Matrix Multiplication Using Numba and Broadcasting</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In this notebook I’ll solidy the matrix multiplication concepts taught in Lesson 11 of the fastai course (part 2). Most importantly, I want to make sure I understand the use of broadcasting to make the matmul operation 7000x faster!</p>
<p>Here’s a summary of run times for the five methods explored in this blog post:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Images</th>
<th style="text-align: center;">Run Time (ms)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Python for-loops</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1090ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba-compiled Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.555ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Python Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.47ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.22ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.158ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba-compiled Broadcasting</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.0936ms</td>
</tr>
</tbody>
</table>
<p>Here’s my video walkthrough of the code in this notebook:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-t8b7Otfmjo?si=XxML2gDu0u2H9P0g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
</section>
<section id="load-the-data" class="level2">
<h2 class="anchored" data-anchor-id="load-the-data">Load the Data</h2>
<p>We’ll use the MNIST dataset for this exercise.</p>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> torch <span class="im" style="color: #00769E;">import</span> tensor</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> pickle, gzip, math, os, time, shutil, matplotlib <span class="im" style="color: #00769E;">as</span> mpl, matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> urllib.request <span class="im" style="color: #00769E;">import</span> urlretrieve</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">MNIST_URL<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'</span></span>
<span id="cb2-2">path_data <span class="op" style="color: #5E5E5E;">=</span> Path(<span class="st" style="color: #20794D;">'data'</span>)</span>
<span id="cb2-3">path_data.mkdir(exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-4">path_gz <span class="op" style="color: #5E5E5E;">=</span> path_data<span class="op" style="color: #5E5E5E;">/</span><span class="st" style="color: #20794D;">'mnist.pkl.gz'</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> path_gz.exists(): urlretrieve(MNIST_URL, path_gz)</span>
<span id="cb3-2"><span class="cf" style="color: #003B4F;">with</span> gzip.<span class="bu" style="color: null;">open</span>(path_gz, <span class="st" style="color: #20794D;">'rb'</span>) <span class="im" style="color: #00769E;">as</span> f: ((x_train, y_train), (x_valid, y_valid), _) <span class="op" style="color: #5E5E5E;">=</span> pickle.load(f, encoding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'latin-1'</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="314ea9fa-e0ee-4889-b82b-2fa6eb76da22" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="op" style="color: #5E5E5E;">!</span>ls <span class="op" style="color: #5E5E5E;">-</span>l data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>total 16656
-rw-r--r-- 1 root root 17051982 Apr 21 22:56 mnist.pkl.gz</code></pre>
</div>
</div>
<div class="cell" data-outputid="35f01f0b-da44-4f57-ecd7-0735437dd72e" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">x_train,y_train,x_valid,y_valid <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(tensor, (x_train,y_train,x_valid,y_valid))</span>
<span id="cb6-2">x_train.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>torch.Size([50000, 784])</code></pre>
</div>
</div>
<div class="cell" data-outputid="b485d5c3-2095-4a56-87d4-1aa1d0932eed" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">imgs <span class="op" style="color: #5E5E5E;">=</span> x_train.reshape((<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">28</span>,<span class="dv" style="color: #AD0000;">28</span>))</span>
<span id="cb8-2">imgs.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>torch.Size([50000, 28, 28])</code></pre>
</div>
</div>
<div class="cell" data-outputid="2bf4f561-0371-41b3-fae9-e322e1b8d812" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">plt.imshow(imgs[<span class="dv" style="color: #AD0000;">0</span>])<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/cell-8-output-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/index_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
</div>
</div>
<p>For our weights, we’ll create a set of random floats with shape 784 (rows) x 10 (columns). In an applied sense, these 10 outputs would be the logits associated with the ten possible digits (0-9) for each 28x28 image.</p>
<div class="cell" data-outputid="1f22c0e7-a087-4b0b-b0d1-dd41e8940ecb" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">torch.manual_seed(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb11-2">weights <span class="op" style="color: #5E5E5E;">=</span> torch.randn(<span class="dv" style="color: #AD0000;">784</span>, <span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb11-3">weights.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>torch.Size([784, 10])</code></pre>
</div>
</div>
<p>For our inputs (which get multiplied by our weights) we’ll use the first 5 digits (28x28 images) from the validation set. These inputs and our weights are the two matrices we want to multiply!</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">m1 <span class="op" style="color: #5E5E5E;">=</span> x_valid[:<span class="dv" style="color: #AD0000;">5</span>]</span>
<span id="cb13-2">m2 <span class="op" style="color: #5E5E5E;">=</span> weights</span></code></pre></div>
</div>
<div class="cell" data-outputid="212a05d8-26bd-4556-860b-257409a0fee5" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">m1.shape,m2.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>(torch.Size([5, 784]), torch.Size([784, 10]))</code></pre>
</div>
</div>
</section>
<section id="initial-solution-python-for-loops" class="level2">
<h2 class="anchored" data-anchor-id="initial-solution-python-for-loops">Initial Solution: Python for-Loops</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Naive implementation of matrix multiplication"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/1.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Naive implementation of matrix multiplication</figcaption><p></p>
</figure>
</div>
<p>For our first iteration, we’ll do a nested for-loop—the most naive implementation of matrix multiplication in this exercise.</p>
<p>We iterate through the 5 rows of our input matrix (images). For each row, we iterate through each column of our weights matrix. For each of the 784 elements in that row/column (i,j) combination, we take the dot product and store it in the output matrix. 5 images x 10 outputs x 784 elements = 39200 total items operated on.</p>
<div class="cell" data-outputid="cb867e65-bd14-4756-a67d-532d55b3abd1" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="dv" style="color: #AD0000;">5</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">10</span><span class="op" style="color: #5E5E5E;">*</span><span class="dv" style="color: #AD0000;">784</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>39200</code></pre>
</div>
</div>
<div class="cell" data-outputid="60c72dc6-52ab-412f-a330-aa63684b44da" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">ar,ac <span class="op" style="color: #5E5E5E;">=</span> m1.shape <span class="co" style="color: #5E5E5E;"># n_rows * n_cols</span></span>
<span id="cb18-2">br,bc <span class="op" style="color: #5E5E5E;">=</span> m2.shape</span>
<span id="cb18-3">(ar,ac),(br,bc)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>((5, 784), (784, 10))</code></pre>
</div>
</div>
<div class="cell" data-outputid="8425c8be-f9b5-40d5-f2d0-d7d301d18c05" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1">t1 <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc) <span class="co" style="color: #5E5E5E;"># resultant tensor</span></span>
<span id="cb20-2">t1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): <span class="co" style="color: #5E5E5E;">#5</span></span>
<span id="cb22-2">    <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): <span class="co" style="color: #5E5E5E;"># 10</span></span>
<span id="cb22-3">        <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ac): <span class="co" style="color: #5E5E5E;"># 784</span></span>
<span id="cb22-4">            t1[i,j] <span class="op" style="color: #5E5E5E;">+=</span> m1[i,k] <span class="op" style="color: #5E5E5E;">*</span> m2[k,j]</span></code></pre></div>
</div>
<p>The resulting matrix has 5 rows (1 for each image) and 10 columns (one for each “neuron” in our weights matrix).</p>
<div class="cell" data-outputid="237f3596-1c48-43c0-bb07-bae65246ac40" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">torch.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>, sci_mode<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span>
<span id="cb23-2">t1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([[-10.94,  -0.68,  -7.00,  -4.01,  -2.09,  -3.36,   3.91,  -3.44, -11.47,  -2.12],
        [ 14.54,   6.00,   2.89,  -4.08,   6.59, -14.74,  -9.28,   2.16, -15.28,  -2.68],
        [  2.22,  -3.22,  -4.80,  -6.05,  14.17,  -8.98,  -4.79,  -5.44, -20.68,  13.57],
        [ -6.71,   8.90,  -7.46,  -7.90,   2.70,  -4.73, -11.03, -12.98,  -6.44,   3.64],
        [ -2.44,  -6.40,  -2.40,  -9.04,  11.18,  -5.77,  -8.92,  -3.79,  -8.98,   5.28]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb25-2">np.set_printoptions(precision<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">140</span>)</span></code></pre></div>
</div>
<p>Wrapping this code into a function we can time it.</p>
<div class="cell" data-execution_count="135">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb26-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb26-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb26-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb26-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc):</span>
<span id="cb26-6">            <span class="cf" style="color: #003B4F;">for</span> k <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ac): c[i,j] <span class="op" style="color: #5E5E5E;">+=</span> a[i,k] <span class="op" style="color: #5E5E5E;">*</span> b[k,j]</span>
<span id="cb26-7">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-outputid="20110470-6efe-4296-fe08-6e37fb72d9aa" data-execution_count="137">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="op" style="color: #5E5E5E;">%</span>time _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.09 s, sys: 544 µs, total: 1.09 s
Wall time: 1.09 s</code></pre>
</div>
</div>
<p>It takes a whopping 1.09 seconds to perform this matrix multiplication for 5 images! Let’s optimize this with numba.</p>
</section>
<section id="compiling-the-dot-product-with-numba" class="level2">
<h2 class="anchored" data-anchor-id="compiling-the-dot-product-with-numba">Compiling the Dot Product with Numba</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="2.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3" title="Matrix multiplication using a numba-compiled dot product operation"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/2.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Matrix multiplication using a numba-compiled dot product operation</figcaption><p></p>
</figure>
</div>
<p>To reduce the number of python for-loops, we write the dot product (between the two 784-element vectors) in numba:</p>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><span class="im" style="color: #00769E;">from</span> numba <span class="im" style="color: #00769E;">import</span> njit</span></code></pre></div>
</div>
<div class="cell" data-execution_count="139">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb30-2"><span class="kw" style="color: #003B4F;">def</span> dot(a,b):</span>
<span id="cb30-3">    res <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.</span></span>
<span id="cb30-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(a)): res<span class="op" style="color: #5E5E5E;">+=</span>a[i]<span class="op" style="color: #5E5E5E;">*</span>b[i]</span>
<span id="cb30-5">    <span class="cf" style="color: #003B4F;">return</span> res</span></code></pre></div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><span class="im" style="color: #00769E;">from</span> numpy <span class="im" style="color: #00769E;">import</span> array</span></code></pre></div>
</div>
<p>The first run of <code>dot</code> takes longer as it includes the compile time:</p>
<div class="cell" data-outputid="61b070bc-e64a-4931-eb9a-16dc74db549c" data-execution_count="141">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="op" style="color: #5E5E5E;">%</span>time dot(array([<span class="fl" style="color: #AD0000;">1.</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>]),array([<span class="fl" style="color: #AD0000;">2.</span>,<span class="dv" style="color: #AD0000;">3</span>,<span class="dv" style="color: #AD0000;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 123 ms, sys: 0 ns, total: 123 ms
Wall time: 124 ms</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="141">
<pre><code>20.0</code></pre>
</div>
</div>
<p>The second run is 250x times faster.</p>
<div class="cell" data-outputid="8b7c64a0-582c-4b7f-ba4c-fae8fbcf9c26" data-execution_count="143">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><span class="fl" style="color: #AD0000;">0.124</span><span class="op" style="color: #5E5E5E;">/</span><span class="fl" style="color: #AD0000;">0.000489</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="143">
<pre><code>253.5787321063395</code></pre>
</div>
</div>
<div class="cell" data-outputid="30d7d3a4-c845-477c-9623-675a383c6fbb" data-execution_count="142">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="op" style="color: #5E5E5E;">%</span>time dot(array([<span class="fl" style="color: #AD0000;">1.</span>,<span class="dv" style="color: #AD0000;">2</span>,<span class="dv" style="color: #AD0000;">3</span>]),array([<span class="fl" style="color: #AD0000;">2.</span>,<span class="dv" style="color: #AD0000;">3</span>,<span class="dv" style="color: #AD0000;">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 40 µs, sys: 5 µs, total: 45 µs
Wall time: 48.9 µs</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="142">
<pre><code>20.0</code></pre>
</div>
</div>
<p>We replace the third for-loop with our numba <code>dot</code> function:</p>
<div class="cell" data-execution_count="160">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb40-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb40-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb40-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb40-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> dot(a[i,:], b[:,j])</span>
<span id="cb40-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">m1a,m2a <span class="op" style="color: #5E5E5E;">=</span> m1.numpy(),m2.numpy()</span></code></pre></div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="im" style="color: #00769E;">from</span> fastcore.test <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span></code></pre></div>
</div>
<p>We test that it yields the same result:</p>
<div class="cell" data-execution_count="163">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div class="cell" data-outputid="b9655c05-775a-425e-8921-91505c5a4d48" data-execution_count="151">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> matmul(m1a,m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>555 µs ± 14.5 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
<p>Our numba-compiled <code>dot</code> operation makes our matrix multiplication 2000x faster!</p>
<div class="cell" data-outputid="5d850c83-dc19-43fb-a238-e613ef13bfc8" data-execution_count="152">
<div class="sourceCode cell-code" id="cb46" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><span class="fl" style="color: #AD0000;">1.09</span><span class="op" style="color: #5E5E5E;">/</span><span class="fl" style="color: #AD0000;">555e-6</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="152">
<pre><code>1963.963963963964</code></pre>
</div>
</div>
<p>The same operation can be done in Python:</p>
<div class="cell" data-execution_count="164">
<div class="sourceCode cell-code" id="cb48" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb48-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb48-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb48-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb48-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:] <span class="op" style="color: #5E5E5E;">*</span> b[:,j]).<span class="bu" style="color: null;">sum</span>()</span>
<span id="cb48-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="165">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<p>But it’s three times slower than numba:</p>
<div class="cell" data-outputid="e9b4fe5b-ca19-4d9c-ab52-6b6e5b7f5cc9" data-execution_count="166">
<div class="sourceCode cell-code" id="cb50" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.47 ms ± 32.3 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
<p>Using <code>torch.dot</code> is a smidge faster than Python:</p>
<div class="cell" data-execution_count="167">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb52-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb52-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb52-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb52-5">        <span class="cf" style="color: #003B4F;">for</span> j <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(bc): c[i,j] <span class="op" style="color: #5E5E5E;">=</span> torch.dot(a[i,:], b[:,j])</span>
<span id="cb52-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="168">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="60fdda95-41de-4628-b901-bd94f407e572" data-execution_count="169">
<div class="sourceCode cell-code" id="cb54" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.22 ms ± 39.1 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
</section>
<section id="faster-use-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="faster-use-broadcasting">Faster: Use Broadcasting!</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="3.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4" title="Using broadcasting to compute all image/weight dot products simultaneously!"><img src="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/3.png" class="img-fluid figure-img"></a></p>
<p></p><figcaption class="figure-caption">Using broadcasting to compute all image/weight dot products simultaneously!</figcaption><p></p>
</figure>
</div>
<p>Broadcasting effectively expands the smaller matrix to match the size of the larger one so that element-wise operations can take place.</p>
<p>Suppose we wanted to take the dot product between the first image and all 10 columns of weights. Adding a <code>None</code> during indexing adds a unit axis at that position:</p>
<div class="cell" data-outputid="2676c4cc-c732-4947-e7d1-851a3b0fadf1" data-execution_count="21">
<div class="sourceCode cell-code" id="cb56" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1">m1[<span class="dv" style="color: #AD0000;">0</span>,:].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>torch.Size([784])</code></pre>
</div>
</div>
<div class="cell" data-outputid="bc6ed9d8-f7cc-48b8-b6e5-a0e3e5edcf7b" data-execution_count="22">
<div class="sourceCode cell-code" id="cb58" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1">m1[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>torch.Size([784, 1])</code></pre>
</div>
</div>
<div class="cell" data-outputid="8c97f11e-a361-4495-dc0e-1b02a7a41a11" data-execution_count="23">
<div class="sourceCode cell-code" id="cb60" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1">m2.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>torch.Size([784, 10])</code></pre>
</div>
</div>
<p>Multiplying (element-wise) <code>m1[0, :, None]</code> with <code>m2</code> <em>broadcasts</em> <code>m1[0, :, None]</code> across the 10 columns of <code>m2</code>. In other words, each row of <code>m1[0]</code> is virtually copied over 10 times, one for each column of <code>m2</code>.</p>
<div class="cell" data-outputid="851cd77c-a7c6-47c4-b5ab-4cf31b2f3992" data-execution_count="25">
<div class="sourceCode cell-code" id="cb62" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1">(m1[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> m2).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>torch.Size([784, 10])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ff7e2357-7bd5-4fcc-b145-209686989ebb" data-execution_count="36">
<div class="sourceCode cell-code" id="cb64" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1">m1.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>torch.Size([5, 784])</code></pre>
</div>
</div>
<div class="cell" data-outputid="6d3005bf-b2b3-47df-ed78-974f090d94e6" data-execution_count="42">
<div class="sourceCode cell-code" id="cb66" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1">m1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])</code></pre>
</div>
</div>
<p>Here’s a smaller example. <code>a</code> has 5 rows, “images”, each with 4 pixels.</p>
<div class="cell" data-outputid="a1c16304-fd94-4b01-e12c-dfe5d97511b6" data-execution_count="37">
<div class="sourceCode cell-code" id="cb68" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1">a <span class="op" style="color: #5E5E5E;">=</span> torch.randint(low<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, high<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">5</span>,<span class="dv" style="color: #AD0000;">4</span>))</span>
<span id="cb68-2">a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([[1, 4, 3, 4],
        [1, 4, 1, 3],
        [3, 2, 2, 4],
        [3, 1, 3, 1],
        [2, 3, 1, 1]])</code></pre>
</div>
</div>
<p>We pluck out the first “image” with <code>0</code>, then add a unit axis at the end with <code>None</code> to make it “broadcastable”</p>
<div class="cell" data-outputid="917a5f84-282b-4c51-bf82-4860c08cc859" data-execution_count="38">
<div class="sourceCode cell-code" id="cb70" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1">a[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([[1],
        [4],
        [3],
        [4]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="19287d6f-36f8-42e6-8136-36cb6881f1ff" data-execution_count="43">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1">a.shape, a[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>(torch.Size([5, 4]), torch.Size([4, 1]))</code></pre>
</div>
</div>
<p>Suppose we have weights <code>w</code> with 4 rows, each 10 columns wide.</p>
<div class="cell" data-outputid="2370ca54-9190-4415-d920-171c9c705707" data-execution_count="47">
<div class="sourceCode cell-code" id="cb74" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1">w <span class="op" style="color: #5E5E5E;">=</span> torch.randint(low<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, high<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, size<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">4</span>, <span class="dv" style="color: #AD0000;">10</span>))</span>
<span id="cb74-2">w</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([[2, 2, 1, 1, 4, 3, 4, 2, 4, 3],
        [1, 2, 4, 2, 4, 1, 3, 1, 2, 1],
        [4, 3, 4, 3, 1, 2, 1, 3, 3, 4],
        [1, 3, 3, 3, 3, 1, 1, 1, 4, 4]])</code></pre>
</div>
</div>
<p>We broadcast the 4-vector <code>a[0, :, None]</code> across all 10 4-vectors in <code>w</code>:</p>
<div class="cell" data-outputid="73442351-22b9-46eb-cde5-d4ee374d2679" data-execution_count="48">
<div class="sourceCode cell-code" id="cb76" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1">a[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> w</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([[ 2,  2,  1,  1,  4,  3,  4,  2,  4,  3],
        [ 4,  8, 16,  8, 16,  4, 12,  4,  8,  4],
        [12,  9, 12,  9,  3,  6,  3,  9,  9, 12],
        [ 4, 12, 12, 12, 12,  4,  4,  4, 16, 16]])</code></pre>
</div>
</div>
<p>Then take the sum down the columns (along the row axis) to get the 10 output “activations” for this “image”:</p>
<div class="cell" data-outputid="0795be2f-d5b5-42a7-91f8-13d352fc7a46" data-execution_count="49">
<div class="sourceCode cell-code" id="cb78" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1">(a[<span class="dv" style="color: #AD0000;">0</span>, :, <span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> w).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>tensor([22, 31, 41, 30, 35, 17, 23, 19, 37, 35])</code></pre>
</div>
</div>
<p>Looking at the first value of <code>22</code>, it comes from the dot product between the first “image” in <code>a</code> and the first row of weights (the “neuron”) in <code>w</code>:</p>
<p>22 = 1*2 + 4*1 + 3*4 + 4*1 = 2 + 4 + 12 + 4</p>
<p>In this way, we have the dot product between the first image and all 10 columns. This is the first row of the matrix product between <code>a</code> and <code>w</code>.</p>
<p>We can then loop over the images, broadcasting it across the weight matrix, summing down the columns to get each subsequent row of our resultant matrix product:</p>
<div class="cell" data-outputid="db6f46a2-bfa0-48a7-b336-5f5c1332f01f" data-execution_count="51">
<div class="sourceCode cell-code" id="cb80" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1">(ar,ac),(wr,wc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,w.shape</span>
<span id="cb80-2">ar,ac,wr,wc</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>(5, 4, 4, 10)</code></pre>
</div>
</div>
<div class="cell" data-outputid="2b8330a8-6dbd-4092-8f5f-6aaeaf7ccdfb" data-execution_count="52">
<div class="sourceCode cell-code" id="cb82" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1">c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, wc)</span>
<span id="cb82-2">c.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>torch.Size([5, 10])</code></pre>
</div>
</div>
<div class="cell" data-outputid="ab5b28b8-b7be-4d85-da36-730fd8943ca4" data-execution_count="53">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar):</span>
<span id="cb84-2">    c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i, :, <span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> w).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb84-3">c</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>tensor([[22., 31., 41., 30., 35., 17., 23., 19., 37., 35.],
        [13., 22., 30., 21., 30., 12., 20., 12., 27., 23.],
        [20., 28., 31., 25., 34., 19., 24., 18., 38., 35.],
        [20., 20., 22., 17., 22., 17., 19., 17., 27., 26.],
        [12., 16., 21., 14., 24., 12., 19., 11., 21., 17.]])</code></pre>
</div>
</div>
<p>In this way, we have performed matrix multiplication by taking the dot product of each row/column using broadcasting! Returning to our original dataset:</p>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb86-2">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb86-3">    c <span class="op" style="color: #5E5E5E;">=</span> torch.zeros(ar, bc)</span>
<span id="cb86-4">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i]  <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(dim<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb86-5">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1">test_close(t1,matmul(m1, m2))</span></code></pre></div>
</div>
<div class="cell" data-outputid="dcb5e610-3ea9-4af8-83bf-c0390020cd2c" data-execution_count="58">
<div class="sourceCode cell-code" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1, m2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>158 µs ± 15.1 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
<p>This gives us a 8x speedup from the numba-compiled dot product (1.22ms –&gt; 0.158 ms).</p>
<p>Now, instead of 5 images we can perform matmul with all 50k images in our dataset.</p>
<div class="cell" data-outputid="3877da3f-6cfe-433f-f7bc-6e70d2b80678" data-execution_count="59">
<div class="sourceCode cell-code" id="cb90" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1">tr <span class="op" style="color: #5E5E5E;">=</span> matmul(x_train, weights)</span>
<span id="cb90-2">tr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>tensor([[  0.96,  -2.96,  -2.11,  ..., -15.09, -17.69,   0.60],
        [  6.89,  -0.34,   0.79,  ..., -17.13, -25.36,  16.23],
        [-10.18,   7.38,   4.13,  ...,  -6.73,  -6.79,  -1.58],
        ...,
        [  7.40,   7.64,  -3.50,  ...,  -1.02, -16.22,   2.07],
        [  3.25,   9.52,  -9.37,  ...,   2.98, -19.58,  -1.96],
        [ 15.70,   4.12,  -5.62,  ...,   8.08, -12.21,   0.42]])</code></pre>
</div>
</div>
<div class="cell" data-outputid="a96bae33-3c9c-4380-c4da-7df3c44e1cb3" data-execution_count="60">
<div class="sourceCode cell-code" id="cb92" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1">tr.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>torch.Size([50000, 10])</code></pre>
</div>
</div>
<p>This operation now takes less than two seconds!</p>
<div class="cell" data-outputid="9b5bb005-9613-4419-dfc5-af1c2b30c464" data-execution_count="63">
<div class="sourceCode cell-code" id="cb94" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><span class="op" style="color: #5E5E5E;">%</span>time _<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train, weights)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 1.62 s, sys: 0 ns, total: 1.62 s
Wall time: 1.63 s</code></pre>
</div>
</div>
</section>
<section id="fastest-numba-broadcasting" class="level2">
<h2 class="anchored" data-anchor-id="fastest-numba-broadcasting">Fastest: Numba Broadcasting</h2>
<div class="cell" data-outputid="4af16216-46bd-41a9-a893-aa5229bb6d54" data-execution_count="69">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">m1a.shape, m2a.shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>((5, 784), (784, 10))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb98" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><span class="at" style="color: #657422;">@njit</span></span>
<span id="cb98-2"><span class="kw" style="color: #003B4F;">def</span> matmul(a,b):</span>
<span id="cb98-3">    (ar,ac),(br,bc) <span class="op" style="color: #5E5E5E;">=</span> a.shape,b.shape</span>
<span id="cb98-4">    c <span class="op" style="color: #5E5E5E;">=</span> np.zeros((ar, bc))</span>
<span id="cb98-5">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(ar): c[i] <span class="op" style="color: #5E5E5E;">=</span> (a[i,:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">*</span> b).<span class="bu" style="color: null;">sum</span>(axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb98-6">    <span class="cf" style="color: #003B4F;">return</span> c</span></code></pre></div>
</div>
<div class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb99" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1">test_close(t1,matmul(m1a, m2a))</span></code></pre></div>
</div>
<div class="cell" data-outputid="13b4fff2-ef89-4c34-9bc9-0d77963e5334" data-execution_count="86">
<div class="sourceCode cell-code" id="cb100" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><span class="op" style="color: #5E5E5E;">%</span>timeit <span class="op" style="color: #5E5E5E;">-</span>n <span class="dv" style="color: #AD0000;">50</span> _<span class="op" style="color: #5E5E5E;">=</span>matmul(m1a, m2a)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>93.6 µs ± 9.26 µs per loop (mean ± std. dev. of 7 runs, 50 loops each)</code></pre>
</div>
</div>
<p>We can now perform matrix multiplication for all 50_000 images in less time than we could for 5 images using nested for-loops. AMAZING!</p>
<div class="cell" data-outputid="6f076764-93d6-41d6-a7bf-b82f5ee271a2" data-execution_count="91">
<div class="sourceCode cell-code" id="cb102" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><span class="op" style="color: #5E5E5E;">%</span>time _<span class="op" style="color: #5E5E5E;">=</span>matmul(x_train.numpy(), weights.numpy())</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>CPU times: user 885 ms, sys: 0 ns, total: 885 ms
Wall time: 881 ms</code></pre>
</div>
</div>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>I’ve been busy with other ML projects over the past few months but I’m so glad I have gotten back in the driver’s seat for fastai course part 2! The videos, content, and potential projects/exercises that spring forth are absolutely delicious. Using relatively simple building blocks, I was able to understand matrix multiplication through Python loops, numba dot product, and Yorick-inspired PyTorch broadcasting. Creating the visuals (in excalidraw) was a <em>must</em> because I really needed to cement these concepts in my mind, as encouraged by Jeremy in the video.</p>
<p>Here’s the summary again of run times for each of the methods shown above:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Method</th>
<th style="text-align: center;">Images</th>
<th style="text-align: center;">Run Time (ms)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Python for-loops</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1090ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba-compiled Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.555ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Python Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.47ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">PyTorch Dot Product</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1.22ms</td>
</tr>
<tr class="odd">
<td style="text-align: center;">PyTorch Broadcasting</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.158ms</td>
</tr>
<tr class="even">
<td style="text-align: center;">Numba-compiled Broadcasting</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.0936ms</td>
</tr>
</tbody>
</table>
<p>Using numba-compiled broadcasting, the 5-image matrix multiplication with weights experienced a 12000x speedup compared to the naive Python nested for-loop implementation! Amazing!!</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/index.html</guid>
  <pubDate>Mon, 21 Apr 2025 07:00:00 GMT</pubDate>
  <media:content url="https://vishalbakshi.github.io/blog/posts/2025-04-21-Matrix-Multiplication/1.png" medium="image" type="image/png" height="49" width="144"/>
</item>
<item>
  <title>Logging Data Types for Activations, Gradients, Weights, Optimizer States and Loss during Training with LLM-Foundry</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-02-Composer-Callback-Logging-dtypes/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>In a <a href="https://vishalbakshi.github.io/blog/posts/2025-03-30-Composer-Callback/">previous blog post</a> I shared my first couple of iterations of custom Composer callback used to log data types of different entities (activations, gradients, weights, optimizer states, and loss) during training with LLM-Foundry. In this blog post I’ll share my final callback iteration’s code, some lessons I learned along the way (i.e.&nbsp;LLaMA’s self-attention module doesn’t have positional arguments!) and analyze the logging results to observe entity data types throughout the training loop.</p>
</section>
<section id="composer-callback-walkthrough" class="level2">
<h2 class="anchored" data-anchor-id="composer-callback-walkthrough">Composer Callback Walkthrough</h2>
<p>The data types of entities (activations, gradients, weights, loss, and optimizer states) are logged during training with a custom Composer callback <code>DtypeLogger</code> passed to the Composer <code>Trainer</code>. This callback was built up and tested event-by-event using Claude. There is one event handler in the callback for each Composer event from <code>&lt;FIT_START&gt;</code> to <code>&lt;BATCH_END&gt;</code>:</p>
<pre><code># &lt;INIT&gt;
# &lt;BEFORE_LOAD&gt;
# &lt;AFTER_LOAD&gt;
# &lt;FIT_START&gt;
for epoch in range(NUM_EPOCHS):
    # &lt;EPOCH_START&gt;
    while True:
        # &lt;BEFORE_DATALOADER&gt;
        batch = next(dataloader)
        if batch is None:
            break
        inputs, targets = batch
        # &lt;AFTER_DATALOADER&gt;

        # &lt;BATCH_START&gt;

        # &lt;BEFORE_FORWARD&gt;
        outputs = model.forward(inputs)
        # &lt;AFTER_FORWARD&gt;

        # &lt;BEFORE_LOSS&gt;
        loss = model.loss(outputs, targets)
        # &lt;AFTER_LOSS&gt;

        # &lt;BEFORE_BACKWARD&gt;
        loss.backward()
        # &lt;AFTER_BACKWARD&gt;

        optimizer.step()
        optimizer.zero_grad()

        # &lt;BATCH_END&gt;
    # &lt;EPOCH_END&gt;</code></pre>
<p>There are four explicit logging functions:</p>
<ul>
<li><code>_log_model_weight_dtypes</code></li>
<li><code>_log_gradient_dtypes</code></li>
<li><code>_log_optimizer_state_dtypes</code></li>
<li><code>_log_loss_dtype</code></li>
</ul>
<p>Additionally, activations are logged using <code>register_forward_hook</code> for all modules except self-attention (more on that below). Self-attention inputs are logged using a monkey-patched forward pass.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">class</span> DtypeLogger(Callback):</span>
<span id="cb2-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, save_path<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"/model-checkpoints/dtype_tracking"</span>, log_interval<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>):</span>
<span id="cb2-3">        <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">=</span> Path(save_path)</span>
<span id="cb2-4">        <span class="va" style="color: #111111;">self</span>.dtype_logs <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'log'</span>: {}}</span>
<span id="cb2-5">        <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">=</span> log_interval</span>
<span id="cb2-6">        <span class="va" style="color: #111111;">self</span>.hooks <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb2-7">        </span>
<span id="cb2-8">    <span class="kw" style="color: #003B4F;">def</span> fit_start(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-9">        <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"fit_start"</span>)</span>
<span id="cb2-10">        <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-11">        </span>
<span id="cb2-12">    <span class="kw" style="color: #003B4F;">def</span> epoch_start(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-13">        <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"epoch_start"</span>)</span>
<span id="cb2-14">        <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-15">    </span>
<span id="cb2-16">    <span class="kw" style="color: #003B4F;">def</span> before_dataloader(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-17">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-18">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_dataloader"</span>)</span>
<span id="cb2-19">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-20">            </span>
<span id="cb2-21">    <span class="kw" style="color: #003B4F;">def</span> after_dataloader(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-22">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-23">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"after_dataloader"</span>)</span>
<span id="cb2-24">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-25">            </span>
<span id="cb2-26">    <span class="kw" style="color: #003B4F;">def</span> batch_start(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-27">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-28">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"batch_start"</span>)</span>
<span id="cb2-29">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-30">            </span>
<span id="cb2-31">    <span class="kw" style="color: #003B4F;">def</span> before_forward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-32">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-33">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_forward"</span>)</span>
<span id="cb2-34">            </span>
<span id="cb2-35">            <span class="co" style="color: #5E5E5E;"># Clear old hooks</span></span>
<span id="cb2-36">            <span class="cf" style="color: #003B4F;">for</span> hook <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.hooks:</span>
<span id="cb2-37">                hook.remove()</span>
<span id="cb2-38">            <span class="va" style="color: #111111;">self</span>.hooks <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb2-39">            </span>
<span id="cb2-40">            <span class="co" style="color: #5E5E5E;"># Get the model</span></span>
<span id="cb2-41">            model <span class="op" style="color: #5E5E5E;">=</span> state.model.model.base_model.model</span>
<span id="cb2-42">            transformer_model <span class="op" style="color: #5E5E5E;">=</span> model.model  <span class="co" style="color: #5E5E5E;"># This is the transformer part</span></span>
<span id="cb2-43">            batch_id <span class="op" style="color: #5E5E5E;">=</span> state.timestamp.batch.value</span>
<span id="cb2-44">            </span>
<span id="cb2-45">            <span class="co" style="color: #5E5E5E;"># Store original forward methods to restore later</span></span>
<span id="cb2-46">            <span class="va" style="color: #111111;">self</span>.original_forward_methods <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb2-47">            </span>
<span id="cb2-48">            <span class="kw" style="color: #003B4F;">def</span> hook_fn(layer_name, module_name):</span>
<span id="cb2-49">                <span class="kw" style="color: #003B4F;">def</span> _hook(module, inputs, outputs):</span>
<span id="cb2-50">                    <span class="co" style="color: #5E5E5E;"># Log input activation dtype</span></span>
<span id="cb2-51">                    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(inputs, <span class="bu" style="color: null;">tuple</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(inputs) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-52">                        <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:</span><span class="sc" style="color: #5E5E5E;">{</span>module_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>layer_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_input"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(inputs[<span class="dv" style="color: #AD0000;">0</span>].dtype)</span>
<span id="cb2-53">                    </span>
<span id="cb2-54">                    <span class="co" style="color: #5E5E5E;"># Log output activation dtype</span></span>
<span id="cb2-55">                    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(outputs, torch.Tensor):</span>
<span id="cb2-56">                        <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:</span><span class="sc" style="color: #5E5E5E;">{</span>module_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>layer_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_output"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(outputs.dtype)</span>
<span id="cb2-57">                    <span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">isinstance</span>(outputs, <span class="bu" style="color: null;">tuple</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(outputs) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-58">                        <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:</span><span class="sc" style="color: #5E5E5E;">{</span>module_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>layer_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_output"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(outputs[<span class="dv" style="color: #AD0000;">0</span>].dtype)</span>
<span id="cb2-59">                <span class="cf" style="color: #003B4F;">return</span> _hook</span>
<span id="cb2-60">            </span>
<span id="cb2-61">            <span class="co" style="color: #5E5E5E;"># Monkey patch self-attention modules</span></span>
<span id="cb2-62">            <span class="cf" style="color: #003B4F;">for</span> layer_idx, layer <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(transformer_model.layers):</span>
<span id="cb2-63">                <span class="co" style="color: #5E5E5E;"># Store the original forward method</span></span>
<span id="cb2-64">                original_forward <span class="op" style="color: #5E5E5E;">=</span> layer.self_attn.forward</span>
<span id="cb2-65">                <span class="va" style="color: #111111;">self</span>.original_forward_methods[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> original_forward</span>
<span id="cb2-66">                </span>
<span id="cb2-67">                <span class="co" style="color: #5E5E5E;"># Define a closure to capture the current layer_idx</span></span>
<span id="cb2-68">                <span class="kw" style="color: #003B4F;">def</span> make_patched_forward(layer_idx, orig_forward):</span>
<span id="cb2-69">                    <span class="kw" style="color: #003B4F;">def</span> patched_forward(self_attn, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb2-70">                        <span class="co" style="color: #5E5E5E;"># Log the hidden_states dtype</span></span>
<span id="cb2-71">                        <span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'hidden_states'</span> <span class="kw" style="color: #003B4F;">in</span> kwargs <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">hasattr</span>(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>], <span class="st" style="color: #20794D;">'dtype'</span>):</span>
<span id="cb2-72">                            <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:self_attn:layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_input"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>].dtype)</span>
<span id="cb2-73">                        </span>
<span id="cb2-74">                        <span class="co" style="color: #5E5E5E;"># Call the original method as a bound method</span></span>
<span id="cb2-75">                        <span class="co" style="color: #5E5E5E;"># This ensures 'self_attn' is correctly passed as 'self'</span></span>
<span id="cb2-76">                        <span class="cf" style="color: #003B4F;">return</span> orig_forward.<span class="fu" style="color: #4758AB;">__get__</span>(self_attn, <span class="bu" style="color: null;">type</span>(self_attn))(<span class="op" style="color: #5E5E5E;">**</span>kwargs)</span>
<span id="cb2-77">                    </span>
<span id="cb2-78">                    <span class="cf" style="color: #003B4F;">return</span> patched_forward</span>
<span id="cb2-79">                </span>
<span id="cb2-80">                <span class="co" style="color: #5E5E5E;"># Replace the forward method</span></span>
<span id="cb2-81">                layer.self_attn.forward <span class="op" style="color: #5E5E5E;">=</span> make_patched_forward(layer_idx, original_forward).<span class="fu" style="color: #4758AB;">__get__</span>(layer.self_attn, <span class="bu" style="color: null;">type</span>(layer.self_attn))</span>
<span id="cb2-82">            </span>
<span id="cb2-83">            <span class="co" style="color: #5E5E5E;"># Register hook for lm_head</span></span>
<span id="cb2-84">            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(model, <span class="st" style="color: #20794D;">'lm_head'</span>):</span>
<span id="cb2-85">                <span class="va" style="color: #111111;">self</span>.hooks.append(model.lm_head.register_forward_hook(hook_fn(<span class="st" style="color: #20794D;">"output"</span>, <span class="st" style="color: #20794D;">"lm_head"</span>)))</span>
<span id="cb2-86">            </span>
<span id="cb2-87">            <span class="co" style="color: #5E5E5E;"># Register hook for embedding layer</span></span>
<span id="cb2-88">            <span class="va" style="color: #111111;">self</span>.hooks.append(transformer_model.embed_tokens.register_forward_hook(hook_fn(<span class="st" style="color: #20794D;">"embeddings"</span>, <span class="st" style="color: #20794D;">"embed_tokens"</span>)))</span>
<span id="cb2-89">            </span>
<span id="cb2-90">            <span class="co" style="color: #5E5E5E;"># Register hooks for each transformer layer</span></span>
<span id="cb2-91">            <span class="cf" style="color: #003B4F;">for</span> layer_idx, layer <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(transformer_model.layers):</span>
<span id="cb2-92">                <span class="co" style="color: #5E5E5E;"># Self-attention components - we still register hooks for outputs</span></span>
<span id="cb2-93">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"self_attn"</span>)))</span>
<span id="cb2-94">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.q_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"q_proj"</span>)))</span>
<span id="cb2-95">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.k_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"k_proj"</span>)))</span>
<span id="cb2-96">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.v_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"v_proj"</span>)))</span>
<span id="cb2-97">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.self_attn.o_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"o_proj"</span>)))</span>
<span id="cb2-98">                </span>
<span id="cb2-99">                <span class="co" style="color: #5E5E5E;"># MLP components</span></span>
<span id="cb2-100">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.mlp.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"mlp"</span>)))</span>
<span id="cb2-101">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.mlp.gate_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"gate_proj"</span>)))</span>
<span id="cb2-102">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.mlp.up_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"up_proj"</span>)))</span>
<span id="cb2-103">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.mlp.down_proj.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"down_proj"</span>)))</span>
<span id="cb2-104">                </span>
<span id="cb2-105">                <span class="co" style="color: #5E5E5E;"># Layer norms</span></span>
<span id="cb2-106">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.input_layernorm.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"input_layernorm"</span>)))</span>
<span id="cb2-107">                <span class="va" style="color: #111111;">self</span>.hooks.append(layer.post_attention_layernorm.register_forward_hook(hook_fn(<span class="ss" style="color: #20794D;">f"layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, <span class="st" style="color: #20794D;">"post_attention_layernorm"</span>)))</span>
<span id="cb2-108">            </span>
<span id="cb2-109">            <span class="co" style="color: #5E5E5E;"># Final layer norm</span></span>
<span id="cb2-110">            <span class="va" style="color: #111111;">self</span>.hooks.append(transformer_model.norm.register_forward_hook(hook_fn(<span class="st" style="color: #20794D;">"final"</span>, <span class="st" style="color: #20794D;">"norm"</span>)))</span>
<span id="cb2-111">            </span>
<span id="cb2-112">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-113">            </span>
<span id="cb2-114">    <span class="kw" style="color: #003B4F;">def</span> after_forward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-115">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-116">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"after_forward"</span>)</span>
<span id="cb2-117">            </span>
<span id="cb2-118">            <span class="co" style="color: #5E5E5E;"># Restore original forward methods</span></span>
<span id="cb2-119">            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(<span class="va" style="color: #111111;">self</span>, <span class="st" style="color: #20794D;">'original_forward_methods'</span>):</span>
<span id="cb2-120">                model <span class="op" style="color: #5E5E5E;">=</span> state.model.model.base_model.model</span>
<span id="cb2-121">                transformer_model <span class="op" style="color: #5E5E5E;">=</span> model.model</span>
<span id="cb2-122">                </span>
<span id="cb2-123">                <span class="cf" style="color: #003B4F;">for</span> layer_idx, original_forward <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.original_forward_methods.items():</span>
<span id="cb2-124">                    transformer_model.layers[layer_idx].self_attn.forward <span class="op" style="color: #5E5E5E;">=</span> original_forward</span>
<span id="cb2-125">                </span>
<span id="cb2-126">                <span class="va" style="color: #111111;">self</span>.original_forward_methods <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb2-127">            </span>
<span id="cb2-128">            <span class="co" style="color: #5E5E5E;"># Clear hooks</span></span>
<span id="cb2-129">            <span class="cf" style="color: #003B4F;">for</span> hook <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.hooks:</span>
<span id="cb2-130">                hook.remove()</span>
<span id="cb2-131">            <span class="va" style="color: #111111;">self</span>.hooks <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb2-132">            </span>
<span id="cb2-133">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-134">            </span>
<span id="cb2-135">    <span class="kw" style="color: #003B4F;">def</span> before_loss(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-136">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-137">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_loss"</span>)</span>
<span id="cb2-138">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-139">            </span>
<span id="cb2-140">    <span class="kw" style="color: #003B4F;">def</span> after_loss(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-141">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-142">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"after_loss"</span>)</span>
<span id="cb2-143">            <span class="va" style="color: #111111;">self</span>._log_loss_dtype(state, <span class="st" style="color: #20794D;">"after_loss"</span>)</span>
<span id="cb2-144">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-145">            </span>
<span id="cb2-146">    <span class="kw" style="color: #003B4F;">def</span> before_backward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-147">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-148">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_backward"</span>)</span>
<span id="cb2-149">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-150">            </span>
<span id="cb2-151">    <span class="kw" style="color: #003B4F;">def</span> after_backward(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-152">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-153">            <span class="co" style="color: #5E5E5E;"># Log gradient dtypes as before</span></span>
<span id="cb2-154">            <span class="va" style="color: #111111;">self</span>._log_gradient_dtypes(state, <span class="st" style="color: #20794D;">"after_backward"</span>)</span>
<span id="cb2-155">            </span>
<span id="cb2-156">            <span class="co" style="color: #5E5E5E;"># Track weight dtypes before optimizer step</span></span>
<span id="cb2-157">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"before_optim_step"</span>)</span>
<span id="cb2-158">            </span>
<span id="cb2-159">            <span class="co" style="color: #5E5E5E;"># Log optimizer state dtypes</span></span>
<span id="cb2-160">            <span class="va" style="color: #111111;">self</span>._log_optimizer_state_dtypes(state, <span class="st" style="color: #20794D;">"optimizer_step"</span>)</span>
<span id="cb2-161">            </span>
<span id="cb2-162">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-163">                    </span>
<span id="cb2-164">    <span class="kw" style="color: #003B4F;">def</span> batch_end(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-165">        <span class="cf" style="color: #003B4F;">if</span> state.timestamp.batch.value <span class="op" style="color: #5E5E5E;">%</span> <span class="va" style="color: #111111;">self</span>.log_interval <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">0</span>:</span>
<span id="cb2-166">            <span class="co" style="color: #5E5E5E;"># Track weight dtypes after optimizer step to detect precision changes</span></span>
<span id="cb2-167">            <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"after_optim_step"</span>)</span>
<span id="cb2-168">            <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-169"></span>
<span id="cb2-170">    <span class="kw" style="color: #003B4F;">def</span> epoch_end(<span class="va" style="color: #111111;">self</span>, state: State, logger: Logger) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-171">        <span class="va" style="color: #111111;">self</span>._log_model_weight_dtypes(state, <span class="st" style="color: #20794D;">"epoch_end"</span>)</span>
<span id="cb2-172">        <span class="va" style="color: #111111;">self</span>._save_logs()</span>
<span id="cb2-173">        </span>
<span id="cb2-174">    <span class="kw" style="color: #003B4F;">def</span> _log_model_weight_dtypes(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-175">        model <span class="op" style="color: #5E5E5E;">=</span> state.model</span>
<span id="cb2-176">        <span class="cf" style="color: #003B4F;">for</span> name, param <span class="kw" style="color: #003B4F;">in</span> model.named_parameters():</span>
<span id="cb2-177">            name <span class="op" style="color: #5E5E5E;">=</span> name.removeprefix(<span class="st" style="color: #20794D;">"model.base_model.model.model."</span>)</span>
<span id="cb2-178">            <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:weights"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(param.dtype)</span>
<span id="cb2-179"></span>
<span id="cb2-180">    <span class="kw" style="color: #003B4F;">def</span> _log_gradient_dtypes(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-181">        model <span class="op" style="color: #5E5E5E;">=</span> state.model</span>
<span id="cb2-182">        <span class="cf" style="color: #003B4F;">for</span> name, param <span class="kw" style="color: #003B4F;">in</span> model.named_parameters():</span>
<span id="cb2-183">            name <span class="op" style="color: #5E5E5E;">=</span> name.removeprefix(<span class="st" style="color: #20794D;">"model.base_model.model.model."</span>)</span>
<span id="cb2-184">            <span class="cf" style="color: #003B4F;">if</span> param.grad <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>: <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">'log'</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:gradients"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(param.grad.dtype)</span>
<span id="cb2-185">            <span class="cf" style="color: #003B4F;">else</span>: <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">'log'</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:gradients"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"None"</span></span>
<span id="cb2-186">    </span>
<span id="cb2-187">    <span class="kw" style="color: #003B4F;">def</span> _log_loss_dtype(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-188">        <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(state, <span class="st" style="color: #20794D;">'loss'</span>) <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">hasattr</span>(state.loss, <span class="st" style="color: #20794D;">'dtype'</span>):</span>
<span id="cb2-189">            <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:loss"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(state.loss.dtype)</span>
<span id="cb2-190">            </span>
<span id="cb2-191">    <span class="kw" style="color: #003B4F;">def</span> _log_optimizer_state_dtypes(<span class="va" style="color: #111111;">self</span>, state: State, event_name: <span class="bu" style="color: null;">str</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-192">        <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(state, <span class="st" style="color: #20794D;">'optimizers'</span>) <span class="kw" style="color: #003B4F;">and</span> state.optimizers <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-193">            <span class="co" style="color: #5E5E5E;"># Handle single optimizer or list of optimizers</span></span>
<span id="cb2-194">            optimizers <span class="op" style="color: #5E5E5E;">=</span> state.optimizers <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(state.optimizers, <span class="bu" style="color: null;">list</span>) <span class="cf" style="color: #003B4F;">else</span> [state.optimizers]</span>
<span id="cb2-195">            </span>
<span id="cb2-196">            <span class="cf" style="color: #003B4F;">for</span> opt_idx, optimizer <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(optimizers):</span>
<span id="cb2-197">                <span class="co" style="color: #5E5E5E;"># Get optimizer state dict</span></span>
<span id="cb2-198">                opt_state <span class="op" style="color: #5E5E5E;">=</span> optimizer.state_dict()</span>
<span id="cb2-199">                </span>
<span id="cb2-200">                <span class="co" style="color: #5E5E5E;"># Check if 'state' exists in the optimizer state dict</span></span>
<span id="cb2-201">                <span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'state'</span> <span class="kw" style="color: #003B4F;">in</span> opt_state:</span>
<span id="cb2-202">                    <span class="cf" style="color: #003B4F;">for</span> param_id, param_state <span class="kw" style="color: #003B4F;">in</span> opt_state[<span class="st" style="color: #20794D;">'state'</span>].items():</span>
<span id="cb2-203">                        <span class="cf" style="color: #003B4F;">for</span> state_name, state_value <span class="kw" style="color: #003B4F;">in</span> param_state.items():</span>
<span id="cb2-204">                            <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(state_value, torch.Tensor):</span>
<span id="cb2-205">                                <span class="co" style="color: #5E5E5E;"># Store dtype of optimizer state tensors (momentum buffers, etc.)</span></span>
<span id="cb2-206">                                key <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f"optimizer_</span><span class="sc" style="color: #5E5E5E;">{</span>opt_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_param_</span><span class="sc" style="color: #5E5E5E;">{</span>param_id<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_</span><span class="sc" style="color: #5E5E5E;">{</span>state_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span></span>
<span id="cb2-207">                                <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"</span><span class="sc" style="color: #5E5E5E;">{</span>event_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:</span><span class="sc" style="color: #5E5E5E;">{</span>key<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:optimizer_states"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(state_value.dtype)</span>
<span id="cb2-208">            </span>
<span id="cb2-209">    <span class="kw" style="color: #003B4F;">def</span> _save_logs(<span class="va" style="color: #111111;">self</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-210">        os.makedirs(<span class="va" style="color: #111111;">self</span>.save_path, exist_ok<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-211">        log_file <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.save_path <span class="op" style="color: #5E5E5E;">/</span> <span class="st" style="color: #20794D;">"dtype_logs.json"</span></span>
<span id="cb2-212">        <span class="cf" style="color: #003B4F;">with</span> <span class="bu" style="color: null;">open</span>(log_file, <span class="st" style="color: #20794D;">'w'</span>) <span class="im" style="color: #00769E;">as</span> f:</span>
<span id="cb2-213">            json.dump(<span class="va" style="color: #111111;">self</span>.dtype_logs, f, indent<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<p>The most involved event handler is <code>before_forward</code> which involves creating a hook function (<code>hook_fn</code>) passed to PyTorch’s <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_forward_hook"><code>register_forward_hook</code></a> which exposes the positional inputs and outputs of a module’s <code>forward</code> pass. The hook function modifies <code>self.dtype_logs</code> directly by storing the data type string of inputs and outputs. <code>hook_fn</code> is used for all modules except self attention.</p>
<p>Self attention <a href="https://github.com/huggingface/transformers/issues/29247#issuecomment-1965894085">cannot utilize <code>register_forward_hook</code></a> because the <a href="https://github.com/huggingface/transformers/blob/bf41e54fc8242dafa31bf6203e3d505bcb907119/src/transformers/models/llama/modeling_llama.py#L345">LlamaDecoderLayer</a> does not call self attention forward pass with any positional arguments:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">hidden_states, self_attn_weights <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.self_attn(</span>
<span id="cb3-2">    hidden_states<span class="op" style="color: #5E5E5E;">=</span>hidden_states,</span>
<span id="cb3-3">    attention_mask<span class="op" style="color: #5E5E5E;">=</span>attention_mask,</span>
<span id="cb3-4">    position_ids<span class="op" style="color: #5E5E5E;">=</span>position_ids,</span>
<span id="cb3-5">    past_key_value<span class="op" style="color: #5E5E5E;">=</span>past_key_value,</span>
<span id="cb3-6">    output_attentions<span class="op" style="color: #5E5E5E;">=</span>output_attentions,</span>
<span id="cb3-7">    use_cache<span class="op" style="color: #5E5E5E;">=</span>use_cache,</span>
<span id="cb3-8">    cache_position<span class="op" style="color: #5E5E5E;">=</span>cache_position,</span>
<span id="cb3-9">    position_embeddings<span class="op" style="color: #5E5E5E;">=</span>position_embeddings,</span>
<span id="cb3-10">    <span class="op" style="color: #5E5E5E;">**</span>kwargs,</span>
<span id="cb3-11">)</span></code></pre></div>
<p>Contrast this with how the forward pass of other modules are called with positional arguments only:</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># self attention sublayers</span></span>
<span id="cb4-2">query_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.q_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb4-3">key_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.k_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb4-4">value_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.v_proj(hidden_states).view(hidden_shape).transpose(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb4-5">attn_output <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.o_proj(attn_output)</span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;"># mlp sublayers</span></span>
<span id="cb4-8">down_proj <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.down_proj(<span class="va" style="color: #111111;">self</span>.act_fn(<span class="va" style="color: #111111;">self</span>.gate_proj(x)) <span class="op" style="color: #5E5E5E;">*</span> <span class="va" style="color: #111111;">self</span>.up_proj(x))</span>
<span id="cb4-9"></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;"># non-self attention modules</span></span>
<span id="cb4-11">hidden_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.input_layernorm(hidden_states)</span>
<span id="cb4-12">hidden_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.post_attention_layernorm(hidden_states)</span>
<span id="cb4-13">hidden_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.mlp(hidden_states)</span>
<span id="cb4-14">hidden_states <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.norm(hidden_states)</span></code></pre></div>
<p>Since self-attention inputs can’t be captured by a hook I had to monkey patch its forward pass to log its inputs’ data type:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="cf" style="color: #003B4F;">for</span> layer_idx, layer <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(transformer_model.layers):</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;"># Store the original forward method</span></span>
<span id="cb5-3">    original_forward <span class="op" style="color: #5E5E5E;">=</span> layer.self_attn.forward</span>
<span id="cb5-4">    <span class="va" style="color: #111111;">self</span>.original_forward_methods[layer_idx] <span class="op" style="color: #5E5E5E;">=</span> original_forward</span>
<span id="cb5-5">    </span>
<span id="cb5-6">    <span class="co" style="color: #5E5E5E;"># Define a closure to capture the current layer_idx</span></span>
<span id="cb5-7">    <span class="kw" style="color: #003B4F;">def</span> make_patched_forward(layer_idx, orig_forward):</span>
<span id="cb5-8">        <span class="kw" style="color: #003B4F;">def</span> patched_forward(self_attn, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb5-9">            <span class="co" style="color: #5E5E5E;"># Log the hidden_states dtype</span></span>
<span id="cb5-10">            <span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'hidden_states'</span> <span class="kw" style="color: #003B4F;">in</span> kwargs <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">hasattr</span>(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>], <span class="st" style="color: #20794D;">'dtype'</span>):</span>
<span id="cb5-11">                <span class="va" style="color: #111111;">self</span>.dtype_logs[<span class="st" style="color: #20794D;">"log"</span>][<span class="ss" style="color: #20794D;">f"forward:self_attn:layer_</span><span class="sc" style="color: #5E5E5E;">{</span>layer_idx<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">:activation_input"</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(kwargs[<span class="st" style="color: #20794D;">'hidden_states'</span>].dtype)</span>
<span id="cb5-12">            </span>
<span id="cb5-13">            <span class="co" style="color: #5E5E5E;"># Call the original method as a bound method</span></span>
<span id="cb5-14">            <span class="co" style="color: #5E5E5E;"># This ensures 'self_attn' is correctly passed as 'self'</span></span>
<span id="cb5-15">            <span class="cf" style="color: #003B4F;">return</span> orig_forward.<span class="fu" style="color: #4758AB;">__get__</span>(self_attn, <span class="bu" style="color: null;">type</span>(self_attn))(<span class="op" style="color: #5E5E5E;">**</span>kwargs)</span>
<span id="cb5-16">        </span>
<span id="cb5-17">        <span class="cf" style="color: #003B4F;">return</span> patched_forward</span>
<span id="cb5-18"></span>
<span id="cb5-19">    <span class="co" style="color: #5E5E5E;"># Replace the forward method</span></span>
<span id="cb5-20">    layer.self_attn.forward <span class="op" style="color: #5E5E5E;">=</span> make_patched_forward(layer_idx, original_forward).<span class="fu" style="color: #4758AB;">__get__</span>(layer.self_attn, <span class="bu" style="color: null;">type</span>(layer.self_attn))</span></code></pre></div>
<p><code>patched_forward</code> receives positional arguments <code>*args</code> (of which there are none) and keyword arguments <code>**kwargs</code> (all of the arguments to the self-attention forward) and logs the data types of the inputs to self-attention (<code>hidden_states</code>) as <code>self_attn_input</code> before returning the outputs of the original forward pass.</p>
<p>A key line is <code>orig_forward.__get__(self_attn, type(self_attn))(**kwargs)</code>. As Claude’s comment mentions, this is to avoid using <code>orig_forward(self_attn, **kwargs)</code> which was causing the following error because the first argument, <code>self_attn</code>, was being interpreted as <code>hidden_states</code> whereas it was intended to represent <code>self</code>:</p>
<pre><code>TypeError: LlamaFlashAttention2.forward() got multiple values for argument 'hidden_states'</code></pre>
<p>In short, when you call <code>__get__(obj, type)</code> on a function it will bind that function as a method to the given object, thus no longer requiring you to pass in <code>self</code> as an argument. This is critical because <code>self_attn.forward</code> <em>has no positional arguments</em>. We can then pass in the keyword arguments to the bound method <code>orig_forward.__get__(self_attn, type(self_attn))(**kwargs)</code>, and let the model continue using self-attention correctly. See the <a href="https://docs.python.org/3/howto/descriptor.html#functions-and-methods:~:text=To%20recap%2C%20functions%20have%20a%20__get__()%20method%20so%20that%20they%20can%20be%20converted%20to%20a%20method%20when%20accessed%20as%20attributes.%20The%20non%2Ddata%20descriptor%20transforms%20an%20obj.f(*args)%20call%20into%20f(obj%2C%20*args).%20Calling%20cls.f(*args)%20becomes%20f(*args).">Descriptor Guide in the Python docs</a> for more information.</p>
</section>
<section id="helper-functions" class="level2">
<h2 class="anchored" data-anchor-id="helper-functions">Helper Functions</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;">import</span> re</span>
<span id="cb7-2"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb7-3"><span class="im" style="color: #00769E;">import</span> json</span>
<span id="cb7-4"><span class="im" style="color: #00769E;">import</span> requests</span></code></pre></div>
</div>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;">def</span> parse_index(string):</span>
<span id="cb8-2">    <span class="co" style="color: #5E5E5E;">"""Extract structured information from parameter names"""</span></span>
<span id="cb8-3">    info <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb8-4">        <span class="st" style="color: #20794D;">'layer_number'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-5">        <span class="st" style="color: #20794D;">'module'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-6">        <span class="st" style="color: #20794D;">'layer_name'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-7">        <span class="st" style="color: #20794D;">'lora_layer'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-8">        <span class="st" style="color: #20794D;">'training_step'</span>: <span class="va" style="color: #111111;">None</span>,</span>
<span id="cb8-9">        <span class="st" style="color: #20794D;">'entity'</span>: <span class="va" style="color: #111111;">None</span></span>
<span id="cb8-10">    }</span>
<span id="cb8-11"></span>
<span id="cb8-12">    <span class="co" style="color: #5E5E5E;"># layer = string.split(":")[1]</span></span>
<span id="cb8-13">    <span class="co" style="color: #5E5E5E;"># info["layer"] = layer</span></span>
<span id="cb8-14"></span>
<span id="cb8-15">    layer_number_match <span class="op" style="color: #5E5E5E;">=</span> re.search(<span class="vs" style="color: #20794D;">r'layers\.(\d+)'</span>, string)</span>
<span id="cb8-16">    <span class="cf" style="color: #003B4F;">if</span> layer_number_match: info[<span class="st" style="color: #20794D;">'layer_number'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(layer_number_match.group(<span class="dv" style="color: #AD0000;">1</span>))</span>
<span id="cb8-17"></span>
<span id="cb8-18">    modules <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb8-19">        <span class="st" style="color: #20794D;">"embed_tokens"</span>,</span>
<span id="cb8-20">        <span class="st" style="color: #20794D;">"input_layernorm"</span>,</span>
<span id="cb8-21">        <span class="st" style="color: #20794D;">"self_attn"</span>,</span>
<span id="cb8-22">        <span class="st" style="color: #20794D;">"post_attention_layernorm"</span>,</span>
<span id="cb8-23">        <span class="st" style="color: #20794D;">"mlp"</span>,</span>
<span id="cb8-24">        <span class="st" style="color: #20794D;">"norm"</span>,</span>
<span id="cb8-25">        <span class="st" style="color: #20794D;">"lm_head"</span></span>
<span id="cb8-26">    ]</span>
<span id="cb8-27"></span>
<span id="cb8-28">    module_match <span class="op" style="color: #5E5E5E;">=</span> re.search(<span class="vs" style="color: #20794D;">r'(mlp|self_attn|input_layernorm|post_attention_layernorm|embed_tokens|norm|lm_head)'</span>, string)</span>
<span id="cb8-29">    <span class="cf" style="color: #003B4F;">if</span> module_match: info[<span class="st" style="color: #20794D;">'module'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(modules.index(module_match.group(<span class="dv" style="color: #AD0000;">1</span>))).zfill(<span class="dv" style="color: #AD0000;">2</span>) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'_'</span> <span class="op" style="color: #5E5E5E;">+</span> module_match.group(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb8-30"></span>
<span id="cb8-31">    layer_name_match <span class="op" style="color: #5E5E5E;">=</span> re.search(<span class="vs" style="color: #20794D;">r'(q_proj|k_proj|v_proj|o_proj|gate_proj|up_proj|down_proj)'</span>, string)</span>
<span id="cb8-32">    <span class="cf" style="color: #003B4F;">if</span> layer_name_match: info[<span class="st" style="color: #20794D;">'layer_name'</span>] <span class="op" style="color: #5E5E5E;">=</span> layer_name_match.group(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb8-33"></span>
<span id="cb8-34">    lora_match <span class="op" style="color: #5E5E5E;">=</span> re.search(<span class="vs" style="color: #20794D;">r'(base_layer|lora_A|lora_B)'</span>, string)</span>
<span id="cb8-35">    <span class="cf" style="color: #003B4F;">if</span> lora_match: info[<span class="st" style="color: #20794D;">'lora_layer'</span>] <span class="op" style="color: #5E5E5E;">=</span> lora_match.group(<span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb8-36">    <span class="cf" style="color: #003B4F;">else</span>: info[<span class="st" style="color: #20794D;">'lora_layer'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Not a LoRA Layer"</span></span>
<span id="cb8-37"></span>
<span id="cb8-38">    training_steps <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb8-39">        <span class="st" style="color: #20794D;">"fit_start"</span>,</span>
<span id="cb8-40">        <span class="st" style="color: #20794D;">"epoch_start"</span>,</span>
<span id="cb8-41">        <span class="st" style="color: #20794D;">"before_dataloader"</span>,</span>
<span id="cb8-42">        <span class="st" style="color: #20794D;">"after_dataloader"</span>,</span>
<span id="cb8-43">        <span class="st" style="color: #20794D;">"batch_start"</span>,</span>
<span id="cb8-44">        <span class="st" style="color: #20794D;">"before_forward"</span>,</span>
<span id="cb8-45">        <span class="st" style="color: #20794D;">"forward"</span>,</span>
<span id="cb8-46">        <span class="st" style="color: #20794D;">"after_forward"</span>,</span>
<span id="cb8-47">        <span class="st" style="color: #20794D;">"before_loss"</span>,</span>
<span id="cb8-48">        <span class="st" style="color: #20794D;">"after_loss"</span>,</span>
<span id="cb8-49">        <span class="st" style="color: #20794D;">"before_backward"</span>,</span>
<span id="cb8-50">        <span class="st" style="color: #20794D;">"after_backward"</span>,</span>
<span id="cb8-51">        <span class="st" style="color: #20794D;">"before_optim_step"</span>,</span>
<span id="cb8-52">        <span class="st" style="color: #20794D;">"optimizer_step"</span>,</span>
<span id="cb8-53">        <span class="st" style="color: #20794D;">"after_optim_step"</span></span>
<span id="cb8-54">        ]</span>
<span id="cb8-55"></span>
<span id="cb8-56">    training_step <span class="op" style="color: #5E5E5E;">=</span> string.split(<span class="st" style="color: #20794D;">":"</span>)[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb8-57">    info[<span class="st" style="color: #20794D;">'training_step'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(training_steps.index(training_step)).zfill(<span class="dv" style="color: #AD0000;">2</span>) <span class="op" style="color: #5E5E5E;">+</span> <span class="st" style="color: #20794D;">'_'</span> <span class="op" style="color: #5E5E5E;">+</span> training_step</span>
<span id="cb8-58"></span>
<span id="cb8-59">    info[<span class="st" style="color: #20794D;">'entity'</span>] <span class="op" style="color: #5E5E5E;">=</span> string.split(<span class="st" style="color: #20794D;">":"</span>)[<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb8-60"></span>
<span id="cb8-61"></span>
<span id="cb8-62">    <span class="cf" style="color: #003B4F;">return</span> info</span></code></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;">def</span> _df(url):</span>
<span id="cb9-2">    dtype_data <span class="op" style="color: #5E5E5E;">=</span> json.loads(requests.get(url).text)</span>
<span id="cb9-3"></span>
<span id="cb9-4">    df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(dtype_data).reset_index()</span>
<span id="cb9-5">    df <span class="op" style="color: #5E5E5E;">=</span> df.rename(columns<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">"index"</span>: <span class="st" style="color: #20794D;">"index"</span>, <span class="st" style="color: #20794D;">"log"</span>: <span class="st" style="color: #20794D;">"dtype"</span>})</span>
<span id="cb9-6"></span>
<span id="cb9-7">    parsed_info <span class="op" style="color: #5E5E5E;">=</span> df[<span class="st" style="color: #20794D;">'index'</span>].<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: parse_index(x))</span>
<span id="cb9-8"></span>
<span id="cb9-9">    df[<span class="st" style="color: #20794D;">'layer_number'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'layer_number'</span>])</span>
<span id="cb9-10">    df[<span class="st" style="color: #20794D;">'module'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'module'</span>])</span>
<span id="cb9-11">    df[<span class="st" style="color: #20794D;">'layer_name'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'layer_name'</span>])</span>
<span id="cb9-12">    df[<span class="st" style="color: #20794D;">'lora_layer'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'lora_layer'</span>])</span>
<span id="cb9-13">    df[<span class="st" style="color: #20794D;">'training_step'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'training_step'</span>])</span>
<span id="cb9-14">    df[<span class="st" style="color: #20794D;">'entity'</span>] <span class="op" style="color: #5E5E5E;">=</span> parsed_info.<span class="bu" style="color: null;">apply</span>(<span class="kw" style="color: #003B4F;">lambda</span> x: x[<span class="st" style="color: #20794D;">'entity'</span>])</span>
<span id="cb9-15"></span>
<span id="cb9-16">    <span class="cf" style="color: #003B4F;">return</span> df</span></code></pre></div>
</div>
</section>
<section id="model-in-fp32-master_weights_dtypenone" class="level2">
<h2 class="anchored" data-anchor-id="model-in-fp32-master_weights_dtypenone">Model in fp32 (<code>master_weights_dtype==None</code>)</h2>
<p>In this case, <code>master_weights_dtype</code> is not provided in the training YAML file.</p>
<div class="cell" data-outputid="73fb1c7d-f091-413b-90af-cf9fb0c6eb51" data-execution_count="5">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">url <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"https://gist.githubusercontent.com/vishalbakshi/9ade8d501629d4c30e8aecfa1c6f67cf/raw/0c162e2305002fbe57fd2570ade302c3659140a1/dtypes_logs_1ba_fp32.json"</span></span>
<span id="cb10-2">df <span class="op" style="color: #5E5E5E;">=</span> _df(url)</span>
<span id="cb10-3">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">


  <div id="df-f6bb70e8-9110-47f0-85d1-46d907c311a6" class="colab-df-container">
    <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>index</th>
      <th>dtype</th>
      <th>layer_number</th>
      <th>module</th>
      <th>layer_name</th>
      <th>lora_layer</th>
      <th>training_step</th>
      <th>entity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>fit_start:embed_tokens.weight:weights</td>
      <td>torch.float32</td>
      <td>NaN</td>
      <td>00_embed_tokens</td>
      <td>None</td>
      <td>Not a LoRA Layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fit_start:layers.0.self_attn.q_proj.base_layer...</td>
      <td>torch.float32</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>base_layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fit_start:layers.0.self_attn.q_proj.lora_A.def...</td>
      <td>torch.float32</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>lora_A</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fit_start:layers.0.self_attn.q_proj.lora_B.def...</td>
      <td>torch.float32</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>lora_B</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>4</th>
      <td>fit_start:layers.0.self_attn.k_proj.base_layer...</td>
      <td>torch.float32</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>k_proj</td>
      <td>base_layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-f6bb70e8-9110-47f0-85d1-46d907c311a6')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-f6bb70e8-9110-47f0-85d1-46d907c311a6 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-f6bb70e8-9110-47f0-85d1-46d907c311a6');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-b878e7a4-6a3d-484e-8565-4873e2d61a8a">
  <button class="colab-df-quickchart" onclick="quickchart('df-b878e7a4-6a3d-484e-8565-4873e2d61a8a')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-b878e7a4-6a3d-484e-8565-4873e2d61a8a button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<section id="data-types-by-lora_layer" class="level3">
<h3 class="anchored" data-anchor-id="data-types-by-lora_layer">Data Types by <code>lora_layer</code></h3>
<p>All LoRA layer entities are in fp32.</p>
<div class="cell" data-outputid="d3494bca-3fbd-4a42-ae1b-5087d3ef6618" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">df.groupby([<span class="st" style="color: #20794D;">'lora_layer'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>lora_layer</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="4" valign="top">Not a LoRA Layer</th>
      <th>None</th>
      <td>62</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>331</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>2339</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">base_layer</th>
      <th>None</th>
      <td>210</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>2520</td>
    </tr>
    <tr>
      <th>lora_A</th>
      <th>torch.float32</th>
      <td>2730</td>
    </tr>
    <tr>
      <th>lora_B</th>
      <th>torch.float32</th>
      <td>2730</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
<section id="data-types-by-entity-activations-gradients-loss-optimizer-states-and-weights" class="level3">
<h3 class="anchored" data-anchor-id="data-types-by-entity-activations-gradients-loss-optimizer-states-and-weights">Data Types by <code>entity</code> (Activations, Gradients, Loss, Optimizer States and Weights)</h3>
<p>Every entity except activations are in fp32. Some parameters don’t have gradients because we are training with LoRA.</p>
<div class="cell" data-outputid="78343b50-69b7-4e1e-f2eb-58f2a3fbc781" data-execution_count="7">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">df.groupby([<span class="st" style="color: #20794D;">'entity'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>entity</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="3" valign="top">activation_input</th>
      <th>torch.bfloat16</th>
      <td>60</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">activation_output</th>
      <th>torch.bfloat16</th>
      <td>271</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>62</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">gradients</th>
      <th>None</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>420</td>
    </tr>
    <tr>
      <th>loss</th>
      <th>torch.float32</th>
      <td>1</td>
    </tr>
    <tr>
      <th>optimizer_states</th>
      <th>torch.float32</th>
      <td>1260</td>
    </tr>
    <tr>
      <th>weights</th>
      <th>torch.float32</th>
      <td>8304</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
<section id="data-types-by-composer-training-step" class="level3">
<h3 class="anchored" data-anchor-id="data-types-by-composer-training-step">Data Types by Composer Training Step</h3>
<div class="cell" data-outputid="98def9cf-d2c3-4003-a11c-1293b9879460" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">df.groupby([<span class="st" style="color: #20794D;">'training_step'</span>, <span class="st" style="color: #20794D;">'entity'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>training_step</th>
      <th>entity</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>00_fit_start</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>01_epoch_start</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>02_before_dataloader</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>03_after_dataloader</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>04_batch_start</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>05_before_forward</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">06_forward</th>
      <th rowspan="3" valign="top">activation_input</th>
      <th>torch.bfloat16</th>
      <td>60</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">activation_output</th>
      <th>torch.bfloat16</th>
      <td>271</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>62</td>
    </tr>
    <tr>
      <th>07_after_forward</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>08_before_loss</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">09_after_loss</th>
      <th>loss</th>
      <th>torch.float32</th>
      <td>1</td>
    </tr>
    <tr>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>10_before_backward</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">11_after_backward</th>
      <th rowspan="2" valign="top">gradients</th>
      <th>None</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>420</td>
    </tr>
    <tr>
      <th>12_before_optim_step</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
    <tr>
      <th>13_optimizer_step</th>
      <th>optimizer_states</th>
      <th>torch.float32</th>
      <td>1260</td>
    </tr>
    <tr>
      <th>14_after_optim_step</th>
      <th>weights</th>
      <th>torch.float32</th>
      <td>692</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
</section>
<section id="model-in-bf16-master_weights_dtypebfloat16" class="level2">
<h2 class="anchored" data-anchor-id="model-in-bf16-master_weights_dtypebfloat16">Model in bf16 (<code>master_weights_dtype==bfloat16</code>)</h2>
<p>I also logged data types after setting <code>master_weights_dtype</code> in the training YAML to <code>bfloat16</code>.</p>
<div class="cell" data-outputid="5b638922-40c0-42a9-9c0e-8b907d105abd" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">url <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"https://gist.githubusercontent.com/vishalbakshi/ec91a59754633611fd8eb33b59031243/raw/5b83a7ebd5759cf6bd2db2369edf1c73e1fb67cf/dtypes_logs_1ba_bf16.json"</span></span>
<span id="cb14-2">df <span class="op" style="color: #5E5E5E;">=</span> _df(url)</span>
<span id="cb14-3">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">


  <div id="df-6f3e8532-20df-451d-8e93-caa52d279f3f" class="colab-df-container">
    <div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>index</th>
      <th>dtype</th>
      <th>layer_number</th>
      <th>module</th>
      <th>layer_name</th>
      <th>lora_layer</th>
      <th>training_step</th>
      <th>entity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>fit_start:embed_tokens.weight:weights</td>
      <td>torch.bfloat16</td>
      <td>NaN</td>
      <td>00_embed_tokens</td>
      <td>None</td>
      <td>Not a LoRA Layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fit_start:layers.0.self_attn.q_proj.base_layer...</td>
      <td>torch.bfloat16</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>base_layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>2</th>
      <td>fit_start:layers.0.self_attn.q_proj.lora_A.def...</td>
      <td>torch.bfloat16</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>lora_A</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>3</th>
      <td>fit_start:layers.0.self_attn.q_proj.lora_B.def...</td>
      <td>torch.bfloat16</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>q_proj</td>
      <td>lora_B</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
    <tr>
      <th>4</th>
      <td>fit_start:layers.0.self_attn.k_proj.base_layer...</td>
      <td>torch.bfloat16</td>
      <td>0.0</td>
      <td>02_self_attn</td>
      <td>k_proj</td>
      <td>base_layer</td>
      <td>00_fit_start</td>
      <td>weights</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-6f3e8532-20df-451d-8e93-caa52d279f3f')" title="Convert this dataframe to an interactive table." style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"></path>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-6f3e8532-20df-451d-8e93-caa52d279f3f button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-6f3e8532-20df-451d-8e93-caa52d279f3f');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-159646a6-3c88-49de-8770-5f4464ad1b49">
  <button class="colab-df-quickchart" onclick="quickchart('df-159646a6-3c88-49de-8770-5f4464ad1b49')" title="Suggest charts" style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewbox="0 0 24 24" width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"></path>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-159646a6-3c88-49de-8770-5f4464ad1b49 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>
</div>
</div>
<section id="data-type-by-lora_layer" class="level3">
<h3 class="anchored" data-anchor-id="data-type-by-lora_layer">Data Type by <code>lora_layer</code></h3>
<p>Interestingly, setting <code>master_weights_dtype</code> makes all LoRA layers bfloat16 but some non-LoRA layers’ entities are still in fp32.</p>
<div class="cell" data-outputid="b18ff791-dbf5-40a8-fcfe-402ed510d645" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">df.groupby([<span class="st" style="color: #20794D;">'lora_layer'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>lora_layer</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="4" valign="top">Not a LoRA Layer</th>
      <th>None</th>
      <td>62</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>2249</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>421</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">base_layer</th>
      <th>None</th>
      <td>210</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>2520</td>
    </tr>
    <tr>
      <th>lora_A</th>
      <th>torch.bfloat16</th>
      <td>2730</td>
    </tr>
    <tr>
      <th>lora_B</th>
      <th>torch.bfloat16</th>
      <td>2730</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
<section id="data-types-by-entity-activations-gradients-loss-optimizer-states-and-weights-1" class="level3">
<h3 class="anchored" data-anchor-id="data-types-by-entity-activations-gradients-loss-optimizer-states-and-weights-1">Data Types by <code>entity</code> (Activations, Gradients, Loss, Optimizer States and Weights)</h3>
<p>All floating point values are in bfloat16 except for the loss and some of the optimizer states. I’m not sure why some optimizer states are in bf16, even though it says in the <a href="https://docs.mosaicml.com/projects/composer/en/latest/notes/numerics.html#automatic-mixed-precision-amp-training">Composer docs</a>:</p>
<blockquote class="blockquote">
<p>Store the weights and perform the optimizer step in single precision, enabling the weight update to be done more precisely.</p>
</blockquote>
<div class="cell" data-outputid="17283b63-7034-448d-f2a6-b51857b9d320" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">df.groupby([<span class="st" style="color: #20794D;">'entity'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>entity</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">activation_input</th>
      <th>torch.bfloat16</th>
      <td>332</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th>activation_output</th>
      <th>torch.bfloat16</th>
      <td>333</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">gradients</th>
      <th>None</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>420</td>
    </tr>
    <tr>
      <th>loss</th>
      <th>torch.float32</th>
      <td>1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">optimizer_states</th>
      <th>torch.bfloat16</th>
      <td>840</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>420</td>
    </tr>
    <tr>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>8304</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
<section id="data-type-by-composer-training-step" class="level3">
<h3 class="anchored" data-anchor-id="data-type-by-composer-training-step">Data Type by Composer Training Step</h3>
<div class="cell" data-outputid="168d15bc-1303-40c0-cc01-7a529ed5cb5d" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">df.groupby([<span class="st" style="color: #20794D;">'training_step'</span>, <span class="st" style="color: #20794D;">'entity'</span>, <span class="st" style="color: #20794D;">'dtype'</span>])[<span class="st" style="color: #20794D;">'dtype'</span>].count()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th></th>
      <th>dtype</th>
    </tr>
    <tr>
      <th>training_step</th>
      <th>entity</th>
      <th>dtype</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>00_fit_start</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>01_epoch_start</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>02_before_dataloader</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>03_after_dataloader</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>04_batch_start</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>05_before_forward</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="3" valign="top">06_forward</th>
      <th rowspan="2" valign="top">activation_input</th>
      <th>torch.bfloat16</th>
      <td>332</td>
    </tr>
    <tr>
      <th>torch.int64</th>
      <td>1</td>
    </tr>
    <tr>
      <th>activation_output</th>
      <th>torch.bfloat16</th>
      <td>333</td>
    </tr>
    <tr>
      <th>07_after_forward</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>08_before_loss</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">09_after_loss</th>
      <th>loss</th>
      <th>torch.float32</th>
      <td>1</td>
    </tr>
    <tr>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th>10_before_backward</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">11_after_backward</th>
      <th rowspan="2" valign="top">gradients</th>
      <th>None</th>
      <td>272</td>
    </tr>
    <tr>
      <th>torch.bfloat16</th>
      <td>420</td>
    </tr>
    <tr>
      <th>12_before_optim_step</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">13_optimizer_step</th>
      <th rowspan="2" valign="top">optimizer_states</th>
      <th>torch.bfloat16</th>
      <td>840</td>
    </tr>
    <tr>
      <th>torch.float32</th>
      <td>420</td>
    </tr>
    <tr>
      <th>14_after_optim_step</th>
      <th>weights</th>
      <th>torch.bfloat16</th>
      <td>692</td>
    </tr>
  </tbody>
</table>
</div><br><label><b>dtype:</b> int64</label>
</div>
</div>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>I absolutely loved this exercise. I learned a ton about callbacks, data types during mixed precision training, and Python fundamentals. Working with LLM-Foundry has opened up a whole universe of learning opportunities as I try to better understand what’s going on under the hood. It’s a gift that keeps giving!</p>
<p>I’m trying to grow <a href="https://www.youtube.com/@vishal_learner">my YouTube channel</a> so please give it a visit and subscribe if you want to stay in the loop.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-02-Composer-Callback-Logging-dtypes/index.html</guid>
  <pubDate>Wed, 02 Apr 2025 07:00:00 GMT</pubDate>
</item>
<item>
  <title>Understanding Python Descriptors</title>
  <dc:creator>Vishal Bakshi</dc:creator>
  <link>https://vishalbakshi.github.io/blog/posts/2025-04-01-Python-Descriptor/index.html</link>
  <description><![CDATA[ 



<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>When monkey-patching the Llama self-attention forward pass (to log its inputs’ data type) I was vibe coding with Claude and it generated the following line to pass the necessary arguments to the original forward pass of the module:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">orig_forward.<span class="fu" style="color: #4758AB;">__get__</span>(self_attn, <span class="bu" style="color: null;">type</span>(self_attn))(<span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
<p>In a prior iteration, I was using the following line suggested by Claude, with the intention of passing <code>self_attn</code> as <code>self</code>:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">orig_forward(self_attn, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
<p>This was essentially doing the following:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">orig_forward(self_attn, hidden_states<span class="op" style="color: #5E5E5E;">=</span>hidden_states, attention_mask<span class="op" style="color: #5E5E5E;">=</span>attention_mask, ...)</span></code></pre></div>
<p>Which caused the following error:</p>
<pre><code>TypeError: LlamaFlashAttention2.forward() got multiple values for argument 'hidden_states'</code></pre>
<p><code>self_attn</code> was being passed as the argument to the <code>hidden_states</code> parameter, and then <code>hidden_states=hidden_states</code> was again assigning an argument to the <code>hidden_states</code> parameter. So how do we pass <code>self_attn</code> as <code>self</code>? This is where the <code>__get__</code> method comes in which is part of the Python <a href="https://docs.python.org/3/glossary.html#term-descriptor">Descriptor</a>. Descriptors are:</p>
<blockquote class="blockquote">
<p>Any object which defines the methods <code>__get__()</code>, <code>__set__()</code>, or <code>__delete__()</code>. When a class attribute is a descriptor, its special binding behavior is triggered upon attribute lookup. Normally, using <em>a.b</em> to get, set or delete an attribute looks up the object named <em>b</em> in the class dictionary for <em>a</em>, but if <em>b</em> is a descriptor, the respective descriptor method gets called. Understanding descriptors is a key to a deep understanding of Python because they are the basis for many features including functions, methods, properties, class methods, static methods, and reference to super classes.</p>
</blockquote>
<p>After reading that a few times I still didn’t understand it! Though I think the key is:</p>
<blockquote class="blockquote">
<p>When a class attribute is a descriptor, its special binding behavior is triggered upon attribute lookup.</p>
</blockquote>
<p>Claude explained it this way:</p>
<blockquote class="blockquote">
<p><code>__get__</code> is a special method that converts a function into a bound method. It’s like saying “make this function a method of this object.”</p>
</blockquote>
<p>Translating that to my use case: <code>__get__</code> makes <code>orig_forward</code> a method of <code>self_attn</code>, no longer requiring us to pass <code>self_attn</code> as it now is <code>self</code>.</p>
<p>That certainly makes sense (i.e.&nbsp;I understand those words) but I don’t really understand why or how. That led me to the Python documentation’s <a href="https://docs.python.org/3/howto/descriptor.html#id1">Descriptor Guide</a> which I’ll walk through here.</p>
<p>(There was also this interesting <a href="https://discuss.python.org/t/changing-the-name-of-get-to-bind/14243">discussion</a> about changing the name to <code>__bind__</code> when calling it on a function as it binds the function as a method of the given object, which we’ll see later on).</p>
</section>
<section id="primer" class="level2">
<h2 class="anchored" data-anchor-id="primer">Primer</h2>
<section id="simple-example-a-descriptor-that-returns-a-constant" class="level3">
<h3 class="anchored" data-anchor-id="simple-example-a-descriptor-that-returns-a-constant">Simple example: A descriptor that returns a constant</h3>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;">class</span> Ten:</span>
<span id="cb5-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb5-3">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">10</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="eeac4968-a49d-4411-c5f6-3231b2ff396c" data-execution_count="18">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">t <span class="op" style="color: #5E5E5E;">=</span> Ten()</span>
<span id="cb6-2">t</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>&lt;__main__.Ten at 0x78b2fd072c50&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="3c8c18b5-e974-4c71-90cd-bed54365c3f9" data-execution_count="19">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="bu" style="color: null;">type</span>(t)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>__main__.Ten</code></pre>
</div>
</div>
<div class="cell" data-outputid="6af99ff9-5bb6-4561-b5df-af18e218253f" data-execution_count="20">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">t.<span class="fu" style="color: #4758AB;">__get__</span>(<span class="dv" style="color: #AD0000;">4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>10</code></pre>
</div>
</div>
<p>I think the only reason <code>Ten</code> is a descriptor is because it “defines the methods <code>__get__()</code>, <code>__set__()</code>, or <code>__delete__()</code>”.</p>
<blockquote class="blockquote">
<p>To use the descriptor, it must be stored as a class variable in another class:</p>
</blockquote>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="kw" style="color: #003B4F;">class</span> A:</span>
<span id="cb12-2">    x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span>                       <span class="co" style="color: #5E5E5E;"># Regular class attribute</span></span>
<span id="cb12-3">    y <span class="op" style="color: #5E5E5E;">=</span> Ten()                   <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="fe3fcdb4-845c-4e7e-d4aa-83f23603d858" data-execution_count="22">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">a <span class="op" style="color: #5E5E5E;">=</span> A()                     <span class="co" style="color: #5E5E5E;"># Make an instance of class A</span></span>
<span id="cb13-2">a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>&lt;__main__.A at 0x78b2fd0707d0&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="93f0602a-05b0-4a09-b674-aa00ee892704" data-execution_count="23">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1">a.x                         <span class="co" style="color: #5E5E5E;"># Normal attribute lookup</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>5</code></pre>
</div>
</div>
<div class="cell" data-outputid="52372c3e-1077-4f9a-b2f8-71b3394c8b1b" data-execution_count="24">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">a.y                         <span class="co" style="color: #5E5E5E;"># Descriptor lookup</span></span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>10</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note that the value 10 is not stored in either the class dictionary or the instance dictionary. Instead, the value 10 is computed on demand.</p>
</blockquote>
<div class="cell" data-outputid="afb4e225-ef85-4202-eb56-db22b5269554" data-execution_count="25">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">A.__dict__</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>mappingproxy({'__module__': '__main__',
              'x': 5,
              'y': &lt;__main__.Ten at 0x78b2fd0722d0&gt;,
              '__dict__': &lt;attribute '__dict__' of 'A' objects&gt;,
              '__weakref__': &lt;attribute '__weakref__' of 'A' objects&gt;,
              '__doc__': None})</code></pre>
</div>
</div>
<p>Modifying <code>Ten</code> a bit to visualize this:</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="kw" style="color: #003B4F;">class</span> Ten2:</span>
<span id="cb21-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb21-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__get__ called with obj=</span><span class="sc" style="color: #5E5E5E;">{</span>obj<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, objtype=</span><span class="sc" style="color: #5E5E5E;">{</span>objtype<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb21-4">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb21-5"></span>
<span id="cb21-6"><span class="kw" style="color: #003B4F;">class</span> A2:</span>
<span id="cb21-7">    x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb21-8">    y <span class="op" style="color: #5E5E5E;">=</span> Ten2()  <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">a2 <span class="op" style="color: #5E5E5E;">=</span> A2()</span></code></pre></div>
</div>
<div class="cell" data-outputid="e528db12-faa4-463b-b3ba-71897fc0b887" data-execution_count="28">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">a2.y</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2fd089710&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>10</code></pre>
</div>
</div>
<p>Cool!</p>
</section>
<section id="dynamic-lookups" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-lookups">Dynamic Lookups</h3>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb26-2"></span>
<span id="cb26-3"><span class="kw" style="color: #003B4F;">class</span> DirectorySize:</span>
<span id="cb26-4"></span>
<span id="cb26-5">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb26-6">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">len</span>(os.listdir(obj.dirname))</span>
<span id="cb26-7"></span>
<span id="cb26-8"><span class="kw" style="color: #003B4F;">class</span> Directory:</span>
<span id="cb26-9"></span>
<span id="cb26-10">    size <span class="op" style="color: #5E5E5E;">=</span> DirectorySize()              <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span>
<span id="cb26-11"></span>
<span id="cb26-12">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, dirname):</span>
<span id="cb26-13">        <span class="va" style="color: #111111;">self</span>.dirname <span class="op" style="color: #5E5E5E;">=</span> dirname          <span class="co" style="color: #5E5E5E;"># Regular instance attribute</span></span></code></pre></div>
</div>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1">s <span class="op" style="color: #5E5E5E;">=</span> Directory(<span class="st" style="color: #20794D;">'songs'</span>)</span>
<span id="cb27-2">g <span class="op" style="color: #5E5E5E;">=</span> Directory(<span class="st" style="color: #20794D;">'games'</span>)</span></code></pre></div>
</div>
<div class="cell" data-outputid="09aa2729-6427-4da8-e619-fb6ce2abd29e" data-execution_count="54">
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1">s.size</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>4</code></pre>
</div>
</div>
<div class="cell" data-outputid="5f1ace26-b65a-4747-dccf-150ae2da1111" data-execution_count="48">
<div class="sourceCode cell-code" id="cb30" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1">g.size</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>2</code></pre>
</div>
</div>
<p>Removing a file then calling the descriptor’s <code>__get__</code> dynamically calculates the new value:</p>
<div class="cell" data-outputid="0e7788d5-e734-40fc-df0c-07077782244a" data-execution_count="49">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1">os.remove(<span class="st" style="color: #20794D;">'games/game1.txt'</span>)            <span class="co" style="color: #5E5E5E;"># Delete a game</span></span>
<span id="cb32-2">g.size</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>1</code></pre>
</div>
</div>
</section>
<section id="managed-attributes" class="level3">
<h3 class="anchored" data-anchor-id="managed-attributes">Managed attributes</h3>
<blockquote class="blockquote">
<p>The descriptor is assigned to a public attribute in the class dictionary while the actual data is stored as a private attribute in the instance dictionary.</p>
</blockquote>
<p>Note that I wasn’t able to see the logging output in this notebook so I’m using print statements instead.</p>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb34" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><span class="kw" style="color: #003B4F;">class</span> LoggedAgeAccess:</span>
<span id="cb34-2"></span>
<span id="cb34-3">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb34-4">        value <span class="op" style="color: #5E5E5E;">=</span> obj._age</span>
<span id="cb34-5">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Accessing age giving </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb34-6">        <span class="cf" style="color: #003B4F;">return</span> value</span>
<span id="cb34-7"></span>
<span id="cb34-8">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__set__</span>(<span class="va" style="color: #111111;">self</span>, obj, value):</span>
<span id="cb34-9">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Updating age to </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb34-10">        obj._age <span class="op" style="color: #5E5E5E;">=</span> value</span>
<span id="cb34-11"></span>
<span id="cb34-12"><span class="kw" style="color: #003B4F;">class</span> Person:</span>
<span id="cb34-13"></span>
<span id="cb34-14">    age <span class="op" style="color: #5E5E5E;">=</span> LoggedAgeAccess()             <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span>
<span id="cb34-15"></span>
<span id="cb34-16">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, name, age):</span>
<span id="cb34-17">        <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name                <span class="co" style="color: #5E5E5E;"># Regular instance attribute</span></span>
<span id="cb34-18">        <span class="va" style="color: #111111;">self</span>.age <span class="op" style="color: #5E5E5E;">=</span> age                  <span class="co" style="color: #5E5E5E;"># Calls __set__()</span></span>
<span id="cb34-19"></span>
<span id="cb34-20">    <span class="kw" style="color: #003B4F;">def</span> birthday(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb34-21">        <span class="va" style="color: #111111;">self</span>.age <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span>                   <span class="co" style="color: #5E5E5E;"># Calls both __get__() and __set__()</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="8b75d44a-d3d3-4a0f-8b6a-b1526c61850c" data-execution_count="82">
<div class="sourceCode cell-code" id="cb35" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1">mary <span class="op" style="color: #5E5E5E;">=</span> Person(<span class="st" style="color: #20794D;">'Mary M'</span>, <span class="dv" style="color: #AD0000;">30</span>)         <span class="co" style="color: #5E5E5E;"># The initial age update is logged</span></span>
<span id="cb35-2">dave <span class="op" style="color: #5E5E5E;">=</span> Person(<span class="st" style="color: #20794D;">'David D'</span>, <span class="dv" style="color: #AD0000;">40</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Updating age to 30
Updating age to 40</code></pre>
</div>
</div>
<div class="cell" data-outputid="6bfbbf95-7e19-4375-e7d0-3ea569224486" data-execution_count="83">
<div class="sourceCode cell-code" id="cb37" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><span class="bu" style="color: null;">vars</span>(mary), <span class="bu" style="color: null;">vars</span>(dave)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>({'name': 'Mary M', '_age': 30}, {'name': 'David D', '_age': 40})</code></pre>
</div>
</div>
<div class="cell" data-outputid="b498be42-317d-4880-e5cd-0ec735143778" data-execution_count="84">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1">mary.age</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accessing age giving 30</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>30</code></pre>
</div>
</div>
<div class="cell" data-outputid="c30f9e43-22cb-4d26-b75b-75d9c486f9b9" data-execution_count="85">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">mary.birthday()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accessing age giving 30
Updating age to 31</code></pre>
</div>
</div>
<div class="cell" data-outputid="317f28b0-1e3a-49ed-ef6b-fa6904e9c636" data-execution_count="86">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1">mary.age</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accessing age giving 31</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>31</code></pre>
</div>
</div>
<div class="cell" data-outputid="805635b0-8485-4fdb-b066-60314f8ff50c" data-execution_count="87">
<div class="sourceCode cell-code" id="cb47" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1">dave.name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>'David D'</code></pre>
</div>
</div>
<div class="cell" data-outputid="a14b4606-f0e2-4654-956e-0b937a8bc394" data-execution_count="88">
<div class="sourceCode cell-code" id="cb49" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1">dave.age</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accessing age giving 40</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>40</code></pre>
</div>
</div>
</section>
<section id="customized-names" class="level3">
<h3 class="anchored" data-anchor-id="customized-names">Customized names</h3>
<blockquote class="blockquote">
<p>When a class uses descriptors, it can inform each descriptor about which variable name was used.</p>
</blockquote>
<div class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb52" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><span class="kw" style="color: #003B4F;">class</span> LoggedAccess:</span>
<span id="cb52-2"></span>
<span id="cb52-3">    <span class="kw" style="color: #003B4F;">def</span> __set_name__(<span class="va" style="color: #111111;">self</span>, owner, name):</span>
<span id="cb52-4">        <span class="va" style="color: #111111;">self</span>.public_name <span class="op" style="color: #5E5E5E;">=</span> name</span>
<span id="cb52-5">        <span class="va" style="color: #111111;">self</span>.private_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'_'</span> <span class="op" style="color: #5E5E5E;">+</span> name</span>
<span id="cb52-6"></span>
<span id="cb52-7">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb52-8">        value <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">getattr</span>(obj, <span class="va" style="color: #111111;">self</span>.private_name)</span>
<span id="cb52-9">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Accessing </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>public_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> giving </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb52-10">        <span class="cf" style="color: #003B4F;">return</span> value</span>
<span id="cb52-11"></span>
<span id="cb52-12">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__set__</span>(<span class="va" style="color: #111111;">self</span>, obj, value):</span>
<span id="cb52-13">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Updating </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>public_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> to </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb52-14">        <span class="bu" style="color: null;">setattr</span>(obj, <span class="va" style="color: #111111;">self</span>.private_name, value)</span>
<span id="cb52-15"></span>
<span id="cb52-16"><span class="kw" style="color: #003B4F;">class</span> Person:</span>
<span id="cb52-17"></span>
<span id="cb52-18">    name <span class="op" style="color: #5E5E5E;">=</span> LoggedAccess()                <span class="co" style="color: #5E5E5E;"># First descriptor instance</span></span>
<span id="cb52-19">    age <span class="op" style="color: #5E5E5E;">=</span> LoggedAccess()                 <span class="co" style="color: #5E5E5E;"># Second descriptor instance</span></span>
<span id="cb52-20"></span>
<span id="cb52-21">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, name, age):</span>
<span id="cb52-22">        <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name                 <span class="co" style="color: #5E5E5E;"># Calls the first descriptor</span></span>
<span id="cb52-23">        <span class="va" style="color: #111111;">self</span>.age <span class="op" style="color: #5E5E5E;">=</span> age                   <span class="co" style="color: #5E5E5E;"># Calls the second descriptor</span></span>
<span id="cb52-24"></span>
<span id="cb52-25">    <span class="kw" style="color: #003B4F;">def</span> birthday(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb52-26">        <span class="va" style="color: #111111;">self</span>.age <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="84700369-3ad4-4565-f86b-10eb90e39f15" data-execution_count="97">
<div class="sourceCode cell-code" id="cb53" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><span class="bu" style="color: null;">vars</span>(Person)[<span class="st" style="color: #20794D;">'name'</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>&lt;__main__.LoggedAccess at 0x78b2edeb8950&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="7cac51e2-e623-48fd-8fb0-5a24e8eb9ec0" data-execution_count="98">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="bu" style="color: null;">vars</span>(<span class="bu" style="color: null;">vars</span>(Person)[<span class="st" style="color: #20794D;">'name'</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="98">
<pre><code>{'public_name': 'name', 'private_name': '_name'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="92758304-fcce-4f59-b09d-4b5e8bd02aae" data-execution_count="91">
<div class="sourceCode cell-code" id="cb57" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><span class="bu" style="color: null;">vars</span>(<span class="bu" style="color: null;">vars</span>(Person)[<span class="st" style="color: #20794D;">'age'</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="91">
<pre><code>{'public_name': 'age', 'private_name': '_age'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="1eaab803-e055-4a57-c28e-be9a86a91e4e" data-execution_count="92">
<div class="sourceCode cell-code" id="cb59" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1">pete <span class="op" style="color: #5E5E5E;">=</span> Person(<span class="st" style="color: #20794D;">'Peter P'</span>, <span class="dv" style="color: #AD0000;">10</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Updating name to Peter P
Updating age to 10</code></pre>
</div>
</div>
<div class="cell" data-outputid="90fbd1f4-dd19-4e81-ddc0-fa6fc51f8cca" data-execution_count="93">
<div class="sourceCode cell-code" id="cb61" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1">kate <span class="op" style="color: #5E5E5E;">=</span> Person(<span class="st" style="color: #20794D;">'Catherine C'</span>, <span class="dv" style="color: #AD0000;">20</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Updating name to Catherine C
Updating age to 20</code></pre>
</div>
</div>
<div class="cell" data-outputid="aa93dc1b-bbef-4bba-ec4f-adea7923f972" data-execution_count="94">
<div class="sourceCode cell-code" id="cb63" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><span class="bu" style="color: null;">vars</span>(pete)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="94">
<pre><code>{'_name': 'Peter P', '_age': 10}</code></pre>
</div>
</div>
<div class="cell" data-outputid="b45e31dc-98a5-4fca-c3ab-f0f18e80416f" data-execution_count="95">
<div class="sourceCode cell-code" id="cb65" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><span class="bu" style="color: null;">vars</span>(kate)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="95">
<pre><code>{'_name': 'Catherine C', '_age': 20}</code></pre>
</div>
</div>
<p>I think the main takeaway here is that we didn’t specify the name of the field so we could use the same descriptor for both <code>name</code> and <code>age</code>.</p>
</section>
<section id="closing-thoughts" class="level3">
<h3 class="anchored" data-anchor-id="closing-thoughts">Closing thoughts</h3>
<p>Looking at how <code>__set_name__</code> behaves (the example in the <a href="https://docs.python.org/3/reference/datamodel.html#object.__set_name__">docs</a>):</p>
<div class="cell" data-outputid="0db303bd-1e64-4471-940d-7dd8c37833e8" data-execution_count="103">
<div class="sourceCode cell-code" id="cb67" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><span class="kw" style="color: #003B4F;">class</span> C:</span>
<span id="cb67-2">    <span class="kw" style="color: #003B4F;">def</span> __set_name__(<span class="va" style="color: #111111;">self</span>, owner, name):</span>
<span id="cb67-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__set_name__ called with owner=</span><span class="sc" style="color: #5E5E5E;">{</span>owner<span class="sc" style="color: #5E5E5E;">.</span><span class="va" style="color: #111111;">__name__</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, name='</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'"</span>)</span>
<span id="cb67-4">        <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name</span>
<span id="cb67-5"></span>
<span id="cb67-6"><span class="kw" style="color: #003B4F;">class</span> A:</span>
<span id="cb67-7">    x <span class="op" style="color: #5E5E5E;">=</span> C()  <span class="co" style="color: #5E5E5E;"># This will trigger __set_name__</span></span>
<span id="cb67-8">    y <span class="op" style="color: #5E5E5E;">=</span> C()  <span class="co" style="color: #5E5E5E;"># This will trigger it again with a different name</span></span>
<span id="cb67-9">    bananas <span class="op" style="color: #5E5E5E;">=</span> C()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set_name__ called with owner=A, name='x'
__set_name__ called with owner=A, name='y'
__set_name__ called with owner=A, name='bananas'</code></pre>
</div>
</div>
<div class="cell" data-outputid="940a7982-0418-4c1f-aa86-adf2fecace1f" data-execution_count="104">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1">a <span class="op" style="color: #5E5E5E;">=</span> A()</span>
<span id="cb69-2">a.x, a.y, a.x.name, a.y.name, a.bananas.name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<pre><code>(&lt;__main__.C at 0x78b331674190&gt;,
 &lt;__main__.C at 0x78b2df52ccd0&gt;,
 'x',
 'y',
 'bananas')</code></pre>
</div>
</div>
<p>The part of particular interest to me is:</p>
<blockquote class="blockquote">
<p>Descriptors are used throughout the language. It is how functions turn into bound methods.</p>
</blockquote>
</section>
</section>
<section id="complete-practical-example" class="level2">
<h2 class="anchored" data-anchor-id="complete-practical-example">Complete practical example</h2>
<section id="validator-class" class="level3">
<h3 class="anchored" data-anchor-id="validator-class">Validator class</h3>
<blockquote class="blockquote">
<p>A validator is a descriptor for managed attribute access. Prior to storing any data, it verifies that the new value meets various type and range restrictions. If those restrictions aren’t met, it raises an exception to prevent data corruption at its source.</p>
</blockquote>
<div class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><span class="im" style="color: #00769E;">from</span> abc <span class="im" style="color: #00769E;">import</span> ABC, abstractmethod</span>
<span id="cb71-2"></span>
<span id="cb71-3"><span class="kw" style="color: #003B4F;">class</span> Validator(ABC):</span>
<span id="cb71-4"></span>
<span id="cb71-5">    <span class="kw" style="color: #003B4F;">def</span> __set_name__(<span class="va" style="color: #111111;">self</span>, owner, name):</span>
<span id="cb71-6">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__set_name__ is called"</span>)</span>
<span id="cb71-7">        <span class="va" style="color: #111111;">self</span>.private_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'_'</span> <span class="op" style="color: #5E5E5E;">+</span> name</span>
<span id="cb71-8"></span>
<span id="cb71-9">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb71-10">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__get__ is called"</span>)</span>
<span id="cb71-11">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">getattr</span>(obj, <span class="va" style="color: #111111;">self</span>.private_name)</span>
<span id="cb71-12"></span>
<span id="cb71-13">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__set__</span>(<span class="va" style="color: #111111;">self</span>, obj, value):</span>
<span id="cb71-14">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__set__ is called"</span>)</span>
<span id="cb71-15">        <span class="va" style="color: #111111;">self</span>.validate(value)</span>
<span id="cb71-16">        <span class="bu" style="color: null;">setattr</span>(obj, <span class="va" style="color: #111111;">self</span>.private_name, value)</span>
<span id="cb71-17"></span>
<span id="cb71-18">    <span class="at" style="color: #657422;">@abstractmethod</span></span>
<span id="cb71-19">    <span class="kw" style="color: #003B4F;">def</span> validate(<span class="va" style="color: #111111;">self</span>, value):</span>
<span id="cb71-20">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"validate is called"</span>)</span>
<span id="cb71-21">        <span class="cf" style="color: #003B4F;">pass</span></span></code></pre></div>
</div>
</section>
<section id="custom-validators" class="level3">
<h3 class="anchored" data-anchor-id="custom-validators">Custom validators</h3>
<blockquote class="blockquote">
<p>Here are three practical data validation utilities:</p>
<ol type="1">
<li><p><code>OneOf</code> verifies that a value is one of a restricted set of options.</p></li>
<li><p><code>Number</code> verifies that a value is either an int or float. Optionally, it verifies that a value is between a given minimum or maximum.</p></li>
<li><p><code>String</code> verifies that a value is a str. Optionally, it validates a given minimum or maximum length. It can validate a user-defined predicate as well.</p></li>
</ol>
</blockquote>
<div class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><span class="kw" style="color: #003B4F;">class</span> OneOf(Validator):</span>
<span id="cb72-2"></span>
<span id="cb72-3">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, <span class="op" style="color: #5E5E5E;">*</span>options):</span>
<span id="cb72-4">        <span class="va" style="color: #111111;">self</span>.options <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">set</span>(options)</span>
<span id="cb72-5"></span>
<span id="cb72-6">    <span class="kw" style="color: #003B4F;">def</span> validate(<span class="va" style="color: #111111;">self</span>, value):</span>
<span id="cb72-7">        <span class="cf" style="color: #003B4F;">if</span> value <span class="kw" style="color: #003B4F;">not</span> <span class="kw" style="color: #003B4F;">in</span> <span class="va" style="color: #111111;">self</span>.options:</span>
<span id="cb72-8">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-9">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be one of </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>options<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-10">            )</span>
<span id="cb72-11"></span>
<span id="cb72-12"><span class="kw" style="color: #003B4F;">class</span> Number(Validator):</span>
<span id="cb72-13"></span>
<span id="cb72-14">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, minvalue<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, maxvalue<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb72-15">        <span class="va" style="color: #111111;">self</span>.minvalue <span class="op" style="color: #5E5E5E;">=</span> minvalue</span>
<span id="cb72-16">        <span class="va" style="color: #111111;">self</span>.maxvalue <span class="op" style="color: #5E5E5E;">=</span> maxvalue</span>
<span id="cb72-17"></span>
<span id="cb72-18">    <span class="kw" style="color: #003B4F;">def</span> validate(<span class="va" style="color: #111111;">self</span>, value):</span>
<span id="cb72-19">        <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="bu" style="color: null;">isinstance</span>(value, (<span class="bu" style="color: null;">int</span>, <span class="bu" style="color: null;">float</span>)):</span>
<span id="cb72-20">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">TypeError</span>(<span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be an int or float'</span>)</span>
<span id="cb72-21">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.minvalue <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> value <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="va" style="color: #111111;">self</span>.minvalue:</span>
<span id="cb72-22">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-23">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be at least </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>minvalue<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-24">            )</span>
<span id="cb72-25">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.maxvalue <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> value <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="va" style="color: #111111;">self</span>.maxvalue:</span>
<span id="cb72-26">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-27">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be no more than </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>maxvalue<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-28">            )</span>
<span id="cb72-29"></span>
<span id="cb72-30"><span class="kw" style="color: #003B4F;">class</span> String(Validator):</span>
<span id="cb72-31"></span>
<span id="cb72-32">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, minsize<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, maxsize<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, predicate<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb72-33">        <span class="va" style="color: #111111;">self</span>.minsize <span class="op" style="color: #5E5E5E;">=</span> minsize</span>
<span id="cb72-34">        <span class="va" style="color: #111111;">self</span>.maxsize <span class="op" style="color: #5E5E5E;">=</span> maxsize</span>
<span id="cb72-35">        <span class="va" style="color: #111111;">self</span>.predicate <span class="op" style="color: #5E5E5E;">=</span> predicate</span>
<span id="cb72-36"></span>
<span id="cb72-37">    <span class="kw" style="color: #003B4F;">def</span> validate(<span class="va" style="color: #111111;">self</span>, value):</span>
<span id="cb72-38">        <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="bu" style="color: null;">isinstance</span>(value, <span class="bu" style="color: null;">str</span>):</span>
<span id="cb72-39">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">TypeError</span>(<span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be an str'</span>)</span>
<span id="cb72-40">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.minsize <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(value) <span class="op" style="color: #5E5E5E;">&lt;</span> <span class="va" style="color: #111111;">self</span>.minsize:</span>
<span id="cb72-41">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-42">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be no smaller than </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>minsize<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-43">            )</span>
<span id="cb72-44">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.maxsize <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> <span class="bu" style="color: null;">len</span>(value) <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="va" style="color: #111111;">self</span>.maxsize:</span>
<span id="cb72-45">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-46">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;"> to be no bigger than </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>maxsize<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-47">            )</span>
<span id="cb72-48">        <span class="cf" style="color: #003B4F;">if</span> <span class="va" style="color: #111111;">self</span>.predicate <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">self</span>.predicate(value):</span>
<span id="cb72-49">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(</span>
<span id="cb72-50">                <span class="ss" style="color: #20794D;">f'Expected </span><span class="sc" style="color: #5E5E5E;">{</span><span class="va" style="color: #111111;">self</span><span class="sc" style="color: #5E5E5E;">.</span>predicate<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> to be true for </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">!r}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb72-51">            )</span></code></pre></div>
</div>
</section>
<section id="practical-application" class="level3">
<h3 class="anchored" data-anchor-id="practical-application">Practical application</h3>
<div class="cell" data-outputid="a291dd22-396d-4771-ef6d-f9ccf1dd7aa8" data-execution_count="119">
<div class="sourceCode cell-code" id="cb73" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><span class="kw" style="color: #003B4F;">class</span> Component:</span>
<span id="cb73-2"></span>
<span id="cb73-3">    name <span class="op" style="color: #5E5E5E;">=</span> String(minsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, maxsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>, predicate<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">str</span>.isupper)</span>
<span id="cb73-4">    kind <span class="op" style="color: #5E5E5E;">=</span> OneOf(<span class="st" style="color: #20794D;">'wood'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="st" style="color: #20794D;">'plastic'</span>)</span>
<span id="cb73-5">    quantity <span class="op" style="color: #5E5E5E;">=</span> Number(minvalue<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb73-6"></span>
<span id="cb73-7">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, name, kind, quantity):</span>
<span id="cb73-8">        <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name</span>
<span id="cb73-9">        <span class="va" style="color: #111111;">self</span>.kind <span class="op" style="color: #5E5E5E;">=</span> kind</span>
<span id="cb73-10">        <span class="va" style="color: #111111;">self</span>.quantity <span class="op" style="color: #5E5E5E;">=</span> quantity</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set_name__ is called
__set_name__ is called
__set_name__ is called</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>The descriptors prevent invalid instances from being created:</p>
</blockquote>
<div class="cell" data-outputid="3b846377-b1de-40cd-dc38-47f088d7bda6" data-execution_count="120">
<div class="sourceCode cell-code" id="cb75" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1">Component(<span class="st" style="color: #20794D;">'Widget'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="dv" style="color: #AD0000;">5</span>)      <span class="co" style="color: #5E5E5E;"># Blocked: 'Widget' is not all uppercase</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>ValueError: Expected &lt;method 'isupper' of 'str' objects&gt; to be true for 'Widget'</code></pre>
</div>
</div>
<div class="cell" data-outputid="a1ff6411-3569-4dca-91df-dc09c8cfe544" data-execution_count="121">
<div class="sourceCode cell-code" id="cb78" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1">Component(<span class="st" style="color: #20794D;">'WIDGET'</span>, <span class="st" style="color: #20794D;">'metle'</span>, <span class="dv" style="color: #AD0000;">5</span>)      <span class="co" style="color: #5E5E5E;"># Blocked: 'metle' is misspelled</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called
__set__ is called</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>ValueError: Expected 'metle' to be one of {'metal', 'plastic', 'wood'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="8b1180ca-b0c2-4911-a392-e358c0b51258" data-execution_count="122">
<div class="sourceCode cell-code" id="cb81" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1">Component(<span class="st" style="color: #20794D;">'WIDGET'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">5</span>)     <span class="co" style="color: #5E5E5E;"># Blocked: -5 is negative</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called
__set__ is called
__set__ is called</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>ValueError: Expected -5 to be at least 0</code></pre>
</div>
</div>
<div class="cell" data-outputid="f79c42d5-1ba2-48b0-a112-012fbf3be47b" data-execution_count="123">
<div class="sourceCode cell-code" id="cb84" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1">Component(<span class="st" style="color: #20794D;">'WIDGET'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="st" style="color: #20794D;">'V'</span>)    <span class="co" style="color: #5E5E5E;"># Blocked: 'V' isn't a number</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called
__set__ is called
__set__ is called</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>TypeError: Expected 'V' to be an int or float</code></pre>
</div>
</div>
<div class="cell" data-outputid="b0422385-73be-45e5-b490-fe4632f4fe19" data-execution_count="124">
<div class="sourceCode cell-code" id="cb87" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1">c <span class="op" style="color: #5E5E5E;">=</span> Component(<span class="st" style="color: #20794D;">'WIDGET'</span>, <span class="st" style="color: #20794D;">'metal'</span>, <span class="dv" style="color: #AD0000;">5</span>)  <span class="co" style="color: #5E5E5E;"># Allowed:  The inputs are valid</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__set__ is called
__set__ is called
__set__ is called</code></pre>
</div>
</div>
<div class="cell" data-outputid="bdccab04-b422-445b-dd67-18994ae02b77" data-execution_count="125">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1">c.name</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ is called</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="125">
<pre><code>'WIDGET'</code></pre>
</div>
</div>
</section>
</section>
<section id="technical-tutorial" class="level2">
<h2 class="anchored" data-anchor-id="technical-tutorial">Technical tutorial</h2>
<p>After the reading the introduction of this guide I assumed I would skip the technical tutorial, expecting it to be too technical, but after skimming it I’ve decided to go through it as it might clear some things up for me and the following line was attractive:</p>
<blockquote class="blockquote">
<p>Learning about descriptors not only provides access to a larger toolset, it creates a deeper understanding of how Python works.</p>
</blockquote>
<section id="definition-and-introduction" class="level3">
<h3 class="anchored" data-anchor-id="definition-and-introduction">Definition and introduction</h3>
<p>Reiterating the important definition that a descriptor is anything that has one of the methods in the descriptor protocol:</p>
<blockquote class="blockquote">
<p>In general, a descriptor is an attribute value that has one of the methods in the descriptor protocol. Those methods are <code>__get__()</code>, <code>__set__()</code>, and <code>__delete__()</code>. If any of those methods are defined for an attribute, it is said to be a descriptor.</p>
</blockquote>
<p>And the main goal of descriptors:</p>
<blockquote class="blockquote">
<p>The default behavior for attribute access is to get, set, or delete the attribute from an object’s dictionary.</p>
</blockquote>
</section>
<section id="descriptor-protocol" class="level3">
<h3 class="anchored" data-anchor-id="descriptor-protocol">Descriptor protocol</h3>
<p>I don’t have any comments for this section other than reiterating the following points:</p>
<blockquote class="blockquote">
<p><code>descr.__get__(self, obj, type=None)</code></p>
<p><code>descr.__set__(self, obj, value)</code></p>
<p><code>descr.__delete__(self, obj)</code></p>
<p>That is all there is to it. Define any of these methods and an object is considered a descriptor and can override default behavior upon being looked up as an attribute.</p>
</blockquote>
<blockquote class="blockquote">
<p>If an object defines <code>__set__()</code> or <code>__delete__()</code>, it is considered a data descriptor. Descriptors that only define <code>__get__()</code> are called non-data descriptors (they are often used for methods but other uses are possible).</p>
</blockquote>
</section>
<section id="overview-of-descriptor-invocation" class="level3">
<h3 class="anchored" data-anchor-id="overview-of-descriptor-invocation">Overview of descriptor invocation</h3>
<blockquote class="blockquote">
<p>A descriptor can be called directly with <code>desc.__get__(obj)</code> or <code>desc.__get__(None, cls)</code>.</p>
</blockquote>
<blockquote class="blockquote">
<p>But it is more common for a descriptor to be invoked automatically from attribute access.</p>
</blockquote>
<p>We saw this earlier, but putting that example here again:</p>
<div class="cell" data-outputid="4b62a4a6-552d-4080-eb17-deeba13a03de" data-execution_count="127">
<div class="sourceCode cell-code" id="cb92" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><span class="kw" style="color: #003B4F;">class</span> Ten2:</span>
<span id="cb92-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb92-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__get__ called with obj=</span><span class="sc" style="color: #5E5E5E;">{</span>obj<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, objtype=</span><span class="sc" style="color: #5E5E5E;">{</span>objtype<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb92-4">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb92-5"></span>
<span id="cb92-6"><span class="kw" style="color: #003B4F;">class</span> A2:</span>
<span id="cb92-7">    x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb92-8">    y <span class="op" style="color: #5E5E5E;">=</span> Ten2()  <span class="co" style="color: #5E5E5E;"># Descriptor instance</span></span>
<span id="cb92-9"></span>
<span id="cb92-10">a2 <span class="op" style="color: #5E5E5E;">=</span> A2()</span>
<span id="cb92-11">a2.y</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2ded96890&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="127">
<pre><code>10</code></pre>
</div>
</div>
</section>
<section id="invocation-from-an-instance" class="level3">
<h3 class="anchored" data-anchor-id="invocation-from-an-instance">Invocation from an instance</h3>
<blockquote class="blockquote">
<p>Instance lookup scans through a chain of namespaces giving data descriptors the highest priority, followed by instance variables, then non-data descriptors, then class variables, and lastly <code>__getattr__()</code> if it is provided.</p>
</blockquote>
<p>I’ve added some print statements in their example code to show which option is triggered:</p>
<div class="cell" data-execution_count="138">
<div class="sourceCode cell-code" id="cb95" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><span class="kw" style="color: #003B4F;">def</span> find_name_in_mro(cls, name, default):</span>
<span id="cb95-2">    <span class="co" style="color: #5E5E5E;">"Emulate _PyType_Lookup() in Objects/typeobject.c"</span></span>
<span id="cb95-3">    <span class="cf" style="color: #003B4F;">for</span> base <span class="kw" style="color: #003B4F;">in</span> cls.__mro__:</span>
<span id="cb95-4">        <span class="cf" style="color: #003B4F;">if</span> name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">vars</span>(base):</span>
<span id="cb95-5">            <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">vars</span>(base)[name]</span>
<span id="cb95-6">    <span class="cf" style="color: #003B4F;">return</span> default</span>
<span id="cb95-7"></span>
<span id="cb95-8"><span class="kw" style="color: #003B4F;">def</span> object_getattribute(obj, name):</span>
<span id="cb95-9">    <span class="co" style="color: #5E5E5E;">"Emulate PyObject_GenericGetAttr() in Objects/object.c"</span></span>
<span id="cb95-10">    null <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">object</span>()</span>
<span id="cb95-11">    objtype <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">type</span>(obj)</span>
<span id="cb95-12">    cls_var <span class="op" style="color: #5E5E5E;">=</span> find_name_in_mro(objtype, name, null)</span>
<span id="cb95-13">    descr_get <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">getattr</span>(<span class="bu" style="color: null;">type</span>(cls_var), <span class="st" style="color: #20794D;">'__get__'</span>, null)</span>
<span id="cb95-14">    <span class="cf" style="color: #003B4F;">if</span> descr_get <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> null:</span>
<span id="cb95-15">        <span class="cf" style="color: #003B4F;">if</span> (<span class="bu" style="color: null;">hasattr</span>(<span class="bu" style="color: null;">type</span>(cls_var), <span class="st" style="color: #20794D;">'__set__'</span>)</span>
<span id="cb95-16">            <span class="kw" style="color: #003B4F;">or</span> <span class="bu" style="color: null;">hasattr</span>(<span class="bu" style="color: null;">type</span>(cls_var), <span class="st" style="color: #20794D;">'__delete__'</span>)):</span>
<span id="cb95-17">            <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"returning data descriptor set/delete"</span>)</span>
<span id="cb95-18">            <span class="cf" style="color: #003B4F;">return</span> descr_get(cls_var, obj, objtype)     <span class="co" style="color: #5E5E5E;"># data descriptor</span></span>
<span id="cb95-19">    <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">hasattr</span>(obj, <span class="st" style="color: #20794D;">'__dict__'</span>) <span class="kw" style="color: #003B4F;">and</span> name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">vars</span>(obj):</span>
<span id="cb95-20">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"returning instance variable"</span>)</span>
<span id="cb95-21">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">vars</span>(obj)[name]                          <span class="co" style="color: #5E5E5E;"># instance variable</span></span>
<span id="cb95-22">    <span class="cf" style="color: #003B4F;">if</span> descr_get <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> null:</span>
<span id="cb95-23">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"returning descr_get"</span>)</span>
<span id="cb95-24">        <span class="cf" style="color: #003B4F;">return</span> descr_get(cls_var, obj, objtype)         <span class="co" style="color: #5E5E5E;"># non-data descriptor</span></span>
<span id="cb95-25">    <span class="cf" style="color: #003B4F;">if</span> cls_var <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> null:</span>
<span id="cb95-26">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"returning class variable"</span>)</span>
<span id="cb95-27">        <span class="cf" style="color: #003B4F;">return</span> cls_var                                  <span class="co" style="color: #5E5E5E;"># class variable</span></span>
<span id="cb95-28">    <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">AttributeError</span>(name)</span></code></pre></div>
</div>
<div class="cell" data-outputid="7624e6f8-8312-40d2-9c43-178a8e8a5655" data-execution_count="139">
<div class="sourceCode cell-code" id="cb96" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1">object_getattribute(a2, <span class="st" style="color: #20794D;">'y'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>returning descr_get
__get__ called with obj=&lt;__main__.A2 object at 0x78b2ded96890&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="139">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="588ae176-621c-4ae7-b37c-c7a616007844" data-execution_count="140">
<div class="sourceCode cell-code" id="cb99" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1">object_getattribute(a2, <span class="st" style="color: #20794D;">'x'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>returning class variable</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="140">
<pre><code>5</code></pre>
</div>
</div>
<div class="cell" data-execution_count="145">
<div class="sourceCode cell-code" id="cb102" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><span class="kw" style="color: #003B4F;">def</span> getattr_hook(obj, name):</span>
<span id="cb102-2">    <span class="co" style="color: #5E5E5E;">"Emulate slot_tp_getattr_hook() in Objects/typeobject.c"</span></span>
<span id="cb102-3">    <span class="cf" style="color: #003B4F;">try</span>:</span>
<span id="cb102-4">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__getattribute__"</span>)</span>
<span id="cb102-5">        <span class="cf" style="color: #003B4F;">return</span> obj.<span class="fu" style="color: #4758AB;">__getattribute__</span>(name)</span>
<span id="cb102-6">    <span class="cf" style="color: #003B4F;">except</span> <span class="pp" style="color: #AD0000;">AttributeError</span>:</span>
<span id="cb102-7">        <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="bu" style="color: null;">hasattr</span>(<span class="bu" style="color: null;">type</span>(obj), <span class="st" style="color: #20794D;">'__getattr__'</span>):</span>
<span id="cb102-8">            <span class="cf" style="color: #003B4F;">raise</span></span>
<span id="cb102-9">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"__getattr__"</span>)</span>
<span id="cb102-10">    <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">type</span>(obj).<span class="fu" style="color: #4758AB;">__getattr__</span>(obj, name)</span></code></pre></div>
</div>
<div class="cell" data-outputid="0aabb2c0-7a6d-416b-893c-47b6c94dd29e" data-execution_count="146">
<div class="sourceCode cell-code" id="cb103" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1">getattr_hook(a2, <span class="st" style="color: #20794D;">'y'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__getattribute__
__get__ called with obj=&lt;__main__.A2 object at 0x78b2ded96890&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="146">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="f95a8401-3380-4234-b372-e43d61463745" data-execution_count="147">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1">getattr_hook(a2, <span class="st" style="color: #20794D;">'x'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__getattribute__</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="147">
<pre><code>5</code></pre>
</div>
</div>
</section>
<section id="invocation-from-a-class" class="level3">
<h3 class="anchored" data-anchor-id="invocation-from-a-class">Invocation from a class</h3>
<blockquote class="blockquote">
<p>The logic for a dotted lookup such as <code>A.x</code> is in <code>type.__getattribute__()</code>.</p>
</blockquote>
<div class="cell" data-execution_count="150">
<div class="sourceCode cell-code" id="cb109" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1">A2.<span class="fu" style="color: #4758AB;">__getattribute__</span>??</span></code></pre></div>
</div>
<pre><code>Signature:   A2.__getattribute__(*args, **kwargs)
Type:        wrapper_descriptor
String form: &lt;slot wrapper '__getattribute__' of 'object' objects&gt;
Docstring:   Return getattr(self, name).</code></pre>
<div class="cell" data-outputid="a7e35d14-2e01-4cb6-f616-cc491f83a923" data-execution_count="152">
<div class="sourceCode cell-code" id="cb111" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1">A2.<span class="fu" style="color: #4758AB;">__getattribute__</span>(A2, <span class="st" style="color: #20794D;">'y'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="152">
<pre><code>&lt;__main__.Ten2 at 0x78b2dee79310&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="da9fcb9a-e92a-4040-eaee-008bfaff133b" data-execution_count="153">
<div class="sourceCode cell-code" id="cb113" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1">A2.<span class="fu" style="color: #4758AB;">__getattribute__</span>(A2, <span class="st" style="color: #20794D;">'x'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="153">
<pre><code>5</code></pre>
</div>
</div>
</section>
<section id="invocation-from-super" class="level3">
<h3 class="anchored" data-anchor-id="invocation-from-super">Invocation from super</h3>
<blockquote class="blockquote">
<p>A dotted lookup such as <code>super(A, obj).m</code> searches <code>obj.__class__.__mro__</code> for the base class <code>B</code> immediately following <code>A</code> and then returns <code>B.__dict__['m'].__get__(obj, A)</code>. If not a descriptor, <code>m</code> is returned unchanged.</p>
</blockquote>
<div class="cell" data-execution_count="175">
<div class="sourceCode cell-code" id="cb115" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><span class="kw" style="color: #003B4F;">class</span> Base:</span>
<span id="cb115-2">    z <span class="op" style="color: #5E5E5E;">=</span> Ten2()  <span class="co" style="color: #5E5E5E;"># Descriptor in the base class</span></span>
<span id="cb115-3"></span>
<span id="cb115-4"><span class="kw" style="color: #003B4F;">class</span> A2(Base):</span>
<span id="cb115-5">    x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb115-6">    y <span class="op" style="color: #5E5E5E;">=</span> Ten2()  <span class="co" style="color: #5E5E5E;"># Descriptor instance in A2</span></span>
<span id="cb115-7"></span>
<span id="cb115-8">    <span class="kw" style="color: #003B4F;">def</span> show_super_lookup(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb115-9">        <span class="co" style="color: #5E5E5E;"># This will trigger the descriptor lookup through super()</span></span>
<span id="cb115-10">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">super</span>().z</span></code></pre></div>
</div>
<div class="cell" data-outputid="31c162b5-50cb-4d2f-aeab-40bc3a875242" data-execution_count="176">
<div class="sourceCode cell-code" id="cb116" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1">a <span class="op" style="color: #5E5E5E;">=</span> A2()</span>
<span id="cb116-2">a.y</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2dededa90&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="176">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="506d9028-2db4-425b-e3e3-2dadd34ff683" data-execution_count="177">
<div class="sourceCode cell-code" id="cb119" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><span class="bu" style="color: null;">super</span>(A2, a).z</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2dededa90&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="177">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="f4e57871-b58e-4058-ca54-b2d696eca82e" data-execution_count="178">
<div class="sourceCode cell-code" id="cb122" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1">Base.__dict__[<span class="st" style="color: #20794D;">'z'</span>].<span class="fu" style="color: #4758AB;">__get__</span>(a, A2)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2dededa90&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="178">
<pre><code>10</code></pre>
</div>
</div>
<div class="cell" data-outputid="b2270d8e-31ea-4f77-d03f-f9679b1e541e" data-execution_count="179">
<div class="sourceCode cell-code" id="cb125" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1">a.__class__.__mro__</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="179">
<pre><code>(__main__.A2, __main__.Base, object)</code></pre>
</div>
</div>
</section>
<section id="summary-of-invocation-logic" class="level3">
<h3 class="anchored" data-anchor-id="summary-of-invocation-logic">Summary of invocation logic</h3>
<p>Showing examples of some of the bullet points in the summary:</p>
<ul>
<li>Descriptors are invoked by the <code>__getattribute__()</code> method.</li>
</ul>
<div class="cell" data-outputid="ea38ba47-a928-4128-a1fb-cbc231fa3a35" data-execution_count="180">
<div class="sourceCode cell-code" id="cb127" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1">a.<span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="st" style="color: #20794D;">'y'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.A2 object at 0x78b2dededa90&gt;, objtype=&lt;class '__main__.A2'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="180">
<pre><code>10</code></pre>
</div>
</div>
<ul>
<li>Overriding <code>__getattribute__()</code> prevents automatic descriptor calls because all the descriptor logic is in that method.</li>
</ul>
<div class="cell" data-outputid="68ac78c2-2ec1-4ee6-f840-32491435634e" data-execution_count="195">
<div class="sourceCode cell-code" id="cb130" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><span class="kw" style="color: #003B4F;">class</span> MyDescriptor:</span>
<span id="cb130-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb130-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Descriptor __get__ called!"</span>)</span>
<span id="cb130-4">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">42</span></span>
<span id="cb130-5"></span>
<span id="cb130-6"><span class="kw" style="color: #003B4F;">class</span> Normal:</span>
<span id="cb130-7">    x <span class="op" style="color: #5E5E5E;">=</span> MyDescriptor()</span>
<span id="cb130-8"></span>
<span id="cb130-9">n <span class="op" style="color: #5E5E5E;">=</span> Normal()</span>
<span id="cb130-10">n.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Descriptor __get__ called!</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="195">
<pre><code>42</code></pre>
</div>
</div>
<div class="cell" data-outputid="4c3bfd01-d824-4254-9e21-daf3ab13b60b" data-execution_count="196">
<div class="sourceCode cell-code" id="cb133" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb133-1"><span class="kw" style="color: #003B4F;">class</span> OverrideGetattribute:</span>
<span id="cb133-2">    x <span class="op" style="color: #5E5E5E;">=</span> MyDescriptor()</span>
<span id="cb133-3">    y <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb133-4"></span>
<span id="cb133-5">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="va" style="color: #111111;">self</span>, name):</span>
<span id="cb133-6">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Custom __getattribute__ called for </span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb133-7">        <span class="cf" style="color: #003B4F;">if</span> name <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'x'</span>:</span>
<span id="cb133-8">            <span class="cf" style="color: #003B4F;">return</span> <span class="st" style="color: #20794D;">"Bypassed descriptor"</span></span>
<span id="cb133-9">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">object</span>.<span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="va" style="color: #111111;">self</span>, name)</span>
<span id="cb133-10"></span>
<span id="cb133-11">o <span class="op" style="color: #5E5E5E;">=</span> OverrideGetattribute()</span>
<span id="cb133-12">o.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Custom __getattribute__ called for x</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="196">
<pre><code>'Bypassed descriptor'</code></pre>
</div>
</div>
<div class="cell" data-outputid="db10e098-648b-42ca-8ca4-51a062eb62c8" data-execution_count="197">
<div class="sourceCode cell-code" id="cb136" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1">o.y</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Custom __getattribute__ called for y</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="197">
<pre><code>5</code></pre>
</div>
</div>
<ul>
<li><code>object.__getattribute__()</code> and <code>type.__getattribute__()</code> make different calls to <code>__get__()</code>. The first includes the instance and may include the class. The second puts in <code>None</code> for the instance and always includes the class.</li>
</ul>
<div class="cell" data-execution_count="208">
<div class="sourceCode cell-code" id="cb139" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb139-1"><span class="kw" style="color: #003B4F;">class</span> DetailedDescriptor:</span>
<span id="cb139-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb139-3">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__get__ called with obj=</span><span class="sc" style="color: #5E5E5E;">{</span>obj<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, objtype=</span><span class="sc" style="color: #5E5E5E;">{</span>objtype<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb139-4">        <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">42</span></span>
<span id="cb139-5"></span>
<span id="cb139-6"><span class="kw" style="color: #003B4F;">class</span> Normal:</span>
<span id="cb139-7">    x <span class="op" style="color: #5E5E5E;">=</span> DetailedDescriptor()</span>
<span id="cb139-8"></span>
<span id="cb139-9">n <span class="op" style="color: #5E5E5E;">=</span> Normal()</span></code></pre></div>
</div>
<div class="cell" data-outputid="0d60c5f0-9623-4c6f-ccb4-fbcddfa7a428" data-execution_count="209">
<div class="sourceCode cell-code" id="cb140" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1">n.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=&lt;__main__.Normal object at 0x78b2dedf0750&gt;, objtype=&lt;class '__main__.Normal'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="209">
<pre><code>42</code></pre>
</div>
</div>
<div class="cell" data-outputid="cc7f4537-465e-48e7-c91d-0060eac405d9" data-execution_count="210">
<div class="sourceCode cell-code" id="cb143" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb143-1">Normal.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>__get__ called with obj=None, objtype=&lt;class '__main__.Normal'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="210">
<pre><code>42</code></pre>
</div>
</div>
<ul>
<li>Data descriptors always override instance dictionaries.</li>
</ul>
<div class="cell" data-execution_count="211">
<div class="sourceCode cell-code" id="cb146" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><span class="kw" style="color: #003B4F;">class</span> DataDescriptor:</span>
<span id="cb146-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, initial_value<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb146-3">        <span class="va" style="color: #111111;">self</span>.value <span class="op" style="color: #5E5E5E;">=</span> initial_value</span>
<span id="cb146-4"></span>
<span id="cb146-5">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb146-6">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"DataDescriptor.__get__ called"</span>)</span>
<span id="cb146-7">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.value</span>
<span id="cb146-8"></span>
<span id="cb146-9">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__set__</span>(<span class="va" style="color: #111111;">self</span>, obj, value):</span>
<span id="cb146-10">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"DataDescriptor.__set__ called with value: </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb146-11">        <span class="va" style="color: #111111;">self</span>.value <span class="op" style="color: #5E5E5E;">=</span> value</span>
<span id="cb146-12"></span>
<span id="cb146-13"><span class="kw" style="color: #003B4F;">class</span> Example:</span>
<span id="cb146-14">    x <span class="op" style="color: #5E5E5E;">=</span> DataDescriptor(<span class="dv" style="color: #AD0000;">42</span>)  <span class="co" style="color: #5E5E5E;"># Data descriptor defined in class</span></span>
<span id="cb146-15"></span>
<span id="cb146-16">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb146-17">        <span class="co" style="color: #5E5E5E;"># Try to override with instance attribute</span></span>
<span id="cb146-18">        <span class="va" style="color: #111111;">self</span>.__dict__[<span class="st" style="color: #20794D;">'x'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Instance value"</span></span>
<span id="cb146-19"></span>
<span id="cb146-20"></span>
<span id="cb146-21">example <span class="op" style="color: #5E5E5E;">=</span> Example()</span></code></pre></div>
</div>
<div class="cell" data-outputid="1733a8ce-6f53-4e41-9649-7fa4ddd997f3" data-execution_count="212">
<div class="sourceCode cell-code" id="cb147" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1">example.__dict__</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="212">
<pre><code>{'x': 'Instance value'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="1d03bcd6-c2b8-4c63-cbfc-cc7c91dbe214" data-execution_count="213">
<div class="sourceCode cell-code" id="cb149" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1">example.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DataDescriptor.__get__ called</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="213">
<pre><code>42</code></pre>
</div>
</div>
<div class="cell" data-outputid="11962f2b-4023-4831-cbb2-cff4a1d85fa1" data-execution_count="215">
<div class="sourceCode cell-code" id="cb152" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1">example.x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">100</span></span>
<span id="cb152-2">example.__dict__[<span class="st" style="color: #20794D;">'x'</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DataDescriptor.__set__ called with value: 100</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="215">
<pre><code>'Instance value'</code></pre>
</div>
</div>
<div class="cell" data-outputid="b74e3010-a30c-4e4e-b9e3-6d8ddee5a1e8" data-execution_count="216">
<div class="sourceCode cell-code" id="cb155" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1">example.x</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>DataDescriptor.__get__ called</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="216">
<pre><code>100</code></pre>
</div>
</div>
<ul>
<li>Non-data descriptors may be overridden by instance dictionaries.</li>
</ul>
<div class="cell" data-execution_count="217">
<div class="sourceCode cell-code" id="cb158" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><span class="kw" style="color: #003B4F;">class</span> NonDataDescriptor:</span>
<span id="cb158-2">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, initial_value<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb158-3">        <span class="va" style="color: #111111;">self</span>.value <span class="op" style="color: #5E5E5E;">=</span> initial_value</span>
<span id="cb158-4"></span>
<span id="cb158-5">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb158-6">        <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"DataDescriptor.__get__ called"</span>)</span>
<span id="cb158-7">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.value</span>
<span id="cb158-8"></span>
<span id="cb158-9"><span class="kw" style="color: #003B4F;">class</span> Example:</span>
<span id="cb158-10">    x <span class="op" style="color: #5E5E5E;">=</span> NonDataDescriptor(<span class="dv" style="color: #AD0000;">42</span>)  <span class="co" style="color: #5E5E5E;"># Data descriptor defined in class</span></span>
<span id="cb158-11"></span>
<span id="cb158-12">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb158-13">        <span class="co" style="color: #5E5E5E;"># Try to override with instance attribute</span></span>
<span id="cb158-14">        <span class="va" style="color: #111111;">self</span>.__dict__[<span class="st" style="color: #20794D;">'x'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"Instance value"</span></span>
<span id="cb158-15"></span>
<span id="cb158-16"></span>
<span id="cb158-17">example <span class="op" style="color: #5E5E5E;">=</span> Example()</span></code></pre></div>
</div>
<div class="cell" data-outputid="2e68841b-5462-42ae-d551-9bda604be404" data-execution_count="218">
<div class="sourceCode cell-code" id="cb159" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb159-1">example.__dict__</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="218">
<pre><code>{'x': 'Instance value'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="01acab7f-edb3-4c11-e650-0fa57a156ceb" data-execution_count="219">
<div class="sourceCode cell-code" id="cb161" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb161-1">example.x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="219">
<pre><code>'Instance value'</code></pre>
</div>
</div>
</section>
<section id="automatic-name-notification" class="level3">
<h3 class="anchored" data-anchor-id="automatic-name-notification">Automatic name notification</h3>
<blockquote class="blockquote">
<p>Sometimes it is desirable for a descriptor to know what class variable name it was assigned to. When a new class is created, the <code>type</code> metaclass scans the dictionary of the new class. If any of the entries are descriptors and if they define <code>__set_name__()</code>, that method is called with two arguments. The owner is the class where the descriptor is used, and the name is the class variable the descriptor was assigned to.</p>
</blockquote>
<div class="cell" data-execution_count="227">
<div class="sourceCode cell-code" id="cb163" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><span class="kw" style="color: #003B4F;">class</span> NameTracker:</span>
<span id="cb163-2">   <span class="kw" style="color: #003B4F;">def</span> __set_name__(<span class="va" style="color: #111111;">self</span>, owner, name): <span class="va" style="color: #111111;">self</span>.name <span class="op" style="color: #5E5E5E;">=</span> name</span></code></pre></div>
</div>
<div class="cell" data-execution_count="228">
<div class="sourceCode cell-code" id="cb164" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1">class_dict <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb164-2">        <span class="st" style="color: #20794D;">'x'</span>: NameTracker(),</span>
<span id="cb164-3">        <span class="st" style="color: #20794D;">'y'</span>: NameTracker(),</span>
<span id="cb164-4">        <span class="st" style="color: #20794D;">'z'</span>: <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb164-5">    }</span></code></pre></div>
</div>
<div class="cell" data-execution_count="229">
<div class="sourceCode cell-code" id="cb165" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1">Demo <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">type</span>(<span class="st" style="color: #20794D;">'Demo'</span>, (), class_dict)</span></code></pre></div>
</div>
<div class="cell" data-outputid="c1ee1f3c-ddbe-4e35-bced-a11f96ae3cc4" data-execution_count="231">
<div class="sourceCode cell-code" id="cb166" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb166-1">Demo.x.name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="231">
<pre><code>'x'</code></pre>
</div>
</div>
<div class="cell" data-outputid="b3867517-a51b-4675-b24b-70b33ce13579" data-execution_count="232">
<div class="sourceCode cell-code" id="cb168" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1">Demo.y.name</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="232">
<pre><code>'y'</code></pre>
</div>
</div>
<p>I’m skipping the ORM example since I don’t have access to the example database.</p>
</section>
</section>
<section id="pure-python-equivalents" class="level2">
<h2 class="anchored" data-anchor-id="pure-python-equivalents">Pure Python Equivalents</h2>
<p>Finally! The section I’m most interested in.</p>
<blockquote class="blockquote">
<p>Properties, bound methods, static methods, class methods, and <code>__slots__</code> are all based on the descriptor protocol.</p>
</blockquote>
<p>I’m going to focus on the functions and methods section.</p>
<section id="functions-and-methods" class="level3">
<h3 class="anchored" data-anchor-id="functions-and-methods">Functions and methods</h3>
<blockquote class="blockquote">
<p>Functions stored in class dictionaries get turned into methods when invoked. Methods only differ from regular functions in that the object instance is prepended to the other arguments. By convention, the instance is called self but could be called this or any other variable name.</p>
</blockquote>
<blockquote class="blockquote">
<p>Methods can be created manually with types.MethodType which is roughly equivalent to:</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb170" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><span class="kw" style="color: #003B4F;">class</span> MethodType:</span>
<span id="cb170-2">    <span class="co" style="color: #5E5E5E;">"Emulate PyMethod_Type in Objects/classobject.c"</span></span>
<span id="cb170-3"></span>
<span id="cb170-4">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, func, obj):</span>
<span id="cb170-5">        <span class="va" style="color: #111111;">self</span>.__func__ <span class="op" style="color: #5E5E5E;">=</span> func</span>
<span id="cb170-6">        <span class="va" style="color: #111111;">self</span>.__self__ <span class="op" style="color: #5E5E5E;">=</span> obj</span>
<span id="cb170-7"></span>
<span id="cb170-8">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__call__</span>(<span class="va" style="color: #111111;">self</span>, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb170-9">        func <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.__func__</span>
<span id="cb170-10">        obj <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.__self__</span>
<span id="cb170-11">        <span class="cf" style="color: #003B4F;">return</span> func(obj, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span>
<span id="cb170-12"></span>
<span id="cb170-13">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="va" style="color: #111111;">self</span>, name):</span>
<span id="cb170-14">        <span class="co" style="color: #5E5E5E;">"Emulate method_getset() in Objects/classobject.c"</span></span>
<span id="cb170-15">        <span class="cf" style="color: #003B4F;">if</span> name <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'__doc__'</span>:</span>
<span id="cb170-16">            <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.__func__.__doc__</span>
<span id="cb170-17">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">object</span>.<span class="fu" style="color: #4758AB;">__getattribute__</span>(<span class="va" style="color: #111111;">self</span>, name)</span>
<span id="cb170-18"></span>
<span id="cb170-19">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__getattr__</span>(<span class="va" style="color: #111111;">self</span>, name):</span>
<span id="cb170-20">        <span class="co" style="color: #5E5E5E;">"Emulate method_getattro() in Objects/classobject.c"</span></span>
<span id="cb170-21">        <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">getattr</span>(<span class="va" style="color: #111111;">self</span>.__func__, name)</span>
<span id="cb170-22"></span>
<span id="cb170-23">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb170-24">        <span class="co" style="color: #5E5E5E;">"Emulate method_descr_get() in Objects/classobject.c"</span></span>
<span id="cb170-25">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span></span></code></pre></div>
</div>
<p>The key dunder method of interest is <code>__call</code>__:</p>
<div class="sourceCode" id="cb171" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb171-1"><span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__call__</span>(<span class="va" style="color: #111111;">self</span>, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb171-2">    func <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.__func__</span>
<span id="cb171-3">    obj <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.__self__</span>
<span id="cb171-4">    <span class="cf" style="color: #003B4F;">return</span> func(obj, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs)</span></code></pre></div>
<p>In the example of the self attention module, it has no positional arguments <code>*args</code> and so when I passed <code>self_attn</code> to the <code>obj</code> parameter in <code>func(obj, *args, **kwargs)</code> it understood it to be the first keyword argument.</p>
<blockquote class="blockquote">
<p>The interesting behavior occurs during dotted access from an instance. The dotted lookup calls <strong>get</strong>() which returns a bound method object:</p>
</blockquote>
<div class="cell" data-execution_count="236">
<div class="sourceCode cell-code" id="cb172" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><span class="kw" style="color: #003B4F;">class</span> D:</span>
<span id="cb172-2">    <span class="kw" style="color: #003B4F;">def</span> f(<span class="va" style="color: #111111;">self</span>):</span>
<span id="cb172-3">         <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span></span></code></pre></div>
</div>
<div class="cell" data-outputid="d7863453-4518-4486-909a-226a3a4b8b2c" data-execution_count="238">
<div class="sourceCode cell-code" id="cb173" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1">d <span class="op" style="color: #5E5E5E;">=</span> D()</span>
<span id="cb173-2"><span class="bu" style="color: null;">print</span>(d.f)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;bound method D.f of &lt;__main__.D object at 0x78b2dec54790&gt;&gt;</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Internally, the bound method stores the underlying function and the bound instance:</p>
</blockquote>
<div class="cell" data-outputid="e01f04f2-79f4-4fb7-df6d-734f9a3490e7" data-execution_count="240">
<div class="sourceCode cell-code" id="cb175" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><span class="bu" style="color: null;">print</span>(d.f.__func__)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;function D.f at 0x78b2dedd3ba0&gt;</code></pre>
</div>
</div>
<div class="cell" data-outputid="be868138-560a-4319-d92a-2572e6d78318" data-execution_count="241">
<div class="sourceCode cell-code" id="cb177" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><span class="bu" style="color: null;">print</span>(d.f.__self__)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;__main__.D object at 0x78b2dec54790&gt;</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>If you have ever wondered where <code>self</code> comes from in regular methods or where <code>cls</code> comes from in class methods, this is it!</p>
</blockquote>
</section>
<section id="kinds-of-methods" class="level3">
<h3 class="anchored" data-anchor-id="kinds-of-methods">Kinds of methods</h3>
<p>Here’s the crux of what I was looking for:</p>
<blockquote class="blockquote">
<p>To recap, functions have a <code>__get__()</code> method so that they can be converted to a method when accessed as attributes. The non-data descriptor transforms an <code>obj.f(*args</code>) call into <code>f(obj, *args)</code>. Calling <code>cls.f(*args)</code> becomes <code>f(*args)</code>.</p>
</blockquote>
<p>If I call <code>__get__(d)</code> on <code>d.f</code> it creates a bound method which passes in the object as <code>self</code>, the first argument of a bound method.</p>
<div class="cell" data-outputid="881f67c4-ba12-49a2-f010-d585a5594103" data-execution_count="243">
<div class="sourceCode cell-code" id="cb179" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb179-1"><span class="bu" style="color: null;">print</span>(d.f.<span class="fu" style="color: #4758AB;">__get__</span>(d))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;bound method D.f of &lt;__main__.D object at 0x78b2dec54790&gt;&gt;</code></pre>
</div>
</div>
<p>Now when I call <code>d.f.__get__(d)()</code> I don’t need to explicitly pass in the object:</p>
<div class="cell" data-outputid="b9d99ad4-baa0-4101-b3bc-a8de2a759be3" data-execution_count="244">
<div class="sourceCode cell-code" id="cb181" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1">d.f.<span class="fu" style="color: #4758AB;">__get__</span>(d)()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="244">
<pre><code>&lt;__main__.D at 0x78b2dec54790&gt;</code></pre>
</div>
</div>
</section>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>Thanks to vibe coding, Claude introduced me to Python behavior I was unfamiliar with, and thanks to the excellent Python documentation, I understood it at a much deeper level than I was planning to.</p>
<p>I think something that still confuses me, and where I feel empathy for <a href="https://discuss.python.org/t/changing-the-name-of-get-to-bind/14243">this poster</a>, is how <code>__get__</code> has special behavior for functions where it binds it to the given object.</p>
<p>In the Primer, initial examples of <code>__get__</code> all, well, get a value:</p>
<div class="sourceCode" id="cb183" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1"><span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb183-2">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"__get__ called with obj=</span><span class="sc" style="color: #5E5E5E;">{</span>obj<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, objtype=</span><span class="sc" style="color: #5E5E5E;">{</span>objtype<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb183-3">    <span class="cf" style="color: #003B4F;">return</span> <span class="dv" style="color: #AD0000;">10</span></span>
<span id="cb183-4"></span>
<span id="cb183-5"></span>
<span id="cb183-6"><span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb183-7">    <span class="cf" style="color: #003B4F;">return</span> <span class="bu" style="color: null;">len</span>(os.listdir(obj.dirname))</span>
<span id="cb183-8"></span>
<span id="cb183-9"></span>
<span id="cb183-10"><span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__get__</span>(<span class="va" style="color: #111111;">self</span>, obj, objtype<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb183-11">    value <span class="op" style="color: #5E5E5E;">=</span> obj._age</span>
<span id="cb183-12">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Accessing age giving </span><span class="sc" style="color: #5E5E5E;">{</span>value<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb183-13">    <span class="cf" style="color: #003B4F;">return</span> value</span></code></pre></div>
<p>How that behavior is related to binding a function to an object is beyond my current understanding.</p>
<p>This poster’s response does make sense:</p>
<blockquote class="blockquote">
<p>If descriptors were only callables that bind as methods when accessed as an attribute, then perhaps <code>__bind__()</code> would be a reasonable name for the method. But the descriptor protocol (i.e.&nbsp;<code>__get__</code>, <code>__set__</code>, and <code>__delete__</code>) is a means of implementing a computed attribute in general, which is not necessarily about binding a callable to the instance or type. For example, the <code>__get__()</code> method of a property named <code>x</code> might return the instance attribute <code>_x</code>.</p>
</blockquote>
<p>So perhaps of a computed attributed is generalizable whether your using <code>__get__</code> on a callable descriptor or otherwise. For a function, the “computation” of the attribute is binding it to the object.</p>
<p>I hope you enjoyed this blog post! I’m trying to <a href="https://www.youtube.com/@vishal_learner">grow my YouTube channel</a> so please give that a look/subscribe.</p>


</section>

 ]]></description>
  <category>python</category>
  <category>deep learning</category>
  <category>LLM</category>
  <guid>https://vishalbakshi.github.io/blog/posts/2025-04-01-Python-Descriptor/index.html</guid>
  <pubDate>Tue, 01 Apr 2025 07:00:00 GMT</pubDate>
</item>
</channel>
</rss>
